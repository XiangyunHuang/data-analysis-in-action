[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R 语言数据分析实战",
    "section": "",
    "text": "欢迎\n\n\n\n\n\n\n警告\n\n\n\nBook in early development. Planned release in 2024.\n\n\n本书初稿是在 RStudio IDE 内使用 Quarto 编辑的，Quarto 是继R Markdown之后，一个新的开源的科学和技术发布系统，它基于 Pandoc支持输出多种格式的书稿，比如 HTML 网页、EPUB 电子书、DOCX 文档和 PDF 便携式文档等。Quarto 吸收了过去 10 年 R Markdown 取得的经验和教训，在书籍写作、创建博客、制作简历和幻灯片等系列场景中支持更加统一的使用语法，一份源文档输出多种格式，使文档内容在不同场景中的迁移成本更低。了解更多 Quarto 特性，请访问 https://quarto.org/。\n书中的代码字体采用美观的 Source Code Pro 字体， 为方便跨操作系统编译书籍电子版，正文的中文字体采用开源的 fandol 字体。此外，考虑到美观性，本书图形使用了 Noto 系列中英文字体，它们来自 Google Fonts 字体库，分别是 Noto Sans 无衬线英文字体和 Noto Serif SC 宋体中文字体。\n书中 R 包名以粗体表示，如 knitr 包，函数名以等宽体表示，如 plot()，函数的参数名同理。代码块内注释用 # 表示，运行结果每一行开头以 #&gt; 标记。本书写作过程中，依赖 knitr (Xie 2015)、ggplot2 (Wickham 2016) 和 lattice (Sarkar 2008) 等众多 R 包。考虑到要同时支持 DOCX、EPUB、PDF 和 HTML 四种书籍格式，书中使用 knitr 包和 gt 包制作静态的表格。\n为方便测试贡献者提供的 PR，本书托管在 Github 上，同时启用 Github Action 服务，为书籍自定义了一个可复现全书内容的运行环境，包括 R 软件、扩展包和系统软件依赖，详见仓库中的 DESCRIPTION 文件。你现在看到的是在线编译版本，使用 Quarto 1.4.547，最新一次编译时间是 2024-01-23 15:13:35。\n\nxfun::session_info(packages = c(\n  \"ggplot2\", \"gganimate\", \"ggrepel\", \"ggraph\",\n  \"ggridges\", \"ggsignif\", \"ggforce\", \"ggdensity\",\n  \"ggbeeswarm\", \"ggeffects\", \"ggnewscale\",\n  \"patchwork\", \"shiny\", \"plotly\", \"lattice\", \n  \"dplyr\", \"purrr\", \"tidyr\", \"data.table\",\n  \"rsconnect\", \"knitr\", \"rmarkdown\", \"gt\", \"DT\",\n  \"mgcv\", \"glmnet\", \"lme4\", \"xgboost\", \"spaMM\",\n  \"sf\", \"stars\", \"terra\", \"INLA\", \"cmdstanr\",\n  \"showtext\", \"gifski\", \"tinytex\", \"magick\"\n), dependencies = FALSE)\n\n#&gt; R version 4.3.2 (2023-10-31)\n#&gt; Platform: x86_64-apple-darwin20 (64-bit)\n#&gt; Running under: macOS Ventura 13.6.3\n#&gt; \n#&gt; Locale: en_US.UTF-8 / en_US.UTF-8 / en_US.UTF-8 / C / en_US.UTF-8 / en_US.UTF-8\n#&gt; \n#&gt; Package version:\n#&gt;   cmdstanr_0.7.1     data.table_1.14.10 dplyr_1.1.4        DT_0.31           \n#&gt;   gganimate_1.0.8    ggbeeswarm_0.7.2   ggdensity_1.0.0    ggeffects_1.3.4   \n#&gt;   ggforce_0.4.1      ggnewscale_0.4.9   ggplot2_3.5.0      ggraph_2.1.0.9000 \n#&gt;   ggrepel_0.9.5      ggridges_0.5.5     ggsignif_0.6.4     gifski_1.12.0.2   \n#&gt;   glmnet_4.1.8       gt_0.10.1          INLA_23.9.9        knitr_1.45        \n#&gt;   lattice_0.21.9     lme4_1.1.35.1      magick_2.8.2       mgcv_1.9.0        \n#&gt;   patchwork_1.2.0    plotly_4.10.4      purrr_1.0.2        rmarkdown_2.25    \n#&gt;   rsconnect_1.2.0    sf_1.0.15          shiny_1.8.0        showtext_0.9.6    \n#&gt;   spaMM_4.4.16       stars_0.6.4        terra_1.7.65       tidyr_1.3.0       \n#&gt;   tinytex_0.49       xgboost_1.7.6.1   \n#&gt; \n#&gt; Pandoc version: 3.1.11\n#&gt; \n#&gt; LaTeX version used: \n#&gt;   TeX Live 2023 (TinyTeX) with tlmgr 2024-01-13\n\n\n\n\n\n\nSarkar, Deepayan. 2008. lattice: Multivariate Data Visualization with R. New York: Springer. http://lmdvr.r-forge.r-project.org.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant Graphics for Data Analysis. 2nd 本. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and knitr. 2nd 本. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.",
    "crumbs": [
      "欢迎"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "前言",
    "section": "",
    "text": "为什么是 R 语言？\nR 语言在统计图形方面不仅走得早还走得远，当然，Python 语言也不错，近年来新起的 Julia 语言也很好。R 语言在统计图形方面的沉淀是非常深厚的，近年来，我发现越是简洁的越是优美，灵活的东西使用起来还非常简单，以 R 包 datasets内的数据集 PlantGrowth 为例，一般地，展示数据的分布会想到箱线图、直方图、密度图等，R 函数的泛型设计可以根据数据对象和变量的类型自动选择合适的图形， 图 植物干重 是泛型函数 plot() 调用普通函数 boxplot() 和 spineplot() 绘制的。\n所以，直接调用相应的绘图函数也是可以的，如下：\nboxplot(weight ~ group, data = PlantGrowth, \n        ylab = \"植物干重\", xlab = \"组\")\nspineplot(cut(weight, 2) ~ group, data = PlantGrowth, \n          ylab = \"植物干重\", xlab = \"组\")\n脊柱图是马赛克图的一种特殊情况，也可以看做是堆积条形图的推广形式或者直方图的扩展。上面 cut() 函数的作用是将数值型变量 weight 分桶，对照组（control，简写 ctrl）和两个不同的实验组（treatment，简写 trt）都按同样的划分方式分作两桶。\ndat &lt;- transform(PlantGrowth, weight_bucket = cut(weight, 2))\naggregate(data = dat, weight ~ weight_bucket + group, FUN = length)\n\n#&gt;   weight_bucket group weight\n#&gt; 1   (3.59,4.95]  ctrl      4\n#&gt; 2   (4.95,6.31]  ctrl      6\n#&gt; 3   (3.59,4.95]  trt1      8\n#&gt; 4   (4.95,6.31]  trt1      2\n#&gt; 5   (3.59,4.95]  trt2      1\n#&gt; 6   (4.95,6.31]  trt2      9",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-why-r",
    "href": "preface.html#sec-why-r",
    "title": "前言",
    "section": "",
    "text": "(a) 箱线图\n\n\n\n\n\n\n\n\n\n(b) 脊柱图\n\n\n\n\n\n\n图 1: 影响植物生长的因素",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-why-book",
    "href": "preface.html#sec-why-book",
    "title": "前言",
    "section": "为什么写这本书？",
    "text": "为什么写这本书？\n近年来，数字经济成为热门词汇，企业数字化转型离不开数据，精细化运营更离不开数据分析，数据分析受到越来越多的关注。在数据分析领域，R 语言越来越流行，一本以 R 语言为依托，以实战为导向的数据分析书，市面上还不多。\n\n提供完整可复现的书籍源码，书中示例可以在 R 语言环境下复现。\n数据可视化部分，以一个真实数据串联绘图的基本要素，从图形的用途出发，将图形分类，结合真实数据介绍图形。\n展现数据分析的完整工作流，数据获取、操作、处理、可视化探索和分析、展示交流、建模分析、解释。\n将工作流应用于特定领域的数据分析，覆盖网络数据、文本数据、时序数据、空间数据等四大常见且重要的场景。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-how-book",
    "href": "preface.html#sec-how-book",
    "title": "前言",
    "section": "本书是怎么写的？",
    "text": "本书是怎么写的？\n\n本书在写作风格上借鉴了以下书籍\n\n《现代统计图形》 (赵鹏, 谢益辉, 和 黄湘云 2021) 讲清楚统计图形的来龙去脉，提供丰富的实战案例。\n《R in Action》(Kabacoff 2022) 根据入门、进阶和高阶将书籍内容分出层次。\n《R for Data Science》 (Wickham, Çetinkaya-Rundel, 和 Grolemund 2023) 根据数据分析的整个工作流拆分各个部分、章节。\n\n本书的写作素材来源非常广泛，比如\n\n大量的原始论文、书籍，回顾经典理论、数据案例，追根溯源\n大量的 R 包帮助文档，配合真实数据提供软件工具的使用说明\n一些国内外政府网站发布的权威数据，提供大量的实际案例数据\n从国内外论坛、书店搜集数据操作、展示和交流等方面的高频问题",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-intrinsical-motivation",
    "href": "preface.html#sec-intrinsical-motivation",
    "title": "前言",
    "section": "写作理念是什么？",
    "text": "写作理念是什么？\n\n\n以真实的数据为基础，介绍数据分析所用到的软件工具、统计方法和算法模型，对经典的数据分析案例，力求还原历史，讲清楚故事背景，数据处理的过程，不单单是分析方法和结果。\n尽可能选用来自社会、经济、文化、历史等方面的真实的、最新的或经典的数据，在讲数据分析技术的同时，也了解一点我们所处的社会，希望给读者一些启发，勾起读者的兴趣，主动探寻有趣的问题，收集整理所需的数据，做自己的研究，找到问题的答案，享受数据探索分析的过程，摸索出适合自己的分析方法和分析工具。\n结合多年使用 R 语言的经验以及最近几年在互联网行业工作的体会，形成数据分析师的技能栈，梳理知识体系，沉淀一套数据分析的方法。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-who-book",
    "href": "preface.html#sec-who-book",
    "title": "前言",
    "section": "目标读者是哪些？",
    "text": "目标读者是哪些？\n\n\n想通过编程实现数据分析的完整过程，使得整个过程可以复现，可以重复利用。\n对数据分析的实战有兴趣，想将数据分析技能应用于解决实际问题。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-what-book",
    "href": "preface.html#sec-what-book",
    "title": "前言",
    "section": "本书有哪些内容？",
    "text": "本书有哪些内容？\n\n入门部分：介绍软件 R、 RStudio 和 VS Code 的安装配置过程，常见的基本数据结构和类型，循环、判断、函数等基本的编程知识。\n数据部分：从本地文件、远程数据库、网页爬取等数据获取方式，筛选、变换、重塑、排序等基础的数据操作，离群值、异常值检测，缺失值处理等基础的数据处理\n展示部分：ggplot2 基础、统计图形、实战应用、经验总结\n交流部分：交互的图形、表格和应用，动态的 HTML 网页、PDF 文档和办公文档。\n建模部分：线性模型、广义线性模型、混合效应模型、数据挖掘算法和神经网络模型\n应用部分：网络数据、文本数据、时序数据、空间数据的分析\n其它部分：参数估计、假设检验和抽样分布等基础的统计推断，L-BFGS 算法、EM 算法等统计计算，自助法、重抽样等统计模拟。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-finding-public-datasets",
    "href": "preface.html#sec-finding-public-datasets",
    "title": "前言",
    "section": "公开数据从哪找？",
    "text": "公开数据从哪找？\n\n各国、各级政府的统计局，比如美国人口调查局、中国国家统计局等。\n国际、国内各类组织机构，比如世界银行、美国疾病预防控制中心等。\n各类网站提供的数据集，比如 GitHub 开放数据集列表 awesome-public-datasets，kaggle 网站提供大量数据分析竞赛及相应的数据集。\nR 包内置数据集，已整理得很好，比如 spData 包 收集整理了很多空间统计方面的数据集。Rdatasets 更是收集约 1900 个数据集，全部来自 CRAN 上发布的 R 包。\n一些 R 包封装数据下载的接口，比如tidyBdE包可以下载西班牙银行开放的数据，WDI 可以下载世界银行开放的数据。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-asking-the-right-questions",
    "href": "preface.html#sec-asking-the-right-questions",
    "title": "前言",
    "section": "学会有效地提问？",
    "text": "学会有效地提问？\n\n想清楚自己的问题是什么？尽力做好拆解和界定。\n去掉枝叶，保留主干，提供最小的可重复的示例。\n有耐心地等待社区的回应，积极地与社区沟通。\n为社区提供力所能及的帮助，提升自己的影响力。\n\n\n\n\n\nKabacoff, Robert I. 2022. R in Action: Data Analysis and graphics with R and Tidyverse. 3rd 本. Shelter Island, NY: Manning Publications Co.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, 和 Garrett Grolemund. 2023. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 2nd 本. Sebastopol, California: O’Reilly Media, Inc. https://r4ds.hadley.nz/.\n\n\n赵鹏, 谢益辉, 和 黄湘云. 2021. 现代统计图形. 北京: 人民邮电出版社. https://bookdown.org/xiangyun/msg.",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "介绍",
    "section": "",
    "text": "数据探索和分析\n数据可视化是数据探索和分析的一个手段，数据可视化的主要目的有两个：其一是探索 Explore，其二是解释 Explain。\n探索是面向数据分析师自己，而展示是面向数据分析的消费者。面对不同的角色，可视化的目的是不一样的，探索是了解数据，展示是传递信息。了解数据的分布、隐藏的模式、缺失情况、异常情况，步步深入地挖掘数据的潜在规律。展示是传递数据分析的结论和洞见，强调美观、效率、效果，除了数据分析师本人几乎没人想看探索数据过程中产生的数以十计的中间图形。\n数据可视化是通过计算机程序绘制图形来展示数据，有时是在图上展示原始数据，比如散点图，有时展示汇总数据，比如直方图，有时借助一些数据变换，比如对数变换，甚至更为复杂的统计变换。数据可视化主要是描述、提炼和汇总原始数据，从数据中获取信息。\n除了选择合适的工具（Base R / grid / lattice / ggplot2）绘制图形（提供 R 代码实现），选择图形（30+多种常见图形）和解释图形（真实数据背景）往往比想的更加困难，本书试图去回答这些问题。\n大多教科书侧重理论和方法，计算机强调编程，数值计算是精确的，图形是粗燥的。然而，只有模型和方法，缺乏数据探索的分析和建模，计算的结果和分析的结论可能是不正确的，数据可能在欺骗你(Anscombe 1973)。\ndatasauRus 包 (Davies, Locke, 和 D’Agostino McGowan 2022) 内置了一个数据集 datasaurus_dozen，它整合了 13 个子数据集，它们在均值、标准差等描述性统计量方面十分接近，见下 表格 datasaurus_dozen 数据集的一些描述性统计量和线性回归结果 。其中 \\(\\bar{x},\\sigma_x\\) 分别代表预测变量 \\(X\\) 的均值和标准差，\\(\\bar{y},\\sigma_y\\) 代表响应变量 \\(Y\\) 的均值和标准差，\\(\\beta_0,\\beta_1\\) 代表回归方程 方程式 eq-datasaurus-lm 的截距和斜率，\\(R^2\\) 代表模型拟合数据的程度。\n\\[\ny = \\beta_0 + \\beta_1 x + \\epsilon\n\\tag{1}\\]\n表格 1: datasaurus_dozen 数据集的一些描述性统计量和线性回归结果\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n子数据集\n\\(\\bar{x}\\)\n\\(\\sigma_x\\)\n\\(\\bar{y}\\)\n\\(\\sigma_y\\)\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(R^2\\)\n\n\n\ndino\n54.263\n16.765\n47.832\n26.935\n53.453\n-0.104\n0.004\n\n\naway\n54.266\n16.770\n47.835\n26.940\n53.425\n-0.103\n0.004\n\n\nh_lines\n54.261\n16.766\n47.830\n26.940\n53.211\n-0.099\n0.004\n\n\nv_lines\n54.270\n16.770\n47.837\n26.938\n53.891\n-0.112\n0.005\n\n\nx_shape\n54.260\n16.770\n47.840\n26.930\n53.554\n-0.105\n0.004\n\n\nstar\n54.267\n16.769\n47.840\n26.930\n53.327\n-0.101\n0.004\n\n\nhigh_lines\n54.269\n16.767\n47.835\n26.940\n53.809\n-0.110\n0.005\n\n\ndots\n54.260\n16.768\n47.840\n26.930\n53.098\n-0.097\n0.004\n\n\ncircle\n54.267\n16.760\n47.838\n26.930\n53.797\n-0.110\n0.005\n\n\nbullseye\n54.269\n16.769\n47.831\n26.936\n53.809\n-0.110\n0.005\n\n\nslant_up\n54.266\n16.769\n47.831\n26.939\n53.813\n-0.110\n0.005\n\n\nslant_down\n54.268\n16.767\n47.836\n26.936\n53.850\n-0.111\n0.005\n\n\nwide_lines\n54.267\n16.770\n47.832\n26.938\n53.635\n-0.107\n0.004\n诸多统计量都难以发现它们的差异，透过数据可视化这面照妖镜，却可以使数据的本来面目无所遁形，如 图 数据可视化为何如此重要 所示。可见，单个统计量就好比管窥蠡测，稍有不慎，我们就成了盲人摸象。\n图 1: 数据可视化为何如此重要\n数据可视化的重要性在于探索数据的真实分布，为数据建模提供假设和依据，也为验证、评估模型的效果。结合 图 数据可视化为何如此重要 也解释了为什么线性回归模型在解释数据方面的无能为力，即 \\(R^2\\) 介于 0.004 至 0.005 之间，数据根本不符合线性模型的条件。\n有时候是有的数据符合模型假设，而有的不符合，我们没有上帝之眼，看不到哪些符合哪些不符合。在数据集不多的情况下，可以全部展示出来，数据集很多的时候，可以抽样一部分，再展示。下面再举一个例子，anscombe 数据集来自 R 软件内置的 R 包 datasets，它包含四组数据 \\((x_i, y_i), i =1,2,3,4\\)，如 表格 anscombe 数据集 所示。\n表格 2: anscombe 数据集\n\n\n\n\n\n\n\n第1组\n第2组\n第3组\n第4组\n\n\nx1\ny1\nx2\ny2\nx3\ny3\nx4\ny4\n\n\n\n\n10\n8.04\n10\n9.14\n10\n7.46\n8\n6.58\n\n\n8\n6.95\n8\n8.14\n8\n6.77\n8\n5.76\n\n\n13\n7.58\n13\n8.74\n13\n12.74\n8\n7.71\n\n\n9\n8.81\n9\n8.77\n9\n7.11\n8\n8.84\n\n\n11\n8.33\n11\n9.26\n11\n7.81\n8\n8.47\n\n\n14\n9.96\n14\n8.10\n14\n8.84\n8\n7.04\n\n\n6\n7.24\n6\n6.13\n6\n6.08\n8\n5.25\n\n\n4\n4.26\n4\n3.10\n4\n5.39\n19\n12.50\n\n\n12\n10.84\n12\n9.13\n12\n8.15\n8\n5.56\n\n\n7\n4.82\n7\n7.26\n7\n6.42\n8\n7.91\n\n\n5\n5.68\n5\n4.74\n5\n5.73\n8\n6.89\n用统计的方法发现四组数据的样本均值、方差、相关系数和回归系数几乎是相同的，实际上，借助散点 图 数据可视化很重要 分别描述各组数据的关系时，却发现四组数据之间有极大的差异，且只有第一组数据看起来符合线性模型的条件 (Anscombe 1973)。\n图形还告诉我们第二组数据的更适合二次非线性回归，第三组数据受到离群点的重大影响，第四组数据自变量只有两个取值，像是两个分布按不同比例混合的结果。",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "intro.html#sec-exploration-explaination",
    "href": "intro.html#sec-exploration-explaination",
    "title": "介绍",
    "section": "",
    "text": "(a) 第一组数据\n\n\n\n\n\n\n\n\n\n(b) 第二组数据\n\n\n\n\n\n\n\n\n\n\n\n(c) 第三组数据\n\n\n\n\n\n\n\n\n\n(d) 第四组数据\n\n\n\n\n\n\n图 2: 数据可视化为何如此重要",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "intro.html#sec-data-communication",
    "href": "intro.html#sec-data-communication",
    "title": "介绍",
    "section": "数据展示和交流",
    "text": "数据展示和交流\n无论是数据表格还是交互图形，首先都承担着数据展示的基础作用，通过趋势、对比继而传递更加明确的信息和洞见，采用合适的表达方式可以高效准确地传递信息，促进交流，获取反馈，从而改善已有的分析方法和结论。\n数据展示和交流主要分两大部分：其一是用户可与之交互的图形、表格和应用，其二是文档内容可重复的 HTML 动态网页文档、PDF 便携式文档、 Office 办公文档。涵盖完整数据分析过程的网页文档， 用于毕业的学位论文、投稿的期刊论文、出版的书籍初稿、交流的演示文稿，无论是 LaTeX 编译的 PDF 格式文档还是 DOCX 文档，R 语言社区都有非常先进的工具满足需求。\n13  交互图形 首先介绍 plotly 包绘图的基础语法以及与 ggplot2 包绘图 的关系，其次介绍制作常用的交互图形，如条形图、直方图、箱线图、曲线图等，最后介绍一些常用的技巧，如导出静态图片、添加水印徽标等。\n14  交互表格 首先介绍 DT 包制作交互表格的基础语法，其次介绍常用的功能，如列分层分组、按列配色、列格式化、搜索排序、数据导出等，最后介绍一些基础的 CSS 和 JavaScript 知识，支持一些中高级的表格定制功能。\n15  交互应用 首先介绍 shiny 包制作交互应用的整体概览，如前端布局、后端计算、筛选器、模块交互等，其次从易到难介绍一个完整的数据应用，最后介绍生产级的 Shiny 应用开发的技术栈。\n16  HTML 文档 首先回顾 R 语言社区陆续出现的 R Sweave、R Markdown 和 Quarto 三套创作工具，其次介绍 Quarto 的基础用法，如 Markdown 基础和 Pandoc 的基础，接着根据使用场景分别介绍 HTML、PDF 和 Office 文档的特性。\n\n\n\n\nAnscombe, F. J. 1973. 《Graphs in Statistical Analysis》. The American Statistician 27 (1): 17. https://doi.org/10.2307/2682899.\n\n\nDavies, Rhian, Steph Locke, 和 Lucy D’Agostino McGowan. 2022. datasauRus: Datasets from the Datasaurus Dozen. https://CRAN.R-project.org/package=datasauRus.\n\n\nRigby, R. A., 和 D. M. Stasinopoulos. 2005. 《Generalized additive models for location, scale and shape (with discussion)》. Journal of the Royal Statistical Society: Series C (Applied Statistics) 54 (3): 507–54. https://doi.org/10.1111/j.1467-9876.2005.00510.x.",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "wrangling-objects.html",
    "href": "wrangling-objects.html",
    "title": "1  数据对象",
    "section": "",
    "text": "1.1 数据类型",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-objects.html#sec-data-type",
    "href": "wrangling-objects.html#sec-data-type",
    "title": "1  数据对象",
    "section": "",
    "text": "1.1.1 整型\n\nc(1L, 2L)\n\n[1] 1 2\n\n\n\n1.1.2 逻辑型\n\nc(TRUE, FALSE)\n\n[1]  TRUE FALSE\n\n\n\n1.1.3 字符型\n\nc(\"A\", \"B\")\n\n[1] \"A\" \"B\"\n\n\n\n1.1.4 日期型\n\nc(as.Date(\"2022-01-01\"), as.Date(\"2022-01-02\"))\n\n[1] \"2022-01-01\" \"2022-01-02\"\n\n\n\n1.1.5 数值型\n\nc(1,1.2)\n\n[1] 1.0 1.2",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-objects.html#sec-data-structure",
    "href": "wrangling-objects.html#sec-data-structure",
    "title": "1  数据对象",
    "section": "\n1.2 数据结构",
    "text": "1.2 数据结构\n\n1.2.1 向量\n所有元素都是同一类型\n\n1.2.2 矩阵\n所有元素都是同一类型\n\n1.2.3 数组\n所有元素都是同一类型\n\n1.2.4 列表\n元素可以属于不同类型\n\n1.2.5 因子\n\n1.2.6 数据框\n同列的元素类型必须一致，不同列的元素类型可以不同。\n\n1.2.7 ts\nts 类型用于表示时间序列数据，是继承自数组类型的。给定数据、采样初始时间、采样频率的情况下，利用内置的函数 ts() 构造一个 ts 类型的分钟级的时间序列对象。\n\nx &lt;- ts(\n  data = rnorm(100), \n  start = c(2017, 1), \n  frequency = 365.25 * 24 * 60, \n  class = \"ts\", names = \"Time_Series\"\n)\n\nts() 函数的 start 和 frequency 参数很关键，前者指定了时间单位是天，后者指定每个时间单位下的数据点的数量。其中 365.25 是因为每隔 4 年有 366 天，平均下来，每年算 365.25 天。每隔 1 / (24 * 60) 天（即 1 分钟）采样一个点。如果初始时间不是从一年的第1分钟开始，而是从此时此刻 2023-01-31 10:43:30 CST 开始，则可以换算成今年的第 30 * 24 * 60 + 9 * 60 + 43 = 43783 分钟，则 Start = c(2023, 43783)。\n以数据集 x 为例，它是一个 ts 类型的时间序列数据对象。时间序列对象有很多方法，如函数 class() 、 mode() 和 str() 分别可以查看其数据类型、存储类型和数据结构。\n\n# 数据类型\nclass(x)\n\n[1] \"ts\"\n\n# 存储类型\nmode(x)\n\n[1] \"numeric\"\n\n# 数据结构\nstr(x)\n\n Time-Series [1:100] from 2017 to 2017: -2.3977 -1.2243 -0.5188 -1.63 0.0735 ...\n\n\n函数 start() 和 end() 查看开始和结束的时间点。\n\nc(start(x), end(x))\n\n[1] 2017    1 2017  100\n\n\n函数 time() 可以查看在以上时间区间的划分。\n\ntime(x)\n\nTime Series:\nStart = c(2017, 1) \nEnd = c(2017, 100) \nFrequency = 525960 \n  [1] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [16] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [31] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [46] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [61] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [76] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [91] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n\n\n函数 tsp() 可以查看其期初、期末和周期。\n\ntsp(x)\n\n[1]   2017   2017 525960",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html",
    "href": "wrangling-collection.html",
    "title": "2  数据获取",
    "section": "",
    "text": "2.1 从本地文件读取\n利用 Base R 提供的基础函数从各类文件导入数据",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-file",
    "href": "wrangling-collection.html#sec-file",
    "title": "2  数据获取",
    "section": "",
    "text": "2.1.1 csv 文件\n小的 csv 文件，可用 Base R 提供的 read.csv() 函数读取。 大型 csv 文件，可用 data.table 的 fread() 函数读取。\n\n\n2.1.2 xlsx 文件\nreadxl 读 xls 和 xlsx 文件，writexl 写 xlsx。\nopenxlsx 读/写 xlsx 文件\n\n\n2.1.3 arrow 文件\nApache Arrow 的 R 语言接口 arrow 超出内存的大规模数据操作。比如在时空数据处理场景，数据文件往往比较大，需要在远程服务器上处理超出本地计算机内存的数据，geoarrow包和sfarrow包都是应对此类需求。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-database",
    "href": "wrangling-collection.html#sec-database",
    "title": "2  数据获取",
    "section": "2.2 从数据库中导入",
    "text": "2.2 从数据库中导入\n从各类数据库导入数据，比如 RSQLite 等\n\n2.2.1 RSQLite\n\n\n2.2.2 odbc\n\n\n2.2.3 RJDBC\n很多数据库都有 Java 接口驱动",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-web-scraping",
    "href": "wrangling-collection.html#sec-web-scraping",
    "title": "2  数据获取",
    "section": "2.3 从各类网页中抓取",
    "text": "2.3 从各类网页中抓取\nrvest 包从网页、网站抓取数据， 再用 xml2 和 httr2 解析处理网页数据。\n\n2.3.1 豆瓣排行榜\n\n\n2.3.2 链家二手房",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-rest-api",
    "href": "wrangling-collection.html#sec-rest-api",
    "title": "2  数据获取",
    "section": "2.4 从数据接口中获取",
    "text": "2.4 从数据接口中获取\n\n2.4.1 中国地震台网\n中国地震台网 可以想象后台有一个数据库，在页面的小窗口中输入查询条件，转化为某种 SQL 语句，传递给数据库管理系统，执行查询语句，返回查询结果，即数据。\n\n\n2.4.2 美国地质调查局\n美国地质调查局提供一些选项窗口，可供选择数据范围，直接下载 CSV 或 XLS 文件。\n\n\n2.4.3 美国人口调查局\n美国人口调查局\ntidycensus 需要注册账号，获取使用 API 接口的访问令牌，可以想象后台不仅有一个数据库，在此之上，还有一层数据鉴权。\n\n\n2.4.4 世界银行\n世界银行和国际货币基金组织\nwbstats 包封装世界银行提供的数据接口 REST API",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html",
    "href": "wrangling-cleaning.html",
    "title": "3  数据清洗",
    "section": "",
    "text": "3.1 正则表达式",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html#sec-regexp",
    "href": "wrangling-cleaning.html#sec-regexp",
    "title": "3  数据清洗",
    "section": "",
    "text": "3.1.1 量词\n\n\n3.1.2 级联\n\n\n3.1.3 断言\n正向查找 / 反向查找\n\n\n3.1.4 反向引用\n\n\n3.1.5 命名捕捉",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html#sec-string-operations",
    "href": "wrangling-cleaning.html#sec-string-operations",
    "title": "3  数据清洗",
    "section": "3.2 字符串操作",
    "text": "3.2 字符串操作\n\n3.2.1 查找\ngrep() / grepl() 返回是否匹配的结果\n\n\n3.2.2 替换\nsub() / gsub() 替换一次和多次\n\n\n3.2.3 提取\nregexpr() / gregexpr()\nregexec() / gregexec()",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html",
    "href": "wrangling-manipulation.html",
    "title": "4  数据操作",
    "section": "",
    "text": "4.1 操作工具\n本节所用数据来自世界银行，介绍 Base R、data.table、dplyr 的简介、特点、对比",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-tools",
    "href": "wrangling-manipulation.html#sec-tools",
    "title": "4  数据操作",
    "section": "",
    "text": "4.1.1 Base R\n在 data.frame 的基础上，提供一系列辅助函数实现各类数据操作。\n\naggregate(iris, Sepal.Length ~ Species, FUN = length)\n\n     Species Sepal.Length\n1     setosa           50\n2 versicolor           50\n3  virginica           50\n\n\n\n4.1.2 data.table\ndata.table 包在 Base R 的基础上，扩展和加强了原有函数的功能，提供一套完整的链式操作语法。\n\nlibrary(data.table)\niris_dt &lt;- as.data.table(iris)\niris_dt[ ,.(cnt = length(Sepal.Length)) , by = \"Species\"]\n\n      Species cnt\n1:     setosa  50\n2: versicolor  50\n3:  virginica  50\n\n\n\n4.1.3 dplyr\ndplyr 包提供一套全新的数据操作语法，与 purrr 包和 tidyr 包一起形成完备的数据操作功能。在 R 环境下，dplyr 包提供一套等价的表示，代码如下：\n\niris |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count()\n\n# A tibble: 3 × 2\n# Groups:   Species [3]\n  Species        n\n  &lt;fct&gt;      &lt;int&gt;\n1 setosa        50\n2 versicolor    50\n3 virginica     50\n\n\n\n4.1.4 SQL\n实际工作中，SQL （结构化查询语言）是必不可少的基础性工具，比如 SQLite、 Hive 和 Spark 等都提供基于 SQL 的数据查询引擎，没有重点介绍 SQL 操作是因为本书以 R 语言为数据分析的主要工具，而不是它不重要。以 dplyr 来说吧，它的诸多语义动词就是对标 SQL 的。\n\nlibrary(DBI)\nconn &lt;- DBI::dbConnect(RSQLite::SQLite(),\n  dbname = system.file(\"db\", \"datasets.sqlite\", package = \"RSQLite\")\n)\n\n按 Species 分组统计数据条数， SQL 查询语句如下：\n\nSELECT COUNT(1) AS cnt, Species\nFROM iris\nGROUP BY Species;\n\nSQL 代码执行的结果如下：\n\niris_preview\n\n  cnt    Species\n1  50     setosa\n2  50 versicolor\n3  50  virginica\n\n\ndplyr 包能连接数据库，以上 SQL 代码也可以翻译成等价的 dplyr 语句。\n\ndplyr::tbl(conn, \"iris\") |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count()\n\n# Source:   SQL [3 x 2]\n# Database: sqlite 3.45.0 [/Users/runner/work/_temp/Library/RSQLite/db/datasets.sqlite]\n# Groups:   Species\n  Species        n\n  &lt;chr&gt;      &lt;int&gt;\n1 setosa        50\n2 versicolor    50\n3 virginica     50\n\n\ndplyr 包的函数 show_query() 可以将 dplyr 语句转化为查询语句，这有助于排错。\n\ndplyr::tbl(conn, \"iris\") |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count() |&gt; \n  dplyr::show_query()\n\n&lt;SQL&gt;\nSELECT `Species`, COUNT(*) AS `n`\nFROM `iris`\nGROUP BY `Species`\n\n\nglue 包可以使用 R 环境中的变量，相比于 sprintf() 函数，可以组合更大型的 SQL 语句，这在生产环境中广泛使用。\n\n# R 环境中的变量\ngroup &lt;- \"Species\"\n# 组合 SQL\nquery &lt;- glue::glue(\"\n  SELECT COUNT(1) AS cnt, Species\n  FROM iris\n  GROUP BY ({group})\n\")\n# 将 SQL 语句传递给数据库，执行 SQL 语句\nDBI::dbGetQuery(conn, query)\n\n  cnt    Species\n1  50     setosa\n2  50 versicolor\n3  50  virginica\n\n\n用完后，关闭连接通道。\n\ndbDisconnect(conn = conn)\n\n更多关于 SQL 语句的使用介绍见书籍《Become a SELECT star》。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-basic-operator",
    "href": "wrangling-manipulation.html#sec-basic-operator",
    "title": "4  数据操作",
    "section": "\n4.2 Base R 操作",
    "text": "4.2 Base R 操作\n介绍最核心的 Base R 数据操作，如筛选、排序、变换、聚合、重塑等\n\n4.2.1 筛选\n筛选操作可以用函数 subset() 或 [ 实现\n\nsubset(iris, subset = Species == \"setosa\" & Sepal.Length &gt; 5.5, select = c(\"Sepal.Length\", \"Sepal.Width\"))\n\n   Sepal.Length Sepal.Width\n15          5.8         4.0\n16          5.7         4.4\n19          5.7         3.8\n\n\n\niris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5.5, c(\"Sepal.Length\", \"Sepal.Width\")]\n\n   Sepal.Length Sepal.Width\n15          5.8         4.0\n16          5.7         4.4\n19          5.7         3.8\n\n\n\n4.2.2 变换\n变换操作可以用函数 within()/transform() 实现。最常见的变换操作是类型转化，比如从字符串型转为因子型、整型或日期型等。\n\n# iris2 &lt;- transform(iris, Species_N = as.integer(Species))[1:3, ]\niris2 &lt;- within(iris, {\n  Species_N &lt;- as.integer(Species)\n})\nstr(iris2)\n\n'data.frame':   150 obs. of  6 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Species_N   : int  1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n4.2.3 排序\n排序操作可以用函数 order() 实现\n\niris[order(iris$Sepal.Length, decreasing = FALSE)[1:3], ]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n14          4.3         3.0          1.1         0.1  setosa\n9           4.4         2.9          1.4         0.2  setosa\n39          4.4         3.0          1.3         0.2  setosa\n\n\n\n4.2.4 聚合\n聚合操作可以用函数 aggregate() 实现\n\naggregate(iris, Sepal.Length ~ Species, mean)\n\n     Species Sepal.Length\n1     setosa        5.006\n2 versicolor        5.936\n3  virginica        6.588\n\n\n\n4.2.5 合并\n两个数据框的合并操作可以用函数 merge() 实现\n\ndf1 &lt;- data.frame(a1 = c(1, 2, 3), a2 = c(\"A\", \"B\", \"C\"))\ndf2 &lt;- data.frame(b1 = c(2, 3, 4), b2 = c(\"A\", \"B\", \"D\"))\n# LEFT JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all.x = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  C  3 NA\n\n# RIGHT JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all.y = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  D NA  4\n\n# INNER JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all = FALSE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n\n# FULL JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  C  3 NA\n4  D NA  4\n\n\n\n4.2.6 重塑\n将数据集从宽格式转为长格式，可以用函数 reshape() 实现，反之，亦然。\n\n# 长格式\ndf3 &lt;- data.frame(\n  extra = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4),\n  group = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),\n  id = c(1, 2, 3, 1, 2, 3)\n)\n# 长转宽\nreshape(df3, direction = \"wide\", timevar = \"group\", idvar = \"id\")\n\n  id extra.A extra.B\n1  1     0.7    -1.2\n2  2    -1.6    -0.1\n3  3    -0.2     3.4\n\n# 也可以指定组合变量的列名\nreshape(df3, direction = \"wide\", timevar = \"group\", idvar = \"id\",\n        v.names = \"extra\", sep = \"_\")\n\n  id extra_A extra_B\n1  1     0.7    -1.2\n2  2    -1.6    -0.1\n3  3    -0.2     3.4\n\n\n提取并整理分组线性回归系数。函数 split() 将数据集 iris 按分类变量 Species 拆分成列表， 函数 lapply() 将线性回归操作 lm() 应用于列表的每一个元素上，再次用函数 lapply() 将函数 coef() 应用于线性回归后的列表上，提取回归系数，用函数 do.call() 将系数合并成矩阵，最后，用函数as.data.frame() 转化成数据框。\n\ns1 &lt;- split(iris, ~Species)\ns2 &lt;- lapply(s1, lm, formula = Sepal.Length ~ Sepal.Width)\ns3 &lt;- lapply(s2, coef)\ns4 &lt;- do.call(\"rbind\", s3)\ns5 &lt;- as.data.frame(s4)\ns5\n\n           (Intercept) Sepal.Width\nsetosa        2.639001   0.6904897\nversicolor    3.539735   0.8650777\nvirginica     3.906836   0.9015345\n\ndo.call(\n  \"rbind\",\n  lapply(\n    lapply(\n      split(iris, ~Species), lm,\n      formula = Sepal.Length ~ Sepal.Width\n    ),\n    coef\n  )\n)\n\n           (Intercept) Sepal.Width\nsetosa        2.639001   0.6904897\nversicolor    3.539735   0.8650777\nvirginica     3.906836   0.9015345",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-data-table",
    "href": "wrangling-manipulation.html#sec-data-table",
    "title": "4  数据操作",
    "section": "\n4.3 data.table 操作",
    "text": "4.3 data.table 操作\n掌握此等基础性的工具，再去了解新工具也不难，更重要的是，只要将一种工具掌握的足够好，也就足以应付绝大多数的情况。\n\n介绍 data.table 基础语法，对标 Base R，介绍基础操作，同时给出等价的 dplyr 实现，但不运行代码。\ndata.table 扩展 Base R 数据操作，介绍常用的操作 8 个，讲清楚出现的具体场景，同时给出等价的 dplyr 实现，但不运行代码。\ndata.table 特有的高级数据操作 on、.SD 、.I 、.J 等。\n\n\n4.3.1 筛选\ndata.table 扩展了函数 [ 功能，简化 iris$Species == \"setosa\" 代码 Species == \"setosa\"\n\niris_dt[Species == \"setosa\" & Sepal.Length &gt; 5.5, c(\"Sepal.Length\", \"Sepal.Width\")]\n\n   Sepal.Length Sepal.Width\n1:          5.8         4.0\n2:          5.7         4.4\n3:          5.7         3.8\n\n\n\n4.3.2 变换\n变换操作可以用函数 :=\n\niris_dt[, Species_N := as.integer(Species)]\nstr(iris_dt)\n\nClasses 'data.table' and 'data.frame':  150 obs. of  6 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Species_N   : int  1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\n\n\n4.3.3 排序\n排序操作可以用函数 order()\n\niris_dt[order(Sepal.Length, decreasing = FALSE)[1:3], ]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Species_N\n1:          4.3         3.0          1.1         0.1  setosa         1\n2:          4.4         2.9          1.4         0.2  setosa         1\n3:          4.4         3.0          1.3         0.2  setosa         1\n\n\n\n4.3.4 聚合\n聚合操作用函数 .() 和 by 组合\n\niris_dt[, .(mean = mean(Sepal.Length)), by = \"Species\"]\n\n      Species  mean\n1:     setosa 5.006\n2: versicolor 5.936\n3:  virginica 6.588\n\n\n\n4.3.5 合并\n合并操作也是用函数 merge() 来实现。\n\ndt1 &lt;- data.table(a1 = c(1, 2, 3), a2 = c(\"A\", \"B\", \"C\"))\ndt2 &lt;- data.table(b1 = c(2, 3, 4), b2 = c(\"A\", \"B\", \"D\"))\n# LEFT JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all.x = TRUE)\n\n   a2 a1 b1\n1:  A  1  2\n2:  B  2  3\n3:  C  3 NA\n\n# RIGHT JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all.y = TRUE)\n\n   a2 a1 b1\n1:  A  1  2\n2:  B  2  3\n3:  D NA  4\n\n# INNER JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all = FALSE)\n\n   a2 a1 b1\n1:  A  1  2\n2:  B  2  3\n\n# FULL JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all = TRUE)\n\n   a2 a1 b1\n1:  A  1  2\n2:  B  2  3\n3:  C  3 NA\n4:  D NA  4\n\n\n\n4.3.6 重塑\n将数据集从宽格式转为长格式，可以用函数 dcast() 实现，反之，可以用函数 melt() 实现。\n\n# 长格式\ndt3 &lt;- data.table(\n  extra = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4),\n  group = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),\n  id = c(1, 2, 3, 1, 2, 3)\n)\n# 长转宽\ndcast(dt3, id ~ group, value.var = \"extra\")\n\n   id    A    B\n1:  1  0.7 -1.2\n2:  2 -1.6 -0.1\n3:  3 -0.2  3.4\n\n\n类似 Base R，也用 data.table 来实现 iris 分组线性回归\n\niris_dt[, as.list(coef(lm(Sepal.Length ~ Sepal.Width))), by = \"Species\"]\n\n      Species (Intercept) Sepal.Width\n1:     setosa    2.639001   0.6904897\n2: versicolor    3.539735   0.8650777\n3:  virginica    3.906836   0.9015345",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html",
    "href": "wrangling-processing.html",
    "title": "5  数据处理",
    "section": "",
    "text": "5.1 缺失值处理\n缺失是一种非常常见的数据问题。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-missing-data",
    "href": "wrangling-processing.html#sec-missing-data",
    "title": "5  数据处理",
    "section": "",
    "text": "5.1.1 查找\n缺失值在数据框中的位置\n\n\n5.1.2 汇总\n缺失值的占比、分布情况，可视化获得缺失的结构 VIM\n\n\n5.1.3 替换\n替换数据框中的缺失值\n\n\n5.1.4 插补\nmice Multivariate Imputation by Chained Equations 缺失值插补",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-exception-data",
    "href": "wrangling-processing.html#sec-exception-data",
    "title": "5  数据处理",
    "section": "5.2 异常值处理",
    "text": "5.2 异常值处理\n提及异常，一般会联想到数据本身出问题了，比如数据错误。比较常见的情况是业务有异动，导致数据异常波动，需要及时捕捉到这种异常波动，找到异常的原因，进而采取措施。\n\n5.2.1 检测\n\n\n5.2.2 识别\n\n\n5.2.3 处理",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-outlier-data",
    "href": "wrangling-processing.html#sec-outlier-data",
    "title": "5  数据处理",
    "section": "5.3 离群值处理",
    "text": "5.3 离群值处理\n离群，并不是数据本身出问题，而是数据隐藏着特殊信息，与平时不一样的情况，与大家伙不一样的情况。比如情人节鲜花和蛋糕的需求量激增，端午节粽子的需求激增，这和平时很不一样。需求数据本身没有问题，如实反应了现实情况。因此，需要根据现实情况，调整预测模型，做出更加准确的需求预测，提前安排供给。\n\n5.3.1 检测\n\n\n5.3.2 识别\n\n\n5.3.3 处理",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html",
    "href": "visualization-basic.html",
    "title": "6  ggplot2 入门",
    "section": "",
    "text": "6.1 图层\nggplot2 绘图必须包含以下三个要素，缺少任何一个，图形都是不完整的。\n下面逐一说明三个要素的作用，为简单起见，从数据集 gapminder 中选取 2007 年的数据。\n图 6.1 (a) 仅提供数据，只渲染出来一个绘图区域。 图 6.1 (b) 仅提供数据和映射，将变量 gdpPercap 映射给横轴，变量 lifeExp 映射给纵轴，继续渲染出来横、纵坐标轴及标签。 图 6.1 (c) 提供了数据、映射和图层三要素，观察值根据几何图层 geom_point() 将几何元素 「点」渲染在绘图区域上，形成散点图。函数 ggplot() 和函数 geom_point() 之间是以加号 + 连接的。无论最终产出的图形如何复杂，这个模式贯穿 ggplot2 绘图。\n10 多年来，ggplot2 包陆续添加了很多几何图层，目前支持的有 53 个，如下：\n也正因这些丰富多彩的图层，ggplot2 可以非常便捷地做各种数据探索和展示工作。从时间序列数据、网络社交数据到文本数据、空间数据，乃至时空数据都有它大显身手的地方。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-layer",
    "href": "visualization-basic.html#sec-layer",
    "title": "6  ggplot2 入门",
    "section": "",
    "text": "数据，前面已经重点介绍和准备了；\n映射，数据中的变量与几何元素的对应关系；\n图层，至少需要一个图层用来渲染观察值。\n\n\nlibrary(ggplot2)\ngapminder_2007 &lt;- gapminder[gapminder$year == 2007, ]\nggplot(data = gapminder_2007)\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp))\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(size = pop))\n\n\n\n\n\n\n\n\n\n(a) 只有数据\n\n\n\n\n\n\n\n\n\n(b) 只有数据和坐标映射\n\n\n\n\n\n\n\n\n\n\n\n(c) 数据、坐标映射和点图层\n\n\n\n\n\n\n\n\n\n(d) 数据、坐标映射、点图层和视觉映射（可选）\n\n\n\n\n\n\n图 6.1: ggplot2 绘图三要素\n\n\n\n\n\n\n表格 6.2: ggplot2 包可以绘制丰富的统计图形\n\n\n\ngeom_abline\ngeom_dotplot\ngeom_qq_line\n\n\ngeom_area\ngeom_errorbar\ngeom_quantile\n\n\ngeom_bar\ngeom_errorbarh\ngeom_raster\n\n\ngeom_bin_2d\ngeom_freqpoly\ngeom_rect\n\n\ngeom_bin2d\ngeom_function\ngeom_ribbon\n\n\ngeom_blank\ngeom_hex\ngeom_rug\n\n\ngeom_boxplot\ngeom_histogram\ngeom_segment\n\n\ngeom_col\ngeom_hline\ngeom_sf\n\n\ngeom_contour\ngeom_jitter\ngeom_sf_label\n\n\ngeom_contour_filled\ngeom_label\ngeom_sf_text\n\n\ngeom_count\ngeom_line\ngeom_smooth\n\n\ngeom_crossbar\ngeom_linerange\ngeom_spoke\n\n\ngeom_curve\ngeom_map\ngeom_step\n\n\ngeom_density\ngeom_path\ngeom_text\n\n\ngeom_density_2d\ngeom_point\ngeom_tile\n\n\ngeom_density_2d_filled\ngeom_pointrange\ngeom_violin\n\n\ngeom_density2d\ngeom_polygon\ngeom_vline\n\n\ngeom_density2d_filled\ngeom_qq",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-label",
    "href": "visualization-basic.html#sec-label",
    "title": "6  ggplot2 入门",
    "section": "\n6.2 标签",
    "text": "6.2 标签\n用函数 labs() 可以添加横轴、纵轴、图例的标题，整个图片的标题和副标题等。下图 图 6.2 (a) 是默认设置下显示的标签内容，而 图 6.2 (b) 是用户指定标签内容后的显示效果。\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region))\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", tag = \"标签\",\n       title = \"这里是标题\", caption = \"这是图形说明\", \n       subtitle = \"这里是副标题\", color = \"图例标题\")\n\n\n\n\n\n\n\n\n\n(a) 默认设置\n\n\n\n\n\n\n\n\n\n\n\n(b) 自定义标签\n\n\n\n\n\n\n图 6.2: 添加标签",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-scale",
    "href": "visualization-basic.html#sec-scale",
    "title": "6  ggplot2 入门",
    "section": "\n6.3 刻度",
    "text": "6.3 刻度\n\n有时候 图 6.1 (c) 看起来不太好，收入低的国家太多，聚集在一起，重叠覆盖比较严重。而高收入国家相对较少，分布稀疏，距离低收入比较远，数据整体的分布很不平衡。此时，可以考虑对横轴标度做一些变换，常用的有以 10 为底的对数变换，如 图 6.3 。\n\nlibrary(scales)\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.3: 人均 GDP 做对数变换\n\n\n\n\n为了更加醒目地展示横轴做了对数变换，需要添加对应的刻度标签。scales 包 (H. Wickham 和 Seidel 2022) 提供很多刻度标签支持，比如函数 label_log() 默认提供以 10 为底的刻度标签，如 图 6.4 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(labels = label_log()) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.4: 刻度标签随数据变换调整\n\n\n\n\n这其实还不够，有的刻度标签含义不够显然，且看 图 6.4 的横轴第一个刻度标签 \\(10^{2.48}\\) 是用来替换 图 6.3 的横轴第一个刻度标签 300。10 的 2.48 次方可不容易看出是 300 的意思，实际上它等于 302。因此，结合人均 GDP 的实际范围，有必要适当调整横轴显示范围，这可以在函数 scale_x_log10() 中设置参数 limits，横轴刻度标签会随之适当调整，调整后的效果如 图 6.5 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(labels = label_log(), limits = c(100, 110000)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.5: 设置数据展示范围\n\n\n\n\n根据横轴所代表的人均 GDP （单位：美元）的实际含义，其实，可以进一步，添加更多的信息，即刻度标签带上数量单位，此处是美元符号。scales 包提供的函数 label_dollar() 可以实现，效果如 图 6.6 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(labels = label_dollar(), limits = c(100, 110000)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.6: 设置数据展示范围\n\n\n\n\n最后，有必要添加次刻度线作为辅助参考线。图中点与点之间的横向距离代表人均 GDP 差距，以 10 为底的对数变换不是线性变化的，肉眼识别起来有点困难。从 100 美元到 100000 美元，在 100 美元、1000 美元、10000 美元和 100000 美元之间均添加 10 条次刻度线，每个区间内相邻的两条次刻度线之差保持恒定。下面构造刻度线的位置，了解原值和对数变换后的对应关系。\n\n# 刻度线位置\nmb &lt;- unique(as.numeric(1:10 %o% 10^(1:4)))\n# 对数变换后\nlog10(mb)\n\n#&gt;  [1] 1.000000 1.301030 1.477121 1.602060 1.698970 1.778151 1.845098 1.903090\n#&gt;  [9] 1.954243 2.000000 2.301030 2.477121 2.602060 2.698970 2.778151 2.845098\n#&gt; [17] 2.903090 2.954243 3.000000 3.301030 3.477121 3.602060 3.698970 3.778151\n#&gt; [25] 3.845098 3.903090 3.954243 4.000000 4.301030 4.477121 4.602060 4.698970\n#&gt; [33] 4.778151 4.845098 4.903090 4.954243 5.000000\n\n# 刻度线位置\nformat(mb, big.mark = \",\", scientific = 999)\n\n#&gt;  [1] \"     10\" \"     20\" \"     30\" \"     40\" \"     50\" \"     60\" \"     70\"\n#&gt;  [8] \"     80\" \"     90\" \"    100\" \"    200\" \"    300\" \"    400\" \"    500\"\n#&gt; [15] \"    600\" \"    700\" \"    800\" \"    900\" \"  1,000\" \"  2,000\" \"  3,000\"\n#&gt; [22] \"  4,000\" \"  5,000\" \"  6,000\" \"  7,000\" \"  8,000\" \"  9,000\" \" 10,000\"\n#&gt; [29] \" 20,000\" \" 30,000\" \" 40,000\" \" 50,000\" \" 60,000\" \" 70,000\" \" 80,000\"\n#&gt; [36] \" 90,000\" \"100,000\"\n\n\n函数 scale_x_log10() 提供参数 minor_breaks 设定刻度线的位置。最终效果如 图 6.7 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.7: 添加次刻度线，提供更多参考",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-color",
    "href": "visualization-basic.html#sec-color",
    "title": "6  ggplot2 入门",
    "section": "\n6.4 配色",
    "text": "6.4 配色\n好的配色可以让图形产生眼前一亮的效果，R 语言社区在统计图形领域深耕 20 多年，陆续涌现很多专门调色的 R 包，常见的有：\n\n\nRColorBrewer (Neuwirth 2022) (https://github.com/axismaps/colorbrewer/)\n\nmunsell (C. Wickham 2018) (https://github.com/cwickham/munsell/)\n\ncolorspace (Zeileis 等 2020) (https://colorspace.r-forge.r-project.org/)\n\npaletteer (Hvitfeldt 2021) (https://github.com/EmilHvitfeldt/paletteer)\n\nscico (Pedersen 和 Crameri 2022) (https://github.com/thomasp85/scico)\n\nviridis (Garnier 等 2021) (https://github.com/sjmgarnier/viridis/)\n\nviridisLite (Garnier 等 2021) (https://github.com/sjmgarnier/viridisLite/)\n\ncolormap (Karambelkar 2016) (https://github.com/bhaskarvk/colormap)\n\nggplot2 提供多种方式给图形配色，最常见的要数函数 scale_color_brewer()，它调用 RColorBrewer 包制作离散型的调色板，根据离散型变量的具体情况，可分为发散型 qualitative、对撞型 Diverging、有序型 Sequential。在图 图 6.7 的基础上，将分类型的区域变量映射给散点的颜色，即得到 图 6.8 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region)) +\n  scale_color_brewer(palette = \"Set1\") +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", color = \"区域\")\n\n\n\n\n\n\n图 6.8: 使用 RColorBrewer 包提供的 Set1 调色板\n\n\n\n\n另一种方式是调用函数 scale_color_manual()，需要用户给分类变量值逐个指定颜色，即提供一个命名的向量，效果如 图 6.9 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region)) +\n  scale_color_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", color = \"区域\")\n\n\n\n\n\n\n图 6.9: 手动挨个指定分类变量的颜色",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-legend",
    "href": "visualization-basic.html#sec-legend",
    "title": "6  ggplot2 入门",
    "section": "\n6.5 图例",
    "text": "6.5 图例\n在 图 6.8 的基础上，继续将每个国家的人口总数映射给点的大小，绘制气泡图。此时有两个视觉映射变量 — 离散型的变量 country （国家）和连续型的变量 pop （人口总数）。不仅仅是图层函数 geom_point()，所有的几何图层都提供参数 show.legend 来控制图例的显示或隐藏。传递命名逻辑向量还可以在多个图例中选择性保留。 图 6.10 在两个图例中保留一个，即人口总数。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region, size = pop),\n    show.legend = c(color = FALSE, size = TRUE)\n  ) +\n  scale_color_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", size = \"人口总数\")\n\n\n\n\n\n\n图 6.10: 在两个图例中保留一个\n\n\n\n\n全世界各个国家的人口总数从百万级横跨到十亿级，根据此实际情况，适当调整图例刻度标签是很有必要的，可以让图例内容更具可读性。 图 6.11 是修改图例刻度标签后的效果，其中 M 表示 Million（百万），B 表示 Billion （十 亿）。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region, size = pop),\n    show.legend = c(color = FALSE, size = TRUE)\n  ) +\n  scale_color_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12), labels = label_number(scale_cut = cut_short_scale())) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", size = \"人口总数\")\n\n\n\n\n\n\n图 6.11: 修改图例刻度标签",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-theme",
    "href": "visualization-basic.html#sec-theme",
    "title": "6  ggplot2 入门",
    "section": "\n6.6 主题",
    "text": "6.6 主题\n主题就是一系列风格样式的集合，提前设定标题、文本、坐标轴、图例等元素的默认参数，供后续调用。10 年来，R 语言社区陆续出现很多主题包。\n\n\nggthemes (Arnold 2021) 收集了网站（如 Fivethirtyeight）、杂志（如《经济学家》）、软件（如 Stata）等的配色主题，打包成可供 ggplot2 绘图的主题，更多内容见 (https://github.com/jrnold/ggthemes)\n\nggsci (Xiao 2018) 包收集了多份期刊杂志的图形配色，将其融入 ggplot2 绘图主题中，更多内容见 (https://github.com/road2stat/ggsci)。\n\nggpubr (Kassambara 2022) 包在 ggplot2 之上封装一套更加易用的函数，可以快速绘制出版级的统计图形 (https://github.com/kassambara/ggpubr)。\n\nggcharts (Neitmann 2020) 包类似 ggpubr 包，也提供一套更加快捷的函数接口，缩短数据可视化的想法与实际图形的距离，更多内容见 (https://github.com/thomas-neitmann/ggcharts)。\n\nggthemr (Tobin 2020) 是比较早的 ggplot2 主题包，上游依赖少，更多内容见 (https://github.com/Mikata-Project/ggthemr)。\n\nggtech (Bion 2018) 包收集了许多科技公司的设计风格，将其制作成可供 ggplot2 绘图使用的主题，更多内容见 (https://github.com/ricardo-bion/ggtech)。\n\nbbplot (Stylianou 等 2022) 为 BBC 新闻定制的一套主题，更多内容见 (https://github.com/bbc/bbplot)。\n\npilot (Hawkins 2022) 包提供一套简洁的 ggplot2 主题，特别是适合展示分类、离散型数据，更多内容见 (https://github.com/olihawkins/pilot)。\n\nggthemeassist (Gross 和 Ottolinger 2016) 包提供 RStudio IDE 插件，帮助用户以鼠标点击的交互方式设置 ggplot2 图形的主题样式，更多内容见 (https://github.com/calligross/ggthemeassist)。\n\n在 图 6.11 的基础上，以 ggplot2 包内置的主题 theme_classic() 替换默认的主题，效果如下 图 6.12 ，这是一套非常经典的主题，它去掉所有的背景色和参考系，显得非常简洁。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop), shape = 21, col = \"white\",\n    show.legend = c(fill = TRUE, size = FALSE)\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_classic() +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.12: ggplot2 内置的经典主题风格\n\n\n\n\n在已有主题的基础上，还可以进一步细微调整，比如，将图例移动至绘图区域的下方，见 图 6.13 。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop), shape = 21, col = \"white\",\n    show.legend = c(fill = TRUE, size = FALSE)\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_classic() +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.13: 图例置于图形下方\n\n\n\n\n或者用户觉得合适的任意位置。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop), shape = 21, col = \"white\",\n    show.legend = c(fill = TRUE, size = FALSE)\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.875, 0.3)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.14: 微调图例位置\n\n\n\n\n或者更换其它主题，比如 ggthemes 包内置极简主题 theme_tufte()，它仅保留主刻度线，更加凸显数据。\n\nlibrary(ggthemes)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_tufte(base_family = \"sans\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside =  c(0.875, 0.3), \n    legend.title = element_text(family = \"Noto Sans CJK SC\"),\n    legend.text = element_text(family = \"Noto Sans CJK SC\"),\n    axis.title = element_text(family = \"Noto Sans CJK SC\")) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.15: ggthemes 的极简主题 Tufte",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-annotation",
    "href": "visualization-basic.html#sec-annotation",
    "title": "6  ggplot2 入门",
    "section": "\n6.7 注释",
    "text": "6.7 注释\n注释可以是普通文本，数学公式，还可以是图形照片、表情包。注释功能非常强大，但也是非常灵活，往往使用起来颇费功夫，需要结合数据情况，从图形所要传递的信息出发，适当添加。R 语言社区陆续出现一些扩展包，让用户使用起来更方便些。\n\n\nggrepel (Slowikowski 2021) 包可以通过添加一定距离的扰动，可以缓解文本重叠的问题，更多内容见 (https://github.com/slowkow/ggrepel)。\n\nggtext (Wilke 2020) 包支持以 Markdown 语法添加丰富的文本内容，更多内容见 (https://github.com/wilkelab/ggtext)。\n\nstring2path (Yutani 2022) 包字体轮廓生成路径，注释文本随路径变化，更多内容见 (https://github.com/yutannihilation/string2path)。\n\nggimage (Yu 2022) 包提供图像图层，实现以图片代替散点的效果，图片还可以是表情包，更多内容见 (https://github.com/GuangchuangYu/ggimage)。\n\n在 图 6.15 的基础上，给人口总数大于 2 亿的国家添加文本注释。这可以用 ggplot2 包提供的文本图层函数 geom_text() 实现，效果如 图 6.16 。\n\nlibrary(ggrepel)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  geom_text(\n    data = function(x) subset(x, year == 2007 & pop &gt;= 20 * 10^7),\n    aes(label = country), show.legend = FALSE\n  ) +\n  scale_size(range = c(2, 12)) +\n  theme_tufte(base_family = \"sans\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside =  c(0.9, 0.3), \n    legend.title = element_text(family = \"Noto Sans CJK SC\"),\n    legend.text = element_text(family = \"Noto Sans CJK SC\"),\n    axis.title = element_text(family = \"Noto Sans CJK SC\")) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.16: 添加文本注释\n\n\n\n\n当需要给许多点添加文本注释时，就难以避免地遇到注释文本重叠的问题。比如给人口总数大于 5000 万的国家添加文本注释，此时，适合使用 ggrepel 包，调用函数 geom_text_repel() — 这是一个新的文本图层，通过添加适当的位移缓解文本重叠问题。\n\nlibrary(ggrepel)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(data = function(x) subset(x, year == 2007),\n             aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  geom_text_repel(\n    data = function(x) subset(x, year == 2007 & pop &gt;= 5 * 10^7),\n    aes(label = country), size = 3, max.overlaps = 50,\n    segment.colour = \"gray\", seed = 2022, show.legend = FALSE\n  ) +\n  scale_size(range = c(2, 12)) +\n  theme_tufte(base_family = \"sans\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside =  c(0.9, 0.3), \n    legend.title = element_text(family = \"Noto Sans CJK SC\"),\n    legend.text = element_text(family = \"Noto Sans CJK SC\"),\n    axis.title = element_text(family = \"Noto Sans CJK SC\")) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.17: 缓解文本注释相互覆盖的问题",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-facet",
    "href": "visualization-basic.html#sec-facet",
    "title": "6  ggplot2 入门",
    "section": "\n6.8 分面",
    "text": "6.8 分面\nggplot2 包有两个函数 facet_wrap() 和 facet_grid() 都可以用来实现分面操作，分面的目的是将数据切分，一块一块地展示。下面在 图 6.15 的基础上，按收入水平变量分面，即将各个国家或地区按收入水平分开，效果如 图 6.18 所示。facet_grid() 与 facet_wrap() 的效果是类似的，就不再赘述了。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(data = function(x) subset(x, year == 2007),\n             aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(labels = label_log(), limits = c(100, 110000)) +\n  facet_wrap(facets = ~income_level, ncol = 2) +\n  theme_classic() +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.18: 按收入水平变量分面\n\n\n\n\n在函数 facet_wrap() 内设置不同的参数值，会有不同的排列效果。设置 ncol = 3，意味着排成 3 列，而分类变量 continent 总共有 5 种不同的类别，因此将会是 3 列 2 行的布局，效果如下 图 6.19 。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(data = function(x) subset(x, year == 2007),\n             aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(labels = label_log(), limits = c(100, 110000)) +\n  facet_wrap(facets = ~income_level, ncol = 3) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.2)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.19: 按区域变量分面",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-animate",
    "href": "visualization-basic.html#sec-animate",
    "title": "6  ggplot2 入门",
    "section": "\n6.9 动画",
    "text": "6.9 动画\n从 1991 年至 2020 年，gapminder 数据集一共是 30 年的数据。根据 2007 年的数据绘制了 图 6.20 ，每年的数据绘制一幅图像，30 年总共可获得 30 帧图像，再以每秒播放 6 帧图像的速度将 30 帧图像合成 GIF 动画。因此，设置这个动画总共 30 帧，每秒播放的图像数为 6。\n\noptions(gganimate.nframes = 30, gganimate.fps = 6)\n\ngganimate 包提供一套代码风格类似 ggplot2 包的动态图形语法，可以非常顺滑地与之连接。在了解了 ggplot2 绘制图形的过程后，用 gganimate 包制作动画是非常容易的。gganimate 包会调用 gifski (https://github.com/r-rust/gifski) 包来合成动画，因此，除了安装 gganimate 包，还需要安装 gifski 包。接着，在已有的 ggplot2 绘图代码基础上，再追加一个转场图层函数 transition_time()，这里是按年逐帧展示图像，因此，其转场的时间变量为 gapminder 数据集中的变量 year。\n\nlibrary(gganimate)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE), \n    alpha = 0.65, shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12), labels = label_number(scale_cut = cut_short_scale())) +\n  scale_x_log10(labels = label_log(), limits = c(10, 130000)) +\n  facet_wrap(facets = ~income_level) +\n  theme_classic() +\n  labs(\n    title = \"{frame_time} 年\", x = \"人均 GDP\",\n    y = \"预期寿命\", size = \"人口总数\", fill = \"区域\"\n  ) +\n  transition_time(time = year)\n\n\n\n\n\n\n图 6.20: 制作动画",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-combine",
    "href": "visualization-basic.html#sec-combine",
    "title": "6  ggplot2 入门",
    "section": "\n6.10 组合",
    "text": "6.10 组合\n将多幅小图组合起来构成一幅大图也是常见的需求，常见于出版级、产品级的作品中。组合涉及到布局，布局涉及到层次。有的组合图是从不同角度呈现数据，有的组合图是从传递信息的主次出发，等等。patchwork 包是非常流行的一个基于 ggplot2 的用于图形组合的 R 包，下面基于 faithful 数据展示绘制组合图形的过程。\n首先根据喷发时间将 faithful 数据分成两组。\n\n# 根据喷发时间将数据分成两组\nfaithful &lt;- transform(faithful, group = ifelse(eruptions &gt; 3, \"A\", \"B\"))\n\n绘制分组散点图，叠加二维核密度曲线。\n\n# 绘制分组散点图\nscatterplot &lt;- ggplot(faithful, aes(eruptions, waiting, color = group)) +\n  geom_point() +\n  geom_density_2d() +\n  theme_classic() +\n  theme(axis.text = element_blank(), axis.title = element_blank())\n\n将上图中的图例单独抽取出来，作为一个子图。\n\n# https://stackoverflow.com/questions/46079033/\n# Extract legend from ggplot object\nextract_legend &lt;- function(gg) {\n  grobs &lt;- ggplot_gtable(ggplot_build(gg))\n  foo &lt;- which(sapply(grobs$grobs, function(x) x$name) == \"guide-box\")\n  grobs$grobs[[foo]]\n}\nlegend &lt;- extract_legend(scatterplot)\n\n获得图例后，原图中不需要图例了。\n\nscatterplot &lt;- scatterplot + theme(legend.position = \"none\")\n\n准备两个箱线图分别描述 faithful 数据集中的等待时间 waiting 和喷发时间 eruptions 。\n\nboxplot_left &lt;- ggplot(faithful, aes(group, waiting, fill = group)) +\n  geom_boxplot() +\n  theme_classic() +\n  theme(\n    legend.position = \"none\", axis.ticks.x = element_blank(),\n    axis.text.x = element_blank(), axis.title.x = element_blank()\n  )\n\nboxplot_bottom &lt;- ggplot(faithful, aes(group, eruptions, fill = group)) +\n  geom_boxplot() +\n  theme_classic() +\n  theme(\n    legend.position = \"none\", axis.ticks.y = element_blank(),\n    axis.text.y = element_blank(), axis.title.y = element_blank()\n  ) +\n  coord_flip()\n\n加载 patchwork 包，使用函数 wrap_plots() 组合 boxplot_left 、scatterplot 、legend 和 boxplot_bottom 四个子图，最终效果见下图。\n\nlibrary(patchwork)\ntop &lt;- wrap_plots(boxplot_left, scatterplot, ncol = 2, widths = c(0.2, 0.8))\nbottom &lt;- wrap_plots(legend, boxplot_bottom, ncol = 2, widths = c(0.22, 0.8))\nfinal &lt;- wrap_plots(top, bottom, nrow = 2, heights = c(0.8, 0.2))\nfinal\n\n\n\n\n\n\n图 6.21: patchwork 组合多幅子图\n\n\n\n\n主图是占据着最大篇幅的叠加二维密度曲线的散点图，展示数据的二维分布，两个箱线图辅助展示等待时间 waiting 和喷发时间 eruptions 的分布，而左下角的图例是次要的说明。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-arts",
    "href": "visualization-basic.html#sec-arts",
    "title": "6  ggplot2 入门",
    "section": "\n6.11 艺术",
    "text": "6.11 艺术\nGeorgios Karamanis 基于 R 语言和扩展包 ggforce 制作了一系列生成艺术（Generative Arts）作品。下图是 ggforce 包的 4 个图层函数 geom_regon()、 geom_spiro()、 geom_diagonal() 和 geom_spoke() 分别生成的四幅图片。\nlibrary(ggforce)\ns &lt;- 900\nggplot() +\n  geom_regon(aes(\n    x0 = cos((1:s) / 57), y0 = sin((1:s) / 57),\n    sides = 6, r = cos((1:s) / 24),\n    angle = cos((1:s) / 23), color = 1:s %% 15\n  ),\n  linewidth = 0.2, fill = NA, linetype = \"twodash\"\n  ) +\n  scale_color_viridis_c(option = 15, guide = \"none\") +\n  coord_fixed() +\n  theme_void()\n\nr &lt;- seq(1, 11, 0.1)\nggplot() +\n  geom_spiro(aes(r = r, R = r * 20, d = r^2, outer = T, color = r %% 10), linewidth = 3) +\n  scale_color_viridis_c(option = \"turbo\") +\n  coord_fixed() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\ns &lt;- 1200\nggplot() +\n  geom_diagonal(aes(\n    x = cos(seq(0, pi, length.out = s)),\n    y = sin(seq(0, pi, length.out = s)),\n    xend = cos(seq(0, 360 * pi, length.out = s)),\n    yend = sin(seq(0, 360 * pi, length.out = s))\n  ),\n  linewidth = 0.1, strength = 1\n  ) +\n  coord_fixed() +\n  theme_void()\n\ne &lt;- 1e-3\ns &lt;- 1e4\nt &lt;- pi / 2 * cumsum(seq(e, -e, length.out = s))^3\nggplot() +\n  geom_spoke(aes(\n    x = cumsum(cos(t)), y = cumsum(sin(t)),\n    angle = t, color = t, radius = 1:s %% 500\n  ), alpha = 0.5) +\n  scale_color_distiller(palette = 15, guide = \"none\") +\n  coord_fixed() +\n  theme_void()\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_regon()\n\n\n\n\n\n\n\n\n\n(b) 函数 geom_spiro()\n\n\n\n\n\n\n\n\n\n\n\n(c) 函数 geom_diagonal()\n\n\n\n\n\n\n\n\n\n(d) 函数 geom_spoke()\n\n\n\n\n\n\n图 6.22: R 语言与生成艺术\n\n\n需要充满想象，或借助数学、物理方程，或借助算法、数据生成。好看，但没什么用的生成艺术作品。\n\nhttps://art-from-code.netlify.app/\nhttps://clauswilke.com/art/project/before-after\nhttps://clauswilke.com/art/\nhttps://art.djnavarro.net/\nhttps://www.data-imaginist.com/art\n\n\n\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra Themes, Scales and Geoms for ggplot2. https://CRAN.R-project.org/package=ggthemes.\n\n\nBion, Ricardo. 2018. ggtech: ggplot2 tech themes and scales.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, 等. 2021. viridis: Colorblind-Friendly Color Maps for R. https://doi.org/10.5281/zenodo.4679424.\n\n\nGross, Calli, 和 Philipp Ottolinger. 2016. ggThemeAssist: Add-in to Customize ggplot2 Themes. https://CRAN.R-project.org/package=ggThemeAssist.\n\n\nHawkins, Oliver. 2022. pilot: A minimal ggplot2 theme with an accessible discrete color palette. https://github.com/olihawkins/pilot.\n\n\nHvitfeldt, Emil. 2021. paletteer: Comprehensive Collection of Color Palettes. https://github.com/EmilHvitfeldt/paletteer.\n\n\nKarambelkar, Bhaskar. 2016. colormap: Color Palettes using Colormaps Node Module. https://CRAN.R-project.org/package=colormap.\n\n\nKassambara, Alboukadel. 2022. ggpubr: ggplot2 Based Publication Ready Plots. https://CRAN.R-project.org/package=ggpubr.\n\n\nNeitmann, Thomas. 2020. ggcharts: Shorten the Distance from Data Visualization Idea to Actual Plot. https://CRAN.R-project.org/package=ggcharts.\n\n\nNeuwirth, Erich. 2022. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.\n\n\nPedersen, Thomas Lin, 和 Fabio Crameri. 2022. scico: Colour Palettes Based on the Scientific Colour-Maps. https://CRAN.R-project.org/package=scico.\n\n\nSlowikowski, Kamil. 2021. ggrepel: Automatically Position Non-Overlapping Text Labels with ggplot2. https://CRAN.R-project.org/package=ggrepel.\n\n\nStylianou, Nassos, Will Dahlgreen, Robert Cuffe, Tom Calver, 和 Ransome Mpini. 2022. bbplot: making ggplot2 graphics in BBC NEWS style.\n\n\nTobin, Ciaran. 2020. ggthemr: Themes for ggplot2.\n\n\nWickham, Charlotte. 2018. munsell: Utilities for Using Munsell Colours. https://CRAN.R-project.org/package=munsell.\n\n\nWickham, Hadley, 和 Dana Seidel. 2022. scales: Scale Functions for Visualization. https://CRAN.R-project.org/package=scales.\n\n\nWilke, Claus O. 2020. ggtext: Improved Text Rendering Support for ggplot2. https://CRAN.R-project.org/package=ggtext.\n\n\nXiao, Nan. 2018. ggsci: Scientific Journal and Sci-Fi Themed Color Palettes for ggplot2. https://CRAN.R-project.org/package=ggsci.\n\n\nYu, Guangchuang. 2022. ggimage: Use Image in ggplot2. https://CRAN.R-project.org/package=ggimage.\n\n\nYutani, Hiroaki. 2022. string2path: Rendering Font into data.frame. https://CRAN.R-project.org/package=string2path.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, 和 Claus O. Wilke. 2020. 《colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes》. Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html",
    "href": "visualization-intermediate.html",
    "title": "7  基础图形",
    "section": "",
    "text": "7.1 描述趋势\nGNU R 是一个自由的统计计算和统计绘图环境，最初由新西兰奥克兰大学统计系的 Ross Ihaka 和 Robert Gentleman 共同开发。1997 年之后，成立了一个 R Core Team（R 语言核心团队），他们在版本控制系统 Apache Subversion上一起协作开发至今。25 年—四分之一个世纪过去了，下面分析他们留下的一份开发日志，了解一段不轻易为人所知的故事。\n首先，下载 1997 年至今约 25 年的原始代码提交日志数据。下载数据的代码如下，它是一行 Shell 命令，可在 MacOS 或 Ubuntu 等 Linux 系统的终端里运行，借助 Apache Subversion 软件，将提交日志导出为 XML 格式 的数据文件，保存在目录 data-raw/ 下，文件名为 svn_trunk_log_2022.xml，本书网页版随附。\nsvn log --xml --verbose -r 6:83528 \\\n  https://svn.r-project.org/R/trunk &gt; data-raw/svn_trunk_log_2022.xml\n去掉没什么信息的前5次代码提交记录：初始化仓库，上传原始的 R 软件源码等。 从 Ross Ihaka 在 1997-09-18 提交第 1 次代码改动开始，下载所有的提交日志。截至 2022-12-31，代码最新版本号为 83528，意味着代码仓库已存在 8 万多次提交。\n下载数据后，借助 xml2 包预处理这份 XML 格式数据，提取最重要的信息，谁在什么时间做了什么改动。经过一番操作后，将清洗干净的数据保存到目录 data/ 下，以 R 软件特有的文件格式保存为 svn-trunk-log-2022.rds，同样与书随附。这样下来，原 XML 格式保存的 35 M 文件减少为 1 M 多，极大地减少存储空间，方便后续的数据探索和可视化。下面是这份日志数据最初的两行：\nsvn_trunk_log &lt;- readRDS(file = \"data/svn-trunk-log-2022.rds\")\nhead(svn_trunk_log, 2)\n\n#&gt;   revision author               stamp                                msg\n#&gt; 1        6  ihaka 1997-09-18 04:41:25 New predict.lm from Peter Dalgaard\n#&gt; 2        7  ihaka 1997-09-18 04:42:42             Updated release number\n一共是四个字段，分别是代码提交时记录的版本号 revision，提交代码的人 author，提交代码的时间 stamp 和提交代码时伴随的说明 msg。接下来，带着问题一起探索开源自由的统计软件 R 过去 25 年波澜壮阔的历史！",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualize-data-trend",
    "href": "visualization-intermediate.html#sec-visualize-data-trend",
    "title": "7  基础图形",
    "section": "",
    "text": "7.1.1 折线图\n\n\n\n\n\n\n\n提示\n\n\n\n不再介绍每个函数、每个参数和每行代码的作用，而是重点阐述折线图的作用，以及如何解读数据，阐述解读的思路和方向，建立起数据分析的思维。将重点放在这些方面，有助于书籍存在的长远意义，又结合了最真实的背景和原始数据，相信对实际工作的帮助会更大。而对于使用到统计方法的函数，则详加介绍，展示背后的实现细节，而不是调用函数做调包侠。\n\n\n折线图的意义是什么？在表达趋势变化，趋势的解读很重要。先来了解一下总体趋势，即过去 25 年里代码提交次数的变化情况。数据集 svn_trunk_log 没有年份字段，但时间字段 stamp 隐含了年份信息，因此，新生成一个字段 year 将年份信息从 stamp 提取出来。\n\nsvn_trunk_log &lt;- within(svn_trunk_log, {\n  # 提取日期、月份、年份、星期、第几周、第几天等时间成分\n  year &lt;- as.integer(format(stamp, \"%Y\"))\n  date &lt;- format(stamp, format = \"%Y-%m-%d\", tz = \"UTC\")\n  month &lt;- format(stamp, format = \"%m\", tz = \"UTC\")\n  hour &lt;- format(stamp, format = \"%H\", tz = \"UTC\")\n  week &lt;- format(stamp, format = \"%U\", tz = \"UTC\")\n  wday &lt;- format(stamp, format = \"%a\", tz = \"UTC\")\n  nday &lt;- format(stamp, format = \"%j\", tz = \"UTC\")\n})\n# 代码维护者 ID 和姓名对应\nctb_map &lt;- c(\n  \"bates\" = \"Douglas Bates\", \"deepayan\" = \"Deepayan Sarkar\",\n  \"duncan\" = \"Duncan Temple Lang\", \"falcon\" = \"Seth Falcon\",\n  \"guido\" = \"Guido Masarotto\", \"hornik\" = \"Kurt Hornik\",\n  \"iacus\" = \"Stefano M. Iacus\", \"ihaka\" = \"Ross Ihaka\",\n  \"jmc\" = \"John Chambers\", \"kalibera\" = \"Tomas Kalibera\",\n  \"lawrence\" = \"Michael Lawrence\", \"leisch\" = \"Friedrich Leisch\",\n  \"ligges\" = \"Uwe Ligges\", \"luke\" = \"Luke Tierney\",\n  \"lyndon\" = \"Others\", \"maechler\" = \"Martin Maechler\",\n  \"mike\" = \"Others\", \"morgan\" = \"Martin Morgan\",\n  \"murdoch\" = \"Duncan Murdoch\", \"murrell\" = \"Paul Murrell\",\n  \"pd\" = \"Peter Dalgaard\", \"plummer\" = \"Martyn Plummer\",\n  \"rgentlem\" = \"Robert Gentleman\", \"ripley\" = \"Brian Ripley\",\n  \"smeyer\" = \"Sebastian Meyer\", \"system\" = \"Others\",\n  \"tlumley\" = \"Thomas Lumley\", \"urbaneks\" = \"Simon Urbanek\"\n)\nsvn_trunk_log$author &lt;- ctb_map[svn_trunk_log$author]\n\n接着，调用分组聚合函数 aggregate() 统计各年的代码提交量。\n\ntrunk_year &lt;- aggregate(data = svn_trunk_log, revision ~ year, FUN = length)\n\n然后，将数据集 trunk_year 以折线图展示，如 图 7.1 所示。\n\nlibrary(ggplot2)\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_line() +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.1: 过去 25 年代码提交次数的变化情况\n\n\n\n\n为什么呈现这样的变化趋势？我最初想到的是先逐步增加，然后下降一会儿，再趋于平稳。这比较符合软件从快速迭代开发期，过渡到成熟稳定期的生命周期。接着，从小时趋势图观察代码提交量的变化，发现有高峰有低谷，上午高峰，晚上低峰，但也并不是所有年份都一致，这是因为开发者来自世界各地，位于不同的时区。\n\naggregate(data = svn_trunk_log, revision ~ year + hour, length) |&gt; \n  ggplot(aes(x = hour, y = revision, group = year)) +\n  geom_line() +\n  geom_line(data = function(x) subset(x, year &lt; 2006),\n            aes(color = as.character(year))) +\n  theme_classic() +\n  labs(x = \"时段\", y = \"提交量\", color = \"年份\")\n\n\n\n\n\n\n图 7.2: 提交代码的时段分布\n\n\n\n\n最后，观察代码提交量的月趋势图，12月和次年1月、7-8 月份提交量迎来小高峰，应该是教授们放寒暑假。\n\naggregate(data = svn_trunk_log, revision ~ year + month, length) |&gt;\n  transform(date = as.Date(paste(year, month, \"01\", sep = \"-\"))) |&gt;\n  ggplot(aes(x = date, y = revision)) +\n  geom_point(aes(color = factor(year)), show.legend = F, size = 0.75) +\n  geom_line(aes(color = factor(year)), show.legend = F) +\n  scale_x_date(date_minor_breaks = \"1 year\") +\n  theme_classic() +\n  theme(panel.grid.minor.x = element_line()) +\n  labs(x = \"时间（月粒度）\", y = \"提交量\")\n\n\n\n\n\n\n图 7.3: 提交代码的月份分布\n\n\n\n\n\n7.1.2 瀑布图\n相比于折线图，瀑布图将变化趋势和增减量都展示了，如 图 7.4 所示，每年的提交量就好像瀑布上的水，图中每一段水柱表示当期相对于上一期的增减量。瀑布图是用矩形图层 geom_rect() 构造的，数据点作为矩形对角点，对撞型的颜色表示增减。\n\ntrunk_year &lt;- trunk_year[order(trunk_year$year), ]\n\ntrunk_year_tmp &lt;- data.frame(\n  xmin = trunk_year$year[-length(trunk_year$year)],\n  ymin = trunk_year$revision[-length(trunk_year$revision)],\n  xmax = trunk_year$year[-1],\n  ymax = trunk_year$revision[-1],\n  fill = trunk_year$revision[-1] - trunk_year$revision[-length(trunk_year$revision)] &gt; 0\n)\n\nggplot() +\n  geom_rect(\n    data = trunk_year_tmp,\n    aes(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax, fill = fill\n), \n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = trunk_year, aes(x = year, y = revision), size = 0.75\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.4: 25 年代码逐年提交量的变化趋势\n\n\n\n\nggTimeSeries 包 (Kothari 2022) (https://github.com/thecomeonman/ggTimeSeries) 提供统计图层 stat_waterfall() 实现类似的瀑布图，如 图 7.5 所示。\n\nlibrary(ggTimeSeries)\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  stat_waterfall() +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.5: 矩形图层构造瀑布图\n\n\n\n\n\n7.1.3 曲线图\n\n将散点以线段逐个连接起来，形成折线图，刻画原始的变化，而曲线图的目标是刻画潜在趋势。有两种画法，其一从代数的角度出发，做插值平滑，在相邻两点之间以一条平滑的曲线连接起来；其二从统计的角度出发，做趋势拟合，通过线性或非线性回归，获得变化趋势，以图呈现，使得散点之中隐藏的趋势更加清晰。\nggplot2 (Wickham 2016) 包提供函数 geom_smooth() 拟合散点图中隐含的趋势，通过查看函数 geom_smooth() 的帮助文档，可以了解其内部调用的统计方法。默认情况下，采用局部多项式回归拟合方法，内部调用了函数 loess() 来拟合趋势，如 图 7.6 所示。\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(data = subset(trunk_year, year != 1997)) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n图 7.6: 过去 25 年代码提交次数的变化情况\n\n\n\n\n类似大家熟悉的线性回归拟合函数 lm()，函数 loess() 也是基于类似的使用语法。下面继续以此数据为例，了解该函数的使用，继而了解 ggplot2 绘制平滑曲线图背后的统计方法。1997 年是不完整的，不参与模型参数的估计。\n\ntrunk_year_loess &lt;- loess(revision ~ year,\n  data = subset(trunk_year, year != 1997),\n  span = 0.75, degree = 2, method = \"loess\",\n  family = \"symmetric\",\n  control = loess.control(surface = \"direct\", iterations = 4)\n)\n\n下面通过设定函数 geom_smooth() 的参数，可以达到一样的效果，见下 图 7.7\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\",\n    method.args = list(\n      span = 0.75, degree = 2, family = \"symmetric\",\n      control = loess.control(surface = \"direct\", iterations = 4)\n    ), data = subset(trunk_year, year != 1997)) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.7: 过去 25 年代码提交次数的变化情况\n\n\n\n\nmethod = \"loess\" 意味着调用了一种非参数的回归方法，即局部估计散点平滑 （locally estimated scatterplot smoothing），另一个与之类似的回归方法是局部加权散点平滑 （locally weighted scatterplot smoothing），简称 lowess 。1991 年 Jerome Friedman 提出多元适应性回归样条（Multivariate Adaptive Regression Splines），R 语言社区对应功能的扩展包是 earth 。\n除了 method = \"loess\"，函数 geom_smooth() 支持的统计方法还有很多，比如非线性回归拟合 nls()\n\ntrunk_year_nls &lt;- nls(revision ~ a * (year - 1996)^2 + b,\n  data = subset(trunk_year, year != 1997),\n  start = list(a = -0.1, b = 1000)\n)\n\n采用一元二次非线性回归拟合方法，效果如 图 7.8 所示。\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    method = \"nls\", \n    formula = \"y ~ a * (x - 1996)^2 + b\",\n    method.args = list(\n      start = list(a = -0.1, b = 1000)\n    ), se = FALSE, \n    data = subset(trunk_year, year != 1997),\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.8: 过去 25 年代码提交次数的变化情况\n\n\n\n\n\n\n\n\n\n\n注意\n\n\n\n在函数 geom_smooth() 内调用非线性回归拟合方法时，暂不支持提供置信区间。\n\n\n即便在不清楚统计原理的情况下，也不难看出 图 7.7 和 图 7.8 的差异，局部多项式回归捕捉到了更多的信息，特别是起步阶段的上升趋势，以及 2000-2005 年的高峰特点。\n\nsummary(trunk_year_loess)\n\n#&gt; Call:\n#&gt; loess(formula = revision ~ year, data = subset(trunk_year, year != \n#&gt;     1997), span = 0.75, degree = 2, family = \"symmetric\", method = \"loess\", \n#&gt;     control = loess.control(surface = \"direct\", iterations = 4))\n#&gt; \n#&gt; Number of Observations: 25 \n#&gt; Equivalent Number of Parameters: 4.53 \n#&gt; Residual Scale Estimate: 308.4 \n#&gt; Trace of smoother matrix: 4.97  (exact)\n#&gt; \n#&gt; Control settings:\n#&gt;   span     :  0.75 \n#&gt;   degree   :  2 \n#&gt;   family   :  symmetric      iterations = 4\n#&gt;   surface  :  direct\n#&gt;   normalize:  TRUE\n#&gt;  parametric:  FALSE\n#&gt; drop.square:  FALSE\n\n\n\nsummary(trunk_year_nls)\n\n#&gt; \n#&gt; Formula: revision ~ a * (year - 1996)^2 + b\n#&gt; \n#&gt; Parameters:\n#&gt;    Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; a   -2.9625     0.4555  -6.504 1.23e-06 ***\n#&gt; b 3070.0890   147.1920  20.858  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 471.8 on 23 degrees of freedom\n#&gt; \n#&gt; Number of iterations to convergence: 1 \n#&gt; Achieved convergence tolerance: 2.808e-08\n\n\n非线性回归模型带有 2 个参数，一共 26 个观察值，因此，自由度为 26 - 2 = 24。 RSE 残差平方和的标准差为\n\n# 非线性回归的残差平方和的标准差\nsqrt(sum(residuals(trunk_year_nls)^2)/24)\n\n#&gt; [1] 461.8963\n\n\n以平滑曲线连接相邻的散点，可以构造一个插值方法给函数 geom_smooth()，如下示例基于样条插值函数 spline()。样条源于德国宝马工程师，车辆外壳弧线，那些拥有非常漂亮的弧线，越光滑，与空气的摩擦阻力越小，车辆的气动外形更加符合流体力学的要求，加工打磨更加困难，往往价值不菲。美感是相通的，即使不懂车标，通过气动外形，也能识别出车辆的档次。\nggplot2 包支持的平滑方法有很多，如借助函数 splinefun() 构造样条插值获得平滑曲线，调用 mgcv 包的函数 gam() ，调用 ggalt 包的函数 geom_xspline() 。\nxxspline &lt;- function(formula, data, ...) {\n  dat &lt;- model.frame(formula, data)\n  res &lt;- splinefun(dat[[2]], dat[[1]])\n  class(res) &lt;- \"xxspline\"\n  res\n}\n\npredict.xxspline &lt;- function(object, newdata, ...) {\n  object(newdata[[1]])\n}\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    formula = \"y~x\",\n    method = xxspline, se = FALSE,\n    data = subset(trunk_year, year != 1997)\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    formula = y ~ s(x, k = 12),\n    method = \"gam\", se = FALSE,\n    data = subset(trunk_year, year != 1997)\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    method = \"lm\", \n    formula = \"y ~ poly((x - 1996), 3)\",\n    se = FALSE, \n    data = subset(trunk_year, year != 1997),\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n\n\n\n(a) 自定义样条插值 spline\n\n\n\n\n\n\n\n\n\n(b) 广义可加模型样条拟合\n\n\n\n\n\n\n\n\n\n\n\n(c) 自由度为 3 的正交多项式拟合\n\n\n\n\n\n\n图 7.9: 过去 25 年代码提交次数的变化情况\n\n\n数学公式表达的统计模型与 R 语言表达的计算公式的对应关系见下 表格 7.1 ，更多详情见帮助文档 ?formula。\n\n\n表格 7.1: 数学公式与 R 语言表示的计算公式\n\n\n\n\n\n\n\n数学公式\nR 语言计算公式\n\n\n\n\\(y = \\beta_0\\)\ny ~ 1\n\n\n\\(y = \\beta_0 + \\beta_1 x_1\\)\n\ny ~ 1 + x1 或 y ~ x1 或 y ~ x1 + x1^2\n\n\n\n\\(y = \\beta_1 x_1\\)\n\ny ~ 0 + x1 或 y ~ -1 + x1\n\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\\)\ny ~ x1 + x2\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2\\)\ny ~ x1 * x2\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 x_2\\)\ny ~ x1:x2\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2\\)\ny ~ x1 + x2 + x1:x2\n\n\n\\(y = \\beta_0 + \\sum_{i=1}^{999}\\beta_i x_i\\)\ny ~ .\n\n\n\\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^5\\)\ny ~ x + I(x^5)\n\n\n\\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\)\ny ~ x + I(x^2)\n\n\n\\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\)\ny ~ poly(x, degree = 2, raw = TRUE)\n\n\n\n\n\n\n\n7.1.4 流线图\n流线图（Stream Graph）是堆积面积图（Stacked Area Graph）的一种变体，适合描述时间序列数据的趋势。ggplot2 扩展包 ggstream 可以制作流线图，如下图所示。\n\nlibrary(ggstream)\ntrunk_year_author &lt;- aggregate(data = svn_trunk_log, revision ~ year + author, FUN = length)\nggplot(trunk_year_author, aes(x = year, y = revision, fill = author)) +\n  geom_stream() +\n  theme_classic() +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"年份\", y = \"提交量\", fill = \"贡献者\")\n\n\n\n\n\n\n图 7.10: 各开发者的提交量趋势\n\n\n\n\n\n7.1.5 曲面图\nggplot2 包暂不支持绘制三维曲面图，而 lattice 包支持，但也是非常有限的支持。lattice 包和 ggplot2 包都是基于图形语法的，层层叠加就必然会出现覆盖，只有在绘制函数型数据的图像时是合适的，因为覆盖少，即使覆盖也不妨碍趋势的表达。根据不同的使用场景有两个更好的选择，基于 OpenGL 的真三维图形可以用 rayrender 和 rayshader 包绘制，而基于 JavaScripts 的交互式三维图形可以用 rgl 或 plotly 包绘制。\n下 图 7.11 是用 lattice 包的 wireframe() 函数绘制的，这是一个三维曲面透视图，三维图形有时候并不能很好地表达数据，或者数据并不适合用三维图形表示。数据本身并没有那么明显的趋势规律，同样也会体现不出三维图形的表达能力。大部分情况下，我们应当避免使用静态的三维图形，但函数型数据是适合用三维图形来表达的。\n\n代码trunk_year_week &lt;- aggregate(data = svn_trunk_log, revision ~ year + week, FUN = length)\nlibrary(lattice)\nwireframe(\n  data = trunk_year_week, revision ~ year * as.integer(week),\n  shade = TRUE, drape = FALSE,\n  xlab = \"年份\",\n  ylab = \"第几周\",\n  zlab = list(\"提交量\", rot = 90),\n  scales = list(\n    arrows = FALSE, col = \"black\"\n  ),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -.6, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.8, units = \"inches\"),\n      top.padding = list(x = -1.0, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = -60, x = -70, y = 0)\n)\n\n\n\n\n\n\n图 7.11: 25 年代码提交量变化趋势图\n\n\n\n\n每周的代码提交量受影响因素多，不确定性多，波动表现尖锐高频，上图反而对整体趋势的表达不够简洁清晰。按年、月统计提交量平均掉了每日的波动，反而可以体现更大的周期性和趋势性。下面绘制三维柱形图，三维图形天然给人有更加直观的感觉，毕竟立体。latticeExtra 包提供三维柱形图图层 panel.3dbars()，如 图 7.12 所示。\n\n代码# 按年、月分组统计代码提交量\ntrunk_year_month &lt;- aggregate(\n  data = svn_trunk_log,\n  revision ~ year + month, FUN = length\n)\n# 数据转化为矩阵类型\ntrunk_year_month_m &lt;- matrix(\n  data = trunk_year_month[trunk_year_month$year &gt; 1998, \"revision\"],\n  ncol = 12, nrow = 24, byrow = FALSE,\n  dimnames = list(\n    1999:2022, # 行\n    1:12 # 列\n  )\n)\n# 绘制三维柱形图\ncloud(trunk_year_month_m,\n  panel.3d.cloud = latticeExtra::panel.3dbars,\n  col.facet = \"red\", # 柱子的颜色\n  col = \"gray90\",\n  xbase = 0.5, ybase = 0.5, # 柱子的大小\n  scales = list(\n    arrows = FALSE, col = \"black\",\n    # tck 刻度线的长度\n    tck = c(0.7, 1.5, 1),\n    # distance 控制标签到轴的距离\n    distance = c(1.2, 0.6, 0.8)\n  ),\n  # rot 旋转轴标签\n  xlab = list(\"年份\", rot = -45), ylab = list(\"月份\", rot = 45),\n  zlab = list(\"提交量\", rot = 90),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -.6, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.8, units = \"inches\"),\n      top.padding = list(x = -1.0, units = \"inches\")\n    )\n  ),\n  # 去掉边框\n  par.settings = list(\n    axis.line = list(col = \"transparent\"),\n    layout.widths = list(ylab.axis.padding = 0)\n  ),\n  screen = list(z = -45, x = -30, y = 0)\n)\n\n\n\n\n\n\n图 7.12: 25 年代码提交量变化趋势图\n\n\n\n\n\n7.1.6 热力图\n图 7.13 提交量变化趋势\n\nggplot(data = trunk_year_week, aes(x = as.integer(week) , y = year, fill = revision)) +\n  geom_tile(linewidth = 0.4) +\n  scale_fill_viridis_c(option = \"C\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme_classic() +\n  labs(x = \"第几周\", y = \"年份\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.13: 25 年代码提交量变化热力图\n\n\n\n\n图层 scale_x_continuous() 中设置 expand = c(0, 0) 可以去掉数据与 x 轴之间的空隙。 或者添加坐标参考系图层 coord_cartesian()，设置参数 expand = FALSE 同时去掉横纵轴与数据之间的空隙。\n\naggregate(data = svn_trunk_log, revision ~ year + month, length) |&gt;\n  ggplot(aes(x = month, y = year, fill = revision)) +\n  geom_tile(linewidth = 0.4) +\n  scale_fill_viridis_c(option = \"C\") +\n  coord_cartesian(expand = FALSE) +\n  theme_classic() +\n  labs(x = \"月份\", y = \"年份\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.14: 25 年代码提交量变化热力图\n\n\n\n\n\n7.1.7 日历图\n更加直观地展示出节假日、休息工作日、寒暑假，比如描述学生学习规律、需求的季节性变化、周期性变化。\n\n# 星期、月份缩写\nweek.abb &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\nmonth.abb &lt;- c(\n  \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n)\n# 按年、星期、第几周聚合统计提交量数据\nsvn_trunk_year &lt;- aggregate(\n  revision ~ year + wday + week, FUN = length,\n  data = svn_trunk_log, subset = year %in% 2018:2022\n)\n# 第几周转为整型数据\n# 周几转为因子型数据\nsvn_trunk_year &lt;- within(svn_trunk_year, {\n   week = as.integer(week)\n   wday = factor(wday, labels = week.abb)\n})\n\n\nggplot(data = svn_trunk_year, aes(\n  x = week, y = wday, fill = cut(revision, breaks = 5 * 0:5)\n)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  scale_fill_brewer(palette = \"Greens\") +\n  scale_x_continuous(\n    expand = c(0, 0), breaks = seq(1, 52, length = 12), labels = month.abb\n  ) +\n  facet_wrap(~year, ncol = 1) +\n  theme_minimal() +\n  labs(x = \"月份\", y = \"星期\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.15: 最近 5 年休息和工作日打码活跃度\n\n\n\n\n经过了解 svn_trunk_year 2018 - 2022 年每天提交量的范围是 0 次到 21 次，0 次表示当天没有提交代码，SVN 上也不会有日志记录。因此，将提交量划分为 5 档\n\n7.1.8 棋盘图\n棋盘图一般可以放所有时间节点的聚合信息，格点处为落的子\n该数据集的存储结构很简单，是一个两列的数据框，它的一些属性如下：\n\nstr(rversion)\n\n#&gt; 'data.frame':    140 obs. of  2 variables:\n#&gt;  $ version: chr  \"0.49\" \"0.50-a1\" \"0.50-a4\" \"0.60.0\" ...\n#&gt;  $ date   : chr  \"1997-04-23\" \"1997-07-22\" \"1997-09-10\" \"1997-12-04\" ...\n\n\n做一点数据处理，将 date 字段转为日期类型，并从日期中提取年、月信息。\n\nrversion$date &lt;- as.Date(rversion$date, format = \"%Y-%m-%d\", tz = \"UTC\")\nrversion$year &lt;- format(rversion$date, \"%Y\")\nrversion$month &lt;- format(rversion$date, \"%m\")\n\n统计过去 25 年里每月的发版次数，如图 图 7.16\n\naggregate(data = rversion, version ~ year + month, length) |&gt;\n  ggplot(aes(x = month, y = year)) +\n  geom_label(aes(label = version, fill = version),\n    show.legend = F, color = \"white\") +\n  scale_fill_viridis_c(option = \"D\", begin = 0.2, end = 0.8) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray95\")) +\n  labs(x = \"月份\", y = \"年份\")\n\n\n\n\n\n\n图 7.16: 25 年 R 软件发版情况\n\n\n\n\n\n7.1.9 时间线图\n时间线图非常适合回顾过去，展望未来，讲故事\n时间线图展示信息的层次和密度一般由时间跨度决定。时间跨度大时，展示重点节点信息，时间跨度小时，重点和次重点信息都可以放。从更加宏观的视角，厘清发展脉络，比如近两年的 R 软件发版情况。\n本节用到一个数据集 rversion，记录了历次 R 软件发版时间及版本号，见 表格 7.2\n\n\n\n表格 7.2: R 软件发版数据集（部分）\n\n\n\n\n版本号\n发版日期\n发版年份\n发版月份\n\n\n\n0.49\n1997-04-23\n1997\n04\n\n\n0.50-a1\n1997-07-22\n1997\n07\n\n\n0.50-a4\n1997-09-10\n1997\n09\n\n\n0.60.0\n1997-12-04\n1997\n12\n\n\n0.60.1\n1997-12-07\n1997\n12\n\n\n0.61.0\n1997-12-22\n1997\n12\n\n\n\n\n\n\n\n\n\nrversion_tl &lt;- within(rversion, {\n  # 版本号为 x.0.0 为重大版本 big\n  # 版本号为 x.1.0 x.12.0 x.20.0 为主要版本 major\n  # 版本号为 x.0.1 为次要版本 minor\n  status &lt;- ifelse(grepl(pattern = \"*\\\\.0\\\\.0\", x = version), \"big\", version)\n  status &lt;- ifelse(grepl(pattern = \"*\\\\.[1-9]{1,2}\\\\.0$\", x = status), \"major\", status)\n  status &lt;- ifelse(!status %in% c(\"big\", \"major\"), \"minor\", status)\n})\npositions &lt;- c(0.5, -0.5, 1.0, -1.0, 1.5, -1.5)\ndirections &lt;- c(1, -1)\n# 位置\nrversion_pos &lt;- data.frame(\n  # 只要不是同一天发布的版本，方向相对\n  date = unique(rversion_tl$date),\n  position = rep_len(positions, length.out = length(unique(rversion_tl$date))),\n  direction = rep_len(directions, length.out = length(unique(rversion_tl$date)))\n)\n# 原始数据上添加方向和位置信息\nrversion_df &lt;- merge(x = rversion_tl, y = rversion_pos, by = \"date\", all = TRUE)\n# 最重要的状态放在最后绘制到图上\nrversion_df &lt;- rversion_df[with(rversion_df, order(date, status)), ]\n\n选取一小段时间内的发版情况，比如最近的三年 — 2020 - 2022 年\n\n# 选取 2020 - 2022 年的数据\nsub_rversion_df&lt;- rversion_df[rversion_df$year %in% 2020:2022, ]\n# 月份注释\nmonth_dat &lt;- data.frame(\n  date = seq(from = as.Date('2020-01-01'), to = as.Date('2022-12-31'), by = \"3 month\")\n)\nmonth_dat &lt;- within(month_dat, {\n  month = format(date, \"%b\")\n})\n# 年份注释\nyear_dat &lt;- data.frame(\n  date = seq(from = as.Date('2020-01-01'), to = as.Date('2022-12-31'), by = \"1 year\")\n)\nyear_dat &lt;- within(year_dat, {\n  year = format(date, \"%Y\")\n})\n\n图 7.17 展示 2020-2022 年 R 软件发版情况\n\nggplot(data = sub_rversion_df) +\n  geom_segment(aes(x = date, y = 0, xend = date, yend = position)) +\n  geom_hline(yintercept = 0, color = \"black\", linewidth = 1) +\n  geom_label(\n    aes(x = date, y = position, label = version, color = status),\n    show.legend = FALSE\n  ) +\n  geom_point(aes(x = date, y = 0, color = status),\n    size = 3, show.legend = FALSE\n  ) +\n  geom_text(\n    data = month_dat, aes(x = date, y = 0, label = month), vjust = 1.5\n  ) +\n  geom_text(\n    data = year_dat, aes(x = date, y = 0, label = year), vjust = -0.5\n  ) +\n  theme_void()\n\n\n\n\n\n\n图 7.17: 2020-2022 年 R 软件发版情况\n\n\n\n\n图中红色标注的是里程碑式的重大版本，绿色标注的是主要版本，蓝色标注的次要版本，小修小补，小版本更新。\n当时间跨度非常大时，比如过去 25 年，那就只能放重大版本和主要版本信息了，时间上月份信息就不能用名称简写，而用数字更加合适。而且还得竖着放，同时添加那个版本最有影响力的改动。相比于，棋盘图，这是时间线图的优势。\n\nsub_rversion_df2 &lt;- rversion_df[rversion_df$status %in% c(\"big\", \"major\"), ]\nggplot(data = sub_rversion_df2) +\n  geom_segment(aes(x = 0, y = date, xend = position, yend = date, color = status),\n    show.legend = F\n  ) +\n  geom_vline(xintercept = 0, color = \"black\", linewidth = 1) +\n  geom_label(\n    aes(x = position, y = date, label = version, color = status),\n    show.legend = FALSE\n  ) +\n  geom_point(aes(x = 0, y = date, color = status), size = 3, show.legend = FALSE) +\n  geom_text(\n    aes(x = 0, y = as.Date(format(date, \"%Y-01-01\")), label = year),\n    hjust = -0.1\n  ) +\n  theme_void()\n\n\n\n\n\n\n图 7.18: 25 年里 R 软件重大及主要版本发布情况\n\n\n\n\n在 R 语言诞生的前 5 年里，每年发布 3 个主要版本，这 5 年是 R 软件活跃开发的时期。而 2003-2012 年的这 10 年，基本上每年发布 2 个主要版本。2013-2022 年的这 10 年，基本上每年发布 1 个主要版本。\ntimevis 包基于 JavaScript 库 Vis 的 vis-timeline 模块，可以 创建交互式的时间线图，支持与 Shiny 应用集成。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualize-data-comparisons",
    "href": "visualization-intermediate.html#sec-visualize-data-comparisons",
    "title": "7  基础图形",
    "section": "\n7.2 描述对比",
    "text": "7.2 描述对比\n数据来自中国国家统计局发布的2021年统计年鉴，\n\n\n\n表格 7.3: 中国各年龄段的性别比数据（部分）\n\n\n\n\n年龄\n人口数/男\n人口数/女\n性别比（女=100）\n区域\n\n\n\n0-4\n16078524\n14523013\n110.71\n城市\n\n\n5-9\n17172999\n15087731\n113.82\n城市\n\n\n10-14\n14619691\n12727731\n114.86\n城市\n\n\n15-19\n17249362\n15404683\n111.97\n城市\n\n\n20-24\n19776472\n18481665\n107.01\n城市\n\n\n25-29\n22937131\n21478748\n106.79\n城市\n\n\n\n\n\n\n\n\n对比的是什么？城市、镇和乡村的性别分布，是否失衡？在哪个年龄段表现很失衡？\n\n7.2.1 柱形图\n分年龄段比较城市、镇和乡村的性别比数据\n\nggplot(data = china_age_sex, aes(x = `年龄`, y = `性别比（女=100）`, fill = `区域`)) +\n  geom_hline(yintercept = 100, color = \"gray\", lty = 2, linewidth = 1) +\n  geom_col(position = \"dodge2\", width = 0.75) +\n  theme_bw()\n\n\n\n\n\n\n图 7.19: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n考虑到数据本身的含义，一般来说，性别比不可能从 0 开始，除非现实中出现了《西游记》里的女儿国。因此，将纵轴的范围，稍加限制，从 性别比为 70 开始，目的是突出城市、镇和乡村的差异。\n\nggplot(data = china_age_sex, aes(x = `年龄`, y = `性别比（女=100）`, fill = `区域`)) +\n  geom_hline(yintercept = 100, color = \"gray\", lty = 2, linewidth = 1) +\n  geom_col(position = \"dodge2\", width = 0.75) +\n  coord_cartesian(ylim = c(70, 130)) +\n  theme_bw()\n\n\n\n\n\n\n图 7.20: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n\n7.2.2 条形图\n将柱形图横过来即可得到条形图，横过来的好处主要体现在分类很多的时候，留足空间给年龄分组的分类标签，从左到右，从上往下也十分符合大众的阅读习惯\n\nggplot(data = china_age_sex, aes(x = `性别比（女=100）`, y = `年龄`, fill = `区域`)) +\n  geom_vline(xintercept = 100, color = \"gray\", lty = 2, linewidth = 1) +\n  geom_col(position = \"dodge2\", width = 0.75) +\n  coord_cartesian(xlim = c(70, 130)) +\n  theme_bw()\n\n\n\n\n\n\n图 7.21: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n\n7.2.3 点线图\n克利夫兰点图 dotchart() 在条形图的基础上，省略了条形图的宽度，可以容纳更多的数据点。\n\nggplot(data = china_age_sex, aes(x = `性别比（女=100）`, y = `年龄`, color = `区域`)) +\n  geom_vline(xintercept = 100, color = \"lightgray\", lty = 2, linewidth = 1) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n图 7.22: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n\n7.2.4 词云图\nggwordcloud 包提供词云图层 geom_text_wordcloud() 根据代码提交的说明制作词云图。\n\nlibrary(ggwordcloud)\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  ggplot(aes(label = author, size = revision)) +\n  geom_text_wordcloud(seed = 2022, grid_size = 10, max_grid_size = 24) +\n  scale_size_area(max_size = 20)\n\n\n\n\n\n\n图 7.23: 词云图\n\n\n\n\n词云图也可以是条形图或柱形图的一种替代，词云图不用担心数目多少，而条形图不适合太多的分类情形。\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  subset(subset = revision &gt;= 100) |&gt; \n  ggplot(aes(x = revision, y = reorder(author, revision))) +\n  geom_col() +\n  theme_classic() +\n  coord_cartesian(expand = FALSE) +\n  labs(x = \"提交量\", y = \"维护者\")\n\n\n\n\n\n\n图 7.24: 开发者提交量排行榜",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualize-data-proportion",
    "href": "visualization-intermediate.html#sec-visualize-data-proportion",
    "title": "7  基础图形",
    "section": "\n7.3 描述占比",
    "text": "7.3 描述占比\n\n7.3.1 简单饼图\n提交量小于 2000 次的贡献者合并为一类 Others，按贡献者分组统计提交量及其占比，如 图 7.25 所示。\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  transform(author2 = ifelse(revision &lt; 2000, \"Others\", author)) |&gt;\n  aggregate(revision ~ author2, FUN = sum) |&gt;\n  transform(label = paste0(round(revision / sum(revision), digits = 4) * 100, \"%\")) |&gt;\n  ggplot(aes(x = 1, fill = reorder(author2, revision), y = revision)) +\n  geom_col(position = \"fill\", show.legend = FALSE, color = \"white\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  coord_polar(theta = \"y\") +\n  geom_text(aes(x = 1.2, label = author2),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  geom_text(aes(x = 1.65, label = label),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.25: 维护者提交量占比\n\n\n\n\n当把提交量小于 1000 次的贡献者合并为 Others，则分类较多，占比小的也有一席之地，饼图上显得十分拥挤。\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  transform(author2 = ifelse(revision &lt; 1000, \"Others\", author)) |&gt; \n  aggregate(revision ~ author2, FUN = sum) |&gt; \n  transform(label = paste0(round(revision / sum(revision), digits = 4) * 100, \"%\")) |&gt; \n  ggplot(aes(x = 1, fill = reorder(author2, revision)  , y = revision)) +\n  geom_col(position = \"fill\", show.legend = FALSE, color = \"white\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  coord_polar(theta = \"y\") +\n  geom_text(aes(x = 1.2, label = author2),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  geom_text(aes(x = 1.6, label = label),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.26: 维护者提交量占比\n\n\n\n\n一种缓解拥挤的办法是通过 ggrepel 包在扇形区域旁边添加注释\n\nlibrary(ggrepel)\ndat1 &lt;- aggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  transform(author2 = ifelse(revision &lt; 1000, \"Others\", author)) |&gt;\n  aggregate(revision ~ author2, FUN = sum)\n\ndat2 &lt;- within(dat1, {\n  value &lt;- 100 * revision / sum(revision)\n  csum &lt;- rev(cumsum(rev(value)))\n  pos &lt;- value / 1.5 + c(csum[-1], NA)\n  pos &lt;- ifelse(is.na(pos), value / 2, pos)\n  label &lt;- paste(author2, paste0(round(value, 2), \"%\"), sep = \"\\n\")\n})\n\nggplot(data = dat2, aes(x = 1, fill = author2, y = value)) +\n  geom_col(show.legend = FALSE, color = \"white\") +\n  coord_polar(theta = \"y\") +\n  geom_label_repel(aes(y = pos, label = label), \n    size = 4.5, nudge_x = 0.75, show.legend = FALSE\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.27: 维护者提交量占比\n\n\n\n\n但是数量很多的情况下，也是无能为力的，当然，是否需要显示那么多，是否可以合并占比小的部分，也是值得考虑的问题。\n\n\n\n表格 7.4: SVN 日志中的贡献者（部分）\n\n\n\n\nSVN 花名\n真实名字\n主要贡献\n\n\n\nrgentlem\nRobert Gentleman\nR 语言创始人\n\n\nihaka\nRoss Ihaka\nR 语言创始人\n\n\nripley\nBrian Ripley\nR Core Team 中的核心\n\n\nmurrell\nPaul Murrell\ngrid 包及栅格绘图系统\n\n\nmaechler\nMartin Maechler\ncluster / Matrix 包维护者\n\n\nhornik\nKurt Hornik\nR FAQ 和 CRAN 维护者\n\n\njmc\nJohn Chambers\nS 语言的创始人之一\n\n\nbates\nDouglas Bates\nnlme / lme4 包核心开发者\n\n\npd\nPeter Dalgaard\n《统计导论与 R 语言》作者\n\n\nligges\nUwe Ligges\n让 BUGS 与 R 同在\n\n\nplummer\nMartyn Plummer\n让 JAGS 与 R 携手\n\n\nluke\nLuke Tierney\ncompiler 包核心开发者\n\n\niacus\nStefano M. Iacus\n让 CRAN 拥抱 Fedora 系统\n\n\nkalibera\nTomas Kalibera\n编码问题终结者\n\n\ndeepayan\nDeepayan Sarkar\nlattice 包维护者\n\n\nmurdoch\nDuncan Murdoch\nR 软件的 Windows 版本维护者\n\n\nduncan\nDuncan Temple Lang\nXML / RCurl 包开发者\n\n\nurbaneks\nSimon Urbanek\nrJava / Rserve 包维护者\n\n\n\n\n\n\n\n\n\n7.3.2 环形饼图\n中间空了一块\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  transform(author2 = ifelse(revision &lt; 2000, \"Others\", author)) |&gt; \n  aggregate(revision ~ author2, FUN = sum) |&gt; \n  transform(label = paste0(round(revision / sum(revision), digits = 4) * 100, \"%\")) |&gt; \n  ggplot(aes(x = 1, fill = author2, y = revision)) +\n  geom_col(position = \"fill\", show.legend = FALSE, color = \"white\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  coord_polar(theta = \"y\") +\n  geom_text(aes(x = 1.2, label = author2),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  geom_text(aes(x = 1.7, label = label),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL) +\n  xlim(c(0.2, 1.7))\n\n\n\n\n\n\n图 7.28: 维护者提交量占比\n\n\n\n\n\n7.3.3 扇形饼图\n扇形饼图又叫风玫瑰图或南丁格尔图\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  transform(author2 = ifelse(revision &lt; 2000, \"Others\", author)) |&gt; \n  aggregate(revision ~ author2, FUN = sum) |&gt; \n  ggplot(aes(x = reorder(author2, revision), y = revision)) +\n  geom_col(aes(fill = author2), show.legend = FALSE) +\n  coord_polar() +\n  theme_minimal() +\n  theme(axis.text.y = element_blank()) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.29: 维护者提交量分布\n\n\n\n\n\n7.3.4 帕累托图\n\n除了饼图，还常用堆积柱形图描述各个部分的数量，柱形图的优势在于简洁，准确，兼顾对比和趋势。下 图 7.30 描述各年开发者们的贡献量及其变化趋势，饼图无法表达数量的变化趋势。\n\naggregate(data = svn_trunk_log, revision ~ year + author, FUN = length) |&gt; \n  ggplot(aes(x = year, y = revision, fill = author)) +\n  geom_col() +\n  theme_classic() +\n  coord_cartesian(expand = FALSE) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"年份\", y = \"提交量\", fill = \"开发者\")\n\n\n\n\n\n\n图 7.30: 代码提交量的比例趋势\n\n\n\n\n百分比堆积柱形图在数量堆积柱形图的基础上，将纵坐标的数量转化为百分比，下 图 7.31 展示各年开发者代码提交比例的变化趋势。\n\naggregate(data = svn_trunk_log, revision ~ year + author, FUN = length) |&gt; \n  ggplot(aes(x = year, y = revision, fill = author)) +\n  geom_col(position = \"fill\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  theme_classic() +\n  coord_cartesian(expand = FALSE) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"年份\", y = \"提交量\", fill = \"开发者\")\n\n\n\n\n\n\n图 7.31: 代码提交量的比例趋势\n\n\n\n\n帕累托图描述各个部分的占比，特别是突出关键要素的占比。收入常服从帕累托分布，这是一个幂率分布，比如 80% 的财富集中在 20% 的人的手中。下 图 7.32 展示过去 25 年各位开发者的代码累计提交量，提交量小于 1000 的已经合并为一类。不难看出，Ripley 的提交量远高于其他开发者。\n\ndat &lt;- aggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  transform(author = ifelse(revision &lt; 1000, \"Others\", author)) |&gt;\n  aggregate(revision ~ author, FUN = sum)\ndat &lt;- dat[order(-dat$revision), ]\n\nggplot(data = dat, aes(x = reorder(author, revision, decreasing = T), y = revision)) +\n  geom_col(width = 0.75) +\n  geom_line(aes(y = cumsum(revision), group = 1)) +\n  geom_point(aes(y = cumsum(revision))) +\n  theme_classic() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  labs(x = \"维护者\", y = \"累计提交量\")\n\n\n\n\n\n\n图 7.32: 代码提交量的比例分布\n\n\n\n\n\n7.3.5 马赛克图\n马赛克图常用于展示多个分类数据，如 图 7.33 所示，展示加州伯克利分校院系录取情况。\n\nlibrary(ggmosaic)\nggplot(data = as.data.frame(UCBAdmissions)) +\n  geom_mosaic(aes(x = product(Dept, Gender), weight = Freq, fill = Admit)) +\n  theme_minimal()\n\n\n\n\n\n\n图 7.33: 加州伯克利分校院系录取情况\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\nBase R 提供函数 plot() 和 mosaicplot() 对 table 表格类型的数据可视化，提供一套公式绘图语法，可以绘制类似的马赛克图。\n\nmosaicplot(~ Gender + Dept + Admit,\n  data = UCBAdmissions, color = TRUE,\n  main = \"\", xlab = \"性别\", ylab = \"院系\"\n)\n\n对于多维列联表数据，Base R 提供函数 loglin() 拟合对数线性模型，以获取更加定量的结果。更进一步，MASS 包在函数 loglin() 的基础上，打包了另一个函数 loglm() ，它提供与函数 lm() 和 glm() 相一致的公式语法，使用起来更加方便。当然，函数 glm() 本身也是可以拟合对数线性模型的，毕竟它也是一种特殊的广义线性模型。\n\n\n\n7.3.6 矩阵树图\n矩阵树图展示有层次的占比，比如 G20 国家的 GDP 按半球、地域分组。treemapify 包专门绘制矩阵树图，下 图 7.34 展示南北半球，各地域内各个国家 GDP 的占比。\n\n\n\n表格 7.5: G20 国家经济水平：GDP 总量、人类发展指数等\n\n\n\n\n\n\n\n\n\n\n\n\n区域\n国家\nGDP\n人类发展指数\n经济水平\n所属半球\n\n\n\nAfrica\nSouth Africa\n384315\n0.629\nDeveloping\nSouthern\n\n\nNorth America\nUnited States\n15684750\n0.937\nAdvanced\nNorthern\n\n\nNorth America\nCanada\n1819081\n0.911\nAdvanced\nNorthern\n\n\nNorth America\nMexico\n1177116\n0.775\nDeveloping\nNorthern\n\n\nSouth America\nBrazil\n2395968\n0.730\nDeveloping\nSouthern\n\n\nSouth America\nArgentina\n474954\n0.811\nDeveloping\nSouthern\n\n\n\n\n\n\n\n\n每个瓦片的大小代表国家的 GDP 在所属半球里的比重。\n\nggplot(G20, aes(area = gdp_mil_usd, fill = region, label = country, subgroup = region)) +\n  geom_treemap() +\n  geom_treemap_text(grow = T, reflow = T, colour = \"black\") +\n  facet_wrap(~hemisphere) +\n  scale_fill_brewer(palette = \"Set1\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"G20 主要经济体\", fill = \"区域\")\n\n\n\n\n\n\n图 7.34: G20 主要经济体的 GDP 占比\n\n\n\n\n\n7.3.7 量表图\n展示调查研究中的用户态度。量表在市场调查，问卷调查，App 用户体验反馈等方面应用十分广泛，已经成为调查研究中的金标准。量表由心理学家 Rensis Likert 于 1932 年提出 (Likert 1932)，Likert Scale 就是以他的名字命名的。\n量表在互联网产品中应用非常广泛，比如美团App里消息页面中的反馈框，用以收集用户使用产品的体验情况，如 表格 7.6 所示，从极其困难到极其方便，将用户反馈分成7个等级，目的是收集用户的反馈，以期改善产品的体验。\n\n\n表格 7.6: 您觉得在本页面，找想看的消息方便吗？\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n极其困难\n非常困难\n比较困难\n一般\n比较方便\n非常方便\n极其方便\n\n\n\n\n\n量表中的问题、观点的描述极其简单明了，对回答、表明态度的任何人都不会造成歧义，以确保不受文化差异、学历差异等的影响，受调查的人只需在待选的几个选项中圈选即可。候选项一般为 5-7 个，下面是一组典型的选项：\n\nStrongly disagree （强烈反对），\nDisagree（反对），\nNeither agree nor disagree（中立），\nAgree（同意），\nStrongly agree（强烈同意）。\n\nJason M. Bryer 开发了一个 R 包 likert，特别适合调查研究数据可视化，将研究对象的态度以直观有效的方式展示出来，内置多个数据集，其中 表格 7.7 是一个数学焦虑量表调查的结果，调查数据来自统计课上的 20 个学生。\n调查对象是 78 个来自不同学科的本科生，样本含有 36 个男性和 42 个女性，64% 的样本的年龄在 18 至 24 岁，36% 的样本年龄 25 岁及以上。更多数据背景信息 (Bai 等 2009)。\n\n\n表格 7.7: 你对数学感到焦虑吗？\n\n\n\n\n\n\n\n\n\n\n\n观点\n强烈反对\n反对\n中立\n同意\n强烈同意\n\n\n\nI find math interesting.\n10\n15\n10\n35\n30\n\n\nI get uptight during math tests.\n10\n20\n20\n25\n25\n\n\nI think that I will use math in the future.\n0\n0\n20\n25\n55\n\n\nMind goes blank and I am unable to think clearly when doing my math test.\n30\n30\n15\n10\n15\n\n\nMath relates to my life.\n5\n20\n10\n40\n25\n\n\nI worry about my ability to solve math problems.\n20\n20\n20\n30\n10\n\n\nI get a sinking feeling when I try to do math problems.\n35\n10\n15\n35\n5\n\n\nI find math challenging.\n5\n10\n15\n45\n25\n\n\nMathematics makes me feel nervous.\n20\n25\n15\n25\n15\n\n\nI would like to take more math classes.\n20\n25\n30\n20\n5\n\n\nMathematics makes me feel uneasy.\n25\n15\n20\n25\n15\n\n\nMath is one of my favorite subjects.\n35\n15\n25\n20\n5\n\n\nI enjoy learning with mathematics.\n15\n25\n30\n20\n10\n\n\nMathematics makes me feel confused.\n15\n20\n15\n35\n15\n\n\n\n\n\n\n相比于 ggplot2 绘制的普通条形图， 图 7.35 有一些独特之处：对立型的渐变色表示两个不同方向的态度，左右两侧以中立态度为中间位置，非常形象，并且按照其中一个方向的态度数据排序，显得比较整齐有序，便于理解。\n\n# 数据来自 likert 包\nMathAnxiety &lt;- readRDS(file = \"data/MathAnxiety.rds\")\n# 宽转长格式\nMathAnxiety_df &lt;- reshape(data = MathAnxiety, \n  varying = c(\"Strongly Disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly Agree\"),\n  times = c(\"Strongly Disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly Agree\"),\n  timevar = \"Attitude\", v.names = \"Numbers\",  idvar = \"Item\", \n  new.row.names = 1:(5 * 14), direction = \"long\"\n )\n\nMathAnxiety_df$Attitude &lt;- factor(MathAnxiety_df$Attitude, levels = c(\n  \"Strongly Agree\", \"Agree\", \"Neutral\", \"Disagree\", \"Strongly Disagree\"\n), labels =  c(\n  \"强烈同意\", \"同意\", \"中立\", \"反对\", \"强烈反对\"\n), ordered = TRUE)\n\nggplot(data = MathAnxiety_df, aes(x = Numbers, y = Item)) +\n  geom_col(aes(fill = Attitude), position = \"fill\") +\n  scale_x_continuous(labels = scales::label_percent()) +\n  scale_y_discrete(labels = scales::label_wrap(25)) +\n  scale_fill_brewer(palette = \"BrBG\", direction = -1) +\n  theme_classic() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  coord_cartesian(expand = FALSE) +\n  labs(x = \"占比\", y = \"问题\", fill = \"态度\")\n\n\n\n\n\n\n图 7.35: 你喜欢数学吗\n\n\n\n\nlikert 包的函数 likert() 适合对聚合的调查数据绘图。\n\nlibrary(likert)\nlmath &lt;- likert(summary = MathAnxiety)\nplot(lmath)\n\n而 ggstats 包的函数 gglikert() 适合对明细的调查数据绘图。下面模拟一次调查收集到的数据，共计 150 人回答 6 个问题，每个问题都有 5 个候选项构成。\n\nlibrary(ggstats)\nlikert_levels &lt;- c(\"强烈反对\", \"反对\", \"中立\", \"同意\", \"强烈同意\")\nset.seed(2023)\nlibrary(data.table)\ndf &lt;- data.table(\n  q1 = sample(likert_levels, 150, replace = TRUE),\n  q2 = sample(likert_levels, 150, replace = TRUE, prob = 5:1),\n  q3 = sample(likert_levels, 150, replace = TRUE, prob = 1:5),\n  q4 = sample(likert_levels, 150, replace = TRUE, prob = 1:5),\n  q5 = sample(c(likert_levels, NA), 150, replace = TRUE),\n  q6 = sample(likert_levels, 150, replace = TRUE, prob = c(1, 0, 1, 1, 0))\n)\nfkt &lt;- paste0(\"q\", 1:6)\ndf[, (fkt) := lapply(.SD, factor, levels = likert_levels), .SDcols = fkt]\n\n一个调查问卷共有 6 个题目，150 个人对 6 个问题的回答构成一个数据框 df 。\n\ngglikert(df)\n\n\n\n\n\n\n图 7.36: Likert 图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualization-intermediate-exercise",
    "href": "visualization-intermediate.html#sec-visualization-intermediate-exercise",
    "title": "7  基础图形",
    "section": "\n7.4 习题",
    "text": "7.4 习题\n\n\n根据 Github 代码提交量数据制作日历图。\n\ngithub_ctb &lt;- jsonlite::read_json(path = \"data/contributions.json\")\ngithub_df &lt;- data.frame(\n  date = unlist(lapply(github_ctb$contributions, \"[[\", \"date\")),\n  count = unlist(lapply(github_ctb$contributions, \"[[\", \"count\")),\n  color = unlist(lapply(github_ctb$contributions, \"[[\", \"color\")),\n  intensity = unlist(lapply(github_ctb$contributions, \"[[\", \"intensity\"))\n)\nweek.abb &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\ngithub_df &lt;- within(github_df, {\n  date &lt;- as.Date(date)\n  year &lt;- format(date, format = \"%Y\", tz = \"UTC\")\n  month &lt;- format(date, format = \"%m\", tz = \"UTC\")\n  week &lt;- format(date, format = \"%U\", tz = \"UTC\")\n  wday &lt;- format(date, format = \"%a\", tz = \"UTC\")\n  nday &lt;- format(date, format = \"%j\", tz = \"UTC\")\n  week &lt;- as.integer(week)\n  wday &lt;- factor(wday, labels = week.abb)\n})\nggplot(\n  data = subset(github_df, subset = year %in% 2020:2022),\n  aes(x = week, y = wday, fill = count)\n) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  scale_fill_distiller(palette = \"Greens\", direction = 1) +\n  scale_x_continuous(\n    expand = c(0, 0), breaks = seq(1, 52, length = 12), labels = month.abb\n  ) +\n  facet_wrap(~year, ncol = 1) +\n  theme_minimal() +\n  labs(x = \"月份\", y = \"星期\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.37: Github 打卡日历图\n\n\n\n\n\n\n\n\n\n\nBai, H., L. Wang, W. Pan, 和 M. Frey. 2009. 《Measuring mathematics anxiety: Psychometric analysis of a bidimensional affective scale》. Journal of Instructional Psychology 36 (3): 185–93.\n\n\nKothari, Aditya. 2022. ggTimeSeries: Time Series Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggTimeSeries.\n\n\nLikert, Rensis. 1932. 《A Technique for the Measurement of Attitudes》. Archives of Psychology 142 (1): 1–55.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant Graphics for Data Analysis. 2nd 本. Springer-Verlag New York. https://ggplot2.tidyverse.org.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html",
    "href": "visualization-advanced.html",
    "title": "8  统计图形",
    "section": "",
    "text": "8.1 描述分布\n数据来自中国国家统计局发布的2021年统计年鉴，各省、直辖市和自治区分区域的性别比数据（部分）情况见 表格 8.1 。\n表格 8.1: 各省、直辖市和自治区分区域的性别比数据（部分）\n\n\n\n\n地区\n人口数/男\n人口数/女\n性别比（女=100）\n区域\n\n\n\n北京\n8937161\n8814520\n101.39\n城市\n\n\n天津\n5610161\n5322931\n105.40\n城市\n\n\n河北\n11010407\n11119188\n99.02\n城市\n\n\n山西\n6588788\n6608849\n99.70\n城市\n\n\n内蒙古\n4714495\n4731924\n99.63\n城市\n\n\n辽宁\n12626419\n12946058\n97.53\n城市",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html#sec-visualize-data-distribution",
    "href": "visualization-advanced.html#sec-visualize-data-distribution",
    "title": "8  统计图形",
    "section": "",
    "text": "8.1.1 箱线图\nlibrary(ggplot2)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_boxplot() +\n  theme_classic()\n\nlibrary(lvplot)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_lv() +\n  theme_classic()\n\nboxplot(`性别比（女=100）` ~ `区域` , data = province_sex_ratio)\n\n\n\n\n\n\n\n\n\n(a) ggplot2 包\n\n\n\n\n\n\n\n\n\n(b) lvplot 包\n\n\n\n\n\n\n\n\n\n\n\n(c) Base R 包\n\n\n\n\n\n\n图 8.1: 箱线图的几种绘制形式\n\n\n箱线图的历史有 50 多年了，它的变体也有很多。lvplot 包绘制箱线图的变体 (McGill 和 Larsen 1978)\n\n8.1.2 提琴图\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin(fill = \"lightgray\", draw_quantiles = c(0.25, 0.5, 0.75)) +\n  theme_classic()\n\nvioplot::vioplot(`性别比（女=100）` ~ `区域`,\n  data = province_sex_ratio, col = \"lightgray\"\n)\n\nbeanplot::beanplot(`性别比（女=100）` ~ `区域`,\n  data = province_sex_ratio, col = \"lightgray\", log = \"\",\n  xlab = \"区域\", ylab = \"性别比（女=100）\"\n)\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_violin()\n\n\n\n\n\n\n\n\n\n(b) vioplot 包\n\n\n\n\n\n\n\n\n\n\n\n(c) beanplot 包\n\n\n\n\n\n\n图 8.2: 提琴图\n\n\nbeanplot 包的名字是根据图形的外观取的，bean 即是豌豆，rug 用须线表示数据。\n\n8.1.3 直方图\nggplot2 包绘制直方图的函数是 geom_histogram() ，而与之相关的函数 geom_freqpoly() 是绘制折线图，将直方图中每个柱子的顶点连接起来。\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, fill = `区域`)) +\n  geom_histogram(binwidth = 5, color = \"white\", position = \"stack\") +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8))\n\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, color = `区域`)) +\n  geom_freqpoly(binwidth = 5, stat = \"bin\") +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8))\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_histogram()\n\n\n\n\n\n\n\n\n\n(b) 函数 geom_freqpoly()\n\n\n\n\n\n\n图 8.3: 直方图\n\n\n\n8.1.4 密度图\nggplot2 包绘制密度图的函数是 geom_density()， 图 8.4 展示分组密度曲线图\n\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`)) +\n  geom_density(aes(fill = `区域`), alpha = 0.5) +\n  theme_classic()\n\n\n\n\n\n\n图 8.4: 密度图\n\n\n\n\n\n8.1.4.1 堆积（条件）密度图\n\n\n\n\n\n\n注意\n\n\n\nStacked density plots: if you want to create a stacked density plot, you probably want to ‘count’ (density * n) variable instead of the default density\n\n\n堆积密度图正确的绘制方式是保护边际密度。\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, y = after_stat(density))) +\n  geom_density(aes(fill = `区域`), position = \"stack\", alpha = 0.5) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8))\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, y = after_stat(density * n))) +\n  geom_density(aes(fill = `区域`), position = \"stack\", alpha = 0.5) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8))\n\n\n\n\n\n\n\n\n\n(a) 堆积密度图 after_stat(density)\n\n\n\n\n\n\n\n\n\n(b) 堆积密度图 after_stat(density * n)\n\n\n\n\n\n\n图 8.5: 累积分布密度图\n\n\n什么原因导致 图 8.5 中两个子图看起来没什么差别呢？而换一组数据，就可以看出明显的差别。\nggplot(diamonds, aes(x = carat, y = after_stat(density), fill = cut)) +\n  geom_density(position = \"stack\") +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.8, 0.8))\nggplot(diamonds, aes(x = carat, y = after_stat(density * n), fill = cut)) +\n  geom_density(position = \"stack\") +\n  scale_y_continuous(\n    breaks = c(25000, 50000, 75000), \n    labels = c(\"25K\", \"50K\", \"75K\")) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.8, 0.8))\n\n\n\n\n\n\n\n\n\n(a) 函数 after_stat(density)\n\n\n\n\n\n\n\n\n\n(b) 函数 after_stat(density * n)\n\n\n\n\n\n\n图 8.6: 堆积密度图\n\n\n\n8.1.4.2 联合密度图\n\nstate_x77 &lt;- data.frame(state.x77,\n  state_name = rownames(state.x77),\n  state_region = state.region,\n  check.names = FALSE\n)\np1 &lt;- ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point() +\n  geom_density_2d(aes(\n    color = after_stat(level),\n    alpha = after_stat(level)\n  ), show.legend = F\n  ) +\n  scale_color_viridis_c(option = \"inferno\") +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\np1\n\n\n\n\n\n\n图 8.7: 二维联合密度图\n\n\n\n\n\n8.1.4.3 边际密度图\nggExtra 包(Attali 和 Baker 2022) 添加边际密度曲线和边际直方图。\n\nlibrary(ggExtra)\nggMarginal(p1, type = \"density\")\nggMarginal(p1, type = \"histogram\")\n\n\n\n\n\n\n图 8.8: 描述边际分布\n\n\n\n\n\n8.1.4.4 填充密度图\nggplot2 包提供二维密度图层 geom_density_2d_filled() 绘制热力图， ggdist (Kay 2022) 进行了一些扩展。\n\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_density_2d_filled(contour_var = \"count\") +\n  theme_classic() +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  )\n\n\n\n\n\n\n图 8.9: ggplot2 包绘制二维填充密度图\n\n\n\n\n相比于 ggplot2 内置的二维核密度估计，ggdensity (Otto 和 Kahle 2023) 有一些优势，根据数据密度将目标区域划分，更加突出层次和边界。gghdr 包与 ggdensity 类似，展示 highest density regions (HDR)\n\nlibrary(ggdensity)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_hdr() +\n  geom_point() +\n  theme_classic() +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  )\n\n\n\n\n\n\n图 8.10: ggdensity 包绘制二维填充密度图\n\n\n\n\n\n8.1.5 岭线图\n叠嶂图，还有些其它名字，如峰峦图、岭线图等，详情参考统计之都主站《叠嶂图的前世今生》，主要用来描述数据的分布情况，在展示分布的对比上效果非常好。\n图 8.11 设置窗宽为 1.5 个百分点\n\n\n\n\n\n\n\n\n\n(a) 岭线图\n\n\n\n\n\n\n\n\n\n(b) 岭线图和抖动图组合\n\n\n\n\n\n\n\n\n\n\n\n(c) 岭线图和轴须图组合\n\n\n\n\n\n\n图 8.11: 描述数据分布\n\n\n\n\n\n\n\n\n提示\n\n\n\n除了中国国家统计年鉴，各省、自治区、直辖市及各级统计局每年都会发布一些统计年鉴、公告等数据，读者可以在此基础上继续收集更多数据，来分析诸多有意思的问题：\n\n城市、镇和乡村男女性别比呈现差异化分布的成因。\n城市、镇和乡村男女年龄构成。\n将上述问题从省级下钻到市、县级来分析。\n\n\n\n\n8.1.6 抖动图\n下面先用函数 geom_point() 绘制散点图展示原始数据，通过点的疏密程度暗示数据的分布。Base R 函数 stripchart() 可以实现类似的效果。当数据量比较大时，点相互覆盖比较严重，此时，抖动图比较适合用来展示原始数据。\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_point() +\n  theme_classic()\n\nstripchart(\n  `性别比（女=100）` ~ `区域`, vertical = TRUE, pch = 1,\n  data = province_sex_ratio, xlab = \"区域\"\n)\n\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_jitter(width = 0.25) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_point()\n\n\n\n\n\n\n\n\n\n(b) 函数 stripchart()\n\n\n\n\n\n\n\n\n\n\n\n(c) 函数 geom_jitter()\n\n\n\n\n\n\n图 8.12: 散点图\n\n\nSidiropoulos 等 (2018) 提出一种新的方式描述数据的分布，集合抖动图和小提琴图的功能，在给定的分布界限内抖动。数据点受 violin 的曲线限制，蜂群图也是某种形式的抖动图，添加 violin 作为参考边界，与 sina 图是非常类似的。\nlibrary(ggforce)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_sina() +\n  theme_classic()\n\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin() +\n  geom_sina() +\n  theme_classic()\n\nlibrary(ggbeeswarm)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_quasirandom() +\n  theme_classic()\n\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin() +\n  geom_quasirandom() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) ggforce 包的函数 geom_sina()\n\n\n\n\n\n\n\n\n\n(b) 函数 geom_sina() 叠加函数 geom_violin()\n\n\n\n\n\n\n\n\n\n\n\n(c) ggbeeswarm 包的函数 geom_quasirandom()\n\n\n\n\n\n\n\n\n\n(d) 函数 geom_quasirandom() 叠加函数 geom_violin()\n\n\n\n\n\n\n图 8.13: 加强版的抖动图\n\n\n函数 geom_beeswarm() 提供了另一种散点的组织方式，按一定的规则，而不是近似随机的方式组织\n\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin() +\n  geom_beeswarm() +\n  theme_classic()",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html#sec-visualize-data-relation",
    "href": "visualization-advanced.html#sec-visualize-data-relation",
    "title": "8  统计图形",
    "section": "\n8.2 描述关系",
    "text": "8.2 描述关系\n\n8.2.1 散点图\n散点图用以描述变量之间的关系，展示原始的数据，点的形态、大小、颜色等都可以随更多变量变化。\n中国国家统计局 2021 年发布的统计年鉴，2020 年 31 个省、直辖市、自治区的抚养比、文盲率、人口数的关系。\n\n\n\n表格 8.2: 2020 年各省、直辖市、自治区，总抚养比和文盲率相关数据（部分）\n\n\n\n\n地区\n人口数\n15-64岁\n抚养比\n15岁及以上人口\n文盲人口\n文盲率\n\n\n\n广东\n126012510\n91449628\n37.79\n102262628\n1826344\n1.79\n\n\n山东\n101527453\n67100737\n51.31\n62464815\n3308280\n4.01\n\n\n河南\n99365519\n62974661\n57.79\n76376565\n2228594\n2.92\n\n\n江苏\n84748016\n58129537\n45.79\n71856068\n2211291\n3.08\n\n\n四川\n83674866\n56036154\n49.32\n70203754\n3330733\n4.74\n\n\n河北\n74610235\n49133330\n51.85\n59521267\n1128423\n1.90\n\n\n\n\n\n\n\n\n其中，文盲人口是指15岁及以上不识字及识字很少人口，文盲率 = 文盲人口 / 15岁及以上人口，抚养比 = (0-14岁 + 65岁及以上) / 15-64岁人口数。\n\nlibrary(ggplot2)\nggplot(data = china_raise_illiteracy) +\n  geom_point(aes(x = `总抚养比`, y = `文盲人口占15岁及以上人口的比重`)) +\n  theme_classic() +\n  labs(x = \"抚养比（%）\", y = \"文盲率（%）\")\n\n\n\n\n\n\n图 8.14: 文盲率与抚养比的关系\n\n\n\n\n\n8.2.2 气泡图\n气泡图在散点图的基础上，添加了散点大小的视觉维度，可以在图上多展示一列数据，下 图 8.15 新增了人口数变量。此外，在气泡旁边添加地区名称，将气泡填充的颜色也映射给了人口数变量。\n\nlibrary(ggrepel)\nlibrary(scales)\nggplot(\n  data = china_raise_illiteracy,\n  aes(x = `总抚养比`, y = `文盲人口占15岁及以上人口的比重`)\n) +\n  geom_point(aes(size = `人口数`, color = `人口数`),\n    alpha = 0.85, pch = 16,\n    show.legend = c(color = FALSE, size = TRUE)\n  ) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  scale_color_viridis_c(option = \"C\") +\n  geom_text_repel(\n    aes(label = `地区`), size = 3, max.overlaps = 50,\n    segment.colour = \"gray\", seed = 2022, show.legend = FALSE\n  ) +\n  coord_cartesian(xlim = c(30, 60), ylim = c(0, 10.5), expand = FALSE) +\n  theme_classic() +\n  labs(x = \"抚养比（%）\", y = \"文盲率（%）\")\n\n\n\n\n\n\n图 8.15: 文盲率和抚养比数据\n\n\n\n\n\n8.2.3 凹凸图\n凹凸图描述位置排序关系随时间的变化，比如前年、去年和今年各省的 GDP 排序变化，春节各旅游景点的人流量变化。ggbump 包专门用来绘制凹凸图，如 图 8.16 所示，展示\n\nlibrary(ggbump)\n# 位置排序变化\ndf &lt;- data.frame(\n  country = c(\n    \"印度\", \"印度\", \"印度\", \"瑞典\",\n    \"瑞典\", \"瑞典\", \"德国\", \"德国\",\n    \"德国\", \"芬兰\", \"芬兰\", \"芬兰\"\n  ),\n  year = c(\n    2018, 2019, 2020, 2018, 2019, 2020,\n    2018, 2019, 2020, 2018, 2019, 2020\n  ),\n  value = c(\n    492, 246, 246, 369, 123, 492,\n    246, 369, 123, 123, 492, 369\n  )\n)\n\nlibrary(data.table)\ndf &lt;- as.data.table(df)\ndf[, rank := rank(value, ties.method = \"random\"), by = \"year\"]\n\nggplot(df, aes(year, rank, color = country)) +\n  geom_point(size = 7) +\n  geom_text(data = df[df$year == min(df$year), ],\n            aes(x = year - .1, label = country), size = 5, hjust = 1) +\n  geom_text(data = df[df$year == max(df$year), ],\n            aes(x = year + .1, label = country), size = 5, hjust = 0) +\n  geom_bump(linewidth = 2, smooth = 8) +\n  scale_x_continuous(limits = c(2017.6, 2020.4), breaks = seq(2018, 2020, 1)) +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\",\n        panel.grid.major = element_blank()) +\n  labs(x = NULL, y = \"排名\") +\n  scale_y_reverse() +\n  coord_fixed(ratio = 0.5)\n\n\n\n\n\n\n图 8.16: 凹凸图\n\n\n\n\n\n8.2.4 韦恩图\n韦恩图描述集合、群体的交叉关系，整体和部分的包含关系，ggVennDiagram 包展示 A、B、C 三个集合的交叉关系，如 图 8.17 所示\n\nx &lt;- list(A = 1:5, B = 2:7, C = 5:10)\nggVennDiagram::ggVennDiagram(x) +\n  scale_fill_gradient(low = \"#F4FAFE\", high = \"#4981BF\")\n\n\n\n\n\n\n图 8.17: A、B、C 三个集合的交叉关系\n\n\n\n\n\n8.2.5 网络图\ntidygraph 包基于 igraph 包操作图数据，计算网络图中节点重要性，ggraph包基于 ggplot2 包可视化网络关系。\n\nlibrary(ggraph)\ndata(\"highschool\")\nstr(highschool)\n\n#&gt; 'data.frame':    506 obs. of  3 variables:\n#&gt;  $ from: num  1 1 1 1 1 2 2 3 3 4 ...\n#&gt;  $ to  : num  14 15 21 54 55 21 22 9 15 5 ...\n#&gt;  $ year: num  1957 1957 1957 1957 1957 ...\n\n\nhighschool 是一个数据框类型的数据，记录了1957 年和 1958 年一些高中男生之间的关系，在数据集中，这些男生被编码成数字 1-71。\n\nhighschool[highschool$from == 1, ]\n\n#&gt;     from to year\n#&gt; 1      1 14 1957\n#&gt; 2      1 15 1957\n#&gt; 3      1 21 1957\n#&gt; 4      1 54 1957\n#&gt; 5      1 55 1957\n#&gt; 244    1 15 1958\n#&gt; 245    1 21 1958\n#&gt; 246    1 22 1958\n\n\n1 号男生在 1957 年与 14、15、21、54、55 男生关系密切，到了 1958 年，他与 15、21、22 关系比较密切。tidygraph 包在 igraph 的基础上，可以对图数据进行操作，下面先将数据框转化为图，然后计算中心度，作为高中生的受欢迎程度。\n\ngraph &lt;- tidygraph::as_tbl_graph(highschool, directed = TRUE) |&gt; \n  dplyr::mutate(Popularity = tidygraph::centrality_degree(mode = 'in'))\ngraph\n\n#&gt; # A tbl_graph: 70 nodes and 506 edges\n#&gt; #\n#&gt; # A directed multigraph with 1 component\n#&gt; #\n#&gt; # Node Data: 70 × 1 (active)\n#&gt;    Popularity\n#&gt;         &lt;dbl&gt;\n#&gt;  1          2\n#&gt;  2          0\n#&gt;  3          0\n#&gt;  4          4\n#&gt;  5          5\n#&gt;  6          2\n#&gt;  7          2\n#&gt;  8          3\n#&gt;  9          4\n#&gt; 10          4\n#&gt; # ℹ 60 more rows\n#&gt; #\n#&gt; # Edge Data: 506 × 3\n#&gt;    from    to  year\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     1    13  1957\n#&gt; 2     1    14  1957\n#&gt; 3     1    20  1957\n#&gt; # ℹ 503 more rows\n\n\n\nggraph(graph, layout = \"kk\") +\n  geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) +\n  geom_node_point(aes(size = Popularity)) +\n  facet_edges(~year) +\n  theme_graph(base_family = \"sans\", foreground = \"steelblue\", fg_text_colour = \"white\")\n\n\n\n\n\n\n图 8.18: 高中男生间关系的变化",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html#sec-visualize-data-uncertainty",
    "href": "visualization-advanced.html#sec-visualize-data-uncertainty",
    "title": "8  统计图形",
    "section": "\n8.3 描述不确定性",
    "text": "8.3 描述不确定性\n统计是一门研究不确定性的学科，由不确定性引出许多的基本概念，比如用置信区间描述点估计的不确定性，用覆盖概率描述区间估计方法的优劣。下面以二项分布参数的点估计与区间估计为例，通过可视化图形介绍这一系列统计概念。就点估计来说，描述不确定性可以用标准差、置信区间。\nggdist 包可视化分布和不确定性 (Kay 2022)\n\nMichael Friendly 2021 年的课程 Psychology of Data Visualization\n\nClaus O. Wilke 2023 年的课程 SDS 375 Schedule Spring 2023\n\n\n\n8.3.1 置信区间\n\n\n表格 8.3: 二项分布的分布列\n\n\n\n0\n1\n2\n\\(\\cdots\\)\nn\n\n\n\\(p_0\\)\n\\(p_1\\)\n\\(p_2\\)\n\\(\\cdots\\)\n\\(p_n\\)\n\n\n\n\n\n二项分布 \\(\\mathrm{Binomial}(n,p)\\) 的参数 \\(p\\) 的精确区间估计如下：\n\\[\n\\big(\\mathrm{Beta}(\\frac{\\alpha}{2}; x, n-x+1), \\mathrm{Beta}(1-\\frac{\\alpha}{2}; x+1, n-x)\\big)\n\\tag{8.1}\\]\n其中， \\(x\\) 表示成功次数，\\(n\\) 表示实验次数，\\(\\mathrm{Beta}(p;v,w)\\) 表示形状参数为 \\(v\\) 和 \\(w\\) 的 Beta 贝塔分布的 \\(p\\) 分位数，参数 \\(p\\) 的置信区间的上下限 \\(P_L,P_U\\) 满足\n\\[\n\\begin{aligned}\n\\frac{\\Gamma(n+1)}{\\Gamma(x)\\Gamma(n-x+1)}\\int_{0}^{P_L}t^{x-1}(1-t)^{n-x}\\mathrm{dt} &= \\frac{\\alpha}{2} \\\\\n\\frac{\\Gamma(n+1)}{\\Gamma(x+1)\\Gamma(n-x)}\\int_{0}^{P_U}t^{x}(1-t)^{n-x-1}\\mathrm{dt} &= 1-\\frac{\\alpha}{2}\n\\end{aligned}\n\\]\n\\(p_x\\) 表示二项分布 \\(\\mathrm{Binomial}(n,p)\\) 第 \\(x\\) 项的概率，\\(x\\) 的取值为 \\(0,1,\\cdots,n\\)\n\\[p_x = \\binom{n}{x}p^x(1-p)^{n-x}, \\quad x = 0,1,\\cdots,n\\]\n二项分布的累积分布函数和 \\(S_k\\) 表示前 \\(k\\) 项概率之和\n\\[S_k = \\sum_{x=0}^{k} p_x\\]\n\\(S_k\\) 服从形状参数为 \\(n-k,k+1\\) 的贝塔分布 \\(I_x(a,b)\\)，对应于 R 函数 pbeta(x,a,b)。 \\(S_k\\) 看作贝塔分布的随机变量 \\(X\\)\n\\[\n\\begin{aligned}\nB_x(a,b) &=\\int_{0}^{x}t^{a-1}(1-t)^{b-1}\\mathrm{dt} \\\\\nI_x(a,b) &= \\frac{B_x(a,b)}{B(a,b)}, \\quad B(a,b) = B_1(a,b)\n\\end{aligned}\n\\]\n考虑二项总体的参数 \\(p=0.7\\)，重复模拟 50 次，每次模拟获得的比例 \\(\\hat{p}\\) 及其置信区间，如 图 8.19 所示，置信区间覆盖真值的情况用不同颜色表示，覆盖用 TRUE 表示，没有覆盖用 FALSE 表示\n\nlibrary(ggplot2)\n# Clopper and Pearson (1934)\n# 与 binom.test() 计算结果一致\nclopper_pearson &lt;- function(p = 0.1, n = 10, nsim = 100) {\n  set.seed(2022)\n  nd &lt;- rbinom(nsim, prob = p, size = n)\n  ll &lt;- qbeta(p = 0.05 / 2, shape1 = nd, shape2 = n - nd + 1)\n  ul &lt;- qbeta(p = 1 - 0.05 / 2, shape1 = nd + 1, shape2 = n - nd)\n  data.frame(nd = nd, ll = ll, ul = ul, cover = ul &gt; p & ll &lt; p)\n}\n# 二项分布的参数 p = 0.7\ndat &lt;- clopper_pearson(p = 0.7, n = 10, nsim = 50)\n# 二项分布的参数的置信区间覆盖真值的情况\nggplot(data = dat, aes(x = 1:50, y = nd / 10, colour = cover)) +\n  geom_hline(yintercept = 0.7, lty = 2, linewidth = 1.2, color = \"gray\") +\n  geom_pointrange(aes(ymin = ll, ymax = ul)) +\n  theme_classic() +\n  labs(x = \"第几次模拟\", y = \"置信区间上下限\", color = \"覆盖\")\n\n\n\n\n\n\n图 8.19: Clopper-Pearson 置信区间\n\n\n\n\n\n8.3.2 假设检验\n假设检验的目的是做决策，决策是有风险的，是可能发生错误的，为了控制犯第一类错误的可能性，我们用 P 值描述检验统计假设的不确定性，用功效描述检验方法的优劣。对同一个统计假设，同一组数据，不同的检验方法有不同的 P 值，本质是检验方法的功效不同。\nggpval 在图上添加检验的 P 值结果，ggsignif (Constantin 和 Patil 2021) 在图上添加显著性注释。ggstatsplot (Patil 2021) 可视化统计检验、模型的结果，描述功效变化。ggpubr 制作出版级统计图形，两样本均值的比较。\n\nwith(\n  aggregate(\n    data = PlantGrowth, weight ~ group,\n    FUN = function(x) c(dist_mean = mean(x), dist_sd = sd(x))\n  ),\n  cbind.data.frame(weight, group)\n) |&gt;\n  ggplot(aes(x = group, y = dist_mean)) +\n  geom_col(\n    position = position_dodge(0.4), width = 0.4, fill = \"gray\"\n  ) +\n  geom_errorbar(aes(\n    ymin = dist_mean - dist_sd,\n    ymax = dist_mean + dist_sd\n  ),\n  position = position_dodge(0.4), width = 0.2\n  ) +\n  theme_classic() +\n  labs(x = \"组别\", y = \"植物干重\")\n\n\n\n\n\n\n图 8.20: 植物生长\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\nR 3.5.0 以后，函数 aggregate() 的参数 drop 默认值为 TRUE， 表示扔掉未用来分组的变量，聚合返回的是一个矩阵类型的数据对象。\n\n\n单因素方差分析 oneway.test() 检验各组的方差是否相等。\n\noneway.test(data = PlantGrowth, weight ~ group)\n\n#&gt; \n#&gt;  One-way analysis of means (not assuming equal variances)\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 5.181, num df = 2.000, denom df = 17.128, p-value = 0.01739\n\n\n结果显示方差不全部相等，因此，采用函数 t.test(var.equal = FALSE) 来检验数据。图 8.21 展示假设检验的结果，分别标记了 ctrl 与 trt1、trt1 与 trt2 两组 t 检验的结果。\n\nlibrary(ggsignif)\nggplot(data = PlantGrowth, aes(x = group, y = weight)) +\n  geom_boxplot(width = 0.25) +\n  geom_jitter(width = 0.15) +\n  geom_signif(comparisons = list(c(\"ctrl\", \"trt1\"), c(\"trt1\", \"trt2\")), \n              map_signif_level = function(p) sprintf(\"p = %.2g\", p), \n              textsize = 6, test = \"t.test\") +\n  theme_classic() +\n  coord_cartesian(clip = \"off\")\n\n\n\n\n\n\n图 8.21: 展示假设检验的结果\n\n\n\n\n为了了解其中的原理，下面分别使用函数 t.test() 检验数据，结果给出的 P 值与上 图 8.21 完全一样。\n\nt.test(data = PlantGrowth, weight ~ group, subset = group %in% c(\"ctrl\", \"trt1\"))\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  weight by group\n#&gt; t = 1.1913, df = 16.524, p-value = 0.2504\n#&gt; alternative hypothesis: true difference in means between group ctrl and group trt1 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.2875162  1.0295162\n#&gt; sample estimates:\n#&gt; mean in group ctrl mean in group trt1 \n#&gt;              5.032              4.661\n\nt.test(data = PlantGrowth, weight ~ group, subset = group %in% c(\"trt1\", \"trt2\"))\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  weight by group\n#&gt; t = -3.0101, df = 14.104, p-value = 0.009298\n#&gt; alternative hypothesis: true difference in means between group trt1 and group trt2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -1.4809144 -0.2490856\n#&gt; sample estimates:\n#&gt; mean in group trt1 mean in group trt2 \n#&gt;              4.661              5.526\n\n\n\n8.3.3 模型预测\n描述模型预测的不确定性，预测的方差、预测区间。线性回归来说，回归线及置信带。代码提交量的趋势拟合\n\nsvn_trunk_log &lt;- readRDS(file = \"data/svn-trunk-log-2022.rds\")\nsvn_trunk_log$year &lt;- as.integer(format(svn_trunk_log$stamp, \"%Y\"))\ntrunk_year &lt;- aggregate(data = svn_trunk_log, revision ~ year, FUN = length)\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(aes(color = \"LOESS\", fill = \"LOESS\"),\n    method = \"loess\", formula = \"y~x\",\n    method.args = list(\n      span = 0.75, degree = 2, family = \"symmetric\",\n      control = loess.control(surface = \"direct\", iterations = 4)\n    ), data = subset(trunk_year, year != c(1997, 2022))\n  ) +\n  geom_smooth(aes(color = \"GAM\", fill = \"GAM\"),\n    formula = y ~ s(x, k = 12), method = \"gam\", se = TRUE,\n    data = subset(trunk_year, year != c(1997, 2022))\n  ) +\n  geom_smooth(aes(color = \"Cubic Spline\", fill = \"Cubic Spline\"),\n                method = \"lm\", formula = y ~ splines::bs(x, 3), se = T,\n              data = subset(trunk_year, year != c(1997, 2022))) +\n  scale_color_brewer(name = \"模型\", palette = \"Set1\") +\n  scale_fill_brewer(name = \"模型\", palette = \"Set1\") +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 8.22: 趋势拟合、预测和推断\n\n\n\n\n\n8.3.4 模型诊断\n\n所有模型都是错误的，但有些是有用的。\n— 乔治·博克斯\n\n描述模型的敏感性，数据中存在的离群值，变量之间的多重共线性等。引入 Cook 距离、杠杆值、VIF 等来诊断模型。\n\n# 准备数据\nstate_x77 &lt;- data.frame(state.x77,\n  state_name = rownames(state.x77),\n  state_region = state.region,\n  state_abb = state.abb,\n  check.names = FALSE\n)\n# 线性模型拟合\nfit &lt;- lm(`Life Exp` ~ Income + Murder, data = state_x77)\n# 模型诊断图\nlibrary(ggfortify)\nautoplot(fit, which = 1:6, label.size = 3)\n\n\n\n\n\n\n图 8.23: 线性模型的诊断图\n\n\n\n\n对于复杂的统计模型，比如混合效应模型的诊断，ggPMX 包。\n\n8.3.5 边际效应\n继续 state_x77 数据集，以预期寿命（1969-1971 年统计）为因变量，Income 人均收入（1974 年）和 Murder 谋杀和非过失杀人率（单位：十万分之一，1976 年统计）为自变量，建立线性模型如下：\n\\[\n\\text{Life Exp} = \\alpha + \\beta_1  \\text{Income} + \\beta_2 \\text{Murder} + \\epsilon\n\\tag{8.2}\\]\n在 R 语言中，可以用函数 lm() 拟合上述模型，\n\nfit &lt;- lm(`Life Exp` ~ Income + Murder, data = state_x77)\n\n模型拟合结果输出如下：\n\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = `Life Exp` ~ Income + Murder, data = state_x77)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.48301 -0.62099 -0.01714  0.47768  2.20831 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 71.2255815  0.9673952  73.626  &lt; 2e-16 ***\n#&gt; Income       0.0003705  0.0001973   1.878   0.0666 .  \n#&gt; Murder      -0.2697594  0.0328408  -8.214 1.22e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.8259 on 47 degrees of freedom\n#&gt; Multiple R-squared:  0.637,  Adjusted R-squared:  0.6215 \n#&gt; F-statistic: 41.23 on 2 and 47 DF,  p-value: 4.561e-11\n\n\nggeffects 描述单个自变量的作用，人均收入对预期寿命的边际效应\n\nlibrary(ggeffects)\nincome_pred &lt;- ggpredict(fit, terms = \"Income\")\nggplot(income_pred, aes(x, predicted)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.1) +\n  theme_classic() +\n  labs(x = \"人均收入\", y = \"预期寿命\")\n\n\n\n\n\n\n图 8.24: 边际效应\n\n\n\n\n\n\n\n\nAttali, Dean, 和 Christopher Baker. 2022. ggExtra: Add Marginal Histograms to ggplot2, and More ggplot2 Enhancements. https://CRAN.R-project.org/package=ggExtra.\n\n\nConstantin, Ahlmann-Eltze, 和 Indrajeet Patil. 2021. 《ggsignif: R Package for Displaying Significance Brackets for ggplot2》. PsyArxiv. https://doi.org/10.31234/osf.io/7awm6.\n\n\nKay, Matthew. 2022. ggdist: Visualizations of Distributions and Uncertainty. https://doi.org/10.5281/zenodo.3879620.\n\n\nMcGill, Tukey, R., 和 W. A. Larsen. 1978. 《Variations of box plots》. The American Statistician 32 (1): 12–16. https://www.jstor.org/stable/2683468.\n\n\nOtto, James, 和 David Kahle. 2023. 《ggdensity: Improved Bivariate Density Visualization in R》. The R Journal 15: 220–36. https://doi.org/10.32614/RJ-2023-048.\n\n\nPatil, Indrajeet. 2021. 《Visualizations with statistical details: The ggstatsplot approach》. Journal of Open Source Software 6 (61): 3167. https://doi.org/10.21105/joss.03167.\n\n\nSidiropoulos, Nikos, Sina Hadi Sohi, Thomas Lin Pedersen, Bo Torben Porse, Ole Winther, Nicolas Rapin, 和 Frederik Otzen Bagger. 2018. 《SinaPlot: An Enhanced Chart for Simple and Truthful Representation of Single Observations Over Multiple Classes》. Journal of Computational and Graphical Statistics 27 (3): 673–76. https://doi.org/10.1080/10618600.2017.1366914.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html",
    "href": "visualization-lattice.html",
    "title": "9  lattice 入门",
    "section": "",
    "text": "9.1 分组散点图\n函数 xyplot() 在 lattice 包中非常具有代表性，掌握此函数的作图规律，其它函数学起来也就不难了。分组散点图是一个非常常见的、用来描述变量之间关系的图形，下面就以绘制一个分组散点图来介绍函数 xyplot() 的用法。\nlibrary(lattice)\nxyplot(\n  x = Sepal.Length ~ Petal.Length, groups = Species, scales = \"free\",\n  data = iris, grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\",\n  auto.key = list(space = \"top\", columns = 3)\n)\n\n\n\n\n\n\n图 9.1: 分组散点图\n除了通过 space 参数设置图例的位置，还可以通过坐标设置图例的位置，比如下 图 9.2 (b) 中设置图例的位置坐标为 x = 1, y = 0 使得图例位于图的右下角。图例坐标的参考点是原点 x = 0, y = 0 就是左下角的位置，而右上角的位置为 x = 1, y = 1 。\n除了上面介绍的几个参数，还有许多其它参数，其中一部分会在后续介绍其它种类的图形时顺带介绍，剩余的部分请感兴趣的读者查看函数 xyplot() 的帮助文档。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-lattice-xyplot",
    "href": "visualization-lattice.html#sec-lattice-xyplot",
    "title": "9  lattice 入门",
    "section": "",
    "text": "参数 x 需要传递 R 语言中的表达式，这是一种被广泛使用的公式语法，示例中为 Sepal.Length ~ Petal.Length ，表示横坐标为 Petal.Length， 纵坐标为 Sepal.Length 。\n参数 groups 指定分组变量，此处为 Species 变量，表示鸢尾花种类。\n参数 scales 设置坐标轴刻度， scales = \"free\" 表示去掉边框上面和右面的刻度线。\n参数 data 指定绘图数据，此处为 iris 数据集。\n参数 grid 控制是否添加背景网格线，此处为 TRUE 表示添加背景网格线。\n参数 xlab 和参数 ylab 分别指定横、纵坐标轴标签。\n参数 auto.key 设置图例，示例中设置 space = \"top\" 将图例置于图形上方，设置 columns = 3 使条目排成 3 列，此外，设置 reverse.rows = TRUE 还可以使图例中的条目顺序反向。\n\n\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(space = \"right\", columns = 1)\n)\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(corner = c(1, 0))\n)\n\n\n\n\n\n\n\n\n\n(a) 图例位于图右侧\n\n\n\n\n\n\n\n\n\n\n\n(b) 图例位于内内部\n\n\n\n\n\n\n图 9.2: 调整图例位置",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-lattice-par",
    "href": "visualization-lattice.html#sec-lattice-par",
    "title": "9  lattice 入门",
    "section": "\n9.2 图形参数",
    "text": "9.2 图形参数\n类似 Base R 绘图系统中的图形参数设置函数 par()和 ggplot2 包中的主题设置函数 theme()， lattice 包也有图形参数设置函数 trellis.par.set() ，而图形参数查询函数为 trellis.par.get() 。可设置的图形参数非常多，仅常用的也不少。首先来看看有哪些图形参数可以设置。\n\ntp &lt;- trellis.par.get()\nnames(tp)\n\n#&gt;  [1] \"grid.pars\"         \"fontsize\"          \"background\"       \n#&gt;  [4] \"panel.background\"  \"clip\"              \"add.line\"         \n#&gt;  [7] \"add.text\"          \"plot.polygon\"      \"box.dot\"          \n#&gt; [10] \"box.rectangle\"     \"box.umbrella\"      \"dot.line\"         \n#&gt; [13] \"dot.symbol\"        \"plot.line\"         \"plot.symbol\"      \n#&gt; [16] \"reference.line\"    \"strip.background\"  \"strip.shingle\"    \n#&gt; [19] \"strip.border\"      \"superpose.line\"    \"superpose.symbol\" \n#&gt; [22] \"superpose.polygon\" \"regions\"           \"shade.colors\"     \n#&gt; [25] \"axis.line\"         \"axis.text\"         \"axis.components\"  \n#&gt; [28] \"layout.heights\"    \"layout.widths\"     \"box.3d\"           \n#&gt; [31] \"par.title.text\"    \"par.xlab.text\"     \"par.ylab.text\"    \n#&gt; [34] \"par.zlab.text\"     \"par.main.text\"     \"par.sub.text\"\n\n\n可以看到，图形参数着实非常多，知道了这么多图形参数，而每个参数又有哪些选项可取呢？不忙，再看看图形参数的结构，比如 superpose.symbol 。\n\ntp$superpose.symbol\n\n#&gt; $alpha\n#&gt; [1] 1 1 1 1 1 1 1\n#&gt; \n#&gt; $cex\n#&gt; [1] 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n#&gt; \n#&gt; $col\n#&gt;          blue        orange   bluishgreen    vermillion       skyblue \n#&gt;     \"#0072B2\"     \"#E69F00\"     \"#009E73\"     \"#D55E00\"     \"#56B4E9\" \n#&gt;        yellow reddishpurple \n#&gt;     \"#F0E442\"     \"#CC79A7\" \n#&gt; \n#&gt; $fill\n#&gt; [1] \"#CCFFFF\" \"#FFCCFF\" \"#CCFFCC\" \"#FFE5CC\" \"#CCE6FF\" \"#FFFFCC\" \"#FFCCCC\"\n#&gt; \n#&gt; $font\n#&gt; [1] 1 1 1 1 1 1 1\n#&gt; \n#&gt; $pch\n#&gt; [1] 1 1 1 1 1 1 1\n\n\n这是一个列表，有 6 个元素，每个元素设置符号的不同属性，依次是透明度 alpha、大小 cex、颜色 col、填充色 fill、字型 font 和类型 pch ，这些属性的含义与函数 par() 是一致的。下 图 9.3 展示所有的常用图形参数及其可设置的选项。\n\n\n\n\n\n\n\n图 9.3: 常用图形参数\n\n\n\n\n现在，知道了图形设置参数及其结构，还需要知道它们究竟在绘图时起什么作用，也就是说它们控制图形中的哪部分元素及效果。下 图 9.4 展示 lattice 包图形参数效果。由图可知，图形参数 superpose.symbol 是控制散点图中的点，点可以是普通的点，也可以是任意的字母符号。\n\n\n\n\n\n\n\n图 9.4: 图形参数效果预览\n\n\n\n\n在之前的 图 9.1 的基础上，设置 type = c(\"p\", \"r\") 添加回归线。通过图形参数 par.settings 设置各类绘图元素的符号类型和大小，该参数接受一个列表类型的数据，列表的元素还是列表，列表的层层嵌套实现图中元素的精细控制。列表元素 superpose.symbol 控制点的符号，pch = 16 设置为 16，相比于默认的点要大一号。列表元素 superpose.line 控制线，lwd = 2 设置宽度为 2，比默认的宽度大一倍，lty = 3 设置线的类型为 3，表示虚线。通过参数 auto.key 设置图例位置，图例位于图形上方，图例中的条目排成3列。\n\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, type = c(\"p\", \"r\"),\n  xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(columns = 3, space = \"top\"), \n  par.settings = list(\n    superpose.symbol = list(pch = 16),\n    superpose.line = list(lwd = 2, lty = 3)\n  )\n)\n\n\n\n\n\n\n图 9.5: 调整点、线、图例元素\n\n\n\n\nlatticeExtra 包有两个函数专门用来设置图形风格，分别是 theEconomist.theme() 和 ggplot2like() ，这两个主题函数提供一系列预设的图形参数，前者来自《经济学人》杂志的图形主题，后者来自 ggplot2 包的默认绘图主题。\nlibrary(latticeExtra)\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(space = \"top\", columns = 3), \n  par.settings = ggplot2like()\n)\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(space = \"top\", columns = 3), \n  par.settings = theEconomist.theme(with.bg = TRUE, box = \"transparent\")\n)\n\n\n\n\n\n\n\n\n\n(a) ggplot2 包默认的绘图主题\n\n\n\n\n\n\n\n\n\n\n\n(b) 《经济学人》杂志的绘图主题\n\n\n\n\n\n\n图 9.6: latticeExtra 内置的两个主题",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-common-lattice",
    "href": "visualization-lattice.html#sec-common-lattice",
    "title": "9  lattice 入门",
    "section": "\n9.3 常见图形",
    "text": "9.3 常见图形\n\n9.3.1 分组柱形图\n本节所用数据集 Insurance 来自 MASS 包，记录一家保险公司面临风险的投保人数量，以及在 1973 年第 3 季度他们提出汽车理赔的数量。数据类型、各个变量的类型及部分预览数据如下：\n\ndata(Insurance, package = \"MASS\")\nstr(Insurance)\n\n#&gt; 'data.frame':    64 obs. of  5 variables:\n#&gt;  $ District: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ Group   : Ord.factor w/ 4 levels \"&lt;1l\"&lt;\"1-1.5l\"&lt;..: 1 1 1 1 2 2 2 2 3 3 ...\n#&gt;  $ Age     : Ord.factor w/ 4 levels \"&lt;25\"&lt;\"25-29\"&lt;..: 1 2 3 4 1 2 3 4 1 2 ...\n#&gt;  $ Holders : int  197 264 246 1680 284 536 696 3582 133 286 ...\n#&gt;  $ Claims  : int  38 35 20 156 63 84 89 400 19 52 ...\n\n\n其中，District 表示投保人居住的地区，因子型变量。Group 汽车按油箱大小分组的变量，有序的因子型变量。Age 投保人的年龄段标签，有序的因子型变量。Holders 投保人数量，整型变量。Claims 理赔数量，整型变量。下 图 9.7 先按投保人的汽车类型分面，再按投保人所在地区分组，展示理赔频度与投保人年龄的关系。\n\nbarchart(\n  Claims / Holders ~ Age | Group, groups = District,\n  data = Insurance, xlab = \"年龄段\", ylab = \"理赔频度\",\n  auto.key = list(space = \"top\", columns = 4, title = \"地区\", cex.title = 1)\n)\n\n\n\n\n\n\n图 9.7: 分组柱形图\n\n\n\n\n函数 barchart() 中的公式 Claims / Holders ~ Age | Group ，斜杠 / 表示除法，波浪线 ~ 表示响应变量与自变量的分界，竖线 | 表示分面。\n\n9.3.2 分组箱线图\n\nbwplot(Petal.Length ~ Species, data = iris, scales = \"free\",\n  xlab = \"鸢尾花种类\", ylab = \"花瓣长度\")\n\n\n\n\n\n\n图 9.8: 分组箱线图\n\n\n\n\n\n9.3.3 经验分布图\n用阶梯图表示累积经验分布图，纵轴表示累积概率，不同种类的鸢尾花，花瓣长度的分布明显不同。根据 Glivenko–Cantelli 定理，经验分布函数以概率 1 收敛至累积分布函数。\n\nlibrary(latticeExtra)\necdfplot(~ Petal.Length | Species, data = iris, scales = \"free\", \n         xlab = \"花瓣长度\", ylab = \"累积概率\")\n\n\n\n\n\n\n图 9.9: 经验分布图\n\n\n\n\n\n9.3.4 回归曲线图\n\n\nsplines 自然立方样条 ns()\n\n\nmgcv 广义可加模型 s()\n\n\n\n\n\n\n\n\n\n图 9.10: 调色板\n\n\n\n\n图 9.11 中用不同的回归模型拟合数据中的趋势。1920s 汽车行驶距离和速度的关系图。函数 panel.smoother() 来自 latticeExtra 包\nlibrary(splines)\nlibrary(nlme)\nlibrary(mgcv)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ x,\n      col.line = \"#EA4335\", method = \"lm\", ...\n    )\n  }\n)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ x,\n      col.line = \"#4285f4\", method = \"loess\", span = 0.9, ...\n    )\n  }\n)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ ns(x, 5),\n      col.line = \"#34A853\", method = \"lm\", ...\n    )\n  }\n)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ s(x),\n      col.line = \"#FBBC05\", method = \"gam\", ...\n    )\n  }\n)\n\n\n\n\n\n\n\n\n\n(a) 线性回归\n\n\n\n\n\n\n\n\n\n(b) 局部多项式回归\n\n\n\n\n\n\n\n\n\n\n\n(c) 自然样条回归\n\n\n\n\n\n\n\n\n\n(d) 广义可加回归\n\n\n\n\n\n\n图 9.11: 回归曲线图\n\n\n\n9.3.5 置信区间图\n各个郡县每 10 万人当中因癌症死亡的人数。USCancerRates 数据集来自 latticeExtra 包，记录各个郡县的癌症死亡率及其置信区间，下图展示新泽西州各个郡县的癌症死亡率及其置信区间。\n\nsegplot(reorder(county, rate.male) ~ LCL95.male + UCL95.male,\n  data = subset(USCancerRates, state == \"New Jersey\"),\n  draw.bands = FALSE, centers = rate.male,\n  scales = list(x = list(alternating = 1, tck = c(1, 0))),\n  xlab = \"癌症死亡率\", ylab = \"郡县\"\n)\n\n\n\n\n\n\n图 9.12: 置信区间图\n\n\n\n\n\n9.3.6 置信椭圆图\nlatticeExtra 包的函数 panel.ellipse() 可以绘制置信椭圆。二维数据，置信水平为 0.95 时，置信椭圆。\n\nxyplot(Sepal.Length ~ Petal.Length,\n  groups = Species, data = iris, scales = \"free\",\n  xlab = \"萼片长度\", ylab = \"花瓣长度\",\n  par.settings = list(\n    superpose.symbol = list(pch = 16),\n    superpose.line = list(lwd = 2, lty = 3)\n  ),\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.ellipse(x, y, level = 0.85, ...)\n  },\n  auto.key = list(space = \"top\", columns = 3)\n)\n\n\n\n\n\n\n图 9.13: 分组置信椭圆图\n\n\n\n\n\n9.3.7 切片水平图\n按照深度降序排列，根据震级 mag 划分 4 个区间，每个区间内数据点的数量比较平衡，相邻区间之间有重叠部分。对数据进行切片，观察连续的切片数据，增加一个维度。\n对震深排序的目的是让数据点按照一定的顺序绘制在图上，数据点相距较近容易互相覆盖。使得在二维平面上，通过对数据点的染色，也能体现地震深度在空间中的层次变化。\n不同的震级下，地震深度在空间中的变化是一致的。\n\n# 震级区间\nquakes$Magnitude &lt;- equal.count(quakes$mag, number = 4)\n# 震深\ndepth.ord &lt;- rev(order(quakes$depth))\nquakes.ordered &lt;- quakes[depth.ord, ]\n\nIntervals:\n   min  max count\n1 3.95 4.55   484\n2 4.25 4.75   492\n3 4.45 4.95   425\n4 4.65 6.45   415\n\nOverlap between adjacent intervals:\n[1] 293 306 217\n函数 equal.count() 内部调用函数 co.intervals() ，还有两个参数 number 和 overlap。如果要没有重叠的话，得设置 overlap = 0 。\n\nquakes$Magnitude &lt;- equal.count(quakes$mag, number = 4, overlap = 0)\n\n\nlevelplot(depth ~ long + lat | Magnitude,\n  data = quakes.ordered, scales = \"free\",\n  panel = panel.levelplot.points, \n  prepanel = prepanel.default.xyplot, \n  type = c(\"p\", \"g\"), layout = c(2, 2)\n)\n\n\n\n\n\n\n图 9.14: 分面水平图\n\n\n\n\n\n9.3.8 三维散点图\nlattice 包的函数 cloud() 三维散点图\n\ncloud(Sepal.Length ~ Sepal.Width + Petal.Length,\n  groups = Species, data = iris,\n  # 去掉方向箭头\n  scales = list(arrows = FALSE, col = \"black\"),\n  xlab = list(\"萼片宽度\", rot = 30),\n  ylab = list(\"花瓣长度\", rot = -35),\n  zlab = list(\"萼片长度\", rot = 90),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(\n    # 点的类型\n    superpose.symbol = list(pch = 16),\n    # 去掉外框线\n    axis.line = list(col = \"transparent\")\n  )\n)\n\n\n\n\n\n\n图 9.15: 三维散点图\n\n\n\n\n下面是一个示例，自定义面板函数 panel.3d.cloud 。\n\n\n\n\n\n\n注释\n\n\n\n图底部的网格待改进，生成网格线的代码太死板。\n\n\n\n# 加载数据\nrongelap &lt;- readRDS(file = \"data/rongelap.rds\")\nrongelap_coastline &lt;- readRDS(file = \"data/rongelap_coastline.rds\")\n\nlibrary(lattice)\n# 参考 lattice 书籍的图 6.5 的绘图代码\npanel.3dcoastline &lt;- function(..., rot.mat, distance, xlim, ylim, zlim,\n                              xlim.scaled, ylim.scaled, zlim.scaled) {\n  scale.vals &lt;- function(x, original, scaled) {\n    scaled[1] + (x - original[1]) * diff(scaled) / diff(original)\n  }\n  scaled.map &lt;- rbind(\n    scale.vals(rongelap_coastline$cX, xlim, xlim.scaled),\n    scale.vals(rongelap_coastline$cY, ylim, ylim.scaled),\n    zlim.scaled[1]\n  )\n  m &lt;- ltransform3dto3d(scaled.map, rot.mat, distance)\n  panel.lines(m[1, ], m[2, ], col = \"black\")\n}\n\nrongelap_grid_line &lt;- rbind.data.frame(\n  data.frame(x = 1000 * -6:0, y = -3500),\n  data.frame(x = 1000 * 0:-6, y = -3000),\n  data.frame(x = 1000 * -6:0, y = -2500),\n  data.frame(x = 1000 * 0:-6, y = -2000),\n  data.frame(x = 1000 * -6:0, y = -1500),\n  data.frame(x = 1000 * 0:-6, y = -1000),\n  data.frame(x = 1000 * -6:0, y = -500),\n  data.frame(x = 1000 * 0:-6, y = 0),\n  data.frame(x = -6000, y = -500 * 7:0),\n  data.frame(x = -5000, y = -500 * 0:7),\n  data.frame(x = -4000, y = -500 * 7:0),\n  data.frame(x = -3000, y = -500 * 0:7),\n  data.frame(x = -2000, y = -500 * 7:0),\n  data.frame(x = -1000, y = -500 * 0:7),\n  data.frame(x = 0, y = -500 * 7:0)\n)\n\npanel.3dgridline &lt;- function(..., rot.mat, distance, xlim, ylim, zlim,\n                              xlim.scaled, ylim.scaled, zlim.scaled) {\n  scale.vals &lt;- function(x, original, scaled) {\n    scaled[1] + (x - original[1]) * diff(scaled) / diff(original)\n  }\n  scaled.map &lt;- rbind(\n    scale.vals(rongelap_grid_line$x, xlim, xlim.scaled),\n    scale.vals(rongelap_grid_line$y, ylim, ylim.scaled),\n    zlim.scaled[1]\n  )\n  m &lt;- ltransform3dto3d(scaled.map, rot.mat, distance)\n  panel.lines(x = m[1,], y = m[2,], col = \"gray\", lty = 2)\n}\n\ncloud(counts / time ~ cX * cY,\n  data = rongelap, col = \"black\",\n  xlim = c(-6500, 100), ylim = c(-3800, 150),\n  scales = list(arrows = FALSE, col = \"black\"),\n  aspect = c(0.75, 0.5),\n  xlab = list(\"横坐标（米）\", rot = 20),\n  ylab = list(\"纵坐标（米）\", rot = -50),\n  zlab = list(\"辐射强度\", rot = 90),\n  type = c(\"p\", \"h\"), pch = 16, lwd = 0.5,\n  panel.3d.cloud = function(...) {\n    panel.3dgridline(...)\n    panel.3dcoastline(...) # 海岸线\n    panel.3dscatter(...)\n  },\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(\n    # 移除几条内框线\n    # box.3d = list(col = c(1, 1, NA, NA, 1, NA, 1, 1, 1)),\n    # 刻度标签字体大小\n    axis.text = list(cex = 0.8),\n    # 去掉外框线\n    axis.line = list(col = \"transparent\")\n  ),\n  # 设置三维图的观察方位\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 9.16: 添加三维网格参考线和透视曲线\n\n\n\n\n\n9.3.9 三维透视图\n有如下参数方程\n\\[\n\\begin{aligned}\n\\left\\{\n\\begin{array}{l}\nx(u,v) = \\cos(u)\\big(r + \\cos(u / 2)\\big) \\\\\ny(u,v) = \\sin(u)\\big(r + \\cos(u / 2)\\sin(tv) - \\sin(u / 2)\\sin(2tv)\\big)\\sin(tv) -\n    \\sin(u / 2)\\sin(2tv) \\\\\nz(u,v) = \\sin(u / 2) \\sin(tv) + \\cos(u / 2) \\sin(tv)\n\\end{array} \\right.\n\\end{aligned}\n\\]\n其中，\\(u\\) 和 \\(v\\) 是参数，\\(\\frac{u}{2\\pi} \\in [0.3,1.25], \\frac{v}{2\\pi} \\in [0,1]\\)，\\(r\\) 和 \\(t\\) 是常量，不妨设 \\(r = 2\\) 和 \\(t=1\\) 。\n\n# lattice 书 6.3.1 节 参数\nkx &lt;- function(u, v) cos(u) * (r + cos(u / 2))\nky &lt;- function(u, v) {\n  sin(u) * (r + cos(u / 2) * sin(t * v) -\n    sin(u / 2) * sin(2 * t * v)) * sin(t * v) -\n    sin(u / 2) * sin(2 * t * v)\n}\nkz &lt;- function(u, v) sin(u / 2) * sin(t * v) + cos(u / 2) * sin(t * v)\nn &lt;- 50\nu &lt;- seq(0.3, 1.25, length = n) * 2 * pi\nv &lt;- seq(0, 1, length = n) * 2 * pi\num &lt;- matrix(u, length(u), length(u))\nvm &lt;- matrix(v, length(v), length(v), byrow = TRUE)\nr &lt;- 2\nt &lt;- 1\n\nwireframe(kz(um, vm) ~ kx(um, vm) + ky(um, vm),\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90), alpha = 0.75,\n  scales = list(arrows = FALSE, col = \"black\"),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 9.17: 三维透视图\n\n\n\n\n绘图函数 wireframe() 支持使用公式语法，也支持矩阵类型的数据绘制透视图。\n\nwireframe(volcano,\n  drape = TRUE, colorkey = FALSE, shade = TRUE,\n  xlab = list(\"南北方向\", rot = -40),\n  ylab = list(\"东西方向\", rot = 45),\n  zlab = list(\"高度\", rot = 90),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -.6, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.8, units = \"inches\"),\n      top.padding = list(x = -1.0, units = \"inches\")\n    )\n  ),\n  # 设置坐标轴字体大小\n  par.settings = list(\n    axis.line = list(col = \"transparent\"),\n    fontsize = list(text = 12, points = 10)\n  ),\n  scales = list(arrows = FALSE, col = \"black\"), \n  screen = list(z = -45, x = -50, y = 0)\n)\n\n\n\n\n\n\n图 9.18: 奥克兰火山地形图\n\n\n\n\n\n9.3.10 地形轮廓图\n绘图函数 levelplot() 支持使用公式语法，也支持矩阵类型的数据绘制轮廓图。基于奥克兰火山地形数据 volcano 绘制轮廓图，volcano 是矩阵类型的数据。\n\nlevelplot(volcano, useRaster = TRUE,\n  # 去掉图形上、右边多余的刻度线\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ),\n  par.settings = list(\n    # x/y 轴标签字体，刻度标签字体\n    par.xlab.text = list(fontfamily = \"Noto Serif CJK SC\"),\n    par.ylab.text = list(fontfamily = \"Noto Serif CJK SC\"),\n    axis.text = list(fontfamily = \"sans\")\n  ),\n  xlab = \"南北方向\", ylab = \"东西方向\"\n)\n\n\n\n\n\n\n图 9.19: 奥克兰火山的地形轮廓图\n\n\n\n\n函数 levelplot() 的参数 col.regions 需要传递一个函数，示例中使用的默认设置。常见的函数有 hcl.colors() 、 gray.colors() 、terrain.colors() 、cm.colors() 和 topo.colors() 等，函数 hcl.colors() 默认使用 viridis 调色板，还可以用函数 colorRampPalette() 构造调色板函数。\n\ndata(topo, package = \"MASS\")\nlevelplot(z ~ x * y, data = topo, scales = \"free\",\n  panel = panel.2dsmoother, contour = TRUE,\n  form = z ~ s(x, y, bs = \"gp\", k = 50), method = \"gam\",\n  xlab = \"水平方向\", ylab = \"垂直方向\"\n)\n\n\n\n\n\n\n图 9.20: 奥克兰火山的地形轮廓图\n\n\n\n\n函数 panel.2dsmoother() 来自 latticeExtra 包，数据的二维分布，默认采用 tp\n\n\ntp thin plate regression spline 回归样条方法平滑。\n\ncr Cubic regression spline 立方回归样条。\n\ngp Gaussian process smooths 高斯过程平滑，默认为全秩 Full Rank，指定 k 低秩近似 Low Rank。\n\n9.3.11 地区分布图\n最后一个想要介绍的是地区分布图，也叫面量图、围栏图，描述空间栅格数据的分布，常见的一种情况是展示各个地区的人口、社会、经济指标。下面通过 tigris 包可以下载美国人口调查局发布的数据，本想下载与观测数据年份最近的地图数据，但是 2009 年及以前的地图数据缺失，因此，笔者下载了 2010 年的地图数据，它与得票率数据最近。\n\nlibrary(tigris)\nus_state_map &lt;- states(cb = TRUE, year = 2010, resolution = \"20m\", class = \"sf\")\nus_state_map &lt;- shift_geometry(us_state_map, geoid_column = \"STATE\", position = \"below\")\n\n第一行代码用 tigris 包的函数 states() 下载 2010 年比例尺为 1:20000000 的多边形州边界矢量地图数据，返回一个 simple feature 类型的空间数据类型。第二行代码用该包的另一个函数 shift_geometry() 移动离岸的州和领地，将它们移动到主体部分的下方。\n\nlibrary(sf)\nus_state_sf &lt;- readRDS(\"data/us-state-map-2010.rds\")\n# sf 转 sp\nus_state_sp &lt;- as(us_state_sf, \"Spatial\")\nlibrary(maps)\n# sp 转 map\nus_state_map &lt;- SpatialPolygons2map(us_state_sp, namefield = \"NAME\")\n# 准备观测数据\ndata(votes.repub)\n# 转为 data.frame 类型\nvotes_repub &lt;- as.data.frame(votes.repub)\n\n数据集 votes.repub 记录 1856-1976 年美国历届大选中共和党在各州的得票率。图中以由红到蓝的颜色变化表示由低到高的得票率，1964 年共和党在东南一隅得票率较高，在其它地方得票率普遍较低，形成一边倒的情况，最终由民主党的林登·约翰逊当选美国第36任总统。1968 年共和党在东南部得票率最低，与 1964 年相比，整个反过来了，最终由共和党的理查德·尼克松当选美国第37任总统。\n\nlibrary(RColorBrewer)\nrdbu_pal &lt;- colorRampPalette(colors = brewer.pal(n = 11, name = \"RdBu\"))\nmapplot(rownames(votes_repub) ~ `1964` + `1968`, data = votes_repub,\n  border = NA, map = us_state_map, colramp = rdbu_pal, layout = c(1, 2),\n  scales = list(draw = FALSE), xlab = \"\", ylab = \"\"\n)\n\n\n\n\n\n\n图 9.21: 共和党在各州的得票率\n\n\n\n\n参数 border 设置州边界线的颜色，NA 表示去掉边界线。参数 map 设置州边界地图数据。参数 colramp 设置一个调色板，用于将得票率与调色板上的颜色映射起来。美国历届大选，共和党和民主党竞争总统职位，最终由得票率决定，用红蓝对抗型调色板表现竞争关系。基于 RColorBrewer 包的 RdBu 调色板，用函数 colorRampPalette() 构造一个新的红蓝调色板。参数 layout 将多个子图按照一定顺序排列，图中设置 2 行 1 列的多图布局。参数 scales 用来调整刻度，设置 list(draw = FALSE) 将图中的刻度去掉了。参数 xlab 设置一个空字符，即 xlab = \"\" 可去掉横坐标轴标签，参数 ylab 应用于设置纵坐标，用法与参数 xlab 一样。图中，主要表现得票率在各州的分布，因此，坐标轴刻度和标签都不太重要，可以去掉。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-basic-lattice-summary",
    "href": "visualization-lattice.html#sec-basic-lattice-summary",
    "title": "9  lattice 入门",
    "section": "\n9.4 总结",
    "text": "9.4 总结\n现在回过头来看，无论是图形样式还是绘图语法， lattice 可以看作是介于 Base R 和 ggplot2 之间的一种绘图风格。举例来说，下面比较 Base R 和 lattice 的图形样式。\nplot(Sepal.Length ~ Petal.Length, col = Species, data = iris,\n  xlab = \"萼片长度\", ylab = \"花瓣长度\")\nxyplot(Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", xlab = \"萼片长度\", ylab = \"花瓣长度\")\n\n\n\n\n\n\n\n\n\n(a) Base R 图形\n\n\n\n\n\n\n\n\n\n(b) lattice 图形\n\n\n\n\n\n\n图 9.22: 对比 Base R 和 lattice 制作的分组散点图\n\n\n与函数 plot() 对应的是函数 xyplot() ，它们共用一套公式语法，参数 data 的含义也是一样的。与参数 col 对应的是参数 groups ，作用是添加数据分组标识。在两个函数中，添加横纵坐标轴标签都是用参数 xlab 和 ylab 。函数 xyplot() 中参数 scales 的作用是对坐标轴刻度的调整，参数值 \"free\" 表示去掉图形上边和右边的刻度线，默认情况下是有刻度线的。\n在高级的绘图函数方面，Base R 和 lattice 基本都有功能对应的函数，在低水平的绘图函数方面，二者截然不同，主要是因为后者基于另一套绘图系统 — grid 绘图系统。Base R 作图常常需要一个函数一个函数地不断叠加，在图中画上点、线、轴、标签等元素，而 lattice 主要通过面板函数，层层叠加的方式，每一个面板函数实现一个功能，整合一系列绘图操作。本章主要介绍 lattice 包和 latticeExtra 包，用到的高级绘图函数如下表。\n\n\n表格 9.1: lattice 和 latticeExtra 包的部分函数\n\n\n\n\n\n\n\n\n\nR 包\n函数\n图形\n作用\n\n\n\nlattice\nxyplot()\n（分组）散点图\n描述关系\n\n\nlattice\nbwplot()\n（分组）箱线图\n描述分布\n\n\nlattice\nbarchart()\n（分组）柱形图\n描述对比\n\n\nlattice\nlevelplot()\n切片水平图\n描述趋势\n\n\nlattice\nwireframe()\n三维透视图\n描述趋势\n\n\nlattice\ncloud()\n三维散点图\n描述分布\n\n\nlatticeExtra\npanel.smoother()\n回归曲线图\n描述趋势\n\n\nlatticeExtra\npanel.2dsmoother()\n地形轮廓图\n描述趋势\n\n\nlatticeExtra\necdfplot()\n经验分布图\n描述分布\n\n\nlatticeExtra\nsegplot()\n置信区间图\n描述不确定性\n\n\nlatticeExtra\npanel.ellipse()\n置信椭圆图\n描述不确定性\n\n\nlatticeExtra\nmapplot()\n地区分布图\n描述分布\n\n\n\n\n\n\n\n\n\n\nSarkar, Deepayan. 2008. lattice: Multivariate Data Visualization with R. New York: Springer. http://lmdvr.r-forge.r-project.org.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#footnotes",
    "href": "visualization-lattice.html#footnotes",
    "title": "9  lattice 入门",
    "section": "",
    "text": "Paul 在 DSC 2001 大会上的幻灯片。↩︎",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html",
    "href": "visualization-graphics.html",
    "title": "10  graphics 入门",
    "section": "",
    "text": "10.1 绘图基础\n利用点、线等基础元素从零开始绘图。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-elements",
    "href": "visualization-graphics.html#sec-graphics-elements",
    "title": "10  graphics 入门",
    "section": "",
    "text": "10.1.1 plot()\n\n本节将主要基于鸢尾花数据集介绍 R 语言基础绘图系统，该数据集最早来自埃德加·安德森，后来，被罗纳德·费希尔在介绍判别分析的论文中用到，从而，流行于机器学习社区。鸢尾花是非常漂亮的一种花，在统计和机器学习社区家喻户晓，更别提在植物界的名声。其实，远不止于此，在绘画艺术界也是如雷贯耳，印象派大师文森特·梵高画了一系列鸢尾花作品。万紫千红，但能入画的不多，故而，鸢尾花更显高雅。在生命最后的一段日子里，梵高受精神病折磨，在法国普罗旺斯的圣·雷米医院里，唯有盛开的鸢尾花陪着他，最著名的《星月夜》就是在这时候创作出来的。下面先让我们一睹鸢尾花芳容，图片来自维基百科鸢尾花词条。\n\n\n\n\n\n\n\n\n\n(a) versicolor 杂色鸢尾\n\n\n\n\n\n\n\n\n\n(b) setosa 山鸢尾\n\n\n\n\n\n\n\n\n\n(c) virginica 弗吉尼亚鸢尾\n\n\n\n\n\n\n图 10.1: 三种鸢尾花\n\n\n鸢尾花数据集已经打包在 R 软件中，而且默认已经加载到命名空间，下面用函数 summary() 查看其概况。\n\nsummary(iris)\n\n#&gt;   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n#&gt;  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n#&gt;  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n#&gt;  Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n#&gt;  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n#&gt;  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n#&gt;  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n#&gt;        Species  \n#&gt;  setosa    :50  \n#&gt;  versicolor:50  \n#&gt;  virginica :50  \n#&gt;                 \n#&gt;                 \n#&gt; \n\n\n函数 plot() 采用公式语法可以快速作图。\nplot(Sepal.Length ~ Sepal.Width, data = iris)\nplot(iris$Sepal.Width, iris$Sepal.Length, panel.first = grid())\n\n\n\n\n\n\n\n\n\n(a) 公式语法绘制散点图\n\n\n\n\n\n\n\n\n\n(b) 带背景参考线的散点图\n\n\n\n\n\n\n图 10.2: 快速作图函数 plot()\n\n\n函数 plot() 是一个泛型函数，传递不同类型的参数值会调用不同的绘图方法，而不同的绘图方法的参数是不同的。当采用公式语法绘图时，会自动调用函数 plot.formula() ，此时，参数 panel.first 就不起作用。当不使用公式语法时，会调用函数 plot.default() ，此时，参数 panel.first 就起作用，利用该参数可以添加背景参考线。\n\n10.1.2 标签\n函数 plot() 的参数 xlab 、ylab 和 main 可以分别设置坐标轴横、纵标签和图主标题。\n\nplot(\n  Sepal.Length ~ Sepal.Width, data = iris, \n  xlab = \"Sepal Width\", ylab = \"Sepal Length\",\n  main = \"Edgar Anderson's Iris Data\"\n)\n\n\n\n\n\n\n图 10.3: 标签\n\n\n\n\n\n10.1.3 字体\n作图函数 plot() 和 title() 都有参数 family ，设置该参数可以调整图形中的字体。下 图 10.4 的横纵坐标轴标签和图标题设为宋体，坐标轴刻度标签设为无衬线字体。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, ann = FALSE, family = \"sans\")\ntitle(\n  xlab = \"萼片宽度\", ylab = \"萼片长度\",\n  main = \"埃德加·安德森的鸢尾花数据\", family = \"Noto Serif CJK SC\"\n)\n\n\n\n\n\n\n图 10.4: 字体\n\n\n\n\n\n10.1.4 分组\n分组有两种方式，其一按照数据中的分类变量分组，其二按照一定的规则分组。而图形表达的方式可以借助颜色或图形元素的样式。\n函数 plot() 的参数 col 和 pch 都可以用来分组，前者通过颜色，后者通过点的类型。简单起见，将数据集 iris 中的 Species 列传递给参数 col ，实现不同种类的鸢尾花配以不同的颜色。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, col = Species, pch = 16)\n\n\n\n\n\n\n图 10.5: 分组\n\n\n\n\n下面采用一个简单规则将数据分成两组，将鸢尾花中 setosa 山毛榉类型且 Sepal.Length 萼片长度大于 5 厘米的分成一组，以红色填充散点代表这部分数据，与余下的散点形成对比，达到区分的目的。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris)\npoints(Sepal.Length ~ Sepal.Width, data = iris, \n  col = \"#EA4335\", pch = 16,\n  subset = Species == \"setosa\" & Sepal.Length &gt; 5\n)\n\n\n\n\n\n\n图 10.6: 分组\n\n\n\n\n\n10.1.5 配色\n经过探查，知道数据集 iris 中的 Species 列有三种取值。调用函数 palette() 设置一个超过 3 种颜色的调色板可以实现自定义配色。首先来看看当前调色板的颜色。\n\npalette()\n\n#&gt; [1] \"black\"   \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\"\n#&gt; [8] \"gray62\"\n\n\n一共是 8 种颜色，效果预览见 图 10.7 。\n\n\n\n\n\n\n\n图 10.7: 默认调色板\n\n\n\n\n设置新的调色板也是用函数 palette() ，参数 value 设置新的颜色值向量，下面依次是红、蓝、绿、黄四种颜色。\n\npalette(value = c(\"#EA4335\", \"#4285f4\", \"#34A853\", \"#FBBC05\"))\n\n函数 plot() 的调色板默认来自函数 palette() ，经过上面的调整，同一行绘图代码出来不同的效果，即 图 10.5 变成 图 10.8 。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, col = Species, pch = 16)\n\n\n\n\n\n\n图 10.8: 配色\n\n\n\n\n\n10.1.6 注释\n函数 text() 可以在图上任意位置添加文本或公式。下图在位置 (4,6.5) 处添加红色的文字 flower。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris)\ntext(x = 4, y = 6.5, labels = \"flower\", col = \"#EA4335\")\n\n\n\n\n\n\n图 10.9: 注释\n\n\n\n\n\n10.1.7 图例\n函数 plot() 不会自动添加图例，需要使用函数 legend() 添加图例。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, col = Species, pch = 16)\nlegend(x = \"topright\", title = \"Species\",\n  legend = unique(iris$Species), box.col = NA, bg = NA,\n  pch = 16, col = c(\"#EA4335\", \"#4285f4\", \"#34A853\")\n)\n\n\n\n\n\n\n图 10.10: 图例\n\n\n\n\n图例放置在绘图区域以外，比如右边空区域。此时，通过点和文本构造图例。\n\nop &lt;- par(mar = c(4, 4, 3, 6))\nplot(\n  Sepal.Length ~ Sepal.Width, data = iris, \n  col = Species, pch = 16, main = \"Edgar Anderson's Iris Data\"\n)\ntext(x = 4.7, y = 6.75, labels = \"Species\", pos = 4, offset = .5, xpd = T)\npoints(x = 4.7, y = 6.5, pch = 16, cex = 1, col = \"#EA4335\", xpd = T)\ntext(x = 4.7, y = 6.5, labels = \"setosa\", pos = 4, col = \"#EA4335\", xpd = T)\npoints(x = 4.7, y = 6.3, pch = 16, cex = 1, col = \"#4285f4\", xpd = T)\ntext(x = 4.7, y = 6.3, labels = \"versicolor\", pos = 4, col = \"#4285f4\", xpd = T)\npoints(x = 4.7, y = 6.1, pch = 16, cex = 1, col = \"#34A853\", xpd = T)\ntext(x = 4.7, y = 6.1, labels = \"virginica\", pos = 4, col = \"#34A853\", xpd = T)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.11: 图例\n\n\n\n\n在函数 plot() 内设置较宽的坐标轴范围，获得一个较宽的绘图区域，再用函数 points() 添加数据点，最后，使用函数 legend() 添加图例。\n\nplot(\n  x = c(2, 6), y = range(iris$Sepal.Length), type = \"n\",\n  xlab = \"Sepal Width\", ylab = \"Sepal Length\",\n  main = \"Edgar Anderson's Iris Data\"\n)\npoints(Sepal.Length ~ Sepal.Width,\n  col = Species, pch = 16, data = iris\n)\nlegend(x = \"right\", title = \"Species\",\n  legend = unique(iris$Species), box.col = NA, bg = NA,\n  pch = 16, col = c(\"#EA4335\", \"#4285f4\", \"#34A853\")\n)\n\n\n\n\n\n\n图 10.12: 图例\n\n\n\n\n\n10.1.8 统计\n添加分组线性回归线。按鸢尾花种类分组，线性回归模型拟合数据，抽取回归系数。首先，使用函数 split() 将数据集 iris 按变量 Species 分组拆分，得到一个列表，每个元素都是数据框。接着，调用函数 lapply() 将函数 lm() 作用到列表的每个元素上，得到一个列表，每个元素都是线性拟合对象。最后，再调函数 lapply() 将函数 coef() 应用到列表的每个元素上，得到回归模型的系数向量。\n\nlapply(\n  lapply(\n    split(iris, ~Species), lm,\n    formula = Sepal.Length ~ Sepal.Width\n  ),\n  coef\n)\n\n#&gt; $setosa\n#&gt; (Intercept) Sepal.Width \n#&gt;   2.6390012   0.6904897 \n#&gt; \n#&gt; $versicolor\n#&gt; (Intercept) Sepal.Width \n#&gt;   3.5397347   0.8650777 \n#&gt; \n#&gt; $virginica\n#&gt; (Intercept) Sepal.Width \n#&gt;   3.9068365   0.9015345\n\n\n走到绘图这一步，往往是画什么内容比较清楚，分类数量、调色板都确定下来了。大致来说分 6 步：第一步，实现分组线性回归拟合；第二步，绘制分组散点图；第三步，添加分组回归线；第四步，添加图例并调整图例的位置；第五步，设置图形边界等绘图参数；第六步，添加背景网格线。输入线性拟合对象给函数 abline() 可以直接绘制回归线，不需要从拟合对象中提取回归系数。调用函数 par() 设置图形边界，特别是增加图形右侧边界以容纳图例，再调用函数 legend() 要设置 xpd = TRUE 以允许图例超出绘图区域。\n\n# 分组线性拟合\niris_lm &lt;- lapply(\n  split(iris, ~Species), lm, formula = Sepal.Length ~ Sepal.Width\n)\n# 将分组变量和颜色映射\ncols &lt;- c(\"setosa\" = \"#EA4335\",  \"versicolor\" = \"#4285f4\", \"virginica\" = \"#34A853\")\n# 设置图形边界以容纳标签和图例\nop &lt;- par(mar = c(4, 4, 3, 8))\n# 绘制分组散点图\nplot(\n  Sepal.Length ~ Sepal.Width,\n  data = iris, col = Species, pch = 16,\n  xlab = \"Sepal Width\", ylab = \"Sepal Length\",\n  main = \"Edgar Anderson's Iris Data\"\n)\n# 添加背景参考线\ngrid()\n# 添加回归线\nfor (species in c(\"setosa\", \"versicolor\", \"virginica\")) {\n  abline(iris_lm[[species]], col = cols[species], lwd = 2)\n}\n# 添加图例\nlegend(\n  x = \"right\", title = \"Species\", inset = -0.4, xpd = TRUE,\n  legend = unique(iris$Species), box.col = NA, bg = NA, lty = 1, lwd = 2,\n  pch = 16, col = c(\"#EA4335\", \"#4285f4\", \"#34A853\")\n)\n# 恢复图形参数设置\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.13: 分组线性回归",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-advanced",
    "href": "visualization-graphics.html#sec-graphics-advanced",
    "title": "10  graphics 入门",
    "section": "\n10.2 绘图进阶",
    "text": "10.2 绘图进阶\n\n10.2.1 组合图形\n点、线、多边形组合\n\nx &lt;- seq(-10, 10, length = 400)\ny1 &lt;- dnorm(x)\ny2 &lt;- dnorm(x, m = 3)\nop &lt;- par(mar = c(5, 4, 2, 1))\nplot(x, y2,\n  xlim = c(-3, 8), type = \"n\",\n  xlab = quote(Z == frac(mu[1] - mu[2], sigma / sqrt(n))),\n  ylab = \"Density\"\n)\npolygon(c(1.96, 1.96, x[240:400], 10),\n  c(0, dnorm(1.96, m = 3), y2[240:400], 0),\n  col = \"grey80\", lty = 0\n)\nlines(x, y2)\nlines(x, y1)\npolygon(c(-1.96, -1.96, x[161:1], -10),\n  c(0, dnorm(-1.96, m = 0), y1[161:1], 0),\n  col = \"grey30\", lty = 0\n)\npolygon(c(1.96, 1.96, x[240:400], 10),\n  c(0, dnorm(1.96, m = 0), y1[240:400], 0),\n  col = \"grey30\"\n)\nlegend(x = 4.2, y = .4,\n  fill = c(\"grey80\", \"grey30\"),\n  legend = expression(\n    P(abs(Z) &gt; 1.96, H[1]) == 0.85,\n    P(abs(Z) &gt; 1.96, H[0]) == 0.05\n  ), bty = \"n\"\n)\ntext(0, .2, quote(H[0]:~ ~ mu[1] == mu[2]))\ntext(3, .2, quote(H[1]:~ ~ mu[1] == mu[2] + delta))\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.14: 正态总体下两样本均值之差的检验\n\n\n\n\n\n10.2.2 多图布局\n布局函数 layout() 和图形参数设置函数 par()\n\ndata(anscombe)\nform &lt;- sprintf(\"y%d ~ x%d\", 1:4, 1:4)\nfit &lt;- lapply(form, lm, data = anscombe)\nop &lt;- par(mfrow = c(2, 2), mgp = c(2, 0.7, 0), \n          mar = c(3, 3, 1, 1) + 0.1, oma = c(0, 0, 2, 0))\nfor (i in 1:4) {\n  plot(as.formula(form[i]),\n    data = anscombe, col = \"black\",\n    pch = 20, xlim = c(3, 19), ylim = c(3, 13),\n    xlab = as.expression(substitute(x[i], list(i = i))),\n    ylab = as.expression(substitute(y[i], list(i = i))),\n    family = \"sans\"\n  )\n  abline(fit[[i]], col = \"black\")\n  text(\n    x = 7, y = 12, family = \"sans\",\n    labels = bquote(R^2 == .(round(summary(fit[[i]])$r.squared, 3)))\n  )\n}\nmtext(\"数据集的四重奏\", outer = TRUE)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.15: 数据可视化很重要",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-choose",
    "href": "visualization-graphics.html#sec-graphics-choose",
    "title": "10  graphics 入门",
    "section": "\n10.3 图形选择",
    "text": "10.3 图形选择\n以不同的二维或三维图形可视化同一份多元数据。颜色图、透视图、等值线图和填充等值线图存在某种相似性，又有区别。\n\n10.3.1 颜色图\n\\[\nf(x,y) =\n\\begin{cases}\n\\frac{\\sin(\\sqrt{x^2 + y^2})}{\\sqrt{x^2 + y^2}}, & (x,y) \\neq (0,0)\\\\\n1, & (x,y) = (0,0)\n\\end{cases}\n\\]\n\ny &lt;- x &lt;- seq(from = -8, to = 8, length.out = 51)\nz &lt;- outer(x, y, FUN = function(x, y) sin(sqrt(x^2 + y^2)) / sqrt(x^2 + y^2))\nz[26, 26] &lt;- 1\n\n将绘图区域划分成网格，每个小网格对应一个颜色值。函数 image() 绘制颜色图\n\nimage(x = x, y = y, z = z, xlab = \"$x$\", ylab = \"$y$\")\n\n\n\n\n\n\n图 10.16: 颜色图\n\n\n\n\n\n10.3.2 透视图\n函数 persp() 绘制透视图\n\nop &lt;- par(mar = c(0, 1, 2, 1))\npersp(\n  x = x, y = y, z = z, main = \"二维函数的透视图\",\n  theta = 30, phi = 30, expand = 0.5, col = \"lightblue\",\n  xlab = \"$x$\", ylab = \"$y$\", zlab = \"$f(x,y)$\"\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.17: 透视图\n\n\n\n\n\n10.3.3 等值线图\n地理上，常用等高线图描述地形，等高线图和等值线图其实是一个意思。函数 contour() 绘制等值线图。\n\ncontour(x = x, y = y, z = z, xlab = \"$x$\", ylab = \"$y$\")\n\n\n\n\n\n\n图 10.18: 等值线图\n\n\n\n\n\n10.3.4 填充等值线图\n函数 filled.contour() 绘制填充等值线图。\n\nfilled.contour(\n  x = x, y = y, z = z, asp = 1,\n  color.palette = hcl.colors,\n  plot.title = {\n    title(\n      main = \"二维函数的填充等值线图\",\n      xlab = \"$x$\", ylab = \"$y$\"\n    )\n  },\n  plot.axes = {\n    grid(col = \"gray\")\n    axis(1, at = 2 * -4:4, labels = 2 * -4:4)\n    axis(2, at = 2 * -4:4, labels = 2 * -4:4)\n    points(0, 0, col = \"blue\", pch = 16)\n  },\n  key.axes = {\n    axis(4, seq(-0.2, 1, length.out = 9))\n  }\n)\n\n\n\n\n\n\n图 10.19: 填充等值线图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-summary",
    "href": "visualization-graphics.html#sec-graphics-summary",
    "title": "10  graphics 入门",
    "section": "\n10.4 总结",
    "text": "10.4 总结\n\n10.4.1 plot2 包\nplot2 包扩展 Base R 函数 plot() 的功能，在公式语法方面和 lattice 包很接近。另一个值得一提的 R 包是 basetheme ，用来设置 Base R 绘图主题。\n\nlibrary(plot2)\nplot2(Sepal.Length ~ Sepal.Width | Species, data = iris, \n      palette = \"Tableau 10\", pch = 16)\n\n\n\n\n\n\n图 10.20: plot2 包绘制分组散点图\n\n\n\n\n或者使用参数 by 指定分组变量，效果和上图一样。\n\nwith(iris, {\n  plot2(y = Sepal.Length, x = Sepal.Width, by = Species,\n      palette = \"Tableau 10\", pch = 16)\n})\n\n还可以使用参数 legend 调整图例的位置，比如放置在绘图区域下方。\n\nop &lt;- par(mar = c(5, 4, .5, .5))\nplot2(Sepal.Length ~ Sepal.Width | Species,\n  data = iris, palette = \"Tableau 10\", pch = 16,\n  legend = legend(\"bottom!\", title = \"Species of iris\", bty = \"o\")\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.21: plot2 包调整图例位置\n\n\n\n\n还可以绘制其它类型的图形，如分组密度曲线图等。\n\nwith(iris, plot2(\n  density(Sepal.Length), by = Species,\n  bg = \"by\",   # 分组填充\n  grid = TRUE, # 背景网格\n  palette = \"Tableau 10\",\n  legend = list(\"topright\", bty = \"o\") # 右上角图例\n))\n\n\n\n\n\n\n图 10.22: plot2 包绘制密度曲线图\n\n\n\n\n\n10.4.2 plot3D 包\n虽然不提倡大量使用三维图形，但如何绘制三维图形却是生生不息的命题，以下仅是 R 语言社区的冰山一角。\n\n\nplotrix (Lemon 2006) 一个坐落于 R 的红灯区的 R 包。基于 Base R 各类绘图函数。\n\nscatterplot3d (Ligges 和 Mächler 2003) 基于 Base R 绘制三维散点图。\n\nmisc3d (Feng 和 Tierney 2008) 绘制三维图形的杂项，支持通过 Base R、 tcltk 包和 rgl 包渲染图形。\n\nplot3D (Soetaert 2021) 依赖 misc3d 包，加强 Base R 在制作三维图形方面的能力。\n\n举个比较新颖的一个例子，plot3D 包的函数 image2D() 绘制二维颜色图，细看又和 image() 函数不同，渲染出来的图形有三维的立体感。归根结底，很多时候束缚住自己的不是工具，而是视野和思维。以奥克兰 Maunga Whau 火山地形数据 volcano 为例。\nlibrary(plot3D)\nimage2D(volcano,\n  shade = 0.2, rasterImage = TRUE, asp = 0.7,\n  xlab = \"南北方向\", ylab = \"东西方向\",\n  main = \"奥克兰 Maunga Whau 地形图\", clab = \"高度\",\n  contour = FALSE, col = hcl.colors(100),\n  colkey = list(\n    at = 90 + 20 * 0:5, labels = 90 + 20 * 0:5,\n    length = 1, width = 1\n  )\n)\nop &lt;- par(mar = c(1, 1.5, 0, 0))\npersp3D(\n  x = 1:87, y = 1:61, z = volcano, col = hcl.colors(100),\n  ticktype = \"detailed\", colkey = FALSE, expand = 1, \n  phi = 35, theta = 125, bty = \"b2\", shade = TRUE,\n  ltheta = 100, lphi = 45,\n  xlab = \"\\n南北方向\", ylab = \"\\n东西方向\", zlab = \"\\n高度\"\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n\n\n\n(a) 函数 image2D() 二维颜色图\n\n\n\n\n\n\n\n\n\n\n\n(b) 函数 persp3D() 三维透视图\n\n\n\n\n\n\n图 10.23: 奥克兰火山地形图\n\n\n值得一提，Python 社区的绘图模块 matplotlib 同样具有强大的绘图能力，三维图形也不在话下。不过，不同的绘图系统所采用的透视法不同，如下图所示。\n\n代码from matplotlib import cm\nfrom matplotlib.colors import LightSource\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# 设置 PGF 后端渲染图形\nimport matplotlib as mpl\nmpl.use(\"pgf\")\n# XeLaTeX 编译图形\nplt.rcParams.update({\n    \"text.usetex\": True,\n    \"pgf.texsystem\": \"xelatex\",\n    \"pgf.rcfonts\": False,    # don't setup fonts from rc parameters\n    \"pgf.preamble\": \"\\n\".join([\n            r\"\\usepackage[fontset=fandol,UTF8]{ctex}\",\n        ]),\n})\n# 读取数据\nvolcano = pd.read_csv(\"data/volcano.csv\", header=None)\n# DataFrame 转 Array\nz = volcano.to_numpy()\n# 数据行、列数\nnrows, ncols = z.shape\n# 线性序列\nx = np.linspace(1, 87, ncols)\ny = np.linspace(1, 61, nrows)\n# 类似 R 语言函数 expand.grid()\nxv, yv = np.meshgrid(x, y)\n# 设置主题\nfig, ax = plt.subplots(subplot_kw=dict(projection=\"3d\"))\n# 观察视角\nax.view_init(azim=30, elev=30)\n# 设置坐标轴标签\nax.set_xlabel(r\"南北方向\", rotation=45)\nax.set_ylabel(r\"东西方向\", rotation=-15)\nax.set_zlabel(r\"高度\", rotation=90)\n# 去掉多余的边空\nfig.set_tight_layout(True)\n# 光源照射的角度\nls = LightSource(270, 45)\n# 自定义调色板\nrgb = ls.shade(z, cmap=cm.viridis, vert_exag=0.1, blend_mode=\"soft\")\n# 三维透视图\nsurf = ax.plot_surface(\n    xv, yv, z, rstride=1, cstride=1, facecolors=rgb,\n    linewidth=0, antialiased=False, shade=False\n)\n# 渲染\nplt.show()\n\n\n\n\n\n\n图 10.24: matplotlib 绘制三维透视图\n\n\n\n\n\n\n\n\nFeng, Dai, 和 Luke Tierney. 2008. 《Computing and Displaying Isosurfaces in R》. Journal of Statistical Software 28 (1). https://doi.org/10.18637/jss.v028.i01.\n\n\nLemon, Jim. 2006. 《plotrix: a package in the red light district of R》. R-News 6 (4): 8–12.\n\n\nLigges, Uwe, 和 Martin Mächler. 2003. 《scatterplot3d: An R Package for Visualizing Multivariate Data》. Journal of Statistical Software 8 (11): 1–20. https://doi.org/10.18637/jss.v008.i11.\n\n\nSoetaert, Karline. 2021. plot3D: Plotting Multi-Dimensional Data. https://CRAN.R-project.org/package=plot3D.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html",
    "href": "visualization-tikz.html",
    "title": "11  TikZ 入门",
    "section": "",
    "text": "11.1 standalone 宏包\n最常见的 LaTeX 文档类有 article、report、beamer、book，分别对应文章、报告、演示和书籍。有的宏包在此基础上扩展功能，比如 ctex 宏包提供中文支持，有四个文档类 ctexart、 ctexrep 、ctexbeamer 和 ctexbook 与之对应起来。standalone 宏包提供 standalone 文类主要用于绘制独立的图片，默认情况下，文档四周多余的空白部分会被裁剪掉。在 LaTeX 环境中，推荐使用 TikZ 来绘图。standalone 文类可与 tikz 宏包一起使用，生成一张张由 TikZ 代码绘制的独立图片。下面举个简单的例子，用 TikZ 绘制两个坐标轴。\nstandalone 文类启用 tikz 选项来绘图，选项 border=1mm 表示图片四周的边空保留 1 毫米，文档内容放在 document 环境里，TikZ 绘图代码放在 tikzpicture 环境中，命令 \\draw 负责绘制具体的图形，用 XeLaTeX 编译，效果如 图 11.1 所示。\n图 11.1: TikZ 绘图\nstandalone 文类有很多选项，下面介绍 4 个选项的常用内容。\nstandalone 文类是支持 PSTricks 绘图的，下面在直角坐标系中绘制一个带阴影效果的圆，示例代码如下：\nstandalone 文类的选项 pstricks 表示启用 PSTricks 绘图环境，加载 pst-plot 宏包提供额外的命令，PSTricks 是基于 PostScript 语言的，每一个绘图命令都是 \\ps 开头的，比如 \\psset 、\\psaxes、\\pscircle 等。\\begin{pspicture} 和 \\end{pspicture} 之间是 PSTricks 绘图代码，\\begin{pspicture} 之后的 (0,0)(11,11) 是左下和右上角两个坐标，定义了一个绘图区域。和 TikZ 绘图代码一样，也用 XeLaTeX 编译，效果如 图 11.2 所示。\n图 11.2: PSTricks 绘图\n可以在 Quarto 和 R Markdown 文档中插入 PSTricks 绘图代码，使用 knitr 包的 tikz 引擎绘图。只要修改模版文件 tikz2pdf.tex ，移除一行 \\usetikzlibrary{matrix} ，不再加载 tikz 宏包及其 matrix 库。TIKZ_CLASSOPTION 不再仅限于 TikZ ，而是 standalone 文类的选项，相应地，EXTRA_TIKZ_PREAMBLE_CODE 变成一般的 LaTeX 文档的导言区，TIKZ_CODE 可以是 PSTricks 代码。新的模版文件 tikz2pdf.tex 如下：\n上 图 11.2 即是由 knitr 包的 tikz 引擎渲染出来的。在代码块选项 engine-opts 中，传递一个列表，分别包含 classoption（standalone 文类选项）、 extra.preamble（导言区）、 template （TikZ 模版文件）三块内容。生成 图 11.2 的 engine-opts 设置如下：\n其它选项和更多详细介绍见 standalone 宏包帮助文档。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-standalone",
    "href": "visualization-tikz.html#sec-tikz-standalone",
    "title": "11  TikZ 入门",
    "section": "",
    "text": "\\documentclass[tikz,border=1mm]{standalone}\n\\begin{document}\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) -- (0,0) node[left]{O} -- (0,6);\n\\end{tikzpicture}\n\\end{document}\n\n\n\n\nclass 选项指定文类环境，默认值为 article，表示在 article 文类中绘图。其它选项还有 beamer ，表示在演示环境中绘图。在不同的文类中，图片渲染出来的效果不同。\ntikz=true|false 选项是否启用 TikZ 绘图，默认值是 false 。当显式地在 standalone 文类中启用 tikz 选项，就表示用 TikZ 绘图，将自动加载 tikz 宏包。与之类似的选项 pstricks=true|false ，表示是否启用 PSTricks 绘图，PSTricks 是LaTeX 社区中一套语法不同于 TikZ 的绘图工具。\ncrop=true|false 选项是否裁剪变空，默认值是 true ，表示绘图区域以外的部分都裁剪掉。与之相关的另一个选项是 border ，可以更加精细地控制图片四周的各个边空。\nborder 选项指定边空大小，默认值是 0，表示无边空。当 crop=true 时，再指定 border 选项，比如 border=1mm 表示图片四周的边空保留 1 毫米。图片四周的边空大小可以按照左、下、右、上的顺序指定，比如 border={5mm 6mm 0mm -2mm} 表示图片左边空 5 毫米、下边空 6 毫米、右边空 0 毫米、上边空负 2 毫米。\n\n\n\\documentclass[pstricks,border={5mm 6mm 0mm -2mm}]{standalone}\n\\usepackage{pst-plot}\n\\begin{document}\n\\psset{xunit=0.15in, yunit=0.15in}\n\\begin{pspicture}(0,0)(11,11)\n\\psaxes[Dx=4,Dy=4, subticks=4]{-&gt;}(0,0)(0,0)(10,10)[$x$,0][$y$,0]\n\\pscircle[runit=0.15in, fillcolor=orange!50, fillstyle=solid,shadow=true](5,5){3}\n\\end{pspicture}\n\\end{document}\n\n\n\n\\documentclass[\n%% TIKZ_CLASSOPTION %%\n]{standalone}\n%% EXTRA_TIKZ_PREAMBLE_CODE %%\n\\begin{document}\n%% TIKZ_CODE %%\n\\end{document}\n\nlist(\n  classoption = \"pstricks,border={5mm 6mm 0mm -2mm}\",\n  extra.preamble = \"\\\\usepackage{pst-plot}\",\n  template = \"code/tikz2pdf.tex\"\n)",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-pgf",
    "href": "visualization-tikz.html#sec-tikz-pgf",
    "title": "11  TikZ 入门",
    "section": "\n11.2 PGF 宏包",
    "text": "11.2 PGF 宏包\nPGF 宏包提供一套易于学习和使用的绘图语法 TikZ，TikZ 是 TikZ ist kein Zeichenprogramm 的简写，命名有 Linux 哲学意味。下面比较详细的介绍 LaTeX 宏包 PGF 绘制曲线图的过程。\n\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) -- (0,0) node[left]{O} -- (0,6);\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.3: PGF 绘制曲线图\n\n\n\n\n首先，\\draw 命令绘制带箭头的坐标轴，坐标轴的范围 \\([0,6]\\times[0,6]\\) 。坐标轴是由线构成的，线有虚线、实线，也有宽度和颜色，虚线还有不同类型，这些都是可以设置的参数，比如将 \\draw[&lt;-&gt;] 改为 \\draw[color=red,&lt;-&gt;] ，坐标轴颜色设置为红色。\n\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) node[below]{$q$} -- (0,0) node[left]{O} -- (0,6) node[left]{$V(q)$};\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.4: PGF 绘制曲线图\n\n\n\n\n然后，在位置 (6,0) 和 (0,6) 分别添加节点 node[below]{$q$} 和 node[left]{$V(q)$} 。node 表示节点，节点的标签内容在大括号内，标签的位置在中括号内，这里，below 表示在位置 (6,0) 的下方。\n\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) node[below]{$q$} -- (0,0) node[left]{O} -- (0,6) node[left]{$V(q)$};\n\\draw[very thick] (0,0) to [out=90,in=145] (5,4.5);\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.5: PGF 绘制曲线图\n\n\n\n\n最后，从点 (0,0) 至点 (5,4.5) 绘制一条非常粗的曲线。曲线从点 (0,0) 出去的时候，是以 90 度垂直水平轴的方向出去的，到点 (5,4.5) 是以 145 度方向进入的。角度是按照逆时针方向计算的。线的粗细、方向都是由参数决定的。\n在这里，TikZ 是用来绘制示意图的，不需要知道每个命令的每个参数的取值有哪些。关键是知道自己想要画什么，其实，可以用铅笔在纸上以最快的方式绘制草图，了解每个绘图元素，然后查找 PGF 帮助手册，找到对应的命令和参数，将草图工整地誊抄一遍。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-pgfplots",
    "href": "visualization-tikz.html#sec-tikz-pgfplots",
    "title": "11  TikZ 入门",
    "section": "\n11.3 三维图",
    "text": "11.3 三维图\n顾名思义，pgfplots 宏包基于 PGF 的，用它来绘制三维图形是非常方便的。\n\\documentclass[tikz]{standalone}\n\\usepackage{pgfplots}\n\\pgfplotsset{width=7cm,compat=1.17}\n\\begin{document}\n%% TikZ 代码%%\n\\end{document}\n首先加载 pgfplots 宏包，设置全局的绘图参数，width=7cm 表示绘图页面宽度，compat=1.17 表示使用 pgfplots 的版本。\n\n\\begin{tikzpicture}\n\\begin{axis}[\n    hide axis,\n    colormap/viridis\n]\n\\addplot3[\n    mesh,\n    samples=50,\n    domain=-8:8\n]\n{ sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2) };\n\\addlegendentry{$\\frac{\\sin(r)}{r}$}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.6: TikZ 绘制三维图 viridis 调色板\n\n\n\n\n\n\\begin{tikzpicture}\n\\begin{axis}[\n    hide axis,\n    colormap/jet\n]\n\\addplot3[\n    mesh,\n    samples=50,\n    domain=-8:8\n]\n{ sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2) };\n\\addlegendentry{$\\frac{\\sin(r)}{r}$}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.7: TikZ 绘制三维图 jet 调色板\n\n\n\n\n\n\\begin{tikzpicture}\n\\begin{axis}[\n    hide axis,\n    colormap/cool,\n    colorbar sampled,\n    domain=-8:8\n]\n\\addplot3[\n    contour filled={\n      number=20,\n    },\n    ]{sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2)};\n\\addlegendentry{$\\frac{\\sin(r)}{r}$}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.8: TikZ 绘制三维图 cool 调色板\n\n\n\n\n\n\n\\begin{axis} 和 \\end{axis} 环境有很多配置选项，参数值 [hide axis, colormap/viridis] 中 hide axis 表示隐藏坐标轴，colormap/viridis 表示三维图形的调色板采用 viridis 。colormap 支持很多不同的调色板，上面列举了两个。其实还可以增加不同的选项，比如添加选项 colorbar sampled 会生成一个颜色条，还可以添加选项 colorbar horizontal 来水平放置颜色条。\n可以在导言区加载 \\usetikzlibrary{pgfplots.colorbrewer} 导入 ColorBrewer 系列调色板，方便后续绘图时调用。作用与 R 语言中的 RColorBrewer 包类似，调色板名称略有不同，前者 PuBu-9 对应后者 PuBu 。\n\n\\addplot3 命令绘制函数 sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2) 的三维图像，即函数 \\(f(x,y)=\\frac{\\sin(\\sqrt{x^2 + y^2})}{\\sqrt{x^2 + y^2}}\\) 的三维图像。参数值 [mesh, samples=50, domain=-8:8] 中 mesh 表示三维图形是网格状，其它可选值还有曲面图 surf 、填充等值线图 contour filled 等，samples=50 表示网格密度是 50，domain=-8:8 表示横纵坐标的范围都是 \\([-8,8]\\) 。\n\n\\addlegendentry 添加图例，图例标签是 \\(\\frac{\\sin(r)}{r}\\) ，颜色会随着调色板变化。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-network",
    "href": "visualization-tikz.html#sec-tikz-network",
    "title": "11  TikZ 入门",
    "section": "\n11.4 网络图",
    "text": "11.4 网络图\n绘制网络图用 tikz-network 宏包，也是 PGF 的一个扩展包。图结构是根据顶点和边来定义的，图的复杂程度也可以用顶点和边的规模来衡量。图描述一种非线性的关系，有自己的一套语言，定义顶点 \\Vertex 和边 \\Edge 的两个命令是最基础的。下面绘制柯尼斯堡七桥问题对应的图。\n\\documentclass[tikz]{standalone}\n\\usepackage{tikz-network}\n\\begin{document}\n%% TikZ 代码%%\n\\end{document}\n\n\\begin{tikzpicture}\n\\Vertex[IdAsLabel, x=5, color=gray, size=1, fontsize=\\large]{A}\n\\Vertex[IdAsLabel, x=10, color=gray, size=1, fontsize=\\large]{B}\n\\Vertex[IdAsLabel, x=15, color=gray, size=1, fontsize=\\large]{C}\n\\Vertex[IdAsLabel, x=10, y=6, color=gray, size=1, fontsize=\\large]{D}\n\n\\Edge[label=2, bend=45, fontscale=2](A)(B)\n\\Edge[label=6, bend=30, fontscale=2](A)(D)\n\\Edge[label=3, bend=45, fontscale=2](B)(A)\n\\Edge[label=5, bend=45, fontscale=2](B)(C)\n\\Edge[label=4, bend=45, fontscale=2](C)(B)\n\\Edge[label=7, bend=30, fontscale=2](D)(C)\n\\Edge[label=1, fontscale=2](D)(B)\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.9: 柯尼斯堡七桥\n\n\n\n\n\n\\Vertex 命令定义顶点（含标签），参数 IdAsLabel 表示顶点 ID 作为标签，参数 x 和 y 表示坐标位置，参数 color 表示顶点的填充色，参数 size 表示顶点的大小，参数 fontsize 表示标签文本的大小。\n\\Edge 命令在已有顶点的基础上定义边，(A)(B) 表示从顶点 A 到顶点 B 有一条边，参数label 表示边上的标签文本，参数 bend 表示边的弧度，参数 fontscale 表示标签文本的大小。\n\n不难看出，无论是顶点还是边，都有颜色、大小、标签等参数，尽管参数名称有所不同。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-mindmap",
    "href": "visualization-tikz.html#sec-tikz-mindmap",
    "title": "11  TikZ 入门",
    "section": "\n11.5 思维导图",
    "text": "11.5 思维导图\n思维导图是非常常见的一种树状图，用于梳理层次关系。TikZ 绘制思维导图是通过 mindmap 库实现的，它是 PGF 的一个库。如 图 11.10 所示，看着和脑神经网络有某种相似性，所以，有时候，思维导图也叫脑图。\n\\documentclass[tikz,svgnames]{standalone}\n\\usepackage[fontset=fandol]{ctex}\n\\usetikzlibrary{mindmap}\n\\begin{document}\n%% TikZ 代码%%\n\\end{document}\n\n\\begin{tikzpicture}[\n    mindmap, every node/.style=concept, concept color=orange, text=white,\n    level 1/.append style={level distance=5cm, sibling angle=60, font=\\LARGE},\n    level 2/.append style={level distance=3.5cm, sibling angle=45, font=\\large}\n  ]\n\n  \\node{\\huge{\\textsf{数据分析}}} [clockwise from=60]\n  child [concept color=DarkMagenta] {\n      node {\\textit{数据准备}} [clockwise from=120]\n      child { node {数据对象}}\n      child { node {数据获取}}\n      child { node {数据清洗}}\n      child { node {数据操作}}\n    }\n  child [concept color=DarkBlue] {\n      node {\\textit{数据探索}} [clockwise from=30]\n      child { node {ggplot2 入门}}\n      child { node {基础图形}}\n      child { node {统计图形}}\n    }\n  child [concept color=Brown] {\n      node {\\textit{数据交流}} [clockwise from=-30]\n      child { node {交互图形}}\n      child { node {交互表格}}\n      child { node {交互应用}}\n    }\n  child [concept color=teal] {\n      node {\\textit{统计分析}} [clockwise from=-75]\n      child { node {统计检验}}\n      child { node {回归分析}}\n      child { node {功效分析}}\n    }\n  child [concept color=purple] {\n      node {\\textit{数据建模}} [clockwise from=-120]\n      child { node {网络分析}}\n      child { node {文本分析}}\n      child { node {时序分析}}\n    }\n  child [concept color=DarkGreen] {\n      node {\\textit{优化建模}} [clockwise from=180]\n      child { node {统计计算}}\n      child { node {数值优化}}\n      child { node {优化问题}}\n    };\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.10: TikZ 绘制思维导图\n\n\n\n\n根节点视为一层，则该思维导图有三层。不同的颜色和字体来区分不同的层次或分类，数据分析划分为不同的部分，每个部分有若干章。根节点字体为黑体、第二、三级节点分别为楷体、宋体。\n\\node{\\huge{\\textsf{数据科学}}} [clockwise from=60]\n定义根节点，节点的文本设置为黑体，大小设置为 \\huge 。由根节点向外辐射生成 6 个子节点，每隔 60 度设置一个子节点。\n  child [concept color=DarkMagenta] {\n      node {\\textit{数据准备}} [clockwise from=120]\n      child { node {数据对象}}\n      child { node {数据获取}}\n      child { node {数据清洗}}\n      child { node {数据操作}}\n    }\n第一个子节点，颜色为饱和的紫色 DarkMagenta，二级子节点为「数据准备」，三级子节点有 4 个，逆时针 120 度的位置设置第一个三级子节点「数据对象」，然后顺时针往下，依次是「数据获取」、「数据清洗」和「数据操作」。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-smart-diagram",
    "href": "visualization-tikz.html#sec-smart-diagram",
    "title": "11  TikZ 入门",
    "section": "\n11.6 SmartArt 图",
    "text": "11.6 SmartArt 图\nOffice 办公软件中有一个 SmartArt 绘图模块，专门用来绘制各类示意图。LaTeX 宏包 smartdiagram 基于 TikZ 定制了一套风格类似的绘图库。 smartdiagram 宏包的主要绘图命令是 \\smartdiagram[参数值] ，设置不同的参数值可以绘制不同的图形，如气泡图 bubble diagram 和描述图 descriptive diagram 等。\n\n\\smartdiagram[bubble diagram]{\n  Pandoc,\n  编程语言~\\\\ (Python\\\\R/Julia\\\\JavaScript), \n  编译引擎~\\\\ (Jupyter\\\\Knitr\\\\Observable), \n  扩展Pandoc~\\\\ (交叉引用\\\\悬浮引用\\\\布局面板), \n  文档项目~\\\\ (批量渲染\\\\共享配置),\n  扩展接口~\\\\ (RStudio\\\\VS Code\\\\JupyterLab) \n}\n\n\n\n\n\n\n图 11.11: 气泡图\n\n\n\n\n\n\\smartdiagram[descriptive diagram]{\n  {编程语言, {Python、R、Julia、JavaScript}}, \n  {编译引擎, {Jupyter、Knitr、Observable}}, \n  {扩展Pandoc, {交叉引用、悬浮引用、布局面板}}, \n  {文档项目, {批量渲染、共享配置}},\n  {扩展接口, {RStudio、VS Code、JupyterLab}},\n}\n\n\n\n\n\n\n图 11.12: 描述图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-with-r",
    "href": "visualization-tikz.html#sec-tikz-with-r",
    "title": "11  TikZ 入门",
    "section": "\n11.7 TikZ 与 R",
    "text": "11.7 TikZ 与 R\nTikZ 绘图的优势有很多，语法简单、易于上手、功能强大、资源丰富、成熟稳定等，可以说几乎是集所有优点于一身。正因如此，knitr 包和 tikzDevice 包将其引入 R 语言社区中。knitr 包的 tikz 引擎是用来编译 TikZ 代码的，默认使用的是 standalone 文类。\nR 语言绘图遇到公式时，略显不足，而排版公式是 LaTeX 的优势。正因为有所不足，所以我也不会纠结于工具层面的东西，什么好用用什么！三维 图 11.6 是用 LaTeX 里的优秀绘图工具 TikZ 制作的，细心的读者会发现本书多次用到这个工具。\n众所周知，Donald Knuth 十年磨一剑，开发了 TeX 排版系统，就是解决排版数学公式的痛点。如 图 11.13 所示，因图形中包含数学公式和符号，为了获得原汁原味的渲染效果，在使用 Base R 绘图的过程中通过 tikzDevice 包引入了 LaTeX 中的 TikZ 绘图引擎。\n\nopar &lt;- par(mgp = c(2, 0.7, 0), mar = c(4, 3, 4, 1) + 0.1, no.readonly = TRUE)\nset.seed(2021)\nx &lt;- rnorm(10)\ny &lt;- x + rnorm(5, sd = 0.25)\nlab &lt;- sample(\n  x = paste0(\"$\\\\mathcal{\", LETTERS, \"}$\"),\n  size = 10, replace = FALSE\n)\nmodel &lt;- lm(y ~ x)\nrsq &lt;- summary(model)$r.squared\nrsq &lt;- signif(rsq, 4)\nplot(x, y,\n  main = \"你好 \\\\LaTeX!\", # 引入 7 号文本字体\n  sub = \"$\\\\mathcal{N}(x;\\\\mu,\\\\Sigma)$\",\n  xlab = \"$x$\", ylab = \"$y$\", type = \"n\"\n)\ntext(x = x, y = y, labels = lab)\nabline(model, col = \"black\")\n# 引入 7 号数学字体\nmtext(paste(\"线性模型: $\\\\mathsf{R}^{2}=\", rsq, \"$\"), line = 0.5)\nlegend(\"bottomright\",\n  legend = paste0(\n    \"$y = \", round(coef(model)[2], 3), \"x +\",\n    round(coef(model)[1], 3), \"$\"\n  ),\n  bty = \"n\"\n)\non.exit(par(opar), add = TRUE)\n\n\n\n\n\n\n图 11.13: 简单线性模型\n\n\n\n\n图 11.14 是贝塞尔函数 \\(\\mathcal{K}_{\\kappa}(u)\\) 在区间 \\((10^{-8}, 10^2)\\) 和 \\((0, 4)\\) 上的图像。其中，图 11.14 (a) 是区间 \\((10^{-8}, 10^2)\\) 上的贝塞尔函数 \\(\\mathcal{K}_{\\kappa}(u)\\)， 图 11.14 (b) 是区间 \\((0, 4)\\) 上的贝塞尔函数 \\(\\mathcal{K}_{\\kappa}(u)\\) 。\nx0 &lt;- 2^(-20:10)\nnus &lt;- c(2:5, 10, 20)\nx &lt;- seq(0, 4, length.out = 501)\n\nplot(x0, x0^-8,\n  frame.plot = TRUE, # 添加绘图框\n  log = \"xy\",    # x 和 y 轴都取对数尺度\n  axes = FALSE,  # 去掉坐标轴\n  xlab = \"$u$\", ylab = \"$\\\\mathcal{K}_{\\\\kappa}(u)$\", # 设置坐标轴标签\n  type = \"n\", # 清除绘图区域的内容\n  ann = TRUE, # 添加标题 x和y轴标签\n  panel.first = grid() # 添加背景参考线\n)\n\naxis(1,\n  at = 10^(-8 + 2 * 0:5),\n  labels = paste0(\"$\\\\mathsf{10^{\", -8 + 2 * 0:5, \"}}$\")\n)\naxis(2,\n  at = 10^(-8 + 16 * 0:4),\n  labels = paste0(\"$\\\\mathsf{10^{\", -8 + 16 * 0:4, \"}}$\"), las = 1\n)\n\nfor (i in seq(length(nus))) {\n  lines(x0, besselK(x0, nu = nus[i]), col = hcl.colors(9)[i], lwd = 2)\n}\nlegend(\"topright\",\n  legend = paste0(\"$\\\\kappa=\", rev(nus), \"$\"),\n  col = hcl.colors(9, rev = TRUE), lwd = 2, cex = 1\n)\n\nx &lt;- seq(0, 4, length.out = 501)\nx &lt;- x[x &gt; 0]\nplot(x, x,\n  frame.plot = TRUE, ylim = c(1e+0, 1e+20), log = \"y\",\n  xlab = \"$u$\", ylab = \"$\\\\mathcal{K}_{\\\\kappa}(u)$\",\n  type = \"n\", yaxt = \"n\", ann = TRUE, panel.first = grid()\n)\naxis(2,\n  at = c(1e+0, 1e+05, 1e+10, 1e+15, 1e+20),\n  labels = paste0(\"$\\\\mathsf{10^{\", 5 * 0:4, \"}}$\"), las = 1\n)\n\nfor (i in seq(length(nus))) {\n  lines(x, besselK(x, nu = nus[i]), col = hcl.colors(9)[i], lwd = 2)\n}\nlegend(\"topright\",\n  legend = paste0(\"$\\\\kappa=\", rev(nus), \"$\"),\n  col = hcl.colors(9, rev = TRUE), lwd = 2, cex = 1\n)\n\n\n\n\n\n\n\n\n\n(a) 区间 \\((10^{-8}, 10^2)\\) 上的贝塞尔函数\n\n\n\n\n\n\n\n\n\n(b) 区间 \\((0, 4)\\) 上的贝塞尔函数\n\n\n\n\n\n\n图 11.14: 贝塞尔函数图像",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html",
    "href": "visualization-practice.html",
    "title": "12  探索实践",
    "section": "",
    "text": "12.1 分析老忠实间歇泉喷发规律\n图 12.1 展示美国怀俄明州黄石国家公园老忠实间歇泉喷发规律，横轴表示喷发持续时间（以分钟计），纵轴表示等待时间（以分钟计），点的亮暗程度（白到黑）代表附近点密度的高低，亮度值通过二维核密度估计方法得到，具体实现借助了 KernSmooth (Wand 和 Jones 1995) 包提供的 bkde2D() 函数，设置了喷发时间的窗宽为 0.7 分钟，等待时间的窗宽为 7分钟。不难看出，每等待 55 分钟左右间歇泉喷发约 2 分钟，或者每等待 80 分钟左右间歇泉喷发 4.5 约分钟，非常守时，表现得很老实，故而得名。说实话，二维核密度估计在这里有点大材小用了，因为数据点比较少，肉眼也能分辨出来哪里聚集的点多，哪里聚集的点少。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-faithful",
    "href": "visualization-practice.html#sec-faithful",
    "title": "12  探索实践",
    "section": "",
    "text": "代码# faithful 添加二维核密度估计 density 列\nlibrary(KernSmooth)\nden &lt;- bkde2D(x = faithful, bandwidth = c(0.7, 7), gridsize = c(51L, 51L))\nfaithful2d &lt;- expand.grid(eruptions = den$x1, waiting = den$x2) |&gt;\n  transform(density = as.vector(den$fhat))\n\nplot(faithful,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(0.5, 6.5),\n  ylim = c(35, 100)\n)\ntitle(xlab = \"喷发时间\", ylab = \"等待时间\", family = \"Noto Serif CJK SC\")\n\nplot(faithful,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(0.5, 6.5),\n  ylim = c(35, 100),\n  col = densCols(faithful,\n    bandwidth = c(0.7, 7),\n    nbin = c(51L, 51L), colramp = hcl.colors\n  )\n)\ntitle(xlab = \"喷发时间\", ylab = \"等待时间\", family = \"Noto Serif CJK SC\")\n\nplot(faithful,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(0.5, 6.5),\n  ylim = c(35, 100),\n  col = densCols(faithful,\n    bandwidth = c(0.7, 7),\n    nbin = c(51L, 51L), colramp = hcl.colors\n  )\n)\ncontour(den$x1, den$x2, den$fhat, nlevels = 10, add = TRUE, family = \"sans\")\ntitle(xlab = \"喷发时间\", ylab = \"等待时间\", family = \"Noto Serif CJK SC\")\n\n# 散点添加颜色\nmkBreaks &lt;- function(u) u - diff(range(u)) / (length(u) - 1) / 2\n# faithful 划入网格内\nxbin &lt;- cut(faithful[, 1], mkBreaks(den$x1), labels = FALSE)\nybin &lt;- cut(faithful[, 2], mkBreaks(den$x2), labels = FALSE)\n# 网格对应的核密度估计值即为 faithful 对应的核密度估计值\nfaithful$dens &lt;- den$fhat[cbind(xbin, ybin)]\n# 若是 faithful 数据点没有划分，则置为 0 \nfaithful$dens[is.na(faithful$dens)] &lt;- 0\n\nlibrary(ggplot2)\nlibrary(ggnewscale)\nggplot() +\n  geom_point(\n    data = faithful, aes(x = eruptions, y = waiting, color = dens),\n    shape = 20, size = 2, show.legend = FALSE\n  ) +\n  scale_colour_viridis_c(option = \"D\") +\n  new_scale_color() +\n  geom_contour(data = faithful2d, aes(\n    x = eruptions, y = waiting,\n    z = density, colour = after_stat(level)\n  ), bins = 14, linewidth = 0.45, show.legend = FALSE) +\n  scale_colour_viridis_c(option = \"C\", direction = -1, begin = 0.2, end = 0.8) +\n  # colorspace::scale_color_continuous_sequential(palette = \"Grays\") +\n  scale_x_continuous(breaks = 1:6) +\n  scale_y_continuous(breaks = 10 * 4:10) +\n  coord_cartesian(xlim = c(0.5, 6.5), ylim = c(35, 100)) +\n  labs(x = \"喷发时间\", y = \"等待时间\", colour = \"密度\") +\n  theme_bw(base_size = 13) +\n  theme(\n    legend.title = element_text(family = \"Noto Serif CJK SC\"),\n    axis.title = element_text(family = \"Noto Serif CJK SC\"),\n    axis.title.x = element_text(\n      margin = margin(b = 0, l = 0, t = 20, r = 0)\n    ),\n    axis.title.y = element_text(\n      margin = margin(b = 0, l = 0, t = 0, r = 20)\n    ),\n    panel.border = element_rect(color = \"black\"),\n    panel.grid = element_blank(),\n    panel.grid.major = element_line(\n      color = \"lightgray\",\n      linetype = 3, linewidth = 0.5\n    ),\n    axis.ticks.length = unit(0.25, \"cm\"),\n    axis.text.x = element_text(\n      family = \"sans\", color = \"black\",\n      vjust = -1.5, size = rel(1.25)\n    ),\n    axis.text.y = element_text(\n      family = \"sans\", color = \"black\",\n      angle = 90, vjust = 1.5, hjust = 0.5,\n      size = rel(1.25)\n    )\n  )\n\n\n\n\n\n\n\n\n\n(a) faithful 数据集的散点图\n\n\n\n\n\n\n\n\n\n(b) 点的亮暗表示核密度估计值的大小\n\n\n\n\n\n\n\n\n\n\n\n(c) 等高线表示核密度估计值\n\n\n\n\n\n\n\n\n\n(d) 等高线表示核密度估计值\n\n\n\n\n\n\n图 12.1: 二维核密度估计\n\n\n\n\n\n\n\n\n提示\n\n\n\n函数 bkde2D() 实现二维带窗宽的核密度估计（2D Binned Kernel Density Estimate），R 语言存在多个版本，grDevices 包的函数 densCols() 直接调用 KernSmooth 包的函数 bkde2D()，graphics 包的函数 smoothScatter() 与函数 densCols() 一样，内部也是调用 bkde2D() 函数，ggplot2 包的图层 geom_density_2d() 采用 MASS 包的函数 kde2d()，在算法实现上，MASS::kde2d() 与 KernSmooth::bkde2D() 不同，前者是二维核密度估计（Two-Dimensional Kernel Density Estimation）。Tarn Duong 的著作 《Multivariate Kernel Smoothing and Its Applications 》 (José. Chacón 2018) 对多元核平滑方法及其应用作了专门的论述，相关实现见书籍配套的 ks 包。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-china-household-sex",
    "href": "visualization-practice.html#sec-china-household-sex",
    "title": "12  探索实践",
    "section": "\n12.2 中国地区级男女性别比分布",
    "text": "12.2 中国地区级男女性别比分布\n图 12.2 (a) 展示 2020 年中国各省、自治区和直辖市分城市、镇和乡村的性别比数据。数据来自中国国家统计局发布的 2021 年统计年鉴，在数据量不太大的情况下，尽可能展示原始数据，可以捕捉到更加细致的差异。社会经济相关的数据常常显示有马太效应，对原始数据适当做一些变换有利于比较和展示数据，图 12.2 (b) 展示对数变换后的性别比数据的分布。大部分地区的性别比数据都在 100:100 左右，流动人口的性别比波动大很多。\n\n代码china_household_sex &lt;- readRDS(file = \"data/china-household-sex-2020.rds\")\nggplot(data = china_household_sex, aes(x = `户口登记状况`, y = `男性` / `女性`)) +\n  geom_jitter(aes(color = `区域`), width = 0.3) +\n  theme_classic()\n\nggplot(data = china_household_sex, aes(x = `户口登记状况`, y = `男性` / `女性`)) +\n  geom_jitter(aes(color = `区域`), width = 0.3) +\n  scale_y_continuous(trans = \"log10\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n(a) 原始性别比数据\n\n\n\n\n\n\n\n\n\n(b) 对数变换后的性别比数据\n\n\n\n\n\n图 12.2: 2020 年中国地区级男女性别比分布\n\n\n\n\n「住本乡、镇、街道，户口在本乡、镇、街道」土著和已获得当地户口的。性别比分布有明显的层次差异，性别比均值从大到小依次是城市、乡村、镇。城市里，男性略多于女性，镇里，男性明显少于女性，乡村里，男性略低于女性。\n「住本乡、镇、街道，户口待定」黑户或其它。性别比分布有明显的层次差异。同上。\n「住本乡、镇、街道，户口在外乡、镇、街道，离开户口登记地半年以上」流出人口，流出乡、镇、街道。城市、镇、乡村的性别比数据充分混合了，性别比分布没有明显的层次差异。\n「居住在港澳台或国外，户口在本乡、镇、街道」流出人口，流出国。同上。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-usa-mortality",
    "href": "visualization-practice.html#sec-usa-mortality",
    "title": "12  探索实践",
    "section": "\n12.3 美国历年各年龄死亡率变化",
    "text": "12.3 美国历年各年龄死亡率变化\n\n图 12.3 展示美国 1933-2020 年男性分年龄的死亡率数据1。图分上下两部分，上半部分展示死亡率原值随年龄的变化情况，以 ggplot2 默认的调色板给各个年份配色，下半部分展示死亡率对数变换后随年龄的变化情况，并以红、橙、黄、绿、青、蓝、紫构造彩虹式的调色板给各个年份配色。作图过程中，使用对数变换和调用彩虹式的调色板，帮助我们观察到更多的细节、层次。对数变换后，更加清晰地展示死亡率的变化，尤其是 0-20 岁之间的死亡率起伏变化。调用彩虹式的调色板后，约 20 年为一个阶段，每个阶段内呈现梯度变化，多个阶段体现层次性，更加清晰地展示死亡率曲线的变动趋势。透过层次看到 80 多年来，美国在医疗和公共卫生方面取得的显著改善。\n\n代码usa_mortality &lt;- readRDS(file = \"data/usa-mortality-2020.rds\")\nlibrary(patchwork)\np1 &lt;- ggplot(data = usa_mortality, aes(x = Age, y = Male, group = Year)) +\n  geom_vline(xintercept = \"100\", colour = \"gray\", lty = 2) +\n  geom_line(aes(color = Year), linewidth = 0.25) +\n  scale_x_discrete(\n    breaks = as.character(20 * 0:5),\n    labels = as.character(20 * 0:5)\n  ) +\n  theme_classic() \np2 &lt;- p1 +\n  labs(x = \"年龄\", y = \"死亡率\", color = \"年份\")\np3 &lt;- p1 +\n  scale_y_log10(labels = scales::label_log()) +\n  scale_colour_gradientn(colors = RColorBrewer::brewer.pal(name = \"Spectral\", n = 11)) +\n  labs(x = \"年龄\", y = \"死亡率（对数尺度）\", color = \"年份\")\np2 / p3\n\n\n\n\n\n\n图 12.3: 1933-2020 年美国男性死亡率曲线\n\n\n\n\n图 12.3 也展示了很多基础信息，出生时有很高的死亡率，出生后死亡率迅速下降，一直到10岁，死亡率才又开始回升，直到 20 岁，死亡率才回到出生时的水平。之后，在青年阶段死亡率缓慢增加，直至老年阶段达到很高的死亡率水平。相比于老年阶段，医疗水平的改善作用主要体现在婴儿、儿童、青少年阶段。\n图 12.3 还展示了一个潜在的数据质量问题，在 100 岁之后，死亡率波动程度明显在变大，这是因为高龄人数变得很少，即死亡率的分母变得很小，分子的细小波动会被放大，也因为同样的原因，100 岁以上的死亡率主要依赖模型估计，甚至出现死亡率大于 1 的罕见情况。因此，就对比医疗和公共卫生水平的变化而言，从数据的实际情况出发，100 岁以上的情况可以不参与比较。\n图 12.4 以年份为横轴，以年龄为纵轴绘制网格，网格内部根据男性死亡率数据填充颜色制作热力图，死亡率数据是对数尺度，颜色的变化和死亡率的变化关系同前，采用了相同的调色板。更加深入的分析和建模，详见 Marron 和 Dryden (2022) 的第一章。\n\n代码ggplot(data = usa_mortality, aes(x = Year, y = Age, fill = Male)) +\n  scale_fill_gradientn(\n    colors = RColorBrewer::brewer.pal(name = \"Spectral\", n = 11),\n    trans = \"log10\", labels = scales::percent_format()\n  ) +\n  geom_tile(linewidth = 0.4) +\n  scale_y_discrete(\n    breaks = as.character(10 * 0:10),\n    labels = as.character(10 * 0:10),\n    expand = c(0, 0)\n  ) +\n  scale_x_continuous(\n    breaks = 1940 + 10 * 0:8,\n    labels = 1940 + 10 * 0:8,\n    expand = c(0, 0)\n  ) + \n  theme_classic() +\n  labs(x = \"年份\", y = \"年龄\", fill = \"死亡率\")\n\n\n\n\n\n\n图 12.4: 1933-2020 年美国男性死亡率热力图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-virginia-deaths",
    "href": "visualization-practice.html#sec-virginia-deaths",
    "title": "12  探索实践",
    "section": "\n12.4 美国弗吉尼亚州城乡死亡率",
    "text": "12.4 美国弗吉尼亚州城乡死亡率\nVADeaths 数据来自 Base R 内置的 datasets 包，记录 1940 年美国弗吉尼亚州死亡率，如下表。\n\n\n\n表格 12.1: 1940 年美国弗吉尼亚州死亡率\n\n\n\n\n\n农村男\n农村女\n城市男\n城市女\n\n\n\n50-54\n11.7\n8.7\n15.4\n8.4\n\n\n55-59\n18.1\n11.7\n24.3\n13.6\n\n\n60-64\n26.9\n20.3\n37.0\n19.3\n\n\n65-69\n41.0\n30.9\n54.6\n35.1\n\n\n70-74\n66.0\n54.3\n71.1\n50.0\n\n\n\n\n\n\n\n\n死亡率数据是按年龄段、城乡、性别分组统计的，这是一个三因素交叉统计表，表格中第1行第1列的数据表示 50-54 岁乡村男性的死亡率为 11.7 ‰ ，即在 50-54 岁乡村男性群体中，1000 个人中死亡 11.7 个，这是抽样调查出来的数字。下图分年龄段、城乡、性别展示弗吉尼亚州死亡率数据，从图例来看，突出的是各年龄段的对比，图主要传递的信息是各年龄段的死亡率差异。无论城市还是乡村，也无论男性还是女性，年龄越大死亡率越高，这完全是一个符合生物规律的客观事实，这是众人皆知的，算不上洞见。\n\n代码dat &lt;- transform(expand.grid(\n  site = c(\"乡村\", \"城镇\"), sex = c(\"男\", \"女\"), \n  age = ordered(c(\"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\"))\n), deaths = as.vector(t(VADeaths)) / 1000)\n\nlibrary(ggplot2)\n# (\\u2030) 表示千分号\nggplot(data = dat, aes(x = sex, y = deaths, fill = age)) +\n  geom_col(position = \"dodge2\") +\n  scale_y_continuous(labels = scales::label_percent(scale = 1000, suffix = \"\\u2030\")) +\n  scale_fill_brewer(palette = \"Spectral\") +\n  facet_wrap(~site, ncol = 1) +\n  theme_bw(base_size = 13) +\n  labs(x = \"性别\", y = \"死亡率\", fill = \"年龄\")\n\n\n\n\n\n\n图 12.5: 弗吉尼亚州各年龄段死亡率的对比\n\n\n\n\n将对比对象从年龄段转变为城乡，描述城乡差距在死亡率上的体现，是不是一下子更深刻了呢？城市降低各个年龄段的死亡率，暗示着城市的居住条件、医疗水平比乡村好，提高城市化率增加全民的寿命。严格来说，就这个粗糙的数据集不能如此快地下这个结论，但是，它暗示这个信息，同样也符合人们的常识。\n\n代码ggplot(data = dat, aes(x = age, y = deaths, fill = site)) +\n  geom_col(position = \"dodge2\") +\n  scale_y_continuous(labels = scales::label_percent(scale = 1000, suffix = \"\\u2030\")) +\n  scale_fill_brewer(palette = \"Spectral\") +\n  facet_wrap(~sex, ncol = 1) +\n  theme_bw(base_size = 13) +\n  labs(x = \"年龄\", y = \"死亡率\", fill = \"城乡\")\n\n\n\n\n\n\n图 12.6: 弗吉尼亚州城乡死亡率的对比",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-diamonds-distr",
    "href": "visualization-practice.html#sec-diamonds-distr",
    "title": "12  探索实践",
    "section": "\n12.5 如何用图表示累积概率分布",
    "text": "12.5 如何用图表示累积概率分布\n不失一般性，考虑连续随机变量的条件分布和累积分布。不妨设随机变量 \\(x\\) 的概率分布函数和概率密度函数分别是 \\(F(x)\\) 和 \\(f(x)\\) 。已知概率分布函数和概率密度函数之间有如下关系。\n\\[\nF(x) = \\int_{-\\infty}^{x} f(t) \\mathrm{dt}\n\\]\ndiamonds 数据来自 ggplot2 包，记录了约 54000 颗钻石的价格、重量、切工、颜色、纯净度、尺寸等属性信息。图 12.7 展示这批不同切工的钻石随价格的分布，在这个示例中，如何表达累积分布？概率分布的密度曲线是根据直方图估计得来的，根据不同价格区间内钻石的数量占总钻石的比例估计概率。固定窗宽，即在同一价格区间内累积不同切工的钻石数量，得到累积概率，最后获得累积概率密度曲线，更多理论细节见数据可视化陷阱 (Pu 和 Kay 2020) 。\n\n代码library(ggplot2)\nlibrary(patchwork)\np1 &lt;- ggplot(diamonds, aes(x = price, y = after_stat(density), fill = cut)) +\n  geom_density(position = \"stack\", colour = \"white\") +\n  scale_fill_brewer(palette = \"Spectral\") +\n  scale_y_continuous(\n    labels = expression(0, 5~\"·\"~10^-4, 10 ~ \"·\" ~ 10^-4, 15 ~ \"·\" ~ 10^-4),\n    breaks = c(0, 5, 10, 15) * 10^(-4)\n  ) +\n  theme_bw(base_family = \"Noto Serif CJK SC\") +\n  labs(x = \"价格\", y = \"概率密度\", fill = \"切工\", tag = \"坏\") +\n  theme(\n    axis.text.x = element_text(family = \"sans\", color = \"black\"),\n    axis.text.y = element_text(\n      family = \"sans\", color = \"black\",\n      angle = 90, vjust = 1.5, hjust = 0.5\n    ),\n    legend.text = element_text(family = \"sans\"),\n    plot.tag = element_text(family = \"Noto Serif CJK SC\", color = \"red\"),\n    plot.tag.position = \"topright\"\n  )\n\np2 &lt;- ggplot(diamonds, aes(x = price, y = after_stat(density * n), fill = cut)) +\n  geom_density(position = \"stack\", colour = \"white\") +\n  scale_fill_brewer(palette = \"Spectral\") +\n  theme_bw(base_family = \"Noto Serif CJK SC\") +\n  labs(x = \"价格\", y = \"概率质量\", fill = \"切工\", tag = \"好\") +\n  theme(\n    axis.text.x = element_text(family = \"sans\", color = \"black\"),\n    axis.text.y = element_text(\n      family = \"sans\", color = \"black\",\n      angle = 90, vjust = 1.5, hjust = 0.5\n    ),\n    legend.text = element_text(family = \"sans\"),\n    plot.tag = element_text(family = \"Noto Serif CJK SC\", color = \"black\"),\n    plot.tag.position = \"topright\"\n  )\n\np1 / p2\n\n\n\n\n\n\n图 12.7: 不同切工的钻石随价格的分布",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-confidence-belt",
    "href": "visualization-practice.html#sec-confidence-belt",
    "title": "12  探索实践",
    "section": "\n12.6 解释二项总体参数的置信带",
    "text": "12.6 解释二项总体参数的置信带\n0 和 1 是世界的原点，蕴含大道真意，从 0-1 分布也叫伯努利分布，独立同 0-1分布之和可以衍生出二项分布。在一定条件下，可以用泊松分布近似二项分布。根据中心极限定理，独立同二项分布的极限和与正态分布可以发生关系。在二项分布、正态分布的基础上，可以衍生出超几何分布、贝塔分布等等。本书多个地方以二项分布为例介绍基本统计概念和模型。\n在给定置信水平为 0.95，即 \\(\\alpha = 0.05\\)，固定样本量 \\(n = 10\\)，观测到的成功次数 \\(x\\) 可能为 \\(0,1,\\cdots,10\\)。对于给定的 \\(p\\)，不同 \\(x\\) 值出现的机率 \\(P(X = x)\\) 由 \\((p + q)^{10}\\) 二项展开式的项给出，这里 \\(q = 1-p\\)，即：\n\\[\nP(X = x) = \\binom{n}{x}p^x(1-p)^{n-x}\n\\tag{12.1}\\]\n在给定 \\(p = 0.1\\) 的情况下，求二项分布的上 \\(\\alpha/2 = 0.025\\) 分位点，尾项之和不应超过 \\(\\alpha/2\\)，最大的 \\(x\\) 值可有如下方程给出：\n\\[\n\\sum_{r = x}^{n}\\binom{n}{x}p^x(1-p)^{n-x} = \\frac{\\alpha}{2}\n\\tag{12.2}\\]\n在 R 语言中，函数 qbinom() 可以计算上述二项分布的上分位点 \\(x = 3\\)，即\n\nqbinom(0.025, size = 10, prob = 0.1, lower.tail = F)\n\n#&gt; [1] 3\n\n\n反过来，若已知上分位点为 \\(x = 3\\)，则概率为\n\\[\nP(X &gt; 3) = \\sum_{x &gt; 3}^{10}\\binom{10}{x}0.1^x*(1-0.1)^{10-x}\n\\tag{12.3}\\]\n在 R 语言中，函数 pbinom() 可以计算上述二项分布的上分位点对应的概率为 \\(0.0127952\\)。\n\npbinom(q = 3, size = 10, prob = 0.1, lower.tail = F)\n\n#&gt; [1] 0.0127952\n\n\n首先简单回顾一下置信区间，在学校和教科书里，有两种说法如下：\n\n\n\\(1-\\alpha\\) 的把握确定区间包含真值。\n区间包含真值的概率是 \\(1-\\alpha\\)。\n\n为什么要采纳第一种说法而不是第二种呢？这其实涉及到置信区间的定义问题，历史上 E. S. Pearson 和 R. A. Fisher 曾有过争论。和大多数以正态分布为例介绍参数的置信估计不同，下面以二项分布为例展开介绍。我们知道二项分布是 N 个伯努利分布的卷积，而伯努利分布又称为 0-1 分布，最形象的例子要数抛硬币了，反复投掷硬币，将正面朝上记为 1，反面朝上记为 0，记录正反面出现的次数，正面朝上的总次数又叫成功次数。\n1934 年 C. J. Clopper 和 E. S. Pearson 在给定置信水平 \\(1- \\alpha = 0.95\\) 和样本量 \\(n = 10\\) 的情况下，给出二项分布 \\(B(n, p)\\) 参数 \\(p\\) 的区间估计（即所谓的 Clopper-Pearson 精确区间估计）和置信带 (Clopper 和 Pearson 1934)，如 图 12.8 所示，横坐标为观测到的成功次数，纵坐标为参数 \\(p\\) 的置信限。具体来说，固定样本量为 10，假定观测到的成功次数为 2，在置信水平为 0.95 的情况下，Base R 内置的二项精确检验函数 binom.test()，可以获得参数 \\(p\\) 的精确区间估计为 \\((p_1, p_2) = (0.025, 0.556)\\)，即：\n\n# 精确二项检验 p = 0.2\nbinom.test(x = 2, n = 10, p = 0.2)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  2 and 10\n#&gt; number of successes = 2, number of trials = 10, p-value = 1\n#&gt; alternative hypothesis: true probability of success is not equal to 0.2\n#&gt; 95 percent confidence interval:\n#&gt;  0.02521073 0.55609546\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                    0.2\n\n\n值得注意，这个估计的区间与函数 binom.test() 中参数 p 的取值无关，也就是说，当 \\(p = 0.4\\)，区间估计结果是一样的，如下：\n\n# 精确二项检验 p = 0.4\nbinom.test(x = 2, n = 10, p = 0.4)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  2 and 10\n#&gt; number of successes = 2, number of trials = 10, p-value = 0.3335\n#&gt; alternative hypothesis: true probability of success is not equal to 0.4\n#&gt; 95 percent confidence interval:\n#&gt;  0.02521073 0.55609546\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                    0.2\n\n\n由此，也可以看出区间估计与假设检验的一些关系。\n\n\n代码library(rootSolve) # uniroot.all\noptions(digits = 4)\n# r 为上分位点\np_fun &lt;- function(p, r = 9) qbinom(0.025, size = 10, prob = p, lower.tail = F) - r # 上分位点\nl_fun &lt;- function(p, r = 9) qbinom(0.025, size = 10, prob = p, lower.tail = T) - r # 下分位点\n\n# 计算每个分位点对应的最小的概率 p\np &lt;- sapply(0:10, function(x) min(uniroot.all(p_fun, lower = 0, upper = 1, r = x)))\n\n# 计算每个分位点对应的最大的概率 l\nl &lt;- sapply(0:10, function(x) max(uniroot.all(l_fun, lower = 0, upper = 1, r = x)))\n\nplot(\n  x = seq(from = 0, to = 10, length.out = 11),\n  y = seq(from = 0, to = 1, length.out = 11),\n  type = \"n\", ann = FALSE, family = \"sans\", panel.first = grid()\n)\ntitle(xlab = \"成功次数\", ylab = \"置信限\", family = \"Noto Serif CJK SC\")\nlines(x = 0:10, y = p, type = \"s\") # 朝下的阶梯线\nlines(x = 0:10, y = p, type = \"l\") # 折线\n# points(x = 0:10, y = p, pch = 16, cex = .8) # 散点\n\n# abline(a = 0, b = 0.1, col = \"gray\", lwd = 2, lty = 2) # 添加对称线\ntext(x = 5, y = 0.5, label = \"置信带\", cex = 1.5, srt = 45, family = \"Noto Serif CJK SC\")\n# points(x = 5, y = 0.5, col = \"black\", pch = 16) # 中心对称点\n# points(x = 5, y = 0.5, col = \"black\", pch = 3) # 中心对称点\n\nlines(x = 0:10, y = l, type = \"S\") # 朝上的阶梯线\nlines(x = 0:10, y = l, type = \"l\") # 折线\n# points(x = 0:10, y = l, pch = 16, cex = .8) # 散点\n\npoints(x = c(2, 2), y = c(0.03, 0.55), pch = 8, col = \"black\")\ntext(x = 2, y = 0.55, labels = expression(p[2]), pos = 1)\ntext(x = 2, y = 0.03, labels = expression(p[1]), pos = 3)\n\n\n\n\n\n\n图 12.8: 二项分布参数的置信带",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-coverage-probability",
    "href": "visualization-practice.html#sec-coverage-probability",
    "title": "12  探索实践",
    "section": "\n12.7 解释置信区间及其覆盖概率",
    "text": "12.7 解释置信区间及其覆盖概率\n\n统计图形很重要的一个作用是解释统计概念，这就要求不拘泥于抽象的严格数学表达，借助数值模拟，可视化等手段帮助读者发散思维，加深理解复杂的逻辑概念，建立统计直觉，正如顾恺之所言「以形写神，形神兼备」。下面仅以二项分布为例讲讲区间估计及其覆盖概率。众所周知，在置信水平为 \\(1 - \\alpha\\) 的情况下，二项分布 \\(\\mathrm{Bin}(n,p)\\) 的参数 \\(p\\) （也叫成功概率）的 Wald 区间估计为\n\\[\n(\\hat{p} - Z_{1-\\alpha/2} \\sqrt{\\hat{p}*(1-\\hat{p})/n}, \\hat{p} + Z_{1-\\alpha/2} \\sqrt{\\hat{p}*(1-\\hat{p})/n})\n\\tag{12.4}\\]\n其中，\\(n\\) 为样本量，\\(Z_{1-\\alpha/2}\\) 为标准正态分布 \\(\\mathcal{N}(0,1)\\) 在 \\(1-\\alpha/2\\) 处的分位点。 \\(\\alpha\\) 一般取 0.05，进而 \\(Z_{1-\\alpha/2} \\approx 1.96\\)。用通俗的话说，有 \\(1 - \\alpha\\) 的把握确定参数真值 \\(p\\) 在该估计区间内。可见区间估计的意义是解决点估计可靠性问题，但是可靠性和精度往往不能兼得。统计上，通常的做法是先给定可靠性，去尽可能提升精度，即给定置信水平，使估计区间的长度尽可能短，这就涉及到区间估计的方法问题。\n下面通过数值模拟的方式辅助说明 Wald 和 Agresti-Coull 两种区间估计方法，现固定样本量 \\(n = 10\\) 或 \\(n = 100\\)，重复抽样 1000 次，将参数 \\(p\\) 以 0.01 的间隔离散化，从 0.01 取值到 0.99。已知给定参数 \\(p\\)，每次抽样都可以得到参数 \\(p\\) 的估计值 \\(\\hat{p}\\) 及其置信区间，1000 次的重复抽样可以计算出来 1000 个置信区间，每个区间要么覆盖真值，要么没有覆盖真值，覆盖的比例可以近似为覆盖概率。\n如 图 12.9 所示，从上往下分别代表 Wald、 Agresti-Coull、 Wilson 和 Clopper-Pearson 区间估计，纵坐标是覆盖概率，横坐标是参数 \\(p\\) 的真值，图中黑虚线表示置信水平 \\(1-\\alpha=0.95\\)，红、蓝点线分别表示样本量 \\(n=10\\) 和 \\(n=100\\) 的模拟情况。不难看出，Wald 区间估计方法在小样本情况下表现很差，覆盖概率很少能达到置信水平的，而 Agresti-Coull 区间估计在 Wald 基础上添加了修正后，情况得到显著改善。更多区间估计方法的详细比较见文献 Blyth 和 Hutchinson (1960);Brown, Cai, 和 DasGupta (2001);Geyer 和 Meeden (2005) 。\n\n代码# 计算覆盖概率\n# Wald 覆盖\ncoverage_wald &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  phats &lt;- rbinom(nsim, prob = p, size = n) / n\n  ll &lt;- phats - qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  ul &lt;- phats + qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  mean(ll &lt; p & ul &gt; p)\n}\n# Agresti-Coull 覆盖\ncoverage_agresti &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  phats &lt;- (rbinom(nsim, prob = p, size = n) + 2) / (n + 4)\n  ll &lt;- phats - qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  ul &lt;- phats + qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  mean(ll &lt; p & ul &gt; p)\n}\n# Clopper and Pearson (1934)\n# 与 binom.test() 计算结果一致\ncoverage_clopper &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  nd &lt;- rbinom(nsim, prob = p, size = n)\n  ll &lt;- qbeta(p = 0.05 / 2, shape1 = nd, shape2 = n - nd + 1)\n  ul &lt;- qbeta(p = 1 - 0.05 / 2, shape1 = nd + 1, shape2 = n - nd)\n  mean(ll &lt; p & ul &gt; p)\n}\n# Wilson (1927)\n# 与 prop.test(correct = FALSE) 计算结果一致\ncoverage_wilson &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  phats &lt;- rbinom(nsim, prob = p, size = n) / n\n  lambda &lt;- qnorm(1 - 0.05 / 2)\n  ll &lt;- phats + lambda^2 / (2 * n) - lambda * sqrt(phats * (1 - phats) / n + lambda^2 / (4 * n^2))\n  ul &lt;- phats + lambda^2 / (2 * n) + lambda * sqrt(phats * (1 - phats) / n + lambda^2 / (4 * n^2))\n  mean(ll / (1 + lambda^2 / n) &lt; p & ul / (1 + lambda^2 / n) &gt; p)\n}\n\nsim_dat &lt;- transform(expand.grid(\n  p = seq(0.01, 0.99, by = 0.01),\n  n = c(10, 100),\n  nsim = 1000,\n  methods = c(\"Wald\", \"Agresti-Coull\", \"Wilson\", \"Clopper-Pearson\")\n), prob = ifelse(methods == \"Wald\",\n  Vectorize(coverage_wald)(p = p, n = n, nsim = nsim),\n  ifelse(methods == \"Agresti-Coull\",\n    Vectorize(coverage_agresti)(p = p, n = n, nsim = nsim),\n    ifelse(methods == \"Wilson\",\n      Vectorize(coverage_wilson)(p = p, n = n, nsim = nsim),\n      Vectorize(coverage_clopper)(p = p, n = n, nsim = nsim)\n    )\n  )\n), nsample = ifelse(n == 10, \"n=10\", \"n=100\"))\n\nggplot(data = sim_dat, aes(x = p, y = prob, color = nsample)) +\n  geom_hline(yintercept = 0.95, linetype = 2, \n             linewidth = 1, color = \"gray60\") +\n  geom_point() +\n  geom_path() +\n  # annotate(geom = \"text\", x = 0, y = 0.95, label = \"0.950\",\n  #          fontface = \"bold\", hjust = 2, size = 3.5) +\n  # scale_color_grey() +\n  scale_color_brewer(palette = \"Set1\") +\n  facet_wrap(facets = ~methods, ncol = 1, scales = \"free_y\") +\n  labs(x = \"成功概率\", y = \"覆盖概率\", color = \"样本量\") +\n  theme_bw(base_size = 13, base_family = \"sans\") +\n  theme(title = element_text(family = \"Noto Serif CJK SC\")) + \n  coord_cartesian(clip = 'off')\n\n\n\n\n\n\n图 12.9: 二项分布参数的几种区间估计：覆盖概率随成功概率的变化\n\n\n\n\n通过 图 12.9 一看就明白了几种区间估计方法的优劣，以及为什么软件普遍默认采用 Wilson 估计方法？因为它又稳定又准确。 Wilson 区间估计用的更加广泛的，Base R 内置的比例检验函数 prop.test() 在不启用 Yates 修正时，就是用该方法获得比例 \\(p\\) 的区间估计 (Wilson 1927)。Clopper-Pearson 区间估计特别适合小样本情形，它是精确区间估计方法，Base R 内置的二项比例检验函数 binom.test() 就是用该方法获得比例 \\(p\\) 的区间估计(Clopper 和 Pearson 1934)。\n\n\n\n\n\n\n提示\n\n\n\n请读者再思考两个问题： 图 12.9 为什么呈现对称的形式，泊松分布会和二项分布有类似的现象吗？如果有的话，连续分布，如正态分布和指数分布也会有吗？",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-exercise-practice",
    "href": "visualization-practice.html#sec-exercise-practice",
    "title": "12  探索实践",
    "section": "\n12.8 习题",
    "text": "12.8 习题\n\n1888 年，瑞士开始进入一个人口转变的阶段，从发展中国家的高出生率开始下滑。分析生育率和经济指标的关系。数据集 swiss 记录了 1888 年瑞士 47 个说法语的省份的生育率和社会经济指标数据。Fertility（生育率，采用常见的标准生育率统计口径）、Agriculture（男性从事农业生产的比例）、Examination（应征者在军队考试中获得最高等级的比例）、Education（应征者有小学以上教育水平的比例）、Catholic（信仰天主教的比例）、Infant.Mortality（婴儿死亡率，仅考虑出生一年内死亡），各个指标都统一标准化为百分比的形式。其中，Examination 和 Education 是 1887 年、1888 年和 1889 年的平均值。瑞士 182 个地区 1888 年及其它年份的数据可从网站获得。\n\n\n\n\n\nBlyth, Colin R., 和 David W. Hutchinson. 1960. 《Table of Neyman-Shortest Unbiased Confidence Intervals for the Binomial Parameter》. Biometrika 47 (3/4): 381–91. https://www.jstor.org/stable/2333308.\n\n\nBrown, Lawrence D., T. Tony Cai, 和 Anirban DasGupta. 2001. 《Interval Estimation for a Binomial Proportion》. Statistical Science, 期 2: 101–33. https://projecteuclid.org/euclid.ss/1009213286.\n\n\nClopper, C. J., 和 E. S. Pearson. 1934. 《The Use of Confidence or Fiducial Limits Illustrated In The Case of The Binomial》. Biometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nGeyer, Charles J., 和 Glen D. Meeden. 2005. 《Fuzzy and Randomized Confidence Intervals and P-Values》. Statistical Science 20 (4): 358–66. https://www.jstor.org/stable/20061193.\n\n\nJosé. Chacón, Tarn Duong. 2018. Multivariate Kernel Smoothing and Its Applications. Boca Raton, Florida: Chapman; Hall/CRC. https://www.mvstat.net/mvksa/.\n\n\nMarron, J. S., 和 Ian L. Dryden. 2022. Object Oriented Data Analysis. 1st 本. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nPu, Xiaoying, 和 Matthew Kay. 2020. 《A Probabilistic Grammar of Graphics》. 收入 Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1–13. ACM. https://doi.org/10.1145/3313831.3376466.\n\n\nWand, M. P., 和 M. C. Jones. 1995. Kernel Smoothing. 1st 本. Boca Raton, Florida: Chapman; Hall/CRC. http://matt-wand.utsacademics.info/webWJbook/.\n\n\nWilson, Edwin B. 1927. 《Probable inference, the law of succession, and statistical inference》. Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#footnotes",
    "href": "visualization-practice.html#footnotes",
    "title": "12  探索实践",
    "section": "",
    "text": "数据来自德国马克斯普朗克人口研究所、美国加州大学伯克利分校、法国人口研究所共同建立的人类死亡率数据库 (https://www.mortality.org/)。↩︎",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html",
    "href": "interactive-graphics.html",
    "title": "13  交互图形",
    "section": "",
    "text": "13.1 基础元素",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-interactive-elements",
    "href": "interactive-graphics.html#sec-interactive-elements",
    "title": "13  交互图形",
    "section": "",
    "text": "13.1.1 图层\nplotly 包封装了许多图层函数，可以绘制各种各样的统计图形，见下 表格 13.1 。\n\n\n表格 13.1: plotly 包可以绘制丰富的统计图形\n\n\n\nadd_annotations\nadd_histogram\nadd_polygons\n\n\nadd_area\nadd_histogram2d\nadd_ribbons\n\n\nadd_bars\nadd_histogram2dcontour\nadd_scattergeo\n\n\nadd_boxplot\nadd_image\nadd_segments\n\n\nadd_choropleth\nadd_lines\nadd_sf\n\n\nadd_contour\nadd_markers\nadd_surface\n\n\nadd_data\nadd_mesh\nadd_table\n\n\nadd_fun\nadd_paths\nadd_text\n\n\nadd_heatmap\nadd_pie\nadd_trace\n\n\n\n\n\n下面以散点图为例，使用方式非常类似 ggplot2 包，函数 plot_ly() 类似 ggplot()，而函数 add_markers() 类似 geom_point()，效果如 图 13.1 所示。\n\n# https://plotly.com/r/reference/scatter/\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers()\n\n\n\n\n\n\n\n\n图 13.1: 默认风格的简单散点图\n\n\n\n\n或者使用函数 add_trace()，层层添加图形元素，效果和上 图 13.1 是一样的。\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_trace(type = \"scatter\", mode = \"markers\")\n\n\n\n\n\n\n\n提示\n\n\n\nplotly 包的函数 plot_ly() 又与 ggplot2 包中函数 qplot() 类似，可以将大部分设置塞进去。\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  type = \"scatter\", mode = \"markers\"\n)\n\n所以，总的来说， add_markers() 、add_trace(type = \"scatter\", mode = \"markers\") 和 plot_ly(type = \"scatter\", mode = \"markers\") 是等价的。\n\n\n\n13.1.2 配色\n在 图 13.1 的基础上，将颜色映射到震级变量上。\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers(color = ~mag)\n\n\n\n\n\n\n图 13.2: 给散点图配色\n\n\n\n\n13.1.3 刻度\n东经和南纬\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers(color = ~mag) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\", ticksuffix = 'E'),\n    yaxis = list(title = \"纬度\", ticksuffix = 'S')\n  )\n\n\n\n\n\n\n图 13.3: 设置刻度及标签\n\n\n\n\n13.1.4 标签\n添加横轴、纵轴以及主副标题\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  marker = list(\n    color = ~mag,\n    colorscale = \"Viridis\",\n    colorbar = list(title = list(text = \"震级\"))\n  )\n) |&gt;\n  plotly::add_markers() |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\"),\n    title = \"斐济及其周边地区的地震活动\"\n  )\n\n\n\n\n\n\n图 13.4: 添加各处标题\n\n\n\n\n13.1.5 主题\nplotly 内置了一些主题风格\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  marker = list(\n    color = ~mag,\n    colorscale = \"Viridis\",\n    colorbar = list(title = list(text = \"震级\"))\n  )\n) |&gt;\n  plotly::add_markers() |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\"),\n    title = \"斐济及其周边地区的地震活动\"\n  )\n\n\n\n\n\n\n图 13.5: 设置主题风格\n\n\n\n\n13.1.6 字体\n\n13.1.7 图例",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-plotly-common-graphics",
    "href": "interactive-graphics.html#sec-plotly-common-graphics",
    "title": "13  交互图形",
    "section": "\n13.2 常用图形",
    "text": "13.2 常用图形\n\n13.2.1 散点图\nplotly 包支持绘制许多常见的散点图，从直角坐标系 scatter 到极坐标系 scatterpolar 和地理坐标系 scattergeo，从二维平面 scatter 到三维空间 scatter3d，借助 WebGL 可以渲染大规模的数据点 scattergl。\n\n\n表格 13.2: plotly 包支持绘制的散点图类型\n\n\n\n类型\n名称\n\n\n\nscatter\n二维平面散点图\n\n\nscatter3d\n三维立体散点图\n\n\nscattergl\n散点图（WebGL 版）\n\n\nscatterpolar\n极坐标下散点图\n\n\nscatterpolargl\n极坐标下散点图（WebGL 版）\n\n\nscattergeo\n地理坐标下散点图\n\n\nscattermapbox\n地理坐标下散点图（MapBox 版）\n\n\nscattercarpet\n地毯图\n\n\nscatterternary\n三元图\n\n\n\n\n\n\n图 13.6 展示斐济及其周边的地震分布\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  type = \"scatter\", mode = \"markers\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\")\n  )\n\n\n\n\n\n\n\n\n图 13.6: 普通散点图\n\n\n\n\n\n13.2.2 柱形图\n\n# https://plotly.com/r/reference/bar/\nplotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"bar\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\n\n\n\n\n\n图 13.7: 柱形图\n\n\n\n\n13.2.3 曲线图\n\nplotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"scatter\",\n  mode = \"markers+lines\", line = list(shape = \"spline\")\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\n\n\n\n\n\n图 13.8: 曲线图\n\n\n\n\n13.2.4 直方图\n地震次数随震级的分布变化，下 图 13.9 为频数分布图\n\n# https://plotly.com/r/reference/histogram/\nplotly::plot_ly(quakes, x = ~mag, type = \"histogram\") |&gt; \n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"次数\")\n  )\n\n\n\n\n\n\n\n\n图 13.9: 地震震级的频数分布图\n\n\n\n\n地震震级的概率分布，下 图 13.10 为频率分布图\n\nplotly::plot_ly(\n  data = quakes, x = ~mag, type = \"histogram\",\n  histnorm = \"probability\",\n  marker = list(\n    color = \"lightblue\",\n    line = list(color = \"white\", width = 2)\n  )\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"频率\")\n  )\n\n\n\n\n\n\n\n\n图 13.10: 地震震级的频率分布图\n\n\n\n\nhistnorm = \"probability\" 意味着纵轴表示频率，即每个窗宽下地震次数占总地震次数的比例。地震常常发生在地下，不同的深度对应着不同的地质构造、不同的地震成因，下 图 13.11 展示海平面下不同深度的地震震级分布。\n\nquakes$depth_bin &lt;- cut(quakes$depth, breaks = 150 * 0:5)\n\n\nplotly::plot_ly(quakes,\n  x = ~mag, colors = \"viridis\",\n  color = ~depth_bin, type = \"histogram\"\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"次数\")\n  )\n\n\n\n\n\n\n\n\n图 13.11: 地震震级的频率分布图\n\n\n\n\n\n13.2.5 箱线图\n\nplotly::plot_ly(quakes,\n  x = ~depth_bin, y = ~mag, colors = \"viridis\",\n  color = ~depth_bin, type = \"box\"\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"深度\"),\n    yaxis = list(title = \"震级\")\n  )\n\n\n\n\n\n\n图 13.12: 不同深度下地震震级的分布\n\n\n\n\nplotly::plot_ly(quakes,\n  x = ~depth_bin, y = ~mag, split = ~depth_bin,\n  type = \"violin\", color = ~depth_bin, colors = \"viridis\",\n  box = list(visible = TRUE),\n  meanline = list(visible = TRUE)\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"深度\"),\n    yaxis = list(title = \"震级\")\n  )\n\n\n\n\n\n\n图 13.13: 不同深度下地震震级的分布\n\n\n\n\n13.2.6 热力图\nplotly 整合了开源的 Mapbox GL JS，可以使用 Mapbox 提供的瓦片地图服务（Mapbox Tile Maps），对空间点数据做核密度估计，展示热力分布，如 图 13.14 所示。图左上角为所罗门群岛（Solomon Islands）、瓦努阿图（Vanuatu）和新喀里多尼亚（New Caledonia），图下方为新西兰北部的威灵顿（Wellington）和奥克兰（Auckland），图中部为斐济（Fiji）。\n\nplotly::plot_ly(\n  data = quakes, lat = ~lat, lon = ~long, radius = 10,\n  type = \"densitymapbox\", coloraxis = \"coloraxis\"\n) |&gt;\n  plotly::layout(\n    mapbox = list(\n      style = \"stamen-terrain\", zoom = 3,\n      center = list(lon = 180, lat = -25)\n    ),\n    coloraxis = list(colorscale = \"Viridis\")\n  )\n\n\n\n\n\n\n\n\n图 13.14: 空间点数据的核密度估计\n\n\n\n\n图中设置瓦片地图的风格 style 为 \"stamen-terrain\"，还可以使用其他开放的栅格瓦片地图服务，比如 \"open-street-map\" 和 \"carto-positron\"。如果使用 MapBox 提供的矢量瓦片地图服务，则需要访问令牌 Mapbox Access Token。图中设置中心坐标 center 以及缩放倍数 zoom，目的是突出图片中的数据区域。设置调色板 Viridis 展示热力分布，黄色团块的地方表示地震频次高。\n\n13.2.7 面量图\n在之前我们介绍过用 ggplot2 绘制地区分布图，实际上，地区分布图还有别名，如围栏图、面量图等。本节使用 plotly 绘制交互式的地区分布图，如 图 13.15 所示。\n\n# https://plotly.com/r/reference/choropleth/\ndat &lt;- data.frame(state.x77,\n  stats = rownames(state.x77),\n  stats_abbr = state.abb\n)\n# 绘制图形\nplotly::plot_ly(\n  data = dat,\n  type = \"choropleth\",\n  locations = ~stats_abbr,\n  locationmode = \"USA-states\",\n  colorscale = \"Viridis\",\n  colorbar = list(title = list(text = \"人均收入\")),\n  z = ~Income\n) |&gt;\n  plotly::layout(\n    geo = list(scope = \"usa\"),\n    title = \"1974年美国各州的人均收入\"\n  )\n\n\n\n\n\n\n\n\n图 13.15: 1974 年美国各州的人均收入\n\n\n\n\n\n13.2.8 动态图\n本节参考 plotly 包的官方示例渐变动画，数据来自 SVN 代码提交日志，统计 Martin Maechler 和 Brian Ripley 的年度代码提交量，他们是 R Core Team 非常重要的两位成员，长期参与维护 R 软件及社区。下图展示 1999-2022 年 Martin Maechler 和 Brian Ripley 的代码提交量变化。\n\n# https://plotly.com/r/animations/\ntrunk_year_author &lt;- aggregate(data = svn_trunk_log, revision ~ year + author, FUN = length)\n# https://plotly.com/r/cumulative-animations/\naccumulate_by &lt;- function(dat, var) {\n  var &lt;- lazyeval::f_eval(f = var, data = dat)\n  lvls &lt;- plotly:::getLevels(var) \n  dats &lt;- lapply(seq_along(lvls), function(x) {\n    cbind(dat[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])\n  })\n  dplyr::bind_rows(dats)\n}\n\nsubset(trunk_year_author, year &gt;= 1999 & author %in% c(\"ripley\", \"maechler\")) |&gt;\n  accumulate_by(~year) |&gt;\n  plotly::plot_ly(\n    x = ~year, y = ~revision, split = ~author,\n    frame = ~frame, type = \"scatter\", mode = \"lines\",\n    line = list(simplyfy = F)\n  ) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  ) |&gt;\n  plotly::animation_opts(\n    frame = 100, transition = 0, redraw = FALSE\n  ) |&gt;\n  plotly::animation_button(\n    visible = TRUE, # 显示播放按钮\n    label = \"播放\", # 按钮文本\n    font = list(color = \"gray\")# 文本颜色\n  ) |&gt;\n  plotly::animation_slider(\n    currentvalue = list(\n      prefix = \"年份 \",\n      xanchor = \"right\",\n      font = list(color = \"gray\", size = 30)\n    )\n  )\n\n\n\n\n\n\n图 13.16: 1999-2022 年 Martin Maechler 和 Brian Ripley 的代码提交量变化\n\n\n\nlazyeval 的非标准计算采用 Base R 实现，目前，已经可以被 rlang 替代。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-plotly-common-tricks",
    "href": "interactive-graphics.html#sec-plotly-common-tricks",
    "title": "13  交互图形",
    "section": "\n13.3 常用技巧",
    "text": "13.3 常用技巧\n\n13.3.1 数学公式\n正态分布的概率密度函数形式如下：\n\\[\n\\begin{aligned}\n& f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\{-\\frac{(x -\\mu)^2}{2\\sigma^2}\\}\n\\end{aligned}\n\\]\n下图展示两个正态分布，分别是 \\(\\mathcal{N}(3, 1^2)\\) 和 \\(\\mathcal{N}(2, 1.5^2)\\) 。函数 plotly::TeX() 包裹 LaTeX 书写的数学公式，plotly 包调用 MathJax 库渲染图中的公式符号。\n\n代码x &lt;- seq(from = -4, to = 8, length.out = 193)\ny1 &lt;- dnorm(x, mean = 3, sd = 1)\ny2 &lt;- dnorm(x, mean = 2, sd = 1.5)\n\nplotly::plot_ly(\n  x = x, y = y1, type = \"scatter\", mode = \"lines\",\n  fill = \"tozeroy\", fillcolor = \"rgba(0, 204, 102, 0.2)\",\n  text = ~ paste0(\n    \"x：\", x, \"&lt;br&gt;\",\n    \"y：\", round(y1, 3), \"&lt;br&gt;\"\n  ),\n  hoverinfo = \"text\",\n  name = plotly::TeX(\"\\\\mathcal{N}(3,1^2)\"),\n  line = list(shape = \"spline\", color = \"#009B95\")\n) |&gt; \n  plotly::add_trace(\n    x = x, y = y2, type = \"scatter\", mode = \"lines\",\n    fill = \"tozeroy\", fillcolor = \"rgba(51, 102, 204, 0.2)\",\n    text = ~ paste0(\n      \"x：\", x, \"&lt;br&gt;\",\n      \"y：\", round(y2, 3), \"&lt;br&gt;\"\n    ),\n    hoverinfo = \"text\",\n    name = plotly::TeX(\"\\\\mathcal{N}(2, 1.5^2)\"),\n    line = list(shape = \"spline\", color = \"#403173\")\n  ) |&gt; \n  plotly::layout(\n    xaxis = list(showgrid = F, title = plotly::TeX(\"x\")),\n    yaxis = list(showgrid = F, title = plotly::TeX(\"f(x)\")),\n    legend = list(x = 0.8, y = 1, orientation = \"v\")\n  ) |&gt; \n  plotly::config(mathjax = \"cdn\", displayModeBar = FALSE)\n\n\n\n\n\n\n\n\n\n图 13.17: 设置数学公式\n\n\n\n\n\n13.3.2 动静转化\n在出版书籍，发表期刊文章，打印纸质文稿等场景中，需要将交互图形导出为静态图形，再插入到正文之中。\n\nlibrary(ggplot2)\np &lt;- ggplot(data = quakes, aes(x = long, y = lat)) +\n  geom_point()\np\n\n\n\n\n\n\n图 13.18: ggplot2 绘制的静态图形\n\n\n\n\n将 ggplot2 包绘制的散点图转化为交互式的散点图，只需调用 plotly 包的函数 ggplotly()。\n\nplotly::ggplotly(p)\n\n\n\n\n\n当使用配置函数 config() 设置参数选项 staticPlot = TRUE，可将原本交互式的动态图形转为非交互式的静态图形。\n\nplotly::ggplotly(p) |&gt; \n  plotly::config(staticPlot = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n函数 style() 设置动态点的注释，比如点横纵坐标、坐标文本，以及整个注释标签的样式，如背景色。\n\nplotly::ggplotly(p, dynamicTicks = \"y\") |&gt; \n  plotly::style(hoveron = \"points\", hoverinfo = \"x+y+text\", \n        hoverlabel = list(bgcolor = \"white\"))\n\n\n\n\n\n\n\norca (Open-source Report Creator App) 软件针对 plotly.js 库渲染的图形具有很强的导出功能，安装 orca 后，plotly::orca() 函数可以将基于 htmlwidgets 的 plotly 图形对象导出为 PNG、PDF 和 SVG 等格式的高质量静态图片。\n\n# orca\nplotly::orca(p, \"plotly-quakes.svg\")\n# kaleido\nplotly::save_image(p, \"plotly-quakes.svg\")\n\n\n13.3.3 坐标系统\nquakes 是一个包含空间位置的数据集，plotly 的 scattergeo 图层 针对空间数据提供多边形矢量边界地图数据，支持设定坐标参考系。下 图 13.19 增加了地震震级维度，在空间坐标参考系下绘制散点。\n\nplotly::plot_ly(\n  data = quakes,\n  lon = ~long, lat = ~lat,\n  type = \"scattergeo\", mode = \"markers\",\n  text = ~ paste0(\n    \"站点：\", stations, \"&lt;br&gt;\",\n    \"震级：\", mag\n  ),\n  marker = list(\n    color = ~mag, colorscale = \"Viridis\",\n    size = 10, opacity = 0.8,\n    line = list(color = \"white\", width = 1)\n  )\n) |&gt;\n  plotly::layout(geo = list(\n    showland = TRUE,\n    landcolor = plotly::toRGB(\"gray95\"),\n    countrycolor = plotly::toRGB(\"gray85\"),\n    subunitcolor = plotly::toRGB(\"gray85\"),\n    countrywidth = 0.5,\n    subunitwidth = 0.5,\n    lonaxis = list(\n      showgrid = TRUE,\n      gridwidth = 0.5,\n      range = c(160, 190),\n      dtick = 5\n    ),\n    lataxis = list(\n      showgrid = TRUE,\n      gridwidth = 0.5,\n      range = c(-40, -10),\n      dtick = 5\n    )\n  ))\n\n\n\n\n\n\n\n\n图 13.19: 空间点数据图\n\n\n\n\n\n13.3.4 添加水印\n在图片右下角添加水印图片\n\nplotly::plot_ly(quakes,\n  x = ~long, y = ~lat, color = ~mag, \n  type = \"scatter\", mode = \"markers\"\n) |&gt; \n  plotly::config(staticPlot = TRUE) |&gt; \n  plotly::layout(\n    images = list( # 水印图片\n      source = \"https://images.plot.ly/language-icons/api-home/r-logo.png\",\n      xref = \"paper\", # 页面参考\n      yref = \"paper\",\n      x = 0.90, # 横坐标\n      y = 0.20, # 纵坐标\n      sizex = 0.2, # 长度\n      sizey = 0.2, # 宽度\n      opacity = 0.5 # 透明度\n    )\n  )\n\n\n\n\n\n\n图 13.20: 添加水印图片\n\n\n\n\n13.3.5 多图布局\n将两个图形做上下排列\n\np1 &lt;- plotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"bar\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\np2 &lt;- plotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"scatter\",\n  mode = \"markers+lines\", line = list(shape = \"spline\")\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\nhtmltools::tagList(p1, p2)\n\n\n\n\n\n\n\n图 13.21: 上下布局\n\n\n\nplotly 包提供的函数 subplot() 专门用于布局排列，下图的上下子图共享 x 轴。\n\nplotly::subplot(plotly::style(p1, showlegend = FALSE), \n                plotly::style(p2, showlegend = FALSE), \n                nrows = 2, margin = 0.05, shareX = TRUE, titleY = TRUE)\n\n\n\n\n\n\n图 13.22: 上下布局\n\n\n\n下图展示更加灵活的布局形式，嵌套使用布局函数 subplot() 实现。\n\np11 &lt;- plotly::subplot(plotly::style(p1, showlegend = FALSE),\n  plotly::style(p2, showlegend = FALSE),\n  nrows = 1, margin = 0.05, shareY = TRUE, titleX = TRUE\n)\n\nplotly::subplot(p11,\n  plotly::style(p2, showlegend = FALSE),\n  nrows = 2, margin = 0.05, shareY = FALSE, titleX = FALSE\n)\n\n\n\n\n\n\n图 13.23: 灵活布局\n\n\n\n\n13.3.6 图表联动\ncrosstalk 包可将 plotly 包绘制的图形和 DT 包制作的表格联动起来。plotly 绘制交互图形，在图形上用套索工具筛选出来的数据显示在表格中。\n\nlibrary(crosstalk)\n# quakes 数据变成可共享的\nquakes_sd &lt;- SharedData$new(quakes)\n# 绘制交互图形\np &lt;- plotly::plot_ly(quakes_sd, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers() |&gt; \n  plotly::highlight(on = \"plotly_selected\", off = \"plotly_deselect\")\n# 制作表格\nd &lt;- DT::datatable(quakes_sd, options = list(dom = \"tp\"))\n# 将图表组合一起展示\nbscols(list(p, d))\n\n\n\n\n\n\n\n\n\n\n\n\n\n图 13.24: 图表联动",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html",
    "href": "interactive-tables.html",
    "title": "14  交互表格",
    "section": "",
    "text": "14.1 基础功能",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-basic",
    "href": "interactive-tables.html#sec-table-basic",
    "title": "14  交互表格",
    "section": "",
    "text": "14.1.1 创建表格\n\n14.1.2 添加标题\n\n14.1.3 添加注释\n\n14.1.4 水平滚动\n\n14.1.5 垂直滚动\n\n14.1.6 数据分页\n\n14.1.7 适应宽度\n\n14.1.8 行列分组\n\n14.1.9 列格式化\n\n14.1.10 数据配色\n\nlibrary(tibble)\n\ndat &lt;- tribble(\n  ~name1, ~name2,\n  as.character(htmltools::tags$b(\"加粗\")), as.character(htmltools::a(href = \"https://rstudio.com\", \"超链\")), # 支持超链接\n  as.character(htmltools::em(\"强调\")), '&lt;a href=\"#\" onclick=\"alert(\\'Hello World\\');\"&gt;Hello&lt;/a&gt;',\n  as.character(htmltools::span(style = \"color:red\", \"正常\")), \"正常\"\n)\n\n根据数据的大小配上颜色\n\ncolorize_num &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", x),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", x)\n  )\n}\ncolorize_pct &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", scales::percent(x, accuracy = 0.01)),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", scales::percent(x, accuracy = 0.01))\n  )\n}\n\ncolorize_pp &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", paste0(round(100*x, digits = 2), \"PP\")),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", paste0(round(100*x, digits = 2), \"PP\"))\n  )\n}\n\ncolorize_text &lt;- function(x, color = \"red\") {\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", color, x )\n}\n\n\nlibrary(DT)\ndatatable(\n  data = dat, escape = FALSE, \n  colnames = c(colorize_text(\"第1列\", \"red\"), \n               as.character(htmltools::em(\"第2列\"))),\n  options = list(\n    pageLength = 5, # 每页显示5行\n    dom = \"t\"\n  )\n)\n\n\n表格 14.1: 数据配色\n\n\n\n\n\n\n\n\n\nBase R 内置的 R 包含有丰富的数据集，非常适合演示图形和阐述统计理论，后面技术和理论部分的介绍大多围绕内置的数据集展开，数据集及其描述如下表所示：\n\n# 抽取 R 包信息\nPkgs &lt;- sapply(list.files(R.home(\"library\")), function(x) {\n  packageDescription(pkg = x, fields = \"Priority\")\n})\n# 抽取内置 R 包列表\nCorePkgs &lt;- names(Pkgs[Pkgs %in% c(\"base\", \"recommended\") & !is.na(Pkgs)])\n# 抽取 R 包的数据集\nBaseDataSets &lt;- data(package = CorePkgs)$results[, c(\"Package\", \"Item\", \"Title\")]\n\nlibrary(DT)\ndatatable(BaseDataSets,\n  rownames = FALSE, # 不显示行名\n  extensions = c(\"Buttons\", \"RowGroup\"),\n  options = list(\n    pageLength = 10, # 每页显示的行数\n    language = list(url = \"//cdn.datatables.net/plug-ins/1.10.11/i18n/Chinese.json\"), # 汉化\n    dom = \"Bfrtp\", # 去掉显示行数 i、过滤 f 的能力，翻页用 p 表示\n    ordering = F, # 去掉列排序\n    buttons = c(\"copy\", \"csv\", \"excel\", \"print\"), # 提供打印按钮\n    rowGroup = list(dataSrc = 0), # 按 Package 列分组\n    columnDefs = list(\n      list(className = \"dt-center\", targets = 0), # 不显示行名，则 targets 从 0 开始，否则从 1 开始\n      list(visible = FALSE, targets = 0) # 不显示 Package 列\n    )\n  )\n)\n\n\n表格 14.2: Base R 包内置的数据集",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-extend",
    "href": "interactive-tables.html#sec-table-extend",
    "title": "14  交互表格",
    "section": "\n14.2 扩展功能",
    "text": "14.2 扩展功能\n\n14.2.1 汉化表格\n\n14.2.2 下载数据",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-reactable",
    "href": "interactive-tables.html#sec-table-reactable",
    "title": "14  交互表格",
    "section": "\n14.3 其它工具",
    "text": "14.3 其它工具",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html",
    "href": "interactive-applications.html",
    "title": "15  交互应用",
    "section": "",
    "text": "15.1 简单示例\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  sliderInput(inputId = \"n\", label = \"观测记录的数目\", \n              min = 1, max = nrow(faithful), value = 100),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    hist(faithful$eruptions[seq_len(input$n)],\n      breaks = 40,\n      main = \"美国黄石公园喷泉\",\n      xlab = \"喷发持续时间\"\n    )\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-demo",
    "href": "interactive-applications.html#sec-shiny-demo",
    "title": "15  交互应用",
    "section": "",
    "text": "15.1.1 UI 前端\n\n15.1.2 Server 后端",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-widget",
    "href": "interactive-applications.html#sec-shiny-widget",
    "title": "15  交互应用",
    "section": "\n15.2 Shiny 组件",
    "text": "15.2 Shiny 组件\n组件又很多，下面想重点介绍 4 个，它们使用频次很高，很有代表性。\n\n15.2.1 筛选器\n单个筛选器、独立筛选器、筛选器联动\n\n15.2.2 输入框\n数值型、文本型\n\n15.2.3 动作按钮\n提交按钮、响应按钮\n\n15.2.4 书签\n书签记录输入状态，链接可以指向页面状态\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  sliderInput(inputId = \"n\", label = \"观测记录的数目\", \n              min = 1, max = nrow(faithful), value = 100),\n  plotOutput(\"plot\"),\n  bookmarkButton(id = \"bookmark1\", label = \"书签\", title = \"记录、分享此时应用的状态\")\n)\n\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    hist(faithful$eruptions[seq_len(input$n)],\n      breaks = 40,\n      main = \"美国黄石公园喷泉\",\n      xlab = \"喷发持续时间\"\n    )\n  })\n}\n\nenableBookmarking(store = \"url\")\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-extensions",
    "href": "interactive-applications.html#sec-shiny-extensions",
    "title": "15  交互应用",
    "section": "\n15.3 Shiny 扩展",
    "text": "15.3 Shiny 扩展\n页面布局\n\n\nshinydashboard / shinydashboardPlus Shiny 应用\n\nflexdashboard R Markdown 文档中制作 Shiny 应用\nbs4Dash\n\n交互表格\n\nDT\nreactable\n\n交互图形\n\nplotly\nggiraph\n\n\n15.3.1 页面布局\n\n15.3.2 交互表格\n下面在 Shiny 应用中插入 DT 包制作的交互表格\n\n# 前端\nlibrary(shiny)\nui &lt;- fluidPage(\n  # 应用的标题名称\n  titlePanel(\"鸢尾花数据集\"),\n  # 边栏\n  fluidRow(\n    column(12, DT::dataTableOutput(\"table\"))\n  )\n)\n\n# 服务端\nserver &lt;- function(input, output, session) {\n  output$table &lt;- DT::renderDataTable(iris,\n    options = list(\n      pageLength = 5, # 每页显示5行\n      initComplete = I(\"function(settings, json) {alert('Done.');}\")\n    ), server = F\n  )\n}\n\nshinyApp(ui, server)\n\n\n\n\n\n\n\n重要\n\n\n\n加载 shiny 包后再加载 DT 包，函数 dataTableOutput() 和renderDataTable() 显示冲突，因为两个 R 包都有这两个函数。在创建 shiny 应用的过程中，如果我们需要呈现动态表格，就需要使用 DT 包的 DT::dataTableOutput() 和 DT::renderDataTable() ，否则会报错，详见 https://github.com/rstudio/shiny/issues/2653。\n\n\nreactable 基于 JS 库 React Table 提供交互式表格渲染，和 shiny 无缝集成，是替代 DT 的不二选择，在 app.R 用 reactable 包的 reactableOutput() 和 renderReactable() 函数替代 shiny 里面的 dataTableOutput() 和 renderDataTable()。 再也不用忍受 DT 和 shiny 的函数冲突了，且其覆盖测试达到 99%。\n\nlibrary(shiny)\n\n下面在 Shiny 应用中插入 reactable 包制作的交互表格\n\nlibrary(shiny)\nlibrary(reactable)\n\nui &lt;- fluidPage(\n  reactableOutput(\"table\")\n)\n\nserver &lt;- function(input, output) {\n  output$table &lt;- renderReactable({\n    reactable(iris,\n      filterable = TRUE, # 过滤\n      searchable = TRUE, # 搜索\n      showPageSizeOptions = TRUE, # 页面大小\n      pageSizeOptions = c(5, 10, 15), # 页面大小可选项\n      defaultPageSize = 10, # 默认显示10行\n      highlight = TRUE, # 高亮选择\n      striped = TRUE, # 隔行高亮\n      fullWidth = FALSE, # 默认不要全宽填充，适应数据框的宽度\n      defaultSorted = list(\n        Sepal.Length = \"asc\", # 由小到大排序\n        Petal.Length = \"desc\" # 由大到小\n      ),\n      columns = list(\n        Sepal.Width = colDef(style = function(value) { \n          # Sepal.Width 添加颜色标记\n          if (value &gt; 3.5) {\n            color &lt;- \"#008000\"\n          } else if (value &gt; 2) {\n            color &lt;- \"#e00000\"\n          } else {\n            color &lt;- \"#777\"\n          }\n          list(color = color, fontWeight = \"bold\") # 字体加粗\n        })\n\n      )\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n除了 DT 和 reactable 包，其它支持 Shiny 集成的 R 包还有 gt 、formattable 和 kableExtra 等。\n\n15.3.3 交互图形\nggiraph 包",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-dashboard",
    "href": "interactive-applications.html#sec-shiny-dashboard",
    "title": "15  交互应用",
    "section": "\n15.4 Shiny 仪表盘",
    "text": "15.4 Shiny 仪表盘\ndashboard 翻译过来叫仪表盘，就是驾驶仓的那个玩意，形象地表达作为掌舵者应该关注的对象。R 包 shiny 出现后，仪表盘的制作显得非常容易，也很快形成了一个生态，比如 shinydashboard、 flexdashboard 等，此外 bs4Dash 基于 Bootstrap 4 的仪表盘，目前 shiny 和 rmarkdown 都在向 Bootstrap 4 升级，这是未来的方向。 shinydashboardPlus 主要目的在于扩展 shinydashboard 包\n\n15.4.1 shinydashboard 包\n将如下内容保存为 app.R 文件。\n\nlibrary(shiny)\nlibrary(shinydashboard)\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Basic dashboard\"),\n  ## 边栏\n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Dashboard\", tabName = \"dashboard\", icon = icon(\"dashboard\")),\n      menuItem(\"Widgets\", tabName = \"widgets\", icon = icon(\"th\"))\n    )\n  ),\n  ## 主体内容\n  dashboardBody(\n    tabItems(\n      # 第一个 Tab 页内容\n      tabItem(\n        tabName = \"dashboard\",\n        fluidRow(\n          box(plotOutput(\"plot1\", height = 250)),\n          box(\n            title = \"Controls\",\n            sliderInput(\"slider\", \"Number of observations:\", 1, 100, 50)\n          )\n        )\n      ),\n\n      # 第二个 Tab 页内容\n      tabItem(\n        tabName = \"widgets\",\n        h2(\"Widgets tab content\")\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  set.seed(122)\n  histdata &lt;- rnorm(500)\n\n  output$plot1 &lt;- renderPlot({\n    data &lt;- histdata[seq_len(input$slider)]\n    hist(data)\n  })\n}\n\nshinyApp(ui, server)\n\n\n15.4.2 shinydashboardPlus 包\nshinydashboardPlus 包的函数 descriptionBlock()\n\nlibrary(shiny)\nlibrary(shinydashboard)\nlibrary(shinydashboardPlus)\n\nshinyApp(\n  ui = dashboardPage(\n    dashboardHeader(),\n    dashboardSidebar(),\n    dashboardBody(\n      box(\n        solidHeader = FALSE,\n        title = \"状态概览\",\n        background = NULL,\n        width = 4,\n        status = \"danger\",\n        footer = fluidRow(\n          column(\n            width = 6,\n            descriptionBlock(\n              number = \"17%\",\n              numberColor = \"green\",\n              numberIcon = \"fa fa-caret-up\",\n              header = \"$35,210.43\",\n              text = \"总收入\",\n              rightBorder = TRUE,\n              marginBottom = FALSE\n            )\n          ),\n          column(\n            width = 6,\n            descriptionBlock(\n              number = \"18%\",\n              numberColor = \"red\",\n              numberIcon = \"fa fa-caret-down\",\n              header = \"1200\",\n              text = \"目标完成\",\n              rightBorder = FALSE,\n              marginBottom = FALSE\n            )\n          )\n        )\n      )\n    ),\n    title = \"Description Blocks\"\n  ),\n  server = function(input, output) { }\n)\n\n\n15.4.3 bs4Dash 包\n\nlibrary(bs4Dash)\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Basic dashboard\"),\n  dashboardSidebar(),\n  dashboardBody(\n    # Boxes need to be put in a row (or column)\n    fluidRow(\n      box(plotOutput(\"plot1\", height = 250)),\n      \n      box(\n        title = \"Controls\",\n        sliderInput(\"slider\", \"Number of observations:\", 1, 100, 50)\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  set.seed(122)\n  histdata &lt;- rnorm(500)\n  \n  output$plot1 &lt;- renderPlot({\n    data &lt;- histdata[seq_len(input$slider)]\n    hist(data)\n  })\n}\n\nshinyApp(ui, server)\n\n\n15.4.4 miniUI 包\nminiUI 包制作迷你版 Shiny 应用，适用于小屏幕显示。\n\nlibrary(shiny)\nlibrary(miniUI)\nlibrary(leaflet)\nlibrary(ggplot2)\n\nui &lt;- miniPage(\n  gadgetTitleBar(\"Shiny gadget example\"),\n  miniTabstripPanel(\n    miniTabPanel(title = \"参数\",\n      icon = icon(\"sliders\"),\n      miniContentPanel(\n        sliderInput(\"year\", \"年份\", 1978, 2010, c(2000, 2010), sep = \"\")\n      )\n    ),\n    miniTabPanel(title = \"可视化\",\n      icon = icon(\"area-chart\"),\n      miniContentPanel(\n        plotOutput(\"quakes\", height = \"100%\")\n      )\n    ),\n    miniTabPanel(title = \"地图\",\n      icon = icon(\"map-o\"),\n      miniContentPanel(\n        padding = 0,\n        leafletOutput(\"map\", height = \"100%\")\n      ),\n      miniButtonBlock(\n        actionButton(\"resetMap\", \"Reset\")\n      )\n    ),\n    miniTabPanel(title = \"数据\",\n      icon = icon(\"table\"),\n      miniContentPanel(\n        DT::dataTableOutput(\"table\")\n      )\n    ),\n    selected = \"Map\"\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  output$quakes &lt;- renderPlot({\n    ggplot(quakes, aes(long, lat)) +\n      geom_point()\n  })\n\n  output$map &lt;- renderLeaflet({\n    force(input$resetMap)\n\n    leaflet(quakes, height = \"100%\") |&gt;\n      addTiles() |&gt;\n      addMarkers(lng = ~long, lat = ~lat)\n  })\n\n  output$table &lt;- DT::renderDataTable({\n    quakes\n  })\n\n  observeEvent(input$done, {\n    stopApp(TRUE)\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-themes",
    "href": "interactive-applications.html#sec-shiny-themes",
    "title": "15  交互应用",
    "section": "\n15.5 Shiny 主题",
    "text": "15.5 Shiny 主题\n\n15.5.1 bslib 包\n\nbslib\n\n15.5.2 shinymaterial 包\nshinymaterial 包实现 Material Design\n\nlibrary(shiny)\nlibrary(shinymaterial)\n\nui &lt;- material_page(\n  title = \"用户画像\",\n  nav_bar_fixed = TRUE,\n  # 每个 sidebar 内容\n  material_side_nav(\n    fixed = TRUE,\n    # Place side-nav tabs within side-nav\n    material_side_nav_tabs(\n      side_nav_tabs = c(\n        \"数据汇总\" = \"tab_1\",\n        \"趋势信息\" = \"tab_2\"\n      ),\n      icons = c(\"cast\", \"insert_chart\")\n    )\n  ),\n  # 每个 tab 页面的内容\n  material_side_nav_tab_content(\n    side_nav_tab_id = \"tab_1\",\n    tags$h2(\"第一个tab页\")\n  ),\n  material_side_nav_tab_content(\n    side_nav_tab_id = \"tab_2\",\n    tags$h2(\"第二个tab页\")\n  )\n)\n\nserver &lt;- function(input, output) {\n\n}\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-faster",
    "href": "interactive-applications.html#sec-shiny-faster",
    "title": "15  交互应用",
    "section": "\n15.6 Shiny 优化",
    "text": "15.6 Shiny 优化\n提升 shiny 仪表盘访问性能的4个建议",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-deployment",
    "href": "interactive-applications.html#sec-shiny-deployment",
    "title": "15  交互应用",
    "section": "\n15.7 Shiny 部署",
    "text": "15.7 Shiny 部署\n\n15.7.1 promises 并发\nshiny 异步编程实现并发访问，多人同时访问 Shiny 应用的情况下，解决必须等另一个人完成访问的情况下才能继续访问的问题。\n\nlibrary(shiny)\nlibrary(future)\nlibrary(promises)\n\nplan(multiprocess)\n\nui &lt;- fluidPage(\n  h2(\"测试异步下载\"),\n  tags$ol(\n    tags$li(\"Verify that plot appears below\"),\n    tags$li(\"Verify that pressing Download results in 5 second delay, then rock.csv being downloaded\"),\n    tags$li(\"Check 'Throw on download?' checkbox and verify that pressing Download results in 5 second delay, then error, as well as stack traces in console\")\n  ),\n  hr(),\n  checkboxInput(\"throw\", \"Throw on download?\"),\n  downloadButton(\"download\", \"下载 (等待5秒)\"),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output, session) {\n  output$download &lt;- downloadHandler(\"rock.csv\", function(file) {\n    future({Sys.sleep(5)}) %...&gt;%\n      {\n        if (input$throw) {\n          stop(\"boom\")\n        } else {\n          write.csv(rock, file)\n        }\n      }\n  })\n\n  output$plot &lt;- renderPlot({\n    plot(cars)\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-alternative",
    "href": "interactive-applications.html#sec-shiny-alternative",
    "title": "15  交互应用",
    "section": "\n15.8 Shiny 替代品",
    "text": "15.8 Shiny 替代品\nR Markdown + Shiny 文档\n\ncrosstalk 交互\nflexdashboard 布局\nDT 交互表格\nleaflet 交互地图\nggiraph 交互图形\n\nQuarto Dashboard 文档",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-showcases",
    "href": "interactive-applications.html#sec-shiny-showcases",
    "title": "15  交互应用",
    "section": "\n15.9 Shiny 案例",
    "text": "15.9 Shiny 案例\n\n\nradiant 探索性数据分析解决方案",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-summary",
    "href": "interactive-applications.html#sec-shiny-summary",
    "title": "15  交互应用",
    "section": "\n15.10 总结",
    "text": "15.10 总结\n事实上，作为 BI 工程师，相当一部分工作是与数据开发结合的。从 Kafka 接入埋点上报的原始日志（ODS 层）、清洗抽取特定业务/领域内的数据（Fact 事实层）、面向某一类任务的主题数据（ topic 主题层）、面向特定数据产品的应用数据 （app 应用层）。\n\n数据仓库 Hive 数据开发：事实、主题和应用层\n数据计算 Spark 数据开发工具 Spark SQL / Hive SQL 任务调度\n数据报表 MySQL / Doris 数据同步工具 Hive2MySQL 同步应用层数据\n数据展示 Dashboard 应用开发工具 Shiny RStudio Shiny Server\n\n报表开发从数据仓库的 DWD 层开始，可能一些业务原因，我们需要从 ODS 层甚至从点击流的日志数据开始，经过数据清洗、提取、聚合成为支撑BI报表最底层的基础表，存储在 Hive 中，然后对这一系列的基础表根据BI展示的需要进行第二层聚合形成中间表，这两层数据根据业务情况做增量更新或者全量更新，并将中间表同步到 MySQL 仓库中，全量更新的情况，往往更新数据比较大，建议用 sqoop 做数据的同步。创建第二层的中间表稍有些灵活性，原则是在中间表之上对应的数据操作和可视化是容易实现且效率较高的，否则应该构造第三层的中间表，绝不能将大规模的数据集直接导入 R 中进行分析和可视化，拖慢前端展示的速度，占用过多的服务器资源。\n\n\n\n\n\n\n\n图 15.1: Shiny 生态系统\n\n\n\n\n连接数据库。根据数据库的情况选择相应的 R 接口包，比如连接 MySQL 数据库可以用 RMySQL 包，值得一提， odbc 包支持连接相当多的数据库。\n数据操作。根据需要处理的数据规模，可以选择 Base R、 data.table 或者 dplyr 做数据操作，推荐和管道操作一起使用，增加代码可读性。\n交互表格。推荐 reactable 和 DT 包做数据呈现。\n交互图形。推荐功能强大的 plotly 包，可以先用 ggplot2 绘制，然后调用 plotly 包的 ggplotly() 函数将静态图转化为交互图。\n针对特定应用场景的其它交互可视化工具包，比如 leaflet 可以将地图嵌入 Shiny 应用， dygraphs 可以将时间序列塞进去。\nShiny 组件。shinyFeedback 提供用户输入的反馈。shinyWidgets 提供自定义 widget 的功能。miniUI 专为小屏设计，shinyMobile 在 IOS 和安卓手机上访问 shiny 应用。\nShiny 主题。比如 shinythemes 包可以统一配色，dashboardthemes 提供更加深度的主题，shinytableau 提供仿 Tableau 的 dashboard 框架。sass 在 CSS 样式层面重定义风格。bslib 通过 Bootstrap 3/4/5 定制 Shiny 和 R Markdown 主题。\nShiny 权限。shinymanager / shinyauthr 支持单个 shiny 应用的权限管理，firebase 提供访问权限设置 https://firebase.john-coene.com/。\nShiny 框架。ShinyStudio 打造基于容器架构的协作开发环境的开源解决方案，golem 构建企业级 shiny 应用的框架，RinteRface 开发的系列 R 包也试图打造一套完整的解决方案，并配有速查小抄 cheatsheets。\nShiny 部署。shiny-server 以网络服务的方式支持 shiny 应用，shinyproxy 提供企业级部署 shiny 应用的开源解决方案。\n\n自 RStudio 推出 Shiny 系列产品以来，一些公司进一步根据所需扩展和定制，比如 Appsilon、RinteRface、ThinkR-open、dreamRs 和datastorm-open 等。经过商业公司和个人开发者的努力，Shiny 生态非常庞大，资源非常丰富。\n\nShiny 入门 https://shiny.posit.co/r/getstarted/。\nShiny 扩展包 https://github.com/nanxstats/awesome-shiny-extensions。\nShiny 常用技巧和提示 https://github.com/daattali/advanced-shiny。\nShiny 各类资源列表 https://github.com/grabear/awesome-rshiny。\n\n特别值得一提，Shiny 方面的三本专著。\n\nHadley Wickham 的书 Mastering Shiny。\nColin Fay, Sébastien Rochette, Vincent Guyader, Cervan Girard 的书 Engineering Production-Grade Shiny Apps。\nDavid Granjon 的书 Outstanding User Interfaces with Shiny。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "documents-html.html",
    "href": "documents-html.html",
    "title": "16  HTML 文档",
    "section": "",
    "text": "16.1 文档元素\n无论是 R Markdown 还是 Quarto，都是站在巨人 Pandoc 的肩膀上，Pandoc 在普通 Markdown 的基础上提供了许多扩展支持，通过一些简单的标记，大大丰富了文档内容，下面介绍的内容适用于 R Markdown 和 Quarto，无论文档最终的输出格式如何。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-doc-elements",
    "href": "documents-html.html#sec-doc-elements",
    "title": "16  HTML 文档",
    "section": "",
    "text": "16.1.1 样式\n文字样式，如加粗、倾斜、上下标等。\n\n\n\n\n\n\nMarkdown 语法\n输出\n\n\n\n*斜体*, **加粗**, ***粗斜体***\n\n斜体, 加粗, 粗斜体\n\n\n\n上角标^2^ / 下角标~2~\n上角标2 / 下角标2\n\n\n\n~~删除线~~\n删除线\n\n\n`代码`\n代码\n\n\n\n16.1.2 图片\n其一插入现成的图片，其二插入代码生成的图片\n\n\n\n\n\n\n\n\n\n(a) versicolor 杂色鸢尾\n\n\n\n\n\n\n\n\n\n(b) setosa 山鸢尾\n\n\n\n\n\n\n\n\n\n(c) virginica 弗吉尼亚鸢尾\n\n\n\n\n\n\n图 16.1: 三种鸢尾花\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n图 16.2: 流程图\n\n\n\n\nggplot2 绘制的图形\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(aes(color = Species)) +\n  theme_classic()\n\n\n\n\n\n\n图 16.3: 一幅简单的 ggplot2 图形\n\n\n\n\n\n16.1.3 表格\nMarkdown 原生支持的表格和 knitr 包制作的表格。\n\n\n表格 16.1: 鸢尾花数据集\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n\n\n\n\n\nknitr::kable(head(iris, 3))\n\n\n表格 16.2: 鸢尾花数据集\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n\n\n\n\n\n\n\n\n16.1.4 列表\n常见的列表有无序列表、有序列表及其嵌套。\n\n\n表格 16.3: 几种列表\n\n\n\n\n\n\n\nMarkdown 语法\n输出\n\n\n\n* 无序列表\n    + 子条目 1\n    + 子条目 2\n        - 子子条目 1\n\n无序列表\n\n子条目 1\n子条目 2\n\n子子条目 1\n\n\n\n\n\n\n\n*   条目 2\n\n    继续 (缩进 4 格)\n\n\n条目 2\n继续 (缩进 4 格)\n\n\n\n\n1. 有序列表\n2. 条目 2\n    i) 子条目 1\n         A.  子子条目 1\n\n有序列表\n条目 2\n\n子条目 1\n\n子子条目 1\n\n\n\n\n\n\n\n(@)  第一个人是好的\n\n第二个人是坏的\n\n(@)  第三个人是丑陋的\n\n\n第一个人是好的\n\n第二个人是坏的\n\n第三个人是丑陋的\n\n\n\n\n::: {}\n1. 一个列表\n:::\n\n::: {}\n1. 又一个列表\n:::\n\n\n\n一个列表\n\n\n\n\n又一个列表\n\n\n\n\n\n术语\n: 定义\n\n术语\n\n定义\n\n\n\n\n\n\n\n\n在 (@) 中添加标识符，如 (@good) 就可以引用列表中的条目 (1)。\n\n16.1.5 引用\n除了引用外部书籍、文章、刊物等的内容，还有长文档内部的交叉引用，这项功能是非常需要的，涉及图、表、公式、定理，参考文献，列表条目等。\n\n16.1.6 脚注\n\nIf you imagine that this pen is Trellis, then Lattice is not this pen.1\n— Paul Murrell\n\n\n16.1.7 公式\n公式分两种情况，其一是行内公式，其二是行间公式。前者一对美元符号夹住数学公式，美元符号与字母之间不能有空格，比如 $\\beta$ 渲染出来的效果是 \\(\\beta\\) 。后者是两对美元符号夹住公式，比如 $$\\beta$$ 渲染出来的效果如下：\n\\[\\beta\\]\n行内公式一般用来写数学符号，行间公式一般用来排版数学公式，特别是多行公式。行间公式可以编号，也可以不编号，编号通常是了交叉引用。\n\\[\\mathbf{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\]\n排版行间公式有很多不同的 LaTeX 环境，最常见的有两种，一种是多个公式逐行排，一种是长公式折行，常常都要求对齐。举例来说，线性模型的两种表示方式，一种是矩阵向量式，一种是数据结构式，见 方程式 16.1 。\n\\[\n\\begin{aligned}\n\\mathbf{y} &= X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\\\\ny_i &= \\mathbf{x}_i\\boldsymbol{\\beta} + \\epsilon_i\n\\end{aligned}\n\\tag{16.1}\\]\n在行间公式中，使用 split 公式环境排版一个长公式，这个公式是折成多行的，表达一个计算过程。举例来说，线性模型回归系数的最小二乘估计 \\(\\hat{\\boldsymbol{\\beta}}\\) 的方差的计算过程，见 方程式 16.2 。\n\\[\n\\begin{split}\n\\mathsf{Var}\\{\\hat{\\boldsymbol{\\beta}}\\} & =\\mathsf{Var}\\{(X{^\\top}X)^{-1}X{^\\top}\\mathbf{y}\\}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\mathsf{Var}\\{\\mathbf{y}\\}\\big((X{^\\top}X)^{-1}X{^\\top}\\big){^\\top}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\mathsf{Var}\\{\\mathbf{y}\\}X(X{^\\top}X)^{-1}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\sigma^{2}IX(X{^\\top}X)^{-1}\\\\\n& =(X{^\\top}X)^{-1}\\sigma^{2}\n\\end{split}\n\\tag{16.2}\\]\n值得注意，\n\nLaTeX 命令 \\mathbf 只对英文字母 \\(a,b,c,A,B,C\\) 加粗，对希腊字母 \\(\\theta,\\alpha,\\beta,\\ldots,\\gamma\\) 加粗应该使用命令 \\boldsymbol。\nQuarto 文档中将行间公式中成对 $$ 转化为 LaTeX 中的 equation 环境。Quarto 不支持在多行公式逐行编号，也不支持在多行公式中对某一（些）行编号。而在 LaTeX 文档中，这些全都支持，可以说公式排版是 LaTeX 最突出的优势。\n\nMathJax 支持公式宏定义，如定义命令 \\bm 对希腊字母加粗。在 Quarto 文档中插入如下代码，用命令 \\boldsymbol 定义一个新的命令 \\bm，这种做法很常见，用来简少公式排版的工作量。\n$$\n\\def\\bm#1{{\\boldsymbol #1}}\n$$",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-report",
    "href": "documents-html.html#sec-quarto-report",
    "title": "16  HTML 文档",
    "section": "\n16.2 制作报告",
    "text": "16.2 制作报告\nQuarto Report 文档\n\n16.2.1 SQL 查询\n\nlibrary(DBI)\nconn &lt;- DBI::dbConnect(RSQLite::SQLite(),\n  dbname = system.file(\"db\", \"datasets.sqlite\", package = \"RSQLite\")\n)\n\nBase R 内置的数据集都整合进 RSQLite 的样例数据库里了，\n\ndbListTables(conn)\n\n [1] \"BOD\"              \"CO2\"              \"ChickWeight\"      \"DNase\"           \n [5] \"Formaldehyde\"     \"Indometh\"         \"InsectSprays\"     \"LifeCycleSavings\"\n [9] \"Loblolly\"         \"Orange\"           \"OrchardSprays\"    \"PlantGrowth\"     \n[13] \"Puromycin\"        \"Theoph\"           \"ToothGrowth\"      \"USArrests\"       \n[17] \"USJudgeRatings\"   \"airquality\"       \"anscombe\"         \"attenu\"          \n[21] \"attitude\"         \"cars\"             \"chickwts\"         \"esoph\"           \n[25] \"faithful\"         \"freeny\"           \"infert\"           \"iris\"            \n[29] \"longley\"          \"morley\"           \"mtcars\"           \"npk\"             \n[33] \"pressure\"         \"quakes\"           \"randu\"            \"rock\"            \n[37] \"sleep\"            \"stackloss\"        \"swiss\"            \"trees\"           \n[41] \"warpbreaks\"       \"women\"           \n\n\n随意选择 5 行数据记录，将结果保存到变量 iris_preview\n\nSELECT * FROM iris LIMIT 5;\n\n查看变量 iris_preview 的内容\n\niris_preview\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n\n\n结束后关闭连接\n\ndbDisconnect(conn = conn)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-presentation",
    "href": "documents-html.html#sec-quarto-presentation",
    "title": "16  HTML 文档",
    "section": "\n16.3 制作演示",
    "text": "16.3 制作演示\nQuarto Presentation",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-book",
    "href": "documents-html.html#sec-quarto-book",
    "title": "16  HTML 文档",
    "section": "\n16.4 编写书籍",
    "text": "16.4 编写书籍\nQuarto Book 网页格式",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#footnotes",
    "href": "documents-html.html#footnotes",
    "title": "16  HTML 文档",
    "section": "",
    "text": "(on the difference of Lattice (which eventually was called grid) and Trellis) DSC 2001, Wien (March 2001)↩︎",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html",
    "href": "documents-latex.html",
    "title": "17  PDF 文档",
    "section": "",
    "text": "17.1 LaTeX 基础\nLaTeX 是一个非常方便用户使用的排版工具，提供一套精确的编程语言，下面是一个简单示例。短短 14 行代码展示了大量的常用功能，生成文章标题、作者、目录，设置文档布局、排版公式、交叉引用等。\n接下来，逐行解释上面的 LaTeX 代码。\n所有的 LaTeX 命令都是以反斜杠 \\ 开头的。文类和红包的选项说明可查看其帮助文档。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-tex-elements",
    "href": "documents-latex.html#sec-tex-elements",
    "title": "17  PDF 文档",
    "section": "",
    "text": "\\documentclass[b5paper]{article}\n\\usepackage[heading=true, UTF8]{ctex} % 设置中文环境\n\\usepackage{amsmath,bm} % 处理数学公式\n\\title{LaTeX 入门}\n\\author{张三}\n\\begin{document}\n\\maketitle\n\\tableofcontents\n\\section{线性模型} \\label{sec:lm}\n第 \\ref{sec:lm} 节介绍线性模型，线性模型的矩阵表示见公式 \\ref{eq:lm} 。\n\\begin{align} \\label{eq:lm}\n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n\\end{align}\n\\end{document}\n\n\n\n\\documentclass 命令用来加载文类，常用的有 article、 report、 book 等，文类的选项 b5paper 表示布局为 B5 纸。\n\n\\usepackage 命令用来加载 LaTeX 宏包，上面的第2行设置中文环境，加载了 ctex 宏包，并设置了两个选项 heading=true 和 UTF8 。\n\n\\title 和 \\author 命令分别用来设置文档标题和作者。\\documentclass 和 \\begin{document} 之间的部分叫导言区，常常用来加载宏包和自定义 LaTeX 命令。\\begin{document} 和 \\end{document} 之间的部分叫正文。\n\n\\maketitle 和 \\tableofcontents 命令分别用来生成标题和文档目录。\\section 命令设置小节的标题。\\label 命令设置小节标签，用于交叉引用。\n\n\\begin{align} 和 \\end{align} 是一个公式环境，其间的命令 \\bm 来自 bm 宏包，用于加粗数学符号，命令 \\mathsf 、 \\beta 和 \\epsilon 都来自 amsmath 宏包。\n\n\\begin{align} 之后的命令 \\label{eq:lm} 设置公式标签，eq:lm 是用户指定的唯一标识符，不同公式不能重复使用同一标签，\\ref{eq:lm} 在正文中交叉引用公式。\n\n\n\n17.1.1 中英字体\n大部分情况下，加载 ctex 宏包就够了，但也有的场景需要使用特定的中文字体，比如学位论文排版、项目申请书等，这些对文档格式有极其严格的要求。此时，可以在导言区使用 xecjk 宏包配置字体，或者加载 ctex 宏包时添加选项 fontset=none ，加载 ctex 宏包会自动加载 xecjk 宏包。\n\\usepackage[heading=true, fontset=none, UTF8]{ctex} % 设置中文环境\n下面的代码表示在 LaTeX 文档里使用黑体、宋体、仿宋、楷体四款中文字体。正文字体是宋体，中文没有斜体，倾斜中文使用楷体，加粗中文使用黑体，等宽字体使用仿宋。\n\\setCJKmainfont[ItalicFont={KaiTi_GB2312}, BoldFont={SimHei}]{SimSun}\n\\setCJKsansfont{SimHei}\n\\setCJKmonofont{FangSong_GB2312}\n% 黑体\n\\setCJKfamilyfont{heiti}{SimHei}             \n\\newcommand{\\heiti}{\\CJKfamily{heiti}}\n% 楷体 GB2312\n\\setCJKfamilyfont{kaishu}{KaiTi_GB2312}             \n\\newcommand{\\kaishu}{\\CJKfamily{kaishu}}\n% 宋体\n\\setCJKfamilyfont{songti}{SimSun}             \n\\newcommand{\\songti}{\\CJKfamily{songti}}\n% 仿宋 GB2312\n\\setCJKfamilyfont{fangsong}{FangSong_GB2312}             \n\\newcommand{\\fangsong}{\\CJKfamily{fangsong}}\nLaTeX 提供很多字体宏包，支持英文字体、数学字体单独设定。在加载 amsmath 宏包后，加载 mathpazo 设置数学字体，加载 palatino 设置正文中的英文字体，加载 courier 设置代码中的等宽字体，加载 fontenc 设置字体编码方式。确保已安装 dvips 宏包，它用来处理字体文件。\n\\usepackage{mathpazo} % 数学符号\n\\usepackage{palatino} % 英文衬线字体\n\\usepackage{courier}  % 英文无衬线字体\n\\usepackage[T1]{fontenc} % 字体编码 T1\n\n17.1.2 数学公式\n排版数学公式分三部分，其一是排版的环境，其二是使用的符号、其三是使用的字体。公式环境都是由成对的命令组成，前面已经提及 align 环境，这是一个可对公式编号的适用于对齐多行公式的排版环境。\n\nLaTeX 公式排版环境\n\n可编号\n无编号\n作用\n\n\n\nalign\nalign*\n多行公式对齐\n\n\nequation\nequation*\n可与 split / cases 等环境嵌套使用\n\n\nmultline\nmultline*\n长公式折行\n\n\ngather\ngather*\n多行公式居中\n\n\n\n不可编号的排版环境，行内公式排版，用一对美元符号 $ $或一对小括号 \\( \\)。行间公式排版，用一对双美元符号 $$ $$ 或一对中括号 \\[ \\] 。\nLaTeX 支持丰富的数学符号大、小写英文字母，大、小写希腊字母，字母可以加粗、倾斜，字母也可以设置为等宽字体或衬线字体，还可以设置花体、空心体等。一些常用的数学符号样式见下表。\n\n\n\n\n\n\n\n\n\n大写\n小写\n加粗\n无衬线\n\n\n\\(X\\)\n\\(x\\)\n\\(\\boldsymbol{X}\\)\n\\(\\mathsf{X}\\)\n\n\n衬线\n花体\n空心体\n花体\n\n\n\\(\\mathrm{X}\\)\n\\(\\mathcal{X}\\)\n\\(\\mathbb{X}\\)\n\\(\\mathscr{X}\\)\n\n\n大写\n小写\n加粗\n无衬线\n\n\n\\(\\Gamma\\)\n\\(\\gamma\\)\n\\(\\boldsymbol{\\gamma}\\)\n\\(\\mathsf{\\Gamma}\\)\n\n\n\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2}\n\\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } \n+ \\sqrt{XY} \\Bigg)^3\n\\]\namsmath 宏包渲染效果如下：\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2} \\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } + \\sqrt{XY} \\Bigg)^3\n\\]\nnewtxtext 和 newtxmath 宏包常组合在一起，提供一套 New Times 字体风格的文本和数学公式，一种介于。\n\\documentclass[b5paper]{article}\n\\usepackage{amsmath}\n\\usepackage{newtxtext,newtxmath}\n\\begin{document}\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2}\n\\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } \n+ \\sqrt{XY} \\Bigg)^3\n\\]\n\\end{document}\nnewtxmath 宏包渲染效果如下：\n\n\n\n\n\n图 17.1: newtxmath 包渲染的公式效果\n\n\n\n17.1.3 代码抄录\nverbatim 环境是用来抄录代码的。\n\\begin{verbatim}\nlibrary(stats) % 提供 lowess, rpois, rnorm 等函数\nlibrary(graphics) % 提供 plot 方法\nplot(cars)\nlines(lowess(cars))\n\\end{verbatim}\n渲染出来的效果如下：\n\n\n\n\n\n图 17.2: verbatim 抄录环境\n\n\nlistings 宏包提供丰富的配置，下面在导言区设置代码字体样式和大小，代码块的背景、代码块的行号。\n\\usepackage{xcolor}\n\\definecolor{shadecolor}{rgb}{.97, .97, .97}\n\\usepackage{listings}\n\\lstset{\n  basicstyle=\\ttfamily, % 代码是等宽字体\n  backgroundcolor=\\color{shadecolor},  % 代码块的背景颜色\n  breaklines=true, % 可以段行\n  numbers=left,    % 行序号\n  numberstyle=\\footnotesize, % 行序号字体大小\n  commentstyle=\\ttfamily     % 注释是等宽字体\n}\n启用 lstlisting 环境抄录代码，设置参数 language=R 指定抄录环境中的编程语言类型，以便提供语法高亮。\n\\begin{lstlisting}[language=R]\nlibrary(stats)    % 提供 lowess, rpois, rnorm 等函数\nlibrary(graphics) % 提供 plot 方法\nplot(cars)\nlines(lowess(cars))\n\\end{lstlisting}\n渲染出来的效果如下：\n\n\n\n\n\n图 17.3: lstlisting 抄录环境\n\n\n\n17.1.4 插入图表\n首先在导言区加载 graphicx 宏包，然后可以使用 \\includegraphics 命令插入图片，该命令有一些选项，[width=.65\\textwidth] 表示插入的图片占页面宽度的 65%。\n\\usepackage{graphicx}\n在正文中 figure 环境是专门用来处理的图片，选项 [h] 表示将图片就插入此处，不要浮动。 center 环境将图片居中，\\caption 和 \\label 命令分别用来指定图片的标题和标签。\n\\begin{figure}[h]\n  \\begin{center}\n    \\includegraphics[width=.65\\textwidth]{images/peaks.png}\n    \\caption{图片的标题}\n    \\label{fig:figure}\n  \\end{center}\n\\end{figure}\n渲染效果如下\n\n\n\n\n\n图 17.4: 图片的标题\n\n\ntable 环境用于制作控制表格位置，tabular 用于制作表格，控制表头、每个列和每个格子。\n\\begin{table}[h!]\n  \\begin{center}\n    \\begin{tabular}{|c c c|} \n     \\hline\n      列1 & 列2 & 列3 \\\\ \n      \\hline\n      1 & 6 & 77 \\\\ \n      2 & 7 & 15 \\\\\n      3 & 8 & 44 \\\\\n      \\hline\n    \\end{tabular}\n  \\caption{表格的标题}\n  \\label{tbl:table}\n  \\end{center}\n\\end{table}\n\\begin{table}[h!] 表格环境中 [h!] 让表格不要浮动， center 环境使表格居中，\\begin{tabular}{|c c c|} 表格各个列的元素居中，表格整体封闭， \\hline 制作水平线，\\\\ 用于换行， & 用于表格格子对齐，\\caption 添加表格的标题，\\label 添加表格标识符，以便后续引用。\n渲染出来的效果如下：\n\n\n表格 17.1: 表格的标题\n\n\n\n列 1\n列 2\n列 3\n\n\n\n1\n6\n77\n\n\n2\n7\n15\n\n\n3\n8\n44\n\n\n\n\n\n\n\n17.1.5 交叉引用\n\\ref 命令用于图、表、公式、章节的交叉引用，引用图片 \\ref{fig:figure} 、引用表格 \\ref{tbl:table} 、引用公式 \\ref{eq:lm} 等。\n\\cite 命令用于参考文献的引用。\n\n17.1.6 PDF-A/X\n启用 PDF/X 或 PDF/A 标准，导言区加载 pdfx 宏包\n% PDF/A-1b 标准\n\\usepackage[a-1b]{pdfx}\n示例文档内容如下：\n\\documentclass[b5paper]{article}\n\\usepackage{amsmath} % boldsymbol\n\\usepackage[a-1b]{pdfx}\n\\title{Math in LaTeX}\n\\author{Zhang San}\n\\begin{document}\n\\maketitle\n\\tableofcontents\n\\section{Math}\n\\begin{align}\n\\boldsymbol{x},\\mathbf{x},\\mathsf{x},x\n\\end{align}\n\\begin{verbatim}\nrequire(stats) # for lowess, rpois, rnorm\nrequire(graphics) # for plot methods\nplot(cars)\nlines(lowess(cars))\n\\end{verbatim}\n\\end{document}\n编译 LaTeX 文档的命令如下：\nxelatex --shell-escape -output-driver=\"xdvipdfmx -z 0\" &lt;filename&gt;.tex",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-rmarkdown-elements",
    "href": "documents-latex.html#sec-rmarkdown-elements",
    "title": "17  PDF 文档",
    "section": "\n17.2 R Markdown 基础",
    "text": "17.2 R Markdown 基础\n\n\n---\ntitle: \"R Markdown 入门\"\nauthor: \"张三\"\ndocumentclass: article\noutput: \n  bookdown::pdf_book: \n    extra_dependencies:\n      ctex: \n        - UTF8\n        - heading=true\n      bm: null\n    toc: yes\n    template: null\n    base_format: rmarkdown::pdf_document\n    latex_engine: xelatex\n    number_sections: yes\nmathspec: true\ncolorlinks: yes\nclassoptions: \"b5paper\"    \n---\n\n# 线性模型 {#sec:lm}\n\n第 \\@ref(sec:lm) 节介绍线性模型，线性模型的矩阵表示见公式 \\@ref(eq:lm) 。\n\n```{=tex}\n\\begin{align} \n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n(\\#eq:lm)\n\\end{align}\n```\n\n\n\n17.2.1 中英字体\n\n17.2.2 数学公式\n\n17.2.3 代码抄录\n\n17.2.4 插入图表\n\n17.2.5 交叉引用\n\n17.2.6 布局排版\n\n\n---\ntitle: \"R Markdown 双栏排版\"\nsubtitle: \"副标题\"\nauthor: \"张三\"\ndate: \"`r Sys.Date()`\"\nmathspec: yes\nfontsize: 10pt\ngraphics: yes\nlof: yes\ngeometry: margin=1.18in\noutput: \n  bookdown::pdf_book: \n    number_sections: yes\n    toc: yes\n    fig_crop: no\n    latex_engine: xelatex\n    base_format: rmarkdown::pdf_document\n    citation_package: natbib\n    template: null\n    extra_dependencies:\n      sourcecodepro:\n       - scale=0.85\n      ctex:\n       - heading=true\n       - fontset=fandol\n      caption:\n       - labelfont=bf\n       - singlelinecheck=off\n       - textfont=it\n       - justification=centering\n      Alegreya: null\nkeywords: \n  - 动态文档\n  - 双栏排版\nsubject: \"可重复研究与动态文档\"\nabstract: |\n  这里是摘要内容\nbibliography: \n - packages.bib\nbiblio-style: plainnat\nnatbiboptions: \"authoryear,round\"\nlink-citations: true\ncolorlinks: true\nclassoption: \"UTF8,a4paper,twocolumn\"\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n# R Markdown\n\nR Markdown 文档混合了代码、图形和文字内容[@rmarkdown]。\n\n## 代码 {#sec:code}\n\n```{r cars}\nsummary(cars)\n```\n\n## 插图 {#sec:plot}\n\n```{r}\n#| fig-iris, \n#| fig.cap=\"鸢尾花数据集\", \n#| fig.width=5, \n#| fig.height=4,\n#| fig.showtext=TRUE, \n#| out.width=\"95%\", \n#| echo=FALSE\n\nlibrary(ggplot2)\nggplot(iris, aes(Sepal.Length, Sepal.Width)) +\n  geom_point(aes(colour = Species)) +\n  scale_colour_brewer(palette = \"Set1\") +\n  labs(\n    title = \"鸢尾花数据的散点图\",\n    x = \"萼片长度\", y = \"萼片宽度\", colour = \"鸢尾花类别\",\n    caption = \"鸢尾花数据集最早见于 Edgar Anderson (1935) \"\n  )\n```\n\n# 参考文献 {#chap:refer}",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-quarto-elements",
    "href": "documents-latex.html#sec-quarto-elements",
    "title": "17  PDF 文档",
    "section": "\n17.3 Quarto 基础",
    "text": "17.3 Quarto 基础\n\n\n---\ntitle: \"Quarto 入门\"\nauthor: \"张三\"\nlang: zh\nformat:\n  pdf:\n    include-in-header:\n      - text: |\n          \\usepackage[heading=true,UTF8]{ctex} \n          \\usepackage{amsmath,bm}\n    toc: true\n    mathspec: true\n    number-sections: true\n    colorlinks: true\n    documentclass: article\n    papersize: b5paper\n---\n\n# 线性模型 {#sec-lm}\n\n@sec-lm 介绍线性模型，线性模型的矩阵表示见 @eq-lm 。\n\n$$\n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n$$ {#eq-lm}\n\n\n\n17.3.1 中英字体\n\n17.3.2 数学公式\n\n17.3.3 代码抄录\n\n17.3.4 插入图表\n插入图片的语法是 ![](){}，中括号内是插图标题，小括号内是插图存放路径，大括号内是插图的标识符和属性，比如 width=\"65%\" 设置图片的宽度为页面宽度的 65%。\n![An Elephant](images/peaks.png){#fig-quarto-figure width=\"65%\"}\n渲染效果如下：\n\n\n\n\n\n图 17.5: Peaks 函数图像\n\n\n表格默认左对齐，冒号加虚线、虚线加冒号、虚线两侧加冒号分别对应左对齐、右对齐和居中对齐。\n| Default | Left | Right | Center |\n|---------|:-----|------:|:------:|\n| 12      | 12   |    12 |   12   |\n| 123     | 123  |   123 |  123   |\n| 1       | 1    |     1 |   1    |\n\n: 制作表格的管道语法 {#tbl-quarto-table}\n渲染效果如下：\n\n\n表格 17.2: 制作表格的管道语法\n\n\n\nDefault\nLeft\nRight\nCenter\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n17.3.5 交叉引用\n@tbl-quarto-table 插入 表格 17.2 ，@fig-quarto-figure 插入 图 17.5 。引用表格的标识符前缀必须是 tbl，引用插图的标识符前缀必须是 fig，后以连字符连接其它内容。对比 LaTeX 文档中的图、表引用 \\ref{fig:figure} ，Quarto 中的 @ 符号对应于命令 \\ref 。值得注意，在 LaTeX 文档中，对标识符的命名没有这般要求，但为了区分引用内容，通常会加上不同的前缀。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-quarto-beamer",
    "href": "documents-latex.html#sec-quarto-beamer",
    "title": "17  PDF 文档",
    "section": "\n17.4 Quarto beamer",
    "text": "17.4 Quarto beamer\nQuarto 制作 beamer 幻灯片\n\n\n---\ntitle: \"Quarto 幻灯片模版\"\nauthor:\n  - 张三\n  - 李四\ninstitute: \n  - XX 大学\n  - XX 学院\ndate: today\ndate-format: long\ndocumentclass: beamer\nclassoption: \n  - 11pt\n  - compress\n  - xcolor=x11names\n  - UTF8\nlang: zh\nformat:\n  beamer:\n    theme: Singapore\n    fonttheme: structurebold\n    pdf-engine: lualatex\n    include-in-header: \n      text: |\n        \\usecolortheme[named=SpringGreen4]{structure}\n        \\usepackage[fontset=fandol]{ctex}\n    keep-tex: false\n    mathspec: true\n    toc: true\n    navigation: horizontal\n    latex-min-runs: 2\n    latex-auto-install: false\nlink-citations: true\n---\n\n# In the morning\n\n## Getting up\n\n-   Turn off alarm\n-   Get out of bed\n\n## Breakfast\n\n-   Eat eggs\n-   Drink coffee\n\n# In the evening\n\n## Dinner\n\n-   Eat spaghetti\n-   Drink wine\n\n## Going to sleep\n\n-   Get in bed\n-   Count sheep\n\n\nPandoc’s Markdown 制作 beamer 幻灯片\n\n\n---\ntitle: \"Quarto 幻灯片模版\"\nauthor:\n  - 张三\n  - 李四\ninstitute: \n  - XX 大学\n  - XX 学院\nmathspec: true\ntoc: true\ntoc-title: \"目录\"\n---\n\n# In the morning\n\n## Getting up\n\n-   Turn off alarm\n-   Get out of bed\n\n## Breakfast\n\n-   Eat eggs\n-   Drink coffee\n\n# In the evening\n\n## Dinner\n\n-   Eat spaghetti\n-   Drink wine\n\n## Going to sleep\n\n-   Get in bed\n-   Count sheep\n\n\n将 Markdown 文档转化为 beamer 幻灯片的命令\n\npandoc --pdf-engine lualatex -t beamer \\\n  --variable theme=\"Singapore\" --variable fonttheme=\"structurebold\" \\\n  --variable classoption=\"xcolor=x11names\" \\\n  --variable header-includes=\"\\usecolortheme[named=SpringGreen4]{structure}\" \\\n  --variable header-includes=\"\\usepackage[fontset=fandol]{ctex}\" \\\n  -f markdown pandoc-beamer.md -o pandoc-beamer.pdf",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html",
    "href": "documents-office.html",
    "title": "18  Office 文档",
    "section": "",
    "text": "18.1 Word 文档",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-words",
    "href": "documents-office.html#sec-office-words",
    "title": "18  Office 文档",
    "section": "",
    "text": "18.1.1 Markdown 制作 Word 文档\n本节探索 (R) Markdown + Pandoc 以 Word 格式作为最终交付的可能性。\n\n\n18.1.2 R Markdown 制作 Word 文档\ndocxtools、officer 和 officedown 大大扩展了 rmarkdown 包在制作 Word/PPT 方面的功能。\n\n\n18.1.3 自定义 Word 模版\nR Markdown 借助 Pandoc 将 Markdown 转化为 Word 文档，继承自 Pandoc 的扩展性， R Markdown 也支持自定义 Word 模版，那如何自定义呢？首先，我们需要知道 Pandoc 内建的 Word 模版长什么样子，然后我们依样画葫芦，制作适合实际需要的模版。获取 Pandoc 自带的 Word 和 PPT 模版，只需在命令行中执行\n# DOCX 模版\npandoc -o custom-reference.docx --print-default-data-file reference.docx\n# PPTX 模版\npandoc -o custom-reference.pptx --print-default-data-file reference.pptx\n这里其实是将 Pandoc 自带的 docx 文档 reference.docx 拷贝一份到 custom-reference.docx，而后将 custom-reference.docx 文档自定义一番，但仅限于借助 MS Word 去自定义样式。\n\nWord 文档的 YAML 元数据定义\n如何深度自定义文档模版\n\nbookdown 提供的函数 word_document2() 相比于 rmarkdown 提供的 word_document() 支持图表的交叉引用，更多细节详见帮助 ?bookdown::word_document2。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-powerpoints",
    "href": "documents-office.html#sec-office-powerpoints",
    "title": "18  Office 文档",
    "section": "18.2 PowerPoint 演示",
    "text": "18.2 PowerPoint 演示",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-emails",
    "href": "documents-office.html#sec-office-emails",
    "title": "18  Office 文档",
    "section": "18.3 电子邮件",
    "text": "18.3 电子邮件\nRahul Premraj 基于 rJava 包开发的 mailR 虽然还未在 CRAN 上正式发布，但是已得到很多人的关注，也被广泛的使用，目前作者已经不维护了，继续使用有一定风险。 RStudio 公司 Richard Iannone 新开发的 blastula 扔掉了 Java 的重依赖，更加轻量化、现代化，支持发送群组邮件。\n\n18.3.1 curl 包\ncurl 包提供的函数 send_mail() 本质上是在利用 curl 软件发送邮件，举个例子，邮件内容如下：\nFrom: \"张三\" &lt;邮箱地址&gt;\nTo: \"李四\" &lt;邮箱地址&gt;\nSubject: 测试邮件\n\n你好：\n\n这是一封测试邮件！\n将邮件内容保存为 mail.txt 文件，然后使用 curl 命令行工具将邮件内容发出去。\ncurl --url 'smtp://公司邮件服务器地址:开放的端口号' \\\n  --ssl-reqd --mail-from '发件人邮箱地址' \\\n  --mail-rcpt '收件人邮箱地址' \\\n  --upload-file data/mail.txt \\\n  --user '发件人邮箱地址:邮箱登陆密码'\n\n\n\n\n\n\n注释\n\n\n\nGmail 出于安全性考虑，不支持这种发送邮件的方式，会将邮件内容阻挡，进而接收不到邮件。\n\n\n\n\n18.3.2 blastula 包\n下面以 blastula 包为例怎么支持 Gmail、Outlook、QQ 等邮件发送，先安装系统软件依赖，CentOS 8 上安装依赖\nsudo dnf install -y libsecret-devel libsodium-devel\n然后安装 keyring 和 blastula\ninstall.packages(c(\"keyring\", \"blastula\"))\n接着配置邮件帐户，这一步需要邮件账户名和登陆密码，配置一次就够了，不需要每次发送邮件的时候都配置一次\nlibrary(blastula)\ncreate_smtp_creds_key(\n  id = \"outlook\", \n  user = \"zhangsan@outlook.com\",\n  provider = \"outlook\"\n)\n第二步，准备邮件内容，包括邮件主题、发件人、收件人、抄送人、密送人、邮件主体和附件等。\nattachment &lt;- \"data/mail.txt\" # 如果没有附件，引号内留空即可。\n# 这个Rmd文件渲染后就是邮件的正文，交互图形和交互表格不适用\nbody &lt;- \"examples/html-document.Rmd\" \n# 渲染邮件内容，生成预览\nemail &lt;- render_email(body) |&gt; \n  add_attachment(file = attachment)\nemail\n最后，发送邮件\nsmtp_send(\n  from = c(\"张三\" = \"xxx@outlook.com\"), # 发件人\n  to = c(\"李四\" = \"xxx@foxmail.com\",\n         \"王五\" = \"xxx@gmail.com\"), # 收件人\n  cc = c(\"赵六\" = \"xxx@outlook.com\"), # 抄送人\n  subject = \"这是一封测试邮件\",\n  email = email,\n  credentials = creds_key(id = \"outlook\")\n)\n密送人实现群发单显，即一封邮件同时发送给多个人，每个收件人只能看到发件人地址而看不到其它收件人地址。\nemail &lt;- compose_email(\n  body = md(\"\nMarkdown 格式的邮件内容\n\")\n)\n\nsmtp_send(\n  from = c(\"发件人\" = \"xx@outlook.com\"),\n  to = c(\"收件人\" = \"xx@outlook.com\"),\n  bcc = c(\n    \"抄送人\" = \"xx@outlook.com\"\n    ),\n  subject = \"邮件主题\",\n  email = email,\n  credentials = creds_key(id = \"outlook\")\n)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html",
    "href": "common-statistical-tests.html",
    "title": "19  常见的统计检验",
    "section": "",
    "text": "19.1 单样本检验\nflowchart LR\n  A(单样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D1(方差已知) --&gt; E1(Z 检验)\n  C1 --&gt; D2(方差未知) --&gt; E2(t 检验)\n  B1 --&gt; C2(方差检验) --&gt; E3(卡方检验)\n  B2 --&gt; C3(均值检验) --&gt; E4(Wilcoxon 秩和检验)\n  B2 --&gt; C4(方差检验) --&gt; E5[无检验方法]\n\n\n\n\n图 19.1: 单样本检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-one-sample",
    "href": "common-statistical-tests.html#sec-one-sample",
    "title": "19  常见的统计检验",
    "section": "",
    "text": "19.1.1 正态总体均值检验\n\n19.1.1.1 方差已知\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu - \\mu_0 \\leq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu - \\mu_0 \\geq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu - \\mu_0 = 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 \\neq 0\n\\end{aligned}\n\\]\n设 \\(x_1,\\cdots,x_n\\) 是来自总体 \\(\\mathcal{N}(\\mu,\\sigma^2)\\) 的样本，样本均值和方差分别\n\\(\\bar{x} = \\frac{\\sum_{i=1}^{n}x_i}{n}\\) ，\\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\)\n考虑到 \\(\\bar{x} \\sim \\mathcal{N}(\\mu,\\sigma^2 / n)\\) ，则检验统计量服从正态分布\n\\[\nu = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n\\]\n假定 \\(\\mu_0 = 1\\) 对于检验问题 I 拒绝域 \\(\\{u \\geq u_{1-\\alpha}\\}\\)\n\nset.seed(20232023)\nn &lt;- 20\n# 样本\nx &lt;- rnorm(n, mean = 1.8, sd = 2)\n# 检验统计量\nu &lt;- (mean(x) - 1) / (2 / sqrt(n))\n# 临界值\nqnorm(p = 1 - 0.05, mean = 0, sd = 1)\n\n#&gt; [1] 1.644854\n\n# P 值\n1 - pnorm(q = u)\n\n#&gt; [1] 0.005082465\n\n\n\n\n\n\n\n\n重要\n\n\n\n随机变量 \\(X\\) 服从标准正态分布，它的概率分布函数如下：\n\\[\nP(X \\leq u)= \\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{u}\\mathrm{e}^{-t^2/2}\\mathrm{dt}\n\\]\n若已知概率 \\(p = 0.95\\) ，则对应的下分位点可用函数 qnorm() 计算。\n\nqnorm(p = 0.95, mean = 0, sd = 1)\n\n#&gt; [1] 1.644854\n\n\n\n\n\n19.1.1.2 方差未知\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu - \\mu_0 \\leq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu - \\mu_0 \\geq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu - \\mu_0 = 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 \\neq 0\n\\end{aligned}\n\\]\n考虑到\n\\[\n\\begin{aligned}\n& \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0,1) \\\\\n& \\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi^2(n-1) \\\\\n& \\mathsf{E}\\{s^2\\} = \\sigma^2 \\quad \\mathsf{Var}\\{s^2\\} = \\frac{2\\sigma^4}{n-1}\n\\end{aligned}\n\\]\n根据 t 分布的定义，检验统计量服从 t 分布，即 \\(t \\sim t(n-1)\\)\n\\[\nt = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\n\\]\n假定 \\(\\mu_0 = 1\\) 对于检验问题 I ，拒绝域 \\(\\{t \\geq t_{1-\\alpha}(n-1)\\}\\)\n\n# 检验统计量\nt0 &lt;- (mean(x) - 1) / sqrt(var(x) / n)\n# 临界值\nqt(p = 1 - 0.05, df = n - 1)\n\n#&gt; [1] 1.729133\n\n# P 值\n1 - pt(q = t0, df = n - 1)\n\n#&gt; [1] 0.01569596\n\n\n\n\n\n\n\n\n注释\n\n\n\n英国统计学家 William Sealy Gosset (1876-1937) 于 1908 年在杂志 《Biometrics》 上以笔名 Student 发表论文《The Probable Error of a Mean》(\"Student\" 1908)，论文中展示了独立同正态分布的样本 \\(x_1, \\ldots, x_n \\stackrel{i.i.d}{\\sim} \\mathcal{N}(\\mu,\\sigma^2)\\) 的样本方差 \\(s^2\\) 和样本标准差 \\(s\\) 的抽样分布，根据均值和标准差不相关的性质导出 t 分布，宣告 t 分布的诞生，因其在小样本领域的突出贡献，W. S. Gosset 进入世纪名人录 (Heyde 等 2001)。\n\n\n\n\n\n表格 19.1: \\(t\\) 分布的分位数表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.75\n0.8\n0.9\n0.95\n0.975\n0.99\n0.995\n0.999\n\n\n\n1\n1.0000\n1.3764\n3.0777\n6.3138\n12.7062\n31.8205\n63.6567\n318.3088\n\n\n2\n0.8165\n1.0607\n1.8856\n2.9200\n4.3027\n6.9646\n9.9248\n22.3271\n\n\n3\n0.7649\n0.9785\n1.6377\n2.3534\n3.1824\n4.5407\n5.8409\n10.2145\n\n\n4\n0.7407\n0.9410\n1.5332\n2.1318\n2.7764\n3.7469\n4.6041\n7.1732\n\n\n5\n0.7267\n0.9195\n1.4759\n2.0150\n2.5706\n3.3649\n4.0321\n5.8934\n\n\n6\n0.7176\n0.9057\n1.4398\n1.9432\n2.4469\n3.1427\n3.7074\n5.2076\n\n\n7\n0.7111\n0.8960\n1.4149\n1.8946\n2.3646\n2.9980\n3.4995\n4.7853\n\n\n8\n0.7064\n0.8889\n1.3968\n1.8595\n2.3060\n2.8965\n3.3554\n4.5008\n\n\n9\n0.7027\n0.8834\n1.3830\n1.8331\n2.2622\n2.8214\n3.2498\n4.2968\n\n\n10\n0.6998\n0.8791\n1.3722\n1.8125\n2.2281\n2.7638\n3.1693\n4.1437\n\n\n\n\n\n\n\n\n\n19.1.2 正态总体方差检验\n卡方检验 \\(\\chi^2\\) 检验统计量服从卡方分布。\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\sigma^2 - \\sigma^2_0 \\leq 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\sigma^2 - \\sigma^2_0 \\geq 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\sigma^2 - \\sigma^2_0 = 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 \\neq 0\n\\end{aligned}\n\\]\n一般假定均值 \\(\\mu\\) 是未知的。检验统计量服从卡方分布 \\(\\chi^2(n-1)\\)\n\\[\n\\chi^2 = \\frac{(n-1)s^2}{\\sigma^2_0}\n\\]\n设 \\(\\sigma^2_0 = 1.5^2\\) ，考虑检验问题 I\n\n# 检验统计量\nchi &lt;- (n - 1) * var(x) / 1.5^2\n# 临界值\nqchisq(p = 1 - 0.05, df = n -1)\n\n#&gt; [1] 30.14353\n\n# P 值\n1 - pchisq(q = chi, df = n -1)\n\n#&gt; [1] 0.002183653\n\n\nR 软件提供很多统计分布的计算，因此，不再需要查分位数表，现算即可。计算自由度为 \\(n\\) 概率为 \\(p\\) 的 \\(\\chi^2\\) 分布的分位数 \\(\\chi^2_p(n)\\) ，即\n\\[\nP(\\chi^2(n) \\leq \\chi^2_p(n)) = p\n\\]\n若已知自由度为 1 ，概率为 0.05，则可借助分位数函数 qchisq() 计算对应的（下）分位点。\n\nqchisq(p = 0.05, df = 1)\n\n#&gt; [1] 0.00393214\n\n\n同理，也可以获得 \\(\\chi^2\\) 分布的分位数 表格 19.2 ，计算出来的分位数保留 4 位小数。\n\n\n\n表格 19.2: \\(\\chi^2\\) 分布的分位数表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n0.01\n0.025\n0.05\n0.1\n0.9\n0.95\n0.975\n0.99\n0.995\n\n\n\n1\n0.0000\n0.0002\n0.0010\n0.0039\n0.0158\n2.7055\n3.8415\n5.0239\n6.6349\n7.8794\n\n\n2\n0.0100\n0.0201\n0.0506\n0.1026\n0.2107\n4.6052\n5.9915\n7.3778\n9.2103\n10.5966\n\n\n3\n0.0717\n0.1148\n0.2158\n0.3518\n0.5844\n6.2514\n7.8147\n9.3484\n11.3449\n12.8382\n\n\n4\n0.2070\n0.2971\n0.4844\n0.7107\n1.0636\n7.7794\n9.4877\n11.1433\n13.2767\n14.8603\n\n\n5\n0.4117\n0.5543\n0.8312\n1.1455\n1.6103\n9.2364\n11.0705\n12.8325\n15.0863\n16.7496\n\n\n6\n0.6757\n0.8721\n1.2373\n1.6354\n2.2041\n10.6446\n12.5916\n14.4494\n16.8119\n18.5476\n\n\n7\n0.9893\n1.2390\n1.6899\n2.1673\n2.8331\n12.0170\n14.0671\n16.0128\n18.4753\n20.2777\n\n\n8\n1.3444\n1.6465\n2.1797\n2.7326\n3.4895\n13.3616\n15.5073\n17.5345\n20.0902\n21.9550\n\n\n9\n1.7349\n2.0879\n2.7004\n3.3251\n4.1682\n14.6837\n16.9190\n19.0228\n21.6660\n23.5894\n\n\n10\n2.1559\n2.5582\n3.2470\n3.9403\n4.8652\n15.9872\n18.3070\n20.4832\n23.2093\n25.1882\n\n\n\n\n\n\n\n\n\n19.1.3 总体未知均值检验\n有了均值和方差，为什么还要位置参数和尺度参数？为了更一般地描述问题，扩展范围。特别是在总体分布未知或知之甚少的情况下做检验，不再仅限于均值和方差这样的特征量。\n考虑前面正态总体均值检验中的假设 I 的形式，若总体的分布形式未知，则需要 Wilcoxon （威尔科克森）秩和检验 wilcox.test() 来做均值的比较。\n\nwilcox.test(x = x, mu = 1, alternative = \"greater\")\n\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  x\n#&gt; V = 163, p-value = 0.01479\n#&gt; alternative hypothesis: true location is greater than 1\n\n\n相比于 t 检验，P 值更小。\n\n19.1.4 总体未知方差检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-two-samples",
    "href": "common-statistical-tests.html#sec-two-samples",
    "title": "19  常见的统计检验",
    "section": "\n19.2 两样本检验",
    "text": "19.2 两样本检验\n\n\n\n\n\nflowchart LR\n  A(两样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D1(方差已知) --&gt; E1(Z 检验)\n  C1 --&gt; D2(方差未知但相等) --&gt; E2(t 检验)\n  C1 --&gt; D3(方差未知且不等) --&gt; E3(Welch t 检验)\n  B1 --&gt; C2(方差检验) --&gt; E4(F 检验)\n  C2 --&gt; E7(Bartlett 检验)\n  B2 --&gt; C3(均值检验) --&gt; E5(Wilcoxon 符号秩检验\\nKruskal-Wallis 秩和检验)\n  B2 --&gt; C4(方差检验) --&gt; E8(Ansari-Bradley 检验\\nMood 检验\\nFligner-Killeen 检验)\n\n\n\n\n图 19.2: 两样本检验\n\n\n\n\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的样本。\n\n19.2.1 正态总体均值检验\n两样本均值之差的检验\n\n代码library(ggplot2)\n# 绘制虚线所需的数据\nconst &lt;- 1 / sqrt(2 * pi)\ndat &lt;- data.frame(\n  x = c(-1, -1, 3, 3),\n  y = c(const, 0, const / 1.5, 0),\n  group = c(\"dnorm1\", \"dnorm1\", \"dnorm2\", \"dnorm2\"),\n  upper = c(const, 0, const / 1.5, 0),\n  lower = c(0, 0, 0, 0)\n)\nggplot() +\n  geom_function(\n    fun = dnorm, args = list(mean = -1, sd = 1),\n    aes(colour = \"dnorm1\"), linewidth = 1.5, xlim = c(-5, 10)\n  ) +\n  geom_function(\n    fun = dnorm, args = list(mean = 3, sd = 1.5),\n    aes(colour = \"dnorm2\"), linewidth = 1.5, xlim = c(-5, 10)\n  ) +\n  scale_color_brewer(palette = \"Set1\", labels = c(\n    dnorm1 = \"$\\\\mathcal{N}(\\\\mu_1, \\\\sigma_1^2)$\",\n    dnorm2 = \"$\\\\mathcal{N}(\\\\mu_2, \\\\sigma_2^2)$\"\n  )) +\n  geom_linerange(\n    aes(x = x, y = y, ymin = lower, ymax = upper, colour = group),\n    linewidth = 2, lty = 2, show.legend = FALSE, data = dat\n  ) +\n  annotate(\"text\", x = -1, y = 0, label = \"$\\\\mu_1$\", vjust = 2.5) +\n  annotate(\"text\", x = 3, y = 0, label = \"$\\\\mu_2$\", vjust = 2.5) +\n  theme_classic(base_size = 13) +\n  theme(legend.position.inside = c(0.9, 0.9)) +\n  labs(x = \"$x$\", y = \"$f(x)$\", color = \"正态分布\") +\n  coord_cartesian(clip = \"off\")\n\n\n\n\n\n\n图 19.3: 两样本均值之差的检验\n\n\n\n\n常见检验问题\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu_1 - \\mu_2 \\leq 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu_1 - \\mu_2 \\geq 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu_1 - \\mu_2 = 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 \\neq 0\n\\end{aligned}\n\\]\n\n19.2.1.1 方差已知\n\\[\nu = \\frac{(\\bar{x} - \\bar{y}) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}} }\n\\]\n检验统计量服从标准正态分布 \\(u \\sim \\mathcal{N}(0,1)\\)，检验统计量 \\(u\\) 对应的样本值 \\(u_0\\)，检验的拒绝域和 \\(P\\) 值如下\n\\[\nW_1 = \\{u \\geq u_{1 - \\alpha} \\}, \\quad p_1 = 1 - \\varPhi(u_0)\n\\]\n\nn_1 &lt;- 100\nn_2 &lt;- 80\nmu_1 &lt;- 10\nsigma_1 &lt;- 2.5\nmu_2 &lt;- 6\nsigma_2 &lt;- 4.5\n\nset.seed(20232023)\nx1 &lt;- rnorm(n_1, mean = mu_1, sd = sigma_1)\ny1 &lt;- rnorm(n_2, mean = mu_2, sd = sigma_2)\nu0 &lt;- (mean(x1) - mean(y1)) / sqrt(sigma_1^2 / n_1 + sigma_2^2 / n_2)\nu0\n\n#&gt; [1] 6.779039\n\n\n对检验问题 I，给定显著性水平 \\(\\alpha = 0.05\\)，得出拒绝域 \\(\\{ u \\geq 1.645\\}\\)，计算样本观察值得到的检验统计量的值 \\(u_0 = 6.779\\)，而该值落在拒绝域，所以拒绝原假设，即拒绝 \\(\\mu_1 - \\mu_2 \\leq 0\\)，则接受 \\(\\mu_1 - \\mu_2 &gt; 0\\)。\n\n# 计算拒绝域\nqnorm(1 - 0.05)\n\n#&gt; [1] 1.644854\n\n# 计算 P 值\n1 - pnorm(u0)\n\n#&gt; [1] 6.048939e-12\n\n\n\n19.2.1.2 方差未知但相等\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma^2)\\) 的样本。\nt 检验，检验统计量服从自由度为 \\(n_1 + n_2 - 2\\) 的 t 分布\n\\[\nt = \\frac{(\\bar{x} -\\bar{y})-(\\mu_1 - \\mu_2)}{s_0\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\]\n其中，\n\\[\n\\begin{aligned}\n& \\bar{x} = \\sum_{i=1}^{n_1}x_i \\quad \\bar{y} = \\sum_{i=1}^{n_2}y_i \\\\\n& s_0^2 = \\frac{1}{n_1 + n_2 - 2}\\big(\\sum_{i=1}^{n_1}(x_i - \\bar{x})^2 + \\sum_{i=1}^{n_2}(y_i - \\bar{y})^2\\big)\n\\end{aligned}\n\\]\n\ns_w &lt;- sqrt(1 / (n_1 + n_2 - 2) * ((n_1 - 1) * var(x1) + (n_2 - 1) * var(y1)))\nt0 &lt;- (mean(x1) - mean(y1)) / (s_w * sqrt(1 / n_1 + 1 / n_2))\nt0\n\n#&gt; [1] 8.155781\n\n\n样本观察值 \\(t_0 = 8.155 &gt; t_{0.95}(n_1 + n_2 -2) = 1.653\\) 落在拒绝域内，对于检验问题 I 我们要拒绝原假设\n\n# 临界值：0.95 分位点对应的分位数\nqt(1 - 0.05, df = n_1 + n_2 - 2)\n\n#&gt; [1] 1.653459\n\n# p 值\n1 - pt(t0, df = n_1 + n_2 - 2, lower.tail = TRUE)\n\n#&gt; [1] 3.019807e-14\n\n\n利用 R 内置的 t.test() 函数计算\n\nt.test(x = x1, y = y1, alternative = \"greater\", var.equal = TRUE)\n\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  x1 and y1\n#&gt; t = 8.1558, df = 178, p-value = 3.016e-14\n#&gt; alternative hypothesis: true difference in means is greater than 0\n#&gt; 95 percent confidence interval:\n#&gt;  3.036384      Inf\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 10.338905  6.530406\n\n\n检验统计量的值及对应的 P 值都是一样的。睡眠数据 sleep 记录了两种药物对病人睡眠时间的影响，此数据集由 “Student”（哥塞特的笔名） 收集。\n\n# 方差未知但相等\nt.test(extra ~ group, data = sleep, var.equal = TRUE)\n\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -1.8608, df = 18, p-value = 0.07919\n#&gt; alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.363874  0.203874\n#&gt; sample estimates:\n#&gt; mean in group 1 mean in group 2 \n#&gt;            0.75            2.33\n\n\n\n19.2.1.3 方差未知且不等\n两个样本的样本量不是很大，总体方差也未知，两样本均值之差的显著性检验，即著名的 Behrens-Fisher 问题，Welch 在 1938 年提出近似服从自由度为 \\(l\\) 的 t 分布。\n两样本的样本量很大，尽管总体方差未知，两样本均值之差的显著性检验，极限分布是正态分布，可以用 Z 检验。在样本量很大的情况下，Welch t 检验也可以用。\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的 IID 样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的 IID 样本。\nWelch（韦尔奇） t 检验\n\\[\nT = \\frac{(\\bar{x} - \\bar{y}) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{s_x^2}{n_1} + \\frac{s_y^2}{n_2}} }\n\\]\n其中，\\(s_x^2\\) 表示样本 x 的方差 \\(s_x^2 = \\frac{1}{n_1-1}\\sum_{i=1}^{n_1}(x_i -\\bar{x})^2\\) ，\\(s_y^2\\) 表示样本 y 的方差 \\(s_y^2 = \\frac{1}{n_2-1}\\sum_{i=1}^{n_2}(y_i -\\bar{y})^2\\) 。检验统计量 \\(T\\) 服从自由度为 \\(l\\) 的 t 分布。\n\\[\nl = \\frac{s_0^4}{ \\frac{s_x^4}{n_1^2(n_1 - 1)} + \\frac{s_y^4}{n_2^2(n_2-1)} }\n\\]\n其中， \\(s_0^2 = s_x^2 / n_1 + s_y^2/n_2\\)，\\(l\\) 通常不是整数，实际使用时，\\(l\\) 可取最近的整数。\n\ns0 &lt;- var(x1) / n_1 + var(y1) / n_2\nl &lt;- s0^2 / (var(x1)^2 / (n_1^2 * (n_1 - 1)) + var(y1)^2 / (n_2^2 * (n_2 - 1)))\nl\n\n#&gt; [1] 126.7708\n\n\n所以， \\(l\\) 可取 127。检验统计量的值如下\n\nt0 &lt;- (mean(x1) - mean(y1)) / sqrt(s0)\nt0\n\n#&gt; [1] 7.77002\n\n\n\n# 临界值：0.95 分位点对应的分位数\nqt(1 - 0.05, df = 127)\n\n#&gt; [1] 1.65694\n\n# p 值\n1 - pt(t0, df = 126.7708, lower.tail = TRUE) \n\n#&gt; [1] 1.162404e-12\n\n# 就近取整\n1 - pt(t0, df = 127, lower.tail = TRUE)\n\n#&gt; [1] 1.153078e-12\n\n\n与函数 t.test() 比较，值得注意，t 分布的自由度可以为非整数。\n\nt.test(x = x1, y = y1, alternative = \"greater\", var.equal = FALSE)\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  x1 and y1\n#&gt; t = 7.77, df = 126.77, p-value = 1.162e-12\n#&gt; alternative hypothesis: true difference in means is greater than 0\n#&gt; 95 percent confidence interval:\n#&gt;  2.996334      Inf\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 10.338905  6.530406\n\n\n举例：sleep 数据集\n\n\n\n\n\n\n\n图 19.4: 学生睡眠数据的分布\n\n\n\n\n\n# 方差未知且不等\nt.test(extra ~ group, data = sleep, var.equal = FALSE)\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -1.8608, df = 17.776, p-value = 0.07939\n#&gt; alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.3654832  0.2054832\n#&gt; sample estimates:\n#&gt; mean in group 1 mean in group 2 \n#&gt;            0.75            2.33\n\n\n\n\n\n\n\n\n注释\n\n\n\nEgon Pearson 接过他父亲 Karl Pearson 的职位，担任伦敦大学学院的高尔顿统计教授。许宝騄（Pao-Lu Hsu）在 Jerzy Neyman 和 Egon Pearson 主编的杂志《Statistical Research Memoirs》发表第一篇关于 Behrens-Fisher 问题的论文 (HSU 1938)，1998 年关于 Behrens-Fisher 问题的综述 (Kim 和 Cohen 1998)。陈家鼎和郑忠国一起整理了许宝騄的生平事迹和学术成就，见《许宝騄先生的生平和学术成就》。钟开涞（Kai-Lai Chung）将许宝騄的论文集整理出版 (HSU 1983)。\n\n\nt 检验的影响是如此巨大，以至于广泛存在于具有统计功能的软件中，比如办公软件里的 t 检验。以 MacOS 上的 Numbers 表格软件为例，如 图 19.5 所示，首先打开 Numbers 软件，新建工作表，输入两组数值，然后点击空白处，再从顶部导航栏找到「插入」菜单，「公式」选项，点击扩展选项「新建公式」，在弹出的会话条里输入 TTEST，依次选择第一组，第二组值，检验类型和样本类型，最后点击确认，即可得到两样本 t 检验的 P 值结果。\n\n\n\n\n\n\n\n图 19.5: 办公软件 Numbers 的两样本 t 检验\n\n\n\n\n微软 Excel 办公软件也提供 t 检验计算器，和 MacOS 系统上的 Numbers 办公软件类似，它提供 T.TEST 函数，计算结果也一样，此处从略。R 软件自带 t.test() 函数，也是用于做 t 检验，如下：\n\nt.test(x = c(3, 4, 5, 8, 9, 1, 2, 4, 5), y = c(6, 19, 3, 2, 14, 4, 5, 17, 1))\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  c(3, 4, 5, 8, 9, 1, 2, 4, 5) and c(6, 19, 3, 2, 14, 4, 5, 17, 1)\n#&gt; t = -1.3622, df = 10.255, p-value = 0.2023\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -8.767183  2.100516\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  4.555556  7.888889\n\n\n\n19.2.2 正态总体方差检验\n比较两个正态总体的方差是否相等，F 检验。\n\n# 两样本\nvar.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; F = 0.79834, num df = 9, denom df = 9, p-value = 0.7427\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.198297 3.214123\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;          0.7983426\n\n# 或者\nbartlett.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; Bartlett's K-squared = 0.10789, df = 1, p-value = 0.7426\n\n\n注意：函数 bartlett.test() 支持多样本情况。\n\n19.2.3 总体未知均值检验\n在总体分布未知的情况下，比较均值是否相等的检验。\n\n\nwilcox.test() 适用于单样本和两样本的均值检验，单样本 Wilcoxon 秩和检验，两样本 Wilcoxon 符号秩和检验，后者也叫 Mann-Whitney 检验。\n\nkruskal.test() 适用于两样本和多样本，比较多个均值是否相等的检验，Kruskal-Wallis 秩和检验。\n\n单样本和两样本 wilcox.test()。\n\nwilcox.test(extra ~ group, data = sleep)\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; \n#&gt;  Wilcoxon rank sum test with continuity correction\n#&gt; \n#&gt; data:  extra by group\n#&gt; W = 25.5, p-value = 0.06933\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\ncoin 包提供渐进 Wilcoxon-Mann-Whitney 检验\n\n# Asymptotic Wilcoxon-Mann-Whitney Test\nwilcox_test(extra ~ group, data = sleep, conf.int = TRUE)\n\n#&gt; \n#&gt;  Asymptotic Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  extra by group (1, 2)\n#&gt; Z = -1.8541, p-value = 0.06372\n#&gt; alternative hypothesis: true mu is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.500000e+00  1.270214e-10\n#&gt; sample estimates:\n#&gt; difference in location \n#&gt;              -1.347344\n\n# Exact Wilcoxon-Mann-Whitney Test\nwilcox_test(\n  extra ~ group, data = sleep,\n  distribution = \"exact\", conf.int = TRUE\n)\n\n#&gt; \n#&gt;  Exact Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  extra by group (1, 2)\n#&gt; Z = -1.8541, p-value = 0.06582\n#&gt; alternative hypothesis: true mu is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.5  0.0\n#&gt; sample estimates:\n#&gt; difference in location \n#&gt;                  -1.35\n\n\n两样本和多样本 kruskal.test() 。\n\nkruskal.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  extra by group\n#&gt; Kruskal-Wallis chi-squared = 3.4378, df = 1, p-value = 0.06372\n\n\n能用参数检验的一定也可以用非参数检验，一般来说，非参数检验的功效不小于参数检验，非参数检验不要求分布是正态，比如此时 P 值从 0.07939 降至 0.06372。\n\n19.2.4 总体未知方差检验\n对总体没有分布要求的方差齐性检验方法有三个，按适用范围分类，见下 表格 19.3 。\n\n\n表格 19.3: 检验方法分类\n\n\n\n\n\n\n\n两个样本\n多个样本\n\n\n\nAnsari-Bradley 检验 ansari.test()\n\nMood 检验 mood.test()\n\n\n\nFligner-Killeen 检验 fligner.test()\n\n\n\n\n\n\n\n以 A. R. Ansari 和 R. A. Bradley 命名的 Ansari-Bradley 检验 (Ansari 和 Bradley 1960)，对应的 R 函数是 ansari.test() ，以 A. M. Mood 命名的 Mood 检验 (Mood 1954)，对应的 R 函数是 mood.test() ，这两者都属于两样本的非参数检验，检验尺度参数是否相同（齐性）。以 M. A. Fligner 和 T. J. Killeen 命名的 Fligner-Killeen 检验 (Fligner 和 Killeen 1976)，对应的 R 函数是 fligner.test() ，也属于非参数检验，适用于两样本和多样本的情况。非参数检验常涉及位置参数和尺度参数这一对概念，就正态分布而言，位置参数可以理解为均值 \\(\\mu\\) ，尺度参数可以理解为方差 \\(\\sigma^2\\) 。\n\nansari.test(extra ~ group, data = sleep)\n\n#&gt; Warning in ansari.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; \n#&gt;  Ansari-Bradley test\n#&gt; \n#&gt; data:  extra by group\n#&gt; AB = 50.5, p-value = 0.4927\n#&gt; alternative hypothesis: true ratio of scales is not equal to 1\n\nmood.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Mood two-sample test of scale\n#&gt; \n#&gt; data:  extra by group\n#&gt; Z = 0.44761, p-value = 0.6544\n#&gt; alternative hypothesis: two.sided\n\nfligner.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; Fligner-Killeen:med chi-squared = 0.21252, df = 1, p-value = 0.6448",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multi-samples",
    "href": "common-statistical-tests.html#sec-multi-samples",
    "title": "19  常见的统计检验",
    "section": "\n19.3 多样本检验",
    "text": "19.3 多样本检验\n\n\n\n\n\nflowchart LR\n  A(多样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D2(方差相等) --&gt; E2(F 检验)\n  C1 --&gt; D3(方差不等) --&gt; E3(F 检验)\n  B1 --&gt; C2(方差检验) --&gt; E4(Hartley 检验\\n Bartlett 检验\\n 修正的 Bartlett 检验\\n Levene 检验)\n  B2 --&gt; C3(均值检验) --&gt; E5(Kruskal-Wallis 秩和检验\\n Friedman 秩和检验\\n Quade 检验)\n  B2 --&gt; C4(方差检验) --&gt; E7(Fligner-Killeen 检验)\n\n\n\n\n图 19.6: 多样本检验\n\n\n\n\n本节考虑 Base R 内置的 PlantGrowth 数据集，它收集自 Annette J. Dobson 所著书籍《An Introduction to Statistical Modelling》(Dobson 1983) 第 2 章第 2 节的案例 — 研究植物在两种不同试验条件下的生长情况，植物通过光合作用吸收土壤的养分和空气中的二氧化碳，完成积累，故以植物的干重来刻画植物的生长情况，首先将几乎相同的种子随机地分配到实验组和对照组，基于完全随机实验设计（completely randomized experimental design），经过预定的时间后，将植物收割，干燥并称重。\n\nstr(PlantGrowth)\n\n#&gt; 'data.frame':    30 obs. of  2 variables:\n#&gt;  $ weight: num  4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ...\n#&gt;  $ group : Factor w/ 3 levels \"ctrl\",\"trt1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n设立对照组（控制组）ctrl 和实验组 trt1 和 trt2，比较不同的处理方式对植物干重的影响\n\nsummary(PlantGrowth)\n\n#&gt;      weight       group   \n#&gt;  Min.   :3.590   ctrl:10  \n#&gt;  1st Qu.:4.550   trt1:10  \n#&gt;  Median :5.155   trt2:10  \n#&gt;  Mean   :5.073            \n#&gt;  3rd Qu.:5.530            \n#&gt;  Max.   :6.310\n\n\n每个组都有 10 颗植物，生长情况如 图 19.7 所示\n\n## Annette J. Dobson 扩展的 Plant Weight Data 数据，见 59 页\nlibrary(ggplot2)\nggplot(data = PlantGrowth, aes(x = group, y = weight, color = group)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n图 19.7: 植物干重\n\n\n\n\n\n19.3.1 正态总体均值检验\n\n19.3.1.1 假定同方差\n讲清楚原假设和备择假设。讲清楚假设检验、方差分析、一般线性模型（包含广义线性模型和线性混合效应模型）的关系。\n\\(\\sigma_i^2 = \\mathsf{Var}\\{\\epsilon_{ij}\\}, i = 1,2,3\\) 表示第 \\(i\\) 组的方差，\n\\[\ny_{ij} = \\mu + \\epsilon_{ij}, i = 1,2,3\n\\]\n其中 \\(\\mu\\) 是固定的未知参数。单因素方差分析 oneway.test()\n\n# 假设各组方差相同\noneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)\n\n#&gt; \n#&gt;  One-way analysis of means\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 4.8461, num df = 2, denom df = 27, p-value = 0.01591\n\n\n线性模型也假定各个组的方差是相同的，模型显著性检验的结果和上面是一致的。\n\nfit_lm &lt;- lm(weight ~ group, data = PlantGrowth)\nanova(fit_lm) # 或者 summary(fit)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: weight\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  3.7663  1.8832  4.8461 0.01591 *\n#&gt; Residuals 27 10.4921  0.3886                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n模型输出整理成 表格 19.4\n\n\n\n表格 19.4: 线性回归的输出\n\n\n\n\n\n估计值\n标准差\nt 统计量\nP 值\n\n\n\n\\(\\alpha\\)\n5.032\n0.1971\n25.5265\n0.0000\n\n\n\\(\\beta_1\\)\n-0.371\n0.2788\n-1.3308\n0.1944\n\n\n\\(\\beta_2\\)\n0.494\n0.2788\n1.7720\n0.0877\n\n\n\n\n\n\n\n\n\n19.3.1.2 假定异方差\n\n# 计算各个组的方差\naggregate(data = PlantGrowth, weight ~ group, FUN = var)\n\n#&gt;   group    weight\n#&gt; 1  ctrl 0.3399956\n#&gt; 2  trt1 0.6299211\n#&gt; 3  trt2 0.1958711\n\n# 或者\nwith(PlantGrowth, tapply(weight, group, var))\n\n#&gt;      ctrl      trt1      trt2 \n#&gt; 0.3399956 0.6299211 0.1958711\n\n\n各个组的方差确实不太相同。\n\n# 假设各组方差不同\noneway.test(weight ~ group, data = PlantGrowth, var.equal = FALSE)\n\n#&gt; \n#&gt;  One-way analysis of means (not assuming equal variances)\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 5.181, num df = 2.000, denom df = 17.128, p-value = 0.01739\n\n\n线性混合效应模型，假定每一组（层）有不同的方差。\n\nfit_gls &lt;- nlme::gls(weight ~ 1,\n  data = PlantGrowth, method = \"ML\",\n  weights = nlme::varIdent(form = ~ 1 | group)\n)\nsummary(fit_gls)\n\n#&gt; Generalized least squares fit by maximum likelihood\n#&gt;   Model: weight ~ 1 \n#&gt;   Data: PlantGrowth \n#&gt;        AIC      BIC    logLik\n#&gt;   67.99884 73.60363 -29.99942\n#&gt; \n#&gt; Variance function:\n#&gt;  Structure: Different standard deviations per stratum\n#&gt;  Formula: ~1 | group \n#&gt;  Parameter estimates:\n#&gt;      ctrl      trt1      trt2 \n#&gt; 1.0000000 1.6028758 0.9103568 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Value Std.Error  t-value p-value\n#&gt; (Intercept) 5.205999  0.115762 44.97158       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.78654574 -0.92900218 -0.08794552  0.61374803  2.09128348 \n#&gt; \n#&gt; Residual standard error: 0.5798892 \n#&gt; Degrees of freedom: 30 total; 29 residual\n\n\n考虑每个组有不同的方差，放开同方差的假设，发现，从对数似然的角度来看，有一定提升。\n\nlogLik(fit_lm)\n\n#&gt; 'log Lik.' -26.80952 (df=4)\n\nlogLik(fit_gls)\n\n#&gt; 'log Lik.' -29.99942 (df=4)\n\n\n\n19.3.2 正态总体方差检验\n总体服从正态分布，有四种常见的参数检验方法：\n\nHartley 检验：各组样本量必须相等。\nBartlett 检验：各组样本量可以相等或不等，但每个组的样本量必须不低于 5。\n修正的 Bartlett 检验：在样本量较大或较小、相等或不等场合都可使用。\nLevene 检验：相当于单因素组间方差分析，相比于 Bartlett 检验，Levene 检验更加稳健。\n\n\n\n\n\n\n\n提示\n\n\n\n在总体分布未知的情况下，检验方差齐性的非参数方法也都可以用在这里。\n\n\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的样本，设 \\(z_1,\\cdots,z_{n_3}\\) 是来自总体 \\(\\mathcal{N}(\\mu_3,\\sigma_3^2)\\) 的样本。\n\\[\n\\sigma_1^2 = \\sigma_2^2 = \\sigma_3^2 \\quad vs. \\quad \\sigma_1^2,\\sigma_2^2,\\sigma_3^2 \\quad  \\text{不全相等}\n\\]\nBartlett （巴特利特）检验 bartlett.test() 要求总体的分布为正态分布，检验各个组的方差是否有显著性差异，即方差齐性检验，属于参数检验，适用于多个样本的情况。\n\n# 三样本\nbartlett.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Bartlett's K-squared = 2.8786, df = 2, p-value = 0.2371\n\n# 或者\ncar::leveneTest(weight ~ group, data = PlantGrowth)\n\n#&gt; Levene's Test for Homogeneity of Variance (center = median)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  2  1.1192 0.3412\n#&gt;       27\n\n\n\n19.3.3 总体未知均值检验\nKruskal-Wallis 秩和检验 kruskal.test() 检验均值是否齐性。\n\nkruskal.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  weight by group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\n等价的线性模型表示\n\nfit_lm &lt;- lm(rank(weight) ~ group, data = PlantGrowth)\nanova(fit_lm) # summary(fit_lm)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: rank(weight)\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  618.95 309.475  5.1324 0.01291 *\n#&gt; Residuals 27 1628.05  60.298                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFriedman 秩和检验是非参数检验。适用于单因素重复测量数据的方差分析，检验是否存在一组值显著高于或低于其他组。针对 unreplicated blocked data\n典型场景：n 个品酒师对 k 瓶葡萄酒打分，是否存在一组打分显著高于其他组。检验睡眠质量一组人显著好于另一组人。\n\nfriedman.test(extra ~ group | ID, data = sleep)\n\n#&gt; \n#&gt;  Friedman rank sum test\n#&gt; \n#&gt; data:  extra and group and ID\n#&gt; Friedman chi-squared = 9, df = 1, p-value = 0.0027\n\n\nformula 参数取值为 a ~ b | c ，a 表示数据值，b 分组变量 groups，c 表示 blocks。\nQuade 检验 quade.test() 与 Friedman 检验类似，Quade 检验应用于 unreplicated complete block designs。\n\n# 睡眠实验\nquade.test(extra ~ group | ID, data = sleep)\n\n#&gt; \n#&gt;  Quade test\n#&gt; \n#&gt; data:  extra and group and ID\n#&gt; Quade F = 28.557, num df = 1, denom df = 9, p-value = 0.0004661\n\n\n术语涉及实验设计，比如完全区组设计 complete block designs 。1879 年迈克尔逊光速测量数据记录了五次实验，每次试验测量 20 次光速。数据集 morley 中光速 Speed 已经编码过了，为了展示方便，原始观测速度减去了 299000 (km/sec)。\n\n# 光速实验\nquade.test(Speed ~ Expt | Run, data = morley)\n\n#&gt; \n#&gt;  Quade test\n#&gt; \n#&gt; data:  Speed and Expt and Run\n#&gt; Quade F = 3.6494, num df = 4, denom df = 76, p-value = 0.008976\n\n\n\n\nggplot(data = morley, aes(x = Expt, y = Speed, group = Expt)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal() +\n  labs(x = \"Expt\", y = \"Speed (km/sec)\")\n\n\n\n\n\n\n图 19.8: 1879 年迈克尔逊光速实验数据\n\n\n\n\n\n19.3.4 总体未知方差检验\n三个及以上样本的方差齐性检验。进一步地，我们在线性模型的基础上考虑每个实验组有不同的方差，先做方差齐性检验。\n\n# 非参数检验\nfligner.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Fligner-Killeen:med chi-squared = 2.3499, df = 2, p-value = 0.3088\n\n\n检验的结果显示，可以认为三个组的方差没有显著差异。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-pairwise-data",
    "href": "common-statistical-tests.html#sec-pairwise-data",
    "title": "19  常见的统计检验",
    "section": "\n19.4 配对样本检验",
    "text": "19.4 配对样本检验\n配对样本检验算是两样本检验的一种特殊情况。若待检验的样本不止两个，则两两配对检验。\n\n\n表格 19.5: 配对样本检验\n\n\n\n\n\n\n\n样本\nR 函数\n\n\n两样本\n\n\nt.test(paired = TRUE) 正态总体均值检验\n\nwilcox.test(paired = TRUE) 总体未知均值检验\n\n\n\n\n\n\n\n19.4.1 配对 t 检验\n做两个组的配对 t 检验，函数 t.test() 的参数 paired 设置为 TRUE ，两个组的样本当作配对样本处理。\n\nt.test(extra ~ group, data = sleep, paired = TRUE)\n\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -4.0621, df = 9, p-value = 0.002833\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -2.4598858 -0.7001142\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;           -1.58\n\n\n做多个组的两两配对 t 检验，函数 pairwise.t.test() 的参数 paired 设置为 TRUE ，当仅做两个组的配对 t 检验时，检验结果与前面的等价。\n\nwith(sleep, pairwise.t.test(x = extra, g = group, paired = TRUE))\n\n#&gt; \n#&gt;  Pairwise comparisons using paired t tests \n#&gt; \n#&gt; data:  extra and group \n#&gt; \n#&gt;   1     \n#&gt; 2 0.0028\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n输出结果中，组 1 和组 2 配对 t 检验的 P 值为 0.0028。\n\n\n\n\n\n\n提示\n\n\n\n两个组的配对 t 检验还与变截距的线性混合效应模型等价。\n\nlibrary(nlme)\nm &lt;- lme(fixed = extra ~ group, random = ~ 1 | ID, data = sleep)\nsummary(m)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: sleep \n#&gt;        AIC      BIC    logLik\n#&gt;   77.95588 81.51737 -34.97794\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | ID\n#&gt;         (Intercept)  Residual\n#&gt; StdDev:      1.6877 0.8697384\n#&gt; \n#&gt; Fixed effects:  extra ~ group \n#&gt;             Value Std.Error DF  t-value p-value\n#&gt; (Intercept)  0.75 0.6003979  9 1.249172  0.2431\n#&gt; group2       1.58 0.3889588  9 4.062127  0.0028\n#&gt;  Correlation: \n#&gt;        (Intr)\n#&gt; group2 -0.324\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.63372282 -0.34157076  0.03346151  0.31510644  1.83858572 \n#&gt; \n#&gt; Number of Observations: 20\n#&gt; Number of Groups: 10\n\n\n输出结果中，固定效应部分 group2 意味着相对于第 1 组，第 2 组的增加值，其为 1.58，对应的 t 统计量的值为 4.062127， P 值为 0.0028。调用 nlme 包的函数 intervals() 计算固定效应部分 95% 的置信区间。\n\nintervals(m, which = \"fixed\")\n\n#&gt; Approximate 95% confidence intervals\n#&gt; \n#&gt;  Fixed effects:\n#&gt;                  lower est.    upper\n#&gt; (Intercept) -0.6081944 0.75 2.108194\n#&gt; group2       0.7001140 1.58 2.459886\n\n\ngroup2 对应的 95% 的置信区间是 \\((0.7001140, 2.459886)\\) 。\n\n\n\n19.4.2 配对 Wilcoxon 检验\nWilcoxon 检验函数 wilcox.test() 设置 paired = TRUE 可以做配对检验，但是仅限于两个组。\n\n# 不支持\n# wilcox.test(weight ~ group, data = PlantGrowth, paired = TRUE)\n# 支持\nwilcox.test(extra ~ group, data = sleep, paired = TRUE)\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with zeroes\n\n\n#&gt; \n#&gt;  Wilcoxon signed rank test with continuity correction\n#&gt; \n#&gt; data:  extra by group\n#&gt; V = 0, p-value = 0.009091\n#&gt; alternative hypothesis: true location shift is not equal to 0",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multiple-comparisons",
    "href": "common-statistical-tests.html#sec-multiple-comparisons",
    "title": "19  常见的统计检验",
    "section": "\n19.5 多重假设检验",
    "text": "19.5 多重假设检验\n同时检验多个统计假设。\n\n\n表格 19.6: 多重假设检验\n\n\n\n\n\n\n\n样本\nR 函数\n\n\n多样本\n\n\npairwise.t.test() 正态总体均值检验\n\npairwise.prop.test() 二项总体比例检验\n\npairwise.wilcox.test() 总体未知均值检验\n\n\n\n\n\n\n\n19.5.1 多重 t 检验\n数据集 sleep 仅有两个组，数据集 PlantGrowth 包含三个组，下面以数据集 PlantGrowth 为例，介绍做多个组同时进行两两比较的 t 检验。\n\n# 样本成对的情况\nwith(PlantGrowth, pairwise.t.test(x = weight, g = group, paired = TRUE))\n\n#&gt; \n#&gt;  Pairwise comparisons using paired t tests \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.346 -    \n#&gt; trt2 0.220 0.058\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n函数 pairwise.t.test() 以 P 值给出两两配对比较的结果，trt1 和 ctrl 配对比较，P 值为 0.346，trt2 和 ctrl 配对比较，P 值为 0.220，以此类推。\n\n# 样本非成对的情况\nwith(PlantGrowth, pairwise.t.test(x = weight, g = group))\n\n#&gt; \n#&gt;  Pairwise comparisons using t tests with pooled SD \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.194 -    \n#&gt; trt2 0.175 0.013\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n19.5.2 多重比例检验\n对于离散数据，做两两比例检验，采用函数 pairwise.prop.test() ，如下示例含有 4 个组。\n\nsmokers &lt;- c(83, 90, 129, 70)\npatients &lt;- c(86, 93, 136, 82)\npairwise.prop.test(smokers, patients)\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n\n#&gt; \n#&gt;  Pairwise comparisons using Pairwise comparison of proportions \n#&gt; \n#&gt; data:  smokers out of patients \n#&gt; \n#&gt;   1     2     3    \n#&gt; 2 1.000 -     -    \n#&gt; 3 1.000 1.000 -    \n#&gt; 4 0.119 0.093 0.124\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n19.5.3 Wilcoxon 检验\nWilcoxon 检验的是两个总体的均值是否相等。\n函数 pairwise.wilcox.test() 做两个及以上组的两两比较检验。\n\nwith(PlantGrowth, pairwise.wilcox.test(x = weight, g = group))\n\n#&gt; Warning in wilcox.test.default(xi, xj, paired = paired, ...): cannot compute\n#&gt; exact p-value with ties\n\n\n#&gt; \n#&gt;  Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.199 -    \n#&gt; trt2 0.126 0.027\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n19.5.4 Dunn 检验\ndunn.test 包提供函数 dunn.test() 实现 Dunn 检验，将 Kruskal-Wallis 秩和检验用于两两比较。\n\nlibrary(dunn.test)\nwith(PlantGrowth, dunn.test(x = weight, g = group, method = \"holm\", altp = TRUE))\n\n#&gt;   Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data: weight and group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.02\n#&gt; \n#&gt; \n#&gt;                          Comparison of weight by group                         \n#&gt;                                     (Holm)                                     \n#&gt; Col Mean-|\n#&gt; Row Mean |       ctrl       trt1\n#&gt; ---------+----------------------\n#&gt;     trt1 |   1.117725\n#&gt;          |     0.2637\n#&gt;          |\n#&gt;     trt2 |  -1.689289  -2.807015\n#&gt;          |     0.1823    0.0150*\n#&gt; \n#&gt; alpha = 0.05\n#&gt; Reject Ho if p &lt;= alpha",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-distribution-test",
    "href": "common-statistical-tests.html#sec-distribution-test",
    "title": "19  常见的统计检验",
    "section": "\n19.6 总体分布的检验",
    "text": "19.6 总体分布的检验\n前面介绍的检验方法都是对总体的某个特征数（均值、方差）进行检验，下面介绍的检验方法是针对分布的性质。比如样本是否来自正态分布，两个样本是否来自同一分布，样本点之间是否相互独立，样本点列是否平稳等。通过检验方法探索样本的分布性质。\n\n19.6.1 正态性检验\n什么样的数据是正态的，理论上是清楚的，对统计建模来说，更实际的问题是什么样的数据是够正态的！探索性数据分析是不断提出假设和验证假设的过程。\n\nUsually (but not always) doing tests of normality reflect a lack of understanding of the power of rank tests, and an assumption of high power for the tests (qq plots don’t always help with that because of their subjectivity). When possible it’s good to choose a robust method. Also, doing pre-testing for normality can affect the type I error of the overall analysis.\n— Frank Harrell 1\n\n检验：拒绝原假设和接受原假设的风险，数据本身和理论的正态分布的距离，抛开 P 值\nShapiro 和 Wilk 提出的 W 检验 (Shapiro 和 Wilk 1965) ，对应的 R 函数为 shapiro.test()\n\nset.seed(20232023)\nx &lt;- rnorm(100, mean = 5, sd = 3)\nshapiro.test(x)\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.98635, p-value = 0.3954\n\n\n\nThe issue really comes down to the fact that the questions: “exactly normal?”, and “normal enough?” are 2 very different questions (with the difference becoming greater with increased sample size) and while the first is the easier to answer, the second is generally the more useful one.\n— Greg Snow 2\n\nEP 检验对多种备择假设有较高的效率，利用样本的特征函数和正态分布的特征函数的差的模的平方产生的一个加权积分得到 EP 检验统计量 (Epps 和 Pulley 1983)\n\n\n\n\n\n\n提示\n\n\n\n样本量 \\(n \\geq 200\\) EP 检验统计量 \\(T_{EP}\\) 非常接近 \\(n = \\infty\\) 时 \\(T_{EP}\\) 的分位数。\n\n\n设 \\(x_1, \\ldots, x_n\\) 是来自正态总体 \\(\\mathcal{N}(\\mu,\\sigma^2)\\) 的样本， EP 检验统计量定义为\n\\[\nT_{EP} = 1 + \\frac{n}{\\sqrt{3}} + \\frac{2}{n}\\sum_{i=2}^{n}\\sum_{j=1}^{i-1}\\exp\\big\\{ - \\frac{(x_j - x_i)^2}{2s^2_{\\star}}  \\big\\} - \\sqrt{2} \\sum_{i=1}^{n}\\exp\\big\\{- \\frac{(x_i - \\bar{x})^2}{4s^2_{\\star}}  \\big\\}\n\\]\n其中 \\(\\bar{x},s^2_{\\star}\\) 分别是样本均值和（除以 \\(n\\) 的）样本方差。\n\n19.6.2 同分布检验\nLilliefors 检验 3 和单样本的 ks 检验的关系\n\nAs to whether you can do a Lilliefors test for several groups, that depends entirely on your ability to understand what the underlying question would be (see Adams D 1979).\n— Knut M. Wittkowski 4\n\nKolmogorov-Smirnov 检验：单样本或两样本的同分布检验 ks.test()\n\n# 数据 x 与正态分布比较\nks.test(x, y = \"pnorm\")\n\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x\n#&gt; D = 0.85897, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: two-sided\n\n\n\n19.6.3 相关性检验\n样本的相关性检验 cor.test()：Pearson’s 相关系数检验，Kendall’s \\(\\tau\\) 检验或者 Spearman’s \\(\\rho\\) 检验。基于美国高等法院律师对州法官的评级数据集 USJudgeRatings 介绍各项评分之间的相关性。\n\n# cor.test(method = \"pearson\")  # lm(y ~ 1 + x)\ncor.test(~ CONT + INTG, data = USJudgeRatings)\n\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  CONT and INTG\n#&gt; t = -0.8605, df = 41, p-value = 0.3945\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.4168591  0.1741182\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.1331909\n\n\n其中，变量 CONT 表示律师与法官的联系次数，INTG 表示司法公正。\n\n# cor.test(method = \"kendall\")\n# cor.test(method = \"spearman\") # lm(rank(y) ~ 1 + rank(x))\n\n\n19.6.4 独立性检验\n时间序列独立性检验 Box.test() 计算 Box-Pierce 或 Ljung-Box 检验统计量来检查给定时间序列的独立性假设。\n\n19.6.5 平稳性检验\n时间序列单位根检验，检验时间序列平稳性 Phillips-Perron 的单位根检验 PP.test()\n\nPP.test(x, lshort = TRUE)",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multivariate-hypothesis-testing",
    "href": "common-statistical-tests.html#sec-multivariate-hypothesis-testing",
    "title": "19  常见的统计检验",
    "section": "\n19.7 多元分布情形",
    "text": "19.7 多元分布情形\n\nHotelling T2 检验：总体服从多元正态分布，两样本均值之差的检验。\nMauchly 球形检验：总体服从多元正态分布，单样本协方差矩阵的检验。\n\n\n19.7.1 Hotelling T2 检验\nHotelling T2 检验是一维情形下两样本 \\(t\\) 检验的多维推广。\n\n19.7.2 Mauchly 球形检验\nMauchly 球形检验 mauchly.test() 检验：Wishart 分布的协方差矩阵是否正比于给定的矩阵。一组样本来自多元正态分布，样本的协方差矩阵是关于样本的随机矩阵，随机矩阵的分布服从 Wishart 分布。\n如果 \\(\\bm{x_1}, \\bm{x_2}, \\cdots, \\bm{x_m}\\)，\\(\\bm{x_i} \\in \\mathbb{R}^p\\)，\\(\\bm{x_i} \\overset{i.i.d}{\\sim} \\mathrm{MVN}(0,\\Sigma)\\)，即 \\(m\\) 个样本点都服从均值为 \\(0\\)，协方差矩阵为 \\(\\Sigma\\) 的 \\(p\\) 维多元正态分布 \\(\\mathrm{MVN}(0,\\Sigma)\\)，且样本点之间相互独立。则 \\(X = \\bm{x}^{\\top}\\bm{x}\\) 服从参数为 \\(\\Sigma\\) ，自由度为 \\(m\\) 的 Wishart 分布 \\(W_p(\\Sigma, m)\\)。概率密度函数如下\n\\[\nf(X) = \\frac{1}{2^{\\frac{mp}{2}}|\\Sigma|^{\\frac{m}{2}}\\Gamma_{p}(\\frac{m}{2})}|X|^{(m-p-1)/2}\\exp\\{-\\frac{1}{2}\\mathrm{tr}(\\Sigma^{-1}X)\\}\n\\]\n其中， \\(\\Gamma_p\\) 是多元伽马函数，定义如下\n\\[\n\\Gamma_p(\\frac{m}{2}) = \\pi^{p(p-1)/4}\\prod_{j=1}^{p}\\Gamma(\\frac{m}{2} - \\frac{j-1}{2})\n\\]\nR 语言内置了一个模拟数生成器，可以直接模拟出服从 Wishart 分布 \\(W_p(\\Sigma, m)\\) 的样本，\\(m = \\mathrm{df}, \\Sigma = \\mathrm{Sigma}\\)。 R 语言命令如下：\n\nrWishart(n, df, Sigma)\n\n其中，整型参数 n 指定样本量，数值参数 df 指定自由度，正定的 \\(p \\times p\\) 矩阵 Sigma 指定 Wishart 分布的矩阵参数。rWishart() 返回一个 \\(p\\times p \\times n\\) 数组 \\(R\\)，其中 \\(R[,,i]\\) 是正定矩阵，是服从 Wishart 分布 \\(W_p(\\Sigma, m)\\) 的一个样本点，其中 \\(m = \\mathrm{df}, \\Sigma = \\mathrm{Sigma}\\)。\n\nset.seed(2022)\n# 构造 n 个随机矩阵\nS &lt;- matrix(c(1.2, 0.9, 0.9, 1.2), nrow = 2, ncol = 2)\nrWishart(n = 3, df = 2, Sigma = S)\n\n#&gt; , , 1\n#&gt; \n#&gt;          [,1]      [,2]\n#&gt; [1,] 3.213745 1.2445391\n#&gt; [2,] 1.244539 0.5032642\n#&gt; \n#&gt; , , 2\n#&gt; \n#&gt;          [,1]     [,2]\n#&gt; [1,] 4.443057 3.387850\n#&gt; [2,] 3.387850 2.605341\n#&gt; \n#&gt; , , 3\n#&gt; \n#&gt;          [,1]     [,2]\n#&gt; [1,] 3.614911 4.797919\n#&gt; [2,] 4.797919 6.846811\n\n\n随机矩阵 \\(M\\) 的期望 \\(\\mathsf{E}(M) = m \\times \\Sigma\\)，随机矩阵 \\(M\\) 中每个元素的方差\n\\[\n\\mathsf{Var}(M_{ij}) = m (\\Sigma_{ij}^2 + \\Sigma_{ii}\\Sigma_{jj}), \\quad S = \\Sigma\n\\]\n若 \\(p = 1\\)，即 \\(\\Sigma\\) 是一个标量 \\(\\sigma^2\\)，Wishart 分布退化为自由度为 \\(\\mathrm{df}\\) 的卡方分布 \\(\\chi^2\\)，即 \\(W_1(\\sigma^2, m) = \\sigma^2\\chi_{m}^2\\)。下面计算随机矩阵 \\(M\\) 的期望。\n\nset.seed(2022)\nWish &lt;- rWishart(n = 3000, df = 2, Sigma = S)\n# 计算随机矩阵 M 的期望\napply(Wish, MARGIN = 1:2, FUN = mean)\n\n#&gt;          [,1]     [,2]\n#&gt; [1,] 2.375915 1.792558\n#&gt; [2,] 1.792558 2.430074\n\n# 随机矩阵 M 的期望理论值\n2 * S\n\n#&gt;      [,1] [,2]\n#&gt; [1,]  2.4  1.8\n#&gt; [2,]  1.8  2.4\n\n\n接着计算随机矩阵 \\(M\\) 的方差。\n\n# 样本方差\napply(Wish, MARGIN = 1:2, var)\n\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.668746 4.472606\n#&gt; [2,] 4.472606 5.729270\n\n# 理论方差\n2*(S^2 + tcrossprod(diag(S)))\n\n#&gt;      [,1] [,2]\n#&gt; [1,] 5.76 4.50\n#&gt; [2,] 4.50 5.76",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-common-statistical-tests-notes",
    "href": "common-statistical-tests.html#sec-common-statistical-tests-notes",
    "title": "19  常见的统计检验",
    "section": "\n19.8 假设检验的一些注记",
    "text": "19.8 假设检验的一些注记\n真实数据的情况是复杂多样的，本章按照数据情况对检验方法分类，方便读者根据手头的数据情况，快速从众多的方法中定位最合适的检验方法。依次是单样本检验、两样本检验、多样本检验、计数数据检验、配对样本检验。如果已知符合参数检验的条件，优先考虑参数检验。如果不确定是否符合参数检验的条件，对参数检验和非参数检验方法都适用，非参数检验方法的功效更大，方法更优。在总体分布未知的情况下，无论是对均值检验还是对方差检验，大部分情况下都需要非参数检验方法。\n在假设检验理论方面作出贡献的人非常多，自 Karl Pearson 提出卡方统计量、卡方分布和卡方检验以来，陆续涌现出来一批人及载入史册的工作，见下表。不难看出，19 世纪后半叶至20世纪前半叶，假设检验理论经过一个世纪的发展趋于成熟。从假设检验这个细分领域也印证了世界的统计中心从英国逐渐转移到美国，相比而言，中国在这方面的贡献微乎其微。笔者同时也注意到很多检验方法都是以人名命名的，且已经被编写到各类统计软件中。R 语言中有十分丰富的统计检验函数，根据这些函数及其帮助文档可以追溯到检验方法的发明者，再从维基百科中找到学者及其提出的检验方法的详情页，最后，根据学者的出生日期排序整理成表格。\n\n\n表格 19.7: 对假设检验理论有重要贡献的学者\n\n\n\n\n\n\n\n\n\n\n\n姓名\n国籍\n出生\n死亡\n寿命\n贡献\n\n\n\nK. Pearson\n英国\n1857-03-27\n1936-04-27\n79\n卡方分布、卡方检验\n\n\nC. Spearman\n英国\n1863-09-10\n1945-09-17\n82\nSpearman’s \\(\\rho\\)\n\n\n\nW. S. Gosset\n英国\n1876-06-13\n1937-10-16\n61\nt 分布、t 检验\n\n\nR. A. Fisher\n英国\n1890-02-17\n1962-07-29\n72\nF 检验、Fisher 精确检验\n\n\nF. Wilcoxon\n美国\n1892-09-02\n1965-11-18\n73\nWilcoxon 秩检验\n\n\nH. Cramér\n瑞士\n1893-09-25\n1985-10-05\n92\nCramér’s V\n\n\nJ. Neyman\n波兰、美国\n1894-04-16\n1981-08-05\n87\nNeyman-Pearson 引理\n\n\nE. S. Pearson\n英国\n1895-08-11\n1980-06-12\n84\nNeyman-Pearson 引理\n\n\nH. Hotelling\n美国\n1895-09-29\n1973-12-26\n78\nHotelling T2 检验\n\n\nE. J. G. Pitman\n澳大利亚\n1897-10-29\n1993-07-21\n95\nPitman 估计\n\n\nJ. Wishart\n英国\n1898-11-28\n1956-07-14\n57\nWishart 分布\n\n\nQ. M. McNemar\n美国\n1900-02-20\n1986-07-03\n86\nMcNemar 检验\n\n\nF. Yates\n英国\n1902-05-12\n1994-06-17\n92\nYates 矫正\n\n\nA. Wald\n匈牙利\n1902-10-31\n1950-12-13\n48\nWald 检验\n\n\nA. Kolmogorov\n苏联\n1903-04-25\n1987-10-20\n84\nKolmogorov-Smirnov 检验\n\n\nS. S. Wilks\n美国\n1906-06-17\n1964-03-07\n57\nWilks 检验/似然比检验\n\n\nJ. W. Mauchly\n美国\n1907-08-30\n1980-01-08\n72\nMauchly 球形检验\n\n\nM. Kendall\n英国\n1907-09-06\n1983-03-29\n76\nKendall’s \\(\\tau\\)\n\n\n\nW. G. Cochran\n英国、美国\n1909-07-15\n1980-03-29\n70\nCochran–Mantel–Haenszel 检验\n\n\nM. S. Bartlett\n英国\n1910-06-18\n2002-01-08\n91\nBartlett 检验\n\n\nW. M. Haenszel\n美国\n1910-06-19\n1998-03-13\n87\nCochran–Mantel–Haenszel 检验\n\n\nB. L. Welch\n英国\n1911\n1989-12-29\n78\nWelch t 检验\n\n\nH. O. Hartley\n德国\n1912-04-13\n1980-12-30\n68\nHartley 检验\n\n\nM. Friedman\n美国\n1912-07-31\n2006-11-16\n94\nFriedman 秩和检验\n\n\nW. A. Wallis\n美国\n1912-11-05\n1998-10-12\n85\nKruskal-Wallis 检验\n\n\nH. Levene\n美国\n1914-01-17\n2003-07-02\n89\nLevene 检验\n\n\nJ. W. Tukey\n美国\n1915-06-16\n2000-07-26\n85\nTukey’s HSD 检验\n\n\nO. J. Dunn\n美国\n1915-09-01\n2008-01-12\n92\nDunn 检验\n\n\nE. L. Lehmann\n法国、美国\n1917-11-20\n2009-09-12\n91\nLehmann-Scheffé 定理\n\n\nT. W. Anderson\n美国\n1918-06-05\n2016-09-17\n98\nAnderson–Darling 检验\n\n\nN. Mantel\n美国\n1919-02-16\n2002-05-25\n83\nCochran–Mantel–Haenszel 检验\n\n\nW. Kruskal\n美国\n1919-10-10\n2005-04-21\n85\nKruskal-Wallis 检验\n\n\nGeorge E. P. Box\n英国、美国\n1919-10-18\n2013-03-28\n93\nBox-Pierce 检验\n\n\nC. R. Rao\n印度、美国\n1920-09-10\n2023-08-22\n102\nScore 检验\n\n\nM. Wilk\n加拿大\n1922-12-18\n2013-02-19\n90\nShapiro-Wilk 检验\n\n\nJ. Durbin\n英国\n1923-06-30\n2012-06-23\n88\nDurbin 检验\n\n\nL. Le Cam\n法国\n1924-11-18\n2000-04-25\n75\n渐近理论\n\n\nH. Lilliefors\n美国\n1928-06-14\n2008-02-23\n80\nLilliefors 检验\n\n\nS. S. Shapiro\n美国\n1930-07-13\n-\n93\nShapiro-Wilk 检验\n\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n笔者仅根据自己搜集了解的材料制作此表，受一定的局限，或有缺漏和主观。20 世纪 60 年代后，假设检验理论开始成熟起来了，所以仅考虑 1930 年以前出生的。此外，学者需具有一定的名气，至少收录在维基百科词条里。\n\n\n其中，最重要的统计学家及其学术传承关系见下 图 19.9 。\n\n\n\n\n\nflowchart LR\n  F_Galton(F. Galton\\n 1822-1911) --&gt; K_Pearson(K. Pearson\\n 1857-1936)\n  K_Pearson --&gt; R_A_Fisher(R. A. Fisher \\n 1890-1962)\n  R_A_Fisher --&gt; J_Neyman(J. Neyman\\n1894-1981)\n  R_A_Fisher --&gt; E_S_Pearson(E. S. Pearson \\n1895-1980)\n  J_Neyman --&gt; E_L_Lehmann(E. L. Lehmann\\n1917-2009)\n  E_S_Pearson --&gt; A_Wald(A. Wald\\n1902-1950)\n\n\n\n\n图 19.9: 最重要的统计学家及其学术传承关系\n\n\n\n\nF. Galton 是 K. Pearson 的老师，E. S. Pearson 是 K. Pearson 的儿子。E. L. Lehmann 是 J. Neyman 的学生，J. Neyman 和 E. S. Pearson 一起提出 N-P 引理，是置信区间和假设检验理论的奠基人。假设检验和区间估计、决策理论是紧密相关的，A. Wald 是继 J. Neyman 和 E. S. Pearson 之后，继续开疆拓土的一位统计学家，不幸的是，在一场飞机事故中英年早逝。\n\n19.8.1 假设检验和多重比较的关系\nFDR 是 False Discovery Rate 的简称\n\n19.8.2 假设检验和方差分析的关系\n\n19.8.2.1 单因素一元方差分析\n函数 aov() 可以做单、双因素一元方差分析\n\nfit_aov &lt;- aov(weight ~ group, data = PlantGrowth)\n\n两两比较，多重比较\n\nTukeyHSD(fit_aov)\n\n#&gt;   Tukey multiple comparisons of means\n#&gt;     95% family-wise confidence level\n#&gt; \n#&gt; Fit: aov(formula = weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt; $group\n#&gt;             diff        lwr       upr     p adj\n#&gt; trt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711\n#&gt; trt2-ctrl  0.494 -0.1972161 1.1852161 0.1979960\n#&gt; trt2-trt1  0.865  0.1737839 1.5562161 0.0120064\n\n\n自己实现方差分析\n\n# 自由度\ndf1 &lt;- 2\ndf2 &lt;- 27\n# 每组样本量\ngroup.size &lt;- 10\n# 组间方差\nsq.between &lt;- sum(tapply(\n  PlantGrowth$weight, PlantGrowth$group,\n  function(x) (mean(x) - mean(PlantGrowth$weight))^2\n)) * group.size\n\nmean.sq.between &lt;- sq.between / df1\n\n# 组内方差\nsq.within &lt;- sum(tapply(\n  PlantGrowth$weight, PlantGrowth$group,\n  function(x) sum((x - mean(x))^2)\n))\n\nmean.sq.within &lt;- sq.within / df2\n# F 统计量\nf.value &lt;- mean.sq.between / mean.sq.within\nf.value\n\n#&gt; [1] 4.846088\n\n# P 值\np.value &lt;- 1 - pf(f.value, df1, df2)\np.value\n\n#&gt; [1] 0.01590996\n\n\n从假设检验角度看单因素方差分析，方差分析其实是在比较多个组的均值是否有显著差异。\n\noneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)\n\n#&gt; \n#&gt;  One-way analysis of means\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 4.8461, num df = 2, denom df = 27, p-value = 0.01591\n\n\n方差分析还可以纳入线性模型的框架内\n\nfit &lt;- lm(weight ~ group, data = PlantGrowth)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.0710 -0.4180 -0.0060  0.2627  1.3690 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   5.0320     0.1971  25.527   &lt;2e-16 ***\n#&gt; grouptrt1    -0.3710     0.2788  -1.331   0.1944    \n#&gt; grouptrt2     0.4940     0.2788   1.772   0.0877 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.6234 on 27 degrees of freedom\n#&gt; Multiple R-squared:  0.2641, Adjusted R-squared:  0.2096 \n#&gt; F-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\n\nanova(fit)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: weight\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  3.7663  1.8832  4.8461 0.01591 *\n#&gt; Residuals 27 10.4921  0.3886                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n假定各个组来自正态总体，且它们的方差相同，从 F 统计量的值和检验的 P 值看，方差分析 aov() 、假设检验 oneway.test() 和线性模型 lm() 在这里等价了。\n\n19.8.2.2 双因素一元方差分析\n\nwith(ToothGrowth, interaction.plot(supp, dose, len))\n\n\n\n\n\n\n图 19.10: OJ 和 VC 的交互作用\n\n\n\n\n如果 dose = 2， 则 len 与提供的方式 supp 没有关系。\n\nfit_aov &lt;- aov(len ~ supp * dose, data = ToothGrowth)\nfit_aov\n\n#&gt; Call:\n#&gt;    aov(formula = len ~ supp * dose, data = ToothGrowth)\n#&gt; \n#&gt; Terms:\n#&gt;                      supp      dose supp:dose Residuals\n#&gt; Sum of Squares   205.3500 2224.3043   88.9201  933.6349\n#&gt; Deg. of Freedom         1         1         1        56\n#&gt; \n#&gt; Residual standard error: 4.083142\n#&gt; Estimated effects may be unbalanced\n\n\n\n19.8.2.3 单因素多元方差分析\nPlantGrowth 属于一元方差分析，观测变量只有植物干重一个变量。如果推广到多个变量，就是多元方差分析 multivariate analysis of variance 。不同种类的鸢尾花的萼片长度的分布有所不同。\n\nlibrary(ggplot2)\nlibrary(ggridges)\nggplot(data = iris, aes(x = Sepal.Length, y = Species, fill = Species)) +\n  scale_fill_brewer(palette = \"Greys\") +\n  geom_density_ridges(bandwidth = 0.2) +\n  theme_ridges(font_size = 12, font_family = \"sans\")\n\n\n\n\n\n\n图 19.11: 鸢尾花萼片长度的分布\n\n\n\n\n\nfit &lt;- manova(cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, data = iris)\nsummary(fit, test = \"Wilks\")\n\n#&gt;            Df    Wilks approx F num Df den Df    Pr(&gt;F)    \n#&gt; Species     2 0.023439   199.15      8    288 &lt; 2.2e-16 ***\n#&gt; Residuals 147                                              \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nP 值小于 0.0.5，说明 iris 数据集三个组的均值向量有显著差异。关于均值向量的检验方法，请看 ?summary.manova 。\n按 Species 分组统计各个变量的样本均值、样本方差\n\naggregate(data = iris, cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, mean)\n\n#&gt;      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; 1     setosa        5.006       3.428        1.462       0.246\n#&gt; 2 versicolor        5.936       2.770        4.260       1.326\n#&gt; 3  virginica        6.588       2.974        5.552       2.026\n\naggregate(data = iris, cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, var)\n\n#&gt;      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; 1     setosa    0.1242490  0.14368980   0.03015918  0.01110612\n#&gt; 2 versicolor    0.2664327  0.09846939   0.22081633  0.03910612\n#&gt; 3  virginica    0.4043429  0.10400408   0.30458776  0.07543265\n\n\n\n19.8.3 假设检验与区间估计的关系\n区间估计的意义是解决点估计可靠性问题，它用置信系数解决了对估计结果的信心问题，弥补了点估计的不足。置信系数是最大的置信水平。\nBase R 提供的 binom.test() 函数可以精确计算置信区间，即所谓的 Clopper-Pearson 区间，而 prop.test() 函数可近似计算置信区间，即所谓的 Wilson 区间。以单样本的比例检验为例。\n\n# 近似区间估计\nprop.test(x = 2, n = 10, p = 0.95, conf.level = 0.95, correct = TRUE)\n\n#&gt; Warning in prop.test(x = 2, n = 10, p = 0.95, conf.level = 0.95, correct =\n#&gt; TRUE): Chi-squared approximation may be incorrect\n\n\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  2 out of 10, null probability 0.95\n#&gt; X-squared = 103.16, df = 1, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true p is not equal to 0.95\n#&gt; 95 percent confidence interval:\n#&gt;  0.03542694 0.55781858\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.2\n\n# 精确区间估计\nbinom.test(x = 2, n = 10, p = 0.95, conf.level = 0.95)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  2 and 10\n#&gt; number of successes = 2, number of trials = 10, p-value = 1.605e-09\n#&gt; alternative hypothesis: true probability of success is not equal to 0.95\n#&gt; 95 percent confidence interval:\n#&gt;  0.02521073 0.55609546\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                    0.2\n\n\n实际达到的置信度水平随真实的未知参数值和样本量的变化而剧烈波动，这意味着这种参数估计方法在实际应用中不可靠、真实场景中参数真值是永远未知的，样本量是可控的，并且是可以变化的。根本原因在于这类分布是离散的，比如这里的二项分布。当样本数据服从离散的分布，置信区间的端点也是离散的。这种缺陷是无法避免的，清晰的置信区间和离散的数据之间存在无法调和的冲突。\n\n19.8.4 常见的统计检验是线性模型\n两样本的均值检验：非参数检验方法\n\n19.8.4.1 Wilcoxon 符号秩检验\n与 wilcox.test() 等价的线性模型\n\nsigned_rank &lt;- function(x) sign(x) * rank(abs(x))\nfit &lt;- lm(signed_rank(extra) ~ group, data = sleep)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = signed_rank(extra) ~ group, data = sleep)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -14.55  -6.55   0.90   6.90  13.95 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)  \n#&gt; (Intercept)    3.050      2.872   1.062   0.3022  \n#&gt; group2         8.300      4.061   2.044   0.0559 .\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 9.081 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.1884, Adjusted R-squared:  0.1433 \n#&gt; F-statistic: 4.177 on 1 and 18 DF,  p-value: 0.05589\n\n\n\n19.8.4.2 Kruskal-Wallis 秩和检验\n与 kruskal.test() 等价的线性模型表示。\n\nfit &lt;- lm(rank(extra) ~ group, data = sleep)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = rank(extra) ~ group, data = sleep)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -8.450 -3.925 -0.500  5.275  8.950 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)    8.050      1.738   4.633 0.000207 ***\n#&gt; group2         4.900      2.457   1.994 0.061520 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.495 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.1809, Adjusted R-squared:  0.1354 \n#&gt; F-statistic: 3.976 on 1 and 18 DF,  p-value: 0.06152\n\n\n\n19.8.5 假设检验的工业应用\n传统的试验设计为什么不适用于互联网？因为Fisher的实验设计和方差分析，主要针对的是受控对象，比如测试武器、肥料配比、飞机制造等实体的东西。互联网是虚拟经济，实验的对象是人，对平台来说，人的行为是半知半解，更不受控，所以需要成千上万、乃至几十万的样本才能抵消样本内部的随机性。互联网数据的噪声太多、太大了，微小的变化就好像一粒小石子扔进大海里，要获得样本间显著的差异性，需要累积相当的样本量。另一方面，大型的互联网公司，搜索、推荐、广告等业务相对成熟，提升关键指标，拿到好的结果，往往比较困难。成熟的业务几乎不太可能一次实验拿到很好的结果，所以，方向比努力重要，更快地迭代，跑在同行前面，更快地试错（想法），试更多的错（想法），更好地试错（想法），累积更多的经验，做更多地创新，这是 A/B 实验平台的核心价值。\n曾经，在学校里，我总想获得一个全局最优解，并且还有这样的情结，到了厂里，发现没人研究全局最优解，大家都在做 A/B 实验优化自己的子业务和方向。有时候这个细分业务方向甚至也就小几万的用户了。 全局最优解和局部最优解，我们不太可能获得全局最优解，一则全局最优解受影响的因素很多，而这些因素变化很快，所以，即使可以获得全局最优解，代价会非常大，那么，怎么办呢？还不如获取局部最优解，研究一个个局部显然比研究全局要简单的多，此外，研究局部的好处是可以快速地随业务迭代。\n一个完整的实验周期包含提出问题、设计实验、收集数据、组织数据、统计检验、分析结论、数据解读、数据交流、决策行动、业务价值。这是一个闭环，根据业务中发现的问题，提出解决方法，并设计实验验证。问题有时候就是机会，奋斗的方向，解决问题自然就会带来业务价值。实验又可以按业务问题、数据问题和统计问题划分三个阶段。\n\n业务问题：根据目标确定方向，找到有价值的、可以解决的业务问题，再提出合理的统计假设。\n数据问题：数据收集、数据组织、数据管理、数据治理，验证数据流的完整性、一致性等。\n统计问题：设计实验方案，包括分流、实验周期等，利用假设检验、区间估计和功效分析等统计工具完成显著性分析、可靠性分析，撰写数据分析和评估报告。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-common-statistical-tests-exercise",
    "href": "common-statistical-tests.html#sec-common-statistical-tests-exercise",
    "title": "19  常见的统计检验",
    "section": "\n19.9 习题",
    "text": "19.9 习题\n\n分析《红楼梦》的情景描写。参考 2009 年东南大学韦博成教授将两个独立二项总体的等价性检验应用于《红楼梦》前80回与后40回某些文风差异的统计分析 (韦博成 2009)。\n\n根据数据集 chickwts 分析不同喂食方式对小鸡体重的影响。（单因素方差分析）\n\nggplot(data = chickwts, aes(x = feed, y = weight)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n图 19.12: 不同喂食方式对小鸡的影响\n\n\n\n\n\n\n根据数据集 ChickWeight 分析 4 种喂食方式对小鸡体重有影响，每个小鸡本身对喂食方式的接受、吸收程度不一样、它们本身的素质不一样（个体差异），要考察喂食的方式的影响，应该剔除掉个体差异，才是喂食方式的真正影响。\n\nggplot(data = ChickWeight, aes(x = Time, y = weight, group = Chick, color = Diet)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~Diet) +\n  theme_minimal()\n\n\n\n\n\n\n图 19.13: 不同喂食方式对小鸡的影响（续）\n\n\n\n\n\n\n\n\n\n\nAnsari, A. R., 和 R. A. Bradley. 1960. 《Rank-Sum Tests for Dispersions》. The Annals of Mathematical Statistics 31 (4): 1174–89. https://doi.org/10.1214/aoms/1177705688.\n\n\nCohen, Jacob. 1994. 《The Earth Is Round (\\(p &lt; .05\\))》. American Psychologist 49 (12): 997–1003. https://doi.org/10.1037/0003-066x.49.12.997.\n\n\nDobson, Annette J. 1983. An Introduction to Statistical Modelling. 1st 本. London: Chapman; Hall/CRC. https://doi.org/10.1007/978-1-4899-3174-0.\n\n\nEpps, T. W., 和 Lawrence B. Pulley. 1983. 《A Test for Normality Based on the Empirical Characteristic Function》. Biometrika 70 (3): 723–26. https://doi.org/10.2307/2336512.\n\n\nFligner, Michael A., 和 Timothy J. Killeen. 1976. 《Distribution-Free Two-Sample Tests for Scale》. Journal of the American Statistical Association 71 (353): 210–13. https://doi.org/10.1080/01621459.1976.10481517.\n\n\nHeyde, C. C., E. Seneta, P. Crépel, S. E. Fienberg, 和 J. Gani. 2001. Statisticians of the Centuries. New York, NY: Springer-Verlag. https://doi.org/10.1007/978-1-4613-0179-0.\n\n\nHSU, P. L. 1938. 《Contribution to the theory of \"Student’s\" \\(T\\)-test as applied to the problem of two samples》. Statistical Research Memoirs 2: 1–24.\n\n\n———. 1983. Collected Papers. New York, NY: Springer-Verlag.\n\n\nKim, Seock-Ho, 和 Allan S. Cohen. 1998. 《On the Behrens-Fisher Problem: A Review》. Journal of Educational and Behavioral Statistics 23 (4): 356–77. https://doi.org/10.2307/1165281.\n\n\nMood, A. M. 1954. 《On the Asymptotic Efficiency of Certain Nonparametric Two-Sample Tests》. The Annals of Mathematical Statistics 25 (3): 514–22. https://doi.org/10.1214/aoms/1177728719.\n\n\nShapiro, S. S., 和 M. B. Wilk. 1965. 《An analysis of variance test for normality (complete samples)》. Biometrika 52 (3-4): 591–611. https://doi.org/10.1093/biomet/52.3-4.591.\n\n\n\"Student\". 1908. 《The probable error of a mean》. Biometrika 6: 1–25.\n\n\n韦博成. 2009. 《《红楼梦》前80回与后40回某些文风差异的统计分析（两个独立二项总体等价性检验的一个应用）》. 应用概率统计 25 (4): 441–48. https://doi.org/10.3969/j.issn.1001-4268.2009.04.012.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#footnotes",
    "href": "common-statistical-tests.html#footnotes",
    "title": "19  常见的统计检验",
    "section": "",
    "text": "https://stat.ethz.ch/pipermail/r-help/2005-April/070508.html↩︎\nhttps://stat.ethz.ch/pipermail/r-help/2009-May/390164.html↩︎\nhttps://personal.utdallas.edu/~herve/Abdi-Lillie2007-pretty.pdf↩︎\nhttps://stat.ethz.ch/pipermail/r-help/2004-February/045597.html↩︎",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html",
    "href": "regression-and-correlation.html",
    "title": "20  回归与相关分析",
    "section": "",
    "text": "20.1 子代身高与亲代身高的关系\n弗朗西斯·高尔顿（Francis Galton, 1822-1911）是历史上著名的优生学家、心理学家、遗传学家和统计学家，是统计学中相关和回归等一批概念的提出者，是遗传学中回归现象的发现者。1885年，高尔顿以保密和给予金钱报酬的方式，向社会征集了 205 对夫妇及其 928 个成年子女的身高数据(Galton 1886)。\n目前，Michael Friendly 从原始文献中整理后，将该数据集命名为 GaltonFamilies，放在 R 包 HistData (Friendly 2021) 内，方便大家使用。篇幅所限，下 表格 20.1 展示该数据集的部分内容。\n表格 20.1: 高尔顿收集的 205 对夫妇及其子女的身高数据（部分）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n家庭编号\n父亲身高\n母亲身高\n中亲身高\n子女数量\n子女编号\n子女性别\n子女身高\n\n\n\n001\n78.5\n67.0\n75.43\n4\n1\nmale\n73.2\n\n\n001\n78.5\n67.0\n75.43\n4\n2\nfemale\n69.2\n\n\n001\n78.5\n67.0\n75.43\n4\n3\nfemale\n69.0\n\n\n001\n78.5\n67.0\n75.43\n4\n4\nfemale\n69.0\n\n\n002\n75.5\n66.5\n73.66\n4\n1\nmale\n73.5\n\n\n002\n75.5\n66.5\n73.66\n4\n2\nmale\n72.5\n表中子女性别一栏，Male 表示男性，Female 表示女性。表中 1 号家庭父亲身高 78.5 英寸，母亲身高 67.0 英寸，育有 4 个成年子女，1 男 3 女，子女身高依次是 73.2 英寸、 69.2 英寸、 69.0 英寸 和 69.0 英寸。1 英寸相当于 2.54 厘米，78.5 英寸相当于 199.39 厘米，约等于 2 米的身高。\n高尔顿提出「中亲」概念，即父母的平均身高，认为子代身高只与父母平均身高相关，而与父母身高差无关，为了消除性别给身高带来的差异，女性身高均乘以 1.08。\n根据数据统计的均值和协方差，椭圆 level = 0.95\n代码library(ggplot2)\nggplot(data = GaltonFamilies, aes(x = midparentHeight, y = childHeight, color = gender)) +\n  geom_point(aes(fill = gender), pch = 21, color = \"white\", \n             size = 2, alpha = 0.75) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", se = FALSE) +\n  stat_ellipse(type = \"norm\", level = 0.95, linetype = 2) +\n  scale_color_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  scale_fill_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  guides(fill = guide_legend(reverse = TRUE), \n         color = guide_legend(reverse = TRUE)) +\n  labs(x = \"父母平均身高\", y = \"子女身高\", fill = \"性别\", color = \"性别\") +\n  theme_classic()\n\n\n\n\n\n\n图 20.1: 子代身高与亲代身高的关系\n女儿的身高乘以 1.08 后，两条回归线将几乎重合。(Hanley 2004)\n代码GaltonFamilies[, height_children := childHeight * c(\"female\" = 1.08, \"male\" = 1)[gender]] |&gt;\n  ggplot(aes(x = midparentHeight, y = height_children, color = gender)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", se = FALSE) +\n  geom_point(size = 1.5, alpha = 0.75) +\n  stat_ellipse( type = \"norm\", linetype = 2) +\n  scale_color_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  guides(color = guide_legend(reverse = TRUE)) +\n  labs(x = \"父母平均身高\", y = \"子女身高\", color = \"性别\") +\n  theme_classic()\n\n\n\n\n\n\n图 20.2: 子代身高与亲代身高的关系\n\\[\n\\mathrm{height}_{children} = \\alpha + \\beta * \\mathrm{height}_{midparent} + \\epsilon\n\\]\n表格 20.2: 子女身高向中亲平均身高回归\n\n\n\n\n性别\n截距\n中亲身高\n\n\n\nmale\n19.91346\n0.7132745\n\n\nfemale\n19.80016\n0.7136104\n代码data(Galton, package = \"HistData\")\nplot(Galton,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(63.5, 73.5),\n  ylim = c(61, 74.5),\n  col = densCols(Galton,\n    bandwidth = c(1, 1),\n    nbin = c(11L, 11L), colramp = hcl.colors\n  )\n)\nreg &lt;- lm(child ~ parent, data = Galton)\nabline(reg, lwd = 2)\nlines(lowess(x = Galton$parent, y = Galton$child), col = \"blue\", lwd = 2)\nlibrary(KernSmooth)\nden &lt;- bkde2D(x = Galton, bandwidth = c(1, 1), gridsize = c(11L, 11L))\ncontour(den$x1, den$x2, den$fhat, nlevels = 10, add = TRUE, family = \"sans\")\ntitle(xlab = \"父母平均身高\", ylab = \"子女身高\", family = \"Noto Serif CJK SC\")\n\n\n\n\n\n\n图 20.3: 二维核密度估计与二元正态分布\n向均值回归现象最早是高尔顿在甜豌豆实验中发现的，实际上，均值回归现象在社会经济和自然界中广泛存在，比如一个人的智力水平受家族平均水平的影响。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#sec-state-x77",
    "href": "regression-and-correlation.html#sec-state-x77",
    "title": "20  回归与相关分析",
    "section": "\n20.2 预期寿命与人均收入的关系",
    "text": "20.2 预期寿命与人均收入的关系\n\n生物遗传的回归现象，更确切地说是因果而不是相关，是一种近似的函数关系。与回归紧密相连的是另一个统计概念是相关，主要刻画数量指标之间的关系深浅程度，相关系数是其中一个度量。在经济、社会领域中，很多数据指标存在相关性，接下来的这个例子基于 1977 年美国人口调查局发布的统计数据，篇幅所限，下 表格 20.3 展示美国各州的部分统计数据。\n\n\n\n表格 20.3: 1977 年美国人口调查局发布的各州统计数据（部分）\n\n\n\n\n州名\n区域划分\n人口数量\n人均收入\n预期寿命\n\n\n\nAlabama\nSouth\n3615\n3624\n69.05\n\n\nAlaska\nWest\n365\n6315\n69.31\n\n\nArizona\nWest\n2212\n4530\n70.55\n\n\nArkansas\nSouth\n2110\n3378\n70.66\n\n\nCalifornia\nWest\n21198\n5114\n71.71\n\n\nColorado\nWest\n2541\n4884\n72.06\n\n\n\n\n\n\n\n\n该数据集在 R 环境中的结构如下：\n\nstr(state_x77)\n\n#&gt; 'data.frame':    50 obs. of  10 variables:\n#&gt;  $ Population  : num  3615 365 2212 2110 21198 ...\n#&gt;  $ Income      : num  3624 6315 4530 3378 5114 ...\n#&gt;  $ Illiteracy  : num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...\n#&gt;  $ Life Exp    : num  69 69.3 70.5 70.7 71.7 ...\n#&gt;  $ Murder      : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...\n#&gt;  $ HS Grad     : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...\n#&gt;  $ Frost       : num  20 152 15 65 20 166 139 103 11 60 ...\n#&gt;  $ Area        : num  50708 566432 113417 51945 156361 ...\n#&gt;  $ state_name  : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n#&gt;  $ state_region: Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n\n\n它是一个 50 行 10 列的数据框，其中，state_name（州名）是字符型变量， state_region（区域划分）是因子型变量。除了这两个变量外，Population（人口数量，单位：1000），Income（人均收入，单位：美元），Life Exp（预期寿命，单位：岁）等都是数值型的变量。下 图 20.4 展示了1977 年美国各州的预期寿命和人均收入的关系，通过此图，可以初步观察出两个指标存在一些明显的正向相关性，也符合常识。\n\n代码library(ggplot2)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point() +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 20.4: 预期寿命与人均收入的关系图\n\n\n\n\n为了更加清楚地观察到哪些州预期寿命长，哪些州人均收入高，在 图 20.4 基础上，在散点旁边添加州名。此外，为了观察各州的地域差异，根据各州所属区域，给散点分类，最后，将各州人口数量映射给散点的大小，形成如下 图 20.5 所示的分类气泡图。\n\n代码library(ggplot2)\nlibrary(ggrepel)\nlibrary(scales)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系（分地域）\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 20.5: 分地域预期寿命与人均收入的气泡图\n\n\n\n\n整体来说，预期寿命与人均收入息息相关。\n\n代码ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\") +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 20.6: 1977 年美国各州预期寿命与人均收入的关系：回归分析\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n从 图 20.5 到 图 20.6 ，尝试初步量化两个变量之间的相关性之前，有没有想过，回归线应该更加陡峭一些，即回归线的斜率应该更大一些，是什么原因导致平缓了这么多？是阿拉斯加州和内华达州的数据偏离集体太远。那又是什么原因导致阿拉斯加州人均收入全美第一，而预期寿命倒数呢？同样的，内华达州的人均收入也不低，但预期寿命为什么上不去呢？\n\n\n\n代码ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", color = \"red\") +\n  geom_smooth(data = function(x) subset(x, !state_name %in% c(\"Nevada\", \"Alaska\") ), method = \"lm\", formula = \"y~x\", color = \"green\") +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\nm &lt;- lm(data = state_x77, `Life Exp` ~ Income)\nsummary(m)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = `Life Exp` ~ Income, data = state_x77)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -2.96547 -0.76381 -0.03428  0.92876  2.32951 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 6.758e+01  1.328e+00  50.906   &lt;2e-16 ***\n#&gt; Income      7.433e-04  2.965e-04   2.507   0.0156 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.275 on 48 degrees of freedom\n#&gt; Multiple R-squared:  0.1158, Adjusted R-squared:  0.09735 \n#&gt; F-statistic: 6.285 on 1 and 48 DF,  p-value: 0.01562\n\n\n输出结果中各个量的计算公式及 R 语言实现，比如方差 Variance、偏差 Deviance/Bias、残差 Residual Error",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#分析影响入院等待时间的因素",
    "href": "regression-and-correlation.html#分析影响入院等待时间的因素",
    "title": "20  回归与相关分析",
    "section": "\n20.3 分析影响入院等待时间的因素",
    "text": "20.3 分析影响入院等待时间的因素\n医院的床位是非常重要的资源。\n\nhospital_waiting_time &lt;- readRDS(file = \"data/hospital_waiting_time.rds\")\n\n\nstr(hospital_waiting_time)\n\n#&gt; 'data.frame':    2625 obs. of  11 variables:\n#&gt;  $ 等待时间    : num  1 1.2 20 6 8.9 2.9 7.9 2.8 2.7 5 ...\n#&gt;  $ 门诊次      : int  2 7 43 1 3 1 10 3 6 2 ...\n#&gt;  $ 住院次      : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 开住院条日期: int  3 3 3 3 3 3 3 3 3 3 ...\n#&gt;  $ 性别        : int  0 0 1 1 1 1 0 1 1 1 ...\n#&gt;  $ 年龄        : int  42 32 59 9 45 73 50 25 14 20 ...\n#&gt;  $ 入院疾病分类: int  3 1 1 3 3 3 4 1 2 3 ...\n#&gt;  $ 入院目的    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 住院类别    : int  2 2 2 2 2 2 2 2 2 2 ...\n#&gt;  $ 入院病情    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 医生        : int  2 2 2 2 2 4 2 2 4 4 ...",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#sec-exercise-regression-and-correlation",
    "href": "regression-and-correlation.html#sec-exercise-regression-and-correlation",
    "title": "20  回归与相关分析",
    "section": "\n20.4 习题",
    "text": "20.4 习题\n\nR 软件内置的数据集 esoph 是一份关于法国伊勒-维莱讷地区食道癌的数据，请读者根据这份数据研究年龄组、烟草消费量、酒精消费量（每日喝酒量）和患食道癌的关系。\n\n\n\n\n\nFriendly, Michael. 2021. HistData: Data Sets from the History of Statistics and Data Visualization. https://CRAN.R-project.org/package=HistData.\n\n\nGalton, F. 1886. 《Regression Towards Mediocrity in Hereditary Stature》. Journal of the Anthropological Institute 15: 246–63.\n\n\nHanley, James A. 2004. 《’Transmuting’ women into men: Galton’s family data on human stature》. The American Statistician 58 (3): 237–43.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html",
    "href": "categorical-data-analysis.html",
    "title": "21  分类数据的分析",
    "section": "",
    "text": "21.1 比例检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-prop-test",
    "href": "categorical-data-analysis.html#sec-prop-test",
    "title": "21  分类数据的分析",
    "section": "",
    "text": "21.1.1 单样本检验\n比例检验函数 prop.test() 检验比例是否等于给定的值。单样本的比例检验结果中比例的区间估计与 Wilson 区间估计 (Wilson 1927) 是相关的。区间估计与假设检验是有紧密关系的，对于二项分布比例的 11 种区间估计方法的比较 (Newcombe 1998)。\n\n21.1.1.1 近似检验\n\n21.1.1.2 精确检验\n函数 binom.test() 来做二项检验，函数 binom.test() 用来检验伯努利试验中成功概率 \\(p\\) 和给定概率 \\(p_0\\) 的关系，属于精确检验 (Clopper 和 Pearson 1934)。\n比例 \\(p\\) 的检验，做 \\(n\\) 次独立试验，样本 \\(X_1,\\ldots,X_n \\sim b(1, p)\\)，事件发生的总次数 \\(\\sum_{i=1}^{n}X_i\\)。\n\n# 模拟一组样本\nset.seed(20232023)\nx &lt;- sample(x = c(0, 1), size = 100, replace = TRUE, prob = c(0.8, 0.2))\n\n二项分布中成功概率的检验\n\nbinom.test(sum(x), n = 100, p = 0.5)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  sum(x) and 100\n#&gt; number of successes = 23, number of trials = 100, p-value = 5.514e-08\n#&gt; alternative hypothesis: true probability of success is not equal to 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.1517316 0.3248587\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                   0.23\n\n\n检验成功概率 p 是否等于 0.5， P 值 \\(5.514 \\times 10^{-8}\\) 结论是拒绝原假设\n\nbinom.test(sum(x), n = 100, p = 0.2)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  sum(x) and 100\n#&gt; number of successes = 23, number of trials = 100, p-value = 0.4534\n#&gt; alternative hypothesis: true probability of success is not equal to 0.2\n#&gt; 95 percent confidence interval:\n#&gt;  0.1517316 0.3248587\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                   0.23\n\n\n检验成功概率 p 是否等于 0.2， P 值 0.4534 结论是不能拒绝原假设\n切比雪夫不等式（Chebyshev, 1821-1894）。设随机变量 \\(X\\) 的数学期望和方差都存在，则对任意常数 \\(\\epsilon &gt; 0\\)，有\n\\[\n\\begin{aligned}\nP(|X - EX| \\geq \\epsilon) & \\leq \\frac{Var(X)}{\\epsilon^2} \\\\\nP(|X - EX| \\leq \\epsilon) & \\geq 1 - \\frac{Var(X)}{\\epsilon^2}\n\\end{aligned}\n\\]\n\n21.1.2 两样本检验\n关于两样本的比例检验问题\n\\[\n\\begin{aligned}\nH_0: P_A = P_B \\quad vs. \\quad H_1: P_A &gt; P_B \\\\\nH_0: P_A = P_B \\quad vs. \\quad H_1: P_A &lt; P_B\n\\end{aligned}\n\\]\n\\(H_0\\) 成立的情况下，暗示着两个样本来自同一总体。\n比例检验函数 prop.test() 用来检验两组或多组二项分布的成功概率（比例）是否相等。\n设随机变量 X 服从参数为 \\(p\\) 的二项分布 \\(b(n, p)\\)， \\(Y\\) 服从参数为 \\(\\theta\\) 的二项分布 \\(b(m,\\theta)\\)， \\(m,n\\) 都假定为较大的正整数，检验如下问题\n\\[\nH_0: P_A \\geq P_B \\quad vs. \\quad H_1: P_A &lt; P_B\n\\]\n根据中心极限定理\n\\[\n\\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{p(1-p)}{n} + \\frac{\\theta(1-\\theta)}{m}}}\n\\]\n近似服从标准正态分布 \\(N(0,1)\\)。如果用矩估计 \\(\\bar{X}\\) 和 \\(\\bar{Y}\\) 分别替代总体参数 \\(p\\) 和 \\(\\theta\\)，构造检验统计量\n\\[\nT = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n} + \\frac{\\bar{Y}(1-\\bar{Y})}{m}}}\n\\]\n根据 Slutsky 定理，检验统计量 \\(T\\) 近似服从标准正态分布，当 \\(T\\) 偏大时，拒绝 \\(H_0\\)。该方法的优势在于当 \\(n,m\\) 比较大时，二项分布比较复杂，无法建立统计表，利用标准正态分布表来给出检验所需要的临界值，简便易行！\n当 \\(p\\) 和 \\(\\theta\\) 都比较小，上述方法检验效果不好，原因在于由中心极限定理对 \\(\\bar{X}\\) 和 \\(\\bar{Y}\\) 的正态分布近似效果不好，或者间接地导致 \\(\\bar{X}-\\bar{Y}\\) 的方差偏小，进而 \\(T\\) 的分辨都不好，而且当 \\(p,\\theta\\) 很接近 1 时，上述现象也会产生！\n下面介绍新的解决办法，办法来自两个二项总体成功概率的比较 (宋泽熙 2011)。\n上面的检验问题等价于\n\\[\nH_0: \\frac{P_A}{P_B} \\geq 1 \\quad vs. \\quad H_1: \\frac{P_A}{P_B} &lt; 1\n\\]\n引入检验统计量\n\\[\nT^{\\star} = \\frac{\\bar{X}}{\\bar{Y}}\n\\]\n同样由 Slutsky 定理和中心极限定理可知， \\(\\bar{X}/\\bar{Y}\\) 近似服从 正态分布 \\(\\mathcal{N}(1,\\frac{1-\\theta}{m\\theta})\\)\n当 \\((T^\\star - 1)/\\hat\\sigma\\) 偏大时接受 \\(H_0\\)，临界值可通过 \\(\\mathcal{N}(0, \\hat\\sigma^2)\\) 分布表计算得到， \\(\\hat\\sigma^2\\) 是对 \\(\\frac{1-\\theta}{m\\theta}\\) 的估计，比如取 \\(\\hat\\sigma^2 = \\frac{1-\\bar{Y}}{m}\\cdot \\frac{1}{\\bar{Y}}\\) 或取 \\(\\hat\\sigma^2 = \\frac{1-\\bar{Y}}{m}\\cdot \\frac{1}{\\bar{X}}\\)\n由于渐近方差形如 \\(\\frac{1-\\theta}{m\\theta}\\)，因而在 \\(\\theta\\) 较小，渐近方差较大，克服了之前 \\(\\bar{X} - \\bar{Y}\\)的方差较小的问题\n\\(p,\\theta\\) 很接近 1 时，我们取检验统计量\n\\[\nT^{\\star\\star} = \\frac{1-\\bar{Y}}{1-\\bar{X}}\n\\]\n结论和 \\(T^\\star\\) 类似，当 \\(T^{\\star\\star}\\) 偏大时，拒绝 \\(H_0\\)。\n\n21.1.3 多样本检验\n\n21.1.3.1 比例齐性检验\n对多组数据的比例检验，可以理解为比例齐性检验。\n\n21.1.3.2 比例趋势检验\n比例趋势检验函数 prop.trend.test() 的原假设：四个组里面病人中吸烟的比例是相同的。备择假设：四个组的吸烟比例是有趋势的。\n\\[\n\\begin{aligned}\n& H_0: P_1 = P_2 = P_3 = P_4 \\\\\n& H_1: P_1 &lt; P_2 &lt; P_3 &lt; P_4 ~\\text{或者}~ P_1 &gt; P_2 &gt; P_3 &gt; P_4\n\\end{aligned}\n\\]\n\nsmokers &lt;- c(83, 90, 129, 70)\npatients &lt;- c(86, 93, 136, 82)\nprop.test(smokers, patients)\n\n#&gt; \n#&gt;  4-sample test for equality of proportions without continuity correction\n#&gt; \n#&gt; data:  smokers out of patients\n#&gt; X-squared = 12.6, df = 3, p-value = 0.005585\n#&gt; alternative hypothesis: two.sided\n#&gt; sample estimates:\n#&gt;    prop 1    prop 2    prop 3    prop 4 \n#&gt; 0.9651163 0.9677419 0.9485294 0.8536585\n\nprop.trend.test(smokers, patients)\n\n#&gt; \n#&gt;  Chi-squared Test for Trend in Proportions\n#&gt; \n#&gt; data:  smokers out of patients ,\n#&gt;  using scores: 1 2 3 4\n#&gt; X-squared = 8.2249, df = 1, p-value = 0.004132",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-poisson-test",
    "href": "categorical-data-analysis.html#sec-poisson-test",
    "title": "21  分类数据的分析",
    "section": "\n21.2 泊松检验",
    "text": "21.2 泊松检验\n泊松分布是 1837年由法国数学家泊松 （Poisson, 1781-1840） 首次提出。\n\\[\np(x) = \\frac{\\lambda^x\\exp(-\\lambda)}{x!}, x = 0, 1, \\cdots .\n\\]\n泊松分布的期望和方差都是 \\(\\lambda\\) ，一般要求 \\(\\lambda &gt; 0\\)。\n\n21.2.1 单样本\npoisson.test() 泊松分布的参数 \\(\\lambda\\) 的精确检验，适用于单样本和两样本。\n\npoisson.test(x,\n  T = 1, r = 1,\n  alternative = c(\"two.sided\", \"less\", \"greater\"),\n  conf.level = 0.95\n)\n\n参数 T 数据的时间单位\n\n21.2.2 两样本",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#列联表描述",
    "href": "categorical-data-analysis.html#列联表描述",
    "title": "21  分类数据的分析",
    "section": "\n21.3 列联表描述",
    "text": "21.3 列联表描述\n泰坦尼克号乘客生存死亡统计数据，Titanic 数据集\n\nTitanic\n\n#&gt; , , Age = Child, Survived = No\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st     0      0\n#&gt;   2nd     0      0\n#&gt;   3rd    35     17\n#&gt;   Crew    0      0\n#&gt; \n#&gt; , , Age = Adult, Survived = No\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st   118      4\n#&gt;   2nd   154     13\n#&gt;   3rd   387     89\n#&gt;   Crew  670      3\n#&gt; \n#&gt; , , Age = Child, Survived = Yes\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st     5      1\n#&gt;   2nd    11     13\n#&gt;   3rd    13     14\n#&gt;   Crew    0      0\n#&gt; \n#&gt; , , Age = Adult, Survived = Yes\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st    57    140\n#&gt;   2nd    14     80\n#&gt;   3rd    75     76\n#&gt;   Crew  192     20\n\n\n\n21.3.1 行列分组表格\n\n代码# 长格式转宽格式\ntitanic_data &lt;- reshape(\n  data = as.data.frame(Titanic), direction = \"wide\",\n  idvar = c(\"Class\", \"Sex\", \"Age\"),\n  timevar = \"Survived\", v.names = \"Freq\", sep = \"_\"\n)\n\n# 制作表格\ngt::gt(titanic_data) |&gt; \n  gt::cols_label(\n    Freq_Yes = \"存活\",\n    Freq_No = \"死亡\",\n    Class = \"船舱\",\n    Sex = \"性别\",\n    Age = \"年龄\"\n  )\n\n\n表格 21.1: 泰坦尼克号乘客生存死亡统计数据\n\n\n\n\n\n\n船舱\n性别\n年龄\n死亡\n存活\n\n\n\n1st\nMale\nChild\n0\n5\n\n\n2nd\nMale\nChild\n0\n11\n\n\n3rd\nMale\nChild\n35\n13\n\n\nCrew\nMale\nChild\n0\n0\n\n\n1st\nFemale\nChild\n0\n1\n\n\n2nd\nFemale\nChild\n0\n13\n\n\n3rd\nFemale\nChild\n17\n14\n\n\nCrew\nFemale\nChild\n0\n0\n\n\n1st\nMale\nAdult\n118\n57\n\n\n2nd\nMale\nAdult\n154\n14\n\n\n3rd\nMale\nAdult\n387\n75\n\n\nCrew\nMale\nAdult\n670\n192\n\n\n1st\nFemale\nAdult\n4\n140\n\n\n2nd\nFemale\nAdult\n13\n80\n\n\n3rd\nFemale\nAdult\n89\n76\n\n\nCrew\nFemale\nAdult\n3\n20\n\n\n\n\n\n\n\n\n\n\n21.3.2 百分比堆积图\n泰坦尼克号处女航乘客数量按船舱、性别、年龄和存活情况分层， ggstats 包绘制百分比堆积柱形图展示多维分类数据。\n\n代码library(ggplot2)\nlibrary(ggstats)\nggplot(as.data.frame(Titanic)) +\n  aes(x = Class, fill = Survived, weight = Freq, by = Class) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  geom_text(stat = \"prop\", position = position_fill(.5)) +\n  facet_grid(~Sex) +\n  labs(x = \"船舱\", y = \"比例\", fill = \"存活\")\n\n\n\n\n\n\n图 21.1: 百分比堆积柱形图展示多维分类数据\n\n\n\n\nggstats 包提供的图层 stat_prop() 是 stat_count() 的变种， as.data.frame(Titanic) 中 Age 一列会自动聚合吗？ by = Class 按 Class 分组聚合，统计 Survived 的比例，提供 prop 计算的变量，传递给 geom_text() 以添加注释，position 设置将注释放在柱子的中间\n\n21.3.3 桑基图\n用 ggalluvial 包(Brunson 2020)绘制桑基图展示多维分类数据。\n\n代码library(ggplot2)\nlibrary(ggalluvial)\nggplot(\n  data = as.data.frame(Titanic),\n  aes(axis1 = Class, axis2 = Sex, axis3 = Age, y = Freq)\n) +\n  scale_x_discrete(limits = c(\"Class\", \"Sex\", \"Age\")) +\n  geom_alluvium(aes(fill = Survived)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_classic() +\n  labs(\n    x = \"分层维度\", y = \"人数\", fill = \"存活\",\n    title = \"泰坦尼克号处女航乘客分层情况\"\n  )\n\n\n\n\n\n\n图 21.2: 桑基图展示多维分类数据\n\n\n\n\n\n21.3.4 马赛克图\n\n代码op &lt;- par(mar = c(2.5, 2.5, 1.5, 0.5))\nmosaicplot(~ Class + Sex + Age + Survived,\n  data = Titanic, # shade = TRUE, \n  color = TRUE, border = \"white\",\n  xlab = \"船舱\", ylab = \"性别\", main = \"泰坦尼克号\")\npar(op)\n\n\n\n\n\n\n图 21.3: 马赛克图展示多维分类数据\n\n\n\n\nvcd 包针对分类数据做了很多专门的可视化工作，内置了很多数据集和绘图函数，在 Base R 绘图基础上，整合了许多统计分析功能，提供了一个统一的可视化框架(Meyer, Zeileis, 和 Hornik 2006; Zeileis, Meyer, 和 Hornik 2007)，更多细节见著作《Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data》及其附带的 R 包 vcdExtra(Friendly 和 Meyer 2016)。\n\n代码library(grid)\nlibrary(vcd)\nmosaic(~ Class + Sex + Age + Survived,\n  data = Titanic, shade = TRUE, legend = TRUE\n)\n\n\n\n\n\n\n图 21.4: 马赛克图展示多维分类数据",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-chisq-test",
    "href": "categorical-data-analysis.html#sec-chisq-test",
    "title": "21  分类数据的分析",
    "section": "\n21.4 列联表分析",
    "text": "21.4 列联表分析\n是否应该按照列联表的维度分类？还是应该从分析的目的和作用出发？比如我的目的是检验独立性。二者似乎也并不冲突。\n列联表中的数据服从多项分布，关于独立性检验，有如下几种常见类型：\n\n相互独立 Mutual independence 所有变量之间相互独立，\\(X \\perp Y \\perp Z\\) 。\n联合独立 Joint independence 两个变量的联合与第三个变量独立，\\(XY \\perp Z\\) 。\n边际独立 Marginal independence 当忽略第三个变量时，两个变量是独立的。列联表压缩\n条件独立 Conditional independence 当固定第三个变量时，两个变量是独立的，\\(X \\perp Y | Z\\)。\n\n本节数据来自著作《An Introduction to Categorical Data Analysis》(Agresti 2007) 的第2章习题 2.33，探索 1976-1977 年美国佛罗里达州的凶杀案件中被告肤色和死刑判决的关系。\n\n代码tbl &lt;- expand.grid(\n  Death = c(\"Yes\", \"No\"), # 判决结果 是否死刑\n  Defend = c(\"白人\", \"黑人\"),  # 被告 肤色\n  Victim = c(\"白人\", \"黑人\")   # 原告 （被害人）肤色\n)\nethnicity &lt;- data.frame(tbl, Freq = c(19, 132, 11, 52, 0, 9,  6, 97))\n\n# 长格式转宽格式\ndat1 &lt;- reshape(\n  data = ethnicity, direction = \"wide\",\n  idvar = c(\"Defend\", \"Victim\"),\n  timevar = \"Death\", v.names = \"Freq\", sep = \"_\"\n)\n# 制作表格\ngt::gt(dat1) |&gt; \n  gt::cols_label(\n    Freq_Yes = \"是\",\n    Freq_No = \"否\",\n    Victim = \"被害人\",\n    Defend = \"被告\"\n  ) |&gt; \n  gt::tab_spanner(\n    label = \"死刑\",\n    columns = c(Freq_Yes, Freq_No)\n  ) |&gt; \n  gt::opt_row_striping()\n\n\n表格 21.2: 佛罗里达州的凶杀案件统计数据\n\n\n\n\n\n\n\n被告\n被害人\n死刑\n\n\n是\n否\n\n\n\n\n白人\n白人\n19\n132\n\n\n黑人\n白人\n11\n52\n\n\n白人\n黑人\n0\n9\n\n\n黑人\n黑人\n6\n97\n\n\n\n\n\n\n\n\n\n\n21.4.1 相互独立性\n皮尔逊卡方检验（ Pearson’s \\(\\chi^2\\) 检验） chisq.test() 常用于列联表独立性检验和方差分析模型的拟合优度检验。下面是一个 \\(2 \\times 2\\) 的列联表。\n\n卡方独立性检验\n\n\n第一列\n第二列\n合计\n\n\n\n第一行\n\\(a\\)\n\\(b\\)\n\\(a+b\\)\n\n\n第二行\n\\(c\\)\n\\(d\\)\n\\(c+d\\)\n\n\n合计\n\\(a+c\\)\n\\(b+d\\)\n\\(a+b+c+d\\)\n\n\n\n\n# Death 死刑与 Defend （被告）独立性检验\nm &lt;- xtabs(Freq ~ Death + Defend, data = ethnicity)\nm\n\n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes   19   17\n#&gt;   No   141  149\n\nchisq.test(m, correct = TRUE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 0.086343, df = 1, p-value = 0.7689\n\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 0.22145, df = 1, p-value = 0.6379\n\n\n当被告是白人时，死刑判决 19 个，占总的死刑判决数量的 19/36 = 52.78%，当被告是黑人时，死刑判决 17 个，占总的死刑判决数量的 17/36 = 47.22%。判决结果与被告种族没有显著关系，但与原告（受害人）种族是有关系的，请继续往下看。\n\n# Death 死刑与 Victim （原告）独立性检验\nm &lt;- xtabs(Freq ~ Death + Victim, data = ethnicity)\nchisq.test(m, correct = TRUE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 4.7678, df = 1, p-value = 0.029\n\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 5.6149, df = 1, p-value = 0.01781\n\n\n当受害人是白人时，死刑判决 30 个，占总的死刑判决数量的 30/36 = 83.33%，当受害人是黑人时，死刑判决 6 个，占总的死刑判决数量的 6/36 = 16.67%。受害人是白人时，死刑判决明显多于黑人。\n多维列联表\n\nm &lt;- xtabs(Freq ~ Death + Defend + Victim, data = ethnicity)\nm\n\n#&gt; , , Victim = 白人\n#&gt; \n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes   19   11\n#&gt;   No   132   52\n#&gt; \n#&gt; , , Victim = 黑人\n#&gt; \n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes    0    6\n#&gt;   No     9   97\n\n\n判决结果、被告种族、原告种族三者是否存在联合独立性，即考虑 (Victim, Death) 是否与 Defend 独立，(Victim, Defend) 是否与 Death 独立，(Death, Defend) 与 Victim 是否相互独立。\n\nfm &lt;- loglin(table = m, margin = list(c(1, 2), c(1, 3), c(2, 3)), print = FALSE)\nfm \n\n#&gt; $lrt\n#&gt; [1] 0.7007504\n#&gt; \n#&gt; $pearson\n#&gt; [1] 0.3751739\n#&gt; \n#&gt; $df\n#&gt; [1] 1\n#&gt; \n#&gt; $margin\n#&gt; $margin[[1]]\n#&gt; [1] \"Death\"  \"Defend\"\n#&gt; \n#&gt; $margin[[2]]\n#&gt; [1] \"Death\"  \"Victim\"\n#&gt; \n#&gt; $margin[[3]]\n#&gt; [1] \"Defend\" \"Victim\"\n\n# 拟合对数线性模型\n# fm &lt;- loglin(m, list(c(1), c(2), c(3)))\n# fm\n\n似然比检验统计量（Likelihood Ratio Test statistic），皮尔逊 \\(\\chi^2\\) 统计量（Pearson X-square Test statistic）\n\n1 - pchisq(fm$lrt, fm$df)\n\n#&gt; [1] 0.4025317\n\n\n拟合对数线性模型\n\nfit_dvp &lt;- glm(Freq ~ ., data = ethnicity, family = poisson(link = \"log\"))\n\n模型输出\n\nsummary(fit_dvp)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ ., family = poisson(link = \"log\"), data = ethnicity)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  2.45087    0.18046  13.582  &lt; 2e-16 ***\n#&gt; DeathNo      2.08636    0.17671  11.807  &lt; 2e-16 ***\n#&gt; Defend黑人   0.03681    0.11079   0.332     0.74    \n#&gt; Victim黑人  -0.64748    0.11662  -5.552 2.83e-08 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 395.92  on 7  degrees of freedom\n#&gt; Residual deviance: 137.93  on 4  degrees of freedom\n#&gt; AIC: 181.61\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\nPearson \\(\\chi^2\\) 统计量\n\nsum(residuals(fit_dvp, type = \"pearson\")^2)\n\n#&gt; [1] 122.3975\n\n\nMASS 包计算模型参数的置信区间\n\nconfint(fit_dvp, trace = FALSE)\n\n#&gt;                  2.5 %     97.5 %\n#&gt; (Intercept)  2.0802598  2.7893934\n#&gt; DeathNo      1.7546021  2.4493677\n#&gt; Defend黑人  -0.1803969  0.2543149\n#&gt; Victim黑人  -0.8790491 -0.4213701\n\n\n对于单元格总样本量小于 40 或 T 小于 1 时，需采用费希尔精确检验（ Fisher ’s Exact 检验）。\n\n21.4.2 边际独立性\n费希尔精确检验：固定边际的情况下，检验列联表行和列之间的独立性 fisher.test() 。\nfisher.test() 函数用法，统计原理和公式，适用范围和条件，概念背景和历史。\n费舍尔 (Sir Ronald Fisher, 1890.2 – 1962.7)1 和一位女士打赌，女士说能品出奶茶中奶和茶的添加顺序。\nfisher.test() 针对计数数据，检验列联表中行和列的独立性。\n\nTeaTasting &lt;- matrix(c(3, 1, 1, 3),\n  nrow = 2,\n  dimnames = list(\n    Guess = c(\"Milk\", \"Tea\"),\n    Truth = c(\"Milk\", \"Tea\")\n  )\n)\nTeaTasting\n\n#&gt;       Truth\n#&gt; Guess  Milk Tea\n#&gt;   Milk    3   1\n#&gt;   Tea     1   3\n\n\n\n# 单边 P 值\nfisher.test(TeaTasting, alternative = \"greater\")\n\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  TeaTasting\n#&gt; p-value = 0.2429\n#&gt; alternative hypothesis: true odds ratio is greater than 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3135693       Inf\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   6.408309\n\n# 双边 P 值\nfisher.test(TeaTasting, alternative = \"two.sided\")\n\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  TeaTasting\n#&gt; p-value = 0.4857\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;    0.2117329 621.9337505\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   6.408309\n\n# 单边 P 值\nsum(dhyper(x = c(3, 4), m = 4, n = 4, k = 4))\n\n#&gt; [1] 0.2428571\n\n\n\n21.4.3 对称性\n用于计数数据的 McNemar 卡方检验（ McNemar \\(\\chi^2\\) 检验）：检验二维列联表行和列的对称性 mcnemar.test()。怎么理解对称性？其实是配对检验。看帮助实例。\n\nPerformance &lt;- matrix(c(794, 86, 150, 570),\n  nrow = 2,\n  dimnames = list(\n    \"1st Survey\" = c(\"Approve\", \"Disapprove\"),\n    \"2nd Survey\" = c(\"Approve\", \"Disapprove\")\n  )\n)\nPerformance\n\n#&gt;             2nd Survey\n#&gt; 1st Survey   Approve Disapprove\n#&gt;   Approve        794        150\n#&gt;   Disapprove      86        570\n\nmcnemar.test(Performance)\n\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  Performance\n#&gt; McNemar's chi-squared = 16.818, df = 1, p-value = 4.115e-05\n\n\n\n21.4.4 条件独立性\n用于分层分类数据的 Cochran-Mantel-Haenszel 卡方检验：两个枚举（分类）变量的条件独立性，假定不存在三个因素的交互作用。Cochran-Mantel-Haenszel 检验 mantelhaen.test()\n\nstr(UCBAdmissions)\n\n#&gt;  'table' num [1:2, 1:2, 1:6] 512 313 89 19 353 207 17 8 120 205 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ Admit : chr [1:2] \"Admitted\" \"Rejected\"\n#&gt;   ..$ Gender: chr [1:2] \"Male\" \"Female\"\n#&gt;   ..$ Dept  : chr [1:6] \"A\" \"B\" \"C\" \"D\" ...\n\n\nUCBAdmissions 数据集是一个 \\(2\\times 2 \\times 6\\) 的三维列联表，R 语言中常用 table 类型表示。实际上，table 类型衍生自 array 数组类型，当把 UCBAdmissions 当作一个数组操作时，1、2、3 分别表示 Admit、Gender、Dept 三个维度。\n\nmantelhaen.test(UCBAdmissions)\n\n#&gt; \n#&gt;  Mantel-Haenszel chi-squared test with continuity correction\n#&gt; \n#&gt; data:  UCBAdmissions\n#&gt; Mantel-Haenszel X-squared = 1.4269, df = 1, p-value = 0.2323\n#&gt; alternative hypothesis: true common odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.7719074 1.0603298\n#&gt; sample estimates:\n#&gt; common odds ratio \n#&gt;         0.9046968\n\n\n没有证据表明院系与性别之间存在关联。在给定院系的情况下，是否录取和性别没有显著关系。\n\n# 按系统计\napply(UCBAdmissions, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))\n\n#&gt;         A         B         C         D         E         F \n#&gt; 0.3492120 0.8025007 1.1330596 0.9212838 1.2216312 0.8278727\n\nwoolf &lt;- function(x) {\n  x &lt;- x + 1 / 2\n  k &lt;- dim(x)[3]\n  or &lt;- apply(x, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))\n  w &lt;- apply(x, 3, function(x) 1 / sum(1 / x))\n  1 - pchisq(sum(w * (log(or) - weighted.mean(log(or), w))^2), k - 1)\n}\nwoolf(UCBAdmissions)\n\n#&gt; [1] 0.0034272",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-ucb-admissions",
    "href": "categorical-data-analysis.html#sec-ucb-admissions",
    "title": "21  分类数据的分析",
    "section": "\n21.5 加州伯克利分校的录取情况",
    "text": "21.5 加州伯克利分校的录取情况\n1973 年加州伯克利分校 6 个最大的院系的录取情况见下 表格 21.3 ，研究目标是加州伯克利分校在招生录取工作中是否有性别歧视？\n\n\n\n表格 21.3: 加州伯克利分校的录取情况\n\n\n\n\n\n\n\n院系\n录取\n拒绝\n\n\n男性\n女性\n男性\n女性\n\n\n\n\nA\n512\n89\n313\n19\n\n\nB\n353\n17\n207\n8\n\n\nC\n120\n202\n205\n391\n\n\nD\n138\n131\n279\n244\n\n\nE\n53\n94\n138\n299\n\n\nF\n22\n24\n351\n317\n\n\n\n\n\n\n\n\n\n借助马赛克图 图 21.5 可以更加直观的看出数据中的比例关系。\n\n\n\n\n\n\n\n图 21.5: 加州伯克利分校院系录取情况\n\n\n\n\n接下来进行定量的分析，首先，按性别和录取情况统计人数，如下：\n\nm &lt;- xtabs(Freq ~ Gender + Admit, data = as.data.frame(UCBAdmissions))\nm\n\n#&gt;         Admit\n#&gt; Gender   Admitted Rejected\n#&gt;   Male       1198     1493\n#&gt;   Female      557     1278\n\n\n可以看到，申请加州伯克利分校的女生当中，只有 \\(557 / (557 + 1278) = 30.35\\%\\) 录取了，而男生则有 \\(1198 / (1198 + 1493) = 44.52\\%\\) 的录取率。根据皮尔逊 \\(\\chi^2\\) 检验：\n\n# 不带耶茨矫正\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 92.205, df = 1, p-value &lt; 2.2e-16\n\n\n可知 \\(\\chi^2\\) 统计量的值为 \\(92.205\\) 且 P 值远远小于 0.05， 差异达到统计显著性，不是随机因素导致的。因此，加州伯克利分校被指控在招生录取工作中存在性别歧视。然而，当我们细分到各个院系去看录取率（录取人数 / 申请人数），结果显示院系 A 的录取率为 64.41%，院系 B 的录取率为 63.24%，依次类推，各院系情况如下：\n\nproportions(xtabs(Freq ~ Dept + Admit,\n  data = as.data.frame(UCBAdmissions)\n), margin = 1)\n\n#&gt;     Admit\n#&gt; Dept   Admitted   Rejected\n#&gt;    A 0.64415863 0.35584137\n#&gt;    B 0.63247863 0.36752137\n#&gt;    C 0.35076253 0.64923747\n#&gt;    D 0.33964646 0.66035354\n#&gt;    E 0.25171233 0.74828767\n#&gt;    F 0.06442577 0.93557423\n\n\n\n\n\n\n\n\n\n图 21.6: 加州伯克利分校各院系录取情况\n\n\n\n\n对每个院系，单独使用皮尔逊 \\(\\chi^2\\) 检验，发现只有 A 系的男、女生录取率的差异达到统计显著性，其它系的差异都不显著。辛普森悖论在这里出现了，在分类数据的分析中，常常遇到。\n\n# 以 A 系为例\nma &lt;- xtabs(Freq ~ Gender + Admit,\n  subset = Dept == \"A\",\n  data = as.data.frame(UCBAdmissions)\n)\nchisq.test(ma, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  ma\n#&gt; X-squared = 17.248, df = 1, p-value = 3.28e-05\n\n\n为了经一步说明此现象的原因，建立对数线性模型来拟合数据，值得一提的是皮尔逊卡方检验可以从对数线性模型的角度来看，而对数线性模型是一种特殊的广义线性模型，针对计数数据建模。\n\nfit_ucb0 &lt;- glm(Freq ~ Dept + Admit + Gender,\n  family = poisson(link = \"log\"),\n  data = as.data.frame(UCBAdmissions)\n)\nsummary(fit_ucb0)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ Dept + Admit + Gender, family = poisson(link = \"log\"), \n#&gt;     data = as.data.frame(UCBAdmissions))\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)    5.37111    0.03964 135.498  &lt; 2e-16 ***\n#&gt; DeptB         -0.46679    0.05274  -8.852  &lt; 2e-16 ***\n#&gt; DeptC         -0.01621    0.04649  -0.349 0.727355    \n#&gt; DeptD         -0.16384    0.04832  -3.391 0.000696 ***\n#&gt; DeptE         -0.46850    0.05276  -8.879  &lt; 2e-16 ***\n#&gt; DeptF         -0.26752    0.04972  -5.380 7.44e-08 ***\n#&gt; AdmitRejected  0.45674    0.03051  14.972  &lt; 2e-16 ***\n#&gt; GenderFemale  -0.38287    0.03027 -12.647  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2650.1  on 23  degrees of freedom\n#&gt; Residual deviance: 2097.7  on 16  degrees of freedom\n#&gt; AIC: 2272.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n添加性别和院系的交互效应后，对数线性模型的 AIC 下降一半多，说明模型的交互效应是显著的，也就是说性别和院系之间存在非常强的关联。\n\nfit_ucb1 &lt;- glm(Freq ~ Dept + Admit + Gender + Dept * Gender,\n  family = poisson(link = \"log\"),\n  data = as.data.frame(UCBAdmissions)\n)\nsummary(fit_ucb1)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ Dept + Admit + Gender + Dept * Gender, family = poisson(link = \"log\"), \n#&gt;     data = as.data.frame(UCBAdmissions))\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)         5.76801    0.03951 145.992  &lt; 2e-16 ***\n#&gt; DeptB              -0.38745    0.05475  -7.076 1.48e-12 ***\n#&gt; DeptC              -0.93156    0.06549 -14.224  &lt; 2e-16 ***\n#&gt; DeptD              -0.68230    0.06008 -11.356  &lt; 2e-16 ***\n#&gt; DeptE              -1.46311    0.08030 -18.221  &lt; 2e-16 ***\n#&gt; DeptF              -0.79380    0.06239 -12.722  &lt; 2e-16 ***\n#&gt; AdmitRejected       0.45674    0.03051  14.972  &lt; 2e-16 ***\n#&gt; GenderFemale       -2.03325    0.10233 -19.870  &lt; 2e-16 ***\n#&gt; DeptB:GenderFemale -1.07581    0.22860  -4.706 2.52e-06 ***\n#&gt; DeptC:GenderFemale  2.63462    0.12343  21.345  &lt; 2e-16 ***\n#&gt; DeptD:GenderFemale  1.92709    0.12464  15.461  &lt; 2e-16 ***\n#&gt; DeptE:GenderFemale  2.75479    0.13510  20.391  &lt; 2e-16 ***\n#&gt; DeptF:GenderFemale  1.94356    0.12683  15.325  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2650.10  on 23  degrees of freedom\n#&gt; Residual deviance:  877.06  on 11  degrees of freedom\n#&gt; AIC: 1062.1\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n此辛普森悖论现象的解释是女生倾向于申请录取率低的院系，而男生倾向于申请录取率高的院系，最终导致整体上，男生的录取率显著高于女生。至于为什么女生会倾向于申请录取率低的院系？这可能要看具体的院系是哪些，招生政策如何？这已经不是仅仅依靠招生办的统计数字就可以完全解释得了的，更多详情见文献 Bickel, Hammel, 和 O’Connell (1975) 。\n\n\n\n\n\n\n提示\n\n\n\n对数线性模型的皮尔逊 \\(\\chi^2\\) 检验的统计量\n\nsum(residuals(fit_ucb1, type = \"pearson\")^2)\n\n#&gt; [1] 797.7045\n\n\n比较多个广义线性模型的拟合效果，除了看 AIC，还可以看对数似然，它越大越好。可以看到添加性别和院系的交互效应后，对数似然增加了一倍多。\n\n# 基础模型\nlogLik(fit_ucb0)\n\n#&gt; 'log Lik.' -1128.365 (df=8)\n\n# 添加交互效应\nlogLik(fit_ucb1)\n\n#&gt; 'log Lik.' -518.0581 (df=13)",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-titanic",
    "href": "categorical-data-analysis.html#sec-titanic",
    "title": "21  分类数据的分析",
    "section": "\n21.6 分析泰坦尼克号乘客生存率",
    "text": "21.6 分析泰坦尼克号乘客生存率\n分析存活率的影响因素。\n除了从条件独立性检验的角度，下面从逻辑回归模型的角度分析这个高维列联表数据，由此，我们可以知道假设检验和广义线性模型之间的联系，针对复杂高维列联表数据进行关联分析和解释。\n响应变量是乘客的状态，存活还是死亡，titanic_data 是按船舱 Class、性别 Sex 和年龄 Age 分类汇总统计的数据，因此，下面的逻辑回归模型是对乘客群体的建模。\n\n# 建立模型\nfit_titanic &lt;- glm(cbind(Freq_Yes, Freq_No) ~ Class + Sex + Age,\n  data = titanic_data, family = binomial(link = \"logit\")\n)\n\n接着，我们查看模型输出的情况\n\n# 模型输出\nsummary(fit_titanic)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = cbind(Freq_Yes, Freq_No) ~ Class + Sex + Age, family = binomial(link = \"logit\"), \n#&gt;     data = titanic_data)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   0.6853     0.2730   2.510   0.0121 *  \n#&gt; Class2nd     -1.0181     0.1960  -5.194 2.05e-07 ***\n#&gt; Class3rd     -1.7778     0.1716 -10.362  &lt; 2e-16 ***\n#&gt; ClassCrew    -0.8577     0.1573  -5.451 5.00e-08 ***\n#&gt; SexFemale     2.4201     0.1404  17.236  &lt; 2e-16 ***\n#&gt; AgeAdult     -1.0615     0.2440  -4.350 1.36e-05 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 671.96  on 13  degrees of freedom\n#&gt; Residual deviance: 112.57  on  8  degrees of freedom\n#&gt; AIC: 171.19\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n\n\n\n\nAgresti, Alan. 2007. An Introduction to Categorical Data Analysis. 2nd 本. Hoboken, New Jersey: John Wiley & Sons, Inc.\n\n\nBickel, P. J., E. A. Hammel, 和 J. W. O’Connell. 1975. 《Sex Bias in Graduate Admissions: Data from Berkeley》. Science 187 (4175): 398–404. https://doi.org/10.1126/science.187.4175.398.\n\n\nBrunson, Jason Cory. 2020. 《ggalluvial: Layered Grammar for Alluvial Plots》. Journal of Open Source Software 5 (49): 2017. https://doi.org/10.21105/joss.02017.\n\n\nClopper, C. J., 和 E. S. Pearson. 1934. 《The Use of Confidence or Fiducial Limits Illustrated In The Case of The Binomial》. Biometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nFriendly, Michael, 和 David Meyer. 2016. Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data. 1st 本. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nMeyer, David, Achim Zeileis, 和 Kurt Hornik. 2006. 《The Strucplot Framework: Visualizing Multi-Way Contingency Tables with vcd》. Journal of Statistical Software 17 (3): 1–48. https://doi.org/10.18637/jss.v017.i03.\n\n\nNewcombe, Robert G. 1998. 《Interval estimation for the difference between independent proportions: comparison of eleven methods》. Statistics in Medicine 17 (8): 873–90. https://doi.org/10.1002/(SICI)1097-0258(19980430)17:8&lt;873::AID-SIM779&gt;3.0.CO;2-I.\n\n\nWilson, Edwin B. 1927. 《Probable inference, the law of succession, and statistical inference》. Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZeileis, Achim, David Meyer, 和 Kurt Hornik. 2007. 《Residual-based Shadings for Visualizing (Conditional) Independence》. Journal of Computational and Graphical Statistics 16 (3): 507–25. https://doi.org/10.1198/106186007X237856.\n\n\n宋泽熙. 2011. 《两个二项总体成功概率的比较》. 中国校外教育（理论） z1: 81. https://doi.org/10.3969/j.issn.1004-8502-B.2011.z1.0919.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#footnotes",
    "href": "categorical-data-analysis.html#footnotes",
    "title": "21  分类数据的分析",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Ronald_Fisher↩︎",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "power-analysis.html",
    "href": "power-analysis.html",
    "title": "22  统计检验的功效",
    "section": "",
    "text": "22.1 三大检验方法\n统计检验的一般方法。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#三大检验方法",
    "href": "power-analysis.html#三大检验方法",
    "title": "22  统计检验的功效",
    "section": "",
    "text": "22.1.1 Wald 检验\n\n22.1.2 Wilks 检验\n也叫似然比检验\n\n22.1.3 Rao 检验\n也叫得分检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#t-检验的功效",
    "href": "power-analysis.html#t-检验的功效",
    "title": "22  统计检验的功效",
    "section": "\n22.2 t 检验的功效",
    "text": "22.2 t 检验的功效\n检验的功效常用于样本量的计算\npower.t.test() 计算单样本或两样本的 t 检验的功效，或者根据功效计算参数，如样本量\n\n代码library(ggplot2)\nn &lt;- 30 # 样本量（只是一个例子）\nx &lt;- seq(from = 0, to = 12, by = 0.01)\ndat &lt;- data.frame(xx = x / sqrt(n), yy = 2 * (1 - pt(x, n - 1)))\nggplot(data = dat, aes(x = xx, y = yy)) +\n  geom_line(linewidth = 1) +\n  geom_vline(xintercept = c(0.01, 0.2, 0.5, 0.8, 1.2, 2), linetype = 2) +\n  theme_classic(base_size = 13) +\n  labs(x = \"$d = \\\\frac{t}{\\\\sqrt{n}}$\", \n       y = \"$2(1 - \\\\mathrm{pt}(x, n - 1))$\")\n\n\n\n\n\n\n图 22.1: t 检验的功效\n\n\n\n\n\npower.t.test(\n  n = 100, delta = 2.2,\n  sd = 1, sig.level = 0.05,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 100\n#&gt;           delta = 2.2\n#&gt;              sd = 1\n#&gt;       sig.level = 0.05\n#&gt;           power = 1\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\n\n\n表格 22.1: 函数 power.t.test() 的参数及其含义\n\n\n\n\n\n\n\n参数\n含义\n\n\n\nn\n每个组的样本量\n\n\ndelta\n两个组的均值之差\n\n\nsd\n标准差，默认值 1\n\n\nsig.level\n显著性水平，默认是 0.05 （犯第 I 类错误的概率）\n\n\npower\n检验的功效（1 - 犯第 II 类错误的概率）\n\n\ntype\nt 检验的类型 \"two.sample\" 两样本、\"one.sample\" 单样本或 \"paired\" 配对样本\n\n\nalternative\n单边或双边检验，取值为 \"two.sided\" 或 \"one.sided\"\n\n\n\n\n\n\n\n参数 n，delta，power，sd 和 sig.level 必须有一个值为 NULL，为 NULL 的参数是由其它参数决定的。\n\n# 前面 t 检验的等价功效计算\nlibrary(pwr)\npwr.t.test(\n  d = 2.2 / 6.4,\n  n = 100,\n  sig.level = 0.05,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 100\n#&gt;               d = 0.34375\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.6768572\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\nsleep 数据集为例，计算功效\n\n# 分组计算均值\naggregate(data = sleep, extra ~ group, FUN = mean)\n\n#&gt;   group extra\n#&gt; 1     1  0.75\n#&gt; 2     2  2.33\n\n# 分组计算标准差\naggregate(data = sleep, extra ~ group, FUN = sd)\n\n#&gt;   group    extra\n#&gt; 1     1 1.789010\n#&gt; 2     2 2.002249\n\n# 代入计算功效\npower.t.test(\n  delta = 2.33 - 0.75,            # 两组均值之差\n  sd = (2.002249 + 1.789010) / 2, # 标准差\n  sig.level = 0.05,         # 显著性水平\n  type = \"two.sample\",      # 两样本\n  power = 0.95,             # 功效水平\n  alternative = \"two.sided\" # 双边检验\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 38.39795\n#&gt;           delta = 1.58\n#&gt;              sd = 1.89563\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\n经检验，上面取两组的平均方差代替共同方差和下面精确计算的结果差不多。各组至少需要 39 个样本。MKpower 包精确计算 Welch t 检验的功效\n\nlibrary(MKpower)\npower.welch.t.test(\n  delta = 2.33 - 0.75,\n  sd1 = 2.002249,\n  sd2 = 1.789010,\n  sig.level = 0.05,\n  power = 0.95,\n  alternative = \"two.sided\"\n)\n\n我国著名统计学家许宝騄先生对此功效计算方法做出过巨大贡献。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#比例检验的功效",
    "href": "power-analysis.html#比例检验的功效",
    "title": "22  统计检验的功效",
    "section": "\n22.3 比例检验的功效",
    "text": "22.3 比例检验的功效\n\n# power.prop.test()\n\npower.prop.test() 计算两样本比例检验的功效\n功效可以用来计算实验所需要的样本量，检验统计量的功效越大/高，检验方法越好，实验所需要的样本量越少\n\n# p1 &gt;= p2 的检验 单边和双边检验\npower.prop.test(\n  p1 = .65, p2 = 0.6, sig.level = .05,\n  power = 0.90, alternative = \"one.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample comparison of proportions power calculation \n#&gt; \n#&gt;               n = 1603.846\n#&gt;              p1 = 0.65\n#&gt;              p2 = 0.6\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = one.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\npower.prop.test(\n  p1 = .65, p2 = 0.6, sig.level = .05,\n  power = 0.90, alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample comparison of proportions power calculation \n#&gt; \n#&gt;               n = 1968.064\n#&gt;              p1 = 0.65\n#&gt;              p2 = 0.6\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\npwr 包 pwr.2p.test() 函数提供了类似 power.prop.test() 函数的功能\n\nlibrary(pwr)\n# 明确 p1 &gt; p2 的检验\n# 单边检验拆分更加明细，分为大于和小于\npwr.2p.test(\n  h = ES.h(p1 = 0.65, p2 = 0.6),\n  sig.level = 0.05, power = 0.9, alternative = \"greater\"\n)\n\n#&gt; \n#&gt;      Difference of proportion power calculation for binomial distribution (arcsine transformation) \n#&gt; \n#&gt;               h = 0.1033347\n#&gt;               n = 1604.007\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = greater\n#&gt; \n#&gt; NOTE: same sample sizes\n\n\n已知两样本的样本量不等，检验 H_0: \\(p_1 = p_2\\) H_1: \\(p_1 \\neq p_2\\) 的功效\n\npwr.2p2n.test(\n  h = 0.30, n1 = 80, n2 = 245,\n  sig.level = 0.05, alternative = \"greater\"\n)\n\n#&gt; \n#&gt;      difference of proportion power calculation for binomial distribution (arcsine transformation) \n#&gt; \n#&gt;               h = 0.3\n#&gt;              n1 = 80\n#&gt;              n2 = 245\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.7532924\n#&gt;     alternative = greater\n#&gt; \n#&gt; NOTE: different sample sizes\n\n\nh 表示两个样本的差异，计算得到的功效是 0.75",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#方差分析的功效",
    "href": "power-analysis.html#方差分析的功效",
    "title": "22  统计检验的功效",
    "section": "\n22.4 方差分析的功效",
    "text": "22.4 方差分析的功效\npower.anova.test() 计算平衡的单因素方差分析检验的功效\n\npower.anova.test(\n  groups = 4,       #  4 个组  \n  between.var = 1,  # 组间方差为 1\n  within.var = 3,   # 组内方差为 3\n  power = 0.95      # 1 - 犯第二类错误的概率\n)\n\n#&gt; \n#&gt;      Balanced one-way analysis of variance power calculation \n#&gt; \n#&gt;          groups = 4\n#&gt;               n = 18.18245\n#&gt;     between.var = 1\n#&gt;      within.var = 3\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt; \n#&gt; NOTE: n is number in each group\n\n\n\nlibrary(pwr)\n# f 是如何和上面的组间/组内方差等价指定的\npwr.anova.test(\n  k = 4,            # 组数\n  f = 0.5,          # 效应大小\n  sig.level = 0.05, # 显著性水平\n  power = 0.95      # 检验的效\n)\n\n#&gt; \n#&gt;      Balanced one-way analysis of variance power calculation \n#&gt; \n#&gt;               k = 4\n#&gt;               n = 18.18244\n#&gt;               f = 0.5\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt; \n#&gt; NOTE: n is number in each group",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html",
    "href": "analyze-network-data.html",
    "title": "23  网络分析",
    "section": "",
    "text": "23.1 R 语言社区的规模\n从 CRAN 上的 R 包及其开发者数量来看目前 R 语言社区规模。\n# 设置就近的 CRAN 镜像站点\nSys.setenv(R_CRAN_WEB = \"https://mirrors.tuna.tsinghua.edu.cn/CRAN\")\n# 获取 R 包元数据\npdb &lt;- tools::CRAN_package_db()\n截止 2022 年 12 月 31 日， CRAN 上发布的 R 包有 18976 个，CRAN 进入年末维护期 2022-12-22 至 2023-01-05。\npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package),\n  select = c(\"Package\", \"Maintainer\", \"Title\", \"Authors@R\", \"Date\", \"Published\")\n)\n距离上次更新的时间分布，有的包是一周内更新的，也有的是 10 多年未更新的。\npdb$date_diff &lt;- as.integer(as.Date(\"2022-12-31\") - as.Date(pdb$Published))\n根据发布日期 Published 构造新的一列 — 发布年份。\npdb$published_year &lt;- as.integer(format(as.Date(pdb$Published), \"%Y\"))\n然后按年统计更新的 R 包数量，如 图 23.1 所示，以 2020 年为例，总数 18976 个 R 包当中有 2470 个 R 包的更新日期停留在 2020 年，占比 2470 / 18976 = 13.02%。过去 1 年内更新的 R 包有 8112 个（包含新出现的 R 包），占总数 8112 / 18976 = 42.75%，过去 2 年内更新的 R 包有 11553 个，占总数 11553 / 18976 = 60.88%，这个占比越高说明社区开发者越活跃。\nlibrary(ggplot2)\naggregate(data = pdb, Package ~ published_year, FUN = length) |&gt;\n  ggplot(aes(x = published_year, y = Package)) +\n  geom_col(fill = NA, color = \"gray20\") +\n  theme_classic() +\n  coord_cartesian(expand = F) +\n  labs(x = \"年份\", y = \"R 包数量\")\n\n\n\n\n\n\n图 23.1: CRAN 上 R 包的更新情况\n截止 2022-12-31，CRAN 上 R 包的维护者有 10049 人，其中有多少人在 2022 年更新了自己的 R 包呢？有 4820 个维护者，占比 47.96%，也就是说 2022 年，有 4820 个开发者更新了 8112 个 R 包，人均更新 1.68 个 R 包，下 图 23.2 按 R 包发布年份统计开发者数量。\n# 清理维护者字段，同一个开发者可能有多个邮箱\nextract_maintainer &lt;- function(x) {\n  x &lt;- gsub(pattern = \"&lt;.*?&gt;\", replacement = \"\", x = x)\n  x &lt;- trimws(x, which = \"both\", whitespace = \"[ \\t\\r\\n]\")\n  x\n}\n# 极少量的维护者名字大小写不一样\npdb$Maintainer2 &lt;- tolower(extract_maintainer(pdb$Maintainer))\n# 维护者总数\nlength(unique(pdb$Maintainer2))\n\n#&gt; [1] 10049\naggregate(\n  data = pdb, Maintainer2 ~ published_year,\n  FUN = function(x) {\n    length(unique(x))\n  }\n) |&gt;\n  ggplot(aes(x = published_year, y = Maintainer2)) +\n  geom_col(fill = NA, color = \"gray20\") +\n  theme_classic() +\n  coord_cartesian(expand = F) +\n  labs(x = \"年份\", y = \"开发者数量\")\n\n\n\n\n\n\n图 23.2: CRAN 上的维护者活跃情况",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-community-org",
    "href": "analyze-network-data.html#sec-community-org",
    "title": "23  网络分析",
    "section": "\n23.2 R 语言社区的组织",
    "text": "23.2 R 语言社区的组织\n有的组织基本停止了开发，如 Omegahat，有的被商业公司收购后，不再活跃了，如 Revolution Analytics。除了众所周知的 tidyverse (Wickham 等 2019) 和 tidymodels (Kuhn 和 Wickham 2020)，还有很多数据分析、建模的工具箱，如 mlr3verse (Lang 和 Schratz 2023)、easystats (Lüdecke 等 2022)、strengejacke (Lüdecke 2019) 和 DrWhy (Biecek 2023)。它们作为解决方案大都属于一些组织，还有深藏功与名，有待笔者挖掘的。因不存在明显的规律，下面从开发者的邮箱出发，隶属企业、组织往往有统一的邮箱后缀。\n\nstr_extract &lt;- function(text, pattern, ...) regmatches(text, regexpr(pattern, text, ...))\n# 移除 ORPHANED\npdb &lt;- subset(pdb, subset = Maintainer != \"ORPHANED\")\n# 抽取邮件后缀\nextract_email_suffix &lt;- function(x) {\n  x &lt;- str_extract(text = x, pattern = \"&lt;.*?&gt;\")\n  sub(x = x, pattern = \".*?@(.*?)&gt;\", replacement = \"\\\\1\")\n}\npdb$Email_suffix &lt;- extract_email_suffix(pdb$Maintainer)\n\n按组织统计扩展包的数量（总的 R 包数量约 2 万），即各个组织开发的 R 包。\n\npdb_pkg &lt;- aggregate(\n  data = pdb, Package ~ Email_suffix, FUN = function(x) { length(unique(x)) }\n)\nhead(pdb_pkg[order(pdb_pkg$Package, decreasing = TRUE), ], 20)\n\n#&gt;        Email_suffix Package\n#&gt; 876       gmail.com    6968\n#&gt; 2044    rstudio.com     208\n#&gt; 979     hotmail.com     185\n#&gt; 1825    outlook.com     152\n#&gt; 1971  R-project.org     106\n#&gt; 2           163.com      94\n#&gt; 210    berkeley.edu      91\n#&gt; 2559      umich.edu      91\n#&gt; 2819         uw.edu      74\n#&gt; 1927 protonmail.com      73\n#&gt; 2564        umn.edu      69\n#&gt; 581      debian.org      68\n#&gt; 2951      yahoo.com      68\n#&gt; 1828     outlook.fr      63\n#&gt; 2212   stanford.edu      58\n#&gt; 155  auckland.ac.nz      57\n#&gt; 887          gmx.de      55\n#&gt; 2911       wisc.edu      55\n#&gt; 895  googlemail.com      50\n#&gt; 1970  r-project.org      50\n\n\n不难看出，至少有如下几类：\n\n邮件服务提供商。6968 个 R 包使用 gmail 邮箱作为联系维护者的方式，googlemail.com 也是谷歌提供的服务。hotmail.com 和 outlook.com 都是微软提供的邮箱服务，outlook.fr （法国）也是，除此之外，比较大的邮件服务提供商就是 163.com（网易）、 protonmail.com 和 yahoo.com （雅虎）等。\n商业组织。208 个 R 包来自 RStudio 公司的员工，这些维护者使用 RStudio 公司提供的邮箱。\n开源组织。R-project.org 和 r-project.org 都是 R 语言组织的联系方式，自不必多说，R 语言核心团队成员不仅维护 R 软件源码，还维护了很多 R 包。debian.org 是 Debian 组织的联系方式，都是开源组织（Open Source Org）。\n大学学院机构。berkeley.edu 、umich.edu 等以 edu 结尾的北美（国）的大学，gmx.de、 posteo.de 等以 de 结尾的德国大学，ucl.ac.uk 等以 uk 结尾的英国的大学，auckland.ac.nz 等以 nz 结尾的新西兰的大学，uwaterloo.ca 等以 ca 结尾的加拿大的大学。\n\n按组织统计开发者的数量（总的开发者数量约 1 万），即各个组织的 R 包开发者。\n\npdb_org &lt;- aggregate(\n  data = pdb, Maintainer2 ~ Email_suffix, FUN = function(x) { length(unique(x)) }\n)\nhead(pdb_org[order(pdb_org$Maintainer2, decreasing = TRUE), ], 20)\n\n#&gt;        Email_suffix Maintainer2\n#&gt; 876       gmail.com        3795\n#&gt; 979     hotmail.com         109\n#&gt; 1825    outlook.com          87\n#&gt; 2           163.com          57\n#&gt; 2559      umich.edu          54\n#&gt; 2951      yahoo.com          51\n#&gt; 2564        umn.edu          47\n#&gt; 1927 protonmail.com          46\n#&gt; 2819         uw.edu          46\n#&gt; 887          gmx.de          34\n#&gt; 210    berkeley.edu          33\n#&gt; 2044    rstudio.com          30\n#&gt; 895  googlemail.com          28\n#&gt; 2212   stanford.edu          27\n#&gt; 468    columbia.edu          26\n#&gt; 1114       inrae.fr          26\n#&gt; 2451      ucl.ac.uk          25\n#&gt; 2964       yale.edu          25\n#&gt; 635        duke.edu          23\n#&gt; 1906      posteo.de          23\n\n\n可见，大部分开发者采用邮件服务提供商的邮件地址。3795 个开发者使用来自谷歌的 gmail.com、196 个开发者使用来自微软的 hotmail.com 或 outlook.com，57 个开发者使用来自网易的 163.com，51 个开发者使用来自雅虎的 yahoo.com，46 个开发者使用来自 Proton 的 protonmail.com。\n无论从开发者数量还是 R 包数量的角度看，都有两个显著特点。其一马太效应，往头部集中，其二，长尾分布，尾部占比接近甚至超过 50%。1666 个开发者来自以 edu 为后缀的邮箱。各个大学及其 R 包开发者数据如下：\n\nsum(pdb_org[grepl(pattern = \"edu$\", x = pdb_org$Email_suffix), \"Maintainer2\"])\n\n#&gt; [1] 1666\n\npdb_org_edu &lt;- pdb_org[grepl(pattern = \"edu$\", x = pdb_org$Email_suffix), ]\npdb_org_edu[order(pdb_org_edu$Maintainer2, decreasing = TRUE), ] |&gt; head(20)\n\n#&gt;        Email_suffix Maintainer2\n#&gt; 2559      umich.edu          54\n#&gt; 2564        umn.edu          47\n#&gt; 2819         uw.edu          46\n#&gt; 210    berkeley.edu          33\n#&gt; 2212   stanford.edu          27\n#&gt; 468    columbia.edu          26\n#&gt; 2964       yale.edu          25\n#&gt; 635        duke.edu          23\n#&gt; 2911       wisc.edu          23\n#&gt; 482     cornell.edu          22\n#&gt; 2444    ucdavis.edu          21\n#&gt; 1929        psu.edu          19\n#&gt; 2449   uchicago.edu          19\n#&gt; 2830 vanderbilt.edu          19\n#&gt; 1660       ncsu.edu          18\n#&gt; 1663         nd.edu          18\n#&gt; 1008    iastate.edu          17\n#&gt; 1919  princeton.edu          17\n#&gt; 1815        osu.edu          16\n#&gt; 2523      uiowa.edu          16\n\n\n好吧，几乎全是美国各个 NB 大学的，比如华盛顿大学（ uw.edu）、密歇根大学（umich.edu）、加州伯克利大学（berkeley.edu）等等。顺便一说，欧美各个大学的网站，特别是统计院系很厉害的，已经帮大家收集得差不多了，有留学打算的读者自取，邮箱后缀就是学校/院官网。\n有些邮箱后缀带有院系，但是并没有向上合并到学校这一级，比如 stanford.edu 、stat.stanford.edu 和 alumni.stanford.edu 等没有合并统计，所以学校排名仅供参考。有的邮箱来自教育机构，但是不以 edu 结尾，实际上，使用 edu 邮箱的教育机构大部份位于美国。美国以外的教育机构，比如新西兰奥克兰大学 auckland.ac.nz 、瑞士苏黎世联邦理工学院 stat.math.ethz.ch 等。如果读者还知道其他一般规律的，或者提供大学邮箱列表或者有其它更好的办法，就可以把这个排序数字做得更加精准一些。\n下面根据邮箱后缀匹配抽取 CRAN 团队及开发的 R 包，规则也许不能覆盖所有的情况，读者若有补充，欢迎 PR 给我。举个例子，Brian Ripley 的邮箱 ripley@stats.ox.ac.uk 就不是一路，需要单独添加。\n代码core_dev &lt;- subset(pdb,\n  subset = grepl(\n    x = Maintainer,\n    pattern = paste0(c(\n      \"(@[Rr]-project\\\\.org)\", # 官方邮箱\n      \"(ripley@stats.ox.ac.uk)\", # Brian Ripley\n      \"(p.murrell@auckland.ac.nz)\", # Paul Murrell\n      \"(paul@stat.auckland.ac.nz)\", # Paul Murrell\n      \"(maechler@stat.math.ethz.ch)\", # Martin Maechler\n      \"(mmaechler+Matrix@gmail.com)\", # Martin Maechler\n      \"(bates@stat.wisc.edu)\", # Douglas Bates\n      \"(pd.mes@cbs.dk)\", # Peter Dalgaard\n      \"(ligges@statistik.tu-dortmund.de)\", # Uwe Ligges\n      \"(tlumley@u.washington.edu)\", # Thomas Lumley\n      \"(t.lumley@auckland.ac.nz)\", # Thomas Lumley\n      \"(martyn.plummer@gmail.com)\", # Martyn Plummer\n      \"(luke-tierney@uiowa.edu)\", # Luke Tierney\n      \"(stefano.iacus@unimi.it)\", # Stefano M. Iacus\n      \"(murdoch.duncan@gmail.com)\", # Duncan Murdoch\n      \"(michafla@gene.com)\" # Michael Lawrence\n    ), collapse = \"|\")\n  ),\n  select = c(\"Package\", \"Maintainer\")\n) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer,\n    pattern = '(&lt;([^&lt;&gt;]*)&gt;)|(\")',\n    replacement = \"\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer,\n    pattern = \"(R-core)|(R Core Team)\",\n    replacement = \"CRAN Team\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer,\n    pattern = \"(S. M. Iacus)|(Stefano M.Iacus)|(Stefano Maria Iacus)\",\n    replacement = \"Stefano M. Iacus\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer,\n    pattern = \"(Toby Hocking)\",\n    replacement = \"Toby Dylan Hocking\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer,\n    pattern = \"(John M Chambers)\",\n    replacement = \"John Chambers\"\n  ))\n\ntmp &lt;- aggregate(data = core_dev, Package ~ Maintainer, FUN = function(x) length(unique(x)))\ntmp &lt;- tmp[order(tmp$Package, decreasing = TRUE), ]\n\nknitr::kable(head(tmp, ceiling(nrow(tmp) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n代码knitr::kable(tail(tmp, floor(nrow(tmp) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n\n\n表格 23.1: CRAN 团队开发维护 R 包数量情况\n\n\n\n\n\n(a) 表\n\n\n\n团队成员\nR 包数量\n\n\n\nKurt Hornik\n28\n\n\nSimon Urbanek\n26\n\n\nAchim Zeileis\n25\n\n\nMartin Maechler\n25\n\n\nTorsten Hothorn\n25\n\n\nPaul Murrell\n19\n\n\nToby Dylan Hocking\n17\n\n\nBrian Ripley\n12\n\n\nThomas Lumley\n12\n\n\nUwe Ligges\n9\n\n\nDuncan Murdoch\n7\n\n\nDavid Meyer\n6\n\n\nCRAN Team\n5\n\n\n\n\n\n\n\n\n\n\n(b) 续表\n\n\n\n团队成员\nR 包数量\n\n\n\nFriedrich Leisch\n5\n\n\nLuke Tierney\n5\n\n\nMichael Lawrence\n5\n\n\nStefan Theussl\n5\n\n\nBettina Grün\n3\n\n\nJohn Chambers\n3\n\n\nSimon Wood\n3\n\n\nBettina Gruen\n2\n\n\nDeepayan Sarkar\n2\n\n\nDouglas Bates\n2\n\n\nMartyn Plummer\n2\n\n\nPeter Dalgaard\n1\n\n\n\n\n\n\n\n\n\n\n\nKurt Hornik、Simon Urbanek、Achim Zeileis 、Martin Maechler、Torsten Hothorn等真是高产呐！除了维护 R 语言核心代码，还开发维护了20 多个 R 包。以 Brian Ripley 为例，看看他都具体维护了哪些 R 包。\n\n代码subset(pdb,\n  subset = grepl(\n    x = Maintainer,\n    pattern = \"Brian Ripley\"\n  ),\n  select = c(\"Package\", \"Title\"), drop = TRUE\n) |&gt;\n  unique(by = \"Package\") |&gt;\n  transform(Title = gsub(\n    pattern = \"(\\\\\\n)\",\n    replacement = \" \", x = Title\n  )) |&gt;\n  knitr::kable(row.names = FALSE)\n\n\n表格 23.2: Brian Ripley 维护的 R 包\n\n\n\n\n\n\n\n\nPackage\nTitle\n\n\n\nboot\nBootstrap Functions (Originally by Angelo Canty for S)\n\n\nclass\nFunctions for Classification\n\n\nfastICA\nFastICA Algorithms to Perform ICA and Projection Pursuit\n\n\ngee\nGeneralized Estimation Equation Solver\n\n\nKernSmooth\nFunctions for Kernel Smoothing Supporting Wand & Jones (1995)\n\n\nMASS\nSupport Functions and Datasets for Venables and Ripley’s MASS\n\n\nmix\nEstimation/Multiple Imputation for Mixed Categorical and Continuous Data\n\n\nnnet\nFeed-Forward Neural Networks and Multinomial Log-Linear Models\n\n\npspline\nPenalized Smoothing Splines\n\n\nRODBC\nODBC Database Access\n\n\nspatial\nFunctions for Kriging and Point Pattern Analysis\n\n\ntree\nClassification and Regression Trees\n\n\n\n\n\n\n\n\n震惊！有一半收录在 R 软件中，所以已经持续维护 20 多年了。下面继续根据邮箱后缀将 RStudio 团队的情况统计出来，结果见下表。\n代码rstudio_db &lt;- subset(pdb,\n  subset = grepl(x = Maintainer, pattern = \"(posit.co)|(rstudio.com)|(yihui.name)\"),\n  select = c(\"Package\", \"Maintainer\")\n) |&gt;\n  transform(Maintainer = extract_maintainer(Maintainer))\n\nrstudio_db &lt;- aggregate(data = rstudio_db, Package ~ Maintainer, FUN = function(x) length(unique(x)))\nrstudio_db &lt;- rstudio_db[order(rstudio_db$Package, decreasing = TRUE), ]\n\nknitr::kable(head(rstudio_db, ceiling(nrow(rstudio_db) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n代码knitr::kable(tail(rstudio_db, floor(nrow(rstudio_db) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n\n\n表格 23.3: RStudio 团队开发维护 R 包数量情况（部分）\n\n\n\n\n\n(a) 表\n\n\n\n团队成员\nR 包数量\n\n\n\nHadley Wickham\n48\n\n\nYihui Xie\n22\n\n\nMax Kuhn\n18\n\n\nLionel Henry\n15\n\n\nWinston Chang\n15\n\n\nDaniel Falbel\n13\n\n\nJennifer Bryan\n13\n\n\nDavis Vaughan\n11\n\n\nCarson Sievert\n10\n\n\nTomasz Kalinowski\n8\n\n\nBarret Schloerke\n6\n\n\nThomas Lin Pedersen\n6\n\n\nHannah Frick\n5\n\n\nChristophe Dervieux\n4\n\n\nJoe Cheng\n4\n\n\nJulia Silge\n4\n\n\n\n\n\n\n\n\n\n\n(b) 续表\n\n\n\n团队成员\nR 包数量\n\n\n\nCole Arendt\n3\n\n\nEdgar Ruiz\n3\n\n\nJJ Allaire\n3\n\n\nKevin Kuo\n3\n\n\nKevin Ushey\n3\n\n\nRichard Iannone\n3\n\n\nAron Atkins\n2\n\n\nRomain François\n2\n\n\nYitao Li\n2\n\n\nBrian Smith\n1\n\n\nEmil Hvitfeldt\n1\n\n\nGarrick Aden-Buie\n1\n\n\nJames Blair\n1\n\n\nNathan Stephens\n1\n\n\nNick Strayer\n1\n\n\n\n\n\n\n\n\n\n\n\nCRAN 和 RStudio 团队是 R 语言社区最为熟悉的，其它团队需借助一些网络分析算法挖掘了。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-community-developer",
    "href": "analyze-network-data.html#sec-community-developer",
    "title": "23  网络分析",
    "section": "\n23.3 R 语言社区的开发者",
    "text": "23.3 R 语言社区的开发者\n\n23.3.1 最高产的开发者\n继续基于数据集 pdb ，将维护 R 包数量比较多的开发者统计出来。\n\npdb_ctb &lt;- aggregate(data = pdb, Package ~ Maintainer2, FUN = length)\nggplot(data = pdb_ctb[pdb_ctb$Package &gt;= 20, ]) +\n  geom_col(aes(x = Package, y = reorder(Maintainer2, Package)), width = .1) +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\n\n\n\n\n\n\n图 23.3: 高产的 R 包开发者\n\n\n\n\n发现，开发 1 个 R 包的开发者有 7656 人，开发 2 个 R 包的开发者有 1678 人，第二名是第一名的五分之一，递减规律非常符合指数分布。\n\ntable(pdb_ctb$Package)\n\n#&gt; \n#&gt;    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n#&gt; 6716 1683  720  328  180   81   82   52   37   36   31   15   18    8   11    7 \n#&gt;   17   18   19   20   21   22   23   24   25   26   27   28   31   32   33   52 \n#&gt;    1    3    4    4    2    3    3    1    5    5    2    1    1    1    1    3 \n#&gt;   58   63   69 \n#&gt;    1    1    1\n\n\n过滤掉非常高产的开发者，可以发现变化规律服从幂律分布。\nggplot(data = pdb_ctb, aes(x = Package)) +\n  geom_histogram(binwidth = 1) +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\nggplot(data = pdb_ctb[pdb_ctb$Package &lt;= 20, ], aes(x = Package)) +\n  geom_histogram(binwidth = 1, fill = NA, color = \"gray20\") +\n  scale_y_log10() +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\n\n\n\n\n\n\n\n\n\n(a) 直方图\n\n\n\n\n\n\n\n\n\n(b) 直方图（对数尺度）\n\n\n\n\n\n\n图 23.4: 开发者数量的分布\n\n\n最高产 Top 1% 的开发者 117 人（开发 R 包超过 10 个的开发者）贡献了 2060 / 18976 = 10.8% 扩展包 ，高产的是商业公司、开源组织、大学机构。\n\ndim(pdb_ctb[pdb_ctb$Package &gt; 10, ])\n\n#&gt; [1] 133   2\n\nsum(pdb_ctb[pdb_ctb$Package &gt; 10, \"Package\"])\n\n#&gt; [1] 2351\n\n\n最低产 Bottom 的开发者 7656 人（仅开发一个 R 包的开发者） 贡献了 7656 / 18976 扩展包 40.3 %，低产的人是主体。\n\n23.3.2 开发者协作关系\n如果一个开发者维护了一个 R 包，就成为维护者。一个 R 包有唯一的一个维护者，可能有一个至多个贡献者，这样，维护者和贡献者之间就形成了有向关系，贡献者可能又是另一个 R 包的维护者，也可能不是。不仅有向而且可能存在环。在一个 R 包中，A 是 B 的贡献者，而在另一个 R 包中，B 是 A 的贡献者，A 和 B 之间可能通过多个 R 包存在多次互相协作关系，这也表明 A 和 B 之间的关系密切。有向环的节点可能有 2 个以上，一个人可能同时属于多个环。\n维护者 A 接受来自多个开发者的贡献，接受次数（所有贡献者人数的累和，A 的每个 R 包的贡献者人数相加）视为 A 的入度。维护者 A 作为开发者给多个维护者贡献，贡献次数（作为开发者给其它 R 包做贡献的次数，向外参与贡献的 R 包数目）视为 A 的出度。注意，A 作为维护者，必然包含 A 作为开发者，忽略 A 到 A 的贡献，只考虑贡献/协作关系。\n\n# 过滤重复和缺失的记录\npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package) & !is.na(`Authors@R`),\n  select = c(\"Package\", \"Maintainer\", \"Authors@R\")\n)\n# 提取维护者的名字\npdb$Maintainer &lt;- extract_maintainer(pdb$Maintainer)\n\n有些包的元数据中没有 Authors@R 字段，有可能是没有贡献者，比如 mgcv 包、gam 包等，但也有可能是有贡献者，只是维护者没有填写这个字段，比如 Rcpp 包、RcppEigen 包等，因此将这些先过滤出来。总之，本文是以 Authors@R 字段作为贡献者的来源，共计 12503 个 R 包含有 Authors@R ，有 6000+ 个 R 包没有该字段，缺失约占 R 包总数的 1/3，在不那么考虑准确性的情况下，也可以使用。Author 字段是一段没有结构的文本，相比于 Author 字段，Authors@R 字段是以 R 语言中的 person 类型为存储结构的，比较规范，因此，提取贡献者的操作比较方便。作为示例，下面提取 Matrix 包的贡献者。\n\ntmp &lt;- eval(parse(text = pdb[pdb$Package == \"Matrix\", \"Authors@R\"]))\ntmp &lt;- unlist(lapply(tmp, function(x) format(x, include = c(\"given\", \"family\"))))\n# 返回一个整洁的数据框\ntmp &lt;- data.frame(Package = \"Matrix\", Maintainer = pdb[pdb$Package == \"Matrix\", \"Maintainer\"], Authors = tmp)\n# 去掉 Authors 是 Maintainer 的记录\nsubset(tmp, subset = Maintainer != Authors)\n\n#&gt;   Package      Maintainer           Authors\n#&gt; 1  Matrix Martin Maechler     Douglas Bates\n#&gt; 3  Matrix Martin Maechler      Mikael Jagan\n#&gt; 4  Matrix Martin Maechler  Timothy A. Davis\n#&gt; 5  Matrix Martin Maechler Jens Oehlschlägel\n#&gt; 6  Matrix Martin Maechler       Jason Riedy\n#&gt; 7  Matrix Martin Maechler       R Core Team\n\n\n数据框包含 R 包（Package 字段）、及其维护者（Maintainer 字段）和贡献者（Authors 字段）。将上述过程写成一个函数，接着，将所有 R 包的贡献者提取出来，形成一个大的数据框。\n\nextract_authors &lt;- function(pkg) {\n  sub_pdb &lt;- pdb[pdb$Package == pkg, ]\n  tmp &lt;- eval(parse(text = sub_pdb[, \"Authors@R\"]))\n  tmp &lt;- unlist(lapply(tmp, function(x) format(x, include = c(\"given\", \"family\"))))\n  tmp &lt;- data.frame(Package = pkg, Maintainer = sub_pdb[, \"Maintainer\"], Authors = tmp)\n  subset(tmp, subset = Maintainer != Authors)\n}\nextract_authors(\"Matrix\")\n\n#&gt;   Package      Maintainer           Authors\n#&gt; 1  Matrix Martin Maechler     Douglas Bates\n#&gt; 3  Matrix Martin Maechler      Mikael Jagan\n#&gt; 4  Matrix Martin Maechler  Timothy A. Davis\n#&gt; 5  Matrix Martin Maechler Jens Oehlschlägel\n#&gt; 6  Matrix Martin Maechler       Jason Riedy\n#&gt; 7  Matrix Martin Maechler       R Core Team\n\n# lapply(c(\"Matrix\", \"gt\"), extract_authors)\n# 抽取所有 R 包的贡献者，运行需要1-2分钟时间\npdb_authors_list &lt;- lapply(pdb[, \"Package\"], extract_authors)\n# 合并列表\npdb_authors_dt &lt;- data.table::rbindlist(pdb_authors_list)\n\n最后整理出来的大数据框 pdb_authors_dt 含有近 26000 条记录，即边的规模大小。考虑到有些维护者和贡献者之间可能存在多次合作的情况，下面统计一下合作次数。\n\npdb_authors_dt[ ,.(cnt = length(Package)) , by = c(\"Maintainer\", \"Authors\")][cnt &gt;= 10, ][order(cnt, decreasing = T), ]\n\n#&gt;                 Maintainer               Authors cnt\n#&gt;  1:         Hadley Wickham               RStudio  36\n#&gt;  2:          Pablo Sanchez            Windsor.ai  25\n#&gt;  3:           Jan Wijffels                BNOSAC  24\n#&gt;  4:           Gábor Csárdi               RStudio  19\n#&gt;  5:               Hong Ooi             Microsoft  16\n#&gt;  6:               Max Kuhn               RStudio  14\n#&gt;  7:           Lionel Henry               RStudio  14\n#&gt;  8:      Robrecht Cannoodt        Wouter Saelens  13\n#&gt;  9:      Scott Chamberlain              rOpenSci  13\n#&gt; 10:            Joe Thorley    Poisson Consulting  13\n#&gt; 11:      Frederic Bertrand Myriam Maumy-Bertrand  12\n#&gt; 12:          Winston Chang               RStudio  12\n#&gt; 13:          Daniel Falbel               RStudio  12\n#&gt; 14:           David Kretch           Adam Banker  12\n#&gt; 15:           David Kretch      Amazon.com, Inc.  12\n#&gt; 16:         Victor Perrier           Fanny Meyer  11\n#&gt; 17:         Jennifer Bryan               RStudio  11\n#&gt; 18: William Michael Landau Eli Lilly and Company  11\n#&gt; 19:        Adrian Baddeley             Ege Rubak  11\n#&gt; 20:           Gábor Csárdi            Jim Hester  10\n#&gt; 21:          Kirill Müller               RStudio  10\n#&gt; 22:         Carson Sievert               RStudio  10\n#&gt; 23:    Thomas Lin Pedersen               RStudio  10\n#&gt; 24:           Lionel Henry        Hadley Wickham  10\n#&gt; 25:        Adrian Baddeley           Rolf Turner  10\n#&gt;                 Maintainer               Authors cnt\n\n\nAuthors 字段出现了不少组织的名字，这是因为有许多 R 包的维护者受雇于该组织，版权归属于该组织，组织不仅提供持续的资金，而且还提供其它帮助。以 dplyr 包为例，Hadley Wickham 受雇于 RStudio 公司，在 dplyr 包的元数据中，字段 Authors@R 中 RStudio 的角色是 cph 和 fnd ，即版权所有和资金支持。角色 cre 就是维护者，负责与 CRAN 团队的沟通。角色 aut 就是对 R 包有实质贡献的人。\n\nformat(eval(parse(text = pdb[pdb$Package == \"dplyr\", \"Authors@R\"])),\n       include = c(\"given\", \"family\", \"role\"))\n\n#&gt; [1] \"Hadley Wickham [aut, cre]\" \"Romain François [aut]\"    \n#&gt; [3] \"Lionel Henry [aut]\"        \"Kirill Müller [aut]\"      \n#&gt; [5] \"RStudio [cph, fnd]\"\n\n\n此外，同属于一个组织的维护者之间常常合作紧密，从上面的结果可以看到，Gábor Csárdi 和 Jim Hester ，Lionel Henry 和 Hadley Wickham，Carson Sievert 和 Joe Cheng ，Jennifer Bryan 和 Hadley Wickham 等同属于 RStudio 公司，常常协作开发项目。对 RStudio、CRAN Team 和 rOpenSci 不再赘述，下面对排名靠前的其它组织略作说明。\n\n\nWindsor.ai 提供一系列可以连接各大营销平台，获取营销效果数据 R 包。\n\nBNOSAC 提供一系列计算机视觉、图像识别、自然语言处理方面的 R 包，比如 word2vec 包、doc2vec 包等。\nMicrosoft 提供一系列连接和操作 Azure 云套件的 R 包，比如 AzureR 包。\n\nWouter Saelens 提供一系列单细胞轨迹推理（single-cell trajectory inference）相关的 R 包，形成一个 dynverse 家族。\n\n\nPoisson Consulting 提供一系列用于计算生物学和统计生态学的 R 包和相关研究论文。\n\nAmazon.com, Inc. 提供一系列用于存储、管理、操作等 Amazon 云服务的 R 包，形成一个 paws 套件。\nEli Lilly and Company 可能是 rOpenSci 的一员，赞助了旗下的 targets 和 jagstargets 等 R 包。\n\n最后，统计协作次数的分布，网络中边的权重的分布。\n\npdb_authors_net &lt;- pdb_authors_dt[, .(cnt = .N), by = c(\"Maintainer\", \"Authors\")]\n\n可以发现，绝大多数人之间协作只有一次。\n\ntable(pdb_authors_net$cnt)\n\n#&gt; \n#&gt;     1     2     3     4     5     6     7     8     9    10    11    12    13 \n#&gt; 20432  1511   365   121    44    28    14     8     3     6     4     5     3 \n#&gt;    14    16    19    24    25    36 \n#&gt;     2     1     1     1     1     1\n\n\n\n23.3.3 节点出入度分布\n下面简化这个网络，仅考虑贡献者也是维护者的情况，就是说网络中所有节点既是维护者也是贡献者，这会过滤掉组织机构、大量没有在 CRAN 发过 R 包的贡献者、从没给其它维护者做贡献的维护者。简化后，网络节点的出度、入度的分布图如下。\n# Maintainer 的入度\npdb_authors_net_indegree &lt;- pdb_authors_dt[Authors %in% Maintainer, ][, .(in_degree = length(Authors)), by = \"Maintainer\"]\n# Authors 的出度\npdb_authors_net_outdegree &lt;- pdb_authors_dt[Authors %in% Maintainer, ][, .(out_degree = length(Maintainer)), by = \"Authors\"]\n\nggplot(pdb_authors_net_indegree, aes(x = in_degree)) +\n  geom_histogram(binwidth = 1) +\n  geom_freqpoly(binwidth = 1) +\n  theme_classic()\nggplot(pdb_authors_net_outdegree, aes(x = out_degree)) +\n  geom_histogram(binwidth = 1) +\n  geom_freqpoly(binwidth = 1) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) 入度的分布\n\n\n\n\n\n\n\n\n\n(b) 出度的分布\n\n\n\n\n\n\n图 23.5: 节点的入度和出度的分布\n\n\n\n23.3.4 可视化协作网络\n节点的大小以维护者维护的 R 包数量来表示，边的大小以维护者之间协作次数来表示。为了美观起见，更为了突出重点，仅保留协作次数大于 1 的边。\n\n# 边\npdb_authors_net_edge &lt;- pdb_authors_dt[Authors %in% Maintainer, ][, .(edge_cnt = .N), by = c(\"Authors\", \"Maintainer\")][edge_cnt &gt; 1,]\npdb_authors_net_edge[order(edge_cnt, decreasing = TRUE),]\n\n#&gt;                      Authors            Maintainer edge_cnt\n#&gt;   1:              Jim Hester          Gábor Csárdi       10\n#&gt;   2:          Hadley Wickham          Lionel Henry       10\n#&gt;   3:               Joe Cheng        Carson Sievert        9\n#&gt;   4:          Hadley Wickham        Jennifer Bryan        8\n#&gt;   5: Steven Andrew Culpepper James Joseph Balamuta        8\n#&gt;  ---                                                       \n#&gt; 526:             Aaron Wolen     Scott Chamberlain        2\n#&gt; 527:               Bob Rudis         Simon Garnier        2\n#&gt; 528:           Marco Sciaini         Simon Garnier        2\n#&gt; 529:          Carlos Morales           Martin Chan        2\n#&gt; 530:               Md Yeasin     Ranjit Kumar Paul        2\n\n# 顶点\npdb_authors_net_vertex &lt;- pdb_authors_dt[, .(vertex_cnt = length(unique(Package))), by = \"Maintainer\"][Maintainer %in% c(pdb_authors_net_edge$Maintainer, pdb_authors_net_edge$Authors),]\npdb_authors_net_vertex[order(vertex_cnt, decreasing = TRUE),]\n\n#&gt;                Maintainer vertex_cnt\n#&gt;   1:       Hadley Wickham         43\n#&gt;   2:         Gábor Csárdi         33\n#&gt;   3:          Jeroen Ooms         28\n#&gt;   4:    Scott Chamberlain         28\n#&gt;   5:            Yihui Xie         21\n#&gt;  ---                                \n#&gt; 579:    Katriona Goldmann          1\n#&gt; 580:        Carlo Pacioni          1\n#&gt; 581:       Michael Scholz          1\n#&gt; 582: Javier Roca-Pardinas          1\n#&gt; 583:         Xianying Tan          1\n\n\n这是一个有向图，其各个字段含义如下。\n\nMaintainer 维护者（代表流 to）\nAuthors 贡献者（代表源 from）\n\nedge_cnt 边的大小表示维护者 Maintainer 和贡献者 Authors 的协作次数\n\nvertex_cnt 顶点大小表示维护者 Maintainer 维护的 R 包数量\n\n下面先考虑用 igraph 包可视化这个复杂的有向带权网络。pdb_authors_net_edge 和 pdb_authors_net_vertex 都是数据框，首先调用 igraph 包的函数 graph_from_data_frame() 将其转化为网络类型 igraph ，然后使用函数 plot() 绘制网络图。\n\n代码# 构造图\nlibrary(igraph)\npdb_authors_graph &lt;- graph_from_data_frame(d = pdb_authors_net_edge, vertices = pdb_authors_net_vertex, directed = TRUE)\n# 可视化\nop &lt;- par(mar = rep(0, 4))\nplot(pdb_authors_graph,\n  edge.width = (E(pdb_authors_graph)$edge_cnt) / 2,\n  edge.arrow.size = .01,\n  edge.curved = .1,\n  layout = layout.kamada.kawai,\n  vertex.size = (V(pdb_authors_graph)$vertex_cnt) / 8,\n  vertex.label.cex = sqrt(V(pdb_authors_graph)$vertex_cnt) / 8\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 23.6: 开发者的协作关系网络\n\n\n\n\n协作关系弱的开发者占大部分，构成一个「月亮」的造型，其中，不乏维护多个 R 包的开发者，这些人要么单干，要么在专业小领域、小组织内协作。与之相对应的是协作关系较强的开发者，人数虽少，影响力却大，构成一个「太阳」的造型。协作得多往往意味着维护的 R 包也不少，甚至同属于一个组织，因此，高产的开发者、影响力大的组织聚集在一起，如 R Core Team、RStudio、rOpenSci 等。\n\neb &lt;- cluster_edge_betweenness(pdb_authors_graph)\neb\n\n#&gt; IGRAPH clustering edge betweenness, groups: 181, mod: 0.88\n#&gt; + groups:\n#&gt;   $`1`\n#&gt;   [1] \"Matt Nunes\"           \"Daniel Grose\"         \"Guy Nason\"           \n#&gt;   [4] \"Rebecca Killick\"      \"Idris Eckley\"         \"Alessandro Cardinali\"\n#&gt;   \n#&gt;   $`2`\n#&gt;   [1] \"Jin Zhu\"    \"Shiyun Lin\"\n#&gt;   \n#&gt;   $`3`\n#&gt;    [1] \"Julio Trecenti\"       \"Henrik Bengtsson\"     \"Morgane Pierre-Jean\" \n#&gt;    [4] \"Zhian N. Kamvar\"      \"Pierre Neuvial\"       \"Michal Bojanowski\"   \n#&gt;   + ... omitted several groups/vertices\n\n\nigraph 包提供多种社区探测的算法，上面简单使用函数 cluster_edge_betweenness() 来探测，结果显示有 181 个社区。社区 1 包含的成员如下：\n\neb$names[eb$membership == 1]\n\n#&gt; [1] \"Matt Nunes\"           \"Daniel Grose\"         \"Guy Nason\"           \n#&gt; [4] \"Rebecca Killick\"      \"Idris Eckley\"         \"Alessandro Cardinali\"\n\n\n社区 3、14、21、34、46、52、75 的成员是比较多的。其中，社区 3 是以 RStudio 为核心的大社区，社区 14 是以 CRAN 为核心的大社区。\n\n# RStudio 为核心的大社区\neb$names[eb$membership == 3]\n\n#&gt;  [1] \"Julio Trecenti\"       \"Henrik Bengtsson\"     \"Morgane Pierre-Jean\" \n#&gt;  [4] \"Zhian N. Kamvar\"      \"Pierre Neuvial\"       \"Michal Bojanowski\"   \n#&gt;  [7] \"Ian Lyttle\"           \"Thomas Lin Pedersen\"  \"Yihui Xie\"           \n#&gt; [10] \"Dirk Schumacher\"      \"Jeroen Ooms\"          \"Gábor Csárdi\"        \n#&gt; [13] \"Sean Kross\"           \"Carl Boettiger\"       \"Neal Richardson\"     \n#&gt; [16] \"Ryan Hafen\"           \"Matthew Fidler\"       \"Hadley Wickham\"      \n#&gt; [19] \"Mark Edmondson\"       \"Kirill Müller\"        \"Richard Iannone\"     \n#&gt; [22] \"Carson Sievert\"       \"Winston Chang\"        \"Lionel Henry\"        \n#&gt; [25] \"Jennifer Bryan\"       \"Michael Sumner\"       \"Scott Chamberlain\"   \n#&gt; [28] \"Garrick Aden-Buie\"    \"Daniel Falbel\"        \"Matthew B. Jones\"    \n#&gt; [31] \"Hiroaki Yutani\"       \"Taiyun Wei\"           \"Jim Hester\"          \n#&gt; [34] \"Romain François\"      \"Greg Freedman Ellis\"  \"Rhian Davies\"        \n#&gt; [37] \"Bryce Mecum\"          \"Steph Locke\"          \"Christophe Dervieux\" \n#&gt; [40] \"Jonathan Keane\"       \"Thibaut Jombart\"      \"Dewey Dunnington\"    \n#&gt; [43] \"Anne Cori\"            \"Bill Denney\"          \"Jared Huling\"        \n#&gt; [46] \"Wush Wu\"              \"Atsushi Yasumoto\"     \"Barret Schloerke\"    \n#&gt; [49] \"Yuan Tang\"            \"Duncan Garmonsway\"    \"Edzer Pebesma\"       \n#&gt; [52] \"Sebastian Meyer\"      \"Derek Burk\"           \"Tim Taylor\"          \n#&gt; [55] \"Alicia Schep\"         \"Tomasz Kalinowski\"    \"Michael Rustler\"     \n#&gt; [58] \"Joe Cheng\"            \"Bhaskar Karambelkar\"  \"Sebastian Kreutzer\"  \n#&gt; [61] \"JJ Allaire\"           \"JooYoung Seo\"         \"Zachary Foster\"      \n#&gt; [64] \"Malcolm Barrett\"      \"Aaron Wolen\"          \"Bruno Tremblay\"      \n#&gt; [67] \"Justin Wilkins\"       \"Yixuan Qiu\"           \"Johannes Friedrich\"  \n#&gt; [70] \"Kevin Ushey\"          \"Steven M. Mortimer\"   \"Karthik Ram\"         \n#&gt; [73] \"Jorrit Poelen\"        \"Maëlle Salmon\"        \"Aron Atkins\"         \n#&gt; [76] \"Ramnath Vaidyanathan\" \"Thomas Leeper\"        \"Dirk Eddelbuettel\"   \n#&gt; [79] \"Xianying Tan\"\n\n# CRAN 为核心的大社区\neb$names[eb$membership == 14]\n\n#&gt;  [1] \"Achim Zeileis\"        \"Michael Hahsler\"      \"Michel Lang\"         \n#&gt;  [4] \"Nikolaus Umlauf\"      \"Vincent Dorie\"        \"Bettina Gruen\"       \n#&gt;  [7] \"Bernd Bischl\"         \"Ben Bolker\"           \"Marc Becker\"         \n#&gt; [10] \"Friedrich Leisch\"     \"Brian Ripley\"         \"Michael Friendly\"    \n#&gt; [13] \"John Fox\"             \"Kurt Hornik\"          \"Patrick Schratz\"     \n#&gt; [16] \"Volodymyr Melnykov\"   \"Martin Maechler\"      \"George Ostrouchov\"   \n#&gt; [19] \"Drew Schmidt\"         \"Georgi N. Boshnakov\"  \"Wei-Chen Chen\"       \n#&gt; [22] \"Stefan Theussl\"       \"David Meyer\"          \"Jakob Bossek\"        \n#&gt; [25] \"Francois Michonneau\"  \"Marius Hofert\"        \"Florian Schwendinger\"\n#&gt; [28] \"Felix Zimmer\"         \"Martin Binder\"        \"Phil Chalmers\"       \n#&gt; [31] \"Lukas Sablica\"        \"Sebastian Fischer\"    \"Lennart Schneider\"   \n#&gt; [34] \"Jakob Richter\"        \"Florian Wickelmaier\"  \"Rudolf Debelak\"      \n#&gt; [37] \"Duncan Murdoch\"       \"Alexander Brenning\"   \"Ingo Feinerer\"\n\n\n同时，在 RStudio 这个大社区下，有一些与之紧密相关的小社区，比如 Rob Hyndman 等人的时间序列社区、Roger Bivand 等人的空间统计社区。\n\n# 时间序列 Rob Hyndman\neb$names[eb$membership == 52]\n\n#&gt;  [1] \"Asael Alonzo Matamoros\"   \"Nicholas Tierney\"        \n#&gt;  [3] \"Sevvandi Kandanaarachchi\" \"Rob Hyndman\"             \n#&gt;  [5] \"Di Cook\"                  \"Mitchell O'Hara-Wild\"    \n#&gt;  [7] \"Han Lin Shang\"            \"Sayani Gupta\"            \n#&gt;  [9] \"Earo Wang\"                \"Christoph Bergmeir\"\n\n# 空间统计 Roger Bivand\neb$names[eb$membership == 75]\n\n#&gt; [1] \"Sebastian Jeworutzki\" \"Roger Bivand\"         \"Colin Rundel\"        \n#&gt; [4] \"Angela Li\"            \"Gianfranco Piras\"     \"Patrick Giraudoux\"   \n#&gt; [7] \"Giovanni Millo\"\n\n\n结合前面的 图 23.6 ，知道有很多小圈圈，这些放一边，重点关注那些大的圈圈，见下图。\n\n代码op &lt;- par(mar = rep(0, 4))\nplot(eb, pdb_authors_graph,\n  edge.width = (E(pdb_authors_graph)$edge_cnt) / 4,\n  edge.arrow.size = .01,\n  edge.curved = .1,\n  layout = layout.kamada.kawai,\n  vertex.size = (V(pdb_authors_graph)$vertex_cnt) / 8,\n  vertex.label.cex = sqrt(V(pdb_authors_graph)$vertex_cnt) / 8\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 23.7: 探测协作关系网络中的社区\n\n\n\n\n下面使用 tidygraph 包构造图数据、计算节点中心度，dplyr 包操作数据。中心度代表节点（开发者）的影响力（或者重要性）。最后，借助 ggraph 包绘制维护者之间的贡献网络，节点的大小代表维护者影响力的强弱。\n\n代码pdb_authors_g &lt;- tidygraph::as_tbl_graph(pdb_authors_net_edge, directed = T) |&gt; \n dplyr::mutate(Popularity = tidygraph::centrality_degree(mode = 'in'))\n\nlibrary(ggraph)\nggraph(pdb_authors_g, layout = \"kk\") +\n  geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) +\n  geom_node_point(aes(size = Popularity), alpha = 0.5) +\n  theme_graph(base_family = \"sans\")\n\n\n\n\n\n\n图 23.8: 开发者的影响力网络\n\n\n\n\n前面两个网络图基于同一份数据、同样的网络布局算法，得到非常类似的结果。静态图上的标签相互重叠，影响细节的观察和探索，比如连接 CRAN 和 RStudio 两大阵营的通道。下面使用 visNetwork 包绘制交互式网络图，这样可以在图上使用鼠标放大、拖拽。可以发现在 CRAN 社区的 Achim Zeileis 和 RStudio 社区的 Max Kuhn 之间是由 Andri Signorell 牵线搭桥。\n\n代码library(visNetwork)\n# 将 igraph 对象转为 visNetwork 包可用的数据\ndat &lt;- toVisNetworkData(pdb_authors_graph)\nnodes_df &lt;- dat$nodes\nnodes_df$value &lt;- nodes_df$vertex_cnt\nedges_df &lt;- dat$edges\nedges_df$value &lt;- edges_df$edge_cnt\n# 输入节点和边的数据\nvisNetwork(nodes = nodes_df, edges = edges_df, height = \"500px\") |&gt; \n  visIgraphLayout(randomSeed = 20232023, layout = \"layout.kamada.kawai\")\n\n\n\n\n\n\n图 23.9: 开发者的影响力网络（visNetwork）",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#扩展阅读",
    "href": "analyze-network-data.html#扩展阅读",
    "title": "23  网络分析",
    "section": "\n23.4 扩展阅读",
    "text": "23.4 扩展阅读\nR 语言网络分析方面的著作有 Erick Kolaczyk 的书籍《Statistical Analysis of Network Data with R》(Kolaczyk 和 Csárdi 2020)，网络可视化方面，推荐 Hadley Wickham 的著作《ggplot2: Elegant Graphics for Data Analysis》(Wickham, Navarro, 和 Pedersen 2024) 的第七章，Sam Tyner 等人的文章《Network Visualization with ggplot2》(Tyner, Briatte, 和 Hofmann 2017) 也值得一看。此外，读者若有兴趣，可以用 visNetwork 包制作交互式网络图形，它是 JS 库 vis-network 的 R 语言接口。而 Richard Iannone 开发的 DiagrammeR 包可以制作静态的矢量网页图形。\n可视化网络的 R 包有 igraph 、ggraph 等，专业的软件有 Gephi 等。igraph 是非常流行和核心的网络分析 C 语言库，它提供有多种语言的接口，其 R 语言接口 igraph 包也被很多其它做网络分析的 R 包所引用。开源的 Gephi 软件适合处理中等规模的网络分析和可视化。大规模图计算可以用 Apache Spark 的 GraphX。R 语言这层，主要还是对应数据分析和数据产品，用于在内部咨询和商业分析。\n企业级的图存储和计算框架，比较有名（可能是最有名的），反正，笔者最先听说的是Neo4j ，它有以 AGPL 协议发布的开源版本，还有商业版本。Nebula Graph 分布式开源图数据库，高扩展性和高可用性，支持千亿节点、万亿条边、毫秒级查询，有中文文档，有企业应用案例，美团图数据库平台建设及业务实践。阿里研发的 GraphScope 提供一站式大规模图计算系统，支持图神经网络计算。HugeGraph 图数据库应用于金融反欺诈实践。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-analysis-network-data-exercise",
    "href": "analyze-network-data.html#sec-analysis-network-data-exercise",
    "title": "23  网络分析",
    "section": "\n23.5 习题",
    "text": "23.5 习题\n\n类似开发者协作关系的分析，可以统计 R 包被多少 R 包依赖，依赖数量的分布。统计 R 包被依赖的深度（若 R 包 A 被 R 包 B 依赖，R 包 B 被 R 包 C 依赖，以此类推）。进而，构建、分析、可视化依赖关系网络，分析 R 包的影响力。\n本文基于 2022 年 12 月 31 日的 R 包元数据进行分析，请与 2023 年 12 月 31 日的数据比较。\n\n\n\n\n\nBates, Douglas, 和 Dirk Eddelbuettel. 2013. 《Fast and Elegant Numerical Linear Algebra Using the RcppEigen Package》. Journal of Statistical Software 52 (5): 1–24. https://doi.org/10.18637/jss.v052.i05.\n\n\nBiecek, Przemyslaw. 2023. DrWhy: Explain, Explore and Debug Predictive Machine Learning Models. https://github.com/ModelOriented/DrWhy.\n\n\nKolaczyk, Eric D., 和 Gábor Csárdi. 2020. Statistical Analysis of Network Data with R. 2nd 本. Springer, New York, NY. https://doi.org/10.1007/978-3-030-44129-6.\n\n\nKuhn, Max, 和 Hadley Wickham. 2020. Tidymodels: a collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org.\n\n\nLang, Michel, 和 Patrick Schratz. 2023. mlr3verse: Easily Install and Load the mlr3 Package Family. https://CRAN.R-project.org/package=mlr3verse.\n\n\nLüdecke, Daniel. 2019. strengejacke: Load Packages Associated with Strenge Jacke! https://github.com/strengejacke/strengejacke.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Brenton M. Wiernik, Etienne Bacher, Rémi Thériault, 和 Dominique Makowski. 2022. 《easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting》. CRAN. https://easystats.github.io/easystats/.\n\n\nTyner, Sam, François Briatte, 和 Heike Hofmann. 2017. 《Network Visualization with ggplot2》. The R Journal 9 (1): 27–59. https://doi.org/10.32614/RJ-2017-023.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, 等. 2019. 《Welcome to the tidyverse》. Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Danielle Navarro, 和 Thomas Lin Pedersen. 2024. ggplot2: Elegant Graphics for Data Analysis. 3rd 本. Springer-Verlag New York. https://ggplot2-book.org/.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html",
    "href": "analyze-text-data.html",
    "title": "24  文本分析",
    "section": "",
    "text": "24.1 基本概念",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#基本概念",
    "href": "analyze-text-data.html#基本概念",
    "title": "24  文本分析",
    "section": "",
    "text": "24.1.1 中文分词\n本文采用 jiebaR 作为中文分词工具，相比于 Rwordseg 包，不仅效果好，而且没有 rJava 包 (JAVA) 环境依赖。\n\nlibrary(jiebaRD)\nlibrary(jiebaR)\njieba_seg &lt;- worker()\nsegment(\"齐白石对花鸟虫鱼都有研究呢\", jieba_seg)\n\n#&gt; [1] \"齐白石\"   \"对\"       \"花鸟虫鱼\" \"都\"       \"有\"       \"研究\"     \"呢\"\n\n\n\n24.1.2 英文分词\n英文环境下，词与词之间本身就是以空格分开的。\n\nsegment(\"Hello world!\", jieba_seg)\n\n#&gt; [1] \"Hello\" \"world\"\n\n\n\n24.1.3 停止词\n数字、标点符号、空格不参与分词，会被抹掉。\n\nsegment(\"国画大师齐白石对花鸟虫鱼都有研究呢！\", jieba_seg)\n\n#&gt; [1] \"国画\"     \"大师\"     \"齐白石\"   \"对\"       \"花鸟虫鱼\" \"都\"       \"有\"      \n#&gt; [8] \"研究\"     \"呢\"\n\n\n还可以添加停止词，将「花鸟虫鱼」作为停止词添加到停止词库中。\n\njieba_seg &lt;- worker(stop_word = \"data/text/stop_word.txt\")\nsegment(\"国画大师齐白石对花鸟虫鱼都有研究呢\", jieba_seg)\n\n#&gt; [1] \"国画\"   \"大师\"   \"齐白石\" \"对\"     \"都\"     \"有\"     \"研究\"   \"呢\"\n\n\n\n24.1.4 分词与词性\n中文环境没有英文的词干化（lemmatization）过程（比如 applied / applies -&gt; apply），只考虑分词、词性。spacyr 包通过 reticulate 包调用 Python 社区的自然语言处理模块 spacy ，支持多种语言的分词、词性识别等。配置好 Python 环境，下载中文环境下的语言模型。\n\nlibrary(spacyr)\n# 下载语言模型\n# spacy_download_langmodel(\"zh_core_web_sm\")\n# 初始化语言模型\nspacy_initialize(model = \"zh_core_web_sm\")\n\n#&gt; successfully initialized (spaCy Version: 3.7.2, language model: zh_core_web_sm)\n\n# Token 化是分词\nspacy_tokenize(\"国画大师齐白石对花鸟虫鱼都有研究呢\")\n\n#&gt; $text1\n#&gt;  [1] \"国画\"   \"大师\"   \"齐白石\" \"对\"     \"花鸟\"   \"虫鱼\"   \"都\"     \"有\"    \n#&gt;  [9] \"研究\"   \"呢\"\n\n# 示例\ntxt &lt;- c(d1 = \"国画大师齐白石对花鸟虫鱼都有研究呢\",\n         d2 = \"中国人民银行很行\",\n         d3 = \"张大千在研究国画\")\n# 解析\nparsed_txt &lt;- spacy_parse(txt)\n\n#&gt; Warning in spacy_parse.character(txt): lemmatization may not work properly in\n#&gt; model 'zh_core_web_sm'\n\n# 结果\nparsed_txt\n\n#&gt;    doc_id sentence_id token_id  token lemma   pos   entity\n#&gt; 1      d1           1        1   国画        NOUN         \n#&gt; 2      d1           1        2   大师        NOUN         \n#&gt; 3      d1           1        3 齐白石       PROPN PERSON_B\n#&gt; 4      d1           1        4     对         ADP         \n#&gt; 5      d1           1        5   花鸟        NOUN         \n#&gt; 6      d1           1        6   虫鱼        NOUN         \n#&gt; 7      d1           1        7     都         ADV         \n#&gt; 8      d1           1        8     有        VERB         \n#&gt; 9      d1           1        9   研究        NOUN         \n#&gt; 10     d1           1       10     呢        PART         \n#&gt; 11     d2           1        1   中国       PROPN    ORG_B\n#&gt; 12     d2           1        2   人民        NOUN    ORG_I\n#&gt; 13     d2           1        3   银行        NOUN    ORG_I\n#&gt; 14     d2           1        4     很         ADV         \n#&gt; 15     d2           1        5     行        VERB         \n#&gt; 16     d3           1        1 张大千       PROPN PERSON_B\n#&gt; 17     d3           1        2     在         ADP         \n#&gt; 18     d3           1        3   研究        VERB         \n#&gt; 19     d3           1        4   国画        NOUN\n\n\n人名都是名词，如齐白石、张大千等，「研究」既可做动词，也可做名词，「都」和「很」是副词。「中国人民银行很行」的「行」应当是形容词，但被识别为动词。\n\n24.1.5 词频统计\n输入字符串向量，计算每个字符串出现的次数。jiebaR 包的函数 freq() 可以统计词出现的频次。\n\nfreq(c(\"a\", \"a\", \"c\"))\n\n#&gt;   char freq\n#&gt; 1    c    1\n#&gt; 2    a    2\n\n\n\n24.1.6 TF-IDF\n输入一个列表，列表中每个元素是字符串向量，每个字符串向量代表一个文档。jiebaR 包的函数 get_idf() 可以计算 TF-IDF（Document Frequency - Inverse Document Frequency） 值。\n\nget_idf(list(c(\"abc\", \"def\"), c(\"abc\", \" \")))\n\n#&gt;   name     count\n#&gt; 1  def 0.6931472\n#&gt; 2  abc 0.0000000",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#益辉的日志",
    "href": "analyze-text-data.html#益辉的日志",
    "title": "24  文本分析",
    "section": "\n24.2 益辉的日志",
    "text": "24.2 益辉的日志\n下载益辉的日志数据\ngit clone git@github.com:yihui/yihui.org.git\n经过整理后，打包成 Rdata 数据供 R 软件使用。\n\n# 加载益辉的日志数据\nload(file = \"data/text/yihui.Rdata\")\n\n\n24.2.1 整体概况\n\n代码library(ggplot2)\nlibrary(ggrepel)\nggplot() +\n  geom_label_repel(\n    data = df2, aes(x = year, y = file_name, label = event_wrap),\n    max.overlaps = 150, segment.colour = \"gray\", seed = 2023\n  ) +\n  geom_point(data = df1, aes(x = file_year, y = file_name)) +\n  geom_line(data = df1, aes(x = file_year, y = file_name)) +\n  scale_x_continuous(n.breaks = 15) +\n  theme_bw() +\n  labs(x = \"年份\", y = \"篇数\")\n\n\n\n\n\n\n图 24.1: 益辉每年发布的日志数量\n\n\n\n\n2006 年获得中国人民大学学士学位，2009 和 2013 年分别获得中国人民大学硕士和爱荷华州立大学博士学位，在校期间，日志数量持续增加，又陆续创立统计之都，举办中国 R 语言大会。在毕业那年需要完成毕业论文，因此，日志数量明显减少。2013 -2016 年，每年都有书籍出版，期间，有博士毕业、找工作、安家等重要事情，因此，日志数量持续处于低位。稳定后，2017-2018 年除了正常出两本书以外，写了大量的日志，迎来第二个高峰，2018 年，中英文日志数量超过 300 篇。2019-2020 年集中精力在写一本食谱。2021 年第一本中文书《现代统计图形》在10年后出版，这主要是 2007-2011 年的工作。2021-2023 年日志数量（2023年中文日志未发布）处于较低水平。\n\n24.2.2 数据清洗\n以 2001 年的一篇日志为例，展开数据清洗的过程。移除文章的 YAML 元数据，对于文本分析来说，主要是没啥信息含量。\n\nremove_yaml &lt;- function(x) {\n  x[(max(which(x == \"---\")) + 1):length(x)]\n}\nx &lt;- remove_yaml(x)\n\n移除「我」 「是」 「你」 「的」 「了」 「也」 等高频的人称、助词、虚词。这些词出现的规律对表现个人风格很重要，且看红楼梦关于后40回作者归属的研究，通过比较一些助词、虚词的出现规律，从而看出作者的习惯、文风。这种东西是在长期的潜移默化中形成的，对作者自己来说，都可能是无意识的。\n\nlibrary(jiebaR)\n# jieba_seg &lt;- worker(stop_word = \"data/text/stop_word.txt\")\njieba_seg &lt;- worker(stop_word = \"data/text/cn_stopwords.txt\")\n\n添加新词，比如「歪贼」、「谢益辉」等，主要是人名、外号等实体。\n\nnew_words &lt;- readLines(file(\"data/text/new_word.txt\"))\nnew_user_word(worker = jieba_seg, words = new_words)\n\n#&gt; [1] TRUE\n\n# 分词\nx_seg &lt;- segment(x, jieba_seg)\n\n分词后，再移除数字和英文\n\nremove_number_english &lt;- function(x) {\n  x &lt;- x[!grepl(\"\\\\d{1,}\", x)]\n  x[!grepl(\"[a-zA-Z]\", x)]\n}\nxx &lt;- remove_number_english(x = x_seg)\n\n词频统计\n\ntmp &lt;- freq(x = xx)\ntmp &lt;- tmp[order(tmp$freq, decreasing = T), ]\nhead(tmp)\n\n#&gt;       char freq\n#&gt; 285   一个    7\n#&gt; 397   同学    5\n#&gt; 178   一篇    4\n#&gt; 356   没有    4\n#&gt; 67    鼻音    3\n#&gt; 106 田春雨    3\n\n\nggwordcloud 包绘制词云图可视化词频统计的结果。\n\nlibrary(ggwordcloud)\nhead(tmp, 150) |&gt;\n  ggplot(aes(label = char, size = freq)) +\n  geom_text_wordcloud(seed = 2022, grid_size = 8, max_grid_size = 24) +\n  scale_size_area(max_size = 10)\n\n\n\n\n\n\n图 24.2: 词云可视化词频结果\n\n\n\n\n计算 TF-IDF 值\n\n# tmp = get_idf(x = list(xx))\nget_idf(x = list(xx)) |&gt; head()\n\n#&gt;     name count\n#&gt; 1   黄新     0\n#&gt; 2   邹瑜     0\n#&gt; 3   张恒     0\n#&gt; 4 蒋前程     0\n#&gt; 5   肖攀     0\n#&gt; 6 刘浩然     0\n\n\n\n24.2.3 主题建模\n益辉的日志是没有分类和标签的，所以，先聚类，接着逐个分析每个类代表的实际含义。然后，将聚类的结果作为结果标签，再应用多分类回归模型，最后联合聚类、分类模型，从无监督转化到有监督模型。\ntopicmodels (Grün 和 Hornik 2011) 基于 tm (Feinerer, Hornik, 和 Meyer 2008) Latent Dirichlet Allocation (LDA) 和 Correlated Topics Models (CTM) 文本主题建模，这一套工具比较适合英文文本分词、向量化和建模。\ntext2vec 包支持多个统计模型，如潜在狄利克雷分配等，可用于分类、回归、聚类等任务。更多详情见 https://text2vec.org。\n\nlibrary(text2vec)\n\n首先将所有日志分词、向量化，构建文档-词矩阵 document-term matrix (DTM)\n\n# 移除链接\nremove_links &lt;- function(x) {\n  gsub(pattern = \"(&lt;http.*?&gt;)|(\\\\(http.*?\\\\))|(&lt;www.*?&gt;)|(\\\\(www.*?&gt;\\\\))\", replacement = \"\", x)\n}\n# 清理、分词、清理\nfile_list1 &lt;- lapply(file_list, remove_yaml)\nfile_list1 &lt;- lapply(file_list1, remove_links)\nfile_list1 &lt;- lapply(file_list1, segment, jiebar = jieba_seg)\nfile_list1 &lt;- lapply(file_list1, remove_number_english)\n\n去掉没啥实际意义的词（比如单个字），极高频词和极低频词。\n\n# Token 化\nit &lt;- itoken(file_list1, ids = 1:length(file_list1), progressbar = FALSE)\nv &lt;- create_vocabulary(it)\n# 去掉单个字 减少 3K\nv &lt;- v[nchar(v$term) &gt; 1,]\n# 去掉极高频词和极低频词 减少 1.4W\nv &lt;- prune_vocabulary(v, term_count_min = 10, doc_proportion_max = 0.2)\n\n采用 LDA（Latent Dirichlet Allocation）算法建模\n\n# 词向量化\nvectorizer &lt;- vocab_vectorizer(v)\n# 文档-词矩阵 DTM\ndtm &lt;- create_dtm(it, vectorizer, type = \"dgTMatrix\")\n#  10 个主题\nlda_model &lt;- LDA$new(n_topics = 10, doc_topic_prior = 0.1, topic_word_prior = 0.01)\n# 训练模型\ndoc_topic_distr &lt;- lda_model$fit_transform(\n    x = dtm, n_iter = 1000, convergence_tol = 0.001, \n    n_check_convergence = 25, progressbar = FALSE\n  )\n\n#&gt; INFO  [07:26:39.702] early stopping at 175 iteration\n#&gt; INFO  [07:26:40.615] early stopping at 75 iteration\n\n\n下图展示主题的分布，各个主题及其所占比例。\n\nbarplot(\n  doc_topic_distr[1, ], xlab = \"主题\", ylab = \"比例\", \n  ylim = c(0, 1), names.arg = 1:ncol(doc_topic_distr)\n)\n\n\n\n\n\n\n图 24.3: 主题分布\n\n\n\n\n将 10 个主题的 Top 12 词分别打印出来。\n\nlda_model$get_top_words(n = 12, topic_number = 2L:10L, lambda = 0.3)\n\n#&gt;       [,1]   [,2]     [,3]     [,4]     [,5]   [,6]     [,7]     [,8]   [,9]  \n#&gt;  [1,] \"人生\" \"网站\"   \"统计\"   \"记得\"   \"吱吱\" \"小时候\" \"工作\"   \"代码\" \"社会\"\n#&gt;  [2,] \"生活\" \"域名\"   \"数据\"   \"老师\"   \"一看\" \"歌词\"   \"项目\"   \"文档\" \"观点\"\n#&gt;  [3,] \"读书\" \"服务器\" \"模型\"   \"同学\"   \"居然\" \"一首\"   \"编辑\"   \"文件\" \"教育\"\n#&gt;  [4,] \"力量\" \"注册\"   \"变量\"   \"学校\"   \"小子\" \"阿姨\"   \"免费\"   \"功能\" \"时代\"\n#&gt;  [5,] \"文字\" \"博客\"   \"计算\"   \"一次\"   \"满意\" \"好吃\"   \"社区\"   \"字体\" \"人类\"\n#&gt;  [6,] \"自然\" \"服务\"   \"图形\"   \"英语\"   \"整理\" \"照片\"   \"文章\"   \"用户\" \"文化\"\n#&gt;  [7,] \"一句\" \"系统\"   \"分布\"   \"高中\"   \"中间\" \"渴望\"   \"意味着\" \"生成\" \"成功\"\n#&gt;  [8,] \"一生\" \"广告\"   \"统计学\" \"第一次\" \"一遍\" \"听到\"   \"精力\"   \"图片\" \"认为\"\n#&gt;  [9,] \"娱乐\" \"访问\"   \"方法\"   \"北京\"   \"一天\" \"我家\"   \"最大\"   \"元素\" \"价值\"\n#&gt; [10,] \"作品\" \"搜索\"   \"矩阵\"   \"小学\"   \"打开\" \"地上\"   \"想法\"   \"编译\" \"创造\"\n#&gt; [11,] \"风格\" \"网址\"   \"回归\"   \"美帝\"   \"飞机\" \"黄瓜\"   \"写作\"   \"安装\" \"美国\"\n#&gt; [12,] \"文中\" \"网络\"   \"数学\"   \"回家\"   \"全都\" \"记忆\"   \"显著\"   \"函数\" \"本书\"\n\n\n结果有点意思，说明益辉喜欢统计图形（主题 4）、代码编程（主题 9）、倒腾网站（主题 3）、回忆青春（主题 5）、读书写作（主题 2、8、10），但是诗词歌赋、做菜吃饭，不是很明显。\n\n24.2.4 日志相似性\n我与益辉日志的相似性度量 https://text2vec.org/similarity.html",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-analysis-text-data-exercises",
    "href": "analyze-text-data.html#sec-analysis-text-data-exercises",
    "title": "24  文本分析",
    "section": "\n24.3 习题",
    "text": "24.3 习题\n\ntext2vec 包内置的电影评论数据集 movie_review 中 sentiment（表示正面或负面评价）列作为响应变量，构建二分类模型，对用户的一段评论分类。（提示：词向量化后，采用 glmnet 包做交叉验证调整参数、模型）\n根据 CRAN 上发布的 R 包元数据分析 R 包的描述字段，实现 R 包主题分类。\n接习题 2，根据任务视图对 R 包的标记，建立有监督的多分类模型，评估模型的分类效果，并对尚未标记的 R 包分类。（提示：一个 R 包可能同时属于多个任务视图，考虑使用 xgboost 包）\n\n\n\n\n\nFeinerer, Ingo, Kurt Hornik, 和 David Meyer. 2008. 《Text Mining Infrastructure in R》. Journal of Statistical Software 25 (5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nGrün, Bettina, 和 Kurt Hornik. 2011. 《topicmodels: An R Package for Fitting Topic Models》. Journal of Statistical Software 40 (13): 1–30. https://doi.org/10.18637/jss.v040.i13.\n\n\nHvitfeldt, Emil, 和 Julia Silge. 2021. Supervised Machine Learning for Text Analysis in R. New York: Chapman; Hall/CRC. https://smltar.com/.\n\n\nSilge, Julia, 和 David Robinson. 2017. Text Mining with R. New York: O’Reilly Media, Inc. https://www.tidytextmining.com/.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本分析</span>"
    ]
  },
  {
    "objectID": "analyze-survival-data.html",
    "href": "analyze-survival-data.html",
    "title": "25  生存分析",
    "section": "",
    "text": "25.1 问题背景\n急性粒细胞白血病生存数据\nlibrary(survival)\ndata(cancer, package = \"survival\")\nstr(aml)\n\n'data.frame':   23 obs. of  3 variables:\n $ time  : num  9 13 13 18 23 28 31 34 45 48 ...\n $ status: num  1 1 0 1 1 0 1 1 0 1 ...\n $ x     : Factor w/ 2 levels \"Maintained\",\"Nonmaintained\": 1 1 1 1 1 1 1 1 1 1 ...\n数据的分布情况如下\nggplot(data = aml, aes(x = time, y = status, color = x)) +\n  geom_jitter(height = 0.2) +\n  theme_minimal()\n\n\n\n\n\n\n图 25.1: 急性粒细胞白血病\n在垂直方向添加了抖动，不影响时间项 time ，可以对数据的分布看得更加清楚。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "analyze-survival-data.html#模型拟合",
    "href": "analyze-survival-data.html#模型拟合",
    "title": "25  生存分析",
    "section": "\n25.2 模型拟合",
    "text": "25.2 模型拟合\nCox 比例风险回归模型与 Box-Cox 变换 (Box 和 Cox 1964)\n\n\nsurvival::coxph() Cox 比例风险回归模型\n\nMASS::boxcox() Box-Cox 变换\nglmnet::glmnet(family = \"cox\")\nINLA 包的函数 inla() 与 inla.surv() 一起拟合，链接\n\n\nsurvstan Stan 与生存分析\nrstanarm 包的函数 stan_jm() 使用说明 Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm 链接\n\nrstanarm 包的生存分析分支\n\n\n\n25.2.1 survival\nR 软件内置了 survival 包，它是实现生存分析的核心 R 包 (Terry M. Therneau 和 Patricia M. Grambsch 2000)，其函数 survfit() 拟合模型。\n\naml_survival &lt;- survfit(Surv(time, status) ~ x, data = aml)\nsummary(aml_survival)\n\nCall: survfit(formula = Surv(time, status) ~ x, data = aml)\n\n                x=Maintained \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    9     11       1    0.909  0.0867       0.7541        1.000\n   13     10       1    0.818  0.1163       0.6192        1.000\n   18      8       1    0.716  0.1397       0.4884        1.000\n   23      7       1    0.614  0.1526       0.3769        0.999\n   31      5       1    0.491  0.1642       0.2549        0.946\n   34      4       1    0.368  0.1627       0.1549        0.875\n   48      2       1    0.184  0.1535       0.0359        0.944\n\n                x=Nonmaintained \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    5     12       2   0.8333  0.1076       0.6470        1.000\n    8     10       2   0.6667  0.1361       0.4468        0.995\n   12      8       1   0.5833  0.1423       0.3616        0.941\n   23      6       1   0.4861  0.1481       0.2675        0.883\n   27      5       1   0.3889  0.1470       0.1854        0.816\n   30      4       1   0.2917  0.1387       0.1148        0.741\n   33      3       1   0.1944  0.1219       0.0569        0.664\n   43      2       1   0.0972  0.0919       0.0153        0.620\n   45      1       1   0.0000     NaN           NA           NA\n\n\n拟合 Cox 比例风险回归模型（Cox Proportional Hazards Regression Model）\n\naml_coxph &lt;- coxph(Surv(time, status) ~ 1 + x, data = aml)\nsummary(aml_coxph)\n\nCall:\ncoxph(formula = Surv(time, status) ~ 1 + x, data = aml)\n\n  n= 23, number of events= 18 \n\n                 coef exp(coef) se(coef)     z Pr(&gt;|z|)  \nxNonmaintained 0.9155    2.4981   0.5119 1.788   0.0737 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nxNonmaintained     2.498     0.4003    0.9159     6.813\n\nConcordance= 0.619  (se = 0.063 )\nLikelihood ratio test= 3.38  on 1 df,   p=0.07\nWald test            = 3.2  on 1 df,   p=0.07\nScore (logrank) test = 3.42  on 1 df,   p=0.06\n\n\n展示拟合结果。可以绘制生存分析的图的 R 包有很多，比如 ggfortify 包、ggsurvfit 包和 survminer 包等。ggfortify 包可以直接针对函数 survfit() 的返回对象绘图，ggsurvfit 包提供新函数 survfit2() 拟合模型、函数 ggsurvfit() 绘制图形，画面内容更加丰富，而 survminer 包依赖很多。\n\nlibrary(ggplot2)\nlibrary(ggfortify)\nautoplot(aml_survival, data = aml) +\n  theme_minimal()\n\n\n\n\n\n\n图 25.2: 急性粒细胞白血病生存数据\n\n\n\n\n参数化的生存分析模型（参数模型，相对于非参数模型而言）\n\naml_surv_reg &lt;- survreg(Surv(time, status) ~ x, data = aml, dist = \"weibull\")\nsummary(aml_surv_reg)\n\n\nCall:\nsurvreg(formula = Surv(time, status) ~ x, data = aml, dist = \"weibull\")\n                Value Std. Error     z      p\n(Intercept)     4.109      0.300 13.70 &lt;2e-16\nxNonmaintained -0.929      0.383 -2.43  0.015\nLog(scale)     -0.235      0.178 -1.32  0.188\n\nScale= 0.791 \n\nWeibull distribution\nLoglik(model)= -80.5   Loglik(intercept only)= -83.2\n    Chisq= 5.31 on 1 degrees of freedom, p= 0.021 \nNumber of Newton-Raphson Iterations: 5 \nn= 23 \n\n\n下面 ggsurvfit 包再次拟合模型，并展示模型结果。\n\n25.2.2 ggsurvfit\n\nlibrary(ggsurvfit)\n\n拟合模型需要函数 survfit2()\n\naml_ggsurvfit &lt;- survfit2(Surv(time, status) ~ x, data = aml)\n\n模型输出\n\naml_ggsurvfit\n\nCall: survfit(formula = Surv(time, status) ~ x, data = aml)\n\n                 n events median 0.95LCL 0.95UCL\nx=Maintained    11      7     31      18      NA\nx=Nonmaintained 12     11     23       8      NA\n\n\n\nggsurvfit(aml_ggsurvfit, linewidth = 1) +\n  add_confidence_interval() +\n  add_risktable() +\n  add_quantile(y_value = 0.6, color = \"gray50\", linewidth = 0.75) +\n  scale_y_continuous(label = scales::percent_format()) +\n  labs(y = \"生存百分比\", title = \"从手术到随机化的复发时间\") \n\nWarning in ggplot2::geom_blank(): All aesthetics have length 1, but the data has 22 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 22 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 22 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 22 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 22 rows.\nℹ Did you mean to use `annotate()`?\n\n\n\n\n\n\n\n图 25.3: 比例风险回归\n\n\n\n\n\n25.2.3 glmnet\nglmnet 包拟合 Cox 比例风险回归模型 (Simon 等 2011) 适合需要多变量筛选的情况。\n\nlibrary(glmnet)\n# alpha = 1 lasso\naml_glmnet &lt;- glmnet(x = aml$x, y = Surv(aml$time, aml$status), family = \"cox\", alpha = 1)\naml_glmnet_cv &lt;- cv.glmnet(x = aml$x, y = Surv(aml$time, aml$status), family = \"cox\", alpha = 1)\n\n\n25.2.4 INLA\nINLA 包拟合 Cox 比例风险回归模型 (Gómez-Rubio 2020) 采用近似贝叶斯推断。\n\nlibrary(INLA)\ninla.setOption(short.summary = TRUE)\naml_inla &lt;- inla(inla.surv(time, status) ~ x, data = aml, family = \"exponential.surv\", num.threads = \"1:1\")\nsummary(aml_inla)\n\nFixed effects:\n                 mean    sd 0.025quant 0.5quant 0.975quant   mode kld\n(Intercept)    -4.173 0.378     -4.913   -4.173     -3.432 -4.173   0\nxNonmaintained  0.984 0.483      0.036    0.984      1.931  0.984   0\n\n is computed",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "analyze-survival-data.html#sec-tobit-regression",
    "href": "analyze-survival-data.html#sec-tobit-regression",
    "title": "25  生存分析",
    "section": "\n25.3 Tobit 回归",
    "text": "25.3 Tobit 回归\nTobit (Tobin’s Probit) regression 起源于计量经济学中的 Tobit 模型，James Tobin 提出的，用于截尾数据，生存分析中的一种加速失效模型 (accelerated failure model) (Tobin 1958)。\n\n逻辑回归，响应变量是无序的分类变量，假定服从二项、多项分布，拟合函数 glm() 和 nnet::multinom()\n\nProbit 回归，响应变量是有序的分类变量，拟合函数 MASS::polr()\n\nTobit 回归，响应变量是有删失/截尾的，VGAM 包依赖少，稳定，推荐使用。VGAM 包括了广义线性模型\n\n\nlibrary(VGAM)\nwith(aml, SurvS4(time, status))\n\n      time status\n [1,]    9      1\n [2,]   13      1\n [3,]   13      0\n [4,]   18      1\n [5,]   23      1\n [6,]   28      0\n [7,]   31      1\n [8,]   34      1\n [9,]   45      0\n[10,]   48      1\n[11,]  161      0\n[12,]    5      1\n[13,]    5      1\n[14,]    8      1\n[15,]    8      1\n[16,]   12      1\n[17,]   16      0\n[18,]   23      1\n[19,]   27      1\n[20,]   30      1\n[21,]   33      1\n[22,]   43      1\n[23,]   45      1\nattr(,\"type\")\n[1] \"right\"\nattr(,\"class\")\n[1] \"SurvS4\"\n\n\n\n\n\n\nBox, G. E. P., 和 D. R. Cox. 1964. 《An analysis of transformations (with discussion)》. Journal of the Royal Statistical Society, Series B 26 (2): 211–52. https://www.jstor.org/stable/2984418.\n\n\nGómez-Rubio, Virgilio. 2020. Bayesian inference with INLA. Boca Raton, Florida: Chapman; Hall/CRC. https://becarioprecario.bitbucket.io/inla-gitbook/.\n\n\nSimon, Noah, Jerome H. Friedman, Trevor Hastie, 和 Rob Tibshirani. 2011. 《Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent》. Journal of Statistical Software 39 (5): 1–13. https://doi.org/10.18637/jss.v039.i05.\n\n\nTerry M. Therneau, 和 Patricia M. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. New York: Springer.\n\n\nTobin, J. 1958. 《Estimation of relationships for limited dependent variables》. Econometrica 26 (1): 24–36. https://doi.org/10.2307/1907382.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "analyze-survival-data.html#footnotes",
    "href": "analyze-survival-data.html#footnotes",
    "title": "25  生存分析",
    "section": "",
    "text": "https://stat.ethz.ch/pipermail/r-help/2005-July/075649.html↩︎",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html",
    "href": "analyze-time-series-data.html",
    "title": "26  时序分析",
    "section": "",
    "text": "26.1 数据获取\nJoshua M. Ulrich 开发维护的 quantmod 包可以下载国内外股票市场的数据。本节主要以美团股价数据为例，美团自 2018-09-20 在香港挂牌上市，股票代码 3690.HK。首先用 quantmod 包 (Ryan 和 Ulrich 2022) 获取美团上市至 2023-11-24 每天的股价数据，包含 Open 开盘价、High 最高价、Low 最低价、Close 闭市价、Adjusted 调整价和 Volume 成交量数据。\nlibrary(quantmod)\n# 美团股票代码 3690\nmeituan &lt;- getSymbols(\"3690.HK\", auto.assign = FALSE, src = \"yahoo\")\n先来看数据的类型，数据类型颇为复杂，是由 xts 和 zoo 两种类型复合而成，xts 类型是继承自 zoo 类型的。\nclass(meituan)\n\n[1] \"xts\" \"zoo\"\n\nstr(meituan)\n\nAn xts object on 2018-09-20 / 2023-11-24 containing: \n  Data:    double [1275, 6]\n  Columns: 3690.HK.Open, 3690.HK.High, 3690.HK.Low, 3690.HK.Close, 3690.HK.Volume ... with 1 more column\n  Index:   Date [1275] (TZ: \"UTC\")\n  xts Attributes:\n    $ src    : chr \"yahoo\"\n    $ updated: POSIXct[1:1], format: \"2023-11-27 06:31:12\"\n数据集 meituan 是一个 xts 类型的时间序列数据对象，时间范围是 2018-09-20 至 2023-11-24，包含 4 个成分，分别如下\n与时间序列数据相关的数据类型有很多，比如 Base R 提供的 Date 和 POSIX 等，扩展包 timeDate 和 chron 也都有自己的一套数据类型及处理方法。xts 包是处理时间序列数据的主要工具之一，xts 是 eXtensible Time Series 的缩写。为了进一步了解用法，下面举个例子，使用该 R 包的函数 xts() 构造时间序列对象。\nlibrary(zoo)\nlibrary(xts)\n# 数据矩阵\nx &lt;- matrix(1:4, ncol = 2, nrow = 2)\n# 日期索引\nidx &lt;- as.Date(c(\"2018-01-01\", \"2019-12-12\"))\n# xts = matrix + index\nxts(x, order.by = idx)\n\n           [,1] [,2]\n2018-01-01    1    3\n2019-12-12    2    4",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#数据获取",
    "href": "analyze-time-series-data.html#数据获取",
    "title": "26  时序分析",
    "section": "",
    "text": "Data 部分显示为 906 行 6 列的双精度浮点存储的数值。\nColumns 部分显示列名，依次是 3690.HK.Open、3690.HK.High、 3690.HK.Low 和 3690.HK.Close 等，当列数很多时，显示时会省略。\nIndex 部分表示索引列，有序是时间序列数据的本质特点。示例中索引存储数据点产生的先后顺序，索引是用日期来表示的，日期所在的时区是 “UTC”。\nxts 部分是数据类型的一些属性（元数据），说明数据集的来源，什么时候制作的数据。示例中数据是从雅虎财经下载的，下载时间是 2023-11-27 14:31:12。\n\n\nxts(x = NULL,\n    order.by = index(x),\n    frequency = NULL,\n    unique = TRUE,\n    tzone = Sys.getenv(\"TZ\"),\n    ...)\n\n参数 x 表示数据。\n参数 order.by 表示索引数据。\n参数 frequency 表示频率。\n参数 unique 表示唯一。\n参数 tzone 表示时区。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#数据探索",
    "href": "analyze-time-series-data.html#数据探索",
    "title": "26  时序分析",
    "section": "\n26.2 数据探索",
    "text": "26.2 数据探索\n\n26.2.1 zoo\nzoo 包提供 S3 范型函数 autoplot.zoo() 专门可视化 zoo 类型的数据，它接受一个 zoo 类型的数据对象，返回一个 ggplot2 数据对象，然后用户可以添加自定义的绘图设置，更多详情见帮助文档 ?autoplot.zoo() 。\n\n# xts 包需要先加载，否则 Index 不是日期类型而是数值类型\nlibrary(ggplot2)\nautoplot(meituan[, \"3690.HK.Adjusted\"]) +\n  theme_classic() +\n  labs(x = \"日期\", y = \"股价\")\n\n\n\n\n\n\n图 26.1: 美团在香港上市以来的股价走势\n\n\n\n\nzoo 包还提供另一个范型函数 fortify() 将 zoo 数据对象转化为 data.frame ，这可以方便使用 ggplot2 包来展示数据。参数 melt = TRUE 意味着重塑原数据集，将数据从宽格式转长格式。参数 names = c(Index = \"Date\") 表示将 Index 列重命名为 date 列。\n\nmeituan_df &lt;- fortify(\n  meituan[, c(\"3690.HK.Adjusted\", \"3690.HK.High\")],\n  melt = TRUE, names = c(Index = \"Date\")\n)\n\n数据集 meituan_df 中的 Series 列是因子型的，将其标签 3690.HK.Adjusted 、3690.HK.High 调整为调整价、最高价。根据日期字段 Date 提取年份字段 year 和一年中的第几天的字段 day_of_year。\n\nmeituan_df &lt;- within(meituan_df, {\n  # 调整 Series 的标签\n  Series &lt;- factor(Series, labels = c(\"调整价\", \"最高价\"))\n  # 日期字段 Date 获取年份\n  year &lt;- format(Date, \"%Y\")\n  # 日期字段 Date 一年中的第几天\n  day_of_year &lt;- as.integer(format(Date, \"%j\"))\n})\n\n调用 ggplot2 包绘制分面、分组时间序列图，以 day_of_year 为横轴，股价 Value 为纵轴，按 year 分组，按 Series 分面。\n\nggplot(data = meituan_df, aes(x = day_of_year, y = Value)) +\n  geom_line(aes(color = year)) +\n  facet_wrap(~Series, ncol = 1) + \n  theme_classic() +\n  labs(x = \"一年中的第几天\", y = \"调整的股价\", color = \"年份\")\n\n\n\n\n\n\n图 26.2: 美团调整的股价逐年走势\n\n\n\n\n2019 年底开始出现疫情，2020 年整年陆续有疫情，美团股价一路狂飙突进，因疫情，利好外卖业务，市场看好外卖业务。2021 年政府去杠杆，互联网监管趋严，又监又管，受外部大环境，逆全球化趋势影响，整年股价一路走低。进入 2022 年，股价在 200 附近徘徊。\n\n26.2.2 xts\n\nlibrary(xts)\n\nxts 包提供 S3 泛型函数 plot.xts() 专门用来可视化 xts 类型的时间序列数据\n\nplot(meituan[, \"3690.HK.Adjusted\"], main = \"调整的股价\")\n\n\n\n\n\n\n图 26.3: 美团在香港上市以来的股价走势\n\n\n\n\n还可以任意选择一个时间窗口，展示相关数据\n\nplot(meituan[, \"3690.HK.Adjusted\"],\n  subset = \"2022-01-01/2022-12-31\", main = \"调整的股价\"\n)\n\n\n\n\n\n\n图 26.4: 美团 2021 年的股价走势\n\n\n\n\n元旦节三天不开市，所以假期没有数据。\n\n26.2.3 ggfortify\nggfortify (Tang, Horikoshi, 和 Li 2016) 支持快速地可视化 ts、timeSeries 、stl 等多种类型的时序数据， ggplot2 做数据探索会有一些帮助。\n\nlibrary(ggfortify)\nautoplot(meituan[, \"3690.HK.Adjusted\"], ts.geom = \"line\") +\n  scale_x_date(\n    date_breaks = \"1 year\",\n    date_minor_breaks = \"6 months\",\n    date_labels = \"%b\\n%Y\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n图 26.5: 美团股价走势\n\n\n\n\n\n26.2.4 dygraphs\ndygraphs 包专门绘制交互式时间序列图形，它封装了时序数据可视化库 dygraphs ，更多情况见 https://dygraphs.com/。下面以美团股价为例，展示时间窗口筛选、坐标轴名称、刻度标签、注释、事件标注、缩放等功能。\n\nlibrary(dygraphs)\n# 缩放\ndyUnzoom &lt;- function(dygraph) {\n  dyPlugin(\n    dygraph = dygraph,\n    name = \"Unzoom\",\n    path = system.file(\"plugins/unzoom.js\", package = \"dygraphs\")\n  )\n}\n\n# 年月\ngetYearMonth &lt;- '\n  function(d) {\n    var monthNames = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\",\"07\", \"08\", \"09\", \"10\", \"11\", \"12\"];\n    date = new Date(d);\n    return date.getFullYear() + \"-\" + monthNames[date.getMonth()]; \n  }'\n\n# 绘图\ndygraph(meituan[, \"3690.HK.Adjusted\"], main = \"美团股价走势\") |&gt;\n  dyRangeSelector(dateWindow = c(\"2023-01-01\", \"2023-11-24\")) |&gt;\n  dyAxis(name = \"x\", axisLabelFormatter = getYearMonth) |&gt;\n  dyAxis(\"y\", valueRange = c(0, 500), label = \"美团股价\") |&gt;\n  dyEvent(\"2020-01-23\", \"武汉封城\", labelLoc = \"bottom\") |&gt;\n  dyShading(from = \"2020-01-23\", to = \"2020-04-08\", color = \"#FFE6E6\") |&gt;\n  dyAnnotation(\"2020-01-23\", text = \"武汉封城\", tooltip = \"武汉封城\", width = 60) |&gt;\n  dyAnnotation(\"2020-04-08\", text = \"武汉解封\", tooltip = \"武汉解封\", width = 60) |&gt;\n  dyHighlight(highlightSeriesOpts = list(strokeWidth = 2)) |&gt;\n  dySeries(label = \"调整股价\") |&gt;\n  dyLegend(show = \"follow\", hideOnMouseOut = FALSE) |&gt;\n  dyOptions(fillGraph = TRUE, drawGrid = FALSE, gridLineColor = \"lightblue\") |&gt;\n  dyUnzoom()\n\n\n\n\n\n\n图 26.6: 美团股价变化趋势\n\n\n\n上图默认展示 YTD 数据，在一个动态的时间窗口内显示数据，假如今天是 2023-07-15，则展示 2023-01-01 至 2023-07-15 的股价数据。在函数 dyRangeSelector() 中设定时间窗口参数 dateWindow，实现数据范围的筛选。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#平稳性诊断",
    "href": "analyze-time-series-data.html#平稳性诊断",
    "title": "26  时序分析",
    "section": "\n26.3 平稳性诊断",
    "text": "26.3 平稳性诊断\n\n26.3.1 自相关图\n\nautoplot(acf(AirPassengers, plot = FALSE)) +\n  theme_classic()\n\n\n\n\n\n\n图 26.7: 乘客数量自相关图\n\n\n\n\n\n26.3.2 偏自相关图\n\nautoplot(pacf(AirPassengers, plot = FALSE)) +\n  theme_classic()\n\n\n\n\n\n\n图 26.8: 乘客数量偏自相关图\n\n\n\n\n\n26.3.3 延迟算子\n\n# 原始序列\nAirPassengers\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\n# 延迟 1 期\nlag(AirPassengers, k = 1)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1948                                             112\n1949 118 132 129 121 135 148 148 136 119 104 118 115\n1950 126 141 135 125 149 170 170 158 133 114 140 145\n1951 150 178 163 172 178 199 199 184 162 146 166 171\n1952 180 193 181 183 218 230 242 209 191 172 194 196\n1953 196 236 235 229 243 264 272 237 211 180 201 204\n1954 188 235 227 234 264 302 293 259 229 203 229 242\n1955 233 267 269 270 315 364 347 312 274 237 278 284\n1956 277 317 313 318 374 413 405 355 306 271 306 315\n1957 301 356 348 355 422 465 467 404 347 305 336 340\n1958 318 362 348 363 435 491 505 404 359 310 337 360\n1959 342 406 396 420 472 548 559 463 407 362 405 417\n1960 391 419 461 472 535 622 606 508 461 390 432    \n\n\n\n26.3.4 差分算子\n函数 diff() 实现差分算子，默认参数 lag = 1 ，differences = 1 表示延迟期数为 1 的一阶差分。\n\n# 延迟 1 期 1 阶差分\ndiff(AirPassengers, lag = 1, differences = 1)\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n1949         6   14   -3   -8   14   13    0  -12  -17  -15   14\n1950   -3   11   15   -6  -10   24   21    0  -12  -25  -19   26\n1951    5    5   28  -15    9    6   21    0  -15  -22  -16   20\n1952    5    9   13  -12    2   35   12   12  -33  -18  -19   22\n1953    2    0   40   -1   -6   14   21    8  -35  -26  -31   21\n1954    3  -16   47   -8    7   30   38   -9  -34  -30  -26   26\n1955   13   -9   34    2    1   45   49  -17  -35  -38  -37   41\n1956    6   -7   40   -4    5   56   39   -8  -50  -49  -35   35\n1957    9  -14   55   -8    7   67   43    2  -63  -57  -42   31\n1958    4  -22   44  -14   15   72   56   14 -101  -45  -49   27\n1959   23  -18   64  -10   24   52   76   11  -96  -56  -45   43\n1960   12  -26   28   42   11   63   87  -16  -98  -47  -71   42\n\n\n\n26.3.5 单位根检验\n\n26.3.6 格兰杰因果检验\n1969 年 Clive Granger 提出格兰杰因果检验，R 语言中 lmtest 包的函数 grangertest() 可以检验序列中变量之间的时间落差的相关性。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-exponential-smoothing",
    "href": "analyze-time-series-data.html#sec-exponential-smoothing",
    "title": "26  时序分析",
    "section": "\n26.4 指数平滑模型",
    "text": "26.4 指数平滑模型\n\n26.4.1 指数平滑\n首先来回答何为指数平滑？用历史数据的线性组合预测下一个时期的值，线性组合的权重随距离变远而按指数衰减。不妨设观测序列数据为 \\(\\{x_i\\}\\) ，预测序列数据为 \\(\\{y_i\\}\\)，用数学公式表达，如下：\n\\[\ny_h(1) = wx_h + w^2x_{h-1} + \\cdots = \\sum_{j=1}^{\\infty} w^j x_{h+1-j}\n\\]\n其中，权重 \\(0 &lt; w &lt; 1\\) ，权重越小表示距离远的历史数据对当前预测的贡献越小。线性组合的权重之和等于 1，所以\n\\[\n\\sum_{j=1}^{\\infty} w^j = \\frac{w}{1-w}\n\\]\n则第 \\(j\\) 个权重应为\n\\[\n\\frac{w^j}{\\frac{w}{1-w}} = (1-w)w^{j-1},j=1,2,\\ldots\n\\]\n则根据历史的 \\(h\\) 期数据预测未来的 1 期数据 \\(y_h(1)\\) 如下：\n\\[\ny_h(1) = (1-w)(x_h + wx_{h-1} + w^2x_{h-2} + \\cdots) = (1-w)\\sum_{j=0}^{\\infty}w^j x_{h-j}\n\\]\n以上就是指数平滑（exponential smoothing），在早期应用中，权重 \\(w\\) 的选取主要依靠经验。适用于没有明显趋势性、季节性、周期性的时间序列数据。\n\n26.4.2 函数 filter()\n\n函数 filter() 实现一元时间序列的线性过滤，或者对多元时间序列的单个序列分别做线性变换，它只是根据既定的平滑模型变换数据，没有拟合数据。函数 filter() 实现递归过滤和卷积过滤两种数据变换方式，分别对应自回归和移动平均两种时间序列平滑模型。\n\n递归过滤（自回归）\n\n\\[\ny_{i} = x_{i} + f_1 y_{i-1} +\\cdots+ f_p y_{i-p}\n\\tag{26.1}\\]\n\n卷积过滤（移动平均）\n\n\\[\ny_{i} = f_1 x_{i+o} + \\cdots + f_p x_{i+o-(p-1)}\n\\tag{26.2}\\]\n其中，\\(p\\) 代表模型的阶数， \\(o\\) 代表漂移项，O 表示英文单词 offset 的首字母。下面举个具体的例子来说明函数 filter() 的作用，设输入序列 \\(\\{x_i\\}\\) 是从 1 至 10 的整数。首先考虑自回归的情况，代码如下：\n\nx &lt;- 1:10\n# 自回归\nfilter(x, filter = c(2 / 3, 1 / 6, 1 / 6), method = \"recursive\")\n\nTime Series:\nStart = 1 \nEnd = 10 \nFrequency = 1 \n [1]  1.000000  2.666667  4.944444  7.907407 11.540123 15.835391 20.798182\n [8] 26.428041 32.724289 39.687230\n\n\n参数 x 指定输入的时间序列 \\(\\{x_i\\}\\)，参数 method 指定平滑的方法，method = \"recursive\" 表示使用自回归方法，参数 filter 表示自回归的系数，系数向量的长度代表模型 方程式 26.1 中的 \\(p\\) ，filter = c(2 / 3, 1 / 6, 1 / 6) 对应的模型如下：\n\\[\n\\begin{aligned}\ny_1 &= x_1 \\\\\ny_2 &= x_2 + \\frac{2}{3} y_1 \\\\\ny_3 &= x_3 + \\frac{2}{3} y_2 + \\frac{1}{6} y_1 \\\\\ny_i &= x_i + \\frac{2}{3} y_{i-1} + \\frac{1}{6} y_{i - 2} + \\frac{1}{6} y_{i - 3}, \\quad i \\geq 4 \\\\\n\\end{aligned}\n\\]\n其中，序列 \\(\\{y_i\\}\\) 表示函数 filter() 的输出结果，由上述方程不难看出自回归模型的递归的特点。为了理解自回归和递归的过程，下面依次计算 \\(y_1\\) 至 \\(y_4\\) 。\n\n# y1\n1\n\n[1] 1\n\n# y2\n2 + 2/3 * 1\n\n[1] 2.666667\n\n# y3\n3 + 2/3 * (2 + 2/3 * 1) + 1/6 * 1\n\n[1] 4.944444\n\n# y4\n4 + 2/3 * (3 + 2/3 * (2 + 2/3 * 1) + 1/6 * 1) + 1/6 *(2 + 2/3 * 1) + 1/6 * 1\n\n[1] 7.907407\n\n\n接下来，考虑移动平均的情况，代码如下：\n\n# 移动平均\nfilter(x, filter = c(2 / 3, 1 / 6, 1 / 6), method = \"convolution\", sides = 1)\n\nTime Series:\nStart = 1 \nEnd = 10 \nFrequency = 1 \n [1]  NA  NA 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5\n\n\n参数 method = \"convolution\" 表示使用移动平均。参数 sides 仅适用于卷积过滤，sides = 1 表示系数都是作用于过去的值。为了对比自回归和移动平均，不妨设移动平均的系数同自回归的系数，则移动平均模型如下：\n\\[\n\\begin{aligned}\ny_1 &~~ \\text{不存在}\\\\\ny_2 &~~ \\text{不存在}\\\\\ny_3 &= \\frac{2}{3} x_{3} + \\frac{1}{6} x_2 + \\frac{1}{6} x_1\\\\\ny_i &= \\frac{2}{3} x_{i} + \\frac{1}{6} x_{i - 1} + \\frac{1}{6} x_{i - 2}, \\quad i \\geq 3\n\\end{aligned}\n\\]\n比照模型 方程式 26.2 ，漂移项参数 \\(o\\) 为 0，也就是没有漂移，移动平均作用于过去的 3 期数据，也就是 \\(p = 3\\) 。因输出序列 \\(\\{y_i\\}\\) 中 \\(y_1,y_2\\) 不存在，下面仅计算 \\(y_3,y_4\\) 。\n\n# y3\n2/3 * 3 + 1/6 * 2 + 1/6 * 1\n\n[1] 2.5\n\n# y4\n2/3 * 4 + 1/6 * 3 + 1/6 * 2\n\n[1] 3.5\n\n\nTTR 包提供许多移动平均的计算函数，比如 SMA() ，下面计算过去 3 个观察值的算术平均。\n\nlibrary(TTR)\nSMA(x, n = 3)\n\n [1] NA NA  2  3  4  5  6  7  8  9\n\n\n\n26.4.3 简单指数平滑\n当时间序列不含趋势和季节性成分的时候，可以用简单指数平滑模型来拟合和预测。简单指数平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= b_{t-1} \\\\\ns_{t} &= s_{t-p}\n\\end{aligned}\n\\]\n其中，周期 \\(p\\)\n\nair_passengers_exp &lt;- HoltWinters(AirPassengers, gamma = FALSE, beta = FALSE)\nair_passengers_exp\n\nHolt-Winters exponential smoothing without trend and without seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, beta = FALSE, gamma = FALSE)\n\nSmoothing parameters:\n alpha: 0.9999339\n beta : FALSE\n gamma: FALSE\n\nCoefficients:\n      [,1]\na 431.9972\n\n\n预测的残差平方和 SSE sum-of-squared-errors\n\nair_passengers_exp$SSE\n\n[1] 162510.6\n\n\n\n# plot(air_passengers_exp)\nautoplot(air_passengers_exp) +\n  theme_classic()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 26.9: 简单指数平滑模型\n\n\n\n\n向前预测 5 期\n\nair_passengers_pred &lt;- predict(air_passengers_exp, n.ahead = 10, prediction.interval = TRUE)\n\n预测值及其预测区间\n\nplot(air_passengers_exp, air_passengers_pred)\n\n\n\n\n\n\n图 26.10: 简单指数平滑模型预测\n\n\n\n\n\n26.4.4 Holt 指数平滑\n当时间序列不含季节性成分，可以用 Holt 指数平滑模型拟合和预测 (Holt 2004) 。\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= s_{t-p}\n\\end{aligned}\n\\]\n\nair_passengers_holt &lt;- HoltWinters(AirPassengers, gamma = FALSE)\nair_passengers_holt\n\nHolt-Winters exponential smoothing with trend and without seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, gamma = FALSE)\n\nSmoothing parameters:\n alpha: 1\n beta : 0.003218516\n gamma: FALSE\n\nCoefficients:\n        [,1]\na 432.000000\nb   4.597605\n\n\n可知，\\(\\alpha = 1,\\beta = 0.0032\\)\n\nplot(air_passengers_holt)\n\n\n\n\n\n\n图 26.11: holt 指数平滑模型\n\n\n\n\n\n26.4.5 Holt-Winters 指数平滑\n时间序列同时含有趋势成分、季节性成分、随机成分，可以用 Holt-Winters 平滑模型来拟合和预测。根据趋势和季节性的关系，Holt-Winters 平滑模型分为可加 Holt-Winters 平滑和可乘 Holt-Winters 平滑。R 提供函数 HoltWinters() 拟合 Holt-Winters 平滑模型(Holt 2004; Winters 1960)。\n可加 Holt-Winters 平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= \\gamma (y_{t} - a_{t}) + (1-\\gamma) s_{t-p}\n\\end{aligned}\n\\]\n可乘 Holt-Winters 平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= (a_{t} + h \\times b_{t}) \\times s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} / s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= \\gamma (y_{t} / a_{t}) + (1-\\gamma) s_{t-p}\n\\end{aligned}\n\\]\n其中 \\(\\alpha, \\beta, \\gamma\\) 是参数，\\(p\\) 为周期长度，\\(a_{t}, b_{t}, s_{t}\\) 分别代表水平、趋势和季节性成分。\n\nair_passengers_add &lt;- HoltWinters(AirPassengers, seasonal = \"additive\")\nair_passengers_add\n\nHolt-Winters exponential smoothing with trend and additive seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, seasonal = \"additive\")\n\nSmoothing parameters:\n alpha: 0.2479595\n beta : 0.03453373\n gamma: 1\n\nCoefficients:\n          [,1]\na   477.827781\nb     3.127627\ns1  -27.457685\ns2  -54.692464\ns3  -20.174608\ns4   12.919120\ns5   18.873607\ns6   75.294426\ns7  152.888368\ns8  134.613464\ns9   33.778349\ns10 -18.379060\ns11 -87.772408\ns12 -45.827781\n\n\n可知，\\(\\alpha = 0.248,\\beta = 0.0345,\\gamma = 1\\)\n\nautoplot(air_passengers_add) +\n  theme_classic()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 26.12: 可加 Holt-Winters 平滑模型拟合\n\n\n\n\n\nair_passengers_mult &lt;- HoltWinters(AirPassengers, seasonal = \"mult\")\n\n\nautoplot(air_passengers_mult) +\n  theme_classic()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 26.13: 可乘 Holt-Winters 平滑模型拟合\n\n\n\n\n做一个 Shiny 应用展示参数 \\(\\alpha, \\beta, \\gamma\\) 对 Holt-Winters 平滑预测的影响。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-time-series-decomposition",
    "href": "analyze-time-series-data.html#sec-time-series-decomposition",
    "title": "26  时序分析",
    "section": "\n26.5 时间序列分解",
    "text": "26.5 时间序列分解\n\n可加模型\n\n\\[\ny_t = T_t + S_t + e_t\n\\]\n\n可乘模型\n\n\\[\ny_t = T_t \\times S_t \\times e_t\n\\]\n对时间序列 \\(\\{y_t\\}\\) 分解，趋势性成分 \\(T_t\\)、季节性成分 \\(S_t\\)、剩余成分 \\(e_t\\)\n\n26.5.1 函数 decompose()\n\n函数 decompose() 分解\n\nair_decomp_add &lt;- decompose(x = AirPassengers, type = \"additive\")\n\n函数返回一个列表，包含 6 个元素，分别是 x 原始序列，seasonal 季节性成分，figure 估计的季节图，trend 趋势成分，random 剩余成分，type 分解方法。\n\n# plot(air_decomp_add)\nautoplot(air_decomp_add) +\n  theme_classic()\n\nWarning: Removed 24 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 26.14: 变化趋势的分解\n\n\n\n\n去掉季节性部分\n\nAirPassengers_adjusted &lt;- AirPassengers - air_decomp_add$seasonal\nplot(AirPassengers_adjusted)\n\n\n\n\n\n\n图 26.15: 季节性调整\n\n\n\n\n\n26.5.2 函数 stl()\n\n函数 stl() 将时间序列分解为趋势性成分、季节性成分（周期性）、剩余成分。\n\nair_stl &lt;- stl(x = AirPassengers, s.window = 12)\n\n\nautoplot(air_stl) +\n  theme_classic()\n\n\n\n\n\n\n图 26.16: 变化趋势的分解\n\n\n\n\n剩余成分不是平稳序列，是异方差的。\nxts 包的 periodicity() 函数可以检测时间序列数据的周期，但时序数据对象最好是在 xts 框架内。\n\nxts::periodicity(AirPassengers)\n\nMonthly periodicity from Jan 1949 to Dec 1960",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-classic-time-series-models",
    "href": "analyze-time-series-data.html#sec-classic-time-series-models",
    "title": "26  时序分析",
    "section": "\n26.6 经典时间序列模型",
    "text": "26.6 经典时间序列模型\n\n26.6.1 自回归模型\n函数 ar() 拟合 AR 模型\n\nar(AirPassengers, order.max = 3)\n\n\nCall:\nar(x = AirPassengers, order.max = 3)\n\nCoefficients:\n      1        2  \n 1.1656  -0.2294  \n\nOrder selected 2  sigma^2 estimated as  1399\n\n\n\n26.6.2 移动平均模型\n将自回归的阶设为 0，函数 arima() 也可以用来拟合 MA 模型。\n\narima(AirPassengers, order = c(0, 1, 3))\n\n\nCall:\narima(x = AirPassengers, order = c(0, 1, 3))\n\nCoefficients:\n         ma1     ma2      ma3\n      0.1309  -0.359  -0.3599\ns.e.  0.0741   0.090   0.0907\n\nsigma^2 estimated as 949.5:  log likelihood = -693.45,  aic = 1394.91\n\n\n\n26.6.3 自回归移动平均模型\n函数 arima() 拟合 ARIMA 模型\n\narima(AirPassengers, order = c(1, 1, 3))\n\n\nCall:\narima(x = AirPassengers, order = c(1, 1, 3))\n\nCoefficients:\n         ar1      ma1      ma2      ma3\n      0.5227  -0.2906  -0.3884  -0.1219\ns.e.  0.1291   0.1284   0.1445   0.1322\n\nsigma^2 estimated as 886:  log likelihood = -688.45,  aic = 1386.89\n\n\nforecast 包提供函数 auto.arima() 自动选择合适的自回归、差分和移动平均的阶来拟合数据。\nforecast::auto.arima(AirPassengers)\nSeries: AirPassengers \nARIMA(2,1,1)(0,1,0)[12] \n\nCoefficients:\n         ar1     ar2      ma1\n      0.5960  0.2143  -0.9819\ns.e.  0.0888  0.0880   0.0292\n\nsigma^2 = 132.3:  log likelihood = -504.92\nAIC=1017.85   AICc=1018.17   BIC=1029.35",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-time-series-summary",
    "href": "analyze-time-series-data.html#sec-time-series-summary",
    "title": "26  时序分析",
    "section": "\n26.7 总结",
    "text": "26.7 总结\n方法没有好坏，只有适合与否。Holt-Winter 适合预警任务，算法简单，可以及时出预测结果，仅需要一步预测，不需要给出多步预测，要求快，以便迅速作出反应。Prophet 实现的贝叶斯结构可加模型适合短期预测任务，只要在可容许的时间范围内出结果即可，可以迅速出结果当然更好，需要给出多步预测结果，且结果需要强解释性，以便提前做一些商家供给、平台资源的分配。商分模型常常需要比较强的可解释性，算法策略模型重在预测精准度，对可解释性要求不高。\n在时间序列数据的可视化方面，除了 Base R 提供的绘图方法外，静态的时序图 lattice 和 ggplot2 都不错，而交互式图形推荐使用 plotly 和 dygraphs。\nPortfolioAnalytics 包做投资组合优化，均值-方差，收益和风险权衡。 Rmetrics 提供系列时间序列数据分析和建模的 R 包，包括投资组合优化 fPortfolio、多元分析 fMultivar、自回归条件异方差模型 fGarch、二元相依结构的 Copulae 分析 fCopulae 、市场和基础统计 fBasics 。\nfable 一元到多元时间序列预测问题，提供 ETS、ARIMA、TSLM 等模型，并有书籍时间序列预测原则。值得一提， forecast 包开发者 Rob J Hyndman 称已不再开发新的功能，推荐大家使用 fable 包。feasts 包辅助特征抽取、序列分解、汇总统计和绘制图形等， 插件包 fable.prophet 接入 Prophet 的预测能力。timetk 时间序列数据处理、分析、预测和可视化工具箱，提供一致的操作方式，试图形成完成的解决方案。The Rmetrics Association 开发了一系列 R 包专门处理金融时间序列数据，比如 fGarch 包提供条件自回归异方差模型。\n从时间序列中寻找规律，这样才是真的数据建模，从数据到模型，而不是相反 Finding Patterns in Time Series，识别金融时间序列的模式和统计规律。\n\n\n\n\nHolt, Charles C. 2004. 《Forecasting seasonals and trends by exponentially weighted moving averages》. International Journal of Forecasting 20 (1): 5–10. https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nRyan, Jeffrey A., 和 Joshua M. Ulrich. 2022. quantmod: Quantitative Financial Modelling Framework. https://CRAN.R-project.org/package=quantmod.\n\n\nTang, Yuan, Masaaki Horikoshi, 和 Wenxuan Li. 2016. 《ggfortify: Unified Interface to Visualize Statistical Result of Popular R Packages》. The R Journal 8 (2): 474–85. https://doi.org/10.32614/RJ-2016-060.\n\n\nWinters, Peter R. 1960. 《Forecasting sales by exponentially weighted moving averages》. Management Science 6 (3): 324–42. https://doi.org/10.1287/mnsc.6.3.324.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>时序分析</span>"
    ]
  },
  {
    "objectID": "analyze-point-pattern.html",
    "href": "analyze-point-pattern.html",
    "title": "27  空间点模式分析",
    "section": "",
    "text": "27.1 数据操作",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>空间点模式分析</span>"
    ]
  },
  {
    "objectID": "analyze-point-pattern.html#数据操作",
    "href": "analyze-point-pattern.html#数据操作",
    "title": "27  空间点模式分析",
    "section": "",
    "text": "27.1.1 类型转化\n先对斐济地震数据 quakes 数据集做一些数据类型转化，从 data.frame 转 Simple feature 对象。\n\nlibrary(sf)\nquakes_sf &lt;- st_as_sf(quakes, coords = c(\"long\", \"lat\"), crs = st_crs(4326))\nquakes_sf\n\n#&gt; Simple feature collection with 1000 features and 3 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 165.67 ymin: -38.59 xmax: 188.13 ymax: -10.72\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    depth mag stations              geometry\n#&gt; 1    562 4.8       41 POINT (181.62 -20.42)\n#&gt; 2    650 4.2       15 POINT (181.03 -20.62)\n#&gt; 3     42 5.4       43     POINT (184.1 -26)\n#&gt; 4    626 4.1       19 POINT (181.66 -17.97)\n#&gt; 5    649 4.0       11 POINT (181.96 -20.42)\n#&gt; 6    195 4.0       12 POINT (184.31 -19.68)\n#&gt; 7     82 4.8       43   POINT (166.1 -11.7)\n#&gt; 8    194 4.4       15 POINT (181.93 -28.11)\n#&gt; 9    211 4.7       35 POINT (181.74 -28.74)\n#&gt; 10   622 4.3       19 POINT (179.59 -17.47)\n\n\n\n27.1.2 坐标转化\n如果知道两个投影坐标系的 EPSG 代码，输入坐标就可以完成转化。如将坐标系 EPSG:4326 下的坐标 \\((2,49)\\) 投影到另一个坐标系 EPSG:3857 。\n\nst_transform(\n  x = st_sfc(st_point(x = c(2, 49)), crs = 4326), crs = 3857\n)\n\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 222639 ymin: 6274861 xmax: 222639 ymax: 6274861\n#&gt; Projected CRS: WGS 84 / Pseudo-Mercator\n\n\n#&gt; POINT (222639 6274861)\n\n\n\n\n名称\nEPSG\n赤道半径\n半轴\n发明者\n\n\n\nGRS80\n3857\na=6378137.0\nrf=298.257222101\nGRS 1980(IUGG, 1980)\n\n\nWGS84\n4326\na=6378137.0\nrf=298.257223563\nWGS 84\n\n\n\n函数 st_crs() 查看坐标参考系的信息，比如 EPSG 代码为 4326 对应的坐标参考系统信息。我们也可以通过网站查询 EPSG 代码对应的坐标参考系统的详细介绍。\n\nst_crs(\"EPSG:4326\")\n\n#&gt; Coordinate Reference System:\n#&gt;   User input: EPSG:4326 \n#&gt;   wkt:\n#&gt; GEOGCRS[\"WGS 84\",\n#&gt;     ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n#&gt;         MEMBER[\"World Geodetic System 1984 (Transit)\"],\n#&gt;         MEMBER[\"World Geodetic System 1984 (G730)\"],\n#&gt;         MEMBER[\"World Geodetic System 1984 (G873)\"],\n#&gt;         MEMBER[\"World Geodetic System 1984 (G1150)\"],\n#&gt;         MEMBER[\"World Geodetic System 1984 (G1674)\"],\n#&gt;         MEMBER[\"World Geodetic System 1984 (G1762)\"],\n#&gt;         MEMBER[\"World Geodetic System 1984 (G2139)\"],\n#&gt;         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n#&gt;             LENGTHUNIT[\"metre\",1]],\n#&gt;         ENSEMBLEACCURACY[2.0]],\n#&gt;     PRIMEM[\"Greenwich\",0,\n#&gt;         ANGLEUNIT[\"degree\",0.0174532925199433]],\n#&gt;     CS[ellipsoidal,2],\n#&gt;         AXIS[\"geodetic latitude (Lat)\",north,\n#&gt;             ORDER[1],\n#&gt;             ANGLEUNIT[\"degree\",0.0174532925199433]],\n#&gt;         AXIS[\"geodetic longitude (Lon)\",east,\n#&gt;             ORDER[2],\n#&gt;             ANGLEUNIT[\"degree\",0.0174532925199433]],\n#&gt;     USAGE[\n#&gt;         SCOPE[\"Horizontal component of 3D system.\"],\n#&gt;         AREA[\"World.\"],\n#&gt;         BBOX[-90,-180,90,180]],\n#&gt;     ID[\"EPSG\",4326]]\n\n\n地球看作一个椭球体 ELLIPSOID，长半轴 6378137 米，短半轴 298.257223563 米，椭圆形的两个轴，纬度单位 0.0174532925199433， 经度单位 0.0174532925199433 。\n地球是一个不规则的球体，不同的坐标参考系对地球的抽象简化不同，会体现在坐标原点、长半轴、短半轴等属性上。为了方便在平面上展示地理信息，需要将地球表面投影到平面上，墨卡托投影是其中非常重要的一种投影方式，墨卡托投影的详细介绍见 PROJ 网站 。WGS 84 / Pseudo-Mercator 投影主要用于网页上的地理可视化，UTM 是 Universal Transverse Mercator 的缩写。360 度对应全球 60 个时区，每个时区横跨 6 经度。\n\nst_transform(\n  x = st_sfc(st_point(x = c(2, 49)), crs = 4326),\n  crs = st_crs(\"+proj=utm +zone=32 +ellps=GRS80\")\n)\n\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -11818.95 ymin: 5451107 xmax: -11818.95 ymax: 5451107\n#&gt; Projected CRS: +proj=utm +zone=32 +ellps=GRS80\n\n\n#&gt; POINT (-11818.95 5451107)\n\n\n快速简单绘图，可采用图层 geom_sf()，它相当于统计图层 stat_sf() 和坐标映射图层 coord_sf() 的叠加，geom_sf() 支持点、线和多边形等数据数据对象，可以混合叠加。 coord_sf() 有几个重要的参数：\n\ncrs：在绘图前将各个 geom_sf() 图层中的数据映射到该坐标参考系。\ndefault_crs：将非 sf 图层（没有携带 CRS 信息）的数据映射到该坐标参考系，默认使用 crs 参数的值，常用设置 default_crs = sf::st_crs(4326) 将非 sf 图层中的横纵坐标转化为经纬度，采用 World Geodetic System 1984 (WGS84)。\ndatum：经纬网线的坐标参考系，默认值 sf::st_crs(4326)。\n\n下图的右子图将 quakes_sf 数据集投影到坐标参考系统EPSG:3460。\nlibrary(ggplot2)\nggplot() +\n  geom_sf(data = quakes_sf, aes(color = mag))\nggplot() +\n  geom_sf(data = quakes_sf, aes(color = mag)) +\n  coord_sf(crs = 3460)\n\n\n\n\n\n\n\n\n\n(a) 坐标参考系 4326（默认）\n\n\n\n\n\n\n\n\n\n(b) 坐标参考系 3460\n\n\n\n\n\n\n图 27.1: 斐济地震的空间分布\n\n\n数据集 quakes_sf 已经准备了坐标参考系统，此时，coord_sf() 就会采用数据集相应的坐标参考系统，即 sf::st_crs(4326)。上图的左子图相当于：\n\nggplot() +\n  geom_sf(data = quakes_sf, aes(color = mag)) +\n  coord_sf(\n    crs = 4326, datum = sf::st_crs(4326),\n    default_crs = sf::st_crs(4326)\n  )\n\n\n27.1.3 凸包操作\n\nquakes_sf &lt;- st_transform(quakes_sf, crs = 3460)\n# 组合 POINT 构造 POLYGON\nquakes_sfp &lt;- st_cast(st_combine(st_geometry(quakes_sf)), \"POLYGON\")\n# 构造 POLYGON 的凸包\nquakes_sfp_hull &lt;- st_convex_hull(st_geometry(quakes_sfp))\n\n# 绘制点及其包络\nplot(st_geometry(quakes_sf))\n# 添加凸包曲线\nplot(quakes_sfp_hull, add = TRUE)\n\nggplot() +\n  geom_sf(data = quakes_sf) +\n  geom_sf(data = quakes_sfp_hull, fill = NA) +\n  coord_sf(crs = 3460, xlim = c(569061, 3008322), ylim = c(1603260, 4665206))\n\n\n\n\n\n\n\n\n\n(a) 凸包（base R）\n\n\n\n\n\n\n\n\n\n(b) 凸包（ggplot2）\n\n\n\n\n\n\n图 27.2: 凸包",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>空间点模式分析</span>"
    ]
  },
  {
    "objectID": "analyze-point-pattern.html#数据探索",
    "href": "analyze-point-pattern.html#数据探索",
    "title": "27  空间点模式分析",
    "section": "\n27.2 数据探索",
    "text": "27.2 数据探索\n\n27.2.1 核密度估计\n给定边界内的核密度估计与绘制热力图\n\n# spatial point pattern ppp 类型\nquakes_ppp &lt;- spatstat.geom::as.ppp(quakes_sf)\n\n#&gt; Warning in as.ppp.sf(quakes_sf): only first attribute column is used for marks\n\n# 限制散点在给定的窗口边界内平滑\nspatstat.geom::Window(quakes_ppp) &lt;- spatstat.geom::as.owin(quakes_sfp_hull)\n\n#&gt; Warning: point-in-polygon test had difficulty with 1 point (total score not 0\n#&gt; or 1)\n\n# 密度估计\ndensity_spatstat &lt;- spatstat.explore::density.ppp(quakes_ppp, dimyx = 256)\n# 转化为 stars 对象 栅格数据\ndensity_stars &lt;- stars::st_as_stars(density_spatstat)\n# 设置坐标参考系\ndensity_sf &lt;- st_set_crs(st_as_sf(density_stars), 3460)\n\n\n27.2.2 绘制热力图\nggplot() +\n  geom_sf(data = density_sf, aes(fill = v), col = NA) +\n  scale_fill_viridis_c() +\n  geom_sf(data = st_boundary(quakes_sfp_hull))\n\nggplot() +\n  geom_sf(data = density_sf, aes(fill = v), col = NA) +\n  scale_fill_viridis_c() +\n  geom_sf(data = st_boundary(quakes_sfp_hull)) +\n  geom_sf(data = quakes_sf, size = 1, col = \"black\")\n\n\n\n\n\n\n\n\n\n(a) 核密度估计\n\n\n\n\n\n\n\n\n\n(b) 核密度估计（原始数据）\n\n\n\n\n\n\n图 27.3: 热力图",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>空间点模式分析</span>"
    ]
  },
  {
    "objectID": "analyze-spatial-data.html",
    "href": "analyze-spatial-data.html",
    "title": "28  空间点参考数据分析",
    "section": "",
    "text": "28.1 数据说明\n在第二次世界大战的吉尔伯特及马绍尔群岛战斗中，美国占领了马绍尔群岛。战后，美国在该群岛的比基尼环礁中陆续进行了许多氢弹核试验，对该群岛造成无法弥补的环境损害。位于南太平洋的朗格拉普环礁是马绍尔群岛的一部分，其中，朗格拉普岛是朗格拉普环礁的主岛，修建有机场，在太平洋战争中是重要的军事基地。朗格拉普岛距离核爆炸的位置较近，因而被放射性尘埃笼罩了，受到严重的核辐射影响，从度假胜地变成人间炼狱，居民出现上吐下泻、皮肤灼烧、脱发等症状。即便是 1985 年以后，那里仍然无人居住，居民担心核辐射对身体健康的影响。又几十年后，一批科学家来到该岛研究生态恢复情况，评估当地居民重返家园的可行性。实际上，该岛目前仍然不适合人类居住，只有经批准的科学研究人员才能登岛。\n代码# 从网站 https://gadm.org/ 下载国家各级行政区划数据\n# geodata 包返回 SpatVector 类型的数据对象\nmhl_map_gadm &lt;- geodata::gadm(country = \"MHL\", level = 1, path = \"data/\")\nlibrary(sf)\n# SpatVector 类型转为 sf 类型\nmhl_map_gadm &lt;- st_as_sf(mhl_map_gadm)\nlibrary(ggplot2)\n# 添加虚线框用来圈选朗格拉普岛\nrongelap_sfp &lt;- st_sfc(st_polygon(x = list(rbind(\n  c(166.82, 11.14),\n  c(166.82, 11.183),\n  c(166.92, 11.183),\n  c(166.92, 11.14),\n  c(166.82, 11.14)\n)), dim = \"XY\"), crs = 4326)\n# 文本标记\ntext_df &lt;- tibble::tribble(\n  ~x, ~y, ~text,\n  166.75, 11.35, \"朗格拉普环礁\",\n  166.97, 11.16, \"朗格拉普岛\"\n)\ntext_df &lt;- as.data.frame(text_df)\ntext_sf &lt;- st_as_sf(text_df, coords = c(\"x\", \"y\"), dim = \"XY\", crs = 4326)\n# 朗格拉普环礁\nggplot() +\n  geom_sf(data = mhl_map_gadm) +\n  geom_sf(data = rongelap_sfp, fill = NA, linewidth = 0.75, lty = 2) +\n  geom_sf_text(data = text_sf, aes(label = text), color = \"gray20\",\n               fun.geometry = sf::st_centroid) +\n  coord_sf(xlim = c(166.6, 167.1), ylim = c(11.14, 11.5)) +\n  theme_bw() +\n  labs(x = \"经度\", y = \"纬度\")\n\n\n\n\n\n\n图 28.1: 朗格拉普环礁和朗格拉普岛\nOle F. Christensen 和 Paulo J. Ribeiro Jr 将 rongelap 数据集存放在 geoRglm(Christensen 和 Ribeiro Jr. 2002) 包内，后来，geoRglm 不维护，已从 CRAN 移除了，笔者从他们主页下载了数据。数据集 rongelap 记录了 157 个测量点的伽马射线强度，即在时间间隔 time （秒）内放射的粒子数目 counts（个），测量点的横纵坐标分别为 cX （米）和 cY（米），下 表格 28.1 展示部分朗格拉普岛核辐射检测数据及海岸线坐标数据。\n坐标原点在岛的东北，下 图 28.2 (a) 右上角的位置。采样点的编号见下 图 28.2 (b)，基本上按照从下（南）到上（北），从左（西）到右（东）的顺序依次测量。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>空间点参考数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-spatial-data.html#sec-rongelap-data",
    "href": "analyze-spatial-data.html#sec-rongelap-data",
    "title": "28  空间点参考数据分析",
    "section": "",
    "text": "代码# 加载数据\nrongelap &lt;- readRDS(file = \"data/rongelap.rds\")\nrongelap_coastline &lt;- readRDS(file = \"data/rongelap_coastline.rds\")\n\nlibrary(knitr)\nknitr::kable(head(rongelap, 6),\n  col.names = c(\"cX 横坐标\", \"cY 纵坐标\", \"counts 数目\", \"time 时间\")\n)\n代码knitr::kable(head(rongelap_coastline, 6),\n  col.names = c(\"cX 横坐标\", \"cY 纵坐标\")\n)\n\n\n表格 28.1: 朗格拉普岛核辐射检测数据及海岸线坐标数据\n\n\n\n\n\n(a) 核辐射检测数据\n\n\n\ncX 横坐标\ncY 纵坐标\ncounts 数目\ntime 时间\n\n\n\n-6050\n-3270\n75\n300\n\n\n-6050\n-3165\n371\n300\n\n\n-5925\n-3320\n1931\n300\n\n\n-5925\n-3165\n4357\n300\n\n\n-5800\n-3350\n2114\n300\n\n\n-5800\n-3165\n2318\n300\n\n\n\n\n\n\n\n\n\n\n(b) 海岸线坐标数据\n\n\n\ncX 横坐标\ncY 纵坐标\n\n\n\n-5509.236\n-3577.438\n\n\n-5544.821\n-3582.250\n\n\n-5561.604\n-3576.926\n\n\n-5580.780\n-3574.535\n\n\n-5599.687\n-3564.288\n\n\n-5605.922\n-3560.910\n\n\n\n\n\n\n\n\n\n\n\n\n代码library(ggplot2)\nggplot() +\n  geom_point(data = rongelap, aes(x = cX, y = cY), size = 0.2) +\n  geom_path(data = rongelap_coastline, aes(x = cX, y = cY)) +\n  theme_bw() +\n  coord_fixed() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\")\n\nrongelap$dummy &lt;- rownames(rongelap)\nggplot(rongelap, aes(x = cX, y = cY)) +\n  geom_text(aes(label = dummy), size = 2) +\n  theme_bw() +\n  coord_fixed() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\")\n\n\n\n\n\n\n\n\n\n(a) 采样分布\n\n\n\n\n\n\n\n\n\n\n\n(b) 采样顺序\n\n\n\n\n\n\n图 28.2: 采样点在岛上的分布",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>空间点参考数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-spatial-data.html#sec-rongelap-exploration",
    "href": "analyze-spatial-data.html#sec-rongelap-exploration",
    "title": "28  空间点参考数据分析",
    "section": "\n28.2 数据探索",
    "text": "28.2 数据探索\n朗格拉普岛呈月牙形，有数千米长，但仅几百米宽，十分狭长。采样点在岛上的分布如 图 28.2 所示，主网格以约 200 米的间隔采样，在岛屿的东北和西南方各有两个密集采样区，每个网格采样区是 \\(5 \\times 5\\) 方式排列的，上下左右间隔均为 40 米。朗格拉普岛上各个检测站点的核辐射强度如 图 28.3 所示，越亮表示核辐射越强，四个检测区的采样阵列非常密集，通过局部放大展示了最左侧的一个检测区，它将作为后续模型比较的参照区域。\n\n代码p1 &lt;- ggplot() +\n  geom_path(data = rongelap_coastline, aes(x = cX, y = cY)) +\n  geom_point(data = rongelap, aes(x = cX, y = cY, color = counts / time), size = 0.2) +\n  scale_x_continuous(n.breaks = 7) +\n  scale_color_viridis_c(option = \"C\") +\n  geom_segment(\n    data = data.frame(x = -5560, xend = -5000, y = -3000, yend = -2300),\n    aes(x = x, y = y, xend = xend, yend = yend),\n    arrow = arrow(length = unit(0.03, \"npc\"))\n  ) +\n  theme_bw() +\n  coord_fixed() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", color = \"辐射强度\")\n\np2 &lt;- ggplot() +\n  geom_point(data = rongelap, aes(x = cX, y = cY, color = counts / time), \n             size = 1, show.legend = FALSE) +\n  scale_color_viridis_c(option = \"C\") +\n  coord_fixed(xlim = c(-5700, -5540), ylim = c(-3260, -3100)) +\n  theme_bw() +\n  labs(x = NULL, y = NULL)\n\np1\nprint(p2, vp = grid::viewport(x = .25, y = .66, width = .275, height = .45))\n\n\n\n\n\n\n图 28.3: 岛上各采样点的核辐射强度\n\n\n\n\nggplot2 包只能在二维平面上展示数据，对于空间数据，立体图形更加符合数据产生背景。如 图 28.4 所示，以三维图形展示朗格拉普岛上采样点的位置及检测到的辐射强度。lattice 包的函数 cloud() 可以绘制三维的散点图，将自定义的面板函数 panel.3dcoastline() 传递给参数 panel.3d.cloud 绘制岛屿海岸线。组合点和线两种绘图元素构造出射线，线的长短表示放射性的强弱，以射线表示粒子辐射现象更加贴切。\n\n代码library(lattice)\n# 参考 lattice 书籍的图 6.5 的绘图代码\npanel.3dcoastline &lt;- function(..., rot.mat, distance, xlim, ylim, zlim,\n                              xlim.scaled, ylim.scaled, zlim.scaled) {\n  scale.vals &lt;- function(x, original, scaled) {\n    scaled[1] + (x - original[1]) * diff(scaled) / diff(original)\n  }\n  scaled.map &lt;- rbind(\n    scale.vals(rongelap_coastline$cX, xlim, xlim.scaled),\n    scale.vals(rongelap_coastline$cY, ylim, ylim.scaled),\n    zlim.scaled[1]\n  )\n  m &lt;- ltransform3dto3d(scaled.map, rot.mat, distance)\n  panel.lines(m[1, ], m[2, ], col = \"black\")\n}\n\ncloud(counts / time ~ cX * cY,\n  data = rongelap, col = \"black\",\n  xlim = c(-6500, 100), ylim = c(-3800, 150),\n  scales = list(arrows = FALSE, col = \"black\"),\n  aspect = c(0.75, 0.5),\n  xlab = list(\"横坐标（米）\", rot = 20),\n  ylab = list(\"纵坐标（米）\", rot = -50),\n  zlab = list(\"辐射强度\", rot = 90),\n  type = c(\"p\", \"h\"), pch = 16, lwd = 0.5,\n  panel.3d.cloud = function(...) {\n    panel.3dcoastline(...) # 海岸线\n    panel.3dscatter(...)\n  },\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(\n    # 移除几条内框线\n    # box.3d = list(col = c(1, 1, NA, NA, 1, NA, 1, 1, 1)),\n    # 刻度标签字体大小\n    axis.text = list(cex = 0.8),\n    # 去掉外框线\n    axis.line = list(col = \"transparent\")\n  ),\n  # 设置三维图的观察方位\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 28.4: 岛上各采样点的辐射强度",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>空间点参考数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-spatial-data.html#sec-rongelap-modeling",
    "href": "analyze-spatial-data.html#sec-rongelap-modeling",
    "title": "28  空间点参考数据分析",
    "section": "\n28.3 数据建模",
    "text": "28.3 数据建模\n\n28.3.1 广义线性模型\n核辐射是由放射元素衰变产生的，通常用单位时间释放出来的粒子数目表示辐射强度，因此，建立如下泊松型广义线性模型来拟合核辐射强度。\n\\[\n\\begin{aligned}\n\\log(\\lambda_i) &= \\beta \\\\\ny_i & \\sim \\mathrm{Poisson}(t_i\\lambda_i)\n\\end{aligned}\n\\]\n其中，\\(\\lambda_i\\) 表示核辐射强度，\\(\\beta\\) 表示未知的截距，\\(y_i\\) 表示观测到的粒子数目，\\(t_i\\) 表示相应的观测时间，\\(i = 1,\\ldots, 157\\) 表示采样点的位置编号。R 软件内置的 stats 包有函数 glm() 可以拟合上述广义线性模型，代码如下。\n\nfit_rongelap_poisson &lt;- glm(counts ~ 1,\n  family = poisson(link = \"log\"), offset = log(time), data = rongelap\n)\nsummary(fit_rongelap_poisson)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = counts ~ 1, family = poisson(link = \"log\"), data = rongelap, \n#&gt;     offset = log(time))\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) 2.013954   0.001454    1385   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 61567  on 156  degrees of freedom\n#&gt; Residual deviance: 61567  on 156  degrees of freedom\n#&gt; AIC: 63089\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\n当 family = poisson(link = \"log\") 时，响应变量只能是正整数，所以不能放 counts / time。泊松广义线性模型是对辐射强度建模，辐射强度与位置 cX 和 cY 有关。当响应变量为放射出来的粒子数目 counts 时，为了表示辐射强度，需要设置参数 offset，表示与放射粒子数目对应的时间间隔 time。联系函数是对数函数，因此时间间隔需要取对数。\n从辐射强度的拟合残差的空间分布 图 28.5 不难看出，颜色深和颜色浅的点分别聚集在一起，且与周围点的颜色呈现层次变化，拟合残差存在明显的空间相关性。如果将位置变量 cX 和 cY 加入广义线性模型，也会达到统计意义上的显著。\n\nrongelap$poisson_residuals &lt;- residuals(fit_rongelap_poisson)\nggplot(rongelap, aes(x = cX, y = cY)) +\n  geom_point(aes(colour = poisson_residuals / time), size = 0.2) +\n  scale_color_viridis_c(option = \"C\") +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", color = \"残差\")\n\n\n\n\n\n\n图 28.5: 残差的空间分布\n\n\n\n\n图 28.6 描述残差的分布，从 图 28.6 (a) 发现残差存在一定的线性趋势，岛屿的东南方，残差基本为正，而在岛屿的西北方，残差基本为负，说明有一定的异方差性。从 图 28.6 (b) 发现残差在水平方向上的分布像个哑铃，说明异方差现象明显。从 图 28.6 (c) 发现残差在垂直方向上的分布像棵松树，也说明异方差现象明显。\nggplot(rongelap, aes(x = 1:157, y = poisson_residuals / time)) +\n  geom_point(size = 1) +\n  theme_bw() +\n  labs(x = \"编号\", y = \"残差\")\n\nggplot(rongelap, aes(x = cX, y = poisson_residuals / time)) +\n  geom_point(size = 1) +\n  theme_bw() +\n  labs(x = \"横坐标\", y = \"残差\")\n\nggplot(rongelap, aes(x = cY, y = poisson_residuals / time)) +\n  geom_point(size = 1) +\n  theme_bw() +\n  labs(x = \"纵坐标\", y = \"残差\")\n\n\n\n\n\n\n\n\n\n(a) 残差与编号的关系\n\n\n\n\n\n\n\n\n\n(b) 残差与横坐标的关系\n\n\n\n\n\n\n\n\n\n\n\n(c) 残差与纵坐标的关系\n\n\n\n\n\n\n图 28.6: 残差分布图\n\n\n\n28.3.2 空间线性混合效应模型\n从实际场景出发，也不难理解，位置信息是非常关键的。进一步，充分利用位置信息，精细建模是很有必要的。相邻位置的核辐射强度是相关的，离得近的比离得远的更相关。下面对辐射强度建模，假定随机效应之间存在相关性结构，去掉随机效应相互独立的假设，这更符合位置效应存在相互影响的实际情况。\n\\[\n\\log\\big(\\lambda(x_i)\\big) = \\beta + S(x_{i}) + Z_{i}\n\\tag{28.1}\\]\n其中，\\(\\beta\\) 表示截距，相当于平均水平，\\(\\lambda(x_i)\\) 表示位置 \\(x_i\\) 处的辐射强度，\\(S(x_{i})\\) 表示位置 \\(x_i\\) 处的空间效应，\\(S(x),x \\in \\mathcal{D} \\subset{\\mathbb{R}^2}\\) 是二维平稳空间高斯过程 \\(\\mathcal{S}\\) 的具体实现。 \\(\\mathcal{D}\\) 表示研究区域，可以理解为朗格拉普岛，它是二维实平面 \\(\\mathbb{R}^2\\) 的子集。 \\(Z_i\\) 之间相互独立同正态分布 \\(\\mathcal{N}(0,\\tau^2)\\) ，\\(Z_i\\) 表示非空间的随机效应，在空间统计中，常称之为块金效应，可以理解为测量误差、空间变差或背景辐射。值得注意，此时，块金效应和模型残差是合并在一起的。\n\n28.3.2.1 自协方差函数\n随机过程 \\(S(x)\\) 的自协方差函数常用的有指数型、幂二次指数型（高斯型）和梅隆型，形式如下：\n\\[\n\\begin{aligned}\n\\mathsf{Cov}\\{ S(x_i), S(x_j) \\} &= \\sigma^2 \\exp\\big( -\\frac{\\|x_i -x_j\\|_{2}}{\\phi} \\big) \\\\\n\\mathsf{Cov}\\{ S(x_i), S(x_j) \\} &= \\sigma^2 \\exp\\big( -\\frac{\\|x_i -x_j\\|_{2}^{2}}{2\\phi^2} \\big) \\\\\n\\mathsf{Cov}\\{ S(x_i), S(x_j) \\} &= \\sigma^2 \\frac{2^{1 - \\nu}}{\\Gamma(\\nu)}\n\\left(\\sqrt{2\\nu}\\frac{\\|x_i -x_j\\|_{2}}{\\phi}\\right)^{\\nu}\nK_{\\nu}\\left(\\sqrt{2\\nu}\\frac{\\|x_i -x_j\\|_{2}}{\\phi}\\right) \\\\\nK_{\\nu}(x) &= \\int_{0}^{\\infty}\\exp(-x \\cosh t) \\cosh (\\nu t) \\mathrm{dt}\n\\end{aligned}\n\\tag{28.2}\\]\n其中，\\(K_{\\nu}\\) 表示阶数为 \\(\\nu\\) 的修正的第二类贝塞尔函数，\\(\\Gamma(\\cdot)\\) 表示伽马函数，当 \\(\\nu = 1/2\\) ，梅隆型将简化为指数型，当 \\(\\nu = \\infty\\) 时，梅隆型将简化为幂二次指数型。\n\\[\n\\mathsf{Cov}\\{ S(x_i), S(x_j) \\} = \\sigma^2 \\rho(u_{ij})\n\\]\n其中，\\(\\rho(u_{ij})\\) 表示自相关函数。 \\(u_{ij}\\) 表示位置 \\(x_i\\) 与 \\(x_j\\) 之间的距离，常用的有欧氏距离。梅隆型自相关函数图像如 图 28.7 所示，不难看出，\\(\\nu\\) 影响自相关函数的平滑性，控制点与点之间相关性的变化，\\(\\nu\\) 越大相关性越迅速地递减。\\(\\phi\\) 控制自相关函数的范围，\\(\\phi\\) 越大相关性辐射距离越远。对模型来说，它们都是超参数。\n\n代码# 参数 x 两点之间的距离，要求 x 大于 0\n# 参数 sigma nu phi 分别与前述公式参数对应\ncov_matern_nu &lt;- function(x, sigma = 1, nu = 3 / 2, phi = 5) {\n  phi &lt;- sqrt(2 * nu) * x / phi\n  sigma^2 * 2^(1 - nu) / gamma(nu) * phi^nu * besselK(x = phi, nu = nu)\n}\nlibrary(ggplot2)\nmesh_matern &lt;- expand.grid(\n  x = seq(from = 0.01, to = 20, by = 0.04),\n  sigma = 1, nu = c(5 / 2, 3 / 2, 1 / 2), phi = c(5, 2.5)\n)\n\nmesh_matern$fv &lt;- cov_matern_nu(\n  x = mesh_matern$x, sigma = mesh_matern$sigma,\n  nu = mesh_matern$nu, phi = mesh_matern$phi\n)\n\nmesh_matern$nu_math &lt;- paste(\"nu==\", mesh_matern$nu, sep = \"\")\nmesh_matern$phi_math &lt;- paste(\"phi==\", mesh_matern$phi, sep = \"\")\n\nggplot(data = mesh_matern, aes(x = x, y = fv)) +\n  geom_line(aes(color = nu_math)) +\n  facet_wrap(vars(phi_math), ncol = 1, labeller = ggplot2::label_parsed) +\n  scale_color_viridis_d(\n    labels = expression(nu == 0.5, nu == 1.5, nu == 2.5), \n    begin = 0.3, end = 0.7, option = \"C\"\n    ) +\n  theme_bw() +\n  labs(x = \"距离\", y = \"相关性\", color = expression(nu))\n\n\n\n\n\n\n图 28.7: 梅隆型自相关函数曲线\n\n\n\n\n\n28.3.2.2 nlme 包的自相关函数\nnlme 包中带块金效应的指数型自相关函数设定如下：\n\\[\n\\rho(u; \\phi, \\tau_{rel}^2 ) = \\tau_{rel}^2 + (1 - \\tau_{rel}^2) \\big(1 - \\exp(- \\frac{u}{\\phi}) \\big)\n\\]\n为了方便参数估计，nlme 包对参数做了一些重参数化的操作。\n\\[\n\\begin{aligned}\n\\tau_{rel}^2 &= \\frac{\\tau^2}{\\tau^2 + \\sigma^2} \\\\\n\\sigma_{tol}^2 &= \\tau^2 + \\sigma^2\n\\end{aligned}\n\\tag{28.3}\\]\n当 \\(u\\) 趋于 0 时， \\(\\rho(u; \\phi, \\tau_{rel}^2 ) = \\tau_{rel}^2\\) 。另外，\\(\\phi\\) 取值为正，\\(\\tau_{rel}^2\\) 取值介于 0-1 之间，在默认设置下，\\(\\phi\\) 的初始值为 \\(0.1 \\times \\max_{i,j \\in A} u_{ij}\\)，即所有点之间距离的最大值的 10%， \\(\\tau_{rel}^2\\) 为 0.1 ，这只是作为参考，用户可根据实际情况调整。\n下面以一个简单示例理解自相关函数 corExp() 的作用，令 \\(\\phi = 1.2, \\tau_{rel}^2 = 0.2\\)，则由距离矩阵和自相关函数构造的自相关矩阵如下：\n\nlibrary(nlme)\nspatDat &lt;- data.frame(x = (1:4) / 4, y = (1:4) / 4)\ncs3Exp &lt;- corExp(c(1.2, 0.2), form = ~ x + y, nugget = TRUE)\ncs3Exp &lt;- Initialize(cs3Exp, spatDat)\ncorMatrix(cs3Exp)\n\n#&gt;           [,1]     [,2]     [,3]      [,4]\n#&gt; [1,] 1.0000000 0.595847 0.443792 0.3305402\n#&gt; [2,] 0.5958470 1.000000 0.595847 0.4437920\n#&gt; [3,] 0.4437920 0.595847 1.000000 0.5958470\n#&gt; [4,] 0.3305402 0.443792 0.595847 1.0000000\n\n\n自相关矩阵的初始化结果等价于如下矩阵：\n\ndiag(0.2, 4) + (1 - 0.2) * exp(-as.matrix(dist(spatDat)) / 1.2)\n\n#&gt;           1        2        3         4\n#&gt; 1 1.0000000 0.595847 0.443792 0.3305402\n#&gt; 2 0.5958470 1.000000 0.595847 0.4437920\n#&gt; 3 0.4437920 0.595847 1.000000 0.5958470\n#&gt; 4 0.3305402 0.443792 0.595847 1.0000000\n\n\n除了函数 corExp() ，nlme 包还有好些自相关函数，如高斯自相关函数 corGaus() ，线性自相关函数 corLin() ，有理自相关函数 corRatio() ，球型自相关函数 corSpher() 等。它们的作用与函数 corExp() 类似，使用方式也一样，如下是高斯型自相关函数的示例，其他的不再一一举例。\n\ncs3Gaus &lt;- corGaus(c(1.2, 0.2), form = ~ x + y, nugget = TRUE)\ncs3Gaus &lt;- Initialize(cs3Gaus, spatDat)\ncorMatrix(cs3Gaus)\n\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.7334843 0.5653186 0.3662667\n#&gt; [2,] 0.7334843 1.0000000 0.7334843 0.5653186\n#&gt; [3,] 0.5653186 0.7334843 1.0000000 0.7334843\n#&gt; [4,] 0.3662667 0.5653186 0.7334843 1.0000000\n\n# 等价于\ndiag(0.2, 4) + (1 - 0.2) * exp(-as.matrix(dist(spatDat))^2 / 1.2^2)\n\n#&gt;           1         2         3         4\n#&gt; 1 1.0000000 0.7334843 0.5653186 0.3662667\n#&gt; 2 0.7334843 1.0000000 0.7334843 0.5653186\n#&gt; 3 0.5653186 0.7334843 1.0000000 0.7334843\n#&gt; 4 0.3662667 0.5653186 0.7334843 1.0000000\n\n\n\n28.3.2.3 nlme 包的拟合函数 gls()\n\nnlme 包的函数 gls() 实现限制极大似然估计方法，可以拟合存在异方差的一般线性模型。所谓一般线性模型，即在简单线性模型的基础上，残差不再是独立同分布的，而是存在相关性。函数 gls() 可以拟合具有空间自相关性的残差结构。这种线性模型又可以看作是一种带空间自相关结构的线性混合效应模型，空间随机效应的结构可以看作异方差的结构。\n\nfit_rongelap_gls &lt;- gls(\n  log(counts / time) ~ 1, data = rongelap,\n  correlation = corExp(\n    value = c(200, 0.1), form = ~ cX + cY, nugget = TRUE\n  )\n)\nsummary(fit_rongelap_gls)\n\n#&gt; Generalized least squares fit by REML\n#&gt;   Model: log(counts/time) ~ 1 \n#&gt;   Data: rongelap \n#&gt;        AIC      BIC    logLik\n#&gt;   184.4451 196.6446 -88.22257\n#&gt; \n#&gt; Correlation Structure: Exponential spatial correlation\n#&gt;  Formula: ~cX + cY \n#&gt;  Parameter estimate(s):\n#&gt;       range      nugget \n#&gt; 169.7472087   0.1092496 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Value Std.Error  t-value p-value\n#&gt; (Intercept) 1.812914 0.1088037 16.66224       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -5.57385199 -0.06909454  0.34610011  0.73852188  1.57152087 \n#&gt; \n#&gt; Residual standard error: 0.5739672 \n#&gt; Degrees of freedom: 157 total; 156 residual\n\n\nnlme 包给出截距项 \\(\\beta\\) 、相对块金效应 \\(\\tau_{rel}^2\\) 、范围参数 \\(\\phi\\) 和残差标准差 \\(\\sigma_{tol}\\) 的估计，\n\\[\n\\begin{aligned}\n\\beta &= 1.812914, \\quad \\phi  = 169.7472088 \\\\\n\\tau_{rel}^2   &= 0.1092496, \\quad \\sigma_{tol} = 0.5739672\n\\end{aligned}\n\\]\n根据前面的 方程式 28.3 ，可以得到 \\(\\tau^2\\) 和 \\(\\sigma^2\\) 的估计。\n\\[\n\\begin{aligned}\n\\tau^2   &= \\tau^2_{rel} \\times \\sigma^2_{tol} = 0.1092496 \\times 0.3294383 = 0.035991 \\\\\n\\sigma^2 &= \\sigma^2_{tol} - \\tau^2_{rel} \\times \\sigma^2_{tol} = 0.5739672^2 - 0.1092496 \\times 0.3294383 = 0.2934473\n\\end{aligned}\n\\]\n\n28.3.2.4 经验半变差函数图\n接下来用经验半变差函数图检查空间相关性。为方便表述起见，令 \\(T(x_i)\\) 代表 方程式 28.1 等号右侧的部分，即表示线性预测（Linear Predictor）。\n\\[\nT(x_i) = \\beta + S(x_{i}) + Z_{i}\n\\]\n令 \\(\\gamma(u_{ij}) = \\frac{1}{2}\\mathsf{Var}\\{T(x_i) - T(x_j)\\}\\) 表示半变差函数（Semivariogram），这里 \\(u_{ij}\\) 表示采样点 \\(x_i\\) 与 \\(x_j\\) 之间的距离。考虑到\n\\[\n\\gamma(u_{ij}) = \\frac{1}{2}\\mathsf{E}\\big\\{\\big[T(x_i) - T(x_j)\\big]^2\\big\\} = \\tau^2 + \\sigma^2\\big(1-\\rho(u_{ij})\\big)\n\\tag{28.4}\\]\n上式第一个等号右侧期望可以用样本代入来计算，称之为经验半变差函数，第二个等号右侧为理论半变差函数。为了便于计算，将距离做一定划分，尽量使得各个距离区间的样本点对的数目接近。此时，第 \\(i\\) 个距离区间上经验半变差函数值 \\(\\hat{\\gamma}(h_i)\\) 的计算公式如下：\n\\[\n\\hat{\\gamma}(h_i) = \\frac{1}{2N(h_i)}\\sum_{j=1}^{N(h_i)}(T(x_i)-T(x_i+h'))^2, \\ \\ h_{i,0} \\le h' &lt; h_{i,1}\n\\]\n其中，\\([h_{i,0},h_{i,1}]\\) 表示第 \\(i\\) 个距离区间，\\(N(h_i)\\) 表示第 \\(i\\) 个距离区间内所有样本点对的数目，只要两个点之间的距离在这个区间内，就算是一对。rongelap 数据集包含 157 个采样点，两两配对，共有 \\((157 - 1) \\times 157 / 2 = 12246\\) 对。下面举个例子说明函数 Variogram() 的作用。假设模型参数已经估计出来了，可以根据理论变差公式 方程式 28.4 计算， 设置为 \\(\\phi = 200, \\tau_{rel}^2 = 0.1\\) 。\n\n0.1  + (1 - 0.1) * (1 - exp(- 40 / 200 ))\n\n#&gt; [1] 0.2631423\n\n\n可知当距离为 40 时，半变差函数值为 0.2631423 ，当距离为 175.9570 时，半变差函数值为 0.6266151 。下面基于 nlme 包中自相关函数计算半变差函数值 ，将 rongelap 数据代入函数 Variogram() 可以计算每个距离对应的函数值，默认计算 50 个，如 图 28.8 所示。\n\ncs &lt;- corExp(value = c(200, 0.1), form = ~ cX + cY, nugget = TRUE)\ncs &lt;- Initialize(cs, rongelap)\nvario &lt;- Variogram(cs)\nhead(vario)\n\n#&gt;      variog     dist\n#&gt; 1 0.2631423  40.0000\n#&gt; 2 0.6266152 175.9570\n#&gt; 3 0.8107963 311.9141\n#&gt; 4 0.9041256 447.8711\n#&gt; 5 0.9514180 583.8282\n#&gt; 6 0.9753822 719.7852\n\n\n可以看到，当距离为 40 时，计算的结果与上面是一致的，也知道了函数 Variogram() 的作用。\n\n代码# 经验半变差图\nplot(vario,\n  col.line = \"black\", scales = list(\n    # 去掉图形上边、右边多余的刻度线\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ), par.settings = list(\n    plot.symbol = list(pch = 20, col = \"black\"),\n    plot.line = list(lwd = 1)\n  ),\n  xlab = \"距离（米）\", ylab = \"半变差函数值\"\n)\n\n\n\n\n\n\n图 28.8: 理论半变差函数图\n\n\n\n\nnlme 包的函数 Variogram() 根据函数 gls() 估计的参数值计算模型残差的经验半变差函数值：\n\nfit_rongelap_vario &lt;- Variogram(fit_rongelap_gls,\n  form = ~ cX + cY, data = rongelap, resType = \"response\"\n)\nfit_rongelap_vario\n\n#&gt;        variog       dist n.pairs\n#&gt; 1  0.07006716   89.44272     510\n#&gt; 2  0.12719889  144.22205     601\n#&gt; 3  0.17289246  252.98221     581\n#&gt; 4  0.22384959  368.78178     622\n#&gt; 5  0.26006395  443.84682     592\n#&gt; 6  0.20694239  521.53619     616\n#&gt; 7  0.41861866  718.05292     611\n#&gt; 8  0.30180842 1028.20230     610\n#&gt; 9  0.16717617 1493.73690     612\n#&gt; 10 0.14683508 2150.08137     612\n#&gt; 11 0.15149089 2993.10009     612\n#&gt; 12 0.21048419 3896.79355     613\n#&gt; 13 0.21372840 4600.21330     618\n#&gt; 14 0.17302418 4889.68302     607\n#&gt; 15 0.20205496 5065.98460     618\n#&gt; 16 0.18620361 5195.76751     623\n#&gt; 17 0.18613578 5293.99660     596\n#&gt; 18 0.20560623 5451.82538     616\n#&gt; 19 0.46457193 5604.41790     608\n#&gt; 20 0.55063433 5979.95802     612\n\n\n\n\n\n\n\n\n注释\n\n\n\n请思考 fit_rongelap_vario 输出的 n.pairs 的总对数为什么是 12090 而不是 12246？\n\n\n结果显示，距离在 0-89.44272 米之间的坐标点有 510 对，经验半变差函数值为 0.07006716。距离在 89.44272-144.22205 米之间的坐标点有 601 对，经验半变差函数值为 0.12719889，依此类推。将距离和计算的经验半变差函数值绘制出来，即得到经验半变差图，如 图 28.9 所示。刚开始，半变差值很小，之后随距离增加而增大，一直到达一个平台。半变差反比于空间相关性的程度，随着距离增加，空间相关性减弱。这说明数据中确含有空间相关性，模型中添加指数型自相关空间结构是合理的。\n\n代码# 经验半变差图\nplot(fit_rongelap_vario,\n  col.line = \"black\", scales = list(\n    # 去掉图形上边、右边多余的刻度线\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ), par.settings = list(\n    plot.symbol = list(pch = 20, col = \"black\"),\n    plot.line = list(lwd = 1)\n  ),\n  xlab = \"距离（米）\", ylab = \"半变差函数值\"\n)\n\n\n\n\n\n\n图 28.9: 残差的经验半变差图\n\n\n\n\n如果空间相关性提取得很充分，则标准化残差的半变差图中的数据点应是围绕标准差 1 上下波动，无明显趋势，拟合线几乎是一条水平线，从 图 28.10 来看，存在一些非均匀的波动，是采样点在空间的分布不均匀所致，岛屿狭长的中部地带采样点稀疏。如前所述，刻画空间相关性，除了指数型，还可以用其它自相关结构来拟合，留待读者练习。\n\n代码fit_rongelap_vario_norm &lt;- nlme::Variogram(fit_rongelap_gls,\n  form = ~ cX + cY, data = rongelap, resType = \"normalized\"\n)\n# 经验半变差图\nplot(fit_rongelap_vario_norm,\n  col.line = \"black\", scales = list(\n    # 去掉图形上边、右边多余的刻度线\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ), par.settings = list(\n    plot.symbol = list(pch = 20, col = \"black\"),\n    plot.line = list(lwd = 1)\n  ),\n  xlab = \"距离（米）\", ylab = \"半变差函数值\"\n)\n\n\n\n\n\n\n图 28.10: 标准化残差的经验半变差图\n\n\n\n\n\n28.3.3 空间广义线性混合效应模型\n简单的广义线性模型并没有考虑距离相关性，它认为各个观测点的数据是相互独立的。因此，考虑采用广义线性混合效应模型，在广义线性模型的基础上添加位置相关的随机效应，用以刻画未能直接观测到的潜在影响。 \\({}^{137}\\mathrm{Cs}\\) 放出伽马射线，在 \\(n=157\\) 个采样点，分别以时间间隔 \\(t_i\\) 测量辐射量 \\(y(x_i)\\)，建立泊松型空间广义线性混合效应模型。\n\\[\n\\begin{aligned}\n\\log\\{\\lambda(x_i)\\} & = \\beta + S(x_{i}) + Z_{i} \\\\\ny(x_{i}) &\\sim \\mathrm{Poisson}\\big(t_i\\lambda(x_i)\\big)\n\\end{aligned}\n\\tag{28.5}\\]\n模型中，放射粒子数 \\(y(x_{i})\\) 作为响应变量服从均值为 \\(t_i\\lambda(x_i)\\) 的泊松分布，其它模型成分的说明同前。简单起见，下面不添加块金效应，即。掉模型中的 \\(Z_i\\) 。此时，块金效应对模型预测效果的提升很有限，由于 \\(\\tau^2\\) 和 \\(\\sigma^2\\) 之间存在的可识别性问题，会显著增加参数估计的复杂度。\nnlme 包不能拟合空间广义线性混合效应模型， spaMM 包可以，它的使用语法与前面介绍的函数 glm() 、 nlme 包都类似，函数 fitme() 可以拟合从线性模型到广义线性混合效应模型的一大类模型，且使用统一的语法，输出一个 HLfit 类型的数据对象。 spaMM 包的函数 Matern() 实现了梅隆型自协方差函数，指数型和幂二次指数型是它的特例。当固定 \\(\\nu = 0.5\\) 时，梅隆型自协方差函数 Matern() 的形式退化为 \\(\\sigma^2\\exp(- \\alpha u)\\) ，其中，\\(\\alpha\\) 与范围参数关联，相当于前面出现的 \\(1/\\phi\\) 。\n\nlibrary(spaMM)\nfit_rongelap_spamm &lt;- fitme(\n  formula = counts ~ 1 + Matern(1 | cX + cY) + offset(log(time)),\n  family = poisson(link = \"log\"), data = rongelap,\n  fixed = list(nu = 0.5), method = \"REML\"\n)\nsummary(fit_rongelap_spamm)\n\n#&gt; formula: counts ~ 1 + Matern(1 | cX + cY) + offset(log(time))\n#&gt; Estimation of corrPars and lambda by REML (p_bv approximation of restricted logL).\n#&gt; Estimation of fixed effects by ML (p_v approximation of logL).\n#&gt; Estimation of lambda by 'outer' REML, maximizing restricted logL.\n#&gt; family: poisson( link = log ) \n#&gt;  ------------ Fixed effects (beta) ------------\n#&gt;             Estimate Cond. SE t-value\n#&gt; (Intercept)    1.829  0.08797   20.78\n#&gt;  --------------- Random effects ---------------\n#&gt; Family: gaussian( link = identity ) \n#&gt;                    --- Correlation parameters:\n#&gt;        1.nu       1.rho \n#&gt; 0.500000000 0.009211761 \n#&gt;            --- Variance parameters ('lambda'):\n#&gt; lambda = var(u) for u ~ Gaussian; \n#&gt;    cX + cY  :  0.3069  \n#&gt; # of obs: 157; # of groups: cX + cY, 157 \n#&gt;  ------------- Likelihood values  -------------\n#&gt;                         logLik\n#&gt; logL       (p_v(h)): -1318.010\n#&gt; Re.logL  (p_b,v(h)): -1319.522\n\n\n从输出结果来看，模型固定效应的截距项 \\(\\beta\\) 为 1.829，空间随机效应的方差 \\(\\sigma^2\\) 为 0.3069，对比函数 Matern() 实现的指数型自协方差函数公式与 方程式 28.2 ，将输出结果转化一下，则 \\(\\phi = 1 / 0.00921 = 108.57\\) ，表示在这个模型的设定下，空间相关性的最大影响距离约为 108.5 米。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>空间点参考数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-spatial-data.html#sec-rongelap-predict",
    "href": "analyze-spatial-data.html#sec-rongelap-predict",
    "title": "28  空间点参考数据分析",
    "section": "\n28.4 模型预测",
    "text": "28.4 模型预测\n接下来，预测给定的边界（海岸线）内任意位置的核辐射强度，展示全岛的核辐射强度分布。先从点构造多边形数据，再将多边形做网格划分，继而将网格中心点作为模型输入获得核辐射强度的预测值。\n\n28.4.1 海岸线数据\n海岸线上取一些点，点的数量越多，对海岸线的刻画越精确，这在转弯处体现得非常明显。海岸线的数据是以成对的坐标构成，导入 R 语言中，是以数据框的形式存储，为了方便后续的操作，引入空间数据操作的 sf 包(Pebesma 2018)，将核辐射数据和海岸线数据转化为 POINT 类型的空间点数据。\n\nlibrary(sf)\nrongelap_sf &lt;- st_as_sf(rongelap, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_coastline_sf &lt;- st_as_sf(rongelap_coastline, coords = c(\"cX\", \"cY\"), dim = \"XY\")\n\nsf 包提供了大量操作空间数据的函数，比如函数 st_bbox() 计算一组空间数据的矩形边界，获得左下和右上两个点的坐标 (xmin,ymin) 和(xmax,ymax)，下面还会陆续涉及其它空间数据操作。\n\nst_bbox(rongelap_coastline_sf)\n\n#&gt;        xmin        ymin        xmax        ymax \n#&gt; -6299.31201 -3582.25000    20.37916   103.54140\n\n\nrongelap_coastline_sf 数据集是朗格拉普岛海岸线的采样点坐标，是一个 POINT 类型的数据，为了以海岸线为边界生成规则网格，首先连接点 POINT 构造多边形 POLYGON 对象。POINT 和 POLYGON 是 sf 包内建的基础的几何类型，其它复杂的空间类型是由它们衍生而来。函数 st_geometry 提取空间点数据中的几何元素，再用函数 st_combine 将点组合起来，最后用函数 st_cast 转换成 POLYGON 多边形类型。\n\nrongelap_coastline_sfp &lt;- st_cast(st_combine(st_geometry(rongelap_coastline_sf)), \"POLYGON\")\n\n图 28.11 上下两个子图分别展示空间点集和多边形。上图是原始的采样点数据，下图是以点带线，串联 POINT 数据构造 POLYGON 数据后的多边形。后续的数据操作将围绕这个多边形展开。\n代码# 点集\nggplot(rongelap_coastline_sf) +\n  geom_sf(size = 0.5) +\n  theme_void()\n# 多边形\nggplot(rongelap_coastline_sfp) +\n  geom_sf(fill = \"white\", linewidth = 0.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n(a) 点数据\n\n\n\n\n\n\n\n\n\n\n\n(b) 多边形数据\n\n\n\n\n\n\n图 28.11: 朗格拉普岛海岸线的表示\n\n\n\n28.4.2 边界处理\n为了确保覆盖整个岛，处理好边界问题，需要一点缓冲空间，就是说在给定的边界线外围再延伸一段距离，构造一个更大的多边形，这可以用函数 st_buffer() 实现，根据海岸线构造缓冲区，得到一个 POLYGON 类型的几何数据对象。考虑到朗格拉普岛的实际大小，缓冲距离选择 50 米。\n\nrongelap_coastline_buffer &lt;- st_buffer(rongelap_coastline_sfp, dist = 50)\n\n缓冲区构造出来的效果如 图 28.12 所示，为了便于与海岸线对比，图中将采样点、海岸线和缓冲区都展示出来了。\n\n代码ggplot() +\n  geom_sf(data = rongelap_sf, size = 0.2) +\n  geom_sf(data = rongelap_coastline_sfp, fill = NA, color = \"gray30\") +\n  geom_sf(data = rongelap_coastline_buffer, fill = NA, color = \"black\") +\n  theme_void()\n\n\n\n\n\n\n图 28.12: 朗格拉普岛海岸线及其缓冲区\n\n\n\n\n\n28.4.3 构造网格\n接下来，利用函数 st_make_grid() 根据朗格拉普岛海岸缓冲线构造网格，朗格拉普岛是狭长的，因此，网格是 \\(75\\times 150\\) 的，意味着水平方向 75 行，垂直方向 150 列。网格的疏密程度是可以调整的，网格越密，格点越多，核辐射强度分布越精确，计算也越耗时。\n\n# 构造带边界约束的网格\nrongelap_coastline_grid &lt;- st_make_grid(rongelap_coastline_buffer, n = c(150, 75))\n\n函数 st_make_grid() 根据 rongelap_coastline_buffer 的矩形边界网格化，效果如 图 38.7 所示，依次添加了网格、海岸线和缓冲区。实际上，网格只需要覆盖朗格拉普岛即可，岛外的部分是大海，不需要覆盖，根据现有数据和模型对岛外区域预测核辐射强度也没有意义，因此，在后续的操作中，岛外的网格都要去掉。函数 st_make_grid() 除了支持方形网格划分，还支持六边形网格划分。\n\n代码ggplot() +\n  geom_sf(data = rongelap_coastline_grid, fill = NA, color = \"gray\") +\n  geom_sf(data = rongelap_coastline_sfp, fill = NA, color = \"gray30\") +\n  geom_sf(data = rongelap_coastline_buffer, fill = NA, color = \"black\") +\n  theme_void()\n\n\n\n\n\n\n图 28.13: 朗格拉普岛规则化网格操作\n\n\n\n\n接下来，调用 sf 包函数 st_intersects() 将小网格落在缓冲区和岛内的筛选出来，一共 1612 个小网格，再用函数 st_centroid() 计算这些网格的中心点坐标。函数 st_intersects() 的作用是对多边形和网格取交集，包含与边界线交叉的网格，默认返回值是一个稀疏矩阵，与索引函数 [.sf （这是 sf 包扩展 [ 函数的一个例子）搭配可以非常方便地过滤出目标网格。与之相关的函数 st_crosses() 可以获得与边界线交叉的网格。\n\n# 将 sfc 类型转化为 sf 类型\nrongelap_coastline_grid &lt;- st_as_sf(rongelap_coastline_grid)\nrongelap_coastline_buffer &lt;- st_as_sf(rongelap_coastline_buffer)\nrongelap_grid &lt;- rongelap_coastline_grid[rongelap_coastline_buffer, op = st_intersects]\n# 计算网格中心点坐标\nrongelap_grid_centroid &lt;- st_centroid(rongelap_grid)\n\n过滤出来的网格如 图 38.7 所示，全岛网格化后，图中将朗格拉普岛海岸线、网格都展示出来了。网格的中心点将作为新的坐标数据，后续要在这些新的坐标点上预测核辐射强度。\n\n代码ggplot() +\n  geom_sf(data = rongelap_coastline_sfp, \n          fill = NA, color = \"gray30\", linewidth = 0.5) +\n  geom_sf(data = rongelap_grid, fill = NA, color = \"gray30\") +\n  theme_void()\n\n\n\n\n\n\n图 28.14: 朗格拉普岛规则网格划分结果\n\n\n\n\n\n28.4.4 整理数据\n函数 st_coordinates() 抽取网格中心点的坐标并用函数 as.data.frame() 转化为数据框类型，新数据的列名需要和训练数据保持一致，最后补充漂移项 time，以便输入模型中。漂移项并不影响核辐射强度，指定为 300 或 400 都可以。\n\nrongelap_grid_df &lt;- as.data.frame(st_coordinates(rongelap_grid_centroid))\ncolnames(rongelap_grid_df) &lt;- c(\"cX\", \"cY\")\nrongelap_grid_df$time &lt;- 1\n\n将数据输入 spaMM 包拟合的模型对象 fit_rongelap_spamm，并将模型返回的结果整理成数据框，再与采样点数据合并。predict() 是一个泛型函数，spaMM 包为模型对象提供了相应的预测方法。\n\n# 预测值\nrongelap_grid_pred &lt;- predict(fit_rongelap_spamm,\n  newdata = rongelap_grid_df, type = \"response\"\n)\nrongelap_grid_df$pred_sp &lt;- as.vector(rongelap_grid_pred)\n# 线性预测的方差\nrongelap_grid_var &lt;- get_predVar(fit_rongelap_spamm,\n  newdata = rongelap_grid_df, variances = list(predVar = TRUE), which = \"predVar\"\n)\n\n#&gt; Non-identity link: predVar is on linear-predictor scale.\n\nrongelap_grid_df$var_sp &lt;- as.vector(rongelap_grid_var)\n\n在空间线性混合效应模型一节，截距 \\(\\beta\\) ，方差 \\(\\sigma^2\\) ，块金效应 \\(\\tau^2\\) 和范围参数 \\(\\phi\\) 都估计出来了。在此基础上，采用简单克里金插值方法预测，对于未采样观测的位置 \\(x_0\\)，它的辐射强度的预测值 \\(\\hat{\\lambda}(x_0)\\) 及其预测方差 \\(\\mathsf{Var}\\{\\hat{\\lambda}(x_0)\\}\\) 的计算公式如下。\n\\[\n\\begin{aligned}\n\\hat{\\lambda}(x_0) &= \\beta + \\boldsymbol{u}^{\\top}(V + \\tau^2I)^{-1}(\\boldsymbol{\\lambda} - \\boldsymbol{1}\\beta) \\\\\n\\mathsf{Var}\\{\\hat{\\lambda}(x_0)\\}  &= \\sigma^2 - \\boldsymbol{u}^{\\top}(V + \\tau^2I)^{-1}\\boldsymbol{u}\n\\end{aligned}\n\\]\n其中，协方差矩阵 \\(V\\) 中第 \\(i\\) 行第 \\(j\\) 列的元素为 \\(\\mathsf{Cov}\\{S(x_i),S(x_j)\\}\\) ，列向量 \\(\\boldsymbol{u}\\) 的第 \\(i\\) 个元素为 \\(\\mathsf{Cov}\\{S(x_i),S(x_0)\\}\\) 。\n\n# 截距\nbeta &lt;- 1.812914\n# 范围参数\nphi &lt;- 169.7472088\n# 方差\nsigma_sq &lt;- 0.2934473\n# 块金效应\ntau_sq &lt;- 0.035991\n# 自协方差函数\ncov_fun &lt;- function(h) sigma_sq * exp(-h / phi)\n# 观测距离矩阵\nm_obs &lt;- cov_fun(st_distance(x = rongelap_sf)) + diag(tau_sq, 157)\n# 预测距离矩阵\nm_pred &lt;- cov_fun(st_distance(x = rongelap_sf, y = rongelap_grid_centroid))\n# 简单克里金插值 Simple Kriging\nmean_sk &lt;- beta + t(m_pred) %*% solve(m_obs, log(rongelap_sf$counts / rongelap_sf$time) - beta)\n# 辐射强度预测值\nrongelap_grid_df$pred_sk &lt;- exp(mean_sk)\n# 辐射强度预测方差\nrongelap_grid_df$var_sk &lt;- sigma_sq - diag(t(m_pred) %*% solve(m_obs, m_pred))\n\n\n28.4.5 展示结果\n将预测结果以散点图的形式呈现到图上，见下 图 28.15 ，由于散点非常多，紧挨在一起就连成片了。上子图是 nlme 包预测的结果，下子图是 spaMM 包预测的结果，前者图像看起来会稍微平滑一些。\n\n代码# 数据框变形\nrongelap_grid_df2 &lt;- reshape(\n  data = rongelap_grid_df, \n  varying = c(\"pred_sp\", \"var_sp\", \"pred_sk\", \"var_sk\"), \n  times = c(\"spaMM\", \"nlme\"), v.names = c(\"pred\", \"var\"), \n  timevar = \"method\", idvar = c(\"cX\", \"cY\"),\n  new.row.names = 1:(2 * 1612), direction = \"long\"\n)\n# 数据框类型转换\nrongelap_grid_sf2 &lt;- st_as_sf(rongelap_grid_df2, coords = c(\"cX\", \"cY\"), dim = \"XY\")\n# 分面展示两种预测方法\nggplot(data = rongelap_grid_sf2) +\n  geom_sf(aes(color = pred), size = 0.5) +\n  scale_color_viridis_c(option = \"C\", breaks = 0:12,\n    guide = guide_colourbar(\n      barwidth = 1, barheight = 15\n    )) +\n  facet_wrap(~method, ncol = 1) +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", color = \"预测值\")\n\n\n\n\n\n\n图 28.15: 朗格拉普岛核辐射强度的分布\n\n\n\n\n从空间线性混合效应模型到空间广义线性混合效应模型的效果提升不多，差异不太明显。下 图 28.16 展示核辐射强度预测方差的分布。越简单的模型，预测值的分布越平滑，越复杂的模型，捕捉到更多局部细节，因而，预测值的分布越曲折。\n\n代码# 分面展示两种预测方法\nggplot(data = rongelap_grid_sf2) +\n  geom_sf(aes(color = var), size = 0.5) +\n  scale_color_viridis_c(\n    option = \"C\", breaks = 0.1 * 0:16 / 4,\n    guide = guide_colourbar(\n      barwidth = 1, barheight = 15\n    )\n  ) +\n  facet_wrap(~method, ncol = 1) +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", color = \"预测方差\")\n\n\n\n\n\n\n图 28.16: 核辐射强度预测方差的分布\n\n\n\n\n考虑到核辐射在全岛的分布应当是连续性的，空间连续性也是这类模型的假设，接下来绘制热力图，先用 stars 包(Pebesma 2022)将预测数据按原网格化的精度转化成栅格对象，裁减超出朗格拉普岛海岸线以外的内容。\n\nlibrary(abind)\nlibrary(stars)\nrongelap_grid_sf &lt;- st_as_sf(rongelap_grid_df, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_grid_stars &lt;- st_rasterize(rongelap_grid_sf, nx = 150, ny = 75)\nrongelap_stars &lt;- st_crop(x = rongelap_grid_stars, y = rongelap_coastline_sfp)\n\n除了矢量栅格化函数 st_rasterize() 和栅格剪裁函数 st_crop() ，stars 包还提供栅格数据图层 geom_stars()，这可以和 ggplot2 内置的图层搭配使用。下 图 28.17 是 ggplot2 包和 grid 包一起绘制的辐射强度的热力分布图，展示 spaMM 包的预测效果。图左侧一小一大两个虚线框是放大前后的部分区域，展示朗格拉普岛核辐射强度的局部变化。\n\n代码# 虚线框数据\ndash_sfp &lt;- st_polygon(x = list(rbind(\n  c(-6000, -3600),\n  c(-6000, -2600),\n  c(-5000, -2600),\n  c(-5000, -3600),\n  c(-6000, -3600)\n)), dim = \"XY\")\n# 主体内容\np3 &lt;- ggplot() +\n  geom_stars(\n    data = rongelap_stars, na.action = na.omit,\n    aes(fill = pred_sp / time)\n  ) +\n  # 海岸线\n  geom_sf(\n    data = rongelap_coastline_sfp,\n    fill = NA, color = \"gray30\", linewidth = 0.5\n  ) +\n  # 图例\n  scale_fill_viridis_c(\n    option = \"C\", breaks = 0:12,\n    guide = guide_colourbar(\n      barwidth = 15, barheight = 1.5,\n      title.position = \"top\" # 图例标题位于图例上方\n    )\n  ) +\n  # 虚线框\n  geom_sf(data = dash_sfp, fill = NA, linewidth = 0.75, lty = 2) +\n  # 箭头\n  geom_segment(\n    data = data.frame(x = -5500, xend = -5000, y = -2600, yend = -2250),\n    aes(x = x, y = y, xend = xend, yend = yend),\n    arrow = arrow(length = unit(0.03, \"npc\"))\n  ) +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", fill = \"辐射强度\") +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.75, 0.1),\n    legend.direction = \"horizontal\",\n    legend.background = element_blank()\n  )\n\np4 &lt;- ggplot() +\n  geom_stars(\n    data = rongelap_stars, na.action = na.omit,\n    aes(fill = pred_sp / time), show.legend = FALSE\n  ) +\n  geom_sf(\n    data = rongelap_coastline_sfp,\n    fill = NA, color = \"gray30\", linewidth = 0.75\n  ) +\n  scale_fill_viridis_c(option = \"C\", breaks = 0:12) +\n  # 虚线框\n  geom_sf(data = dash_sfp, fill = NA, linewidth = 0.75, lty = 2) +\n  theme_void() +\n  coord_sf(expand = FALSE, xlim = c(-6000, -5000), ylim = c(-3600, -2600))\n# 叠加图形\np3\nprint(p4, vp = grid::viewport(x = .3, y = .65, width = .45, height = .45))\n\n\n\n\n\n\n图 28.17: 朗格拉普岛核辐射强度的分布\n\n\n\n\n美国当年是在比基尼环礁做的氢弹核试验，试验地与朗格拉普岛相距 100 多英里。核辐射羽流受大气、海洋环流等影响，漂流到朗格拉普岛。又受朗格拉普岛周围水文、地理环境影响，核辐射强度在全岛的分布是不均匀的，图中越亮的地方表示受到的核辐射越严重。\n\n\n\n\nChristensen, O. F., 和 P. J. Ribeiro Jr. 2002. 《geoRglm: A package for generalised linear spatial models》. R News 2 (2): 26–28.\n\n\nPebesma, Edzer. 2018. 《Simple Features for R: Standardized Support for Spatial Vector Data》. The R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\n———. 2022. stars: Spatiotemporal Arrays, Raster and Vector Data Cubes. https://CRAN.R-project.org/package=stars.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>空间点参考数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-areal-data.html",
    "href": "analyze-areal-data.html",
    "title": "29  空间区域数据分析",
    "section": "",
    "text": "29.1 苏格兰唇癌数据分析\n响应变量服从泊松分布\n记录 1975-1986 年苏格兰 56 个地区的唇癌病例数，这是一个按地区汇总的数据。\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nscotlips &lt;- st_read('data/scotland/scotland.shp', crs = st_crs(\"EPSG:27700\"))\n\nReading layer `scotland' from data source \n  `/Users/runner/work/data-analysis-in-action/data-analysis-in-action/data/scotland/scotland.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 56 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 7150.759 ymin: 529557.2 xmax: 468393.4 ymax: 1218479\nProjected CRS: OSGB36 / British National Grid\n\nstr(scotlips)\n\nClasses 'sf' and 'data.frame':  56 obs. of  10 variables:\n $ SP_ID    : chr  \"12\" \"13\" \"19\" \"02\" ...\n $ NAME     : chr  \"Sutherland\" \"Nairn\" \"Inverness\" \"Banff-Buchan\" ...\n $ ID       : num  12 13 19 2 17 16 21 50 15 25 ...\n $ District : int  12 13 19 2 17 16 21 50 15 25 ...\n $ Observed : int  5 3 9 39 2 9 16 6 17 19 ...\n $ Expected : num  1.8 1.1 5.5 8.7 1.1 4.6 10.5 19.6 7.8 15.5 ...\n $ pcaff    : int  16 10 7 16 10 16 7 1 7 1 ...\n $ Latitude : num  58.1 57.5 57.2 57.6 57.1 ...\n $ Longitude: num  4.64 3.98 4.73 2.36 4.09 3 2.98 3.2 3.1 3.3 ...\n $ geometry :sfc_MULTIPOLYGON of length 56; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:73, 1:2] 254302 254442 253074 245057 259217 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:9] \"SP_ID\" \"NAME\" \"ID\" \"District\" ...\nlibrary(ggplot2)\nggplot() +\n  geom_sf(data = scotlips, aes(fill = Observed)) +\n  scale_fill_viridis_c() +\n  theme_minimal()\n\n\n\n\n\n\n图 29.1: 苏格兰各地区唇癌病例数分布",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>空间区域数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-areal-data.html#sec-scotland-lip-cancer",
    "href": "analyze-areal-data.html#sec-scotland-lip-cancer",
    "title": "29  空间区域数据分析",
    "section": "",
    "text": "Everything is related to everything else, but near things are more related than distant things.\n— Waldo Tobler (Tobler 1970)\n\n\n\n\n\n\n\n空间区域数据分析\n\n\n\n空间区域数据的贝叶斯建模\n\nBayesian spatial and spatio-temporal GLMMs with possible extremes glmmfields\n\nBayesian spatial analysis geostan\n\nSpatial Models in Stan: Intrinsic Auto-Regressive Models for Areal Data\n\nExact sparse CAR models in Stan 网页文档\n\n\nSpatial Models in Stan: Intrinsic Auto-Regressive Models for Areal Data 网页文档 原始数据和代码，接上面苏格兰唇癌数据分析，用 CmdStanR 更新后的代码\n\n\nSpatial modeling of areal data. Lip cancer in Scotland INLA 建模\n\nCAR models Scotland Lip cancer dataset Stan 建模\n空间计量 区域数据分析 on-the-use-of-r-for-spatial-econometrics\n\n\n\n\n\n\nBYM-INLA (Blangiardo 等 2013; Moraga 2020)\n\nBYM-Stan (Morris 等 2019; Donegan 2022; Cabral, Bolin, 和 Rue 2022)",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>空间区域数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-areal-data.html#美国各州犯罪率分析",
    "href": "analyze-areal-data.html#美国各州犯罪率分析",
    "title": "29  空间区域数据分析",
    "section": "\n29.2 美国各州犯罪率分析",
    "text": "29.2 美国各州犯罪率分析\n响应变量服从高斯分布的调查数据 (Bivand 2001)\n数据集 USArrests 记录 1973 年美国各州每 10 万居民中因谋杀 Murder、袭击 Assault 和强奸 Rape 被警察逮捕的人数以及城市人口所占百分比（可以看作城市化率）。\n\n\n\n表格 29.1: 数据集 USArrests（部分）\n\n\n\n\n州名\n区域划分\n谋杀犯\n袭击犯\n城市化率\n强奸犯\n\n\n\nAlabama\nSouth\n13.2\n236\n58\n21.2\n\n\nAlaska\nWest\n10.0\n263\n48\n44.5\n\n\nArizona\nWest\n8.1\n294\n80\n31.0\n\n\nArkansas\nSouth\n8.8\n190\n50\n19.5\n\n\nCalifornia\nWest\n9.0\n276\n91\n40.6\n\n\nColorado\nWest\n7.9\n204\n78\n38.7\n\n\n\n\n\n\n\n\n\nlibrary(sf)\n# 州数据\nus_state_sf &lt;- readRDS(\"data/us-state-map-2010.rds\")\n# 观测数据\nus_state_df &lt;- merge(x = us_state_sf, y = us_arrests,\n  by.x = \"NAME\", by.y = \"state_name\", all.x = TRUE)\n\nggplot() +\n  geom_sf(\n    data = us_state_df, aes(fill = Assault), color = \"gray80\", lwd = 0.25) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"white\") +\n  theme_void()\n\n\n\n\n\n\n图 29.2: 因袭击被逮捕的人数分布\n\n\n\n\n1973 年美国各州因袭击被逮捕的人数与城市化率的关系：相关分析\n\n代码library(ggrepel)\nggplot(data = us_arrests, aes(x = UrbanPop, y = Assault)) +\n  geom_point(aes(color = state_region)) +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  theme_classic() +\n  labs(x = \"城市化率（%）\", y = \"因袭击被逮捕人数\", color = \"区域划分\")\n\n\n\n\n\n\n图 29.3: 逮捕人数比例与城市化率的关系\n\n\n\n\n阿拉斯加州和夏威夷州与其它州都不相连，属于孤立的情况，下面在空间相关性的分析中排除这两个州。\n\n# 州的中心\ncenters48 &lt;- subset(\n  x = data.frame(x = state.center$x, y = state.center$y),\n  subset = !state.name %in% c(\"Alaska\", \"Hawaii\")\n)\n# 观测数据\narrests48 &lt;- subset(\n  x = USArrests,\n  subset = !rownames(USArrests) %in% c(\"Alaska\", \"Hawaii\")\n)\n\n\nlibrary(spData)\nlibrary(spdep)\n# KNN\nk4.48 &lt;- knn2nb(knearneigh(as.matrix(centers48), k = 4))\n# Moran I test\nmoran.test(x = arrests48$Assault, listw = nb2listw(k4.48))\n\n\n    Moran I test under randomisation\n\ndata:  arrests48$Assault  \nweights: nb2listw(k4.48)    \n\nMoran I statistic standard deviate = 3.4216, p-value = 0.0003113\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.294385644      -0.021276596       0.008511253 \n\n# Permutation test for Moran's I statistic\nmoran.mc(x = arrests48$Assault, listw = nb2listw(k4.48), nsim = 499)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  arrests48$Assault \nweights: nb2listw(k4.48)  \nnumber of simulations + 1: 500 \n\nstatistic = 0.29439, observed rank = 499, p-value = 0.002\nalternative hypothesis: greater\n\n\n\n\n\n\nBivand, Roger. 2001. 《More on Spatial Data Analysis》. R News 1 (3): 13–17. https://www.r-project.org/doc/Rnews/Rnews_2001-3.pdf.\n\n\nBlangiardo, Marta, Michela Cameletti, Gianluca Baio, 和 Håvard Rue. 2013. 《Spatial and spatio-temporal models with R-INLA》. Spatial and Spatio-temporal Epidemiology 7 (十二月): 39–55. https://doi.org/10.1016/j.sste.2013.07.003.\n\n\nCabral, Rafael, David Bolin, 和 Håvard Rue. 2022. 《Controlling the Flexibility of Non-Gaussian Processes Through Shrinkage Priors》. Bayesian Analysis -1 (-1): 1–24. https://doi.org/10.1214/22-BA1342.\n\n\nDonegan, Connor. 2022. 《geostan: An R package for Bayesian spatialanalysis》. Journal of Open Source Software 7 (79): 4716. https://doi.org/10.21105/joss.04716.\n\n\nMoraga, Paula. 2020. Geospatial health data: modeling and visualization with R-INLA and Shiny. Boca Raton, Florida: Chapman; Hall/CRC. https://www.paulamoraga.com/book-geospatial/.\n\n\nMorris, Mitzi, Katherine Wheeler-Martin, Dan Simpson, Stephen J. Mooney, Andrew Gelman, 和 Charles DiMaggio. 2019. 《Bayesian hierarchical spatial models: Implementing the Besag York Mollié model in stan》. Spatial and Spatio-temporal Epidemiology 31 (十一月): 100301. https://doi.org/10.1016/j.sste.2019.100301.\n\n\nTobler, Waldo. 1970. 《A computer movie simulating urban growth in the Detroit region》. Economic Geography 46 (Supplement): 234–40. https://doi.org/10.2307/143141.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>空间区域数据分析</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html",
    "href": "statistical-computation.html",
    "title": "30  统计计算",
    "section": "",
    "text": "30.1 回归问题与优化问题\n1996 年出现 Lasso （Least Absolute Selection and Shrinkage Operator，简称 Lasso）(Tibshirani 1996)，由于缺少高效的求解算法，Lasso 在高维小样本特征选择研究中没有广泛流行，最小角回归（Least Angle Regression，简称 LAR）算法 (Efron 等 2004) 的出现有力促进了 Lasso 在高维小样本数据中的应用。为了解决 Lasso 的有偏估计问题，自适应 Lasso、松弛 Lasso， SCAD （Smoothly Clipped Absolute Deviation，简称 SCAD）(Kim, Choi, 和 Oh 2008)，MCP (Minimax Concave Penalty，简称 MCP)(Zhang 2010) 陆续出现。经典的普通最小二乘、广义最小二乘、岭回归、逐步回归、Lasso 回归、最优子集回归都可转化为优化问题。具体地，一个带 L1 正则项的线性回归模型，其对应的优化问题如下：\n\\[\n\\arg \\min_{\\boldsymbol{\\beta},\\lambda} ~~ \\frac{1}{2} || \\bm{y} - X \\boldsymbol{\\beta} ||_2^2 +  \\lambda ||\\boldsymbol{\\beta}||_1\n\\]\n其中，\\(X \\in \\mathbb{R}^{n\\times k}\\)， \\(\\bm{y} \\in \\mathbb{R}^n\\)，\\(\\boldsymbol{\\beta} \\in \\mathbb{R}^k\\)， \\(0 &lt; \\lambda \\in \\mathbb{R}\\) 。下面以逻辑回归模型为例，介绍 R 语言中求解此类优化问题的方法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-log-likelihood",
    "href": "statistical-computation.html#sec-log-likelihood",
    "title": "30  统计计算",
    "section": "\n30.2 对数似然与损失函数",
    "text": "30.2 对数似然与损失函数\n\n30.2.1 Logistic 分布\n在介绍逻辑回归之前，先了解一下 Logistic 分布。一个均值为 \\(m\\) ，方差为 \\(\\frac{\\pi^2}{3}s^2\\) 的 Logistic 分布函数的形式为\n\\[\nF(x) = \\frac{1}{1 + \\exp(-\\frac{x - m}{s})}\n\\]\n密度函数的形式为\n\\[\nf(x) = \\frac{\\exp(-\\frac{x - m}{s})}{s(1 + \\exp(-\\frac{x-m}{s}))^2} = \\frac{\\exp(\\frac{x - m}{s})}{s(1 + \\exp(\\frac{x-m}{s}))^2}\n\\]\n密度函数与分布函数的关系如下：\n\\[\n\\frac{dF(x)}{dx} = f(x) = sF(x)(1 - F(x))\n\\]\n也就是说 Logistic 分布是上述微分方程的解。\n\n\n\n\n\n\n\n\n\n(a) 概率密度函数\n\n\n\n\n\n\n\n\n\n(b) 概率分布函数\n\n\n\n\n\n\n图 30.1: 逻辑斯谛分布\n\n\nR 语言中分别表示逻辑斯谛分布的密度函数、分布函数、分位函数和随机数生成函数如下：\ndlogis(x, location = 0, scale = 1, log = FALSE)\nplogis(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)\nqlogis(p, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)\nrlogis(n, location = 0, scale = 1)\n如果函数参数 location 或 scale 没有指定，则分别取默认值 0 和 1，就是标准的逻辑斯谛分布。位置参数（类似正态分布中的均值 \\(\\mu\\)）为 location = m ，尺度参数（类似正态分布中的标准差 \\(\\sigma\\)）为 scale = s，逻辑斯谛分布是一个长尾分布。\n\n30.2.2 逻辑回归\n响应变量 \\(Y\\) 服从伯努利分布 \\(\\mathrm{Bernoulli}(p)\\)，取值是 0 或 1，对线性预测 \\(X\\boldsymbol{\\beta}\\) 做 Logistic 变换\n\\[\n\\bm{p} = \\mathsf{E}Y = \\mathrm{Logistic}(X\\boldsymbol{\\beta}) = \\frac{1}{1 + e^{-(\\alpha + X\\boldsymbol{\\beta})}} = \\frac{e^{\\alpha + X\\boldsymbol{\\beta}}}{1 + e^{\\alpha + X\\boldsymbol{\\beta}}}\n\\]\nLogistic 的逆变换\n\\[\n\\mathrm{Logistic}^{-1}(\\bm{p})= \\ln\\big(\\frac{\\bm{p}}{1 - \\bm{p}}\\big) = \\alpha + X\\boldsymbol{\\beta}\n\\]\n记数据矩阵 \\(X\\) 为\n\\[\nX = \\begin{bmatrix}\n    x_{11} & x_{12} & x_{13} & \\dots  & x_{1k} \\\\\n    x_{21} & x_{22} & x_{23} & \\dots  & x_{2k} \\\\\n    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    x_{n1} & x_{n2} & x_{n3} & \\dots  & x_{nk}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\bm{x}_1^{\\top} \\\\\n\\bm{x}_2^{\\top} \\\\\n\\vdots \\\\\n\\bm{x}_n^{\\top}\n\\end{bmatrix}\n\\]\n每一行表示一次观测，每一列表示一个变量的 \\(n\\) 次观测，记 \\(X = (X_1, X_2, \\cdots, X_k)\\) 是一个 \\(n \\times k\\) 数据矩阵，其中 \\(\\bm{x}_i^{\\top}\\) 表示矩阵 \\(X\\) 的第 \\(i\\) 行，一共有 \\(n\\) 行，可以看作是 \\(1 \\times k\\) 的矩阵，\\(X_j, j = 1,2, \\cdots, k\\) 表示矩阵 \\(X\\) 的第 \\(j\\) 列，一共有 \\(k\\) 列。类似地， \\(\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\cdots, \\beta_k)^{\\top}\\) 是一个列向量，可以看作是 \\(k \\times 1\\) 的矩阵，\\(\\beta_j\\) 表示第 \\(j\\) 个变量 \\(X_j\\) 的系数。对第 \\(i\\) 次观测\n\\[\n\\mathrm{Logistic}^{-1}(p_i)= \\ln\\big(\\frac{p_i}{1-p_i}\\big) = \\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}\n\\]\n关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的似然函数如下：\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\alpha,\\boldsymbol{\\beta}) &= \\prod_{i=1}^{n} p_i^{y_i}(1 - p_i)^{1 - y_i} \\\\\n     &= \\prod_{i=1}^{n} \\Big(\\frac{e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}\\Big)^{y_i}\\Big(\\frac{1}{e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}\\Big)^{1-y_i} \\\\\n\\end{aligned}\n\\tag{30.1}\\]\n关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的对数似然函数如下：\n\\[\n\\begin{aligned}\n\\ell(\\alpha,\\boldsymbol{\\beta}) &= \\log \\mathcal{L}(\\alpha,\\boldsymbol{\\beta}) \\\\\n& = \\sum_{i=1}^{n} \\Big[y_i \\log (p_i) + (1 - y_i) \\log(1-p_i)\\Big] \\\\\n&= \\sum_{i=1}^{n} \\Big[y_i \\log \\Big(\\frac{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\Big) + (1 - y_i) \\log\\Big(\\frac{1}{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\Big)\\Big]\n\\end{aligned}\n\\tag{30.2}\\]\n对数似然函数 \\(\\ell(\\alpha,\\boldsymbol{\\beta})\\) 关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的偏导数如下：\n\\[\n\\begin{aligned}\n\\frac{\\partial \\ell(\\alpha,\\boldsymbol{\\beta})}{\\partial \\alpha}  &= \\sum_{i=1}^{n}\\Big[ \\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) \\frac{\\partial p_i}{\\partial \\alpha} \\Big] \\\\\n\\frac{\\partial \\ell(\\alpha,\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} &= \\sum_{i=1}^{n}\\Big[\\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) \\frac{\\partial p_i}{\\partial \\beta} \\Big] \\\\\n& = \\sum_{i=1}^{n}\\Big[\\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) p_i(1- p_i) \\bm{x}_i^{\\top} \\Big]\n\\end{aligned}\n\\tag{30.3}\\]\n其中， \\(p_i = \\frac{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\) ，要使 \\(\\ell(\\alpha,\\boldsymbol{\\beta})\\) 取极大值，一般通过迭代加权最小二乘算法（Iteratively (Re-)Weighted Least Squares，简称 IWLS）求解此优化问题，它可以看作拟牛顿法的一种特殊情况，在 R 语言中，函数 glm() 是求解此类问题的办法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-solvers",
    "href": "statistical-computation.html#sec-solvers",
    "title": "30  统计计算",
    "section": "\n30.3 数值优化问题求解器",
    "text": "30.3 数值优化问题求解器\n\n30.3.1 optim()\n\n从一个逻辑回归模型模拟一组样本，共 2500 条记录，即 \\(n = 2500\\)，10 个观测变量，即 \\(k=10\\)，其中，只有变量 \\(X_1\\) 和 \\(X_2\\) 的系数非零，参数设定为 \\(\\alpha = 1, \\beta_1 = 3,\\beta_2 = -2\\)，而 \\(\\beta_i = 0, i=3, \\cdots, 10\\) 模拟数据的代码如下：\n\nset.seed(2023)\nn &lt;- 2500\nk &lt;- 10\nX &lt;- matrix(rnorm(n * k), ncol = k)\ny &lt;- rbinom(n, size = 1, prob = plogis(1 + 3 * X[, 1] - 2 * X[, 2]))\n\n模拟数据矩阵 X 与上述记号 \\(X\\) 是对应的，记号 \\(\\bm{x_i}^{\\top}\\) 表示数据矩阵的第 \\(i\\) 行。\\(\\alpha\\) 是逻辑回归方程的截距，\\(\\bm{\\beta}\\) 是 \\(k\\) 维列向量，\\(X\\) 是 \\(n \\times k\\) 维的矩阵且 \\(n &gt; k\\)，\\(y\\) 是 \\(n\\) 维向量。极大化对数似然函数 方程式 30.2 ，就是求解一个多维非线性无约束优化问题。方便起见，将 \\(\\alpha\\) 合并进 \\(\\bm{\\beta}\\) 向量，另，函数 optim() 默认求极小，因此在对数似然函数前添加负号。\n\n# 目标函数\nlog_logit_lik &lt;- function(beta) {\n  p &lt;- plogis(cbind(1, X) %*% beta)\n  -sum(y * log(p) + (1 - y) * log(1 - p))\n}\n\n高维情形下，没法绘制似然函数图形，退化到二维，如 图 30.2 所示，二维情形下的逻辑回归模型的负对数似然函数曲面。\n\n\n\n\n\n\n\n图 30.2: 二维情形下的逻辑回归模型的负对数似然函数曲面\n\n\n\n\n当用 Base R 函数 optim() 来求解时，发现 Nelder-Mead 算法收敛慢，易陷入局部最优解，即使迭代 10000 次，与真值仍然相去甚远。当用 SANN （模拟退火算法）求解此 11 维非线性无约束优化问题时，迭代 10000 次后，比较接近真值。\n\noptim(\n  par = rep(1, 11), # 初始值\n  fn = log_logit_lik, # 目标函数\n  method = \"SANN\",\n  control = list(maxit = 10000)\n)\n\n#&gt; $par\n#&gt;  [1]  1.0755086156  3.2857327374 -2.1172404451 -0.0268567120  0.0184306330\n#&gt;  [6]  0.0304496968  0.0045154725  0.1283816433 -0.0746276329 -0.0624193044\n#&gt; [11] -0.0001349772\n#&gt; \n#&gt; $value\n#&gt; [1] 754.1838\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    10000       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n\n\n根据目标函数计算其梯度，有了梯度信息，可以使用迭代效率更高的 L-BFGS-B 算法。\n\n# 梯度函数\nlog_logit_lik_grad &lt;- function(beta) {\n  p &lt;- plogis(cbind(1, X) %*% beta)\n  -t((y / p - (1 - y) / (1 - p)) * p * (1 - p)) %*% cbind(1, X)\n}\n\noptim(\n  par = rep(1, 11), # 初始值\n  fn = log_logit_lik, # 目标函数\n  gr = log_logit_lik_grad, # 目标函数的梯度\n  method = \"L-BFGS-B\"\n)\n\n#&gt; $par\n#&gt;  [1]  1.00802641  3.11296713 -2.00955313  0.05855394 -0.02650585  0.01330428\n#&gt;  [7]  0.02171815  0.10213455 -0.02949774 -0.08633384  0.08098888\n#&gt; \n#&gt; $value\n#&gt; [1] 750.9724\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;       13       13 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH\"\n\n\n相比于函数 optim()，R 包 nloptr 不但可以提供类似的数值优化功能，而且可以处理各类非线性约束，能力更强。仍然基于上面的优化问题， 调用 nloptr 包求解的代码如下：\n\nlibrary(nloptr)\nnlp &lt;- nloptr(\n  x0 = rep(1, 11),\n  eval_f = log_logit_lik,\n  eval_grad_f = log_logit_lik_grad,\n  opts = list(\n    \"algorithm\" = \"NLOPT_LD_LBFGS\",\n    \"xtol_rel\" = 1.0e-8\n  )\n)\nnlp\n\n#&gt; \n#&gt; Call:\n#&gt; \n#&gt; nloptr(x0 = rep(1, 11), eval_f = log_logit_lik, eval_grad_f = log_logit_lik_grad, \n#&gt;     opts = list(algorithm = \"NLOPT_LD_LBFGS\", xtol_rel = 1e-08))\n#&gt; \n#&gt; \n#&gt; Minimization using NLopt version 2.7.1 \n#&gt; \n#&gt; NLopt solver status: 3 ( NLOPT_FTOL_REACHED: Optimization stopped because \n#&gt; ftol_rel or ftol_abs (above) was reached. )\n#&gt; \n#&gt; Number of Iterations....: 23 \n#&gt; Termination conditions:  xtol_rel: 1e-08 \n#&gt; Number of inequality constraints:  0 \n#&gt; Number of equality constraints:    0 \n#&gt; Optimal value of objective function:  750.97235708148 \n#&gt; Optimal value of controls: 1.008028 3.112977 -2.009557 0.05854534 -0.02650855 0.01330416 0.02171839 \n#&gt; 0.1021212 -0.02949994 -0.08632463 0.08098663\n\n\n如果对数似然函数是多模态的，一般的求解器容易陷入局部最优解，推荐用 nloptr 包的全局优化求解器。\n\n30.3.2 glm()\n\nBase R 提供的函数 glm() 拟合模型，指定联系函数为 logit 变换。\n\nfit_r &lt;- glm(y ~ X, family = binomial(link = \"logit\"))\nsummary(fit_r)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = y ~ X, family = binomial(link = \"logit\"))\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  1.00803    0.07395  13.631   &lt;2e-16 ***\n#&gt; X1           3.11298    0.13406  23.222   &lt;2e-16 ***\n#&gt; X2          -2.00956    0.09952 -20.192   &lt;2e-16 ***\n#&gt; X3           0.05855    0.06419   0.912    0.362    \n#&gt; X4          -0.02651    0.06588  -0.402    0.687    \n#&gt; X5           0.01330    0.06461   0.206    0.837    \n#&gt; X6           0.02172    0.06496   0.334    0.738    \n#&gt; X7           0.10212    0.06279   1.626    0.104    \n#&gt; X8          -0.02950    0.06474  -0.456    0.649    \n#&gt; X9          -0.08632    0.06482  -1.332    0.183    \n#&gt; X10          0.08099    0.06385   1.268    0.205    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 3381.4  on 2499  degrees of freedom\n#&gt; Residual deviance: 1501.9  on 2489  degrees of freedom\n#&gt; AIC: 1523.9\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 6\n\n\n或者也可以用函数 glm.fit()，效果类似，使用方式不同罢了。\n\nfit_r2 &lt;- glm.fit(x = cbind(1, X), y = y, family = binomial(link = \"logit\"))\ncoef(fit_r2)\n\n#&gt;  [1]  1.00802820  3.11297679 -2.00955727  0.05854534 -0.02650855  0.01330416\n#&gt;  [7]  0.02171839  0.10212118 -0.02949994 -0.08632463  0.08098663\n\n\n函数 glm() 的参数是一个公式，函数 glm.fit() 的参数是矩阵、向量，用函数 glm() 拟合模型，其内部调用的就是函数 glm.fit()。\n\n30.3.3 glmnet 包\n调用 glmnet 包的函数 glmnet() 拟合模型，指定指数族的具体形式为二项分布，伯努利分布是二项分布的特殊形式，也叫两点分布或0-1分布。\n\nlibrary(Matrix)\nlibrary(glmnet)\nfit_glm &lt;- glmnet(x = X, y = y, family = \"binomial\")\n\n逻辑回归模型系数在 L1 正则下的迭代路径图\n\nplot(fit_glm, ylab = \"回归系数\")\n\n\n\n\n\n\n图 30.3: 回归系数的迭代路径\n\n\n\n\n从图可见，剩余两个系数是非零的，一个是 3， 一个是 -2，其余都被压缩，而接近为 0 了。\n\nplot(fit_glm$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\",\n  main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\n图 30.4: 惩罚系数的迭代路径\n\n\n\n\n随着迭代的进行，惩罚系数 \\(\\lambda\\) 越来越小，接近于 0，这也是符合预期的，因为模型本来就是简单的逻辑回归，不带惩罚项。选择一个迭代趋于稳定时的 \\(\\lambda\\) 比如 0.0005247159，此时各个参数的取值如下：\n\ncoef(fit_glm, s = 0.0005247159)\n\n#&gt; 11 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       s1\n#&gt; (Intercept)  0.997741857\n#&gt; V1           3.076358149\n#&gt; V2          -1.984018387\n#&gt; V3           0.052633923\n#&gt; V4          -0.020195037\n#&gt; V5           0.008065018\n#&gt; V6           0.015936357\n#&gt; V7           0.095722046\n#&gt; V8          -0.023589159\n#&gt; V9          -0.080864640\n#&gt; V10          0.075234011\n\n\n截距 (Intercept) 对应 \\(\\alpha = 0.997741857\\)，而 \\(\\beta_1 = 3.076358149\\) 对应 V1，\\(\\beta_2 = -1.984018387\\) 对应 V2，以此类推。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-evaluation-model-performance",
    "href": "statistical-computation.html#sec-evaluation-model-performance",
    "title": "30  统计计算",
    "section": "\n30.4 评估模型的分类效果",
    "text": "30.4 评估模型的分类效果\n逻辑回归模型是二分类模型，评估模型的分类效果，两个办法。\n\n可以用 AUC 指标或者 ROC 曲线，pROC 包和 ROCR 包都可以绘制 ROC 曲线。\n可以用 Wilcoxon 检验，越显著表示分类效果越好。\n\n\n30.4.1 ROC 曲线和 AUC 值\nROC 是 Receiver Operating Characteristic 简写。随机抽取 2000 个样本作为训练集，余下的数据作为测试集。\n\ndat &lt;- cbind.data.frame(X, y)\nset.seed(20232023)\nidx &lt;- sample(x = 1:nrow(dat), size = 2000, replace = F)\n# 训练集\ndat_train &lt;- dat[idx, ]\n# 测试集\ndat_test &lt;- dat[-idx, ]\n\n函数 glm() 拟合训练集数据\n\nfit_binom &lt;- glm(y ~ ., data = dat_train, family = binomial(link = \"logit\"))\n\n将训练好的模型用于测试集，调用函数 predict() 进行预测，type = \"response\" 获得预测概率值，它是对数几率，比值比的对数。\n\ndat_test$pred &lt;- predict(fit_binom, newdata = dat_test, type = \"response\")\n\n返回值介于 0 - 1 之间，表示预测概率。在测试集上绘制 ROC 曲线。\n\npROC::plot.roc(\n  y ~ pred, data = dat_test,\n  col = \"dodgerblue\", print.auc = TRUE,\n  auc.polygon = TRUE, auc.polygon.col = \"#f6f6f6\",\n  xlab = \"FPR\", ylab = \"TPR\", main = \"预测 ROC 曲线\"\n)\n\n#&gt; Setting levels: control = 0, case = 1\n\n\n#&gt; Setting direction: controls &lt; cases\n\n\n\n\n\n\n\n图 30.5: ROC 曲线\n\n\n\n\nROC 曲线越往左上角拱，表示预测效果越好。FPR 是 False Positive Rate 的缩写，TPR 是 True Positive Rate 的缩写。\n\n# 计算 AUC 值\npROC::auc(y ~ pred, data = dat_test)\n\n#&gt; Setting levels: control = 0, case = 1\n\n\n#&gt; Setting direction: controls &lt; cases\n\n\n#&gt; Area under the curve: 0.9487\n\n\nAUC 是 area under curve 的缩写，表示 ROC 曲线下的面积，所以 AUC 指标越接近 1 越好。\n\n30.4.2 Wilcoxon 检验\n对每个标签的预测概率指定服从均匀分布，相当于随机猜测，所以最后 ROC 会接近对角线，而且样本量越大越接近，AUC 会越来越接近 0.5。如果预测结果比随机猜测要好，Wilcoxon 检验会显著，预测效果越好检验会越显著，表示预测 pred 和观测 y 越接近。\n\nwilcox.test(pred ~ y, data = dat_test)\n\n#&gt; \n#&gt;  Wilcoxon rank sum test with continuity correction\n#&gt; \n#&gt; data:  pred by y\n#&gt; W = 3140, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, 和 Robert Tibshirani. 2004. 《Least angle regression》. The Annals of Statistics 32 (2): 407–99. https://doi.org/10.1214/009053604000000067.\n\n\nKim, Yongdai, Hosik Choi, 和 Hee-Seok Oh. 2008. 《Smoothly Clipped Absolute Deviation on High Dimensions》. Journal of the American Statistical Association 103 (484): 1665–73. https://doi.org/10.1198/016214508000001066.\n\n\nTibshirani, Robert. 1996. 《Regression Shrinkage and Selection via the Lasso》. Journal of the Royal Statistical Society. Series B (Methodological) 58 (1): 267–88. http://www.jstor.org/stable/2346178.\n\n\nZhang, Cun-Hui. 2010. 《Nearly unbiased variable selection under minimax concave penalty》. The Annals of Statistics 38 (2): 894–942. https://doi.org/10.1214/09-AOS729.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html",
    "href": "numerical-optimization.html",
    "title": "31  数值优化",
    "section": "",
    "text": "31.1 线性优化\n线性优化是指目标函数和约束条件都是线性的优化问题。考虑如下线性优化问题：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & -6x_1 -5x_2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    x_1  + 4x_2 \\leq 16\\\\\n    6x_1 + 4x_2 \\leq 28\\\\\n    2x_1 - 5x_2 \\leq 6\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n其中，目标函数是 \\(-6x_1 -5x_2\\)，\\(\\min\\) 表示求目标函数的最小值，\\(\\boldsymbol{x} = (x_1,x_2)^{\\top}\\) 表示决策变量，无特殊说明，决策变量都取实数。\\(\\text{s.t.}\\) 是 subject to 的缩写，专指约束条件。上述线性优化问题写成矩阵形式，如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\n  \\begin{bmatrix}\n  -6  \\\\\n  -5\n  \\end{bmatrix}\n  ^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\left\\{\n\\begin{array}{l}\n  \\begin{bmatrix}\n  1 & 4  \\\\\n  6 & 4  \\\\\n  2 & -5\n  \\end{bmatrix}\n  \\boldsymbol{x} \\leq\n  \\begin{bmatrix}\n   16 \\\\\n   28 \\\\\n   6\n  \\end{bmatrix}\n\\end{array} \\right.\n\\end{aligned}\n\\]\n用 \\(\\boldsymbol{d}\\) 表示目标函数的系数向量，\\(A\\) 表示约束矩阵，\\(\\boldsymbol{b}\\) 表示右手边的向量。上述优化问题用矩阵表示，如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\n  \\boldsymbol{d}^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad &\n  A\\boldsymbol{x} \\leq\n  \\boldsymbol{b}\n\\end{aligned}\n\\]\n用 ROI 包提供的一套使用语法表示该线性优化问题，代码如下：\n# 定义优化问题\nop &lt;- OP(\n  objective = L_objective(L = c(-6, -5)),\n  constraints = L_constraint(\n    L = matrix(c(\n      1, 4,\n      6, 4, \n      2, -5\n    ), ncol = 2, byrow = TRUE),\n    dir = c(\"&lt;=\", \"&lt;=\", \"&lt;=\"),\n    rhs = c(16, 28, 6)\n  ),\n  types = c(\"C\", \"C\"),\n  maximum = FALSE\n)\n# 优化问题描述\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n# 求解优化问题\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1] 2.4 3.4\n\n# 目标函数值\nres$objval\n\n#&gt; [1] -31.4\n函数 OP() 定义一个优化问题，参数如下：\n不同类型的目标函数和约束条件组合在一起可以构成非常丰富的优化问题。ROI 包支持的目标函数、约束条件及相应的代码见下表。后续将根据优化问题，逐个介绍用法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-linear-optimization",
    "href": "numerical-optimization.html#sec-linear-optimization",
    "title": "31  数值优化",
    "section": "",
    "text": "objective ：指定目标函数，用函数 L_objective() 表示线性优化中的目标函数，函数名中 L 表示 Linear（线性），包含数值型向量。\n\nconstraints ：指定约束条件，用函数 L_constraint() 表示线性优化中的约束条件，函数名中 L 表示 Linear（线性），包含约束矩阵 \\(A\\) ，约束分量的方向可为 &gt;= 、&lt;= 或 = ，本例中为 &lt;=，右手边的向量 \\(b\\) 。\n\ntypes ：指定决策变量的类型，分三种情况， B 表示 0-1 变量，字母 B 是 binary 的意思，I 表示整型变量，字母 I 是 integer 的意思，C 表示数值型变量，字母 C 是 continuous 的意思。本例中，两个变量都是连续型的，types = c(\"C\", \"C\") 。\n\nmaximum ：指定目标函数需要求极大还是极小，默认求极小，取值为逻辑值 TRUE 或 FALSE。\n\n\n\n\nROI 包可以表示的目标函数和约束条件\n\n目标函数\n代码\n约束条件\n代码\n\n\n\n线性函数\nL_objective()\n无约束\n留空\n\n\n二次函数\nQ_objective()\n箱式约束\nV_bound()\n\n\n非线性函数\nF_objective()\n线性约束\nL_constraint()\n\n\n\n\n二次约束\nQ_constraint()\n\n\n\n\n锥约束\nC_constraint()\n\n\n\n\n非线性约束\nF_constraint()",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-quadratic-optimization",
    "href": "numerical-optimization.html#sec-quadratic-optimization",
    "title": "31  数值优化",
    "section": "\n31.2 凸二次优化",
    "text": "31.2 凸二次优化\n二次优化分严格凸二次和非严格凸二次优化问题，严格凸要求矩阵对称正定，非严格凸要求矩阵对称半正定。对于矩阵负定的情况，不是凸优化问题，暂不考虑。二次优化的一般形式如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2}\\boldsymbol{x}^{\\top}D\\boldsymbol{x} + \\boldsymbol{d}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{x} \\leq \\boldsymbol{b}\n\\end{aligned}\n\\]\n二次优化不都是凸优化，当且仅当矩阵 \\(D\\) 半正定时，上述二次优化是凸二次优化，当矩阵 \\(D\\) 正定时，上述二次优化是严格凸二次优化。下面举个严格凸二次优化的具体例子，令\n\\[\nD = \\begin{bmatrix}\n2 & -1\\\\\n-1 & 2\n\\end{bmatrix}, \\quad\n\\boldsymbol{d} =  \n\\begin{bmatrix}\n3 \\\\\n-2\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n-1 & -1  \\\\\n1 & -1 \\\\\n0  & 1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n-2 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n即目标函数\n\\[\nQ(x_1,x_2) = x_1^2 + x_2^2 - x_1 x_2 + 3x_1- 2x_2\n\\]\n二次优化中的数据矩阵和向量 \\(D,\\boldsymbol{d},A,\\boldsymbol{b}\\) 依次用 Dmat、dvec、Amat、bvec 表示出来。\n\nDmat &lt;- matrix(c(2, -1, -1, 2), nrow = 2, byrow = TRUE)\ndvec &lt;- c(3, -2)\nAmat &lt;- matrix(c(-1, -1, 1, -1, 0, 1), ncol = 2, byrow = TRUE)\nbvec &lt;- c(-2, 2, 3)\n\n同样，也是在函数 OP()中传递目标函数，约束条件。在函数 Q_objective() 中定义二次优化的目标函数，字母 Q 是 Quadratic 的意思，表示二次部分，字母 L 是 Linear 的意思，表示线性部分。函数 L_constraint() 的使用同线性优化，不再赘述。根据 ROI 包的使用接口定义的参数，定义目标优化。\n\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(L = Amat, dir = rep(\"&lt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\nnloptr 包有许多优化求解器，可用于求解二次优化的也有好几个。对于一个目标优化，函数 ROI_applicable_solvers() 可以找到能够求解此优化问题的求解器。\n\nROI_applicable_solvers(op)\n\n#&gt; [1] \"nloptr.cobyla\" \"nloptr.mma\"    \"nloptr.auglag\" \"nloptr.isres\" \n#&gt; [5] \"nloptr.slsqp\"  \"quadprog\"\n\n\n下面使用其中的 nloptr.slsqp 来求解。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 2))\nnlp$objval\n\n#&gt; [1] -0.08333333\n\nnlp$solution\n\n#&gt; [1] 0.1666667 1.8333333\n\n\n作为对比，移除线性不等式约束，求解无约束优化问题。目标函数仍然是二次型，但是已经没有线性约束条件，所以不是二次优化问题，再用求解器 nloptr.slsqp 求解的结果已不是无约束优化的解。\n\nop2 &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  maximum = FALSE\n)\nop2\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 0 constraints\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\nnlp2 &lt;- ROI_solve(op2, solver = \"nloptr.slsqp\", start = c(1, 2))\nnlp2$objval\n\n#&gt; [1] -1\n\nnlp2$solution\n\n#&gt; [1] 0 1\n\n\n在可行域上画出等高线，标记目标解的位置， 图 31.2 展示无约束和有约束条件下的解。图中橘黄色线围成的三角形区域是可行域，红点表示无约束下求解器 nloptr.slsqp 获得的解 \\((0,1)\\) ，真正的无约束解是蓝点所在位置为 \\((-4/3,1/3)\\) ，黄点表示线性约束下求解器 nloptr.slsqp 获得的解 \\((1/6,11/6)\\) 。所以，不能用二次优化的求解器去求解无约束的二次优化问题。\n\n代码# 约束解\nqp_sol &lt;- nlp$solution\n# 无约束解\nuc_sol &lt;- nlp2$solution\ndat &lt;- expand.grid(x1 = seq(-2, 5.5, length.out = 50), \n                   x2 = seq(-1, 3.5, length.out = 50))\n# 二次优化的目标函数\ndat$fn &lt;- with(dat, x1^2 + x2^2 - x1 * x2 + 3 * x1 - 2 * x2)\nlevelplot(fn ~ x1 * x2, data = dat, aspect = .7,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  xlim = c(-2.2, 5.7), ylim = c(-1.1, 3.6),\n  panel = function(...) {\n    panel.levelplot(...)\n    panel.polygon(x = c(2, 5, -1), y = c(0, 3, 3),\n      border = \"orange\", lwd = 2, col = \"transparent\"\n    )\n    panel.points(\n      x = c(uc_sol[1], qp_sol[1], -4/3),\n      y = c(uc_sol[2], qp_sol[2], 1/3),\n      lwd = 5, col = c(\"red\", \"yellow\", \"blue\"), pch = 19\n    )\n  },\n  # 减少图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = 0, units = \"inches\"),\n      right.padding = list(x = 0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ), contour = TRUE, colorkey = TRUE,\n  col.regions = hcl.colors\n)\n\n\n\n\n\n\n图 31.2: 对比无约束和有约束条件下的解\n\n\n\n\nquadprog 包在求解约束条件下的严格凸二次优化问题时，同时给出无约束条件下的解。这个包自定义了一套二次优化问题的符号，查看求解函数 solve.QP() 的说明，略作对应后，求解上述优化问题的代码如下。\n\nlibrary(quadprog)\nsol &lt;- solve.QP(\n  Dmat = Dmat, dvec = -dvec, Amat = t(-Amat), bvec = -bvec\n)\nsol\n\n#&gt; $solution\n#&gt; [1] 0.1666667 1.8333333\n#&gt; \n#&gt; $value\n#&gt; [1] -0.08333333\n#&gt; \n#&gt; $unconstrained.solution\n#&gt; [1] -1.3333333  0.3333333\n#&gt; \n#&gt; $iterations\n#&gt; [1] 2 0\n#&gt; \n#&gt; $Lagrangian\n#&gt; [1] 1.5 0.0 0.0\n#&gt; \n#&gt; $iact\n#&gt; [1] 1\n\n\n其中，返回值的 unconstrained.solution 表示无约束下的解，与预期的解一致，这就没有疑惑了。可见，约束二次优化问题和无约束二次优化问题的求解器不同。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-cone-optimization",
    "href": "numerical-optimization.html#sec-cone-optimization",
    "title": "31  数值优化",
    "section": "\n31.3 凸锥优化",
    "text": "31.3 凸锥优化\n\n31.3.1 锥与凸锥\n二维平面上，圆盘和扇面是凸锥。三维空间中，球，圆锥、椭球、椭圆锥都是凸锥，如 图 31.3 所示。\n\n\n\n\n\n\n\n图 31.3: 常见的三维凸锥\n\n\n\n\n锥定义在对称的矩阵上，凸锥要求矩阵正定。一个 2 阶对称矩阵 \\(A\\) 是正定的\n\\[\nA = \\begin{bmatrix}\n  a_{11} & a_{12}  \\\\\n  a_{21} & a_{22}  \n  \\end{bmatrix}\n\\]\n意味着 \\(a_{11} &gt; 0, a_{22} &gt; 0, a_{12} = a_{21}, a_{11}a_{22} - a_{12}a_{21} &gt; 0\\) 。一般地，将 \\(n\\) 阶半正定的对称矩阵 \\(A\\) 构成的集合记为 \\(\\mathcal{K}_{+}^n\\) 。\n\\[\n\\mathcal{K}_{+}^n = \\{A \\in \\mathbb{R}^{n \\times n}|\\boldsymbol{x}^{\\top}A\\boldsymbol{x} \\geq 0, ~ \\forall \\boldsymbol{x} \\in \\mathbb{R}^n\\}\n\\]\n目标函数为线性的凸锥优化的一般形式如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\\boldsymbol{d}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{x} + \\boldsymbol{k} = \\boldsymbol{b} \\\\\n& \\boldsymbol{k} \\in \\mathcal{K}.\n\\end{aligned}\n\\]\n其中，集合 \\(\\mathcal{K}\\) 是一个非空的封闭凸锥。在一个凸锥里，寻求一个线性目标函数的最小值。专门求解此类问题的 scs 包也在 ROI 包的支持范围内，可以求解的锥优化包括零锥、线性锥、二阶锥、指数锥、幂锥和半正定锥。\n下面举个例子说明凸锥，含参对称矩阵 \\(A(m_1,m_2,m_3)\\) 如下：\n\\[\nA(m_1,m_2,m_3) = \\begin{bmatrix}\n  1 & m_1 & m_2  \\\\\n  m_1 & 1 & m_3  \\\\\n  m_2 & m_3 & 1\n  \\end{bmatrix}.\n\\]\n而 \\(\\boldsymbol{k} = \\boldsymbol{b} - A\\boldsymbol{x}\\) 是非空封闭凸锥集合 \\(\\mathcal{K}\\) 中的元素。半正定矩阵 \\(A\\) 生成的集合（凸锥） \\(K\\) 如下：\n\\[\nK = \\{ (m_1,m_2,m_3) \\in \\mathbb{R}^3 \\mid A(m_1,m_2,m_3) \\in \\mathcal{K}_{+}^3 \\},\n\\]\n集合 \\(K\\) 是有界半正定的，要求含参矩阵 \\(A\\) 的行列式大于等于 0。 矩阵 \\(A\\) 的行列式如下：\n\\[\n\\det(A(m_1,m_2,m_3)) = - (m_1^2 + m_2^2 + m_3^2 -2m_1 m_2 m_3 -1)\n\\]\n集合 \\(K\\) 的边界可表示为如下方程的解：\n\\[\nm_1^2 + m_2^2 + m_3^2 -2m_1 m_2 m_3 = 1\n\\]\n或等价地表示为如下矩阵形式：\n\\[\n\\begin{split}\\left[\n\\begin{array}{c}\nm_1\\\\m_2\n\\end{array}\\right]^{\\top}\n\\left[\\begin{array}{rr}\n1 & -m_3\\\\-m_3 &1\n\\end{array}\\right]\n\\left[\\begin{array}{c}\nm_1\\\\m_2\n\\end{array}\\right] = 1 - m_3^2.\n\\end{split}\n\\]\n当 \\(m_3 = 0\\) 时，集合 \\(K\\) 的边界表示平面上的一个单位圆，当 \\(m_3 \\in [-1, 1]\\) ，集合 \\(K\\) 的边界表示一个椭圆。为了获得一个直观的印象，将集合 \\(K\\) 的边界绘制出来，如 图 31.3 所示，边界是一个三维曲面，曲面及其内部构成一个凸锥。\n\n代码# 分两部分绘图\nfn1 &lt;- function(x) {\n  x[1] * x[2] + sqrt(x[1]^2 * x[2]^2 - x[1]^2 - x[2]^2 + 1)\n}\n\nfn2 &lt;- function(x) {\n  x[1] * x[2] - sqrt(x[1]^2 * x[2]^2 - x[1]^2 - x[2]^2 + 1)\n}\n\ndf2 &lt;- df1 &lt;- expand.grid(\n  x = seq(-1, 1, length.out = 51),\n  y = seq(-1, 1, length.out = 51)\n)\n\n# 计算函数值\ndf1$fnxy &lt;- apply(df1, 1, fn1)\ndf2$fnxy &lt;- apply(df2, 1, fn2)\n# 添加分组变量\ndf1$group &lt;- \"1\"\ndf2$group &lt;- \"2\"\n# 合并数据\ndf &lt;- rbind(df1, df2)\n\n# 绘图\nwireframe(\n  data = df, fnxy ~ x * y, groups = group,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(m[1]),\n  ylab = expression(m[2]),\n  zlab = expression(m[3]),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 31.4: 锥\n\n\n\n\n\n31.3.2 零锥\n零锥的定义如下：\n\\[\n\\mathcal{K}_{zero} = \\{0\\}\n\\]\n常用于表示线性等式约束。\n\n31.3.3 线性锥\n线性锥（Linear Cone）的定义如下：\n\\[\n\\mathcal{K}_{lin} = \\{x \\in \\mathbb{R}|x \\geq 0\\}\n\\]\n常用于表示线性不等式约束。\n\n31.3.4 二阶锥\n二阶锥（Second-order Cone）的定义如下：\n\\[\n\\mathcal{K}_{soc}^{n} = \\{(t,x) \\in \\mathbb{R}^n|x \\in \\mathbb{R}^{n-1}, t\\in\\mathbb{R},\\| x \\|_2 \\leq t\\}\n\\]\n常用于凸二次优化问题。考虑如下二阶锥优化 SOCP 问题：\n\\[\n\\begin{aligned}\n\\max_{(\\boldsymbol{y},t)} \\quad & y_1 + y_2 \\\\\n\\text{s.t.} \\quad & \\sqrt{(2 + 3y_1)^2 + (4+5y_2)^2} \\leq 6 + 7t \\\\\n& y_1,y_2 \\in \\mathbb{R}, ~~ t \\in (-\\infty,9].\n\\end{aligned}\n\\]\n令 \\(\\boldsymbol{x} = (y_1, y_2, t)^{\\top}\\) ，\\(\\boldsymbol{b} = (b_1,b_2,b_3)^\\top\\)\n\\[\nA = \\begin{bmatrix}\n\\boldsymbol{a_1}^{\\top}\\\\\n\\boldsymbol{a_2}^{\\top}\\\\\n\\boldsymbol{a_3}^{\\top}\n\\end{bmatrix}\n\\]\n上述 SOCP 问题的非线性不等式约束等价于\n\\[\n\\sqrt{(b_2 - \\boldsymbol{a_2}^{\\top}\\boldsymbol{x})^2 + (b_3 -\\boldsymbol{a_3}^{\\top}\\boldsymbol{x})^2} \\leq b_1 - \\boldsymbol{a_1}^{\\top}\\boldsymbol{x}\n\\]\n其中，\n\\[\nA = \\begin{bmatrix}\n0 & 0 & -7  \\\\\n-3 & 0 & 0  \\\\\n0 & -5 & 0\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n6 \\\\\n2 \\\\\n4\n\\end{bmatrix}\n\\]\nscs 包不能求解此类优化问题，下面调用 ECOSolveR 包求解。\n\nlibrary(ROI.plugin.ecos)\nop &lt;- OP(\n  objective = c(1, 1, 0),\n  constraints = C_constraint(\n    L = rbind(\n      c(0, 0, -7),\n      c(-3, 0, 0),\n      c(0, -5, 0)\n    ),\n    cones = K_soc(3), rhs = c(6, 2, 4)\n  ), maximum = TRUE,\n  bounds = V_bound(ld = -Inf, ui = 3, ub = 9, nobj = 3)\n)\nsol &lt;- ROI_solve(op, solver = \"ecos\")\n# 最优解\nsol$solution\n\n#&gt; [1] 19.055671  6.300041  9.000000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 25.35571\n\n\n对决策变量 \\(y_1\\) 添加整数约束，则只有 ECOSolveR 包可以求解。\n\nop &lt;- OP(\n  objective = c(1, 1, 0),\n  constraints = C_constraint(\n    L = rbind(\n      c(0, 0, -7),\n      c(-3, 0, 0),\n      c(0, -5, 0)\n    ),\n    cones = K_soc(3), rhs = c(6, 2, 4)\n  ), maximum = TRUE, \n  # 决策变量约束\n  types = c(\"I\", \"C\", \"C\"), \n  bounds = V_bound(ld = -Inf, ui = 3, ub = 9, nobj = 3)\n)\nsol &lt;- ROI_solve(op, solver = \"ecos\")\n# 最优解\nsol$solution\n\n#&gt; [1] 19.000000  6.355418  9.000000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 25.35542\n\n\n\n31.3.5 指数锥\n指数锥（Exponential Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{expp}} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_2 &gt; 0,x_2\\exp\\big(\\frac{x_1}{x_2}\\big) \\leq x_3\\} \\cup \\{(x_1, 0, x_3) \\in \\mathbb{R}^3 | x_1 \\leq 0, x_3 \\geq 0 \\}\n\\]\n它的对偶如下：\n\\[\n\\mathcal{K}_{\\text{expd}} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1 &lt; 0, - x_1\\exp\\big(\\frac{x_2}{x_1}\\big) \\leq \\exp(1)x_3\\} \\cup \\{(0, x_2, x_3) \\in \\mathbb{R}^3 | x_2 , x_3 \\geq 0 \\}\n\\]\n考虑一个锥优化问题\n\\[\n\\begin{aligned}\n\\max_{(\\boldsymbol{x}, \\boldsymbol{t})} \\quad & x_1 + 2 x_2 \\\\\n\\text{s.t.} \\quad & \\exp(7 + 3x_1 + 5 x_2) \\leq 9 + 11 t_1 + 12t_2 \\\\\n\\quad & x_1,x_2 \\in (-\\infty,20], ~ t_1,t_2 \\in (-\\infty, 50]\n\\end{aligned}\n\\]\n约束条件 \\(\\exp(7 + 3x_1 + 5 x_2) \\leq 9 + 11 t_1 + 12t_2\\) 可以用指数锥来表示\n\\[\n\\begin{aligned}\nu &= 7 + 3y_1 + 5y_2 \\\\\nv &= 1 \\\\\nw &= 9 + 11t_1 + 12t_2\n\\end{aligned}\n\\]\n记 \\(\\boldsymbol{x} = (y_1,y_2,t_1,t_2)^{\\top}\\) ，则线性约束矩阵 \\(A\\) 和约束向量 \\(\\boldsymbol{b}\\) 如下：\n\\[\nA = \\begin{bmatrix}\n-3 & -5 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & -11 & -12\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n7 \\\\\n1 \\\\\n9\n\\end{bmatrix}\n\\]\n指数锥用函数 K_expp() 表示，锥优化问题的代码如下：\n\n# 目标优化\nop &lt;- OP(\n  objective = c(1, 2, 0, 0),\n  # 锥约束\n  constraints = C_constraint(L = rbind(\n    c(-3, -5, 0, 0),\n    c(0, 0, 0, 0),\n    c(0, 0, -11, -12)\n  ), cone = K_expp(1), rhs = c(7, 1, 9)),\n  bounds = V_bound(ld = -Inf, ub = c(20, 20, 50, 50)),\n  maximum = TRUE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 4 with\n#&gt; - 4 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'expp'\n#&gt; - 4 lower and 4 upper non-standard variable bounds.\n\n\n对于锥优化，可以调用 scs 包来求解。\n\n# 调用 scs 包\nlibrary(ROI.plugin.scs)\nsol &lt;- ROI_solve(op, solver = \"scs\")\n# 最优解\nsol$solution\n\n#&gt; [1] -33.3148  20.0000  50.0000  50.0000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 6.685201\n\n\n\n31.3.6 幂锥\n一个三维幂锥（Power Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{powp}}^{\\alpha} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1,x_2 \\geq 0,x_1^{\\alpha}x_2^{1-\\alpha} \\geq |x_3| \\}, \\alpha \\in [0,1]\n\\]\n它的对偶形式如下：\n\\[\n\\mathcal{K}_{\\text{powp}}^{\\alpha} = \\Big\\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1,x_2 \\geq 0,\\big(\\frac{x_1}{\\alpha}\\big)^{\\alpha}\\big(\\frac{x_2}{1 - \\alpha}\\big)^{1-\\alpha} \\geq |x_3| \\Big\\}, \\alpha \\in [0,1]\n\\]\n考虑如下锥优化问题\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & 3x_1 + 5 x_2 \\\\\n\\text{s.t.} \\quad & 5 + x_1 \\leq (2 + x_2)^4 \\\\\n\\quad & x_1 \\geq 0, ~ x_2 \\geq 2\n\\end{aligned}\n\\]\n约束条件 \\(5 + x_1 \\leq (2 + x_2)^4\\) 可以重新表示为幂锥\n\\[\n\\begin{aligned}\nu &= 5 + y_1\\\\\nv &= 1 \\\\\nw &= 2 + y_2 \\\\\n\\alpha &= 1/4\n\\end{aligned}\n\\]\n记 \\(\\boldsymbol{x} = (y_1,y_2)^{\\top}\\) ，约束矩阵和约束向量如下\n\\[\nA = \\begin{bmatrix}\n-1  & 0 \\\\\n0   & 0 \\\\\n0   & -1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n5 \\\\\n1 \\\\\n2\n\\end{bmatrix}\n\\]\n幂锥用函数 K_powp() 表示，锥优化问题的代码如下：\n\nA &lt;- rbind(c(-1, 0), c(0, 0), c(0, -1))\ncpowp &lt;- C_constraint(L = A, cones = K_powp(1 / 4), rhs = c(5, 1, 2))\nop &lt;- OP(\n  objective = c(3, 5),\n  constraints = cpowp,\n  bounds = V_bound(lb = c(0, 2))\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'powp'\n#&gt; - 1 lower and 0 upper non-standard variable bounds.\n\n\n\nsol &lt;- ROI_solve(op, solver = \"scs\", max_iter = 1e6)\n# 最优解\nsol$solution\n\n#&gt; [1] 250.998234   2.000352\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 762.9965\n\n\n\n31.3.7 半正定锥\n如果矩阵 \\(A\\) 是半正定的，记为 \\(A \\succeq 0\\) ，如果矩阵 \\(A\\) 是正定的，记为 \\(A \\succ 0\\) 。记 \\(n\\) 阶实对称矩阵的集合为 \\(\\mathcal{S}^{n}\\) 。半正定锥（Positive Semi Definite Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{psd}}^{n} = \\{A | A \\in \\mathcal{S}^{n}, \\boldsymbol{x}^{\\top}A\\boldsymbol{x} \\geq 0, \\forall \\boldsymbol{x} \\in \\mathbb{R}^n \\}\n\\]\n考虑如下锥优化问题\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & x_1 + x_2 - x_3 \\\\\n\\text{s.t.} \\quad &\nx_1 \\begin{bmatrix}\n10  & 3 \\\\\n3   & 10\n\\end{bmatrix} +\nx_2 \\begin{bmatrix}\n6  & -4 \\\\\n-4   & 10\n\\end{bmatrix} +\nx_3 \\begin{bmatrix}\n8  & 1 \\\\\n1  & 6\n\\end{bmatrix} \\preceq\n\\begin{bmatrix}\n16  & -13 \\\\\n-13  & 60\n\\end{bmatrix}\n\\\\\n\\quad & x_1,x_2,x_3 \\geq 0\n\\end{aligned}\n\\]\n函数 K_psd() 表示半正定锥，函数 vech() 将对称矩阵的上三角部分拉成一个向量。\n\n(A &lt;- toeplitz(x = 3:1))\n\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    3    2    1\n#&gt; [2,]    2    3    2\n#&gt; [3,]    1    2    3\n\nvech(A)\n\n#&gt;      [,1]\n#&gt; [1,]    3\n#&gt; [2,]    2\n#&gt; [3,]    1\n#&gt; [4,]    3\n#&gt; [5,]    2\n#&gt; [6,]    3\n\n\n锥优化的表示如下\n\nF1 &lt;- rbind(c(10, 3), c(3, 10))\nF2 &lt;- rbind(c(6, -4), c(-4, 10))\nF3 &lt;- rbind(c(8, 1), c(1, 6))\nF0 &lt;- rbind(c(16, -13), c(-13, 60))\n# 目标优化\nop &lt;- OP(\n  objective = L_objective(c(1, 1, -1)),\n  constraints = C_constraint(\n    L = vech(F1, F2, F3),\n    cones = K_psd(3),\n    rhs = vech(F0)\n  )\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 3 with\n#&gt; - 3 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'psd'\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n仍然调用 scs 包求解器。\n\nsol &lt;- ROI_solve(op, solver = \"scs\")\n# 最优解\nsol$solution\n\n#&gt; [1] 5.782736e-06 1.065260e-06 1.486444e+00\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] -1.486437",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-nonlinear-optimization",
    "href": "numerical-optimization.html#sec-nonlinear-optimization",
    "title": "31  数值优化",
    "section": "\n31.4 非线性优化",
    "text": "31.4 非线性优化\n非线性优化按是否带有约束，以及约束是线性还是非线性，分为无约束优化、箱式约束优化、线性约束优化和非线性约束优化。箱式约束可看作是线性约束的特殊情况。\n\nR 软件内置的非线性优化函数\n\n\nnlm()\nnlminb()\nconstrOptim()\noptim()\n\n\n\n无约束\n支持\n支持\n不支持\n支持\n\n\n箱式约束\n不支持\n支持\n支持\n支持\n\n\n线性约束\n不支持\n不支持\n支持\n不支持\n\n\n\nR 软件内置的 stats 包有 4 个数值优化方面的函数，函数 nlm() 可求解无约束优化问题，函数 nlminb() 可求解无约束、箱式约束优化问题，函数 constrOptim() 可求解箱式和线性约束优化。函数 optim() 是通用型求解器，包含多个优化算法，可求解无约束、箱式约束优化问题。尽管这些函数在 R 语言中长期存在，在统计中有广泛的使用，如非线性最小二乘 stats::nls()，极大似然估计 stats4::mle() 和广义最小二乘估计 nlme::gls() 等。但是，这些优化函数的求解能力有重合，使用语法不尽相同，对于非线性约束无能为力，下面仍然主要使用 ROI 包来求解多维非线性优化问题。\n\n31.4.1 一元非线性优化\n求如下一维分段非线性函数的最小值，其函数图像见 图 31.5 ，这个函数是不连续的，更不光滑。\n\\[\nf(x) =\n\\begin{cases}\n10 & x \\in (-\\infty,-1]  \\\\\n\\exp(-\\frac{1}{|x-1|}) & x \\in (-1,4) \\\\\n10 & x \\in [4, +\\infty)\n\\end{cases}\n\\]\n\nfn &lt;- function(x) ifelse(x &gt; -1, ifelse(x &lt; 4, exp(-1 / abs(x - 1)), 10), 10)\n\n\n代码op &lt;- par(mar = c(4, 4, 0.5, 0.5))\ncurve(\n  expr = fn, from = -2, to = 5, lwd = 2,\n  panel.first = grid(),\n  xlab = \"$x$\", ylab = \"$f(x)$\"\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 31.5: 一维函数图像\n\n\n\n\n函数 optimize() 可以求解一元函数的极值问题，默认求极小值，参数 f 表示目标函数，参数 interval 表示搜索在此区间内最小值。函数返回一个列表，元素 minimum 表示极小值点，objective 表示极值点对应的目标函数值。\n\noptimize(f = fn, interval = c(-4, 20), maximum = FALSE)\n\n#&gt; $minimum\n#&gt; [1] 19.99995\n#&gt; \n#&gt; $objective\n#&gt; [1] 10\n\noptimize(f = fn, interval = c(-7, 20), maximum = FALSE)\n\n#&gt; $minimum\n#&gt; [1] 0.9992797\n#&gt; \n#&gt; $objective\n#&gt; [1] 0\n\n\n值得注意，对于不连续的分段函数，在不同的区间内搜索极值，可能获得不同的结果，可以绘制函数图像帮助选择最小值。\n\n31.4.2 多元隐函数优化\n这个优化问题来自 1stOpt 软件的帮助文档，下面利用 R 语言来求该多元隐函数的极值。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} y = & ~\\sin\\Big((yx_1 -0.5)^2 + 2x_1 x_2^2 - \\frac{y}{10} \\Big)\\cdot \\\\\n&~\\exp\\Big(-\\Big( \\big(x_1 - 0.5 -\\exp(-x_2 + y)\\big)^2 + x_2^2 - \\frac{y}{5} + 3 \\Big)\\Big)\n\\end{aligned}\n\\]\n其中， \\(x_1 \\in [-1,7],x_2 \\in [-2,2]\\) 。\n对于隐函数 \\(f(x_1,x_2,y)=0\\) ，常规的做法是先计算隐函数的偏导数，并令偏导数为 0，再求解非线性方程组，得到各个驻点，最后，将驻点代入原方程，比较驻点处函数值，根据优化目标选择最大或最小值。\n\\[\n\\begin{aligned}\n\\frac{\\partial f(x_1,x_2,y)}{\\partial x_1} = 0 \\\\\n\\frac{\\partial f(x_1,x_2,y)}{\\partial x_2} = 0\n\\end{aligned}\n\\]\n如果目标函数很复杂，隐函数偏导数难以计算，可以考虑暴力网格搜索。先估计隐函数值 \\(z\\) 的大致范围，给定 \\(x,y\\) 时，计算一元非线性方程的根。\n\nfn &lt;- function(m) {\n  subfun &lt;- function(x) {\n    f1 &lt;- (m[1] * x - 0.5)^2 + 2 * m[1] * m[2]^2 - x / 10\n    f2 &lt;- -((m[1] - 0.5 - exp(-m[2] + x))^2 + m[2]^2 - x / 5 + 3)\n    x - sin(f1) * exp(f2)\n  }\n  uniroot(f = subfun, interval = c(-1, 1))$root\n}\n\n在位置 \\((1,2)\\) 处函数值为 0.0007368468。\n\n# 测试函数 fn\nfn(m = c(1, 2))\n\n#&gt; [1] 0.0007368468\n\n\n将目标区域网格化，通过一元非线性方程求根的方式获得每个格点处的函数值。\n\ndf &lt;- expand.grid(\n  x1 = seq(from = -1, to = 7, length.out = 81),\n  x2 = seq(from = -2, to = 2, length.out = 41)\n)\n# 计算格点处的函数值\ndf$fn &lt;- apply(df, 1, FUN = fn)\n\n在此基础上，绘制隐函数图像，如 图 31.6 所示，可以获得关于隐函数的大致情况。\n\n代码# 绘图\nwireframe(\n  data = df, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 31.6: 隐函数图像\n\n\n\n\n最后，获得暴力网格搜索的结果，目标函数在 \\((2.8,-0.9)\\) 处取得最小值 \\(-0.02159723\\)。总的来说，这是一个近似结果，如果进一步缩小搜索区域，将网格划分得越细，搜索的结果将越接近全局最小值。\n\ndf[df$fn == min(df$fn), ]\n\n#&gt;      x1   x2          fn\n#&gt; 930 2.8 -0.9 -0.02159723\n\n\n将求隐函数极值的问题转为含非线性等式约束的非线性优化问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & y \\\\\n\\text{s.t.} \\quad & f(x_1,x_2,y) = 0\n\\end{aligned}\n\\]\n由于等式约束非常复杂，手动计算等式约束的雅可比矩阵不可行，可以用 numDeriv 包的函数 jacobian() 计算等式约束的雅可比矩阵。考虑到本例中仅含有一个等式约束，雅可比矩阵退化为梯度向量，这可以用 numDeriv 包的另一个函数 grad() 计算。\n\n# 等式约束\nheq &lt;- function(x) {\n  f1 &lt;- (x[1] * x[3] - 0.5)^2 + 2 * x[1] * x[2]^2 - x[3] / 10\n  f2 &lt;- (x[1] - 0.5 - exp(-x[2] + x[3]))^2 + x[2]^2 - x[3] / 5 + 3\n  x[3] - sin(f1) * exp(-f2)\n}\n# 等式约束的梯度\nheq.jac &lt;- function(x) {\n  numDeriv::grad(func = heq, x = x)\n}\n\n函数 L_objective() 表示含 1 个决策变量的线性目标函数，函数 F_constraint() 表示非线性等式约束。\n\n# 定义优化问题\nop &lt;- OP(\n  objective = L_objective(L = c(0, 0, 1)),\n  constraints = F_constraint(\n    # 等式约束\n    F = list(heq = heq),\n    dir = \"==\",\n    rhs = 0,\n    # 等式约束的雅可比\n    J = list(heq.jac = heq.jac)\n  ),\n  bounds = V_bound(\n    ld = -Inf, ud = Inf,\n    li = c(1, 2), ui = c(1, 2),\n    lb = c(-1, -2), ub = c(7, 2),\n    nobj = 3L\n  ),\n  maximum = FALSE # 求最小\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 3 with\n#&gt; - 3 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 1 constraint of type nonlinear.\n#&gt; - 3 lower and 2 upper non-standard variable bounds.\n\n\n将网格搜索的结果作为初值，继续寻找更优的目标函数值。\n\nnlp &lt;- ROI_solve(op,\n  solver = \"nloptr.slsqp\", start = c(2.8, -0.9, -0.02159723)\n)\n# 最优解\nnlp$solution\n\n#&gt; [1]  2.89826224 -0.85731584 -0.02335409\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] -0.02335409\n\n\n可以发现，更优的目标函数值 \\(-0.02335\\) 在 \\((2.898,-0.8573)\\) 取得。\n\n31.4.3 多元无约束优化\n\n31.4.3.1 示例 1\nRastrigin 函数是一个 \\(n\\) 维优化问题测试函数。\n\\[\n\\min_{\\boldsymbol{x}} \\sum_{i=1}^{n}\\big(x_i^2 - 10 \\cos(2\\pi x_i) + 10\\big)\n\\]\n计算函数值的 R 代码如下：\n\nfn &lt;- function(x) {\n  sum(x^2 - 10 * cos(2 * pi * x) + 10)\n}\n\n绘制二维情形下的 Rastrigin 函数图像，如 图 31.7 所示，这是一个多模态的函数，有许多局部极小值。如果采用 BFGS 算法寻优容易陷入局部极值点。\n\n代码df &lt;- expand.grid(\n  x = seq(-4, 4, length.out = 151),\n  y = seq(-4, 4, length.out = 151)\n)\n\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 31.7: 二维 Rastrigin 函数图像\n\n\n\n\n不失一般性，考虑函数维数 \\(n=20\\) ，决策变量 \\(x_i \\in [-50,50], i = 1,2,\\ldots,n\\) 的情况。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 20L),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 20L)\n)\n\n调全局优化器求解优化问题。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\n# 最优解\nnlp$solution\n\n#&gt;  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 0\n\n\n\n代码# R 语言内置的非线性优化函数\n# 无约束\nnlm(f = fn, p = rep(1, 20))\noptim(par = rep(1, 20), fn = fn, method = \"BFGS\")\noptim(par = rep(1, 20), fn = fn, method = \"Nelder-Mead\")\n\n# 箱式约束\noptim(par = rep(1, 20), fn = fn, \n      lower = -50, upper = 50, method = \"L-BFGS-B\")\nnlminb(start = rep(1, 20), objective = fn, lower = -50, upper = 50)\nconstrOptim(\n  theta = rep(1, 20), f = fn, grad = NULL,\n  ui = rbind(diag(rep(1, 20)), diag(rep(-1, 20))),\n  ci = c(rep(-50, 20), rep(-50, 20))\n)\n\n\n\n31.4.3.2 示例 2\n下面这个优化问题来自 1stOpt 软件帮助手册，是一个无约束非线性优化问题，它的目标函数非常复杂，一般的求解器都无法求解。最优解在 \\((7.999982, 7.999982)\\) 取得，目标函数值为 -7.978832。\n\\[\n\\begin{aligned}\n  & \\min_{\\boldsymbol{x}} ~ \\cos(x_1)\\cos(x_2) - \\sum_{i=1}^{5}\\Big( (-1)^i \\cdot i \\cdot 2 \\cdot \\exp\\big(-500 \\cdot ( (x_1 - i \\cdot 2)^2 + (x_2 - i\\cdot 2)^2 ) \\big) \\Big)\n\\end{aligned}\n\\]\n目标函数分两步计算，先计算累加部分的通项，然后代入计算目标函数。\n\nsubfun &lt;- function(i, m) {\n  (-1)^i * i * 2 * exp(-500 * ((m[1] - i * 2)^2 + (m[2] - i * 2)^2))\n}\nfn &lt;- function(x) {\n  cos(x[1]) * cos(x[2]) -\n    sum(mapply(FUN = subfun, i = 1:5, MoreArgs = list(m = x)))\n}\n\n直观起见，绘制目标函数在区域 \\([-50, 50] \\times [-50, 50]\\) 内的图像，如 图 31.8 (a) 所示，可以看到几乎没有变化的梯度，给寻优过程带来很大困难。再将区域 \\([0, 12] \\times [0, 12]\\) 上的三维图像绘制出来，如 图 31.8 (b) 所示，可见，有不少局部陷阱，且分布在 \\(x_2 = x_1\\) 的直线上。\n代码df &lt;- expand.grid(\n  x = seq(-50, 50, length.out = 101),\n  y = seq(-50, 50, length.out = 101)\n)\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\ndf &lt;- expand.grid(\n  x = seq(0, 12, length.out = 151),\n  y = seq(0, 12, length.out = 151)\n)\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90), alpha = 0.75, \n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n\n\n\n(a) 区域 \\([-50,50]\\times[-50,50]\\) 内的函数图像\n\n\n\n\n\n\n\n\n\n\n\n(b) 区域 \\([0,12]\\times[0,12]\\) 内的函数图像\n\n\n\n\n\n\n图 31.8: 局部放大前后的函数图像\n\n\n不失一般性，下面考虑 \\(x_1,x_2 \\in [-50,50]\\) ，面对如此复杂的函数，调用全局优化器 nloptr.directL 寻优。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 2L),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 2L)\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\nnlp$solution\n\n#&gt; [1]  0.00000 22.22222\n\nnlp$objval\n\n#&gt; [1] -0.9734211\n\n\n结果还是陷入局部最优解。运筹优化方面的商业软件，著名的有 Lingo 和 Matlab，下面采用 Lingo 20 求解，Lingo 代码如下：\nSETS:\nP/1..5/;\nEndsets\nMin=@cos(x1) * @cos(x2) - @Sum(P(j): (-1)^j * j * 2 * @exp(-500 * ((x1 - j * 2)^2 + (x2 - j * 2)^2)));\n@Bnd(-50, x1, 50);\n@Bnd(-50, x2, 50);\n启用全局优化求解器后，在 \\((x_1 = 7.999982, x_2 = 7.999982)\\) 取得最小值 -7.978832。而默认未启用全局优化求解器的情况下，在 \\((x_1 = 18.84956, x_2 = -40.84070)\\) 取得局部极小值 -1.000000。\n在这种情况下，数值优化算法遇到瓶颈，可以采用一些全局随机优化算法，比如 GA 包 (Scrucca 2013) 实现的遗传算法。经过对参数的一些调优，可以获得与商业软件几乎一样的结果。\n\nnlp &lt;- GA::ga(\n  type = \"real-valued\",\n  fitness = function(x) -fn(x),\n  lower = c(0, 0), upper = c(12, 12),\n  popSize = 500, maxiter = 100, \n  monitor = FALSE, seed = 20232023\n)\n# 最优解\nnlp@solution\n\n#&gt;            x1       x2\n#&gt; [1,] 7.999982 7.999981\n\n# 目标函数值\nnlp@fitnessValue\n\n#&gt; [1] 7.978832\n\n\n其中，参数 type 指定决策变量的类型，type = \"real-valued\" 表示目标函数中的决策变量是实值连续的，参数 fitness 是目标函数，函数 ga() 对目标函数求极大，所以，对当前优化问题，添加了一个负号。 参数 popSize 控制种群大小，值越大，运行时间越长，搜索范围越广，获得的全局优化解越好。对于复杂的优化问题，可以不断增加种群大小来寻优，直至增加种群大小也不能获得更好的解。参数 maxiter 控制种群进化的次数，值越大，搜索次数可以越多，获得的解越好。参数 popSize 的影响大于参数 maxiter ，减少陷入局部最优解（陷阱）的可能。根据已知条件尽可能缩小可行域，以减少种群数量，进而缩短算法迭代时间。\n\n31.4.4 多元箱式约束优化\n有如下带箱式约束的多元非线性优化问题，该示例来自函数 nlminb() 的帮助文档，如果没有箱式约束，全局极小值点在 \\((1,1,\\cdots,1)\\) 处取得。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & (x_1 - 1)^2 + 4\\sum_{i =1}^{n -1}(x_{i+1} -x_i^2)^2  \\\\\n  \\text{s.t.} \\quad &  2 \\leq x_1,x_2,\\cdots,x_n \\leq 4\n\\end{aligned}\n\\]\nR 语言编码的函数代码如下：\n\nfn &lt;- function(x) {\n  n &lt;- length(x)\n  sum(c(1, rep(4, n - 1)) * (x - c(1, x[-n])^2)^2)\n}\n\n在二维的情形下，可以绘制目标函数的三维图像，见 图 31.9 ，函数曲面和香蕉函数有些相似。\n\n代码dat &lt;- expand.grid(\n  x1 = seq(from = 0, to = 4, length.out = 41),\n  x2 = seq(from = 0, to = 4, length.out = 41)\n)\ndat$fn &lt;- apply(dat, 1, fn)\n\nwireframe(\n  data = dat, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 31.9: 类香蕉函数的曲面图\n\n\n\n\nBase R 有 3 个函数可以求解这个优化问题，分别是 nlminb() 、constrOptim()和optim() ，因此，不妨在这个示例上，用这 3 个函数分别求解该优化问题，介绍它们的用法，最后，介绍 ROI 包实现的方法。这个优化问题的目标函数是 \\(n\\) 维非线性的，不失一般性，又不让问题变得太过简单，下面考虑 25 维的情况，\n\n31.4.4.1 nlminb()\n\n函数 nlminb() 参数 start 指定迭代初始值，参数 objective 指定目标函数，参数 lower 和 upper 分别指定箱式约束中的下界和上界。给定初值 \\((3, 3, \\cdots, 3)\\)，下界 \\((2,2,\\cdots,2)\\) 和上界 \\((4,4,\\cdots,4)\\) 。nlminb() 帮助文档说该函数出于历史兼容性的原因尚且存在，一般来说，这个函数会一直维护下去的。\n\nnlminb(\n  start = rep(3, 25), objective = fn,\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093\n#&gt; [25] 4.000000\n#&gt; \n#&gt; $objective\n#&gt; [1] 368.1059\n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $iterations\n#&gt; [1] 6\n#&gt; \n#&gt; $evaluations\n#&gt; function gradient \n#&gt;       10      177 \n#&gt; \n#&gt; $message\n#&gt; [1] \"relative convergence (4)\"\n\n\n从返回结果来看，求解过程成功收敛，最优解的前 23 个决策变量取值为 2，在箱式约束的边界上，第 24 个分量没有边界上，而在内部，第 25 个决策变量取值为 4，也在边界上。目标函数值为 368.1059。\n\n31.4.4.2 constrOptim()\n\n使用 constrOptim() 函数求解，默认求极小，需将箱式或线性不等式约束写成矩阵形式，即 \\(Ax \\geq b\\) 的形式，参数 ui 是 \\(k \\times n\\) 的约束矩阵 \\(A\\)，ci 是右侧 \\(k\\) 维约束向量 \\(b\\)。以上面的优化问题为例，将箱式约束 \\(2 \\leq x_1,x_2 \\leq 4\\) 转化为矩阵形式，约束矩阵和向量分别为：\n\\[\nA = \\begin{bmatrix}\n1  & 0  \\\\\n0  & 1 \\\\\n-1 & 0 \\\\\n0  & -1\n\\end{bmatrix}, \\quad\nb = \\begin{bmatrix}\n2 \\\\\n2 \\\\\n-4 \\\\\n-4\n\\end{bmatrix}\n\\]\n\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  method = \"Nelder-Mead\", # 没有提供梯度，则必须用 Nelder-Mead 方法\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.006142 2.002260 2.003971 2.003967 2.004143 2.004255 2.001178 2.002990\n#&gt;  [9] 2.003883 2.006029 2.017345 2.009236 2.000949 2.007793 2.025831 2.007896\n#&gt; [17] 2.004514 2.004381 2.008771 2.015695 2.005803 2.009127 2.017988 2.257782\n#&gt; [25] 3.999846\n#&gt; \n#&gt; $value\n#&gt; [1] 378.4208\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    12048       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 1\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 25\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003278963\n\n\n返回结果中 convergence = 1 表示迭代次数到达默认的极限 maxit = 500 。参考函数 nlminb() 的求解结果，可知还没有收敛。如果没有提供梯度，则必须用 Nelder-Mead 方法，下面增加迭代次数到 1000。\n\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  method = \"Nelder-Mead\", \n  control = list(maxit = 1000),\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.000081 2.000142 2.001919 2.000584 2.000007 2.000003 2.001097 2.001600\n#&gt;  [9] 2.000207 2.000042 2.000250 2.000295 2.000580 2.002165 2.000453 2.000932\n#&gt; [17] 2.000456 2.000363 2.000418 2.000474 2.009483 2.001156 2.003173 2.241046\n#&gt; [25] 3.990754\n#&gt; \n#&gt; $value\n#&gt; [1] 370.8601\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    18036       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 1\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 19\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003366467\n\n\n结果有改善，目标函数值从 378.4208 减小到 370.8601，但还是没有收敛，可见 Nelder-Mead 方法在这个优化问题上收敛速度比较慢。下面考虑调用基于梯度的 BFGS 优化算法，这得先计算出来目标函数的梯度。\n\n# 输入 n 维向量，输出 n 维向量\ngr &lt;- function(x) {\n  n &lt;- length(x)\n  c(2 * (x[1] - 2), rep(0, n - 1))\n  +8 * c(0, x[-1] - x[-n]^2)\n  -16 * c(x[-n], 0) * c(x[-1] - x[-n]^2, 0)\n}\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  grad = gr,\n  method = \"BFGS\", \n  control = list(maxit = 1000),\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000001\n#&gt; [25] 3.000000\n#&gt; \n#&gt; $value\n#&gt; [1] 373\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;     3721      464 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 3\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003327104\n\n\n从结果来看，虽然已经收敛，但相比于 Nelder-Mead 方法，目标函数值变大了，可见已陷入局部最优解。\n\n31.4.4.3 optim()\n\n下面再使用函数 optim() 提供的 L-BFGS-B 算法求解优化问题。\n\noptim(\n  par = rep(3, 25), fn = fn, gr = NULL, method = \"L-BFGS-B\",\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093\n#&gt; [25] 4.000000\n#&gt; \n#&gt; $value\n#&gt; [1] 368.1059\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;        6        6 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH\"\n\n\n发现结果和函数 nlminb() 的结果差不多了。\n\noptim(\n  par = rep(3, 25), fn = fn, gr = gr, method = \"L-BFGS-B\",\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n#&gt; \n#&gt; $value\n#&gt; [1] 373\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;        2        2 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: NORM OF PROJECTED GRADIENT &lt;= PGTOL\"\n\n\n然而，当在函数 optim() 里提供梯度信息的时候，虽然目标函数及梯度的计算次数变少了，求解速度提升了，但是最优解反而变差了，最优解和在函数 constrOptim() 中设置 method = \"BFGS\" 算法基本一致。\n\n31.4.4.4 ROI 包\n下面通过 ROI 包，分别调用求解器 nloptr.lbfgs 和 nloptr.directL ，发现前者同样陷入局部最优解，而后者可以获得与 nlminb() 函数一致的结果。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 25L, G = gr),\n  bounds = V_bound(ld = 2, ud = 4, nobj = 25L)\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.lbfgs\", start = rep(3, 25))\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 373\n\n# 最优解\nnlp$solution\n\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n\n\n调全局优化算法。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 368.1059\n\n# 最优解\nnlp$solution\n\n#&gt;  [1] 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000\n#&gt; [10] 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000 2.00000\n#&gt; [19] 2.00000 2.00000 2.00000 2.00000 2.00000 2.10913 4.00000\n\n\n\n31.4.5 多元线性约束优化\n对于带线性约束的多元非线性优化问题，Base R 提供函数 constrOptim() 来求解，下面的示例来自其帮助文档，这是一个带线性约束的二次规划问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}}\n\\quad &  - \\begin{bmatrix}\n0 \\\\\n5 \\\\\n0\n\\end{bmatrix}^{\\top} \\boldsymbol{x} +\\frac{1}{2} \\boldsymbol{x}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\begin{bmatrix}\n-4  &  2  &  0 \\\\\n-3  &  1  & -2 \\\\\n0  &  0  &  1\n\\end{bmatrix}^{\\top}\\boldsymbol{x} \\geq \\begin{bmatrix}\n-8 \\\\\n2 \\\\\n0\n\\end{bmatrix}\n\\end{aligned}\n\\]\n\nfQP &lt;- function(x) {\n  -sum(c(0, 5, 0) * x) + 0.5 * sum(x * x)\n}\nAmat &lt;- matrix(c(-4, -3, 0, 2, 1, 0, 0, -2, 1),\n  ncol = 3, nrow = 3, byrow = FALSE\n)\nbvec &lt;- c(-8, 2, 0)\n# 目标函数的梯度\ngQP &lt;- function(x) {\n  -c(0, 5, 0) + x\n}\nconstrOptim(\n  theta = c(2, -1, -1), \n  f = fQP, g = gQP, \n  ui = t(Amat), ci = bvec\n)\n\n#&gt; $par\n#&gt; [1] 0.4761908 1.0476188 2.0952376\n#&gt; \n#&gt; $value\n#&gt; [1] -2.380952\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;      406       81 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 3\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.0006243894\n\n\n在上一节，箱式约束可以看作线性约束的一种特殊情况，ROI 包是支持箱式、线性、二次、锥和非线性约束的。因此，下面给出调用 ROI 包求解上述优化问题的代码。\n\nDmat &lt;- diag(rep(1,3))\ndvec &lt;- c(0, 5, 0)\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = -dvec),\n  constraints = L_constraint(L = t(Amat), dir = rep(\"&gt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(0, 1, 2))\n# 最优解\nnlp$solution\n\n#&gt; [1] 0.4761905 1.0476190 2.0952381\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] -2.380952\n\n\n可见输出结果与函数 constrOptim() 是一致的。\n\n代码# quadprog\nlibrary(quadprog)\nsol &lt;- solve.QP(\n  Dmat = Dmat, dvec = dvec, Amat = Amat, bvec = bvec\n)\nsol\n\n\n\n31.4.6 多元非线性约束优化\nnloptr 包的非线性优化能力覆盖开源优化软件 Octave 和 Ipopt 。通过插件包 ROI.plugin.nloptr，ROI 包可以调用 nloptr 包内置的所有求解器，常用的求解器见下表。表中从优化器类型（局部还是全局优化器），支持的约束条件类型（箱式还是非线性），是否需要提供目标函数的梯度、黑塞和约束条件的雅可比矩阵信息等方面归纳各个求解器的能力。\n\n常用的非线性优化求解器\n\n求解器\n类型\n约束\n梯度\n黑塞\n雅可比\n\n\n\nnloptr.lbfgs\n局部\n箱式\n需要\n不需要\n不需要\n\n\nnloptr.slsqp\n局部\n非线性\n需要\n不需要\n需要\n\n\nnloptr.auglag\n局部\n非线性\n需要\n不需要\n需要\n\n\nnloptr.directL\n全局\n箱式\n不需要\n不需要\n不需要\n\n\nnloptr.isres\n全局\n非线性\n不需要\n不需要\n不需要\n\n\n\n\n31.4.6.1 非线性等式约束\n下面这个示例来自 Octave 软件的非线性优化帮助文档，Octave 中的函数 sqp() 使用序列二次优化求解器（successive quadratic programming solver）求解非线性优化问题，示例中该优化问题包含多个非线性等式约束。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &  \\exp\\big(\\prod_{i=1}^{5} x_i\\big) - \\frac{1}{2}(x_1^3 + x_2^3 + 1)^2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n   \\sum_{i=1}^{5}x_i^2 - 10 = 0 \\\\\n   x_2 x_3 - 5x_4 x_5 = 0 \\\\\n   x_1^3 + x_2^3 + 1 = 0\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n目标函数是非线性的，有 5 个变量，约束条件也是非线性的，有 3 个等式约束。先手动计算目标函数的梯度，等式约束的雅可比矩阵。\n\n# 目标函数\nfn &lt;- function(x) {\n  exp(prod(x)) - 0.5 * (x[1]^3 + x[2]^3 + 1)^2\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    exp(prod(x)) * prod(x[-1]) - 3 * (x[1]^3 + x[2]^3 + 1) * x[1]^2,\n    exp(prod(x)) * prod(x[-2]) - 3 * (x[1]^3 + x[2]^3 + 1) * x[2]^2,\n    exp(prod(x)) * prod(x[-3]),\n    exp(prod(x)) * prod(x[-4]),\n    exp(prod(x)) * prod(x[-5])\n  )\n}\n# 等式约束\nheq &lt;- function(x) {\n  c(\n    sum(x^2) - 10,\n    x[2] * x[3] - 5 * x[4] * x[5],\n    x[1]^3 + x[2]^3 + 1\n  )\n}\n# 等式约束的雅可比矩阵\nheq.jac &lt;- function(x) {\n  matrix(c(2 * x[1], 2 * x[2], 2 * x[3], 2 * x[4], 2 * x[5],\n    0, x[3], x[2], -5 * x[5], -5 * x[4],\n    3 * x[1]^2, 3 * x[2]^2, 0, 0, 0),\n    ncol = 5, byrow = TRUE\n  )\n}\n\n在 OP() 函数里定义目标优化的各个成分。\n\n# 定义目标优化\nop &lt;- OP(\n  # 5 个决策变量\n  objective = F_objective(F = fn, n = 5L, G = gr), \n  constraints = F_constraint(\n    F = list(heq = heq),\n    dir = \"==\",\n    rhs = 0,\n    # 等式约束的雅可比矩阵\n    J = list(heq.jac = heq.jac)\n  ),\n  bounds = V_bound(ld = -Inf, ud = Inf, nobj = 5L),\n  maximum = FALSE # 求最小\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a nonlinear objective function of length 5 with\n#&gt; - 5 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 1 constraint of type nonlinear.\n#&gt; - 5 lower and 0 upper non-standard variable bounds.\n\n\n调用 SQP（序列二次优化） 求解器 nloptr.slsqp 。\n\nnlp &lt;- ROI_solve(op,\n  solver = \"nloptr.slsqp\",\n  start = c(-1.8, 1.7, 1.9, -0.8, -0.8)\n)\n# 最优解\nnlp$solution\n\n#&gt; [1] -1.7171435  1.5957096  1.8272458 -0.7636431 -0.7636431\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 0.05394985\n\n\n计算结果和 Octave 的示例一致。\n\n31.4.6.2 多种非线性约束\n\n非线性等式约束\n非线性不等式约束，不等式约束包含等号\n箱式约束\n\n此优化问题来源于 Ipopt 官网的帮助文档，约束条件比较复杂。提供的初始值为 \\(x_0 = (1,5,5,1)\\)，最优解为 \\(x_{\\star} = (1.00000000,4.74299963,3.82114998,1.37940829)\\)。优化问题的具体内容如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} & \\quad x_1 x_4 (x_1 + x_2 + x_3) + x_3 \\\\\n\\text{s.t.} & \\quad \\left\\{\n    \\begin{array}{l}\n     x_1^2 + x_2^2 + x_3^2 + x_4^2 = 40 \\\\\n     x_1 x_2 x_3 x_4 \\geq 25 \\\\\n     1 \\leq x_1, x_2, x_3, x_4 \\leq 5\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n下面用 ROI 调 nloptr 包求解，看结果是否和例子一致，nloptr 支持箱式约束且支持不等式约束包含等号。\n\n# 一个 4 维的目标函数\nfn &lt;- function(x) {\n  x[1] * x[4] * (x[1] + x[2] + x[3]) + x[3]\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    x[4] * (2 * x[1] + x[2] + x[3]), x[1] * x[4],\n    x[1] * x[4] + 1, x[1] * (x[1] + x[2] + x[3])\n  )\n}\n# 等式约束\nheq &lt;- function(x) {\n  sum(x^2)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  2 * c(x[1], x[2], x[3], x[4])\n}\n# 不等式约束\nhin &lt;- function(x) {\n  prod(x)\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x) {\n  c(prod(x[-1]), prod(x[-2]), prod(x[-3]), prod(x[-4]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, n = 4L, G = gr), # 4 个决策变量\n  constraints = F_constraint(\n    F = list(heq = heq, hin = hin),\n    dir = c(\"==\", \"&gt;=\"),\n    rhs = c(40, 25),\n    # 等式和不等式约束的雅可比\n    J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n  ),\n  bounds = V_bound(ld = 1, ud = 5, nobj = 4L),\n  maximum = FALSE # 求最小\n)\n\n作为对比参考，先计算目标函数的初始值和最优值。\n\n# 目标函数初始值\nfn(c(1, 5, 5, 1))\n\n#&gt; [1] 16\n\n# 目标函数最优值\nfn(c(1.00000000, 4.74299963, 3.82114998, 1.37940829))\n\n#&gt; [1] 17.01402\n\n\n求解一般的非线性约束问题。\n\n求解器 nloptr.mma / nloptr.cobyla 仅支持非线性不等式约束，不支持等式约束。\n函数 nlminb() 只支持等式约束。\n\n因此，下面分别调用 nloptr.auglag、nloptr.slsqp 和 nloptr.isres 来求解上述优化问题。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.auglag\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.000000 4.743174 3.820922 1.379440\n\nnlp$objval\n\n#&gt; [1] 17.01402\n\n\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.000000 4.742996 3.821155 1.379408\n\nnlp$objval\n\n#&gt; [1] 17.01402\n\n\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.isres\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.076354 4.801801 3.726796 1.376968\n\nnlp$objval\n\n#&gt; [1] 17.96234\n\n\n可以看出，nloptr 提供的优化能力可以覆盖 Ipopt 求解器，从以上求解的情况来看，推荐使用 nloptr.slsqp 求解器，这也是 Octave 的选择。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-integer-linear-optimization",
    "href": "numerical-optimization.html#sec-integer-linear-optimization",
    "title": "31  数值优化",
    "section": "\n31.5 整数优化",
    "text": "31.5 整数优化\n整数优化情况有很多，篇幅所限，仅考虑以下几类常见情形：\n\n目标函数和约束条件为线性，变量取值都为整数的整数优化。\n目标函数和约束条件为线性，变量取值为 0 或 1 的 0-1 整数优化。\n目标函数和约束条件为线性，部分变量带有整数约束的混合整数线性优化。\n目标函数为凸二次、约束条件为线性，部分变量是整数的混合整数二次优化。\n目标函数和约束条件为非线性，部分变量是整数的混合整数非线性优化。\n\n\n31.5.1 纯整数线性优化\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & -2x_1 - x_2 - 4x_3 -3x_4 -x_5\\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    2x_2 + x_3 + 4x_4 + 2x_5 &lt; 54 \\\\\n    3x_1 + 4x_2 + 5x_3 - x_4 - x_5 &lt; 62 \\\\\n    x_1,x_2 \\in [0,100] \\quad x_3 \\in [3, 100] \\\\\n    x_4 \\in [0,100] \\quad x_5 \\in [2,100] \\\\\n    x_i \\in \\mathbb{Z}, ~ i = 1,2,\\cdots,5.\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n求解器 glpk 还可以求解一些整数优化问题。\n\nop &lt;- OP(\n  objective = L_objective(c(-2, -1, -4, -3, -1)),\n  types = rep(\"I\", 5),\n  constraints = L_constraint(\n    L = matrix(c(\n      0, 2, 1, 4, 2,\n      3, 4, 5, -1, -1\n    ), ncol = 5, byrow = TRUE),\n    dir = c(\"&lt;\", \"&lt;\"),\n    rhs = c(54, 62)\n  ),\n  # 添加约束\n  bounds = V_bound(\n    li = 1:5, ui = 1:5,\n    lb = c(0, 0, 3, 0, 2), ub = rep(100, 5), nobj = 5\n  ),\n  maximum = FALSE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 5 with\n#&gt; - 5 integer objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type linear.\n#&gt; - 2 lower and 5 upper non-standard variable bounds.\n\n# 求解\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1] 15  0  6 11  2\n\n# 目标函数值\nres$objval\n\n#&gt; [1] -89\n\n\n可知，最优解在 \\((15,0,6,11,2)\\) 处取得，目标函数值为 -89 。\n注意：还有一组最优解 \\((19,0,4,10,5)\\) ，目标函数值也为 -89 ，但是 glpk 求解器未能给出。\n\n31.5.2 0-1 整数线性优化\n目标函数是线性的，决策变量的取值要么是 0 要么是 1。指派问题属于典型的 0-1 整数优化问题。有 \\(n\\) 个人需要去完成 \\(n\\) 项任务，每个人完成一项任务，每项任务只由一个人完成，每个人单独完成各项任务所需花费（时间、费用）不同。要求设计一个方案，人和任务之间建立一一对应的关系，使得总花费最少。\n设第 \\(i\\) 个人完成第 \\(j\\) 项任务的花费为 \\(d_{ij}\\) ，当安排第 \\(i\\) 个人完成第 \\(j\\) 项任务时，记为 \\(x_{ij} = 1\\) ，否则，记为 \\(x_{ij} = 0\\) ，指派问题的数学模型如下：\n\\[\n\\begin{aligned}\n\\min \\quad & \\sum_{i=1}^{n}\\sum_{j=1}^{n}d_{ij}x_{ij} \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    \\sum_{i=1}^{n} x_{ij} = 1, ~~ j = 1,2,\\ldots,n\\\\\n    \\sum_{j=1}^{n} x_{ij} = 1, ~~ i = 1,2,\\ldots,n\\\\\n    x_{ij} = 0 ~~\\text{或}~~ 1\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n指派问题在 lpSolve 包 (Berkelaar 等 2023) 做了很好的封装，只需提供花费矩阵，即可调用求解器求解该问题。\n\n# 花费矩阵 D\nD &lt;- matrix(c(\n  2, 7, 7, 2,\n  7, 7, 3, 2,\n  7, 2, 8, 10,\n  1, 9, 8, 2\n), nrow = 4, ncol = 4, byrow = F)\n# 加载 lpSolve 包 \nlibrary(lpSolve)\n# 调用指派问题求解器\nsol &lt;- lp.assign(D)\n# 最优解\nsol$solution\n\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    0    0    0    1\n#&gt; [2,]    0    0    1    0\n#&gt; [3,]    0    1    0    0\n#&gt; [4,]    1    0    0    0\n\n# 总花费\nsol$objval\n\n#&gt; [1] 8\n\n\n可以使总花费最少的指派计划是第 1 个人完成第 4 项任务，第 2 个人完成第 3 项任务，第 3 个人完成第 2 项任务，第 4 个人完成第 1 项任务，总花费为 8。\n\n31.5.3 混合整数线性优化\n目标函数是线性的，一部分决策变量是整数。\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{x}} \\quad & 3x_1 + 7x_2 - 12x_3 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    5x_1 + 7x_2 + 2x_3 \\leq 61\\\\\n    3x_1 + 2x_2 - 9x_3 \\leq 35\\\\\n    x_1 + 3x_2 + x_3 \\leq 31\\\\\n    x_1,x_2 \\geq 0, \\quad x_2, x_3 \\in \\mathbb{Z}, \\quad x_3 \\in [-10, 10]\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n矩阵形式如下\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{x}} \\quad &\n  \\begin{bmatrix}\n  3  \\\\\n  7  \\\\\n  -12\n  \\end{bmatrix}\n  ^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\left\\{\n\\begin{array}{l}\n  \\begin{bmatrix}\n  5 & 7 & 2 \\\\\n  3 & 2 & -9\\\\\n  1 & 3 & 1\n  \\end{bmatrix}\n  \\boldsymbol{x} \\leq\n  \\begin{bmatrix}\n   61 \\\\\n   35 \\\\\n   31\n  \\end{bmatrix}\n\\end{array} \\right.\n\\end{aligned}\n\\]\n第1个变量是连续值，第2、3个变量是整数，第3个变量的下、上界分别是 -10 和 10。\n\nop &lt;- OP(\n  objective = L_objective(c(3, 7, -12)),\n  types = c(\"C\", \"I\", \"I\"),\n  constraints = L_constraint(\n    L = matrix(c(\n      5, 7, 2,\n      3, 2, -9,\n      1, 3, 1\n    ), ncol = 3, byrow = TRUE),\n    dir = c(\"&lt;=\", \"&lt;=\", \"&lt;=\"),\n    rhs = c(61, 35, 31)\n  ),\n  # 添加约束\n  bounds = V_bound(\n    li = 3, ui = 3,\n    lb = -10, ub = 10, nobj = 3\n  ),\n  maximum = TRUE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 3 with\n#&gt; - 1 continuous objective variable,\n#&gt; - 2 integer objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 1 lower and 1 upper non-standard variable bound.\n\n# 求解\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1]  0.3333333  8.0000000 -2.0000000\n\nres$objval\n\n#&gt; [1] 81\n\n\n\n31.5.4 混合整数二次优化\n目标函数是二次的，一部分决策变量是整数。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & x_1^2 + x_2^2 - x_1  x_2 + 3  x_1 - 2 x_2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      -x_1 - x_2 &lt;= -2 \\\\\n      x_1 - x_2 &lt;= 2 \\\\\n      x_2 &lt;= 3. \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n在二次优化的基础上，对变量添加整型约束，即变成混合整数二次优化 （Mixed Integer Quadratic Programming，简称 MIQP）。\n\n# D\nDmat &lt;- matrix(c(2, -1, -1, 2), nrow = 2, byrow = TRUE)\n# d\ndvec &lt;- c(3, -2)\n# A\nAmat &lt;- matrix(c(\n  -1, -1,\n  1, -1,\n  0, 1\n), ncol = 2, byrow = TRUE)\n# b\nbvec &lt;- c(-2, 2, 3)\n# 目标优化\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(Amat, rep(\"&lt;=\", 3), bvec),\n  types = c(\"I\", \"C\"),\n  maximum = FALSE # 求最小\n)\n# 查看可用于该优化问题的求解器\nROI_applicable_solvers(op)\n\n#&gt; NULL\n\n\n目前，ROI 包支持的开源求解器都不能处理 MIQP 问题。ECOSolveR 包可以求解凸二阶锥优化，部分变量可以是整数。因此，先将凸二次优化转化为凸锥优化问题，再连接 ECOSolveR 包提供 ecos 求解器，最后，调 ecos 求解器求解。\n\\[\n\\begin{aligned}\n\\min_{(t,\\boldsymbol{x})} \\quad &  t\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\nx_1^2 + x_2^2 - x_1  x_2 + 3  x_1 - 2 x_2 \\leq t \\\\\n      -x_1 - x_2 &lt;= -2 \\\\\n      x_1 - x_2 &lt;= 2 \\\\\n      x_2 &lt;= 3. \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n引入新的变量 \\(t\\) ，原目标函数化为线性，约束条件增加一个二次型。\n\\[\n\\begin{aligned}\n\\min_{(t,\\boldsymbol{x})} \\quad &  t\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      \\boldsymbol{x}^{\\top}D\\boldsymbol{x} + 2\\boldsymbol{d}^{\\top}\\boldsymbol{x} \\leq t \\\\\n      A\\boldsymbol{x} \\leq \\boldsymbol{b} \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n其中，\n\\[\nD = \\begin{bmatrix}\n2 & -1\\\\\n-1 & 2\n\\end{bmatrix}, \\quad\n\\boldsymbol{d} =  \n\\begin{bmatrix}\n3 \\\\\n-2\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n-1 & -1  \\\\\n1 & -1 \\\\\n0  & 1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n-2 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n最后，凸二次优化转为二阶锥优化 SOCP，形式如下：\n\\[\n\\begin{aligned}\n\\min_{(t^{\\star},\\boldsymbol{x})} \\quad & t^{\\star}\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      \\|D^{1/2}\\boldsymbol{x} + D^{-1/2}\\boldsymbol{d} \\|_2 \\leq t^{\\star} \\\\\n      A\\boldsymbol{x} \\leq \\boldsymbol{b} \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n代码如下\n\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = c(\n    C_constraint(L, cones = K_soc(3)),\n    L_constraint(Amat, rep(\"&lt;=\", 3), bvec)\n  ),\n  types = c(\"I\", \"C\", \"C\"),\n  maximum = FALSE # 默认求最小\n)\n\n# 调用 ECOSolveR 包\nlibrary(ROI.plugin.ecos)\nnlp &lt;- ROI_solve(op, solver = \"ecos\", start = c(1, 2))\nnlp$objval\nnlp$solution\n\n因二次优化的目标函数是二次连续可微的，而且是凸函数，求解器 Bonmin 可以获得最优解。\nvar x1 integer;\nvar x2;\nminimize z: x1^2 + x2^2 - x1 * x2 + 3 * x1 - 2 * x2;\nsubject to A_limit: -x1 - x2 &lt;= -2;\nsubject to B_limit: x1 - x2 &lt;= 2;\nsubject to C_limit: x2 &lt;= 3;\n\nlibrary(rAMPL)\n# 配置 AMPL 安装路径\nenv &lt;- new(Environment, \"/opt/AMPL/ampl.macos64\")\nampl &lt;- new(AMPL, env)\n# 加载混合整数二次优化模型文件\nampl$read(\"code/MIQP.mod\")\n# 设置 MIQP 求解器 Bonmin\nampl$setOption(\"solver\", \"bonmin\")\n# 求解问题\nampl$solve()\n# 最优解\nampl$getData(\"x1\")\nampl$getData(\"x2\")\n# 目标函数值\nampl$getData(\"z\")\n\n最优解在 \\((0,2)\\) 处获得，最优值为 0。\n\n31.5.5 混合整数非线性优化\n在 R 语言社区的官方仓库中还没有开源的 R 包可以求解此类问题，开源社区中 Bonmin 项目专门求解混合整数非线性优化 MINLP（Mixed Integer Non-Linear Programming）问题。数学优化软件 AMPL 封装了 Bonmin 软件，并提供 R 语言接口 rAMPL。AMPL 社区版可以免费使用打包的开源求解器。\n\n线性优化求解器 HiGHS。\n混合整数线性优化求解器 cbc。\n混合整数非线性优化求解器 Bonmin 和 Couenne。\n非线性优化求解器 Ipopt。\n\n安装 AMPL 社区版软件后，再安装 rAMPL 包，它依赖 Rcpp 包，所以需要一并安装。\ninstall.packages(\"Rcpp\", type = \"source\")\n# 从 AMPL 官网安装 rAMPL 包\ninstall.packages(\"https://ampl.com/dl/API/rAMPL.tar.gz\", repos = NULL,\n  INSTALL_opts = c(\"--no-multiarch\", \"--no-staged-install\")\n)\n下面求解如下混合整数非线性优化问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & 1.5(x_1 - \\sin(x_1 -x_2))^2 + 0.5x_2^2 + x_3^2 -x_1 x_2 -2x_1 + x_2 x_3 \\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      x_1,x_2 \\in \\mathbb{R} ~~ x_3 \\in \\mathbb{Z} \\\\\n      x_1,x_2 \\in [-20,20] ~~ x_3 \\in [-10,10].\n    \\end{array} \\right.\n\\end{aligned}\n\\]\nAMPL 模型代码如下：\nvar X1;\nvar X2;\nvar X3 integer;\nminimize z: 1.5 * (X1 - sin(X1 - X2))^2 + 0.5 * X2^2 + X3^2 - X1 * X2 - 2 * X1 + X2 * X3;\nsubject to A_limit: -20 &lt;= X1 &lt;= 20;\nsubject to B_limit: -20 &lt;= X2 &lt;= 20;\nsubject to C_limit: -10 &lt;= X3 &lt;= 10;\n将代码保存到文件 code/MINLP.mod ，下面加载 rAMPL 包，调用求解器 Bonmin 求解该优化问题。\n\nlibrary(rAMPL)\n# 配置 AMPL 安装路径\nenv &lt;- new(Environment, \"/opt/AMPL/ampl.macos64\")\nampl &lt;- new(AMPL, env)\n# 加载混合整数非线性优化模型文件\nampl$read(\"code/MINLP.mod\")\n# 设置 MINLP 求解器 Bonmin\nampl$setOption(\"solver\", \"bonmin\")\n# 求解问题\nampl$solve()\n# 最优解\nampl$getData(\"X1\")\nampl$getData(\"X2\")\nampl$getData(\"X3\")\n# 目标函数值\nampl$getData(\"z\")\n\n如果使用 Bonmin 求解器，该优化问题的最优解在 \\((2.892556, 1.702552, -1)\\) 处获得，相应的目标函数值为 \\(-4.176012\\) 。如果使用求解器 Couenne ，它可以找到非凸混合整数非线性优化问题的全局最优解，Couenne 好于 Bonmin 求解器。\n\n# 调用 couenne 求解器\nampl$setOption(\"solver\", \"couenne\")\n# 求解问题\nampl$solve()\n\n最优解在 \\(x_1 = 4.999633, x_2 = 9.734148, x_3 = -5\\) 处取得，最优值为 \\(-10.96182\\) 。下面将两个最优解代入目标函数，验证一下最优值。\n\nfun &lt;- function(x) {\n  1.5 * (x[1] - sin(x[1] - x[2]))^2 + 0.5 * x[2]^2 +\n    x[3]^2 - x[1] * x[2] - 2 * x[1] + x[2] * x[3]\n}\n# 局部最优解\nfun(x = c(2.892556, 1.702552, -1))\n\n#&gt; [1] -4.176012\n\n# 全局最优解\nfun(x = c(4.999633, 9.734148, -5))\n\n#&gt; [1] -10.96182",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-numerical-optimization-summary",
    "href": "numerical-optimization.html#sec-numerical-optimization-summary",
    "title": "31  数值优化",
    "section": "\n31.6 总结",
    "text": "31.6 总结\n对大部分常规优化问题，都可以纳入 ROI 包的框架内。对少量复杂的优化问题，目前，必须借助开源社区的第三方求解器。\n\n对于含整型变量的凸锥优化问题，scs 包不能求解，ECOSolveR 包可以，它还可以求解可转化为凸二阶锥优化问题的混合整数二次优化问题。\n对于特定问题，比如 0-1 整数线性优化中的指派问题，相比于 ROI 包的大一统调用方式，lpSolve 包给出非常简明的使用语法。对凸二次优化问题，给出 quadprog 包的使用语法，补充说明 nloptr 包的结果，以及与 ROI 包调用语法的差异。\n对于凸的混合整数二次优化和非凸的混合整数非线性优化问题，借助 rAMPL 包分别调用开源的求解器 Bonmin 和 Couenne 求解。\n对于复杂的非线性优化问题，因其具有非凸、多模态等特点，求解非常困难。需要引入随机优化算法，比如采用 GA 包的遗传算法求解，效果可以达到商业软件的水平。\n对于凸优化问题，可以求解得又快又好，而对于非凸优化问题，要么只能获得局部最优解，要么可以搜索全局最优解，但不给保证，而且运行时间长。\n\n优化建模是一个具有基础性和支柱性的任务，几乎每个统计模型和机器学习算法背后都有一个优化问题。在 R 语言社区的优化任务视图 (Schwendinger 和 Borchers 2023) 中，可以看到数以百计的扩展包。非常广阔的应用场景催生了非常丰富的理论。根据目标函数和约束条件的情况，可以从不同的角度划分，如线性和非线性优化，连续和离散优化，确定性和随机优化，凸优化和非凸优化等。相关的理论著作非常多，感兴趣的读者可以根据自身情况找本教材系统性地学习。本章结构是按照优化问题分类组织的，主要涉及确定性的数值优化，因部分优化问题比较复杂，因此，也涉及少量的随机优化方法。\n优化建模是一个具有重要商业价值的领域，相关的开源和商业软件有很多，比较流行的有 Python 社区的 Pyomo (Hart, Watson, 和 Woodruff 2011)，Julia 社区的 JuMP (Dunning, Huchette, 和 Lubin 2017)。比较著名的商业软件有 Lingo、Mosek、Gurobi 等，而 AMPL 一个软件平台，对 20 个开源和商业求解器提供一套统一的建模语言，且提供 R、Python 等编程语言接口。\n相比于 Python 和 Julia 社区，R 语言社区在整合开源的优化建模软件方面，还有较长的路要走，ROI 包的出现意味着向整合的路迈出坚实的一步。优化建模的场景具有复杂性和多样性，算法实现更是五花八门，仅线性和整数线性优化方面，就至少有 lpSolve、 Rglpk 和 highs (Schwendinger 和 Schumacher 2023)等包，更别提非线性优化方面。这就又出现一个问题，对一个优化问题，采用何种算法及算法实现具有最好的效果，满足可用性、可靠性。尽管涉及数学和统计，但高质量的软件工具更是一个工程问题。\n从数据分析的角度来说，无论是 Python，还是 Julia，甚至于底层的 C++ 库，都不过是软件工具，首要问题是将实际问题转化为统计或数学模型，这需要抓住主要问题的关键因素，只有先做好建模的工作才能实现工具到商业价值的转化。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-numerical-optimization-exercises",
    "href": "numerical-optimization.html#sec-numerical-optimization-exercises",
    "title": "31  数值优化",
    "section": "\n31.7 习题",
    "text": "31.7 习题\n\n求解线性优化和整数线性优化的 R 包有很多，从使用语法、可求解的问题规模和问题类型比较 lpSolve、Rglpk 和 highs 等 R 包。\n求解非线性优化问题的 R 包有很多，其中有一些通过 Rcpp 包打包、调用 C++ 库，比如 RcppEnsmallen、RcppNumerical 等包，还有的 C++ 库提供头文件，可以在 C++ 环境中直接调用，比如 optim 库。通过 R 和 C++ 混合编程，一则引入更加庞大的开源社区，二则扩展求解非线性优化问题的规模和性能。请从求解问题类型、规模和性能等方面比较 5 个比较流行的 C++ 库。\n\n回顾凸二次优化一节，当矩阵 \\(D\\) 为半正定矩阵时，二次优化是非严格凸二次优化。调整示例里目标函数中的矩阵 \\(D\\) 使其行列式等于 0，其它条件不变。使用 ROI 包调用合适的优化求解器求解此类问题。\n\n代码# 非严格凸的二次优化问题\n# 凸二次优化一节的示例 矩阵 D 的行列式为 0\nDmat &lt;- matrix(c(2, 1, 4, 2), nrow = 2, byrow = TRUE)\ndvec &lt;- c(3, -2)\nAmat &lt;- matrix(c(-1, -1, 1, -1, 0, 1), ncol = 2, byrow = TRUE)\nbvec &lt;- c(-2, 2, 3)\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(L = Amat, dir = rep(\"&lt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nop\n# 调用 SQP 序列二次优化求解器\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 2))\n# 目标函数值 0 \nnlp$objval\n# 最优解 (0, 2)\nnlp$solution\n\n\n\n\n求解如下 2 维非线性无约束优化问题。\n\\[\n\\min_{\\boldsymbol{x}} \\quad 100 (x_2 -x_1^2)^2 + (1-x_1)^2\n\\]\n\n代码# Rosenbrock Banana function\n# 目标函数\nfr &lt;- function(x) {\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  100 * (x2 - x1 * x1)^2 + (1 - x1)^2\n}\n# 目标函数的梯度\ngrr &lt;- function(x) {\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  c(\n    -400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),\n    200 * (x2 - x1 * x1)\n  )\n}\n# 求解\nnlminb(start = c(-1.2, 1), objective = fr, gradient = grr)\n# 或者\noptim(par = c(-1.2, 1), fn = fr, gr = grr, method = \"L-BFGS-B\")\n\n\n\n\n求解如下 \\(n\\) 维非线性箱式约束优化问题。\n\\[\n\\min_{\\boldsymbol{x}} \\quad \\exp\\big( - \\sum_{i=1}^{n}(\\frac{x_i}{\\beta})^{2m}\\big)  - 2\\exp(- \\sum_{i=1}^{n}x_i^2)\\prod_{i=1}^{n} \\cos^2(x_i)\n\\]\n其中，\\(\\beta.=15, m = 3\\) ，\\(x_i \\in [-20,20], i = 1,2,\\ldots,n\\) 。请读者分别考虑 \\(n= 2\\) 和 \\(n = 4\\) 的情况。（全局最优解在 \\(x_i = 0, i = 1,2,\\ldots,n\\) 处取得，最优值为 \\(-1\\) 。）\n\n\n求解如下非线性约束优化问题。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & \\exp(\\sin(50 x_1)) + \\sin(60\\exp(x_2)) + \\sin(70\\sin(x_1)) \\\\\n         \\quad & + \\sin(\\sin(80x_2)) - \\sin(10(x_1 +x_2)) + \\frac{(x_1^2 + x_2^2)^{\\sin(x_2)}}{4} \\\\\n    \\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n     x_1 - \\big((\\cos(x_2))^{x_1} - x_1\\big)^{x_2} \\leq 0 \\\\\n    -50 \\leq x_1,x_2 \\leq 50\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n目标函数是不连续的，其函数图像如 图 31.10 所示。（提示：容错能力低的求解器一般无法求解。Lingo 给出一个局部最优解 \\((-46.14402, -0.8879601)\\) ，目标函数值为 \\(-2.645518\\) ，仅供参考。）\n\n代码fn &lt;- function(x) {\n  exp(sin(50 * x[1])) + sin(60 * exp(x[2])) +\n    sin(70 * sin(x[1])) + sin(sin(80 * x[2])) -\n    sin(10 * (x[1] + x[2])) + (x[1]^2 + x[2]^2)^(sin(x[2])) / 4\n}\n\ndf &lt;- expand.grid(\n  x1 = seq(from = 0.8, to = 1.4, length.out = 81),\n  x2 = seq(from = 0, to = 0.4, length.out = 41)\n)\n# 计算格点处的函数值\ndf$fn &lt;- apply(df, 1, FUN = fn)\n\n# 绘图\nwireframe(\n  data = df, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 31.10: 目标函数的曲面图\n\n\n\n\n\n代码fn &lt;- function(x) {\n  exp(sin(50 * x[1])) + sin(60 * exp(x[2])) +\n    sin(70 * sin(x[1])) + sin(sin(80 * x[2])) -\n    sin(10 * (x[1] + x[2])) + (x[1]^2 + x[2]^2)^(sin(x[2])) / 4\n}\ngr &lt;- function(x){\n  numDeriv::grad(fn, c(x[1], x[2]))\n}\nhin &lt;- function(x){\n  x[1] - ( (cos(x[2]))^x[1] - x[1] )^x[2]\n}\nhin.jac &lt;- function(x){\n  numDeriv::grad(hin, c(x[1], x[2]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, n = 2L, G = gr), # 2 个决策变量\n  constraints = F_constraint(\n    F = list(hin = hin),\n    dir = \"&lt;=\",\n    rhs = 0,\n    J = list(hin.jac = hin.jac)\n  ),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 2L),\n  maximum = FALSE # 求最小\n)\n# 全局优化求解器 nloptr.isres，不保证全局最优\n# 最优解 (20.68497, 37.20738) 处取得局部最优解，目标函数值 -3.053314\nnlp &lt;- ROI_solve(op, solver = \"nloptr.isres\", start = c(1, 0))\nnlp$solution\nnlp$objval\n# 局部优化求解器 nloptr.cobyla\n# 在处 (24.199046, 2.964661) 处取得局部最优解，目标函数值 0.6477342\nnlp &lt;- ROI_solve(op, solver = \"nloptr.cobyla\", start = c(1, 0))\nnlp$solution\nnlp$objval\n# nloptr.mma / nloptr.auglag / nloptr.slsqp 容错能力差，都不能求解\nnlp &lt;- ROI_solve(op, solver = \"nloptr.auglag\", start = c(1, 0))\n\n\n\n\n求解如下非线性约束优化问题。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & x_1^2\\sin(x_2) + x_2^2\\cos(x_1)\\\\\n  \\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      1 \\leq 3x_1 -x_2 \\leq 3 \\\\\n      x_1 + x_2 \\geq 2 \\\\\n      x_1 x_2 = 2 \\\\\n      \\sin(x_1) \\cos(x_2) \\leq 0.6 \\\\\n      x_1,x_2 \\in (-100,100).\n    \\end{array} \\right.\n  \\end{aligned}\n\\]\n\n代码# 一个 2 维的目标函数\nfn &lt;- function(x) {\n  x[1]^2 * sin(x[2]) + x[2]^2 * cos(x[1])\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    2 * x[1] * sin(x[2]) - x[2]^2 * sin(x[1]),\n    x[1]^2 * cos(x[2]) + 2 * x[2] * cos(x[1])\n  )\n}\n# 线性约束矩阵\nA &lt;- matrix(c(\n  1, 1,\n  3, -1,\n  3, -1\n), ncol = 2, byrow = TRUE)\n# 等式约束\nheq &lt;- function(x) {\n  prod(x)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  c(x[2], x[1])\n}\n# 不等式约束\nhin &lt;- function(x) {\n  sin(x[1]) * cos(x[2])\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x) {\n  c(cos(x[1]) * cos(x[2]), -sin(x[1]) * sin(x[2]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, G = gr, n = 2L),\n  # rbind 函数组合多种约束\n  constraints = rbind(\n    L_constraint(\n      L = A,\n      dir = c(\"&gt;=\", \"&lt;=\", \"&gt;=\"),\n      rhs = c(2, 3, 1)\n    ),\n    F_constraint(\n      F = list(heq = heq, hin = hin),\n      dir = c(\"==\", \"&lt;=\"),\n      rhs = c(2, 0.6),\n      # 等式和不等式约束的雅可比\n      J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n    )\n  ),\n  bounds = V_bound(ld = -100, ud = 100, nobj = 2L),\n  maximum = FALSE # 求最小\n)\n# 求解优化问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1/2, 4))\n# 最优解\nnlp$solution\n# 目标函数值\nnlp$objval\n\n\n\n\n\n\n\n\nBerkelaar, Michel 等. 2023. lpSolve: Interface to Lp_solve v. 5.5 to Solve Linear/Integer Programs. https://CRAN.R-project.org/package=lpSolve.\n\n\nBrandao, Filipe. 2023. rAMPL: AMPL API for R. https://github.com/ampl/rAMPL.\n\n\nDunning, Iain, Joey Huchette, 和 Miles Lubin. 2017. 《JuMP: A Modeling Language for Mathematical Optimization》. SIAM Review 59 (2): 295–320. https://doi.org/10.1137/15M1020575.\n\n\nFu, Anqi, 和 Balasubramanian Narasimhan. 2023. ECOSolveR: Embedded Conic Solver in R. https://CRAN.R-project.org/package=ECOSolveR.\n\n\nHart, William E, Jean-Paul Watson, 和 David L Woodruff. 2011. 《Pyomo: modeling and solving mathematical programs in Python》. Mathematical Programming Computation 3 (3): 219–60.\n\n\nJohnson, Steven G. 2023. The NLopt nonlinear optimization package. https://CRAN.R-project.org/package=nloptr.\n\n\nO’Donoghue, Brendan, Eric Chu, Parikh Neal, 和 Stephen Boyd. 2016. 《Operator Splitting for Conic Optimization via Homogeneous Self-Dual Embedding》. Journal of Optimization Theory and Applications 169 (3): 1042–68. https://doi.org/10.1007/s10957-016-0892-3.\n\n\nS original by Berwin A. Turlach, Fortran contributions from Cleve Moler dpodi/LINPACK), R port by Andreas Weingessel. 2019. quadprog: Functions to Solve Quadratic Programming Problems. https://CRAN.R-project.org/package=quadprog.\n\n\nSchwendinger, Florian, 和 Hans W. Borchers. 2023. CRAN Task View: Optimization and Mathematical Programming. https://CRAN.R-project.org/view=Optimization.\n\n\nSchwendinger, Florian, 和 Dirk Schumacher. 2023. highs: HiGHS Optimization Solver. https://CRAN.R-project.org/package=highs.\n\n\nScrucca, Luca. 2013. 《GA: A Package for Genetic Algorithms in R》. Journal of Statistical Software 53 (4): 1–37. https://doi.org/10.18637/jss.v053.i04.\n\n\nTheussl, Stefan, 和 Kurt Hornik. 2023. Rglpk: R/GNU Linear Programming Kit Interface. https://CRAN.R-project.org/package=Rglpk.\n\n\nTheußl, Stefan, Florian Schwendinger, 和 Kurt Hornik. 2020. 《ROI: An Extensible R Optimization Infrastructure》. Journal of Statistical Software 94 (15): 1–64. https://doi.org/10.18637/jss.v094.i15.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html",
    "href": "optimization-problems.html",
    "title": "32  优化问题",
    "section": "",
    "text": "32.1 旅行商问题\n旅行商问题 The Traveling Salesman Problem 是一个混合整数线性规划问题，TSP 包 (Hahsler 和 Hornik 2007) 是求解此问题的最佳工具包。一般地，旅行商问题作如下定义。已知 \\(n\\) 个城市之间的距离，以矩阵 \\(D\\) 表示各个城市之间的距离，其元素 \\(d_{ij}\\) 表示城市 \\(i\\) 到城市 \\(j\\) 之间的距离，其对角元素 \\(d_{ii} = 0\\)，其中 \\(i,j = 1,2,\\cdots, n\\) 。一个旅行路线可以用 \\(\\{1,2,\\ldots,n\\}\\) 的循环排列 \\(\\pi\\) 表示，\\(\\pi(i)\\) 表示在旅行线路中跟在城市 \\(i\\) 之后的城市。旅行商问题就是找一个排列 \\(\\pi\\) 使得如下旅行线路最短。\n\\[\n\\sum_{i=1}^{n} d_{i\\pi(i)}\n\\]\n每个城市必须走到，且只能走一次。等价于如下整数规划问题，也是一个指派问题。\n\\[\n\\begin{aligned}\n\\min ~ & \\sum_{i=1}^{n}\\sum_{j=1}^{n} d_{ij}x_{ij} \\\\\n\\text{s.t.} ~& \\sum_{i=1}^{n}x_{ij} = 1, ~j = 1,2,\\ldots,n, \\\\\n~& \\sum_{j=1}^{n}x_{ij} = 1, ~ i = 1,2,\\ldots,n, \\\\\n~& x_{ij} = 0 ~\\text{or} ~ 1\n\\end{aligned}\n\\]\n某人要去美国 10 个城市旅行，分别是亚特兰大 Atlanta、芝加哥 Chicago、丹佛 Denver 、休斯顿 Houston、洛杉矶 Los Angeles、迈阿密 Miami、纽约 New York、旧金山 San Francisco、 西雅图 Seattle、华盛顿特区 Washington DC。10 个城市的分布如 图 32.1 所示。从洛杉矶出发，最后回到洛杉矶，如何规划旅行线路使得总行程最短？行程最短的路径是什么？\n代码# 10 个城市的经纬度数据来自 maps 包的 us.cities 数据集\nus_city_latlong &lt;- read.table(file = textConnection(\"\nCity, Latitude, Longitude\nAtlanta, 33.76, -84.42\nChicago, 41.84, -87.68\nDenver, 39.77, -104.87\nHouston, 29.77, -95.39\nLos Angeles, 34.11, -118.41\nMiami, 25.78, -80.21\nNew York, 40.67, -73.94\nSan Francisco, 37.77, -122.45\nSeattle, 47.62, -122.35\nWashington DC, 38.91, -77.01\n\"), header = TRUE, sep = \",\")\n\nlibrary(sf)\nus_city_latlong &lt;- st_as_sf(us_city_latlong,\n  coords = c(\"Longitude\", \"Latitude\"), crs = 4326\n)\nlibrary(ggplot2)\nggplot() +\n  geom_sf_label(\n    data = us_city_latlong, aes(label = City),\n    fun.geometry = sf::st_centroid\n  ) +\n  geom_sf(data = us_city_latlong, color = \"red\") +\n  coord_sf(crs = \"ESRI:102003\") +\n  theme_bw() +\n  labs(x = \"经度\", y = \"纬度\")\n\n\n\n\n\n\n图 32.1: 10 个城市的分布图\n简单起见，这 10 个城市之间的距离以直线距离代替，R 内置的数据集 UScitiesD 已经记录了这 10 个城市之间的直线距离。 UScitiesD 是一个 dist 类型的数据，可以用函数 as.matrix() 将其转化为矩阵类型。\ndata(UScitiesD)\nD &lt;- as.matrix(UScitiesD)\nlibrary(TSP)\nD_tsp &lt;- as.TSP(D)\n# 出发城市洛杉矶\ntour_sol &lt;- solve_TSP(x = D_tsp, method = \"nearest_insertion\", start = 5)\ntour_sol\n\n#&gt; object of class 'TOUR' \n#&gt; result of method 'nearest_insertion' for 10 cities\n#&gt; tour length: 7373\n途经 10 个城市的最短路程为 7373 。因采用启发式的随机优化算法，每次求解的结果可能会有所不同，建议运行多次，比较结果，选择最优的方法。\n# 旅行最短路程\ntour_length(tour_sol)\n\n#&gt; [1] 7373\n\n# 旅行线路方案\nas.integer(tour_sol)\n\n#&gt;  [1]  5  4  6  1 10  7  2  3  9  8\n\nlabels(D_tsp)[as.integer(tour_sol)]\n\n#&gt;  [1] \"LosAngeles\"    \"Houston\"       \"Miami\"         \"Atlanta\"      \n#&gt;  [5] \"Washington.DC\" \"NewYork\"       \"Chicago\"       \"Denver\"       \n#&gt;  [9] \"Seattle\"       \"SanFrancisco\"\n求解结果对应的旅行方案，如 图 32.2 所示，依次走过的城市是：洛杉矶、旧金山、西雅图、丹佛、芝加哥、纽约、华盛顿特区、亚特兰大、迈阿密、休斯顿。\n代码us_city_tour &lt;- st_cast(st_combine(st_geometry(us_city_latlong[as.integer(tour_sol),])), \"POLYGON\")\nggplot() +\n  geom_sf_label(\n    data = us_city_latlong, aes(label = City),\n    fun.geometry = sf::st_centroid\n  ) +\n  geom_sf(data = us_city_latlong, color = \"red\") +\n  geom_sf(data = us_city_tour, fill = NA, color = \"black\") +\n  coord_sf(crs = \"ESRI:102003\") +\n  theme_bw() +\n  labs(x = \"经度\", y = \"纬度\")\n\n\n\n\n\n\n图 32.2: 10 个城市的路线图",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-markowitz-portfolio-optimization",
    "href": "optimization-problems.html#sec-markowitz-portfolio-optimization",
    "title": "32  优化问题",
    "section": "\n32.2 投资组合问题",
    "text": "32.2 投资组合问题\n作为一个理性的投资者，希望回报最大而风险最小，给定投资和回报的约束条件下，选择风险最小的组合。一个简单的马科维茨投资组合优化问题如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{w}} \\quad & \\boldsymbol{w}^{\\top}\\hat{\\Sigma}\\boldsymbol{w} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{w}^{\\top} \\leq \\boldsymbol{b}\n\\end{aligned}\n\\]\n其中，\\(\\boldsymbol{w}\\) 是权重向量，每个分量代表对投资对象的投资比例，\\(\\hat{\\Sigma}\\) 是关于投资对象的协方差矩阵，约束条件中包含两个部分，一个是权重之和为 1，一个是投资组合的收益率达到预期值。下面基于 12个科技公司公开的股价数据介绍此组合优化问题。\n首先利用 quantmod 包获取微软、谷歌、亚马逊、惠普、甲骨文、英特尔、威瑞森、eBay、AT&T、Apple、Adobe 和 IBM 等 12 支股票的历史股价数据。根据 2022-11-01 至 2022-12-01 期间的股票调整价，计算各支股票天粒度的收益率。收益率可以看作一个随机变量，收益率的波动变化，即随机变量的方差，可以看作风险。\n\n# 12 支股票的收益率\ntech_stock_return &lt;- readRDS(file = \"data/tech_stock_return.rds\")\nDD &lt;- 100 * tech_stock_return\n# 平均收益率\nr &lt;- mean(DD)\nr\n\n#&gt; [1] 0.3476413\n\n# 目标函数\nfoo &lt;- Q_objective(Q = cov(DD), L = rep(0, ncol(DD)))\n# 投资约束\nfull_invest &lt;- L_constraint(rep(1, ncol(DD)), \"==\", 1)\n# 回报约束\ntarget_return &lt;- L_constraint(apply(DD, 2, mean), \"==\", r)\n# 目标规划\nop &lt;- OP(objective = foo, constraints = rbind(full_invest, target_return))\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n求解器 nloptr.slsqp 需要给初值和等式约束的梯度，而求解器 quadprog 不需要给初值。下面使用 quadprog 来求解组合优化问题。\n\nlibrary(ROI.plugin.quadprog)\nsol &lt;- ROI_solve(op, solver = \"quadprog\")\n# 最优解：投资组合\nw &lt;- sol$solution\n# 保留 4 位小数\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 目标函数值：投资风险\nsqrt(t(w) %*% cov(DD) %*% w)\n\n#&gt;           [,1]\n#&gt; [1,] 0.9860861\n\n\n求解出来的投资组合是甲骨文、 AT&T 和 IBM，投资比例分别是 33.58% 、37.40% 和 29.02% 。以上 12 支股票都属于科技公司，收益率具有非常高的相关性，因此，最终选出来 3 支。\n与给定预期回报而风险最小的组合优化问题相对应的是另一个问题：给定风险的约束条件下，获得预期回报最大的组合。即求解如下组合优化问题：\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{w}} \\quad & \\boldsymbol{w}^{\\top}\\hat{\\boldsymbol{\\mu}} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{w} \\leq \\boldsymbol{b} \\\\\n\\quad & \\boldsymbol{w}^{\\top}\\hat{\\Sigma}\\boldsymbol{w} \\leq \\sigma\n\\end{aligned}\n\\]\n其中，目标函数中 \\(\\hat{\\boldsymbol{\\mu}}\\) 表示根据历史数据获得的投资对象的收益率，约束条件中 \\(\\sigma\\) 表示投资者可以接受的投资风险，其他符号的含义同前。在给定风险约束 \\(\\sigma\\) 下，求取回报最大的组合。线性约束也可以用函数 Q_constraint() 来表示，这样线性约束和二次约束可以整合在一起，代码如下：\n\n# 风险阈值\nsigma &lt;- sqrt(t(w) %*% cov(DD) %*% w)\nsigma\n\n#&gt;           [,1]\n#&gt; [1,] 0.9860861\n\n# 12 阶的全 0 矩阵\nzero_mat &lt;- diag(x = rep(0, ncol(DD)))\n# 目标函数\nfoo &lt;- Q_objective(Q = zero_mat, L = colMeans(DD))\n# 线性和二次约束\nmaxret_constr &lt;- Q_constraint(\n  Q = list(cov(DD), NULL),\n  L = rbind(\n    rep(0, ncol(DD)),\n    rep(1, ncol(DD))\n  ),\n dir = c(\"&lt;=\", \"==\"), rhs = c(1/2 * sigma^2, 1)\n)\n# 目标规划\nop &lt;- OP(objective = foo, constraints = maxret_constr, maximum = TRUE)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a quadratic objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type quadratic.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n函数 ROI_applicable_solvers() 识别规划问题类型，给出可求解此规划问题的求解器。\n\nROI_applicable_solvers(op)\n\n#&gt; [1] \"nloptr.cobyla\" \"nloptr.mma\"    \"nloptr.auglag\" \"nloptr.isres\" \n#&gt; [5] \"nloptr.slsqp\"\n\n\nquadprog 求解器不能求解该问题，尝试求解器 nloptr.slsqp ，12 支股票同等看待，所以，权重的初始值都设置为 \\(\\frac{1}{12}\\) 。\n\n# 求解规划问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = rep(1/12, 12))\n# 投资组合\nw &lt;- nlp$solution\n# 保留 4 位小数\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 投资组合的预期收益\nw %*% colMeans(DD)\n\n#&gt;           [,1]\n#&gt; [1,] 0.3476413\n\n\n结果显示，投资组合是甲骨文、 AT&T 和 IBM，投资比例分别是 33.58% 、37.40% 和 29.02% 。\n值得注意，当约束条件比较复杂，比如包含一些非线性的等式或不等式约束，可以用函数 F_constraint() 来表示，这更加的灵活，但需要传递（非）线性约束的雅可比向量或矩阵。用函数 F_constraint() 表示的代码如下，求解结果是一样的。\n\n# x 是一个表示权重的列向量 \n# 等式约束\n# 权重之和为 1 的约束\nheq &lt;- function(x) {\n  sum(x)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  rep(1, length(x))\n}\n# 不等式约束\n# 二次的风险约束\nhin &lt;- function(x){\n  1/2 * t(x) %*% cov(DD) %*% x\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x){\n  cov(DD) %*% x\n}\n# 目标规划\nop &lt;- OP(\n  objective = L_objective(L = colMeans(DD)), # 12 个目标变量\n  constraints = F_constraint(\n    # 等式和不等式约束\n    F = list(heq = heq, hin = hin),\n    dir = c(\"==\", \"&lt;=\"),\n    rhs = c(1, 1/2 * sigma^2),\n    # 等式和不等式约束的雅可比\n    J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n  ),\n  # 目标变量的取值范围\n  bounds = V_bound(ld = 0, ud = 1, nobj = 12L),\n  maximum = TRUE # 最大回报\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type nonlinear.\n#&gt; - 0 lower and 12 upper non-standard variable bounds.\n\n# 求解规划问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = rep(1/12, 12))\n# 投资组合\nw &lt;- nlp$solution\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 投资组合的预期收益\nw %*% colMeans(DD)\n\n#&gt;           [,1]\n#&gt; [1,] 0.3476413",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-gaussian-process-regression",
    "href": "optimization-problems.html#sec-gaussian-process-regression",
    "title": "32  优化问题",
    "section": "\n32.3 高斯过程回归",
    "text": "32.3 高斯过程回归\n高斯过程回归模型如下：\n\\[\n\\boldsymbol{y}(x) = D\\boldsymbol{\\beta} + S(x)\n\\]\n其中，\\(\\boldsymbol{\\beta}\\) 是一个 \\(p\\times 1\\) 维列向量，随机过程 \\(S(x)\\) 是均值为零，协方差为 \\(V_{\\boldsymbol{\\theta}}\\) 的平稳高斯过程，协方差矩阵 \\(V_{\\boldsymbol{\\theta}}\\) 的元素如下：\n\\[\n\\mathsf{Cov}\\{S(x_i), S(x_j)\\} = \\sigma^2 \\exp(-\\|x_i - x_j\\| / \\phi)\n\\]\n其中， \\(\\boldsymbol{\\theta} = (\\sigma^2,\\phi)\\) 表示与协方差矩阵相关的参数，随机过程 \\(S(x)\\) 的一个实现服从多元正态分布 \\(\\mathrm{MVN}(\\boldsymbol{0},V_{\\boldsymbol{\\theta}})\\) ，则 \\(\\boldsymbol{y}(x)\\) 也服从多元正态分布 \\(\\mathrm{MVN}(D\\boldsymbol{\\beta},V_{\\boldsymbol{\\theta}})\\) 。参数 \\(\\boldsymbol{\\beta}\\) 的广义最小二乘估计为 \\(\\hat{\\boldsymbol{\\beta}}(\\boldsymbol{\\theta}) = (D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}D)^{-1} D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\boldsymbol{y}\\) ，关于参数 \\(\\boldsymbol{\\theta}\\) 的剖面对数似然函数如下：\n\\[\n\\log \\mathcal{L}(\\boldsymbol{\\theta}) = -\\frac{n}{2}\\log (2\\pi) - \\frac{1}{2}\\log (\\det V_{\\boldsymbol{\\theta}}) -\\frac{1}{2}\\boldsymbol{y}^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\big(I - D(D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}D)^{-1}D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\big)\\boldsymbol{y}\n\\]\n下面考虑一个来自 MASS 包真实数据 topo。topo 数据集最初来自 John C. Davis （1973年）所著的书《Statistics and Data Analysis in Geology》。后来， J. J. Warnes 和 B. D. Ripley （1987年）以该数据集为例指出空间高斯过程的协方差函数的似然估计中存在的问题(Warnes 和 Ripley 1987)，并将其作为数据集 topo 放在 MASS 包里。Paulo J. Ribeiro Jr 和 Peter J. Diggle （2001年）将该数据集打包成自定义的 geodata 数据类型，放在 geoR 包里，并在他俩合著的书《Model-based Geostatistics》中多次出现。topo 是空间地形数据集，包含有 52 行 3 列，数据点是 310 平方英尺范围内的海拔高度数据，x 坐标每单位 50 英尺，y 坐标单位同 x 坐标，海拔高度 z 单位是英尺。\n\nlibrary(MASS)\ndata(topo)\nstr(topo)\n\n#&gt; 'data.frame':    52 obs. of  3 variables:\n#&gt;  $ x: num  0.3 1.4 2.4 3.6 5.7 1.6 2.9 3.4 3.4 4.8 ...\n#&gt;  $ y: num  6.1 6.2 6.1 6.2 6.2 5.2 5.1 5.3 5.7 5.6 ...\n#&gt;  $ z: int  870 793 755 690 800 800 730 728 710 780 ...\n\n\n根据 topo 数据集， \\(D = \\boldsymbol{1}\\) 是一个 \\(52 \\times 1\\) 的列向量，\\(\\boldsymbol{\\beta} = \\beta\\) 是一个截距项。设置参数初值 \\((\\sigma,\\phi) = (65,2)\\) 。为了与 Ripley 的论文中的图比较，下面扔掉了对数似然函数中常数项，用 R 语言编码的似然函数如下：\n\nlog_lik &lt;- function(x) {\n  n &lt;- nrow(topo)\n  D &lt;- t(t(rep(1, n)))\n  Sigma &lt;- x[1]^2 * exp(-as.matrix(dist(topo[, c(\"x\", \"y\")])) / x[2])\n  inv_Sigma &lt;- solve(Sigma)\n  P &lt;- diag(1, n) - D %*% solve(t(D) %*% solve(Sigma, D), t(D)) %*% inv_Sigma\n  as.vector(-1 / 2 * log(det(Sigma)) - 1 / 2 * t(topo[, \"z\"]) %*% inv_Sigma %*% P %*% topo[, \"z\"])\n}\nlog_lik(x = c(65, 2))\n\n#&gt; [1] -207.1364\n\n\n关于参数的偏导计算复杂，就不计算梯度了，下面调用 R 软件内置的 nlminb 优化器。发现，对不同的初始值，收敛到不同的位置，目标函数值非常接近。\n\nop &lt;- OP(\n  objective = F_objective(log_lik, n = 2L),\n  bounds = V_bound(lb = c(55, 5), ub = c(75, 8)),\n  maximum = TRUE\n)\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(65, 2))\nnlp$solution\n\n#&gt; [1] 65  5\n\nnlp$objval\n\n#&gt; [1] -197.4197\n\n\n如果初始值靠近局部极值点，则就近收敛到该极值点，比如初值 \\((65, 7)\\) ， \\((70, 7.5)\\) 。\n\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(65, 7))\nnlp$solution\n\n#&gt; [1] 65  7\n\nnlp$objval\n\n#&gt; [1] -196.9407\n\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(70, 7.5))\nnlp$solution\n\n#&gt; [1] 70.0  7.5\n\nnlp$objval\n\n#&gt; [1] -196.8441\n\n\n尝试调用来自 nloptr 包的全局优化求解器 nloptr.directL ，大大小小的坑都跳过去了，结果还是比较满意的。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\nnlp$solution\n\n#&gt; [1] 63.934407  6.121375\n\nnlp$objval\n\n#&gt; [1] -196.8158\n\n\n目标区域网格化，计算格点处的似然函数值，然后绘制似然函数图像。\n\ndat &lt;- expand.grid(\n  sigma = seq(from = 55, to = 75, length.out = 41),\n  phi = seq(from = 5, to = 8, length.out = 31)\n)\ndat$fn &lt;- apply(dat, 1, log_lik)\n\n似然函数关于参数 \\((\\sigma,\\phi)\\) 的三维曲面见 图 32.3 。\n\n代码wireframe(\n  data = dat, fn ~ sigma * phi,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(sigma), ylab = expression(phi),\n  zlab = list(expression(\n    italic(log-lik) ~ group(\"(\", list(sigma, phi), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 32.3: 对数似然函数的曲面图\n\n\n\n\n等高线图呈现一道非常长且平滑的山岭 long flat ridge，山岭上布满许多局部极大值，普通的数值优化求解器常常陷入其中，只有全局优化求解器才可能找到全局极大值点。高斯过程回归模型的对数似然函数是非凸的，多模态的。\n\n代码levelplot(fn ~ sigma * phi,\n  data = dat, aspect = 1,\n  xlim = c(54.5, 75.5), ylim = c(4.9, 8.1),\n  xlab = expression(sigma), ylab = expression(phi),\n  col.regions = cm.colors, contour = TRUE,\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = 0, units = \"inches\"),\n      right.padding = list(x = 0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.5, units = \"inches\"),\n      top.padding = list(x = -.5, units = \"inches\")\n    )\n  )\n)\n\n\n\n\n\n\n图 32.4: 对数似然函数的等高线图\n\n\n\n\n上图中没有看到许多局部极小值，与作者论文中的图 1 似乎不符。原因是什么？似然函数中涉及到的矩阵运算不精确，应该设计精度更高的运算方式？lattice 包绘图引擎无法展示更加细微的差异？还有一种解释，上图是对的，算法迭代时，对不同的初值，常常收敛到不同的结果，而这些不同的结果都位于岭上不同位置，对应的对数似然值却又几乎一样。\n作为验证，下面调用 nlme 包的 gls() 函数拟合数据，参数的极大似然估计结果与全局优化求解器的结果比较一致。参数估计结果 \\((\\sigma, \\phi)= (63.93429, 6.121352)\\) ，对数似然函数值为 -244.6006 ，自编的似然函数 log_lik() 在最优解处的值为 -196.8158，再加上之前扔掉的常数项 -52 / 2 * log(2 * pi) ，就是 -244.6006 ，丝毫不差。\n\nlibrary(nlme)\nfit_topo_ml &lt;- gls(z ~ 1,\n  data = topo, method = \"ML\",\n  correlation = corExp(value = 65, form = ~ x + y)\n)\nsummary(fit_topo_ml)\n\n#&gt; Generalized least squares fit by maximum likelihood\n#&gt;   Model: z ~ 1 \n#&gt;   Data: topo \n#&gt;        AIC     BIC    logLik\n#&gt;   495.2012 501.055 -244.6006\n#&gt; \n#&gt; Correlation Structure: Exponential spatial correlation\n#&gt;  Formula: ~x + y \n#&gt;  Parameter estimate(s):\n#&gt;    range \n#&gt; 6.121352 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Value Std.Error  t-value p-value\n#&gt; (Intercept) 863.708  45.49859 18.98318       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.7169766 -1.1919732 -0.5272282  0.1453374  1.5061096 \n#&gt; \n#&gt; Residual standard error: 63.93429 \n#&gt; Degrees of freedom: 52 total; 51 residual\n\n\n如果使用限制极大似然估计，会发现参数估计结果与之相距甚远，而对数似然函数值相差无几。参数估计结果 \\((\\sigma,\\phi) = (128.8275, 25.47324)\\) 。\n\nfit_topo_reml &lt;- gls(z ~ 1,\n  data = topo, method = \"REML\",\n  correlation = corExp(value = 65, form = ~ x + y)\n)\nsummary(fit_topo_reml)\n\n#&gt; Generalized least squares fit by REML\n#&gt;   Model: z ~ 1 \n#&gt;   Data: topo \n#&gt;        AIC      BIC    logLik\n#&gt;   485.1558 490.9513 -239.5779\n#&gt; \n#&gt; Correlation Structure: Exponential spatial correlation\n#&gt;  Formula: ~x + y \n#&gt;  Parameter estimate(s):\n#&gt;    range \n#&gt; 25.47324 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Value Std.Error  t-value p-value\n#&gt; (Intercept) 877.8956  116.7163 7.521619       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.45850507 -0.70167923 -0.37178079 -0.03800119  0.63732032 \n#&gt; \n#&gt; Residual standard error: 128.8275 \n#&gt; Degrees of freedom: 52 total; 51 residual",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-poisson-mixture-distributions",
    "href": "optimization-problems.html#sec-poisson-mixture-distributions",
    "title": "32  优化问题",
    "section": "\n32.4 泊松混合分布",
    "text": "32.4 泊松混合分布\n有限混合模型（Finite Mixtures of Distributions）的应用非常广泛，本节参考 BB 包 (Varadhan 和 Gilbert 2009) 的帮助手册，以泊松混合分布为例，介绍其参数的极大似然估计。更多详细的理论和算法介绍从略，感兴趣的读者可以查阅相关文献 (Hasselblad 1969)。BB 包比内置函数 optim() 功能更强，可以求解大规模非线性方程组，也可以求解带简单约束的非线性优化问题，还可以从多个初始值出发寻找全局最优解。\n两个泊松分布以一定比例 \\(p\\) 混合，以概率 \\(p\\) 服从泊松分布 \\(\\mathrm{Poisson}(\\lambda_1)\\) ，而以概率 \\(1-p\\) 服从泊松分布 \\(\\mathrm{Poisson}(\\lambda_1)\\) 。\n\\[\np\\times \\mathrm{Poisson}(\\lambda_1) + (1 - p)\\times \\mathrm{Poisson}(\\lambda_2)\n\\]\n泊松混合分布的概率密度函数 \\(f(x;p,\\lambda_1,\\lambda_2)\\) 如下：\n\\[\nf(x;p,\\lambda_1,\\lambda_2) = p \\times \\frac{\\lambda_1^x \\exp(-\\lambda_1)}{x!} + (1 - p) \\times \\frac{\\lambda_2^x \\exp(-\\lambda_2)}{x!}\n\\]\n随机变量 \\(X\\) 服从参数为 \\(p\\) 的伯努利分布 \\(X \\sim \\mathrm{Bernoulli}(1, p)\\) ，随机变量 \\(Y\\) 服从泊松混合分布，在伯努利分布的基础上，泊松混合分布也可作如下定义：\n\\[\n\\begin{array}{l}\nY \\sim \\left\\{\n\\begin{array}{l}\n\\mathrm{Poisson}(\\lambda_1), \\quad \\text{当} ~ X = 1 ~ \\text{时},\\\\\n\\mathrm{Poisson}(\\lambda_2), \\quad \\text{当} ~ X = 0 ~ \\text{时}.\n\\end{array} \\right.\n\\end{array}\n\\]\n对数似然函数如下：\n\\[\n\\ell(p,\\lambda_1,\\lambda_2) = \\sum_{i=0}^{n}y_i \\log\\big(p\\times \\exp(-\\lambda_1) \\times\\frac{\\lambda_1^{x_i}}{x_i!} + (1 - p)\\times \\exp(-\\lambda_2) \\times\\frac{\\lambda_2 ^{x_i}}{x_i!} \\big)\n\\]\n下 表格 32.1 数据来自 1947 年 Walter Schilling 发表在 JASA 的一篇文章 (Schilling 1947)。连续三年搜集伦敦《泰晤士报》刊登的死亡告示，每天的告示发布 80 岁及以上女性死亡人数。经过汇总统计，发现，在三年里，没有人死亡的告示出现 162 次，死亡 1 人的告示出现 267 次。\n\n\n表格 32.1: 死亡人数的统计\n\n\n\n死亡人数\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n发生频次\n162\n267\n271\n185\n111\n61\n27\n8\n3\n1\n\n\n\n\n\n考虑到夏季和冬季对老人死亡率的影响是不同的，因此，引入泊松混合分布来对数据建模。\n\n# 对数似然函数\n# p 是一个长度为 3 的向量\n# y 是观测数据向量\npoissmix_loglik &lt;- function(p, y) {\n  i &lt;- 0:(length(y) - 1)\n  loglik &lt;- y * log(p[1] * exp(-p[2]) * p[2]^i / exp(lgamma(i + 1)) +\n    (1 - p[1]) * exp(-p[3]) * p[3]^i / exp(lgamma(i + 1)))\n  sum(loglik)\n}\n# lgamma(i + 1) 表示整数 i 的阶乘的对数\n# 参数的下限\nlo &lt;- c(0, 0, 0)\n# 参数的上限\nhi &lt;- c(1, Inf, Inf)\n# 随机生成一组参数初始值\np0 &lt;- runif(3, c(0.2, 1, 1), c(0.8, 5, 8)) \n# 汇总统计出来的死亡人数的频次分布\ny &lt;- c(162, 267, 271, 185, 111, 61, 27, 8, 3, 1)\n\n调用 BB 包的函数 BBoptim() 求解多元非线性箱式约束优化问题。\n\nlibrary(BB)\n# 参数估计\nans &lt;- BBoptim(\n  par = p0, fn = poissmix_loglik, y = y,\n  lower = lo, upper = hi, \n  control = list(maximize = TRUE)\n)\n\n#&gt; iter:  0  f-value:  -2091.064  pgrad:  239.0115 \n#&gt; iter:  10  f-value:  -1990.866  pgrad:  3.111989 \n#&gt; iter:  20  f-value:  -1990.208  pgrad:  1.174074 \n#&gt; iter:  30  f-value:  -1989.957  pgrad:  0.2473098 \n#&gt; iter:  40  f-value:  -1989.946  pgrad:  0.00578666 \n#&gt; iter:  50  f-value:  -1989.946  pgrad:  0.000259206 \n#&gt;   Successful convergence.\n\nans\n\n#&gt; $par\n#&gt; [1] 0.6401434 2.6633690 1.2560436\n#&gt; \n#&gt; $value\n#&gt; [1] -1989.946\n#&gt; \n#&gt; $gradient\n#&gt; [1] 0.0002523848\n#&gt; \n#&gt; $fn.reduction\n#&gt; [1] -101.1182\n#&gt; \n#&gt; $iter\n#&gt; [1] 54\n#&gt; \n#&gt; $feval\n#&gt; [1] 158\n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"Successful convergence\"\n#&gt; \n#&gt; $cpar\n#&gt; method      M \n#&gt;      2     50\n\n\nnumDeriv::hessian 计算极大似然点的黑塞矩阵，然后计算参数估计的标准差。\n\n# 黑塞矩阵\nhess &lt;- numDeriv::hessian(x = ans$par, func = poissmix_loglik, y = y)\nhess\n\n#&gt;           [,1]      [,2]      [,3]\n#&gt; [1,] -907.1445 -341.2707 -270.2220\n#&gt; [2,] -341.2707 -192.7964  -61.6797\n#&gt; [3,] -270.2220  -61.6797 -113.4704\n\n# 标准差\nse &lt;- sqrt(diag(solve(-hess)))\nse\n\n#&gt; [1] 0.1946749 0.2504619 0.3500384\n\n\nmultiStart 从不同初始值出发寻找全局最大值，先找一系列局部极大值，通过比较获得全局最大值。\n\n# 随机生成 10 组初始值\np0 &lt;- matrix(runif(30, c(0.2, 1, 1), c(0.8, 8, 8)), \n             nrow = 10, ncol = 3, byrow = TRUE)\nans &lt;- multiStart(\n  par = p0, fn = poissmix_loglik, action = \"optimize\",\n  y = y, lower = lo, upper = hi, quiet = TRUE,\n  control = list(maximize = TRUE, trace = FALSE)\n)\n# 筛选出迭代收敛的解\npmat &lt;- round(cbind(ans$fvalue[ans$conv], ans$par[ans$conv, ]), 4)\ndimnames(pmat) &lt;- list(NULL, c(\"fvalue\", \"parameter 1\", \n                               \"parameter 2\", \"parameter 3\"))\n# 去掉结果一样的重复解\npmat[!duplicated(pmat), ]\n\n#&gt;         fvalue parameter 1 parameter 2 parameter 3\n#&gt; [1,] -1989.946      0.6401      2.6634      1.2561\n#&gt; [2,] -1989.946      0.3599      1.2561      2.6634",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-maximum-likelihood-estimation",
    "href": "optimization-problems.html#sec-maximum-likelihood-estimation",
    "title": "32  优化问题",
    "section": "\n32.5 极大似然估计",
    "text": "32.5 极大似然估计\n一元函数最优化问题和求根问题是相关的。在统计应用中，二项分布的比例参数的置信区间估计涉及求根，伽马分布的参数的极大似然估计涉及求根。下面介绍求根在估计伽马分布的参数中的应用。\n形状参数为 \\(\\alpha\\) 和尺度参数为 \\(\\sigma\\) 的伽马分布的概率密度函数 \\(f(x;\\alpha, \\sigma)\\) 如下：\n\\[\nf(x;\\alpha,\\sigma) = \\frac{1}{\\sigma^\\alpha \\Gamma(\\alpha)}x^{\\alpha - 1} \\exp(- \\frac{x}{\\sigma}), \\quad \\alpha \\geq 0, \\sigma &gt; 0\n\\]\n其中，\\(\\Gamma(\\cdot)\\) 表示伽马函数，伽马分布的均值为 \\(\\alpha \\sigma\\) ，方差为 \\(\\alpha\\sigma^2\\) 。下 图 32.5 展示两个伽马分布的概率密度函数，形状参数分别为 5 和 9，尺度参数均为 1，即伽马分布 \\(f(x; 5, 1)\\) 和 \\(f(x; 9, 1)\\) 。\n\n代码ggplot() +\n  geom_function(\n    fun = dgamma, args = list(shape = 9, scale = 1),\n    aes(colour = \"list(alpha == 9, sigma == 1)\"),\n    linewidth = 1.2, xlim = c(0, 20), \n  ) +\n  geom_function(\n    fun = dgamma, args = list(shape = 5, scale = 1),\n    aes(colour = \"list(alpha == 5, sigma == 1)\"),\n    linewidth = 1.2, xlim = c(0, 20)\n  ) +\n  scale_colour_viridis_d(\n    labels = scales::parse_format(),\n    begin = 0.3, end = 0.7,\n    option = \"C\"\n  ) +\n  theme_bw(base_family = \"sans\") +\n  theme(axis.title = element_text(family = \"Noto Serif CJK SC\"),\n        legend.title = element_text(family = \"Noto Serif CJK SC\"),\n        legend.position = \"top\", legend.justification = \"right\") +\n  labs(x = \"随机变量\", y = \"概率密度\", color = \"参数\")\n\n\n\n\n\n\n图 32.5: 伽马分布的概率密度函数\n\n\n\n\n给定一组来自伽马分布的样本 \\(x_1,x_2,\\ldots,x_n\\) ，关于参数 \\(\\alpha\\) 和 \\(\\sigma\\) 的似然函数如下：\n\\[\n\\mathcal{L}(\\alpha, \\sigma) = \\big(\\frac{1}{\\sigma^\\alpha \\Gamma(\\alpha)}\\big)^{n} (\\prod_{i=1}^{n} x_i)^{\\alpha - 1} \\exp(- \\frac{ \\sum_{i=1}^{n} x_i }{\\sigma})\n\\]\n则，其对数似然函数如下：\n\\[\n\\ell(\\alpha, \\sigma) = -n\\big(\\alpha \\log(\\sigma) + \\log \\Gamma(\\alpha) \\big) + (\\alpha - 1)\\sum_{i=1}^{n}\\log(x_i) - \\frac{ \\sum_{i=1}^{n} x_i }{\\sigma}\n\\]\n对数似然函数关于参数 \\(\\alpha\\) 和 \\(\\sigma\\) 的偏导数如下：\n\\[\n\\begin{aligned}\n\\frac{\\partial \\ell(\\alpha,\\sigma)}{\\partial \\alpha} &= -n\\Big( \\log(\\sigma) + \\big(\\log \\Gamma(\\alpha)\\big)' \\Big) + \\sum_{i=1}^{n}\\log (x_i) = 0 \\\\\n\\frac{\\partial \\ell(\\alpha,\\sigma)}{\\partial \\sigma} &= - \\frac{n\\alpha}{\\sigma} + \\frac{\\sum_{i=1}^{n}x_i}{\\sigma^2} = 0\n\\end{aligned}\n\\]\n根据第二个式子可得 \\(\\sigma = \\frac{1}{n\\alpha}\\sum_{i=1}^{n}x_i\\) ，将其代入第一个式子可得\n\\[\n\\log(\\alpha) - \\big(\\log \\Gamma(\\alpha)\\big)' = \\log\\big(\\frac{1}{n}\\sum_{i=1}^{n}x_i\\big) - \\frac{1}{n}\\sum_{i=1}^{n}\\log (x_i)\n\\]\n\nset.seed(20232023)\nx &lt;- rgamma(1000, shape = 1.5, scale = 2)\n# 形状参数和尺度参数的矩估计\nc(mean(x)^2 /var(x), var(x)/mean(x))\n\n#&gt; [1] 1.636030 1.902239\n\n# 极大似然估计\n# 常量\ncc &lt;- log(mean(x)) - mean(log(x))\n# 方程\nfun &lt;- function(alpha){\n  log(alpha) - digamma(alpha) - cc\n}\n# 找根\nuniroot(f = fun, interval = c(1, 3))\n\n#&gt; $root\n#&gt; [1] 1.610272\n#&gt; \n#&gt; $f.root\n#&gt; [1] 2.825244e-09\n#&gt; \n#&gt; $iter\n#&gt; [1] 6\n#&gt; \n#&gt; $init.it\n#&gt; [1] NA\n#&gt; \n#&gt; $estim.prec\n#&gt; [1] 6.103516e-05\n\n\n求得形状参数的估计 \\(\\alpha = 1.610272\\) ，进而，可得尺度参数的估计 \\(\\sigma = 1.932667\\) 。\n函数 uniroot() 只能找到方程的一个根，rootSolve 包采用牛顿-拉弗森（ Newton-Raphson ）算法找一元非线性方程（组）的根，特别适合有多个根的情况。\n\nlibrary(rootSolve)\n# 非线性方程（组）的根\nmultiroot(f = fun, start = 1.2)\n\n#&gt; $root\n#&gt; [1] 1.610272\n#&gt; \n#&gt; $f.root\n#&gt; [1] 3.121097e-10\n#&gt; \n#&gt; $iter\n#&gt; [1] 5\n#&gt; \n#&gt; $estim.precis\n#&gt; [1] 3.121097e-10\n\n# 搜索一个方程在区间内所有的根\nuniroot.all(f = fun, interval = c(1, 3))\n\n#&gt; [1] 1.610339",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-optimization-exercises",
    "href": "optimization-problems.html#sec-optimization-exercises",
    "title": "32  优化问题",
    "section": "\n32.6 习题",
    "text": "32.6 习题\n\n某人要周游美国各州，从纽约出发，走遍 50 个州的行政中心，最后回到纽约。规划旅行线路使得总行程最短。Base R 内置的 R 包 datasets 包含美国 50 个州的地理中心数据 state.center 。\n有限混合模型也常用 EM 算法来估计参数，美国黄石公园老忠实间歇泉的喷发规律近似为二维高斯混合分布，请读者以 R 软件内置的数据集 faithful 为基础，采用 EM 算法估计参数。\n\n获取百度、阿里、腾讯、京东、美团、滴滴、字节、360、网易、新浪等 10 支股票的历史股价数据。根据 2021-12-01 至 2022-12-01 股票的调整价计算 12 个月的股价收益率，根据月度股价收益率和波动率数据，设置投资组合，使得月度收益率不低于2%。股票代码以数字编码和 HK 结尾的为港股代码，有的公司在美股和港股上都有。可以用 quantmod 包下载各个公司的股价数据，下载拼多多股价数据的代码如下：\nquantmod::getSymbols(\"PDD\", auto.assign = FALSE, src = \"yahoo\")\n\n\n表格 32.2: 一些互联网公司及股票代码\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n公司\n美团\n阿里巴巴\n京东\n百度\n腾讯\n拼多多\n京东\n阿里巴巴\n\n\n股票代码\n3690.HK\n9988.HK\n9618.HK\n9888.HK\n0700.HK\nPDD\nJD\nBABA\n\n\n\n\n\n\n\n\n\n\n\nHahsler, Michael, 和 Kurt Hornik. 2007. 《TSP: Infrastructure for the traveling salesperson problem》. Journal of Statistical Software 23 (2): 1–21. https://doi.org/10.18637/jss.v023.i02.\n\n\nHasselblad, Victor. 1969. 《Estimation of Finite Mixtures of Distributions from the Exponential Family》. Journal of the American Statistical Association 64 (328): 1459–71. https://doi.org/10.1080/01621459.1969.10501071.\n\n\nSchilling, Walter. 1947. 《A Frequency Distribution Represented as the Sum of Two Poisson Distributions》. Journal of the American Statistical Association 42 (239): 407–24.\n\n\nVaradhan, Ravi, 和 Paul Gilbert. 2009. 《BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function》. Journal of Statistical Software 32 (4): 1–26. https://www.jstatsoft.org/v32/i04/.\n\n\nWarnes, J. J., 和 B. D. Ripley. 1987. 《Problems with likelihood estimation of covariance functions of spatial gaussian processes》. Biometrika 74 (3): 640–42.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "probabilistic-reasoning-framework.html",
    "href": "probabilistic-reasoning-framework.html",
    "title": "33  概率推理框架",
    "section": "",
    "text": "33.1 Stan 概览\nStan 是一个贝叶斯统计建模和计算的概率推理框架，也是一门用于贝叶斯推断和优化的概率编程语言 (Gelman, Lee, 和 Guo 2015; Carpenter 等 2017)。它使用汉密尔顿蒙特卡罗算法（Hamiltonian Monte Carlo algorithm ，简称 HMC 算法）抽样，内置一种可以自适应调整采样步长的 No-U-Turn sampler （简称 NUTS 采样器） 。Stan 还提供自动微分变分推断（Automatic Differentiation Variational Inference algorithm 简称 ADVI 算法）算法做近似贝叶斯推断获取参数的后验分布，以及拟牛顿法（the limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm 简称 L-BFGS 算法）优化算法获取参数的惩罚极大似然估计。\n经过 10 多年的发展，Stan 已经形成一个相对成熟的生态，它提供统计建模、数据分析和预测能力，广泛应用于社会、生物、物理、工程、商业等领域，在学术界和工业界的影响力也不小。下 图 33.1 是 Stan 生态中各组件依赖架构图，math 库(Carpenter 等 2015)是 Stan 框架最核心的组件，它基于 Boost 、Eigen 、OpenCL 、SUNDIALS 和 oneTBB 等诸多 C++ 库，提供概率推理、自动微分、矩阵计算、并行计算、GPU 计算和求解代数微分方程等功能。\nflowchart TB\n  Boost(Boost) --&gt; math(math)\n  Eigen(Eigen) --&gt; math(math)\n  OpenCL(OpenCL) --&gt; math(math)\n  SUNDIALS(SUNDIALS) --&gt; math(math)\n  oneTBB(oneTBB) --&gt; math(math)\n  math(math) --&gt; Stan(Stan)\n  Stan(Stan) --&gt; CmdStan(CmdStan)\n  Stan(Stan) --&gt; RStan(RStan)\n  RStan --&gt; rstanarm(rstanarm)\n  RStan --&gt; brms(brms)\n  RStan --&gt; prophet(prophet)\n  CmdStan --&gt; CmdStanR(CmdStanR)\n  CmdStan --&gt; CmdStanPy(CmdStanPy)\n  CmdStan --&gt; MathematicaStan(MathematicaStan)\n  CmdStanR --&gt; bayesplot(bayesplot)\n  CmdStanR --&gt; loo(loo)\n  CmdStanR --&gt; posterior(posterior)\n  CmdStanR --&gt; projpred(projpred)\n\n\n\n\n图 33.1: Stan、CmdStan 和 CmdStanR 等的依赖关系图\nCmdStan 是 Stan 的命令行接口，可在 MacOS / Linux 的终端软件，Windows 的命令行窗口或 PowerShell 软件中使用。CmdStanR (Gabry, Češnovar, 和 Johnson 2023)、CmdStanPy 和 MathematicaStan 分别是 CmdStan 的 R 语言、Python 语言和 Mathematica 语言接口。每次当 Stan 发布新版本时，CmdStan 也会随之发布新版，只需指定新的 CmdStan 安装路径，CmdStanR 就可以使用上，CmdStanR 包与 Stan 是相互独立的更新机制。 CmdStanR 负责处理 CmdStan 运行的结果，而编译代码，生成模型和模拟采样等都是由 CmdStan 完成。入门 CmdStanR 后，可以快速转入对 Stan 底层原理的学习，有利于编码符合实际需要的复杂模型，有利于掌握常用的炼丹技巧，提高科研和工作的效率。\n此外，bayesplot 包 (Gabry 等 2019) 针对 cmdstanr 包生成的拟合模型对象提供一系列可视化图形，用于诊断采样过程、展示后验分布等。loo 包(Vehtari, Gelman, 和 Gabry 2017)计算 LOOIC （留一交叉验证信息准则）和 WAIC （通用信息准则）等指标，用于模型评估与比较。posterior 包 (Vehtari 等 2021) 对采样数据提供统一的操作方法和类型转化，计算常用的后验分布的统计量等。projpred 包 (Piironen 和 Vehtari 2017a; Piironen, Paasiniemi, 和 Vehtari 2020) 实现投影预测推断用于模型预测和特征选择。\nrstan 包(Stan Development Team 2023a)是 Stan 的 R 语言接口，该接口依赖 Rcpp (Eddelbuettel 和 François 2011; Eddelbuettel 和 Balamuta 2018)、RcppEigen (Bates 和 Eddelbuettel 2013)、BH (Eddelbuettel, Emerson, 和 Kane 2023)、RcppParallel (Allaire 等 2023)和 StanHeaders (Stan Development Team 2023b)等 R 包，由于存在众多上游 R 包依赖和兼容性问题，尤其在 Windows 系统环境中，因此，RStan 的安装、更新都比较麻烦。RStan 的更新通常严重滞后于 Stan 的更新，不利于及时地使用最新的学术研究成果。 而相比于 rstan 包，CmdStanR 更加轻量，可以更快地将 CmdStan 的新功能融入进来，而且 cmdstanr 和 CmdStan 是分离的，方便用户升级和维护。\nrstanarm (Goodrich 等 2023) 和 brms (Bürkner 2017) 是 RStan 的扩展包，各自提供了一套用于表示统计模型的公式语法。它们都支持丰富的统计模型，比如线性模型、广义线性模型、线性混合效应模型、广义线性混合效应模型等。相比于 rstan， 它们使用起来更加方便，因为它内置了大量统计模型的 Stan 实现，即将公式语法翻译成 Stan 编码的模型，然后调用 rstan 或 cmdstanr 翻译成 C++，最后编译成动态链接库。除了依赖 rstan 包，rstanarm 和 brms 还依赖大量其它 R 包。\n顺便一提，类似的用于概率推理和统计分析的框架，还有 Python 社区的 PyMC (Abril-Pla O 2023)和 TensorFlow Probability (Joshua V. Dillon 2017)，它们采用的 MCMC 采样算法也是基于 NUTS 的 HMC 算法。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>概率推理框架</span>"
    ]
  },
  {
    "objectID": "probabilistic-reasoning-framework.html#sec-getting-started",
    "href": "probabilistic-reasoning-framework.html#sec-getting-started",
    "title": "33  概率推理框架",
    "section": "\n33.2 Stan 入门",
    "text": "33.2 Stan 入门\n\n33.2.1 Stan 的基础语法\n下面以一个简单示例介绍 Stan 的用法，包括 Stan 的基本用法、变量类型、代码结构等，\n考虑一个已知方差的正态分布，设 \\(-3, -2, -1, 0, 1, 2, 3\\) 是取自正态分布 \\(\\mathcal{N}(\\mu,1)\\) 的一个样本，也是取自该正态分布的一组随机数。现在的问题是估计该正态分布的均值参数 \\(\\mu\\) 。Stan 编码的正态分布模型如下：\n\ntransformed data {\n  vector[7] y = [-3, -2, -1, 0, 1, 2, 3]';\n}\nparameters {\n  real mu;\n}\nmodel {\n  y ~ normal(mu, 1);\n}\n\n\ntransformed data 代码块是一组已知的数据，这部分数据是不需要从外部传递进来的。这个样本是以向量存储的，需要声明向量的长度和类型（默认类型是实数），每一行以分号结尾，这与 C++ 的语法一样。\nparameters 代码块是未知的参数，需要声明各个参数的类型。这里只有一个参数，且只是一个未知的实数，声明类型即可。\nmodel 代码块是抽样语句表示的模型结构，符号 ~ 表示服从的意思，函数 y ~ normal(mu, 1) 是正态分布的抽样语句。\n\n接下来，编译 Stan 代码，准备参数初值，配置采样的参数。首先加载 cmdstanr 包，设置 2 条迭代链，给每条链设置相同的参数初始值。代码编译后，生成一个模型对象 mod_gaussian，接着，调用方法 sample() ，传递迭代初值 init，初始化阶段的迭代次数 iter_warmup ，采样阶段的迭代次数 iter_sampling，采样的链条数 chains 及并行时 分配的 CPU 核心数 parallel_chains ，随机数种子 seed 。\n\nlibrary(cmdstanr)\nnchains &lt;- 2 # 2 条迭代链\n# 给每条链设置相同的参数初始值\ninits_data_gaussian &lt;- lapply(1:nchains, function(i) {\n  list(\n    mu = 1\n  )\n})\n\nfit_gaussian &lt;- mod_gaussian$sample(\n  init = inits_data_gaussian,   # 迭代初值\n  iter_warmup = 200,            # 每条链初始化迭代次数\n  iter_sampling = 200,          # 每条链采样迭代次数\n  chains = nchains,         # 马尔科夫链的数目\n  parallel_chains = nchains,# 指定 CPU 核心数，可以给每条链分配一个\n  seed = 20232023           # 设置随机数种子，不要使用 set.seed() 函数\n)\n\n#&gt; Running MCMC with 2 parallel chains...\n#&gt; \n#&gt; Chain 1 Iteration:   1 / 400 [  0%]  (Warmup) \n#&gt; Chain 1 Iteration: 100 / 400 [ 25%]  (Warmup) \n#&gt; Chain 1 Iteration: 200 / 400 [ 50%]  (Warmup) \n#&gt; Chain 1 Iteration: 201 / 400 [ 50%]  (Sampling) \n#&gt; Chain 1 Iteration: 300 / 400 [ 75%]  (Sampling) \n#&gt; Chain 1 Iteration: 400 / 400 [100%]  (Sampling) \n#&gt; Chain 2 Iteration:   1 / 400 [  0%]  (Warmup) \n#&gt; Chain 2 Iteration: 100 / 400 [ 25%]  (Warmup) \n#&gt; Chain 2 Iteration: 200 / 400 [ 50%]  (Warmup) \n#&gt; Chain 2 Iteration: 201 / 400 [ 50%]  (Sampling) \n#&gt; Chain 2 Iteration: 300 / 400 [ 75%]  (Sampling) \n#&gt; Chain 2 Iteration: 400 / 400 [100%]  (Sampling) \n#&gt; Chain 1 finished in 0.0 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; \n#&gt; Both chains finished successfully.\n#&gt; Mean chain execution time: 0.0 seconds.\n#&gt; Total execution time: 0.3 seconds.\n\n\n默认情况下，采样过程中会输出一些信息，以上是 2 条链并行采样的过程，给出百分比进度及时间消耗。采样完成后，调用方法 summary() 汇总和展示采样结果。\n\nfit_gaussian$summary()\n\n#&gt; # A tibble: 2 × 10\n#&gt;   variable     mean   median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -14.4    -14.2    0.708 0.212 -15.6   -14.0    1.01     177.     220.\n#&gt; 2 mu         0.0365   0.0307 0.348 0.298  -0.511   0.572  1.01     229.     173.\n\n\n输出模型中各个参数的后验分布的一些统计量，如均值（mean）、中位数（median）、标准差（sd），0.05 分位点（q5），0.95 分位点（q95）等。此外，还有 lp__ 后验对数概率密度值，每个模型都会有该值。summary() 方法有一些参数可以控制数字的显示方式和精度。下面展示的是保留 4 位有效数字的结果。\n\nfit_gaussian$summary(.num_args = list(sigfig = 4, notation = \"dec\"))\n\n#&gt; # A tibble: 2 × 10\n#&gt;   variable      mean    median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -14.43    -14.15    0.7083 0.2118 -15.60   -14.00   1.007    177.2\n#&gt; 2 mu         0.03647   0.03073 0.3476 0.2978  -0.5115   0.5722 1.007    229.0\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n接下来，要介绍 Stan 代码中的保留字 target 的含义，因为它在 Stan 代码中很常见，与输出结果中的 lp__ 一行紧密相关。\n\n\nlp__ 表示后验概率密度函数的对数。\ntarget 累加一些和参数无关的数不影响参数的估计，但影响 lp__ 的值。\n抽样语句表示模型会扔掉后验概率密度函数的对数的常数项。\n\n\nlibrary(ggplot2)\nlibrary(bayesplot)\nmcmc_hist(fit_gaussian$draws(\"lp__\")) +\n  theme_classic()\n\n\n\n\n\n\n图 33.2: lp__ 的后验分布\n\n\n\n\n为此，不妨在之前的 Stan 代码的基础上添加两行，新的 Stan 代码如下：\n\ntransformed data {\n  vector[7] y = [-3, -2, -1, 0, 1, 2, 3]';\n}\nparameters {\n  real mu;\n}\nmodel {\n  y ~ normal(mu, 1);\n  target += 12345;\n  target += mean(exp(y));\n}\n\n接着，再次编译代码、采样，为了节约篇幅，设置两个参数 show_messages 和 refresh ，不显示中间过程和采样进度。其它参数设置不变，代码如下：\n\nfit_gaussian &lt;- mod_gaussian_target$sample(\n  init = inits_data_gaussian,   \n  iter_warmup = 200,            \n  iter_sampling = 200,          \n  chains = nchains,             \n  parallel_chains = nchains,      \n  show_messages = FALSE,    # 不显示中间过程\n  refresh = 0,              # 不显示采样进度\n  seed = 20232023           \n)\nfit_gaussian$summary(.num_args = list(sigfig = 4, notation = \"dec\"))\n\n#&gt; # A tibble: 2 × 10\n#&gt;   variable        mean      median     sd    mad         q5        q95  rhat\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 lp__     12335.      12335.      0.7074 0.1483 12334.     12336.     1.008\n#&gt; 2 mu           0.03647     0.03073 0.3476 0.2978    -0.5115     0.5722 1.007\n#&gt; # ℹ 2 more variables: ess_bulk &lt;dbl&gt;, ess_tail &lt;dbl&gt;\n\n\n可以清楚地看到 lp__ 的值发生了变化，而参数 mu 的值没有变化。这是因为抽样语句 y ~ normal(mu, 1); 隐含一个 lp__ ，target 指代 lp__ 的值，符号 += 表示累加。两次累加后得到 12335.09。\nmodel {\n  y ~ normal(mu, 1);\n  target += 12345;\n  target += mean(exp(y));\n}\n\ny &lt;- c(-3, -2, -1, 0, 1, 2, 3)\n12345 + mean(exp(y)) - 14.45 \n\n#&gt; [1] 12335.09\n\n\n下面从概率密度函数出发，用 R 语言来计算逐点对数似然函数值。一般地，不妨设 \\(x_1,x_2,\\cdots,x_n\\) 是来自正态总体 \\(\\mathcal{N}(\\mu,1)\\) 的一个样本。则正态分布的概率密度函数 \\(f(x)\\) 的对数如下：\n\\[\n\\log f(x) = \\log \\frac{1}{\\sqrt{2\\pi}} - \\frac{(x - \\mu)^2}{2}\n\\]\n已知参数 \\(\\mu\\) 是一个非常接近 0 的数，不妨将 \\(\\mu = 0\\) 代入计算。\n\nsum(dnorm(x = y, mean = 0, sd = 1, log = TRUE))\n\n#&gt; [1] -20.43257\n\n\n去掉常数项后，计算概率密度函数值的对数和。\n\n# 扔掉常数\nf &lt;- function(y, mu) {\n  return(-0.5 * (y - mu)^2)\n}\nsum(f(-3:3, 0))\n\n#&gt; [1] -14\n\n\n这就比较接近原 lp__ 的值了，所以，lp__ 表示后验概率密度函数的对数，扔掉了与参数无关的常数项。若以概率密度函数的对数 normal_lpdf 替代抽样语句，则常数项是保留的。normal_lpdf 是 Stan 内置的函数，输入值为随机变量的取值 y 、位置参数 mu 和尺度参数 sigma，返回值为 real 实数。\nreal normal_lpdf(reals y | reals mu, reals sigma)\n\ntransformed data {\n  vector[7] y = [-3, -2, -1, 0, 1, 2, 3]';\n}\nparameters {\n  real mu;\n}\nmodel {\n  target += normal_lpdf(y | mu, 1);\n}\n\n接着，编译上述代码以及重复采样的步骤，参数设置也一样。\n\nfit_gaussian &lt;- mod_gaussian_lpdf$sample(\n  init = inits_data_gaussian, \n  iter_warmup = 200,            \n  iter_sampling = 200,          \n  chains = nchains,            \n  parallel_chains = nchains,     \n  show_messages = FALSE,\n  refresh = 0,            \n  seed = 20232023\n)\nfit_gaussian$summary(.num_args = list(sigfig = 4, notation = \"dec\"))\n\n#&gt; # A tibble: 2 × 10\n#&gt;   variable      mean    median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -20.86    -20.58    0.7083 0.2119 -22.03   -20.43   1.007    176.7\n#&gt; 2 mu         0.03647   0.03073 0.3476 0.2978  -0.5115   0.5722 1.007    229.0\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n可以看到，此时 lp__ 的值包含常数项，两种表示方式对参数的计算结果没有影响。\n\n33.2.2 Stan 的变量类型\nStan 语言和 C/C++ 语言比较类似，变量需要先声明再使用，函数需要用 return 返回值，总而言之，类型声明比较严格。变量的声明没有太多的内涵，就是 C++ 和 Stan 定义的语法，比如整型用 int 声明。建模过程中，时常需要将 R 语言环境中的数据传递给 Stan 代码编译出来的模型，而 Stan 是基于 C++ 语言，在变量类型方面有继承有发展。下表给出 Stan 与 R 语言中的变量类型对应关系。值得注意， R 语言的类型检查是不严格的，使用变量也不需要提前声明和初始化。Stan 语言中向量、矩阵的类型都是实数，下标也从 1 开始，元组类型和 R 语言中的列表类似，所有向量默认都是列向量。\n下表第一列表示 Stan 语言的变量类型，第二列给出使用该变量的声明示例，第三列给出 R 语言中构造该类型变量的示例。\n\n\n表格 33.1: Stan 变量类型和 R 语言中的对应\n\n\n\n\n\n\n\n\n类型\nStan 语言\nR 语言\n\n\n\n整型\nint x = 1;\nx = 1L\n\n\n实数\nreal x = 3.14;\nx = 3.14\n\n\n向量\nvector[3] x = [1, 2, 3]';\nx = c(1, 2, 3)\n\n\n矩阵\nmatrix[3,1] x;\nmatrix(data = c(1, 2, 3), nrow = 3)\n\n\n数组\narray[3] int x;\narray(data = c(1L, 2L, 3L), dim = c(3, 1, 1))\n\n\n元组\ntuple(vector[3],vector[3]) x;\nlist(x = c(1, 2, 3), y = c(4, 5, 6))\n\n\n\n\n\n\n\n33.2.3 Stan 的代码结构\nStan 代码文件最多有如下 7 块内容，模拟、拟合和预测模型会用到其中的一部分或全部。\nfunctions {\n  // ... function declarations and definitions ...\n}\ndata {\n  // ... declarations ...\n}\ntransformed data {\n   // ... declarations ... statements ...\n}\nparameters {\n   // ... declarations ...\n}\ntransformed parameters {\n   // ... declarations ... statements ...\n}\nmodel {\n   // ... declarations ... statements ...\n}\ngenerated quantities {\n   // ... declarations ... statements ...\n}\n\n33.2.4 Stan 的函数使用\nStan 有大量的内建函数，然而，有时候，Stan 内建的函数不足以满足需求，需要自己创建函数。下面以函数 cholesky_decompose 为例介绍 Stan 内置/一般函数的调用，在该函数的基础上自定义函数 cholesky_decompose2 ，这不过是对它改个名字，其它内容只要符合 Stan 语言即可，不甚重要。\n根据 Stan 官网函数 cholesky_decompose 帮助文档，Cholesky 分解的形式（Cholesky 分解有多种形式）如下：\n\\[\nM = LL^{\\top}\n\\]\n\\(M\\) 是一个对称正定的矩阵，而 \\(L\\) 是一个下三角矩阵。函数 cholesky_decompose 有一个参数 A， A 需要传递一个对称正定的矩阵。不妨设这个对称正定的矩阵为\n\\[\nM = \\begin{bmatrix}\n4 & 1 \\\\\n1 & 1\n\\end{bmatrix}\n\\]\n\n# 准备函数\nstan_file &lt;- write_stan_file(\"\nfunctions {\n matrix cholesky_decompose2(matrix A) {\n   return cholesky_decompose(A);\n }\n}\nparameters {\n real x;\n}\nmodel {\n x ~ std_normal();\n}\n\")\n\n接着，将以上 Stan 代码编译\n\nmod_cholesky_decompose &lt;- cmdstan_model(stan_file = stan_file, compile = TRUE)\n\n准备测试数据，只要是一个对称正定的矩阵都可以做 cholesky 分解。\n\n# 测试矩阵\nM &lt;- rbind(c(4, 1), c(1, 1))\n\ncmdstanr 包导出函数的方法将以上 Stan 代码中的函数部分独立导出。\n\n# 编译独立的函数\nmod_cholesky_decompose$expose_functions()\n\n现在，可以直接调用导出的函数 cholesky_decompose2 。\n\n# cholesky 分解\nmod_cholesky_decompose$functions$cholesky_decompose2(A = M)\n\n#&gt;      [,1]      [,2]\n#&gt; [1,]  2.0 0.0000000\n#&gt; [2,]  0.5 0.8660254\n\n\n最后，将 Stan 函数计算的结果与 R 语言内置的 cholesky 分解函数的结果比较。发现，函数 chol() 的结果正好是 cholesky_decompose2 的转置。\n\nchol(M)\n\n#&gt;      [,1]      [,2]\n#&gt; [1,]    2 0.5000000\n#&gt; [2,]    0 0.8660254\n\n\n查看帮助文档，可知 R 软件对 Cholesky 分解的定义如下：\n\\[\nM = L^{\\top}L\n\\]\n根据数学表达式，感觉上都是差不多的，但还是有差异。R 与 Stan 混合编程就需要注意这些表达上不同的，不然，排错会很麻烦。\n\n\n\n\n\n\n提示\n\n\n\nStanHeaders 可以编译和调用 Stan 的内置的数学函数，比如 Cholesky 分解函数 cholesky_decompose 。\n\nlibrary(StanHeaders)\nstanFunction(\"cholesky_decompose\", A = M)\n\n#&gt;      [,1]      [,2]\n#&gt; [1,]  2.0 0.0000000\n#&gt; [2,]  0.5 0.8660254\n\n\n可以看到，结果和前面一样。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>概率推理框架</span>"
    ]
  },
  {
    "objectID": "probabilistic-reasoning-framework.html#sec-choose-prior",
    "href": "probabilistic-reasoning-framework.html#sec-choose-prior",
    "title": "33  概率推理框架",
    "section": "\n33.3 先验分布",
    "text": "33.3 先验分布\n考虑一个响应变量服从伯努利分布的广义线性模型。\n\\[\n\\begin{aligned}\n&\\boldsymbol{y} \\sim \\mathrm{Bernoulli}(\\boldsymbol{p}) \\\\\n&\\mathrm{logit}(\\boldsymbol{p}) = \\log (\\frac{\\boldsymbol{p}}{1-\\boldsymbol{p}})=  \\alpha + X \\boldsymbol{\\beta}\n\\end{aligned}\n\\]\n下面模拟生成 2500 个样本，其中 10 个正态协变量，非 0 的回归系数是截距 \\(\\alpha = 1\\) 和向量 \\(\\boldsymbol{\\beta}\\) 中的 \\(\\beta_1 = 3,\\beta_2 = -2\\) 。对模型实际有用的是 3 个变量，采用贝叶斯建模，其它变量应该被收缩掉。贝叶斯收缩 （Bayesian shrinkage）与变量选择 （Variable selection） 是有关系的，先验分布影响收缩的力度。\n\nset.seed(2023)\nn &lt;- 2500\nk &lt;- 10\nX &lt;- matrix(rnorm(n * k), ncol = k)\ny &lt;- rbinom(n, size = 1, prob = plogis(1 + 3 * X[, 1] - 2 * X[, 2]))\n# 准备数据\nmdata &lt;- list(k = k, n = n, y = y, X = X)\n\n在贝叶斯先验分布中，有几个常用的概率分布，分别是正态分布、拉普拉斯分布（双指数分布）、柯西分布，下图集中展示了这几个的标准分布。\n\n代码dlaplace &lt;- function(x, mu = 0, sigma = 1) {\n  1 / (2*sigma) * exp(- abs(x - mu) / sigma)\n}\n\nggplot() +\n  geom_function(\n    fun = dnorm, args = list(mean = 0, sd = 1),\n    aes(colour = \"正态分布\"), linewidth = 1.2, xlim = c(-6, 6)\n  ) +\n  geom_function(\n    fun = dlaplace, args = list(mu = 0, sigma = 1),\n    aes(colour = \"双指数分布\"), linewidth = 1.2, xlim = c(-6, 6)\n  ) +\n  geom_function(\n    fun = dcauchy, args = list(location = 0, scale = 0.5),\n    aes(colour = \"柯西分布\"), linewidth = 1.2, xlim = c(-6, 6)\n  ) +\n  theme_classic() +\n  theme(legend.position = c(0.8, 0.8)) +\n  labs(x = \"$x$\", y = \"$f(x)$\", colour = \"先验分布\")\n\n#&gt; Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n#&gt; 3.5.0.\n#&gt; ℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n图 33.3: 几个常用的概率分布\n\n\n\n\n接下来，考虑几种常见的先验设置。\n\n33.3.1 正态先验\n指定回归系数 \\(\\alpha,\\beta\\) 的先验分布如下\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\mathcal{N}(0, 1000) \\\\\n\\beta &\\sim \\mathcal{N}(0, 1000)\n\\end{aligned}\n\\]\n正态分布中设置相当大的方差意味着分布相当扁平， \\(\\alpha,\\beta\\) 的取值在区间 \\((-\\infty,+\\infty)\\) 上比较均匀。\ndata {\n  int&lt;lower=1&gt; k;\n  int&lt;lower=0&gt; n;\n  matrix[n, k] X;\n  array[n] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  vector[k] beta;\n  real alpha;\n}\nmodel {\n  target += normal_lpdf(beta | 0, 1000);\n  target += normal_lpdf(alpha | 0, 1000);\n  target += bernoulli_logit_glm_lpmf(y | X, alpha, beta);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1 : n) {\n    log_lik[i] = bernoulli_logit_lpmf(y[i] | alpha + X[i] * beta);\n  }\n}\n\nmod_logit_normal &lt;- cmdstan_model(\n  stan_file = \"code/bernoulli_logit_glm_normal.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\nfit_logit_normal &lt;- mod_logit_normal$sample(\n  data = mdata,\n  chains = 2,\n  parallel_chains = 2,\n  iter_warmup = 1000, \n  iter_sampling = 1000, \n  threads_per_chain = 2, \n  seed = 20232023,\n  show_messages = FALSE,\n  refresh = 0\n)\n\n# 输出结果\nfit_logit_normal$summary(c(\"alpha\", \"beta\", \"lp__\"))\n\n#&gt; # A tibble: 12 × 10\n#&gt;    variable      mean    median     sd    mad         q5      q95  rhat ess_bulk\n#&gt;    &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha       1.02      1.02   0.0715 0.0728    0.899    1.13e+0 1.00     3082.\n#&gt;  2 beta[1]     3.14      3.13   0.133  0.135     2.93     3.36e+0 1.00     2103.\n#&gt;  3 beta[2]    -2.02     -2.02   0.0985 0.0999   -2.19    -1.86e+0 1.00     2192.\n#&gt;  4 beta[3]     0.0590    0.0586 0.0641 0.0644   -0.0456   1.65e-1 1.00     4654.\n#&gt;  5 beta[4]    -0.0270   -0.0252 0.0669 0.0640   -0.140    8.03e-2 1.00     4460.\n#&gt;  6 beta[5]     0.0122    0.0130 0.0682 0.0691   -0.100    1.25e-1 1.00     4532.\n#&gt;  7 beta[6]     0.0220    0.0205 0.0697 0.0683   -0.0938   1.36e-1 1.00     4304.\n#&gt;  8 beta[7]     0.103     0.102  0.0629 0.0619    0.00356  2.06e-1 0.999    4095.\n#&gt;  9 beta[8]    -0.0297   -0.0303 0.0667 0.0663   -0.143    7.91e-2 1.00     3671.\n#&gt; 10 beta[9]    -0.0870   -0.0856 0.0635 0.0615   -0.193    1.54e-2 1.00     4099.\n#&gt; 11 beta[10]    0.0818    0.0831 0.0639 0.0679   -0.0239   1.86e-1 1.00     4417.\n#&gt; 12 lp__     -843.     -842.     2.41   2.23   -847.      -8.39e+2 1.00      760.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\n33.3.2 Lasso 先验\n指定回归系数 \\(\\alpha,\\beta\\) 的先验分布如下\n\\[\n\\begin{aligned}\n\\lambda &\\sim \\mathrm{Half\\_Cauchy}(0,0.01) \\\\\n\\alpha  &\\sim \\mathrm{Double\\_exponential}(0, \\lambda) \\\\\n\\beta   &\\sim \\mathrm{Double\\_exponential}(0, \\lambda)\n\\end{aligned}\n\\]\n其中， \\(\\alpha,\\beta\\) 服从双指数分布，惩罚因子 \\(\\lambda\\) 服从柯西分布。顺便一提，若把双指数分布改为正态分布，则 Lasso 先验变为岭先验。相比于岭先验，Lasso 先验有意将回归系数往 0 上收缩，这非常类似于频率派中的岭回归与 Lasso 回归的关系 (Bhadra 等 2019)。\ndata {\n  int&lt;lower=1&gt; k;\n  int&lt;lower=0&gt; n;\n  matrix[n, k] X;\n  array[n] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  vector[k] beta;\n  real alpha;\n  real&lt;lower=0&gt; lambda;\n}\nmodel {\n  target += double_exponential_lpdf(beta | 0, lambda);\n  target += double_exponential_lpdf(alpha | 0, lambda);\n  target += cauchy_lpdf(lambda | 0, 0.01);\n  target += bernoulli_logit_glm_lpmf(y | X, alpha, beta);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1 : n) {\n    log_lik[i] = bernoulli_logit_lpmf(y[i] | alpha + X[i] * beta);\n  }\n}\n\nmod_logit_lasso &lt;- cmdstan_model(\n  stan_file = \"code/bernoulli_logit_glm_lasso.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\nfit_logit_lasso &lt;- mod_logit_lasso$sample(\n  data = mdata,\n  chains = 2,\n  parallel_chains = 2,\n  iter_warmup = 1000, \n  iter_sampling = 1000, \n  threads_per_chain = 2, \n  seed = 20232023,\n  show_messages = FALSE,\n  refresh = 0\n)\n\n# 输出结果\nfit_logit_lasso$summary(c(\"alpha\", \"beta\", \"lambda\", \"lp__\"))\n\n#&gt; # A tibble: 13 × 10\n#&gt;    variable      mean    median     sd    mad         q5      q95  rhat ess_bulk\n#&gt;    &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha       0.993     0.989  0.0738 0.0741    0.873    1.12e+0  1.00    2427.\n#&gt;  2 beta[1]     3.08      3.08   0.137  0.133     2.86     3.31e+0  1.00    1707.\n#&gt;  3 beta[2]    -1.99     -1.98   0.100  0.102    -2.15    -1.82e+0  1.00    2014.\n#&gt;  4 beta[3]     0.0533    0.0517 0.0614 0.0586   -0.0463   1.60e-1  1.00    4035.\n#&gt;  5 beta[4]    -0.0232   -0.0222 0.0600 0.0571   -0.121    7.16e-2  1.00    4184.\n#&gt;  6 beta[5]     0.0118    0.0128 0.0628 0.0602   -0.0959   1.15e-1  1.00    5750.\n#&gt;  7 beta[6]     0.0180    0.0163 0.0612 0.0603   -0.0810   1.23e-1  1.00    4271.\n#&gt;  8 beta[7]     0.0942    0.0940 0.0615 0.0607   -0.00725  1.95e-1  1.00    3869.\n#&gt;  9 beta[8]    -0.0268   -0.0252 0.0607 0.0612   -0.125    7.30e-2  1.00    3632.\n#&gt; 10 beta[9]    -0.0815   -0.0817 0.0603 0.0589   -0.182    1.73e-2  1.00    3377.\n#&gt; 11 beta[10]    0.0747    0.0742 0.0637 0.0605   -0.0305   1.80e-1  1.00    3815.\n#&gt; 12 lambda      0.598     0.566  0.189  0.153     0.361    9.32e-1  1.00    3142.\n#&gt; 13 lp__     -775.     -775.     2.58   2.42   -780.      -7.71e+2  1.00     829.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n计算 LOO-CV 比较正态先验和 Lasso 先验\n\nfit_logit_normal_loo &lt;- fit_logit_normal$loo(variables = \"log_lik\", cores = 1)\nprint(fit_logit_normal_loo)\n\n#&gt; \n#&gt; Computed from 2000 by 2500 log-likelihood matrix\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo   -762.3 27.2\n#&gt; p_loo        11.3  0.5\n#&gt; looic      1524.6 54.5\n#&gt; ------\n#&gt; Monte Carlo SE of elpd_loo is 0.1.\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.5).\n#&gt; See help('pareto-k-diagnostic') for details.\n\nfit_logit_lasso_loo &lt;- fit_logit_lasso$loo(variables = \"log_lik\", cores = 1)\nprint(fit_logit_lasso_loo)\n\n#&gt; \n#&gt; Computed from 2000 by 2500 log-likelihood matrix\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo   -761.5 26.8\n#&gt; p_loo        10.3  0.5\n#&gt; looic      1522.9 53.6\n#&gt; ------\n#&gt; Monte Carlo SE of elpd_loo is 0.1.\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.5).\n#&gt; See help('pareto-k-diagnostic') for details.\n\n\nloo 包的函数 loo_compare() 比较两个模型\n\nloo::loo_compare(list(model0 = fit_logit_normal_loo, \n                      model1 = fit_logit_lasso_loo))\n\n#&gt;        elpd_diff se_diff\n#&gt; model1  0.0       0.0   \n#&gt; model0 -0.9       0.5\n\n\n输出结果中最好的模型放在第一行。LOOIC 越小越好，所以，Lasso 先验更好。\n\n33.3.3 Horseshoe 先验\nHorseshoe 先验（Horse shoe）(Piironen 和 Vehtari 2017b) 指定回归系数 \\(\\alpha,\\bm{\\beta}\\) 的先验分布如下\n\\[\n\\begin{aligned}\n\\lambda_i &\\sim \\mathrm{Half\\_Cauchy}(0,1) \\\\\n\\alpha | \\lambda_0,\\tau  &\\sim \\mathcal{N}(0, \\tau^2\\lambda_0^2) \\\\\n\\beta_i | \\lambda_i,\\tau  &\\sim \\mathcal{N}(0, \\tau^2\\lambda_i^2),\\quad i = 1,2,\\cdots,10\n\\end{aligned}\n\\]\n其中，\\(\\tau\\) 称之为全局超参数，它将所有的回归系数朝着 0 收缩。而作用在局部超参数 \\(\\lambda_i\\) 上的重尾柯西先验允许某些回归系数逃脱收缩。\ndata {\n  int&lt;lower=1&gt; k;\n  int&lt;lower=0&gt; n;\n  matrix[n, k] X;\n  array[n] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  vector[k] beta_tilde;\n  real alpha;\n  real&lt;lower=0&gt; tau;\n  vector&lt;lower=0&gt;[k] lambda;\n}\ntransformed parameters {\n  vector[k] beta = beta_tilde .* lambda * tau;\n}\nmodel {\n  target += normal_lpdf(beta_tilde | 0, lambda);\n  target += normal_lpdf(alpha | 0, lambda);\n  target += cauchy_lpdf(tau | 0, 1);\n  target += cauchy_lpdf(lambda | 0, 1);\n  target += bernoulli_logit_glm_lpmf(y | X, alpha, beta);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1 : n) {\n    log_lik[i] = bernoulli_logit_lpmf(y[i] | alpha + X[i] * beta);\n  }\n}\n\n# horseshoe 先验\nmod_logit_horseshoe &lt;- cmdstan_model(\n  stan_file = \"code/bernoulli_logit_glm_horseshoe.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\nfit_logit_horseshoe &lt;- mod_logit_horseshoe$sample(\n  data = mdata,\n  chains = 2,\n  parallel_chains = 2,\n  iter_warmup = 1000, \n  iter_sampling = 1000, \n  threads_per_chain = 2, \n  seed = 20232023,\n  show_messages = FALSE,\n  refresh = 0\n)\n\nfit_logit_horseshoe$summary(c(\"alpha\", \"beta\", \"tau\", \"lambda\", \"lp__\")) \n\n#&gt; # A tibble: 23 × 10\n#&gt;    variable     mean   median     sd    mad      q5     q95  rhat ess_bulk\n#&gt;    &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha     0.933    0.932   0.0770 0.0741  0.809   1.07   1.00     1274.\n#&gt;  2 beta[1]   3.05     3.05    0.133  0.133   2.83    3.26   1.00     1382.\n#&gt;  3 beta[2]  -1.97    -1.96    0.0985 0.0975 -2.13   -1.80   1.00     1875.\n#&gt;  4 beta[3]   0.0272   0.0196  0.0485 0.0399 -0.0407  0.119  0.999    1697.\n#&gt;  5 beta[4]  -0.0112  -0.00764 0.0453 0.0383 -0.0905  0.0591 1.00     1777.\n#&gt;  6 beta[5]   0.00532  0.00429 0.0432 0.0347 -0.0684  0.0838 1.00     1920.\n#&gt;  7 beta[6]   0.00861  0.00554 0.0453 0.0386 -0.0625  0.0890 1.00     2330.\n#&gt;  8 beta[7]   0.0622   0.0572  0.0557 0.0595 -0.0135  0.164  1.00     1450.\n#&gt;  9 beta[8]  -0.0153  -0.0111  0.0455 0.0362 -0.0959  0.0543 1.00     1838.\n#&gt; 10 beta[9]  -0.0490  -0.0396  0.0546 0.0549 -0.152   0.0218 1.00     1638.\n#&gt; # ℹ 13 more rows\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n可以看到回归系数小的压缩效果很明显，而回归系数大的几乎没有压缩。\n\nfit_logit_horseshoe_loo &lt;- fit_logit_horseshoe$loo(variables = \"log_lik\", cores = 1)\nprint(fit_logit_horseshoe_loo)\n\n#&gt; \n#&gt; Computed from 2000 by 2500 log-likelihood matrix\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo   -760.0 26.5\n#&gt; p_loo         7.6  0.3\n#&gt; looic      1519.9 53.1\n#&gt; ------\n#&gt; Monte Carlo SE of elpd_loo is 0.1.\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.5).\n#&gt; See help('pareto-k-diagnostic') for details.\n\n\nLOOIC 比之 Lasso 先验的情况更小了。\n\n\n\n\n\n\n注释\n\n\n\n\nlibrary(rstanarm)\n# set up the prior, use hyperprior tau ∼ half-Cauchy(0,tau0^2) \nD &lt;- ncol(X) # 10 变量\nn &lt;- nrow(X) # 2500 样本量\np0 &lt;- 5 # prior guess for the number of relevant variables \nsigma &lt;- 1 / sqrt(mean(y)*(1-mean(y))) # pseudo sigma\ntau0 &lt;- p0 / (D - p0) * sigma / sqrt(n)\n# hs() 函数指定层次收缩先验 Hierarchical shrinkage\n# 拟合模型\nfit &lt;- stan_glm(\n  y ~ X, family = binomial(), data = data.frame(I(X), y), \n  # horseshoe 先验\n  prior = hs(df = 1, global_df = 1, global_scale = tau0)\n)\n# 输出结果\nsummary(fit, digits = 4)\n\n模型输出如下：\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      y ~ X\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 2500\n predictors:   11\n\nEstimates:\n              mean    sd      10%     50%     90%  \n(Intercept)  1.0016  0.0732  0.9080  1.0007  1.0947\nX1           3.0921  0.1343  2.9219  3.0888  3.2660\nX2          -1.9907  0.1002 -2.1200 -1.9903 -1.8631\nX3           0.0205  0.0429 -0.0180  0.0084  0.0804\nX4          -0.0069  0.0364 -0.0534 -0.0018  0.0297\nX5           0.0045  0.0367 -0.0336  0.0008  0.0474\nX6           0.0062  0.0364 -0.0323  0.0014  0.0519\nX7           0.0469  0.0559 -0.0068  0.0327  0.1258\nX8          -0.0082  0.0376 -0.0545 -0.0021  0.0296\nX9          -0.0342  0.0492 -0.1042 -0.0196  0.0109\nX10          0.0310  0.0472 -0.0125  0.0180  0.0971\n\nFit Diagnostics:\n           mean   sd     10%    50%    90% \nmean_PPD 0.5915 0.0087 0.5804 0.5916 0.6028\n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse   Rhat   n_eff\n(Intercept)   0.0010 0.9994 5422 \nX1            0.0021 0.9996 3994 \nX2            0.0016 1.0000 3817 \nX3            0.0006 0.9997 4531 \nX4            0.0005 0.9998 4652 \nX5            0.0005 0.9993 5052 \nX6            0.0005 0.9994 4795 \nX7            0.0010 1.0002 3045 \nX8            0.0006 1.0000 4397 \nX9            0.0009 1.0002 3034 \nX10           0.0008 1.0003 3292 \nmean_PPD      0.0001 0.9994 4742 \nlog-posterior 0.1367 1.0012 1206 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\nrstanarm 包可以获得与前面一致的结果，甚至收缩效果比手写的 Stan 代码好一点点。\n\n\n\n33.3.4 SpikeSlab 先验\nSpikeSlab 先验（Spike Slab）放在非 0 协变量的个数上，是离散的先验。回归系数的先验分布的有限混合，常用有限混合多元正态分布。参考文章 Discrete Mixture Models\n\n\n\n\n\n\n注释\n\n\n\nBoomSpikeSlab 包是 Boom 包的扩展，提供基于 SpikeSlab 先验的贝叶斯变量选择功能。\n\nset.seed(2023)\nn &lt;- 2500\nk &lt;- 10\nX &lt;- matrix(rnorm(n * k), ncol = k)\ny &lt;- rbinom(n, size = 1, prob = plogis(1 + 3 * X[, 1] - 2 * X[, 2]))\n# 加载 BoomSpikeSlab\nlibrary(BoomSpikeSlab)\nfit_logit_spike &lt;- logit.spike(y ~ X, niter = 500)\n# 模型输出\nsummary(fit_logit_spike)\n\n\nnull log likelihood:            -1690.677 \nposterior mean log likelihood:  -766.5283 \nposterior max log likelihood:   -754.8686 \nmean deviance R-sq:             0.5466147 \n\npredicted vs observed success rates, by decile:\n                  predicted    observed\n(0.00596,0.0279] 0.01388670 0.008032129\n(0.0279,0.108]   0.06371528 0.060000000\n(0.108,0.273]    0.17839881 0.176000000\n(0.273,0.496]    0.39146661 0.404000000\n(0.496,0.734]    0.61807048 0.608000000\n(0.734,0.865]    0.80694458 0.764000000\n(0.865,0.942]    0.90690322 0.928000000\n(0.942,0.979]    0.96436544 0.976000000\n(0.979,0.992]    0.98636201 0.992000000\n(0.992,0.996]    0.99441504 1.000000000\n\nsummary of coefficients:\n             mean    sd mean.inc sd.inc inc.prob\n(Intercept)  1.02 0.105     1.02  0.105     1.00\nX2          -2.00 0.232    -2.02  0.118     0.99\nX1           3.10 0.354     3.13  0.170     0.99\nX10          0.00 0.000     0.00  0.000     0.00\nX9           0.00 0.000     0.00  0.000     0.00\nX8           0.00 0.000     0.00  0.000     0.00\nX7           0.00 0.000     0.00  0.000     0.00\nX6           0.00 0.000     0.00  0.000     0.00\nX5           0.00 0.000     0.00  0.000     0.00\nX4           0.00 0.000     0.00  0.000     0.00\nX3           0.00 0.000     0.00  0.000     0.00",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>概率推理框架</span>"
    ]
  },
  {
    "objectID": "probabilistic-reasoning-framework.html#sec-choose-inference",
    "href": "probabilistic-reasoning-framework.html#sec-choose-inference",
    "title": "33  概率推理框架",
    "section": "\n33.4 推理算法",
    "text": "33.4 推理算法\n开篇提及 Stan 内置了多种推理算法，不同的算法获得的结果是存在差异的。\n\nfull Bayesian statistical inference with MCMC sampling (NUTS, HMC)\napproximate Bayesian inference with variational inference (ADVI)\npenalized maximum likelihood estimation with optimization (L-BFGS)\n\n\n33.4.1 惩罚极大似然算法\nL-BFGS 算法拟合模型，速度非常快。\n\n# L-BFGS 算法拟合模型\nfit_optim_logit &lt;- mod_logit_lasso$optimize(\n  data = mdata, # 观测数据\n  init = 0,     # 所有参数初值设为 0\n  refresh = 0,  # 不显示迭代进程\n  algorithm = \"lbfgs\", # 优化器\n  threads = 1,    # 单线程\n  seed = 20232023 # 随机数种子\n)\n\n#&gt; Finished in  0.2 seconds.\n\nfit_optim_logit$summary(c(\"alpha\", \"beta\", \"lambda\", \"lp__\"))\n\n#&gt; # A tibble: 13 × 2\n#&gt;    variable   estimate\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;\n#&gt;  1 alpha       0.981  \n#&gt;  2 beta[1]     3.05   \n#&gt;  3 beta[2]    -1.96   \n#&gt;  4 beta[3]     0.0488 \n#&gt;  5 beta[4]    -0.0166 \n#&gt;  6 beta[5]     0.00528\n#&gt;  7 beta[6]     0.0126 \n#&gt;  8 beta[7]     0.0923 \n#&gt;  9 beta[8]    -0.0204 \n#&gt; 10 beta[9]    -0.0777 \n#&gt; 11 beta[10]    0.0721 \n#&gt; 12 lambda      0.488  \n#&gt; 13 lp__     -768.\n\n\n\n33.4.2 变分近似推断算法\nADVI 算法拟合模型，可选的优化器有 meanfield 和 fullrank ，相比于 L-BFGS 稍慢\n\n# ADVI 算法拟合模型\nfit_advi_logit &lt;- mod_logit_lasso$variational(\n  data = mdata, # 观测数据\n  init = 0,     # 所有参数初值设为 0\n  refresh = 0,  # 不显示迭代进程\n  algorithm = \"meanfield\", # 优化器\n  threads = 1,    # 单线程\n  seed = 20232023 # 随机数种子\n)\n\n#&gt; Finished in  1.7 seconds.\n\nfit_advi_logit$summary(c(\"alpha\", \"beta\", \"lambda\", \"lp__\"))\n\n#&gt; # A tibble: 13 × 7\n#&gt;    variable       mean     median     sd    mad         q5       q95\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 alpha       1.02       1.02    0.0615 0.0630    0.914      1.11  \n#&gt;  2 beta[1]     3.07       3.07    0.0899 0.0870    2.93       3.22  \n#&gt;  3 beta[2]    -1.98      -1.98    0.0675 0.0666   -2.08      -1.86  \n#&gt;  4 beta[3]     0.0161     0.0159  0.0678 0.0670   -0.0945     0.129 \n#&gt;  5 beta[4]    -0.0199    -0.0221  0.0639 0.0621   -0.121      0.0857\n#&gt;  6 beta[5]    -0.00128   -0.00202 0.0722 0.0713   -0.116      0.121 \n#&gt;  7 beta[6]    -0.0423    -0.0446  0.0705 0.0689   -0.156      0.0754\n#&gt;  8 beta[7]     0.0760     0.0750  0.0490 0.0489   -0.00517    0.152 \n#&gt;  9 beta[8]    -0.0742    -0.0752  0.0659 0.0637   -0.181      0.0347\n#&gt; 10 beta[9]    -0.0495    -0.0501  0.0802 0.0818   -0.185      0.0805\n#&gt; 11 beta[10]    0.0444     0.0440  0.0520 0.0522   -0.0444     0.128 \n#&gt; 12 lambda      0.698      0.662   0.243  0.228     0.379      1.13  \n#&gt; 13 lp__     -777.      -777.      3.39   3.22   -783.      -773.\n\n\n\n33.4.3 拉普拉斯近似算法\nStan 内置的 Laplace 近似算法是对后验分布的 Laplace 正态近似，再从近似的后验分布中采样获得样本，最后，对样本进行统计分析获得参数的后验估计。详见 Stan 语言参考手册的Laplace Approximation 一章。\n\n# Laplace 算法\nfit_laplace_logit &lt;- mod_logit_lasso$laplace(\n  data = mdata, # 观测数据\n  init = 0,     # 所有参数初值设为 0\n  refresh = 0,  # 不显示迭代进程\n  threads = 1,    # 单线程\n  seed = 20232023 # 随机数种子\n)\n\n#&gt; Finished in  0.2 seconds.\n#&gt; Finished in  1.5 seconds.\n\nfit_laplace_logit$summary(c(\"alpha\", \"beta\", \"lambda\", \"lp__\"))\n\n#&gt; # A tibble: 13 × 7\n#&gt;    variable       mean     median     sd    mad        q5       q95\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 alpha       0.983      0.981   0.0701 0.0719    0.874     1.10  \n#&gt;  2 beta[1]     3.05       3.05    0.131  0.129     2.84      3.28  \n#&gt;  3 beta[2]    -1.97      -1.97    0.0960 0.0977   -2.12     -1.80  \n#&gt;  4 beta[3]     0.0516     0.0493  0.0620 0.0605   -0.0432    0.150 \n#&gt;  5 beta[4]    -0.0200    -0.0216  0.0647 0.0602   -0.121     0.0904\n#&gt;  6 beta[5]     0.00546    0.00505 0.0639 0.0645   -0.0971    0.110 \n#&gt;  7 beta[6]     0.0135     0.0138  0.0642 0.0629   -0.0929    0.116 \n#&gt;  8 beta[7]     0.0920     0.0917  0.0638 0.0659   -0.0179    0.195 \n#&gt;  9 beta[8]    -0.0231    -0.0217  0.0641 0.0669   -0.128     0.0867\n#&gt; 10 beta[9]    -0.0810    -0.0798  0.0646 0.0640   -0.194     0.0212\n#&gt; 11 beta[10]    0.0732     0.0745  0.0639 0.0614   -0.0328    0.176 \n#&gt; 12 lambda      0.562      0.536   0.168  0.154     0.333     0.866 \n#&gt; 13 lp__     -775.      -775.      2.63   2.46   -780.     -772.\n\n\n\n33.4.4 探路者变分算法\n探路者算法 Pathfinder 属于变分法，针对可微的对数目标密度函数，沿着逆牛顿优化算法的迭代路径，获得目标密度函数的正态近似。正态近似中的局部协方差的估计采用 LBFGS 计算的负逆 Hessian 矩阵。探路者算法的优势是可以极大地减少对数密度函数和梯度的计算次数，缓解迭代陷入局部最优点和鞍点（何为鞍点，一个可视化示例详见 章节 32.3 ）。\n\n# Pathfinder 算法\nfit_pathfinder_logit &lt;- mod_logit_lasso$pathfinder(\n  data = mdata, # 观测数据\n  init = 0,     # 所有参数初值设为 0\n  refresh = 0,  # 不显示迭代进程\n  num_threads = 1,    # 单线程\n  seed = 20232023 # 随机数种子\n)\n\n#&gt; Finished in  3.8 seconds.\n\nfit_pathfinder_logit$summary(c(\"alpha\", \"beta\", \"lambda\", \"lp__\"))\n\n#&gt; # A tibble: 13 × 7\n#&gt;    variable      mean    median     sd    mad         q5       q95\n#&gt;    &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 alpha       0.995     0.993  0.0765 0.0816    0.875      1.12  \n#&gt;  2 beta[1]     3.08      3.07   0.136  0.130     2.88       3.32  \n#&gt;  3 beta[2]    -1.98     -1.98   0.102  0.106    -2.15      -1.81  \n#&gt;  4 beta[3]     0.0555    0.0594 0.0616 0.0586   -0.0509     0.158 \n#&gt;  5 beta[4]    -0.0217   -0.0209 0.0627 0.0614   -0.124      0.0761\n#&gt;  6 beta[5]     0.0125    0.0132 0.0653 0.0631   -0.0885     0.118 \n#&gt;  7 beta[6]     0.0202    0.0198 0.0620 0.0648   -0.0816     0.125 \n#&gt;  8 beta[7]     0.0968    0.0969 0.0596 0.0617   -0.00574    0.193 \n#&gt;  9 beta[8]    -0.0286   -0.0247 0.0600 0.0572   -0.139      0.0643\n#&gt; 10 beta[9]    -0.0795   -0.0748 0.0598 0.0623   -0.183      0.0102\n#&gt; 11 beta[10]    0.0748    0.0713 0.0618 0.0612   -0.0234     0.173 \n#&gt; 12 lambda      0.598     0.581  0.171  0.163     0.361      0.914 \n#&gt; 13 lp__     -775.     -775.     2.60   2.41   -780.      -771.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>概率推理框架</span>"
    ]
  },
  {
    "objectID": "probabilistic-reasoning-framework.html#习题",
    "href": "probabilistic-reasoning-framework.html#习题",
    "title": "33  概率推理框架",
    "section": "\n33.5 习题",
    "text": "33.5 习题\n\n\n在 章节 33.3 的基础上，比较 Stan 实现的贝叶斯 Lasso 和 R 包 glmnet 的结果，发现 glmnet 包是很有竞争力的。在选择 Lasso 先验的情况下，收缩效果比 Stan 还好，运行速度也很快。Stan 的优势在于不限于先验分布的选取，当选择 Horseshoe 先验时，Stan 的收缩又比 glmnet 包更好。Stan 的优势还在于不限于 glmnet 包支持的常见分布族，如高斯、二项、泊松、多项、Cox 等。本质上，这两点都是 Stan 作为一门概率编程语言的优势，只要知道概率分布的数学表达式，总是可以用 Stan 编码出来的。\n\nlibrary(glmnet)\n# 10 折交叉验证 Lasso 回归\nfit_lasso &lt;- cv.glmnet(x = X, y = y, family = \"binomial\", alpha = 1, nfolds = 10)\n# 回归系数\ncoef(fit_lasso, s = fit_lasso$lambda.min)\n\n#&gt; 11 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                      s1\n#&gt; (Intercept)  0.95778344\n#&gt; V1           2.93183863\n#&gt; V2          -1.88338518\n#&gt; V3           0.02866555\n#&gt; V4           .         \n#&gt; V5           .         \n#&gt; V6           .         \n#&gt; V7           0.06966407\n#&gt; V8           .         \n#&gt; V9          -0.05836894\n#&gt; V10          0.05171457\n\n\n\n\n基于德国信用卡评分数据，建立逻辑回归模型，分析 20 个协变量对响应变量的贡献，采用合适的先验分布选择适当的变量数。\n\ngerman_credit_data &lt;- readRDS(file = \"data/german_credit_data.rds\")\nstr(german_credit_data)\n\n#&gt; 'data.frame':    1000 obs. of  21 variables:\n#&gt;  $ checking: Factor w/ 4 levels \"A11\",\"A12\",\"A13\",..: 1 2 4 1 1 4 4 2 4 2 ...\n#&gt;  $ duration: num  6 48 12 42 24 36 24 36 12 30 ...\n#&gt;  $ history : Factor w/ 5 levels \"A30\",\"A31\",\"A32\",..: 5 3 5 3 4 3 3 3 3 5 ...\n#&gt;  $ purpose : Factor w/ 10 levels \"A40\",\"A41\",\"A410\",..: 5 5 8 4 1 8 4 2 5 1 ...\n#&gt;  $ amount  : num  1169 5951 2096 7882 4870 ...\n#&gt;  $ savings : Factor w/ 5 levels \"A61\",\"A62\",\"A63\",..: 5 1 1 1 1 5 3 1 4 1 ...\n#&gt;  $ employed: Factor w/ 5 levels \"A71\",\"A72\",\"A73\",..: 5 3 4 4 3 3 5 3 4 1 ...\n#&gt;  $ installp: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 4 2 2 2 3 2 3 2 2 4 ...\n#&gt;  $ marital : Factor w/ 4 levels \"A91\",\"A92\",\"A93\",..: 3 2 3 3 3 3 3 3 1 4 ...\n#&gt;  $ coapp   : Factor w/ 3 levels \"A101\",\"A102\",..: 1 1 1 3 1 1 1 1 1 1 ...\n#&gt;  $ resident: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 4 2 3 4 4 4 4 2 4 2 ...\n#&gt;  $ property: Factor w/ 4 levels \"A121\",\"A122\",..: 1 1 1 2 4 4 2 3 1 3 ...\n#&gt;  $ age     : num  67 22 49 45 53 35 53 35 61 28 ...\n#&gt;  $ other   : Factor w/ 3 levels \"A141\",\"A142\",..: 3 3 3 3 3 3 3 3 3 3 ...\n#&gt;  $ housing : Factor w/ 3 levels \"A151\",\"A152\",..: 2 2 2 3 3 3 2 1 2 2 ...\n#&gt;  $ existcr : num  2 1 1 1 2 1 1 1 1 2 ...\n#&gt;  $ job     : Factor w/ 4 levels \"A171\",\"A172\",..: 3 3 2 3 3 2 3 4 2 4 ...\n#&gt;  $ depends : num  1 1 2 2 2 2 1 1 1 1 ...\n#&gt;  $ telephon: Factor w/ 2 levels \"A191\",\"A192\": 2 1 1 1 1 2 1 2 1 1 ...\n#&gt;  $ foreign : Factor w/ 2 levels \"A201\",\"A202\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ good_bad: Factor w/ 2 levels \"1\",\"2\": 1 2 1 1 2 1 1 1 1 2 ...\n\n\n\n\n下图是美国黄石公园老忠实间歇泉喷发时间和等待时间的分布规律，请建立合适的正态混合模型，用 Stan 拟合模型，并对结果做出说明。（提示：参考 Stan 用户手册的有限混合章节）\n\n代码p1 &lt;- ggplot(data = faithful, aes(x = eruptions)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 30, fill = \"white\", color = \"gray\") +\n  geom_density() +\n  theme_classic() +\n  labs(x = \"喷发时间\", y = \"概率密度值\")\n\np2 &lt;- ggplot(data = faithful, aes(x = waiting)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 30, fill = \"white\", color = \"gray\") +\n  geom_density() +\n  theme_classic() +\n  labs(x = \"等待时间\", y = \"概率密度值\")\n\nlibrary(patchwork)\np1 | p2\n\n\n\n\n\n\n图 33.4: 黄石公园老忠实间歇泉\n\n\n\n\ndata {\n  int&lt;lower=1&gt; K;          // number of mixture components\n  int&lt;lower=1&gt; N;          // number of data points\n  array[N] real y;         // observations\n}\nparameters {\n  simplex[K] theta;          // mixing proportions\n  ordered[K] mu;             // locations of mixture components\n  vector&lt;lower=0&gt;[K] sigma;  // scales of mixture components\n}\nmodel {\n  vector[K] log_theta = log(theta);  // cache log calculation\n  sigma ~ lognormal(0, 2);\n  mu ~ normal(0, 10);\n  for (n in 1:N) {\n    vector[K] lps = log_theta;\n    for (k in 1:K) {\n      lps[k] += normal_lpdf(y[n] | mu[k], sigma[k]);\n    }\n    target += log_sum_exp(lps);\n  }\n}\n\n代码library(cmdstanr)\n\nfaithful_d &lt;- list(\n  K = 2, # 几个正态分布混合\n  N = 272, # 样本量\n  # y = faithful$waiting,\n  y = faithful$eruptions\n)\n\nmod_faithful_normal &lt;- cmdstan_model(\n  stan_file = \"code/faithful_finite_mixtures.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\nfit_faithful_normal &lt;- mod_faithful_normal$sample(\n  data = faithful_d,\n  chains = 2,\n  parallel_chains = 2,\n  iter_warmup = 1000, \n  iter_sampling = 1000, \n  threads_per_chain = 2, \n  seed = 20232023,\n  show_messages = FALSE,\n  refresh = 0\n)\n\n# 输出结果\nfit_faithful_normal$summary(c(\"theta\", \"mu\", \"sigma\", \"lp__\"))\n# theta[1] = 0.350 混合比例\n# theta[2] = 0.650\n# mu[1] = 2.02 均值\n# mu[2] = 4.27\n# sigma[1] = 0.243 标准差\n# sigma[2] = 0.437\n\n\n\n\n在 章节 12 的探索分析基础上，对美国黄石公园的老忠实泉喷发规律，建立二项分布和二维正态分布的混合模型，请用 Stan 编码估计模型中的参数。\n\\[\nf(\\bm{x};p,\\bm{\\mu_1},\\Sigma_1,\\bm{\\mu_2},\\Sigma_2) = p\\mathcal{N}(\\bm{x};\\bm{\\mu_1},\\Sigma_1) + (1-p) \\mathcal{N}(\\bm{x};\\bm{\\mu_2},\\Sigma_2)\n\\]\n其中，参数 \\(p\\) 是一个介于 0 到 1 之间的常数，参数 \\(\\bm{\\mu_1} = (\\mu_{11},\\mu_{12})^\\top,\\bm{\\mu_2}=(\\mu_{21},\\mu_{22})^\\top\\) 是二维的列向量，参数 \\(\\Sigma_1 = (\\sigma_{ij}),\\Sigma_2 = (\\delta_{ij}),i=1,2,j=1,2\\) 是二阶的协方差矩阵。（提示：因有限混合模型存在可识别性问题，简单起见，考虑各个多元正态分布的协方差矩阵相同的情况。）\ndata {\n  int&lt;lower=1&gt; K;  // number of mixture components\n  int&lt;lower=1&gt; N;  // number of observations\n  int&lt;lower=1&gt; D;  // dimension of observations\n  array[N] vector[D] y; // observations: a list of N vectors (each has D elements)\n}\ntransformed data {\n  vector[D] mu0 = rep_vector(0, D);\n  matrix[D, D] Sigma0 = diag_matrix(rep_vector(1, D));\n}\nparameters {\n  simplex[K] theta;       // mixing proportions\n  array[K] positive_ordered[D] mu; // locations of mixture components\n  // scales of mixture components\n  array[K] cholesky_factor_corr[D] Lcorr; // cholesky factor (L_u matrix for R)\n}\nmodel {\n  for(i in 1:K){\n    mu[i] ~ multi_normal(mu0, Sigma0); // prior for mu\n    Lcorr[i] ~ lkj_corr_cholesky(2.0); // prior for cholesky factor of a correlation matrix\n  }\n\n  vector[K] log_theta = log(theta);  // cache log calculation\n\n  for (n in 1:N) {\n    vector[K] lps = log_theta;\n    for (k in 1:K) {\n      lps[k] += multi_normal_cholesky_lpdf(y[n] | mu[k], Lcorr[k]);\n    }\n    target += log_sum_exp(lps);\n  }\n}\n\n代码data(\"faithful\")\nlibrary(cmdstanr)\n# 准备数据\nfaithful_2d &lt;- list(\n  K = 2,    # 2 个分布混合\n  N = 272,  # 样本量 nrow(faithful)\n  D = 2,    # 二维正态分布\n  y = faithful # 数据集\n)\n# 编译模型\nmod_faithful_normal_2d &lt;- cmdstan_model(\n  stan_file = \"code/faithful_2d_finite_mixtures.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n# 采样\nfit_faithful_normal_2d &lt;- mod_faithful_normal_2d$sample(\n  data = faithful_2d,\n  chains = 2,\n  parallel_chains = 2,\n  iter_warmup = 1000, \n  iter_sampling = 1000, \n  threads_per_chain = 2, \n  seed = 20232023,\n  show_messages = FALSE,\n  refresh = 0\n)\n# 输出结果\nfit_faithful_normal_2d$summary(c(\"theta\", \"mu\", \"lp__\"))\n\n\n\n\n\n\n\n\nAbril-Pla O, Carroll C, Andreani V. 2023. 《PyMC: a modern, and comprehensive probabilistic programming framework in Python》. PeerJ Computer Science 9 (e1516). https://doi.org/10.7717/peerj-cs.1516.\n\n\nAllaire, JJ, Romain Francois, Kevin Ushey, Gregory Vandenbrouck, Marcus Geelnard, 和 Intel. 2023. RcppParallel: Parallel Programming Tools for Rcpp. https://CRAN.R-project.org/package=RcppParallel.\n\n\nBates, Douglas, 和 Dirk Eddelbuettel. 2013. 《Fast and Elegant Numerical Linear Algebra Using the RcppEigen Package》. Journal of Statistical Software 52 (5): 1–24. https://doi.org/10.18637/jss.v052.i05.\n\n\nBhadra, Anindya, Jyotishka Datta, Nicholas G. Polson, 和 Brandon Willard. 2019. 《Lasso Meets Horseshoe: A Survey》. Statistical Science 34 (3): 405–27. https://doi.org/10.1214/19-STS700.\n\n\nBürkner, Paul-Christian. 2017. 《brms: An R Package for Bayesian Multilevel Models Using Stan》. Journal of Statistical Software 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01.\n\n\nCarpenter, Bob, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, 和 Allen Riddell. 2017. 《Stan: A Probabilistic Programming Language》. Journal of Statistical Software 76 (1): 1–32. https://doi.org/10.18637/jss.v076.i01.\n\n\nCarpenter, Bob, Matthew D. Hoffman, Marcus Brubaker, Daniel Lee, Peter Li, 和 Michael Betancourt. 2015. 《The Stan Math Library: Reverse-Mode Automatic Differentiation in C++》. https://arxiv.org/abs/1509.07164.\n\n\nEddelbuettel, Dirk, 和 James Joseph Balamuta. 2018. 《Extending R with C++: A Brief Introduction to Rcpp》. The American Statistician 72 (1): 28–36. https://doi.org/10.1080/00031305.2017.1375990.\n\n\nEddelbuettel, Dirk, John W. Emerson, 和 Michael J. Kane. 2023. BH: Boost C++ Header Files. https://CRAN.R-project.org/package=BH.\n\n\nEddelbuettel, Dirk, 和 Romain François. 2011. 《Rcpp: Seamless R and C++ Integration》. Journal of Statistical Software 40 (8): 1–18. https://doi.org/10.18637/jss.v040.i08.\n\n\nGabry, Jonah, Rok Češnovar, 和 Andrew Johnson. 2023. cmdstanr: R Interface to CmdStan. https://mc-stan.org/cmdstanr/.\n\n\nGabry, Jonah, Daniel Simpson, Aki Vehtari, Michael Betancourt, 和 Andrew Gelman. 2019. 《Visualization in Bayesian workflow》. Journal of the Royal Statistical Society Series A: Statistics in Society 182: 389–402. https://doi.org/10.1111/rssa.12378.\n\n\nGelman, Andrew, Daniel Lee, 和 Jiqiang Guo. 2015. 《Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization》. Journal of Educational and Behavioral Statistics 40 (5): 530–43. https://doi.org/10.3102/1076998615606113.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, 和 Sam Brilleman. 2023. 《rstanarm: Bayesian applied regression modeling via Stan.》 https://mc-stan.org/rstanarm/.\n\n\nJoshua V. Dillon, Dustin Tran, Ian Langmore. 2017. 《TensorFlow Distributions》. https://arxiv.org/abs/1711.10604.\n\n\nPiironen, Juho, Markus Paasiniemi, 和 Aki Vehtari. 2020. 《Projective Inference in High-Dimensional Problems: Prediction and Feature Selection》. Electronic Journal of Statistics 14 (1): 2155–97. https://doi.org/10.1214/20-EJS1711.\n\n\nPiironen, Juho, 和 Aki Vehtari. 2017a. 《Comparison of Bayesian Predictive Methods for Model Selection》. Statistics and Computing 27 (3): 711–35. https://doi.org/10.1007/s11222-016-9649-y.\n\n\n———. 2017b. 《Sparsity information and regularization in the horseshoe and other shrinkage priors》. Electronic Journal of Statistics 11 (2): 5018–51. https://doi.org/10.1214/17-EJS1337SI.\n\n\nStan Development Team. 2023a. 《RStan: the R interface to Stan》. https://mc-stan.org/.\n\n\n———. 2023b. 《StanHeaders: Headers for the R interface to Stan》. https://mc-stan.org/.\n\n\nVehtari, Aki, Andrew Gelman, 和 Jonah Gabry. 2017. 《Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC》. Statistics and Computing 27: 1413–32. https://doi.org/10.1007/s11222-016-9696-4.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, 和 Paul-Christian Bürkner. 2021. 《Rank-Normalization, Folding, and Localization: An Improved \\(\\widehat{R}\\) for Assessing Convergence of MCMC (with Discussion)》. Bayesian Analysis 16 (2): 667–718. https://doi.org/10.1214/20-BA1221.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>概率推理框架</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html",
    "href": "generalized-linear-models.html",
    "title": "34  广义线性模型",
    "section": "",
    "text": "34.1 生成模拟数据\n先介绍泊松广义线性模型，包括模拟和计算，并和 Stan 实现的结果比较。\n泊松广义线性模型如下：\n\\[\n\\begin{aligned}\n\\log(\\lambda) &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\\\\nY &\\sim \\mathrm{Poisson}(u\\lambda)\n\\end{aligned}\n\\]\n设定参数向量 \\(\\beta = (\\beta_0, \\beta_1, \\beta_2) = (0.5, 0.3, 0.2)\\)，观测变量 \\(X_1\\) 和 \\(X_2\\) 的均值都为 0，协方差矩阵 \\(\\Sigma\\) 为\n\\[\n\\left[\n\\begin{matrix}\n   1.0 & 0.8  \\\\\n   0.8 & 1.0\n\\end{matrix}\n\\right]\n\\]\n模拟观测到的响应变量值和协变量值，添加漂移项\nset.seed(2023)\nn &lt;- 2500 # 样本量\nbeta &lt;- c(0.5, 0.3, 0.2)\nX &lt;- MASS::mvrnorm(n, mu = rep(0, 2), Sigma = matrix(c(1, 0.8, 0.8, 1), 2))\nu &lt;- rep(c(2, 4), each = n / 2)\nlambda &lt;- u * exp(cbind(1, X) %*% beta)\ny &lt;- rpois(n, lambda = lambda)",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html#sec-poisson-model",
    "href": "generalized-linear-models.html#sec-poisson-model",
    "title": "34  广义线性模型",
    "section": "\n34.2 拟合泊松模型",
    "text": "34.2 拟合泊松模型\n拟合泊松回归模型\n\nfit_poisson_glm &lt;- glm(y ~ X, family = poisson(link = \"log\"), offset = log(u))\nsummary(fit_poisson_glm)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = y ~ X, family = poisson(link = \"log\"), offset = log(u))\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) 0.488932   0.009427   51.86   &lt;2e-16 ***\n#&gt; X1          0.289984   0.014298   20.28   &lt;2e-16 ***\n#&gt; X2          0.214846   0.014420   14.90   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 6052.9  on 2499  degrees of freedom\n#&gt; Residual deviance: 2675.5  on 2497  degrees of freedom\n#&gt; AIC: 10773\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\n\n# 对数似然函数值\nlog_poisson_lik &lt;- logLik(fit_poisson_glm)\n# 计算 AIC AIC(fit_poisson_glm)\n-2 * c(log_poisson_lik) + 2 * attr(log_poisson_lik, \"df\")\n\n#&gt; [1] 10772.79\n\n\n下面用 Stan 编码泊松回归模型，模型代码如下：\ndata {\n  int&lt;lower=1&gt; k;\n  int&lt;lower=0&gt; n;\n  matrix[n, k] X;\n  array[n] int&lt;lower=0&gt; y;\n  vector[n] log_offset;\n}\nparameters {\n  vector[k] beta;\n  real alpha;\n}\nmodel {\n  target += std_normal_lpdf(beta);\n  target += std_normal_lpdf(alpha);\n  target += poisson_log_glm_lpmf(y | X, alpha + log_offset, beta);\n}\ngenerated quantities {\n  vector[n] log_lik; // pointwise log-likelihood for LOO\n  vector[n] y_rep;   // replications from posterior predictive dist\n  for (i in 1 : n) {\n    real y_hat_i = alpha + X[i] * beta + log_offset[i];\n    log_lik[i] = poisson_log_lpmf(y[i] | y_hat_i);\n    y_rep[i] = poisson_log_rng(y_hat_i);\n  }\n}\nStan 代码主要分三部分：\n\n数据部分 data：声明模型的输入数据，数据类型、大小、约束。\n参数部分 parameters：类似数据部分，声明模型的参数，参数类型、大小。\n模型部分 model：指定模型参数的先验分布。\n生成量 generated quantities：拟合模型获得参数估计值后，计算一些统计量。\n\n下面准备数据\n\nnchains &lt;- 4 # 4 条迭代链\n# 给每条链设置不同的参数初始值\ninits_data &lt;- lapply(1:nchains, function(i) {\n  list(\n    alpha = runif(1, 0, 1),\n    beta = runif(2, 1, 10)\n  )\n})\n\n# 准备数据\npoisson_d &lt;- list(\n  n = 2500, # 观测记录的条数\n  k = 2, # 协变量个数\n  X = X, # N x 2 矩阵\n  y = y, # N 向量\n  log_offset = log(u)\n)\n\n编译模型，抽样获取参数的后验分布\n\n# 加载 cmdstanr 包\nlibrary(cmdstanr)\n# 编译模型\nmod_poisson &lt;- cmdstan_model(\n  stan_file = \"code/poisson_log_glm.stan\",\n  compile = TRUE,\n  cpp_options = list(stan_threads = TRUE)\n)\n# 采样拟合模型\nfit_poisson_stan &lt;- mod_poisson$sample(\n  data = poisson_d, # 观测数据\n  init = inits_data, # 迭代初值\n  iter_warmup = 1000, # 每条链预处理迭代次数\n  iter_sampling = 2000, # 每条链总迭代次数\n  chains = nchains, # 马尔科夫链的数目\n  parallel_chains = 1, # 指定 CPU 核心数，可以给每条链分配一个\n  threads_per_chain = 1, # 每条链设置一个线程\n  show_messages = FALSE, # 不显示迭代的中间过程\n  refresh = 0, # 不显示采样的进度\n  seed = 20222022 # 设置随机数种子，不要使用 set.seed() 函数\n)\n# 迭代诊断\nfit_poisson_stan$diagnostic_summary()\n\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.015694 1.132531 1.041293 1.084272\n\n# 输出结果\nfit_poisson_stan$summary(c(\"alpha\", \"beta\", \"lp__\"))\n\n#&gt; # A tibble: 4 × 10\n#&gt;   variable      mean    median      sd     mad        q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha        0.489     0.489 0.00964 0.00966     0.473  5.05e-1  1.00    4416.\n#&gt; 2 beta[1]      0.290     0.290 0.0144  0.0143      0.266  3.14e-1  1.00    3093.\n#&gt; 3 beta[2]      0.215     0.215 0.0145  0.0145      0.191  2.39e-1  1.00    3168.\n#&gt; 4 lp__     -5388.    -5388.    1.23    1.05    -5390.    -5.39e+3  1.00    3469.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html#sec-posterior-distribution",
    "href": "generalized-linear-models.html#sec-posterior-distribution",
    "title": "34  广义线性模型",
    "section": "\n34.3 参数后验分布",
    "text": "34.3 参数后验分布\n加载 bayesplot 包，bayesplot 包提供一系列描述数据分布的绘图函数，比如绘制散点图 mcmc_scatter() 。\\(\\beta_1\\) 和 \\(\\beta_2\\) 的联合分布\n\nlibrary(ggplot2)\nlibrary(bayesplot)\nmcmc_scatter(fit_poisson_stan$draws(c(\"beta[1]\", \"beta[2]\")), size = 1) +\n  theme_classic() +\n  labs(x = expression(beta[1]), y = expression(beta[2]))\n\n\n\n\n\n\n图 34.1: \\(\\beta_1\\) 和 \\(\\beta_2\\) 的联合分布\n\n\n\n\n如果提取采样的数据，也可使用 ggplot2 包绘图，不局限于 bayesplot 设定的风格。\n\nbeta_df &lt;- fit_poisson_stan$draws(c(\"beta[1]\", \"beta[2]\"), format = \"draws_df\")\nggplot(data = beta_df, aes(x = `beta[1]`, y = `beta[2]`)) +\n  geom_density_2d_filled() +\n  facet_wrap(~.chain, ncol = 2) +\n  theme_classic() +\n  labs(x = expression(beta[1]), y = expression(beta[2]))\n\n\n\n\n\n\n图 34.2: \\(\\beta_1\\) 和 \\(\\beta_2\\) 的联合分布\n\n\n\n\n\\(\\beta_1\\) 和 \\(\\beta_2\\) 的热力图\n\nmcmc_hex(fit_poisson_stan$draws(c(\"beta[1]\", \"beta[2]\"))) +\n  theme_classic() +\n  labs(x = expression(beta[1]), y = expression(beta[2]))\n\n\n\n\n\n\n图 34.3: \\(\\beta_1\\) 和 \\(\\beta_2\\) 的热力图\n\n\n\n\n各个参数的轨迹图\n\nmcmc_trace(fit_poisson_stan$draws(c(\"beta[1]\", \"beta[2]\")),\n  facet_args = list(\n    labeller = ggplot2::label_parsed, strip.position = \"top\", ncol = 1\n  )\n) +\n  theme_classic()\n\n\n\n\n\n\n图 34.4: 各个参数的轨迹图\n\n\n\n\n可以将模型参数的后验分布图展示出来\n\nmcmc_dens(fit_poisson_stan$draws(c(\"beta[1]\", \"beta[2]\")),\n  facet_args = list(\n    labeller = ggplot2::label_parsed, strip.position = \"top\", ncol = 1\n  )\n) +\n  theme_classic()\n\n\n\n\n\n\n图 34.5: 各个参数的分布图（密度图）\n\n\n\n\n后验分布的中位数、80% 区间\n\nmcmc_areas(fit_poisson_stan$draws(c(\"beta[1]\", \"beta[2]\")), prob = 0.8) +\n  scale_y_discrete(labels = scales::parse_format()) +\n  theme_classic()\n\n\n\n\n\n\n图 34.6: 各个参数的分布图（岭线图）\n\n\n\n\n岭线图就是将各个参数的后验分布图放在一起。\n\nmcmc_areas_ridges(x = fit_poisson_stan$draws(), pars = c(\"beta[1]\", \"beta[2]\")) +\n  scale_y_discrete(labels = scales::parse_format()) +\n  theme_classic()\n\n\n\n\n\n\n图 34.7: 各个参数的分布图（岭线图）\n\n\n\n\n参数的 \\(\\hat{R}\\) 潜在尺度收缩因子\n\nbayesplot::rhat(fit_poisson_stan, pars = \"alpha\")\n\n#&gt;    alpha \n#&gt; 1.000374\n\n\n后验预测诊断的想法是检查根据拟合模型生成的随机数 \\(y^{rep}\\) 与真实观测数据 \\(y\\) 的接近程度。为直观起见，可以用一系列描述数据分布的图来可视化检验。\n\n# mcmc_scatter(fit_poisson_stan$draws(),\n#   pars = c(\"beta[1]\", \"beta[2]\"),\n#   np = nuts_params(fit_poisson_stan)\n# )\n\nmcmc_nuts_energy(x = nuts_params(fit_poisson_stan), binwidth = 1) +\n  ggtitle(label = \"NUTS Energy Diagnostic\")\n\n\n\n\n\n\n图 34.8: NUTS 能量诊断图\n\n\n\n\ny 是真实数据，yrep 是根据贝叶斯拟合模型生成的数据。下图是真实数据的密度图和50组生成数据的密度图。\n\n# 抽取 yrep 数据\nyrep &lt;- fit_poisson_stan$draws(variables = \"y_rep\", format = \"draws_matrix\")\npp_check(y, yrep = yrep[1:50, ], fun = ppc_dens_overlay) +\n  theme_classic()\n\n\n\n\n\n\n图 34.9: 后验预测诊断图（密度图）\n\n\n\n\n观察后验预测区间与真实数据的覆盖情况，不妨取前 50 次观测的数据，即 y[1:50] 与第 2 个自变量 X[1:50, 2] ，基于后验分布的 500 次采样数据绘制 50% 后验置信区间。\n\nppc_intervals(y[1:50], yrep = yrep[1:1000, 1:50], x = X[1:50, 2], prob = 0.5)\n\n\n\n\n\n\n图 34.10: 后验预测诊断图（区间图）",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html#sec-model-evaluation",
    "href": "generalized-linear-models.html#sec-model-evaluation",
    "title": "34  广义线性模型",
    "section": "\n34.4 模型评估指标",
    "text": "34.4 模型评估指标\nloo 包可以计算 WAIC\n\nfit_poisson_waic &lt;- loo::waic(fit_poisson_stan$draws(variables = \"log_lik\"))\nprint(fit_poisson_waic)\n\n#&gt; \n#&gt; Computed from 8000 by 2500 log-likelihood matrix\n#&gt; \n#&gt;           Estimate   SE\n#&gt; elpd_waic  -5386.4 37.7\n#&gt; p_waic         3.0  0.1\n#&gt; waic       10772.9 75.5\n\n\nloo 包推荐使用 LOO-CV ，它还提供诊断信息、有效样本量和蒙特卡罗估计。\n\nfit_poisson_loo &lt;- fit_poisson_stan$loo(variables = \"log_lik\", cores = 2)\nprint(fit_poisson_loo)\n\n#&gt; \n#&gt; Computed from 8000 by 2500 log-likelihood matrix\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo  -5386.4 37.7\n#&gt; p_loo         3.0  0.1\n#&gt; looic     10772.9 75.5\n#&gt; ------\n#&gt; Monte Carlo SE of elpd_loo is 0.0.\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.5).\n#&gt; See help('pareto-k-diagnostic') for details.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html#sec-bayesian-brms",
    "href": "generalized-linear-models.html#sec-bayesian-brms",
    "title": "34  广义线性模型",
    "section": "\n34.5 可选替代实现",
    "text": "34.5 可选替代实现\n对于常见的统计模型，rstanarm 和 brms 包都内置了预编译的 Stan 程序，下面用 brms 包的函数 brm() 拟合带上述漂移项的泊松广义线性模型，参数估计结果和 Base R 函数 glm() 的几乎一致，因编译和抽样的过程比较花费时间，速度不及 Base R。\n# brms\ndat &lt;- data.frame(y = y, X = X, u = u)\ncolnames(dat) &lt;- c(\"y\", \"x1\", \"x2\", \"u\")\nfit_poisson_brm &lt;- brms::brm(y ~ x1 + x2 + offset(log(u)),\n  data = dat, family = poisson(link = \"log\")\n)\nfit_poisson_brm\n Family: poisson \n  Links: mu = log \nFormula: y ~ x1 + x2 + offset(log(u)) \n   Data: dat (Number of observations: 2500) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.49      0.01     0.47     0.51 1.00     2509     2171\nx1            0.29      0.01     0.26     0.32 1.00     1771     1645\nx2            0.21      0.01     0.19     0.24 1.00     1727     1847\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n调用函数 brm() 拟合模型后返回一个 brmsfit 对象 fit_poisson_brm，brms 包提供很多函数处理该数据对象，比如 brms::loo() 计算 LOO-CV\nbrms::loo(fit_poisson_brm)\nComputed from 4000 by 2500 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -5386.3 37.8\np_loo         2.9  0.1\nlooic     10772.6 75.5\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n输出结果中， LOO IC 信息准则 Loo information criterion，looic 指标的作用类似频率派模型中的 AIC 指标，所以也几乎相同的。\n# 后验预测检查\nbrms::pp_check(fit_poisson_brm)",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html#sec-esoph",
    "href": "generalized-linear-models.html#sec-esoph",
    "title": "34  广义线性模型",
    "section": "\n34.6 案例：吸烟喝酒和食道癌的关系",
    "text": "34.6 案例：吸烟喝酒和食道癌的关系\n\n本例数据集 esoph 来自 Base R 内置的 datasets 包，是法国伊勒-维莱讷食道癌研究数据，研究吸烟、喝酒与食道癌的关系，量化酒精、烟草、酒精和烟草的交互作用。部分数据集见 表格 34.1 ，年龄组 agegp、酒精量 alcgp 和烟草量 tobgp 为有序的分类变量，正常来说，年龄越大，吸烟、喝酒对食道癌影响越大。\n\n\n\n表格 34.1: 食道癌研究数据（部分）\n\n\n\n\n年龄组\n酒精量\n烟草量\n实验组\n控制组\n\n\n\n25-34\n0-39g/day\n0-9g/day\n0\n40\n\n\n25-34\n0-39g/day\n10-19\n0\n10\n\n\n25-34\n0-39g/day\n20-29\n0\n6\n\n\n25-34\n0-39g/day\n30+\n0\n5\n\n\n25-34\n40-79\n0-9g/day\n0\n27\n\n\n25-34\n40-79\n10-19\n0\n7\n\n\n\n\n\n\n\n\n\n34.6.1 描述分析\n先来简单统计一下各年龄组、酒精量组的食道癌发病人数\n\nxtabs(data = esoph, cbind(ncases, ncontrols) ~ agegp + alcgp)\n\n#&gt; , ,  = ncases\n#&gt; \n#&gt;        alcgp\n#&gt; agegp   0-39g/day 40-79 80-119 120+\n#&gt;   25-34         0     0      0    1\n#&gt;   35-44         1     4      0    4\n#&gt;   45-54         1    20     12   13\n#&gt;   55-64        12    22     24   18\n#&gt;   65-74        11    25     13    6\n#&gt;   75+           4     4      2    3\n#&gt; \n#&gt; , ,  = ncontrols\n#&gt; \n#&gt;        alcgp\n#&gt; agegp   0-39g/day 40-79 80-119 120+\n#&gt;   25-34        61    45      5    4\n#&gt;   35-44        88    76     20    6\n#&gt;   45-54        77    61     27    2\n#&gt;   55-64        77    62     19    8\n#&gt;   65-74        60    28     16    2\n#&gt;   75+          23     8      0    0\n\n\n图 34.11 描述食道癌发病率与年龄组、酒精量的关系\n\nlibrary(ggplot2)\naggregate(cbind(ncases, ncontrols) ~ agegp + alcgp, data = esoph, sum) |&gt;\n  ggplot(aes(x = agegp, y = alcgp, fill = ncases / (ncases + ncontrols))) +\n  scale_fill_viridis_c(labels = scales::percent_format()) +\n  geom_tile() +\n  labs(x = \"年龄组\", y = \"酒精量\", fill = \"发病率\")\n\n\n\n\n\n\n图 34.11: 食道癌发病率与年龄组、酒精量的关系\n\n\n\n\n\n34.6.2 拟合模型\n响应变量服从二项分布，自变量包含年龄分组 agegp、酒精量 alcgp、烟草量 tobgp 和 酒精量与烟草量的交互作用，建立广义线性模型。\n\nfit_glm_esoph &lt;- glm(cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp,\n  data = esoph, family = binomial(link = \"logit\")\n)\n\n模型输出\n\nsummary(fit_glm_esoph)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp, \n#&gt;     family = binomial(link = \"logit\"), data = esoph)\n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)     -1.16933    0.20767  -5.631 1.79e-08 ***\n#&gt; agegp.L          3.97135    0.69286   5.732 9.94e-09 ***\n#&gt; agegp.Q         -1.58715    0.61943  -2.562   0.0104 *  \n#&gt; agegp.C          0.09866    0.47331   0.208   0.8349    \n#&gt; agegp^4          0.09950    0.32816   0.303   0.7617    \n#&gt; agegp^5         -0.27067    0.21516  -1.258   0.2084    \n#&gt; tobgp.L          1.10809    0.27042   4.098 4.17e-05 ***\n#&gt; tobgp.Q          0.26586    0.25419   1.046   0.2956    \n#&gt; tobgp.C          0.29394    0.24026   1.223   0.2212    \n#&gt; alcgp.L          2.42627    0.28829   8.416  &lt; 2e-16 ***\n#&gt; alcgp.Q          0.12999    0.25418   0.511   0.6091    \n#&gt; alcgp.C          0.36600    0.22252   1.645   0.1000    \n#&gt; tobgp.L:alcgp.L -0.42942    0.58589  -0.733   0.4636    \n#&gt; tobgp.Q:alcgp.L  0.33676    0.56764   0.593   0.5530    \n#&gt; tobgp.C:alcgp.L -0.15742    0.54313  -0.290   0.7719    \n#&gt; tobgp.L:alcgp.Q  0.04169    0.53027   0.079   0.9373    \n#&gt; tobgp.Q:alcgp.Q -0.62384    0.50922  -1.225   0.2205    \n#&gt; tobgp.C:alcgp.Q -0.06700    0.48120  -0.139   0.8893    \n#&gt; tobgp.L:alcgp.C -0.25088    0.47211  -0.531   0.5951    \n#&gt; tobgp.Q:alcgp.C  0.02303    0.44197   0.052   0.9584    \n#&gt; tobgp.C:alcgp.C -0.17340    0.40908  -0.424   0.6717    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 367.953  on 87  degrees of freedom\n#&gt; Residual deviance:  76.886  on 67  degrees of freedom\n#&gt; AIC: 233.94\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 6\n\n\n整理模型输出后，见 表格 34.2\n\n\n\n表格 34.2: 广义线性模型各个参数的估计结果\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-1.1693289\n0.2076675\n-5.6307761\n0.0000000\n\n\nagegp.L\n3.9713482\n0.6928602\n5.7318175\n0.0000000\n\n\nagegp.Q\n-1.5871516\n0.6194310\n-2.5622734\n0.0103989\n\n\nagegp.C\n0.0986649\n0.4733144\n0.2084553\n0.8348735\n\n\nagegp^4\n0.0995027\n0.3281577\n0.3032161\n0.7617251\n\n\nagegp^5\n-0.2706732\n0.2151596\n-1.2580111\n0.2083877\n\n\ntobgp.L\n1.1080898\n0.2704214\n4.0976401\n0.0000417\n\n\ntobgp.Q\n0.2658557\n0.2541932\n1.0458805\n0.2956162\n\n\ntobgp.C\n0.2939369\n0.2402602\n1.2234109\n0.2211745\n\n\nalcgp.L\n2.4262714\n0.2882861\n8.4161937\n0.0000000\n\n\nalcgp.Q\n0.1299883\n0.2541785\n0.5114056\n0.6090671\n\n\nalcgp.C\n0.3659976\n0.2225178\n1.6448016\n0.1000107\n\n\ntobgp.L:alcgp.L\n-0.4294231\n0.5858868\n-0.7329456\n0.4635916\n\n\ntobgp.Q:alcgp.L\n0.3367616\n0.5676428\n0.5932632\n0.5530050\n\n\ntobgp.C:alcgp.L\n-0.1574229\n0.5431330\n-0.2898423\n0.7719369\n\n\ntobgp.L:alcgp.Q\n0.0416850\n0.5302708\n0.0786108\n0.9373422\n\n\ntobgp.Q:alcgp.Q\n-0.6238362\n0.5092212\n-1.2250790\n0.2205454\n\n\ntobgp.C:alcgp.Q\n-0.0670047\n0.4811987\n-0.1392454\n0.8892562\n\n\ntobgp.L:alcgp.C\n-0.2508767\n0.4721073\n-0.5313976\n0.5951433\n\n\ntobgp.Q:alcgp.C\n0.0230305\n0.4419683\n0.0521088\n0.9584420\n\n\ntobgp.C:alcgp.C\n-0.1733950\n0.4090805\n-0.4238652\n0.6716641\n\n\n\n\n\n\n\n\n\n34.6.3 与 brms 比较\n下面从贝叶斯的视角分析和建模，使用 brms 包对该数据拟合，同样是广义线性模型。\nfit_brm_esoph &lt;- brm(ncases | trials(ncases + ncontrols) ~ agegp + tobgp * alcgp, \n                     data = esoph, family = binomial(link = \"logit\"))\n Family: binomial \n  Links: mu = logit \nFormula: ncases | trials(ncases + ncontrols) ~ agegp + tobgp * alcgp \n   Data: esoph (Number of observations: 88) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat\nIntercept          -1.91      0.25    -2.49    -1.51        735 1.01\nagegp.L             3.39      0.86     2.13     5.45        674 1.01\nagegp.Q            -1.68      0.78    -3.58    -0.50        658 1.01\nagegp.C             0.31      0.57    -0.59     1.63        709 1.00\nagegpE4            -0.01      0.36    -0.80     0.65        907 1.01\nagegpE5            -0.20      0.21    -0.59     0.22       1970 1.00\ntobgp.L             0.63      0.20     0.24     1.03       4654 1.00\ntobgp.Q             0.03      0.20    -0.38     0.42       3469 1.00\ntobgp.C             0.17      0.20    -0.21     0.57       3892 1.00\nalcgp.L             1.41      0.22     0.99     1.84       4067 1.00\nalcgp.Q            -0.16      0.20    -0.56     0.24       3335 1.00\nalcgp.C             0.25      0.19    -0.12     0.62       3870 1.00\ntobgp.L:alcgp.L    -0.69      0.42    -1.51     0.16       3878 1.00\ntobgp.Q:alcgp.L     0.13      0.43    -0.75     0.97       4249 1.00\ntobgp.C:alcgp.L    -0.30      0.44    -1.15     0.58       5149 1.00\ntobgp.L:alcgp.Q     0.13      0.41    -0.67     0.94       3127 1.00\ntobgp.Q:alcgp.Q    -0.46      0.41    -1.24     0.34       4037 1.00\ntobgp.C:alcgp.Q    -0.05      0.40    -0.82     0.74       4490 1.00\ntobgp.L:alcgp.C    -0.15      0.38    -0.89     0.58       3507 1.00\ntobgp.Q:alcgp.C     0.04      0.37    -0.69     0.75       3274 1.00\ntobgp.C:alcgp.C    -0.17      0.36    -0.88     0.54       3773 1.00\n\nSamples were drawn using sampling(NUTS). For each parameter, Eff.Sample \nis a crude measure of effective sample size, and Rhat is the potential \nscale reduction factor on split chains (at convergence, Rhat = 1).\n输出结果和 glm() 有不少差别的。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html#案例哥本哈根住房状况调查",
    "href": "generalized-linear-models.html#案例哥本哈根住房状况调查",
    "title": "34  广义线性模型",
    "section": "\n34.7 案例：哥本哈根住房状况调查",
    "text": "34.7 案例：哥本哈根住房状况调查\n\n数据集 housing 哥本哈根住房状况调查中的次数分布表，Sat 住户对目前居住环境的满意程度，是一个有序的因子变量，Infl 住户对物业管理的感知影响程度，Type 租赁住宿类型，如塔楼、中庭、公寓、露台，Cont 联系居民可与其他居民联系(低、高)，Freq 每个类中的居民人数，调查的人数。\n\ndata(\"housing\", package = \"MASS\")\nstr(housing)\n\n#&gt; 'data.frame':    72 obs. of  5 variables:\n#&gt;  $ Sat : Ord.factor w/ 3 levels \"Low\"&lt;\"Medium\"&lt;..: 1 2 3 1 2 3 1 2 3 1 ...\n#&gt;  $ Infl: Factor w/ 3 levels \"Low\",\"Medium\",..: 1 1 1 2 2 2 3 3 3 1 ...\n#&gt;  $ Type: Factor w/ 4 levels \"Tower\",\"Apartment\",..: 1 1 1 1 1 1 1 1 1 2 ...\n#&gt;  $ Cont: Factor w/ 2 levels \"Low\",\"High\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ Freq: int  21 21 28 34 22 36 10 11 36 61 ...\n\n\n响应变量是居民对居住环境满意度 Sat ，分三个等级，且存在强弱，等级，大小之分。\n\n# 因子变量的处理\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n# 有序逻辑回归\nhousing_mass &lt;- MASS::polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing, Hess = TRUE)\nsummary(housing_mass)\n\n#&gt; Call:\n#&gt; MASS::polr(formula = Sat ~ Infl + Type + Cont, data = housing, \n#&gt;     weights = Freq, Hess = TRUE)\n#&gt; \n#&gt; Coefficients:\n#&gt;                 Value Std. Error t value\n#&gt; InflMedium     0.5664    0.10465   5.412\n#&gt; InflHigh       1.2888    0.12716  10.136\n#&gt; TypeApartment -0.5724    0.11924  -4.800\n#&gt; TypeAtrium    -0.3662    0.15517  -2.360\n#&gt; TypeTerrace   -1.0910    0.15149  -7.202\n#&gt; ContHigh       0.3603    0.09554   3.771\n#&gt; \n#&gt; Intercepts:\n#&gt;             Value   Std. Error t value\n#&gt; Low|Medium  -0.4961  0.1248    -3.9739\n#&gt; Medium|High  0.6907  0.1255     5.5049\n#&gt; \n#&gt; Residual Deviance: 3479.149 \n#&gt; AIC: 3495.149\n\n\n计算置信区间\n\n# 剖面\nconfint(profile(housing_mass), level = 0.95)\n\n#&gt;                    2.5 %      97.5 %\n#&gt; InflMedium     0.3616415  0.77195375\n#&gt; InflHigh       1.0409701  1.53958138\n#&gt; TypeApartment -0.8069590 -0.33940432\n#&gt; TypeAtrium    -0.6705862 -0.06204495\n#&gt; TypeTerrace   -1.3893863 -0.79533958\n#&gt; ContHigh       0.1733589  0.54792854",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "generalized-linear-models.html#sec-bayesian-exercises",
    "href": "generalized-linear-models.html#sec-bayesian-exercises",
    "title": "34  广义线性模型",
    "section": "\n34.8 习题",
    "text": "34.8 习题\n\n\n分析挑战者号航天飞机 O 型环数据。DAAG 包的 orings 数据集记录美国挑战者号航天飞机 O 型环在不同温度下发生 Erosion 腐蚀和 Blowby 串气的失效数量。 图 34.12 展示航天飞机 O 型环在不同温度下失效的分布图（条件密度图）：随着温度升高，O 型环越来越不容易失效。请分别用 Base R 函数 glm() 和 cmdstanr 包建模分析 O 型环数据。\n\n代码# data(orings, package = \"DAAG\")\norings &lt;- readRDS(file = \"data/orings.rds\")\nggplot(orings, aes(x = Temperature, y = after_stat(count))) +\n  geom_density(aes(fill = Total &gt; 0), position = \"fill\", bw = 2) +\n  scale_y_continuous(labels = scales::label_percent()) +\n  scale_fill_grey(labels = c(\"TRUE\" = \"是\", \"FALSE\" = \"否\")) +\n  theme_classic() +\n  labs(x = \"温度\", y = \"比例\", fill = \"失效\")\n\n\n\n\n\n\n图 34.12: 航天飞机 O 型环在不同温度下失效的条件密度图\n\n\n\n\n\n\n基于数据集 infert 分析自然流产和人工流产后的不育情况，\n\n代码infert_glm &lt;- glm(\n  case ~ age + parity + education + spontaneous + induced,\n  data = infert, family = binomial()\n)\nsummary(infert_glm)\n\n# conditional logistic regression\nlibrary(survival)\ninfert_survival &lt;- clogit(\n  case ~ age + parity + education + spontaneous + induced + strata(stratum), data = infert\n)\nsummary(infert_survival)\n\n\n\n根据 章节 28 的数据，建立贝叶斯空间广义线性混合模型，用 Stan 预测核辐射强度的分布。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html",
    "href": "hierarchical-normal-models.html",
    "title": "35  分层正态模型",
    "section": "",
    "text": "35.1 rstan 包\n本节以 8schools 数据为例介绍分层正态模型及 rstan 包实现，8schools 数据最早来自 Rubin (1981) ，分层正态模型如下：\n\\[\n\\begin{aligned}\ny_j &\\sim \\mathcal{N}(\\theta_j,\\sigma_j^2) \\quad\n\\theta_j = \\mu + \\tau \\times \\eta_j \\\\\n\\theta_j &\\sim \\mathcal{N}(\\mu, \\tau^2) \\quad\n\\eta_j \\sim \\mathcal{N}(0,1) \\\\\n\\mu &\\sim \\mathcal{N}(0, 100^2) \\quad \\tau \\sim \\mathrm{half\\_normal}(0,100^2)\n\\end{aligned}\n\\]\n其中，\\(y_j,\\sigma_j\\) 是已知的观测数据，\\(\\theta_j\\) 是模型参数， \\(\\eta_j\\) 是服从标准正态分布的潜变量，\\(\\mu,\\tau\\) 是超参数，分别服从正态分布（将方差设置为很大的数，则变成弱信息先验或无信息均匀先验）和半正态分布（随机变量限制为正值）。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#sec-8schools-rstan",
    "href": "hierarchical-normal-models.html#sec-8schools-rstan",
    "title": "35  分层正态模型",
    "section": "",
    "text": "35.1.1 拟合模型\n用 rstan 包来拟合模型，下面采用非中心的参数化表示，降低参数的相关性，减少发散的迭代次数，提高采样效率。\n\n# 编译模型\neight_schools_fit &lt;- stan(\n  model_name = \"eight_schools\",\n  # file = \"code/eight_schools.stan\",\n  model_code = \"\n  // saved as eight_schools.stan\n  data {\n    int&lt;lower=0&gt; J;                // number of schools\n    array[J] real y;               // estimated treatment effects\n    array[J] real &lt;lower=0&gt; sigma; // standard error of effect estimates\n  }\n  parameters {\n    real mu;                // population treatment effect\n    real&lt;lower=0&gt; tau;      // standard deviation in treatment effects\n    vector[J] eta;          // unscaled deviation from mu by school\n  }\n  transformed parameters {\n    vector[J] theta = mu + tau * eta;        // school treatment effects\n  }\n  model {\n    target += normal_lpdf(mu | 0, 100); \n    target += normal_lpdf(tau | 0, 100);\n    target += normal_lpdf(eta | 0, 1);  // prior log-density\n    target += normal_lpdf(y | theta, sigma); // log-likelihood\n  }\n  \",\n  data = list( # 观测数据\n    J = 8,\n    y = c(28, 8, -3, 7, -1, 1, 18, 12),\n    sigma = c(15, 10, 16, 11, 9, 11, 10, 18)\n  ),\n  warmup = 1000, # 每条链预处理迭代次数\n  iter = 2000,   # 每条链总迭代次数\n  chains = 2,    # 马尔科夫链的数目\n  cores = 2,     # 指定 CPU 核心数，可以给每条链分配一个\n  verbose = FALSE, # 不显示迭代的中间过程\n  refresh = 0,     # 不显示采样的进度\n  seed = 20232023  # 设置随机数种子，不要使用 set.seed() 函数\n)\n\n\n35.1.2 模型输出\n用函数 print() 打印输出结果，保留 2 位小数。\n\nprint(eight_schools_fit, digits = 2)\n\n#&gt; Inference for Stan model: eight_schools.\n#&gt; 2 chains, each with iter=2000; warmup=1000; thin=1; \n#&gt; post-warmup draws per chain=1000, total post-warmup draws=2000.\n#&gt; \n#&gt;            mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat\n#&gt; mu         7.90    0.16 5.00  -1.79   4.60   7.71  11.05  18.37   988    1\n#&gt; tau        6.43    0.20 5.35   0.22   2.49   5.23   8.94  19.73   733    1\n#&gt; eta[1]     0.40    0.02 0.96  -1.57  -0.21   0.41   1.06   2.27  2252    1\n#&gt; eta[2]     0.00    0.02 0.88  -1.74  -0.59  -0.01   0.57   1.77  1977    1\n#&gt; eta[3]    -0.17    0.02 0.92  -1.93  -0.78  -0.18   0.41   1.71  2307    1\n#&gt; eta[4]    -0.04    0.02 0.91  -1.90  -0.64  -0.01   0.55   1.76  2053    1\n#&gt; eta[5]    -0.34    0.02 0.89  -2.03  -0.97  -0.38   0.25   1.43  1769    1\n#&gt; eta[6]    -0.22    0.02 0.87  -1.89  -0.81  -0.23   0.36   1.52  1959    1\n#&gt; eta[7]     0.33    0.02 0.86  -1.30  -0.26   0.31   0.90   2.00  2020    1\n#&gt; eta[8]     0.05    0.02 0.96  -1.89  -0.59   0.05   0.69   1.94  2597    1\n#&gt; theta[1]  11.29    0.20 8.11  -1.69   5.88  10.14  15.34  31.08  1728    1\n#&gt; theta[2]   7.80    0.13 6.25  -4.68   3.88   7.88  11.62  19.78  2362    1\n#&gt; theta[3]   6.30    0.17 7.57 -10.90   2.15   6.63  10.87  20.04  1902    1\n#&gt; theta[4]   7.72    0.14 6.53  -5.33   3.78   7.52  11.66  21.22  2249    1\n#&gt; theta[5]   5.10    0.14 6.48  -9.20   1.04   5.69   9.50  16.71  2030    1\n#&gt; theta[6]   6.06    0.16 6.88  -8.61   2.07   6.39  10.33  19.01  1766    1\n#&gt; theta[7]  10.41    0.14 6.42  -0.18   6.03   9.59  13.98  24.97  2057    1\n#&gt; theta[8]   8.45    0.19 8.00  -7.45   4.02   8.13  12.69  26.56  1728    1\n#&gt; lp__     -50.67    0.11 2.64 -56.69 -52.25 -50.40 -48.78 -46.34   584    1\n#&gt; \n#&gt; Samples were drawn using NUTS(diag_e) at Tue Jan 23 07:40:16 2024.\n#&gt; For each parameter, n_eff is a crude measure of effective sample size,\n#&gt; and Rhat is the potential scale reduction factor on split chains (at \n#&gt; convergence, Rhat=1).\n\n\n值得一提，数据有限而且规律不明确，数据隐含的信息不是很多，则先验分布的情况将会对参数估计结果产生很大影响。Stan 默认采用无信息的先验分布，当使用非常弱的信息先验时，结果就非常不同了。提取任意一个参数的结果，如查看参数 \\(\\tau\\) 的 95% 置信区间。\n\nprint(eight_schools_fit, pars = \"tau\", probs = c(0.025, 0.975))\n\n#&gt; Inference for Stan model: eight_schools.\n#&gt; 2 chains, each with iter=2000; warmup=1000; thin=1; \n#&gt; post-warmup draws per chain=1000, total post-warmup draws=2000.\n#&gt; \n#&gt;     mean se_mean   sd 2.5% 97.5% n_eff Rhat\n#&gt; tau 6.43     0.2 5.35 0.22 19.73   733    1\n#&gt; \n#&gt; Samples were drawn using NUTS(diag_e) at Tue Jan 23 07:40:16 2024.\n#&gt; For each parameter, n_eff is a crude measure of effective sample size,\n#&gt; and Rhat is the potential scale reduction factor on split chains (at \n#&gt; convergence, Rhat=1).\n\n\n从迭代抽样数据获得与 print(fit) 一样的结果。以便后续对原始采样数据做任意的进一步分析。rstan 包扩展泛型函数 summary() 以支持对 stanfit 数据对象汇总，输出各个参数分链条和合并链条的后验分布结果。\n\n35.1.3 操作数据\n抽取数据对象 eight_schools_fit 中的采样数据，合并几条马氏链的结果，返回的结果是一个列表。\n\neight_schools_sim &lt;- extract(eight_schools_fit, permuted = TRUE)\n\n返回列表中的每个元素是一个数组，标量参数对应一维数组，向量参数对应二维数组。\n\nstr(eight_schools_sim)\n\n#&gt; List of 5\n#&gt;  $ mu   : num [1:2000(1d)] -1.25 10.57 -2.47 9.82 -1.31 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 1\n#&gt;   .. ..$ iterations: NULL\n#&gt;  $ tau  : num [1:2000(1d)] 22.548 3.581 11.407 10.341 0.231 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 1\n#&gt;   .. ..$ iterations: NULL\n#&gt;  $ eta  : num [1:2000, 1:8] 1.13 -1.33 2.05 -1.27 1.98 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. ..$ iterations: NULL\n#&gt;   .. ..$           : NULL\n#&gt;  $ theta: num [1:2000, 1:8] 24.198 5.796 20.964 -3.31 -0.853 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. ..$ iterations: NULL\n#&gt;   .. ..$           : NULL\n#&gt;  $ lp__ : num [1:2000(1d)] -45.2 -49.1 -51.1 -48.8 -56 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 1\n#&gt;   .. ..$ iterations: NULL\n\n\n对于列表，适合用函数 lapply() 配合算术函数计算 \\(\\mu,\\tau\\) 等参数的均值。\n\nfun_mean &lt;- function(x) {\n  if (length(dim(x)) &gt; 1) {\n    apply(x, 2, mean)\n  } else {\n    mean(x)\n  }\n}\nlapply(eight_schools_sim, FUN = fun_mean)\n\n#&gt; $mu\n#&gt; [1] 7.896911\n#&gt; \n#&gt; $tau\n#&gt; [1] 6.427487\n#&gt; \n#&gt; $eta\n#&gt; [1]  0.39815800 -0.00403665 -0.17091492 -0.03835530 -0.34447579 -0.21592391\n#&gt; [7]  0.33375651  0.04527884\n#&gt; \n#&gt; $theta\n#&gt; [1] 11.293515  7.796730  6.300619  7.722628  5.100476  6.059899 10.411386\n#&gt; [8]  8.451163\n#&gt; \n#&gt; $lp__\n#&gt; [1] -50.66637\n\n\n类似地，计算 \\(\\mu,\\tau\\) 等参数的分位点。\n\nfun_quantile &lt;- function(x, probs) {\n  if (length(dim(x)) &gt; 1) {\n    t(apply(x, 2, quantile, probs = probs))\n  } else {\n    quantile(x, probs = probs)\n  }\n}\nlapply(eight_schools_sim, fun_quantile, probs = c(2.5, 25, 50, 75, 97.5) / 100)\n\n#&gt; $mu\n#&gt;      2.5%       25%       50%       75%     97.5% \n#&gt; -1.787025  4.603868  7.706957 11.054801 18.370903 \n#&gt; \n#&gt; $tau\n#&gt;       2.5%        25%        50%        75%      97.5% \n#&gt;  0.2221582  2.4933088  5.2289974  8.9369194 19.7296019 \n#&gt; \n#&gt; $eta\n#&gt;       \n#&gt;             2.5%        25%          50%       75%    97.5%\n#&gt;   [1,] -1.571814 -0.2051970  0.412478990 1.0592655 2.267580\n#&gt;   [2,] -1.740860 -0.5924433 -0.009587292 0.5740810 1.768344\n#&gt;   [3,] -1.933032 -0.7815080 -0.181728735 0.4102823 1.709490\n#&gt;   [4,] -1.896206 -0.6383988 -0.008634091 0.5491973 1.758581\n#&gt;   [5,] -2.029051 -0.9674769 -0.376669547 0.2505514 1.425229\n#&gt;   [6,] -1.890733 -0.8146685 -0.227713876 0.3642582 1.524509\n#&gt;   [7,] -1.295196 -0.2552945  0.310815774 0.9046577 1.995717\n#&gt;   [8,] -1.894366 -0.5853674  0.053723000 0.6912584 1.940257\n#&gt; \n#&gt; $theta\n#&gt;       \n#&gt;               2.5%      25%       50%       75%    97.5%\n#&gt;   [1,]  -1.6909041 5.879186 10.136104 15.343330 31.08250\n#&gt;   [2,]  -4.6774314 3.880805  7.876314 11.616239 19.77814\n#&gt;   [3,] -10.9015495 2.149377  6.629543 10.872316 20.03882\n#&gt;   [4,]  -5.3329649 3.779338  7.521149 11.663011 21.22172\n#&gt;   [5,]  -9.2028941 1.035711  5.692159  9.501092 16.70603\n#&gt;   [6,]  -8.6129198 2.068728  6.393843 10.333108 19.00727\n#&gt;   [7,]  -0.1804168 6.033491  9.594300 13.980905 24.96505\n#&gt;   [8,]  -7.4463975 4.015728  8.129632 12.694195 26.55720\n#&gt; \n#&gt; $lp__\n#&gt;      2.5%       25%       50%       75%     97.5% \n#&gt; -56.69300 -52.24867 -50.39536 -48.78482 -46.34192\n\n\n同理，可以计算最大值 max()、最小值 min() 和中位数 median() 等。\n\n35.1.4 采样诊断\n获取马尔科夫链迭代点列数据\n\neight_schools_sim &lt;- extract(eight_schools_fit, permuted = FALSE)\n\neight_schools_sim 是一个三维数组，1000（次迭代）* 2 （条链）* 19（个参数）。如果 permuted = TRUE 则会合并马氏链的迭代结果，变成一个列表。\n\n# 数据类型\nclass(eight_schools_sim)\n\n#&gt; [1] \"array\"\n\n# 1000（次迭代）* 2 （条链）* 19（个参数）\nstr(eight_schools_sim)\n\n#&gt;  num [1:1000, 1:2, 1:19] 14.18 2.19 12.29 12.51 5.02 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iterations: NULL\n#&gt;   ..$ chains    : chr [1:2] \"chain:1\" \"chain:2\"\n#&gt;   ..$ parameters: chr [1:19] \"mu\" \"tau\" \"eta[1]\" \"eta[2]\" ...\n\n\n提取参数 \\(\\mu\\) 的迭代点列，绘制迭代轨迹。\n\neight_schools_mu_sim &lt;- eight_schools_sim[, , \"mu\"]\nmatplot(\n  eight_schools_mu_sim, xlab = \"迭代次数\", ylab = expression(mu),\n  type = \"l\", lty = \"solid\", col = custom_colors\n)\nabline(h = apply(eight_schools_mu_sim, 2, mean), col = custom_colors)\nlegend(\n  \"topleft\", legend = paste(\"chain\", 1:2), box.col = \"white\", \n  inset = 0.01, lty = \"solid\", horiz = TRUE, col = custom_colors\n)\n\n\n\n\n\n\n图 35.1: Base R 绘制参数 \\(\\mu\\) 的迭代轨迹\n\n\n\n\n也可以使用 rstan 包提供的函数 traceplot() 或者 stan_trace() 绘制参数的迭代轨迹图。\n\nstan_trace(eight_schools_fit, pars = \"mu\") +\n  labs(x = \"迭代次数\", y = expression(mu))\n\n\n\n\n\n\n图 35.2: rstan 绘制参数 \\(\\mu\\) 的迭代轨迹\n\n\n\n\n\n35.1.5 后验分布\n可以用函数 stan_hist() 或 stan_dens() 绘制后验分布图。下图分别展示参数 \\(\\mu\\)、\\(\\tau\\) 的直方图，以及二者的散点图，参数 \\(\\mu\\) 的后验概率密度分布图。\n\np1 &lt;- stan_hist(eight_schools_fit, pars = c(\"mu\",\"tau\"), bins = 30)\np2 &lt;- stan_scat(eight_schools_fit, pars = c(\"mu\",\"tau\"), size = 1) +\n  labs(x = expression(mu), y = expression(tau))\np3 &lt;- stan_dens(eight_schools_fit, pars = \"mu\") + labs(x = expression(mu))\nlibrary(patchwork)\np1 / (p2 + p3)\n\n\n\n\n\n\n图 35.3: rstan 包绘制后验分布图\n\n\n\n\n相比于 rstan 包，bayesplot 包可视化能力更强，支持对特定的参数做变换。bayesplot 包的函数 mcmc_pairs() 以矩阵图展示多个参数的分布，下图展示参数 \\(\\mu\\)，\\(\\log(\\tau)\\) 后验分布图。但是，这些函数都固定了一些标题，不能修改。\n\nbayesplot::mcmc_pairs(\n  eight_schools_fit, pars = c(\"mu\", \"tau\"), transform = list(tau = \"log\")\n)\n\n\n\n\n\n\n图 35.4: bayesplot 包绘制后验分布图",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#sec-8schools-others",
    "href": "hierarchical-normal-models.html#sec-8schools-others",
    "title": "35  分层正态模型",
    "section": "\n35.2 其它 R 包",
    "text": "35.2 其它 R 包\n\n35.2.1 nlme\n接下来，用 nlme 包拟合模型。\n\n# 成绩\ny &lt;- c(28, 8, -3, 7, -1, 1, 18, 12)\n# 标准差\nsigma &lt;- c(15, 10, 16, 11, 9, 11, 10, 18)\n# 学校编号\ng &lt;- 1:8\n\n首先，调用 nlme 包的函数 lme() 拟合模型。\n\nlibrary(nlme)\nfit_lme &lt;- lme(y ~ 1, random = ~ 1 | g, weights = varFixed(~ sigma^2), method = \"REML\")\nsummary(fit_lme)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: NULL \n#&gt;        AIC      BIC    logLik\n#&gt;   60.21091 60.04864 -27.10546\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | g\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    2.917988 0.780826\n#&gt; \n#&gt; Variance function:\n#&gt;  Structure: fixed weights\n#&gt;  Formula: ~sigma^2 \n#&gt; Fixed effects:  y ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 7.785729  3.368082  8 2.311621  0.0496\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.06635035 -0.73588511 -0.02896764  0.50254917  1.62502386 \n#&gt; \n#&gt; Number of Observations: 8\n#&gt; Number of Groups: 8\n\n\n随机效应的标准差 2.917988 ，随机效应部分的估计\n\nranef(fit_lme)\n\n#&gt;   (Intercept)\n#&gt; 1  1.18135690\n#&gt; 2  0.02625714\n#&gt; 3 -0.55795543\n#&gt; 4 -0.08130333\n#&gt; 5 -1.29202240\n#&gt; 6 -0.70215328\n#&gt; 7  1.25167648\n#&gt; 8  0.17414393\n\n\n类比 Stan 输出结果中的 \\(\\theta\\) 向量，每个学校的成绩估计\n\n7.785729 + 2.917988 * ranef(fit_lme)\n\n#&gt;   (Intercept)\n#&gt; 1   11.232914\n#&gt; 2    7.862347\n#&gt; 3    6.157622\n#&gt; 4    7.548487\n#&gt; 5    4.015623\n#&gt; 6    5.736854\n#&gt; 7   11.438106\n#&gt; 8    8.293879\n\n\n\n35.2.2 lme4\n接着，采用 lme4 包拟合模型，发现 lme4 包获得与 nlme 包一样的结果。\n\ncontrol &lt;- lme4::lmerControl(\n  check.conv.singular = \"ignore\",\n  check.nobs.vs.nRE = \"ignore\",\n  check.nobs.vs.nlev = \"ignore\"\n)\nfit_lme4 &lt;- lme4::lmer(y ~ 1 + (1 | g), weights = 1 / sigma^2, control = control, REML = TRUE)\nsummary(fit_lme4)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ 1 + (1 | g)\n#&gt; Weights: 1/sigma^2\n#&gt; Control: control\n#&gt; \n#&gt; REML criterion at convergence: 54.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.06635 -0.73589 -0.02897  0.50255  1.62502 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  g        (Intercept) 8.5145   2.9180  \n#&gt;  Residual             0.6097   0.7808  \n#&gt; Number of obs: 8, groups:  g, 8\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)    7.786      3.368   2.312\n\n\n\n35.2.3 blme\n下面使用 blme 包 (Chung 等 2013) ，blme 包基于 lme4 包，参数估计结果完全一致。\n\n# the mode should be at the boundary of the space.\n\nfit_blme &lt;- blme::blmer(\n  y ~ 1 + (1 | g), control = control, REML = TRUE, \n  cov.prior = NULL, weights = 1 / sigma^2\n)\nsummary(fit_blme)\n\n#&gt; Prior dev  : 0\n#&gt; \n#&gt; Linear mixed model fit by REML ['blmerMod']\n#&gt; Formula: y ~ 1 + (1 | g)\n#&gt; Weights: 1/sigma^2\n#&gt; Control: control\n#&gt; \n#&gt; REML criterion at convergence: 54.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.06635 -0.73589 -0.02897  0.50255  1.62502 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  g        (Intercept) 8.5145   2.9180  \n#&gt;  Residual             0.6097   0.7808  \n#&gt; Number of obs: 8, groups:  g, 8\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)    7.786      3.368   2.312\n\n\n\n35.2.4 MCMCglmm\nMCMCglmm 包 (Hadfield 2010) 采用 MCMC 算法拟合数据。\n\nschools &lt;- data.frame(y = y, sigma = sigma, g = g)\nschools$g &lt;- as.factor(schools$g)\n# inverse-gamma prior with scale and shape equal to 0.001\nprior1 &lt;- list(\n  R = list(V = diag(schools$sigma^2), fix = 1),\n  G = list(G1 = list(V = 1, nu = 0.002))\n)\n# 为可重复\nset.seed(20232023)\n# 拟合模型\nfit_mcmc &lt;- MCMCglmm::MCMCglmm(\n  y ~ 1, random = ~g, rcov = ~ idh(g):units, \n  data = schools, prior = prior1, verbose = FALSE\n)\n# 输出结果\nsummary(fit_mcmc)\n\n#&gt; \n#&gt;  Iterations = 3001:12991\n#&gt;  Thinning interval  = 10\n#&gt;  Sample size  = 1000 \n#&gt; \n#&gt;  DIC: -98.07615 \n#&gt; \n#&gt;  G-structure:  ~g\n#&gt; \n#&gt;   post.mean  l-95% CI u-95% CI eff.samp\n#&gt; g     11.23 0.0004247    68.57    361.3\n#&gt; \n#&gt;  R-structure:  ~idh(g):units\n#&gt; \n#&gt;          post.mean l-95% CI u-95% CI eff.samp\n#&gt; g1.units       225      225      225        0\n#&gt; g2.units       100      100      100        0\n#&gt; g3.units       256      256      256        0\n#&gt; g4.units       121      121      121        0\n#&gt; g5.units        81       81       81        0\n#&gt; g6.units       121      121      121        0\n#&gt; g7.units       100      100      100        0\n#&gt; g8.units       324      324      324        0\n#&gt; \n#&gt;  Location effects: y ~ 1 \n#&gt; \n#&gt;             post.mean l-95% CI u-95% CI eff.samp pMCMC  \n#&gt; (Intercept)    7.6938  -0.5149  15.3275     1023 0.062 .\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-structure 表示残差方差，这是已知的参数。G-structure 表示随机截距的方差，Location effects 表示固定效应的截距。截距和 nlme 包的结果很接近。\n\n35.2.5 cmdstanr\n一般地，rstan 包使用的 stan 框架版本低于 cmdstanr 包，从 rstan 包切换到 cmdstanr 包，需要注意语法、函数的变化。rstan 和 cmdstanr 使用的 Stan 版本不同导致参数估计结果不同，结果可重复的条件非常苛刻，详见 Stan 参考手册。在都是较新的版本时，Stan 代码不需要做改动，如下：\ndata {\n  int&lt;lower=0&gt; J; // 学校数目 \n  array[J] real y; // 测试效果的预测值\n  array[J] real &lt;lower=0&gt; sigma; // 测试效果的标准差 \n}\nparameters {\n  real mu; \n  real&lt;lower=0&gt; tau;\n  vector[J] eta;\n}\ntransformed parameters {\n  vector[J] theta;\n  theta = mu + tau * eta;\n}\nmodel {\n  target += normal_lpdf(mu | 0, 100); \n  target += normal_lpdf(tau | 0, 100);\n  target += normal_lpdf(eta | 0, 1);\n  target += normal_lpdf(y | theta, sigma);\n}\n此处，给参数 \\(\\mu,\\tau\\) 添加了非常弱（模糊）的先验，结果将出现较大不同。\n\neight_schools_dat &lt;- list(\n  J = 8,\n  y = c(28, 8, -3, 7, -1, 1, 18, 12),\n  sigma = c(15, 10, 16, 11, 9, 11, 10, 18)\n)\nlibrary(cmdstanr)\nmod_eight_schools &lt;- cmdstan_model(\n  stan_file = \"code/eight_schools.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\nfit_eight_schools &lt;- mod_eight_schools$sample(\n  data = eight_schools_dat, # 数据\n  chains = 2,            # 总链条数\n  parallel_chains = 2,   # 并行数目\n  iter_warmup = 1000,    # 每条链预处理的迭代次数\n  iter_sampling = 1000,  # 每条链采样的迭代次数\n  threads_per_chain = 2, # 每条链设置 2 个线程\n  seed = 20232023,       # 随机数种子\n  show_messages = FALSE, # 不显示消息\n  refresh = 0 # 不显示采样迭代的进度\n)\n\n结果保留 3 位有效数字，模型输出如下：\n\nfit_eight_schools$summary(.num_args = list(sigfig = 3, notation = \"dec\"))\n\n#&gt; # A tibble: 19 × 10\n#&gt;    variable      mean    median    sd   mad      q5    q95  rhat ess_bulk\n#&gt;    &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 lp__     -50.6     -50.4     2.59  2.49  -55.4   -46.7   1.00     720.\n#&gt;  2 mu         7.79      7.81    5.05  4.76   -0.652  15.9   1.00    1519.\n#&gt;  3 tau        6.28      4.97    5.36  4.66    0.384  16.6   1.00     833.\n#&gt;  4 eta[1]     0.402     0.387   0.963 0.974  -1.18    1.99  1.00    3034.\n#&gt;  5 eta[2]     0.00672   0.00898 0.877 0.841  -1.45    1.46  1.00    2404.\n#&gt;  6 eta[3]    -0.169    -0.178   0.918 0.916  -1.68    1.38  1.00    2580.\n#&gt;  7 eta[4]    -0.0109   -0.0144  0.878 0.876  -1.43    1.45  1.00    2492.\n#&gt;  8 eta[5]    -0.340    -0.359   0.840 0.811  -1.69    1.06  1.00    1952.\n#&gt;  9 eta[6]    -0.186    -0.178   0.887 0.854  -1.64    1.31  1.00    2559.\n#&gt; 10 eta[7]     0.339     0.362   0.910 0.890  -1.25    1.82  1.00    2322.\n#&gt; 11 eta[8]     0.0687    0.0622  0.893 0.897  -1.35    1.53  1.00    2924.\n#&gt; 12 theta[1]  11.3       9.95    8.07  6.45    0.450  26.8   1.00    2421.\n#&gt; 13 theta[2]   7.75      7.64    6.06  5.45   -1.99   18.0   1.00    2510.\n#&gt; 14 theta[3]   6.27      6.91    7.44  6.28   -6.72   17.4   1.00    2381.\n#&gt; 15 theta[4]   7.83      7.81    6.75  5.98   -2.99   18.7   1.00    2551.\n#&gt; 16 theta[5]   5.25      5.59    6.02  5.67   -5.50   14.3   1.00    1958.\n#&gt; 17 theta[6]   6.29      6.58    6.65  6.16   -5.62   16.7   1.00    2506.\n#&gt; 18 theta[7]  10.6      10.0     6.76  6.22    0.486  22.6   1.00    2242.\n#&gt; 19 theta[8]   8.45      8.11    7.52  6.29   -2.99   21.2   1.00    2472.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n模型采样过程的诊断结果如下：\n\nfit_eight_schools$diagnostic_summary()\n\n#&gt; $num_divergent\n#&gt; [1] 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 0.7979763 0.8891174\n\n\n分层模型的参数 \\(\\mu,\\log(\\tau)\\) 的后验联合分布呈现经典的漏斗状。\n\nbayesplot::mcmc_scatter(\n  fit_eight_schools$draws(), pars = c(\"mu\", \"tau\"), \n  transform = list(tau = \"log\"), size = 2\n) + labs(x = \"$\\\\mu$\", y = \"$\\\\log(\\\\tau)$\")\n\n\n\n\n\n\n图 35.5: 参数 \\(\\mu,\\log(\\tau)\\) 的联合分布\n\n\n\n\n对于调用 cmdstanr 包拟合的模型，适合用 bayesplot 包来可视化后验分布和诊断采样。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#sec-thirty-rats",
    "href": "hierarchical-normal-models.html#sec-thirty-rats",
    "title": "35  分层正态模型",
    "section": "\n35.3 案例：rats 数据",
    "text": "35.3 案例：rats 数据\nrats 数据最早来自 Gelfand 等 (1990) ，记录 30 只小鼠每隔一周的重量，一共进行了 5 周。第一次记录是小鼠第 8 天的时候，第二次测量记录是第 15 天的时候，一直持续到第 36 天。下面在 R 环境中准备数据。\n\n# 总共 30 只老鼠\nN &lt;- 30\n# 总共进行 5 周\nT &lt;- 5\n# 小鼠重量\ny &lt;- structure(c(\n  151, 145, 147, 155, 135, 159, 141, 159, 177, 134,\n  160, 143, 154, 171, 163, 160, 142, 156, 157, 152, 154, 139, 146,\n  157, 132, 160, 169, 157, 137, 153, 199, 199, 214, 200, 188, 210,\n  189, 201, 236, 182, 208, 188, 200, 221, 216, 207, 187, 203, 212,\n  203, 205, 190, 191, 211, 185, 207, 216, 205, 180, 200, 246, 249,\n  263, 237, 230, 252, 231, 248, 285, 220, 261, 220, 244, 270, 242,\n  248, 234, 243, 259, 246, 253, 225, 229, 250, 237, 257, 261, 248,\n  219, 244, 283, 293, 312, 272, 280, 298, 275, 297, 350, 260, 313,\n  273, 289, 326, 281, 288, 280, 283, 307, 286, 298, 267, 272, 285,\n  286, 303, 295, 289, 258, 286, 320, 354, 328, 297, 323, 331, 305,\n  338, 376, 296, 352, 314, 325, 358, 312, 324, 316, 317, 336, 321,\n  334, 302, 302, 323, 331, 345, 333, 316, 291, 324\n), .Dim = c(30, 5))\n# 第几天\nx &lt;- c(8.0, 15.0, 22.0, 29.0, 36.0)\nxbar &lt;- 22.0\n\n重复测量的小鼠重量数据 rats 如下 表格 35.1 所示。\n\n\n\n表格 35.1: 小鼠重量数据（部分）\n\n\n\n\n\n第 8 天\n第 15 天\n第 22 天\n第 29 天\n第 36 天\n\n\n\n1\n151\n199\n246\n283\n320\n\n\n2\n145\n199\n249\n293\n354\n\n\n3\n147\n214\n263\n312\n328\n\n\n4\n155\n200\n237\n272\n297\n\n\n5\n135\n188\n230\n280\n323\n\n\n6\n159\n210\n252\n298\n331\n\n\n\n\n\n\n\n\n小鼠重量数据的分布和变化情况见下图，由图可以假定 30 只小鼠的重量服从正态分布，而30 只小鼠的重量呈现一种线性增长趋势。\n\n\n\n\n\n\n\n\n\n(a) 小鼠重量的分布\n\n\n\n\n\n\n\n\n\n(b) 小鼠重量的变化\n\n\n\n\n\n\n图 35.6: 30 只小鼠 5 次测量的数据",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#sec-rats-frequentist",
    "href": "hierarchical-normal-models.html#sec-rats-frequentist",
    "title": "35  分层正态模型",
    "section": "\n35.4 频率派方法",
    "text": "35.4 频率派方法\n\n35.4.1 nlme\nnlme 包适合长格式的数据，因此，先将小鼠数据整理成长格式。\n\nrats_data &lt;- data.frame(\n  weight = as.vector(y), \n  rats = rep(1:30, times = 5), \n  days = rep(c(8, 15, 22, 29, 36), each = 30)\n)\n\n将 30 只小鼠的重量变化及回归曲线画出来，发现各只小鼠的回归线的斜率几乎一样，截距略有不同。不同小鼠的出生重量是不同，前面 Stan 采用变截距变斜率的混合效应模型拟合数据。\n\nggplot(data = rats_data, aes(x = days, y = weight)) +\n  geom_point() +\n  geom_smooth(formula = \"y ~ x\", method = \"lm\", se = FALSE) +\n  theme_bw() +\n  facet_wrap(facets = ~rats, labeller = \"label_both\", ncol = 6) +\n  labs(x = \"第几天\", y = \"重量\")\n\n\n\n\n\n\n图 35.7: 小鼠重量变化曲线\n\n\n\n\n小鼠的重量随时间增长，不同小鼠的情况又会有所不同。作为一个参照，首先考虑变截距的随机效应模型。\n\\[\ny_{ij} = \\beta_0 + \\beta_1 * x_j + \\alpha_i + \\epsilon_{ij}, \\quad i = 1,2,\\ldots,30. \\quad j = 1,2,3,4,5\n\\]\n其中，\\(y_{ij}\\) 表示第 \\(i\\) 只小鼠在第 \\(j\\) 次测量的重量，一共 30 只小鼠，共测量了 5 次。固定效应部分是 \\(\\beta_0\\) 和 \\(\\beta_1\\) ，分别表示截距和斜率。随机效应部分是 \\(\\alpha_i\\) 和 \\(\\epsilon_{ij}\\) ，分别服从正态分布\\(\\alpha_i \\sim \\mathcal{N}(0, \\sigma^2_{\\alpha})\\) 和 \\(\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma^2_{\\epsilon})\\) 。\\(\\sigma^2_{\\alpha}\\) 和 \\(\\sigma^2_{\\epsilon}\\) 分别表示组间方差（group level）和组内方差（individual level）。\n\nlibrary(nlme)\nrats_lme0 &lt;- lme(data = rats_data, fixed = weight ~ days, random = ~ 1 | rats)\nsummary(rats_lme0)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: rats_data \n#&gt;        AIC     BIC    logLik\n#&gt;   1145.302 1157.29 -568.6508\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | rats\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    14.03351 8.203811\n#&gt; \n#&gt; Fixed effects:  weight ~ days \n#&gt;                 Value Std.Error  DF  t-value p-value\n#&gt; (Intercept) 106.56762 3.0379720 119 35.07854       0\n#&gt; days          6.18571 0.0676639 119 91.41824       0\n#&gt;  Correlation: \n#&gt;      (Intr)\n#&gt; days -0.49 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.7388198 -0.4770046  0.1261342  0.5634904  2.9981636 \n#&gt; \n#&gt; Number of Observations: 150\n#&gt; Number of Groups: 30\n\n\n当然，若考虑不同小鼠的生长速度不同（变化不是很大），可用变截距和变斜率的随机效应模型表示生长曲线模型，下面加载 nlme 包调用函数 lme() 拟合该模型。\n\nlibrary(nlme)\nrats_lme &lt;- lme(data = rats_data, fixed = weight ~ days, random = ~ days | rats)\nsummary(rats_lme)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: rats_data \n#&gt;        AIC      BIC    logLik\n#&gt;   1107.373 1125.357 -547.6867\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~days | rats\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev     Corr  \n#&gt; (Intercept) 10.7425835 (Intr)\n#&gt; days         0.5105447 -0.159\n#&gt; Residual     6.0146608       \n#&gt; \n#&gt; Fixed effects:  weight ~ days \n#&gt;                 Value Std.Error  DF  t-value p-value\n#&gt; (Intercept) 106.56762 2.2976183 119 46.38178       0\n#&gt; days          6.18571 0.1055912 119 58.58174       0\n#&gt;  Correlation: \n#&gt;      (Intr)\n#&gt; days -0.343\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.6370825 -0.5394956  0.1187658  0.4927200  2.6090652 \n#&gt; \n#&gt; Number of Observations: 150\n#&gt; Number of Groups: 30\n\n\n模型输出结果中，固定效应中的截距项 (Intercept) 对应 106.56762，斜率 days 对应 6.18571。Stan 模型中截距参数 alpha0 的后验估计是 106.332，斜率参数 beta_c 的后验估计是 6.188。对比 Stan 和 nlme 包的拟合结果，可以发现贝叶斯和频率方法的结果是非常接近的。截距参数 alpha0 可以看作小鼠的初始（出生）重量，斜率参数 beta_c 可以看作小鼠的生长率 growth rate。\n函数 lme() 的输出结果中，随机效应的随机截距标准差 10.7425835，对应 tau_alpha，表示每个小鼠的截距偏移量的波动。而随机斜率的标准差为 0.5105447，对应 tau_beta，相对随机截距标准差来说很小。残差标准差为 6.0146608，对应 tau_c，表示与小鼠无关的剩余量的波动，比如测量误差。总之，和 Stan 的结果有所不同，但相去不远。主要是前面的 Stan 模型没有考虑随机截距和随机斜率之间的相关性，这可以进一步调整 (Sorensen, Hohenstein, 和 Vasishth 2016) 。\n\n# 参数的置信区间\nintervals(rats_lme, level = 0.95)\n\n#&gt; Approximate 95% confidence intervals\n#&gt; \n#&gt;  Fixed effects:\n#&gt;                  lower       est.      upper\n#&gt; (Intercept) 102.018105 106.567619 111.117133\n#&gt; days          5.976633   6.185714   6.394795\n#&gt; \n#&gt;  Random Effects:\n#&gt;   Level: rats \n#&gt;                            lower       est.      upper\n#&gt; sd((Intercept))        7.5159648 10.7425835 15.3543961\n#&gt; sd(days)               0.3661761  0.5105447  0.7118322\n#&gt; cor((Intercept),days) -0.5659916 -0.1590236  0.3102623\n#&gt; \n#&gt;  Within-group standard error:\n#&gt;    lower     est.    upper \n#&gt; 5.197218 6.014661 6.960675\n\n\nStan 输出中，截距项 alpha、斜率项 beta 参数的标准差分别是 tau_alpha 和 tau_beta ，残差标准差参数 tau_c 的估计为 6.1。简单起见，没有考虑截距项和斜率项的相关性，即不考虑小鼠出生时的重量和生长率的相关性，一般来说，应该是有关系的。函数 lme() 的输出结果中给出了截距项和斜率项的相关性为 -0.343，随机截距和随机斜率的相关性为 -0.159。\n计算与 Stan 输出中的截距项 alpha_c 对应的量，结合函数 lme() 的输出，截距、斜率加和之后，如下\n\n106.56762 + 6.18571 * 22\n\n#&gt; [1] 242.6532\n\n\n值得注意，Stan 代码中对时间 days 做了中心化处理，即 \\(x_t - \\bar{x}\\)，目的是降低采样时参数 \\(\\alpha_i\\) 和 \\(\\beta_i\\) 之间的相关性，而在拟合函数 lme() 中没有做处理，因此，结果无需转化，而且更容易解释。\n\nfit_lm &lt;- lm(weight ~ days, data = rats_data)\nsummary(fit_lm)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = weight ~ days, data = rats_data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -38.253 -11.278   0.197   7.647  64.047 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 106.5676     3.2099   33.20   &lt;2e-16 ***\n#&gt; days          6.1857     0.1331   46.49   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 16.13 on 148 degrees of freedom\n#&gt; Multiple R-squared:  0.9359, Adjusted R-squared:  0.9355 \n#&gt; F-statistic:  2161 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n采用简单线性模型即可获得与 nlme 包非常接近的估计结果，主要是小鼠重量的分布比较正态，且随时间的变化非常线性。\n\n35.4.2 lavaan\nlavaan 包 (Rosseel 2012) 主要是用来拟合结构方程模型，而生长曲线模型可以放在该框架下。所以，也可以用 lavaan 包来拟合，并且，它提供的函数 growth() 可以直接拟合生长曲线模型。\n\nlibrary(lavaan)\n# 设置矩阵 y 的列名\ncolnames(y) &lt;- c(\"t1\",\"t2\",\"t3\",\"t4\",\"t5\")\nrats_growt_model &lt;- \" \n  # intercept and slope with fixed coefficients\n  intercept =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 + 1*t5\n  days =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 + 4*t5 \n\n  # if we fix the variances to be equal, the models are now identical.\n  t1 ~~ resvar*t1    \n  t2 ~~ resvar*t2\n  t3 ~~ resvar*t3\n  t4 ~~ resvar*t4\n  t5 ~~ resvar*t5\n\"\n\n其中，算子符号 =~ 定义潜变量，~~ 定义残差协方差，intercept 表示截距， days 表示斜率。假定 5 次测量的测量误差（组内方差）是相同的。拟合模型的代码如下：\n\nrats_growth_fit &lt;- growth(rats_growt_model, data = y)\n\n提供函数 summary() 获得模型输出，结果如下：\n\nsummary(rats_growth_fit, fit.measures = TRUE)\n\n#&gt; lavaan 0.6.17 ended normally after 87 iterations\n#&gt; \n#&gt;   Estimator                                         ML\n#&gt;   Optimization method                           NLMINB\n#&gt;   Number of model parameters                        10\n#&gt;   Number of equality constraints                     4\n#&gt; \n#&gt;   Number of observations                            30\n#&gt; \n#&gt; Model Test User Model:\n#&gt;                                                       \n#&gt;   Test statistic                               106.203\n#&gt;   Degrees of freedom                                14\n#&gt;   P-value (Chi-square)                           0.000\n#&gt; \n#&gt; Model Test Baseline Model:\n#&gt; \n#&gt;   Test statistic                               247.075\n#&gt;   Degrees of freedom                                10\n#&gt;   P-value                                        0.000\n#&gt; \n#&gt; User Model versus Baseline Model:\n#&gt; \n#&gt;   Comparative Fit Index (CFI)                    0.611\n#&gt;   Tucker-Lewis Index (TLI)                       0.722\n#&gt; \n#&gt; Loglikelihood and Information Criteria:\n#&gt; \n#&gt;   Loglikelihood user model (H0)               -548.029\n#&gt;   Loglikelihood unrestricted model (H1)       -494.927\n#&gt;                                                       \n#&gt;   Akaike (AIC)                                1108.057\n#&gt;   Bayesian (BIC)                              1116.465\n#&gt;   Sample-size adjusted Bayesian (SABIC)       1097.783\n#&gt; \n#&gt; Root Mean Square Error of Approximation:\n#&gt; \n#&gt;   RMSEA                                          0.469\n#&gt;   90 Percent confidence interval - lower         0.388\n#&gt;   90 Percent confidence interval - upper         0.554\n#&gt;   P-value H_0: RMSEA &lt;= 0.050                    0.000\n#&gt;   P-value H_0: RMSEA &gt;= 0.080                    1.000\n#&gt; \n#&gt; Standardized Root Mean Square Residual:\n#&gt; \n#&gt;   SRMR                                           0.151\n#&gt; \n#&gt; Parameter Estimates:\n#&gt; \n#&gt;   Standard errors                             Standard\n#&gt;   Information                                 Expected\n#&gt;   Information saturated (h1) model          Structured\n#&gt; \n#&gt; Latent Variables:\n#&gt;                    Estimate  Std.Err  z-value  P(&gt;|z|)\n#&gt;   intercept =~                                        \n#&gt;     t1                1.000                           \n#&gt;     t2                1.000                           \n#&gt;     t3                1.000                           \n#&gt;     t4                1.000                           \n#&gt;     t5                1.000                           \n#&gt;   days =~                                             \n#&gt;     t1                0.000                           \n#&gt;     t2                1.000                           \n#&gt;     t3                2.000                           \n#&gt;     t4                3.000                           \n#&gt;     t5                4.000                           \n#&gt; \n#&gt; Covariances:\n#&gt;                    Estimate  Std.Err  z-value  P(&gt;|z|)\n#&gt;   intercept ~~                                        \n#&gt;     days              8.444    8.521    0.991    0.322\n#&gt; \n#&gt; Intercepts:\n#&gt;                    Estimate  Std.Err  z-value  P(&gt;|z|)\n#&gt;     intercept       156.053    2.123   73.516    0.000\n#&gt;     days             43.300    0.727   59.582    0.000\n#&gt; \n#&gt; Variances:\n#&gt;                    Estimate  Std.Err  z-value  P(&gt;|z|)\n#&gt;    .t1      (rsvr)   36.176    5.393    6.708    0.000\n#&gt;    .t2      (rsvr)   36.176    5.393    6.708    0.000\n#&gt;    .t3      (rsvr)   36.176    5.393    6.708    0.000\n#&gt;    .t4      (rsvr)   36.176    5.393    6.708    0.000\n#&gt;    .t5      (rsvr)   36.176    5.393    6.708    0.000\n#&gt;     intrcpt         113.470   35.052    3.237    0.001\n#&gt;     days             12.226    4.126    2.963    0.003\n\n\n输出结果显示 lavaan 包的函数 growth() 采用极大似然估计方法。协方差部分 Covariances: 随机效应中斜率和截距的协方差。截距部分 Intercepts: 对应于混合效应模型的固定效应部分。方差部分 Variances: 对应于混合效应模型的随机效应部分，包括残差方差、斜率和截距的方差。不难看出，这和前面 nlme 包的输出结果差别很大。原因是 lavaan 包将测量的次序从 0 开始计，0 代表小鼠出生后的第 8 天。也就是说，lavaan 采用的是次序标记，而不是实际数据。将测量发生的时间（第几天）换算成次序（第几次），并从 0 开始计，则函数 lme() 的输出和函数 growth() 就一致了。\n\n# 重新组织数据\nrats_data2 &lt;- data.frame(\n  weight = as.vector(y), \n  rats = rep(1:30, times = 5), \n  days = rep(c(0, 1, 2, 3, 4), each = 30)\n)\n# ML 方法估计模型参数\nrats_lme2 &lt;- lme(data = rats_data2, fixed = weight ~ days, random = ~ days | rats, method = \"ML\")\nsummary(rats_lme2)\n\n#&gt; Linear mixed-effects model fit by maximum likelihood\n#&gt;   Data: rats_data2 \n#&gt;        AIC      BIC    logLik\n#&gt;   1108.057 1126.121 -548.0287\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~days | rats\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev    Corr  \n#&gt; (Intercept) 10.652385 (Intr)\n#&gt; days         3.496584 0.227 \n#&gt; Residual     6.014613       \n#&gt; \n#&gt; Fixed effects:  weight ~ days \n#&gt;                Value Std.Error  DF  t-value p-value\n#&gt; (Intercept) 156.0533 2.1370181 119 73.02387       0\n#&gt; days         43.3000 0.7316138 119 59.18423       0\n#&gt;  Correlation: \n#&gt;      (Intr)\n#&gt; days 0.026 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.6317200 -0.5421564  0.1154349  0.4948020  2.6188195 \n#&gt; \n#&gt; Number of Observations: 150\n#&gt; Number of Groups: 30\n\n\n可以看到函数 growth() 给出的截距和斜率的协方差估计为 8.444，函数 lme() 给出对应截距和斜率的标准差分别是 10.652390 和 3.496588，它们的相关系数为 0.227，则函数 lme() 给出的协方差估计为 10.652390*3.496588*0.227 ，即 8.455，协方差估计比较一致。同理，比较两个输出结果中的其它成分，函数 growth() 给出的残差方差估计为 36.176，则残差标准差估计为 6.0146，结合函数 lme() 给出的 Random effects: 中 Residual，结果完全一样。函数 growth() 给出的 Intercepts: 对应于函数 lme() 给出的固定效应部分，结果也是完全一样。\n针对模型拟合对象 rats_growth_fit ，除了函数 summary() 可以汇总结果，lavaan 包还提供 AIC() 、 BIC() 和 logLik() 等函数，分别可以提取 AIC、BIC 和对数似然值， AIC() 和 logLik() 结果与前面的函数 lme() 的输出是一样的，而 BIC() 不同。\n\n35.4.3 lme4\n当采用 lme4 包拟合数据的时候，发现输出结果与 nlme 包几乎相同。\n\nrats_lme4 &lt;- lme4::lmer(weight ~ days + (days | rats), data = rats_data)\nsummary(rats_lme4)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: weight ~ days + (days | rats)\n#&gt;    Data: rats_data\n#&gt; \n#&gt; REML criterion at convergence: 1095.4\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.6371 -0.5395  0.1188  0.4927  2.6091 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  rats     (Intercept) 115.4239 10.7435       \n#&gt;           days          0.2607  0.5106  -0.16\n#&gt;  Residual              36.1753  6.0146       \n#&gt; Number of obs: 150, groups:  rats, 30\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept) 106.5676     2.2978   46.38\n#&gt; days          6.1857     0.1056   58.58\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;      (Intr)\n#&gt; days -0.343\n\n\n\n35.4.4 glmmTMB\nglmmTMB 包基于 Template Model Builder (TMB) ，拟合广义线性混合效应模型，公式语法与 lme4 包一致。\n\nrats_glmmtmb &lt;- glmmTMB::glmmTMB(weight ~ days + (days | rats), REML = TRUE, data = rats_data)\nsummary(rats_glmmtmb)\n\n#&gt;  Family: gaussian  ( identity )\n#&gt; Formula:          weight ~ days + (days | rats)\n#&gt; Data: rats_data\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;   1107.4   1125.4   -547.7   1095.4      146 \n#&gt; \n#&gt; Random effects:\n#&gt; \n#&gt; Conditional model:\n#&gt;  Groups   Name        Variance Std.Dev. Corr  \n#&gt;  rats     (Intercept) 115.4195 10.7433        \n#&gt;           days          0.2607  0.5106  -0.16 \n#&gt;  Residual              36.1756  6.0146        \n#&gt; Number of obs: 150, groups:  rats, 30\n#&gt; \n#&gt; Dispersion estimate for gaussian family (sigma^2): 36.2 \n#&gt; \n#&gt; Conditional model:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) 106.5676     2.2977   46.38   &lt;2e-16 ***\n#&gt; days          6.1857     0.1056   58.58   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n结果与 nlme 包完全一样。\n\n35.4.5 MASS\nMASS 包的结果与前面完全一致。\n\nrats_mass &lt;- MASS::glmmPQL(\n  fixed = weight ~ days, random = ~ days | rats, \n  data = rats_data, family = gaussian(), verbose = FALSE\n)\nsummary(rats_mass)\n\n#&gt; Linear mixed-effects model fit by maximum likelihood\n#&gt;   Data: rats_data \n#&gt;   AIC BIC logLik\n#&gt;    NA  NA     NA\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~days | rats\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev     Corr  \n#&gt; (Intercept) 10.4945051 (Intr)\n#&gt; days         0.4994795 -0.15 \n#&gt; Residual     6.0146664       \n#&gt; \n#&gt; Variance function:\n#&gt;  Structure: fixed weights\n#&gt;  Formula: ~invwt \n#&gt; Fixed effects:  weight ~ days \n#&gt;                 Value Std.Error  DF  t-value p-value\n#&gt; (Intercept) 106.56762 2.2742917 119 46.85750       0\n#&gt; days          6.18571 0.1045112 119 59.18709       0\n#&gt;  Correlation: \n#&gt;      (Intr)\n#&gt; days -0.343\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.6316763 -0.5421361  0.1154445  0.4947986  2.6187979 \n#&gt; \n#&gt; Number of Observations: 150\n#&gt; Number of Groups: 30\n\n\n\n35.4.6 spaMM\nspaMM 包的结果与前面完全一致。\n\nrats_spamm &lt;- spaMM::fitme(weight ~ days + (days | rats), data = rats_data)\nsummary(rats_spamm)\n\n#&gt; formula: weight ~ days + (days | rats)\n#&gt; ML: Estimation of ranCoefs and phi by ML.\n#&gt;     Estimation of fixed effects by ML.\n#&gt; Estimation of phi by 'outer' ML, maximizing logL.\n#&gt; family: gaussian( link = identity ) \n#&gt;  ------------ Fixed effects (beta) ------------\n#&gt;             Estimate Cond. SE t-value\n#&gt; (Intercept)  106.568   2.2591   47.17\n#&gt; days           6.186   0.1038   59.58\n#&gt;  --------------- Random effects ---------------\n#&gt; Family: gaussian( link = identity ) \n#&gt;          --- Random-coefficients Cov matrices:\n#&gt;  Group        Term   Var.   Corr.\n#&gt;   rats (Intercept)  110.1        \n#&gt;   rats        days 0.2495 -0.1507\n#&gt; # of obs: 150; # of groups: rats, 30 \n#&gt;  -------------- Residual variance  ------------\n#&gt; phi estimate was 36.1755 \n#&gt;  ------------- Likelihood values  -------------\n#&gt;                         logLik\n#&gt; logL       (p_v(h)): -548.0287\n\n\n --------------- Random effects ---------------\nFamily: gaussian( link = identity ) \n         --- Random-coefficients Cov matrices:\n Group        Term   Var.   Corr.\n  rats (Intercept)  110.1        \n  rats        days 0.2495 -0.1507\n# of obs: 150; # of groups: rats, 30 \n随机效应的截距方差 110.1，斜率方差 0.2495，则标准差分别是 10.49 和 0.499，相关性为 -0.1507。\n -------------- Residual variance  ------------\nphi estimate was 36.1755 \n残差方差为 36.1755，则标准差为 6.0146。\n\n35.4.7 hglm\nhglm 包 (Rönnegård, Shen, 和 Alam 2010) 可以拟合分层广义线性模型，线性混合效应模型和广义线性混合效应模型，随机效应和响应变量服从的分布可以很广泛，使用语法与 lme4 包一样。\n\nrats_hglm &lt;- hglm::hglm2(weight ~ days + (days | rats), data = rats_data)\nsummary(rats_hglm)\n\n#&gt; Call: \n#&gt; hglm2.formula(meanmodel = weight ~ days + (days | rats), data = rats_data)\n#&gt; \n#&gt; ----------\n#&gt; MEAN MODEL\n#&gt; ----------\n#&gt; \n#&gt; Summary of the fixed effects estimates:\n#&gt; \n#&gt;             Estimate Std. Error t-value Pr(&gt;|t|)    \n#&gt; (Intercept) 106.5676     2.1787   48.91   &lt;2e-16 ***\n#&gt; days          6.1857     0.1029   60.13   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; Note: P-values are based on 103 degrees of freedom\n#&gt; \n#&gt; Summary of the random effects estimates:\n#&gt; \n#&gt;                     Estimate Std. Error\n#&gt; (Intercept)| rats:1  -0.1705     5.3422\n#&gt; (Intercept)| rats:2  -9.8655     5.3422\n#&gt; (Intercept)| rats:3   2.7201     5.3422\n#&gt; ...\n#&gt; NOTE: to show all the random effects, use print(summary(hglm.object), print.ranef = TRUE).\n#&gt; \n#&gt; Summary of the random effects estimates:\n#&gt; \n#&gt;              Estimate Std. Error\n#&gt; days| rats:1  -0.1213      0.229\n#&gt; days| rats:2   0.7260      0.229\n#&gt; days| rats:3   0.3280      0.229\n#&gt; ...\n#&gt; NOTE: to show all the random effects, use print(summary(hglm.object), print.ranef = TRUE).\n#&gt; \n#&gt; ----------------\n#&gt; DISPERSION MODEL\n#&gt; ----------------\n#&gt; \n#&gt; NOTE: h-likelihood estimates through EQL can be biased.\n#&gt; \n#&gt; Dispersion parameter for the mean model:\n#&gt; [1] 37.09572\n#&gt; \n#&gt; Model estimates for the dispersion term:\n#&gt; \n#&gt; Link = log \n#&gt; \n#&gt; Effects:\n#&gt;   Estimate Std. Error \n#&gt;     3.6135     0.1391 \n#&gt; \n#&gt; Dispersion = 1 is used in Gamma model on deviances to calculate the standard error(s).\n#&gt; \n#&gt; Dispersion parameter for the random effects:\n#&gt; [1] 103.4501   0.2407\n#&gt; \n#&gt; Dispersion model for the random effects:\n#&gt; \n#&gt; Link = log\n#&gt; \n#&gt; Effects:\n#&gt; .|Random1 \n#&gt;   Estimate Std. Error \n#&gt;     4.6391     0.3069 \n#&gt; \n#&gt; .|Random2 \n#&gt;   Estimate Std. Error \n#&gt;    -1.4241     0.2920 \n#&gt; \n#&gt; Dispersion = 1 is used in Gamma model on deviances to calculate the standard error(s).\n#&gt; \n#&gt; EQL estimation converged in 5 iterations.\n\n\n固定效应的截距和斜率都是和 nlme 包的输出结果一致。值得注意，随机效应和模型残差都是以发散参数（Dispersion parameter）来表示的，模型残差方差为 37.09572，则标准差为 6.0906，随机效应的随机截距和随机斜率的方差分别为 103.4501 和 0.2407，则标准差分别为 10.1710 和 0.4906，这与 nlme 包的结果也是一致的。\n\n35.4.8 mgcv\n先考虑一个变截距的混合效应模型\n\\[\ny_{ij} = \\beta_0 + \\beta_1 * x_j + \\alpha_i + \\epsilon_{ij}, \\quad i = 1,2,\\ldots,30. \\quad j = 1,2,3,4,5\n\\]\n假设随机效应服从独立同正态分布，等价于在似然函数中添加一个岭惩罚。广义可加模型在一定形式下和上述混合效应模型存在等价关系，在广义可加模型中，可以样条表示随机效应。mgcv 包拟合代码如下。\n\nlibrary(mgcv)\nrats_data$rats &lt;- as.factor(rats_data$rats)\nrats_gam &lt;- gam(weight ~ days + s(rats, bs = \"re\"), data = rats_data)\n\n其中，参数取值 bs = \"re\" 指定样条类型，re 是 Random effects 的简写。\n\nsummary(rats_gam)\n\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; weight ~ days + s(rats, bs = \"re\")\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 106.56762    3.03797   35.08   &lt;2e-16 ***\n#&gt; days          6.18571    0.06766   91.42   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;           edf Ref.df     F p-value    \n#&gt; s(rats) 27.14     29 14.63  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.983   Deviance explained = 98.6%\n#&gt; GCV = 83.533  Scale est. = 67.303    n = 150\n\n\n其中，残差的方差 Scale est. = 67.303 ，则标准差为 \\(\\sigma_{\\epsilon} = 8.2038\\) 。随机效应的标准差如下\n\ngam.vcomp(rats_gam, rescale = TRUE)\n\n#&gt;  s(rats) \n#&gt; 14.03351\n\n\nrescale = TRUE 表示恢复至原数据的尺度，标准差 \\(\\sigma_{\\alpha} = 14.033\\)。可以看到，固定效应和随机效应的估计结果与 nlme 包等完全一致。若考虑变截距和变斜率的混合效应模型，拟合代码如下：\n\nrats_gam1 &lt;- gam(\n  weight ~ days + s(rats, bs = \"re\") + s(rats, by = days, bs = \"re\"),\n  data = rats_data, method = \"REML\"\n)\nsummary(rats_gam1)\n\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; weight ~ days + s(rats, bs = \"re\") + s(rats, by = days, bs = \"re\")\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 106.5676     2.2365   47.65   &lt;2e-16 ***\n#&gt; days          6.1857     0.1028   60.18   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;                edf Ref.df     F p-value    \n#&gt; s(rats)      21.80     29 183.9  &lt;2e-16 ***\n#&gt; s(rats):days 23.47     29 201.8  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.991   Deviance explained = 99.4%\n#&gt; -REML = 547.89  Scale est. = 36.834    n = 150\n\n\n输出结果中，固定效应部分的结果和 nlme 包完全一样。\n\ngam.vcomp(rats_gam1, rescale = TRUE)\n\n#&gt; \n#&gt; Standard deviations and 0.95 confidence intervals:\n#&gt; \n#&gt;                 std.dev     lower      upper\n#&gt; s(rats)      10.3107538 7.2978205 14.5675882\n#&gt; s(rats):days  0.4916736 0.3571229  0.6769181\n#&gt; scale         6.0691017 5.2454835  7.0220401\n#&gt; \n#&gt; Rank: 3/3\n\n\n输出结果中，依次是随机效应的截距、斜率和残差的标准差（标准偏差），和 nlme 包给出的结果非常接近。\nmgcv 包还提供函数 gamm()，它将混合效应和固定效应分开，在拟合 LMM 模型时，它类似 nlme 包的函数 lme()。返回一个含有 lme 和 gam 两个元素的列表，前者包含随机效应的估计，后者是固定效应的估计，固定效应中可以添加样条（或样条表示的简单随机效益，比如本节前面提及的模型）。实际上，函数 gamm() 分别调用 nlme 包和 MASS 包来拟合 LMM 模型和 GLMM 模型。\n\nrats_gamm &lt;- gamm(weight ~ days, random = list(rats = ~days), method = \"REML\", data = rats_data)\n# LME\nsummary(rats_gamm$lme)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: strip.offset(mf) \n#&gt;        AIC      BIC    logLik\n#&gt;   1107.373 1125.357 -547.6867\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~days | rats\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev     Corr  \n#&gt; (Intercept) 10.7433332 (Intr)\n#&gt; days         0.5105577 -0.159\n#&gt; Residual     6.0146119       \n#&gt; \n#&gt; Fixed effects:  y ~ X - 1 \n#&gt;                  Value Std.Error  DF  t-value p-value\n#&gt; X(Intercept) 106.56762 2.2977301 119 46.37952       0\n#&gt; Xdays          6.18571 0.1055931 119 58.58069       0\n#&gt;  Correlation: \n#&gt;       X(Int)\n#&gt; Xdays -0.343\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.6371079 -0.5394997  0.1187534  0.4927191  2.6091109 \n#&gt; \n#&gt; Number of Observations: 150\n#&gt; Number of Groups: 30\n\n# GAM\nsummary(rats_gamm$gam)\n\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; weight ~ days\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 106.5676     2.2977   46.38   &lt;2e-16 ***\n#&gt; days          6.1857     0.1056   58.58   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; \n#&gt; R-sq.(adj) =  0.935   \n#&gt;   Scale est. = 36.176    n = 150",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#sec-rats-bayesianism",
    "href": "hierarchical-normal-models.html#sec-rats-bayesianism",
    "title": "35  分层正态模型",
    "section": "\n35.5 贝叶斯方法",
    "text": "35.5 贝叶斯方法\n\n35.5.1 rstan\n初始化模型参数，设置采样算法的参数。\n\n# 迭代链\nchains &lt;- 4\n# 迭代次数\niter &lt;- 1000\n# 初始值\ninit &lt;- rep(list(list(\n  alpha = rep(250, 30), beta = rep(6, 30),\n  alpha_c = 150, beta_c = 10,\n  tausq_c = 1, tausq_alpha = 1,\n  tausq_beta = 1\n)), chains)\n\n接下来，基于重复测量数据，建立线性生长曲线模型：\n\\[\n\\begin{aligned}\n\\alpha_c &\\sim \\mathcal{N}(0,100) \\quad \\beta_c  \\sim \\mathcal{N}(0,100) \\\\\n\\tau^2_{\\alpha} &\\sim \\mathrm{inv\\_gamma}(0.001, 0.001) \\\\\n\\tau^2_{\\beta}  &\\sim \\mathrm{inv\\_gamma}(0.001, 0.001) \\\\\n\\tau^2_c &\\sim \\mathrm{inv\\_gamma}(0.001, 0.001) \\\\\n\\alpha_n &\\sim \\mathcal{N}(\\alpha_c, \\tau_{\\alpha})  \\quad\n\\beta_n  \\sim \\mathcal{N}(\\beta_c, \\tau_{\\beta}) \\\\\ny_{nt} &\\sim \\mathcal{N}(\\alpha_n + \\beta_n * (x_t - \\bar{x}), \\tau_c) \\\\\n& n = 1,2,\\ldots,N \\quad t = 1,2,\\ldots,T\n\\end{aligned}\n\\]\n其中， \\(\\alpha_c,\\beta_c,\\tau_c,\\tau_{\\alpha},\\tau_{\\beta}\\) 为无信息先验，\\(\\bar{x} = 22\\) 表示第 22 天，\\(N = 30\\) 和 \\(T = 5\\) 分别表示实验中的小鼠数量和测量次数，下面采用 Stan 编码、编译、采样和拟合模型。\n\nrats_fit &lt;- stan(\n  model_name = \"rats\",\n  model_code = \"\n  data {\n    int&lt;lower=0&gt; N;\n    int&lt;lower=0&gt; T;\n    vector[T] x;\n    matrix[N,T] y;\n    real xbar;\n  }\n  parameters {\n    vector[N] alpha;\n    vector[N] beta;\n\n    real alpha_c;\n    real beta_c;          // beta.c in original bugs model\n\n    real&lt;lower=0&gt; tausq_c;\n    real&lt;lower=0&gt; tausq_alpha;\n    real&lt;lower=0&gt; tausq_beta;\n  }\n  transformed parameters {\n    real&lt;lower=0&gt; tau_c;       // sigma in original bugs model\n    real&lt;lower=0&gt; tau_alpha;\n    real&lt;lower=0&gt; tau_beta;\n\n    tau_c = sqrt(tausq_c);\n    tau_alpha = sqrt(tausq_alpha);\n    tau_beta = sqrt(tausq_beta);\n  }\n  model {\n    alpha_c ~ normal(0, 100);\n    beta_c ~ normal(0, 100);\n    tausq_c ~ inv_gamma(0.001, 0.001);\n    tausq_alpha ~ inv_gamma(0.001, 0.001);\n    tausq_beta ~ inv_gamma(0.001, 0.001);\n    alpha ~ normal(alpha_c, tau_alpha); // vectorized\n    beta ~ normal(beta_c, tau_beta);  // vectorized\n    for (n in 1:N)\n      for (t in 1:T)\n        y[n,t] ~ normal(alpha[n] + beta[n] * (x[t] - xbar), tau_c);\n  }\n  generated quantities {\n    real alpha0;\n    alpha0 = alpha_c - xbar * beta_c;\n  }\n  \",\n  data = list(N = N, T = T, y = y, x = x, xbar = xbar),\n  chains = chains, init = init, iter = iter,   \n  verbose = FALSE, refresh = 0, seed = 20190425\n)\n\n模型输出结果如下：\n\nprint(rats_fit, pars = c(\"alpha\", \"beta\"), include = FALSE, digits = 1)\n\n#&gt; Inference for Stan model: rats.\n#&gt; 4 chains, each with iter=1000; warmup=500; thin=1; \n#&gt; post-warmup draws per chain=500, total post-warmup draws=2000.\n#&gt; \n#&gt;               mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat\n#&gt; alpha_c      242.5     0.1  2.7  237.1  240.6  242.5  244.3  247.7  1728    1\n#&gt; beta_c         6.2     0.0  0.1    6.0    6.1    6.2    6.3    6.4  2205    1\n#&gt; tausq_c       37.0     0.2  5.8   27.6   32.9   36.4   40.6   50.0   947    1\n#&gt; tausq_alpha  218.0     1.6 64.1  125.3  172.0  207.8  253.0  372.8  1703    1\n#&gt; tausq_beta     0.3     0.0  0.1    0.1    0.2    0.3    0.3    0.5  1481    1\n#&gt; tau_c          6.1     0.0  0.5    5.3    5.7    6.0    6.4    7.1   938    1\n#&gt; tau_alpha     14.6     0.0  2.1   11.2   13.1   14.4   15.9   19.3  1826    1\n#&gt; tau_beta       0.5     0.0  0.1    0.4    0.5    0.5    0.6    0.7  1429    1\n#&gt; alpha0       106.3     0.1  3.6   99.5  103.9  106.4  108.8  113.2  1965    1\n#&gt; lp__        -438.0     0.3  7.0 -452.8 -442.6 -437.4 -433.2 -425.4   558    1\n#&gt; \n#&gt; Samples were drawn using NUTS(diag_e) at Tue Jan 23 07:41:44 2024.\n#&gt; For each parameter, n_eff is a crude measure of effective sample size,\n#&gt; and Rhat is the potential scale reduction factor on split chains (at \n#&gt; convergence, Rhat=1).\n\n\nalpha_c 表示小鼠 5 次测量的平均重量，beta_c 表示小鼠体重的增长率，\\(\\alpha_i,\\beta_i\\) 分别表示第 \\(i\\) 只小鼠在第 22 天（第 3 次测量或 \\(x_t = \\bar{x}\\) ）的重量和增长率（每日增加的重量）。\n对于分量众多的参数向量，比较适合用岭线图展示后验分布，下面调用 bayesplot 包绘制参数向量 \\(\\boldsymbol{\\alpha},\\boldsymbol{\\beta}\\) 的后验分布。\n\n# plot(rats_fit, pars = \"alpha\", show_density = TRUE, ci_level = 0.8, outer_level = 0.95)\nbayesplot::mcmc_areas_ridges(rats_fit, pars = paste0(\"alpha\", \"[\", 1:30, \"]\")) +\n  scale_y_discrete(labels = scales::parse_format()) \n\n\n\n\n\n\n图 35.8: 参数 \\(\\boldsymbol{\\alpha}\\) 的后验分布\n\n\n\n\n参数向量 \\(\\boldsymbol{\\alpha}\\) 的后验估计可以看作 \\(x_t = \\bar{x}\\) 时小鼠的重量，上图即为各个小鼠重量的后验分布。\n\n# plot(rats_fit, pars = \"beta\", ci_level = 0.8, outer_level = 0.95)\nbayesplot::mcmc_areas_ridges(rats_fit, pars = paste0(\"beta\", \"[\", 1:30, \"]\")) +\n  scale_y_discrete(labels = scales::parse_format()) \n\n\n\n\n\n\n图 35.9: 参数 \\(\\boldsymbol{\\beta}\\) 的后验分布\n\n\n\n\n参数向量 \\(\\boldsymbol{\\beta}\\) 的后验估计可以看作是小鼠的重量的增长率，上图即为各个小鼠重量的增长率的后验分布。\n\n35.5.2 cmdstanr\n从 rstan 包转 cmdstanr 包是非常容易的，只要语法兼容，模型代码可以原封不动。\n\nlibrary(cmdstanr)\nmod_rats &lt;- cmdstan_model(\n  stan_file = \"code/rats.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\nfit_rats &lt;- mod_rats$sample(\n  data = list(N = N, T = T, y = y, x = x, xbar = xbar), # 数据\n  chains = 2,            # 总链条数\n  parallel_chains = 2,   # 并行数目\n  iter_warmup = 1000,    # 每条链预处理的迭代次数\n  iter_sampling = 1000,  # 每条链采样的迭代次数\n  threads_per_chain = 2, # 每条链设置 2 个线程\n  seed = 20232023,       # 随机数种子\n  show_messages = FALSE, # 不显示消息\n  adapt_delta = 0.9,     # 接受率\n  refresh = 0 # 不显示采样迭代的进度\n)\n\n模型输出\n\n# 显示除了参数 alpha 和 beta 以外的结果\nvars &lt;- setdiff(fit_rats$metadata()$stan_variables, c(\"alpha\", \"beta\"))\nfit_rats$summary(variables = vars)\n\n#&gt; # A tibble: 10 × 10\n#&gt;    variable       mean   median      sd     mad       q5      q95  rhat ess_bulk\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 lp__       -438.    -438.     6.87    6.83   -450.    -427.    1.01      586.\n#&gt;  2 alpha_c     243.     242.     2.79    2.70    238.     247.    1.00     3528.\n#&gt;  3 beta_c        6.18     6.18   0.106   0.107     6.01     6.36  1.00     3494.\n#&gt;  4 tausq_c      37.4     36.8    5.57    5.49     28.9     47.1   1.00     1720.\n#&gt;  5 tausq_alp…  217.     208.    63.5    57.7     134.     335.    1.00     3104.\n#&gt;  6 tausq_beta    0.275    0.259  0.0975  0.0884    0.148    0.457 0.999    2070.\n#&gt;  7 tau_c         6.10     6.07   0.451   0.453     5.38     6.86  1.00     1720.\n#&gt;  8 tau_alpha    14.6     14.4    2.06    2.00     11.6     18.3   1.00     3104.\n#&gt;  9 tau_beta      0.517    0.509  0.0896  0.0882    0.385    0.676 0.999    2070.\n#&gt; 10 alpha0      106.     107.     3.63    3.68    100.     112.    0.999    3565.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n诊断信息\n\nfit_rats$diagnostic_summary()\n\n#&gt; $num_divergent\n#&gt; [1] 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 0.8995806 0.8828313\n\n\n\n35.5.3 brms\nbrms 包是基于 rstan 包的，基于 Stan 语言做贝叶斯推断，提供与 lme4 包一致的公式语法，且扩展了模型种类。\n\nrats_brms &lt;- brms::brm(weight ~ days + (days | rats), data = rats_data)\nsummary(rats_brms)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: weight ~ days + (days | rats) \n   Data: rats_data (Number of observations: 150) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~rats (Number of levels: 30) \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)          11.27      2.23     7.36    16.08 1.00     2172     2939\nsd(days)                0.54      0.09     0.37     0.74 1.00     1380     2356\ncor(Intercept,days)    -0.11      0.24    -0.53     0.39 1.00      920     1541\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   106.47      2.47   101.61   111.23 1.00     2173     2768\ndays          6.18      0.11     5.96     6.41 1.00     1617     2177\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     6.15      0.47     5.30     7.14 1.00     1832     3151\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n35.5.4 rstanarm\nrstanarm 包与 brms 包类似，区别是前者预编译了 Stan 模型，后者根据输入数据和模型编译即时编译，此外，后者支持的模型范围更加广泛。\n\nlibrary(rstanarm)\nrats_rstanarm &lt;- stan_lmer(formula = weight ~ days + (days | rats), data = rats_data)\nsummary(rats_rstanarm)\n\nModel Info:\n function:     stan_lmer\n family:       gaussian [identity]\n formula:      weight ~ days + (days | rats)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 150\n groups:       rats (30)\n\nEstimates:\n                                      mean    sd      10%     50%     90%  \n(Intercept)                         106.575   2.236 103.789 106.559 109.415\ndays                                  6.187   0.111   6.048   6.185   6.329\nsigma                                 6.219   0.497   5.626   6.183   6.862\nSigma[rats:(Intercept),(Intercept)] 103.927  42.705  57.329  98.128 159.086\nSigma[rats:days,(Intercept)]         -0.545   1.492  -2.361  -0.402   1.162\nSigma[rats:days,days]                 0.304   0.112   0.181   0.285   0.445\n\nMCMC diagnostics\n                                    mcse  Rhat  n_eff\n(Intercept)                         0.043 1.000 2753 \ndays                                0.003 1.005 1694 \nsigma                               0.015 1.001 1172 \nSigma[rats:(Intercept),(Intercept)] 1.140 1.000 1403 \nSigma[rats:days,(Intercept)]        0.054 1.006  772 \nSigma[rats:days,days]               0.003 1.000 1456 \n\nFor each parameter, mcse is Monte Carlo standard error, \nn_eff is a crude measure of effective sample size, \nand Rhat is the potential scale reduction factor \non split chains (at convergence Rhat=1).\n固定效应的部分，截距和斜率如下：\nEstimates:\n                                      mean    sd      10%     50%     90%  \n(Intercept)                         106.575   2.236 103.789 106.559 109.415\ndays                                  6.187   0.111   6.048   6.185   6.329\n模型残差的标准差 sigma、随机效应 Sigma 的随机截距的方差 103.927 、随机斜率的方差 0.304 及其协方差 -0.545。\nsigma                                 6.219   0.497   5.626   6.183   6.862\nSigma[rats:(Intercept),(Intercept)] 103.927  42.705  57.329  98.128 159.086\nSigma[rats:days,(Intercept)]         -0.545   1.492  -2.361  -0.402   1.162\nSigma[rats:days,days]                 0.304   0.112   0.181   0.285   0.445\nrstanarm 和 brms 包的结果基本一致的。\n\n35.5.5 blme\nblme 包 (Chung 等 2013) 基于 lme4 包 (Bates 等 2015) 拟合贝叶斯线性混合效应模型。参考前面 rstan 小节中关于模型参数的先验设置，下面将残差方差的先验设置为逆伽马分布，随机效应的协方差设置为扁平分布。发现拟合结果和 nlme 和 lme4 包的几乎一样。\n\nrats_blme &lt;- blme::blmer(\n  weight ~ days + (days | rats), data = rats_data,\n  resid.prior = invgamma, cov.prior = NULL\n)\nsummary(rats_blme)\n\n#&gt; Resid prior: invgamma(shape = 0, scale = 0, posterior.scale = var)\n#&gt; Prior dev  : 7.1328\n#&gt; \n#&gt; Linear mixed model fit by REML ['blmerMod']\n#&gt; Formula: weight ~ days + (days | rats)\n#&gt;    Data: rats_data\n#&gt; \n#&gt; REML criterion at convergence: 1095.4\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.6697 -0.5440  0.1202  0.4968  2.6317 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  rats     (Intercept) 116.3517 10.7866       \n#&gt;           days          0.2623  0.5121  -0.16\n#&gt;  Residual              35.3891  5.9489       \n#&gt; Number of obs: 150, groups:  rats, 30\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept) 106.5676     2.2977   46.38\n#&gt; days          6.1857     0.1056   58.58\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;      (Intr)\n#&gt; days -0.343\n\n\n与 lme4 包的函数 lmer() 所不同的是参数 resid.prior 、fixef.prior 和 cov.prior ，它们设置参数的先验分布，其它参数的含义同 lme4 包。resid.prior = invgamma 表示残差方差参数使用逆伽马分布，cov.prior = NULL 表示随机效应的协方差参数使用扁平先验 flat priors。\n\n35.5.6 rjags\nrjags (Plummer 2021) 是 JAGS 软件的 R 语言接口，可以拟合分层正态模型，再借助 coda 包 (Plummer 等 2006) 可以分析 JAGS 返回的各项数据。\nJAGS 代码和 Stan 代码有不少相似之处，最大的共同点在于以直观的统计模型的符号表示编码模型，仿照 Stan 代码， JAGS 编码的模型（BUGS 代码）如下：\nmodel {\n  alpha_c ~ dnorm(0, 1.0E-4);\n  beta_c ~ dnorm(0, 1.0E-4);\n  \n  tau_c ~ dgamma(0.001, 0.001);\n  tau_alpha ~ dgamma(0.001, 0.001);\n  tau_beta ~ dgamma(0.001, 0.001);\n\n  sigma_c &lt;- 1.0 / sqrt(tau_c);\n  sigma_alpha &lt;- 1.0 / sqrt(tau_alpha);\n  sigma_beta &lt;- 1.0 / sqrt(tau_beta);\n  \n  for (n in 1:N){\n      alpha[n] ~ dnorm(alpha_c, tau_alpha); \n      beta[n] ~ dnorm(beta_c, tau_beta);\n    for (t in 1:T) {\n      y[n,t] ~ dnorm(alpha[n] + beta[n] * (x[t] - xbar), tau_c);\n    }\n  }\n}\n转化主要集中在模型块，注意二者概率分布的名称以及参数含义对应关系，JAGS 使用 precision 而不是 standard deviation or variance，比如正态分布中的方差（标准偏差）被替换为其倒数。JAGS 可以省略类型声明（初始化模型时会补上），最后，JAGS 不支持 Stan 中的向量化操作，这种新特性是独特的。\n\nlibrary(rjags)\n# 初始值\nrats_inits &lt;- list(\n  list(\".RNG.name\" = \"base::Marsaglia-Multicarry\", \n       \".RNG.seed\" = 20222022, \n       \"alpha_c\" = 100, \"beta_c\" = 6, \"tau_c\" = 5, \"tau_alpha\" = 10, \"tau_beta\" = 0.5),\n  list(\".RNG.name\" = \"base::Marsaglia-Multicarry\", \n       \".RNG.seed\" = 20232023, \n       \"alpha_c\" = 200, \"beta_c\" = 10, \"tau_c\" = 15, \"tau_alpha\" = 15, \"tau_beta\" = 1)\n)\n# 模型\nrats_model &lt;- jags.model(\n  file = \"code/rats.bugs\",\n  data = list(x = x, y = y, N = 30, T = 5, xbar = 22.0),\n  inits = rats_inits, \n  n.chains = 2, quiet = TRUE\n)\n# burn-in\nupdate(rats_model, n.iter = 2000)\n# 抽样\nrats_samples &lt;- coda.samples(rats_model,\n  variable.names = c(\"alpha_c\", \"beta_c\", \"sigma_alpha\", \"sigma_beta\", \"sigma_c\"),\n  n.iter = 4000, thin = 1\n)\n# 参数的后验估计\nsummary(rats_samples)\n\n#&gt; \n#&gt; Iterations = 2001:6000\n#&gt; Thinning interval = 1 \n#&gt; Number of chains = 2 \n#&gt; Sample size per chain = 4000 \n#&gt; \n#&gt; 1. Empirical mean and standard deviation for each variable,\n#&gt;    plus standard error of the mean:\n#&gt; \n#&gt;                 Mean      SD Naive SE Time-series SE\n#&gt; alpha_c     242.4752 2.72749 0.030494       0.031571\n#&gt; beta_c        6.1878 0.10798 0.001207       0.001481\n#&gt; sigma_alpha  14.6233 2.05688 0.022997       0.025070\n#&gt; sigma_beta    0.5176 0.09266 0.001036       0.001741\n#&gt; sigma_c       6.0731 0.46425 0.005191       0.007984\n#&gt; \n#&gt; 2. Quantiles for each variable:\n#&gt; \n#&gt;                 2.5%      25%      50%      75%    97.5%\n#&gt; alpha_c     237.0333 240.6832 242.5024 244.2965 247.7816\n#&gt; beta_c        5.9785   6.1150   6.1867   6.2593   6.4035\n#&gt; sigma_alpha  11.1840  13.1802  14.4152  15.8340  19.2429\n#&gt; sigma_beta    0.3571   0.4538   0.5098   0.5734   0.7187\n#&gt; sigma_c       5.2384   5.7479   6.0455   6.3803   7.0413\n\n\n输出结果与 rstan 十分一致，且采样速度极快。类似地，alpha0 = alpha_c - xbar * beta_c 可得 alpha0 = 242.4752 - 22 * 6.1878 = 106.3436。\n\n35.5.7 MCMCglmm\n同前，先考虑变截距的混合效应模型，MCMCglmm 包 (Hadfield 2010) 给出的拟合结果与 nlme 包很接近。\n\n## 变截距模型\nprior1 &lt;- list(\n  R = list(V = 1, nu = 0.002),\n  G = list(G1 = list(V = 1, nu = 0.002))\n)\nset.seed(20232023)\nrats_mcmc1 &lt;- MCMCglmm::MCMCglmm(\n  weight ~ days, random = ~ rats,\n  data = rats_data, verbose = FALSE, prior = prior1\n)\nsummary(rats_mcmc1)\n\n#&gt; \n#&gt;  Iterations = 3001:12991\n#&gt;  Thinning interval  = 10\n#&gt;  Sample size  = 1000 \n#&gt; \n#&gt;  DIC: 1088.71 \n#&gt; \n#&gt;  G-structure:  ~rats\n#&gt; \n#&gt;      post.mean l-95% CI u-95% CI eff.samp\n#&gt; rats       213    108.4    336.4     1000\n#&gt; \n#&gt;  R-structure:  ~units\n#&gt; \n#&gt;       post.mean l-95% CI u-95% CI eff.samp\n#&gt; units     68.58    50.63    86.58     1000\n#&gt; \n#&gt;  Location effects: weight ~ days \n#&gt; \n#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n#&gt; (Intercept)   106.568  100.464  112.897     1000 &lt;0.001 ***\n#&gt; days            6.185    6.051    6.315     1000 &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n随机效应的方差（组间方差）为 211.4 ，则标准差为 14.539。残差方差（组内方差）为 68.77，则标准差为 8.293。\n再考虑变截距和斜率的混合效应模型。\n\n## 变截距、变斜率模型\nprior2 &lt;- list(\n  R = list(V = 1, nu = 0.002),\n  G = list(G1 = list(V = diag(2), nu = 0.002))\n)\nset.seed(20232023)\nrats_mcmc2 &lt;- MCMCglmm::MCMCglmm(weight ~ days,\n  random = ~ us(1 + days):rats,\n  data = rats_data, verbose = FALSE, prior = prior2\n)\nsummary(rats_mcmc2)\n\n#&gt; \n#&gt;  Iterations = 3001:12991\n#&gt;  Thinning interval  = 10\n#&gt;  Sample size  = 1000 \n#&gt; \n#&gt;  DIC: 1018.746 \n#&gt; \n#&gt;  G-structure:  ~us(1 + days):rats\n#&gt; \n#&gt;                              post.mean l-95% CI u-95% CI eff.samp\n#&gt; (Intercept):(Intercept).rats  124.1327  41.5313  226.059    847.2\n#&gt; days:(Intercept).rats          -0.7457  -4.3090    2.571    896.6\n#&gt; (Intercept):days.rats          -0.7457  -4.3090    2.571    896.6\n#&gt; days:days.rats                  0.2783   0.1067    0.493    786.9\n#&gt; \n#&gt;  R-structure:  ~units\n#&gt; \n#&gt;       post.mean l-95% CI u-95% CI eff.samp\n#&gt; units     38.14    27.07    51.08     1000\n#&gt; \n#&gt;  Location effects: weight ~ days \n#&gt; \n#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n#&gt; (Intercept)    106.40   101.70   110.78    823.3 &lt;0.001 ***\n#&gt; days             6.19     5.99     6.41    963.4 &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nG-structure 代表随机效应部分，R-structure 代表残差效应部分，Location effects 代表固定效应部分。MCMCglmm 包的这套模型表示术语源自商业软件 ASReml 。\n随机截距的方差为 124.1327，标准差为 11.1415，随机斜率的方差 0.2783，标准差为 0.5275，随机截距和随机斜率的协方差 -0.7457，相关系数为 -0.1268，这与 nlme 包结果很接近。\n\n35.5.8 INLA\n同前，先考虑变截距的混合效应模型。\n\nlibrary(INLA)\ninla.setOption(short.summary = TRUE)\n# 数值稳定性考虑\nrats_data$weight &lt;- rats_data$weight / 400\n# 变截距\nrats_inla1 &lt;- inla(weight ~ days + f(rats, model = \"iid\", n = 30), \n                  family = \"gaussian\", data = rats_data)\n# 输出结果\nsummary(rats_inla1)\n\n#&gt; Fixed effects:\n#&gt;              mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; (Intercept) 0.266 0.008      0.252    0.266      0.281 0.266   0\n#&gt; days        0.015 0.000      0.015    0.015      0.016 0.015   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                                            mean     sd 0.025quant 0.5quant\n#&gt; Precision for the Gaussian observations 2414.67 311.30    1852.64  2397.34\n#&gt; Precision for rats                       888.04 244.24     494.56   859.03\n#&gt;                                         0.975quant    mode\n#&gt; Precision for the Gaussian observations    3076.07 2367.82\n#&gt; Precision for rats                         1448.27  806.14\n#&gt; \n#&gt;  is computed\n\n\n再考虑变截距和斜率的混合效应模型。\n\n# https://inla.r-inla-download.org/r-inla.org/doc/latent/iid.pdf\n# 二维高斯随机效应的先验为 Wishart prior\nrats_data$rats &lt;- as.integer(rats_data$rats)\nrats_data$slopeid &lt;- 30 + rats_data$rats\n# 变截距、变斜率\nrats_inla2 &lt;- inla(\n  weight ~ 1 + days + f(rats, model = \"iid2d\", n = 2 * 30) + f(slopeid, days, copy = \"rats\"),\n  data = rats_data, family = \"gaussian\"\n)\n# 输出结果\nsummary(rats_inla2)\n\n#&gt; Fixed effects:\n#&gt;              mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; (Intercept) 0.266 0.034       0.20    0.266      0.333 0.266   0\n#&gt; days        0.015 0.033      -0.05    0.015      0.080 0.015   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                                             mean      sd 0.025quant 0.5quant\n#&gt; Precision for the Gaussian observations 4522.627 666.543   3334.867 4480.319\n#&gt; Precision for rats (component 1)          32.097   7.956     18.939   31.260\n#&gt; Precision for rats (component 2)          33.234   8.227     19.604   32.377\n#&gt; Rho1:2 for rats                           -0.001   0.172     -0.335   -0.001\n#&gt;                                         0.975quant     mode\n#&gt; Precision for the Gaussian observations   5952.936 4407.864\n#&gt; Precision for rats (component 1)            50.050   29.769\n#&gt; Precision for rats (component 2)            51.774   30.858\n#&gt; Rho1:2 for rats                              0.334   -0.001\n#&gt; \n#&gt;  is computed\n\n\n\n\n\n\n\n\n警告\n\n\n\n对于变截距和斜率混合效应模型，还未完全弄清楚 INLA 包的输出结果。固定效应部分和残差部分都是和前面一致的，但不清楚随机效应的方差协方差矩阵的估计与 INLA 输出的对应关系。参考《Bayesian inference with INLA》第 3 章第 3 小节。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#sec-hierarchical-normal-models-summary",
    "href": "hierarchical-normal-models.html#sec-hierarchical-normal-models-summary",
    "title": "35  分层正态模型",
    "section": "\n35.6 总结",
    "text": "35.6 总结\n基于 rats 数据建立变截距、变斜率的分层正态模型，也是线性混合效应模型的一种特殊情况，下表给出不同方法对模型各个参数的估计及置信区间。\n\n\n表格 35.2: 频率派方法比较\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(\\sigma_0\\)\n\\(\\sigma_1\\)\n\\(\\rho_{\\sigma}\\)\n\\(\\sigma_{\\epsilon}\\)\n\n\n\nnlme (REML)\n106.568\n6.186\n10.743\n0.511\n-0.159\n6.015\n\n\nlme4 (REML)\n106.568\n6.186\n10.744\n0.511\n-0.16\n6.015\n\n\nglmmTMB (REML)\n106.568\n6.186\n10.743\n0.511\n-0.16\n6.015\n\n\nMASS (PQL)\n106.568\n6.186\n10.495\n0.500\n-0.15\n6.015\n\n\nspaMM (ML)\n106.568\n6.186\n10.49\n0.499\n-0.15\n6.015\n\n\nhglm\n106.568\n6.186\n10.171\n0.491\n-\n6.091\n\n\nmgcv (REML)\n106.568\n6.186\n10.311\n0.492\n-\n6.069\n\n\n\n\n\n\n表中给出截距 \\(\\beta_0\\) 、斜率 \\(\\beta_1\\) 、随机截距 \\(\\sigma_0\\)、随机斜率 \\(\\sigma_1\\)、随机截距和斜率的相关系数 \\(\\rho_{\\sigma}\\)、残差 \\(\\sigma_{\\epsilon}\\) 等参数的估计及 95% 的置信区间，四舍五入保留 3 位小数。固定效应部分的结果完全相同，随机效应部分略有不同。\n\n\n表格 35.3: 贝叶斯方法比较\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(\\sigma_0\\)\n\\(\\sigma_1\\)\n\\(\\rho_{\\sigma}\\)\n\\(\\sigma_{\\epsilon}\\)\n\n\n\nrstan (NUTS)\n106.4\n6.2\n14.6\n0.5\n-\n6.1\n\n\ncmdstanr (NUTS)\n106\n6.19\n14.5\n0.513\n-\n6.09\n\n\nbrms (NUTS)\n106.47\n6.18\n11.27\n0.54\n-0.11\n6.15\n\n\nrstanarm (NUTS)\n106.575\n6.187\n10.194\n0.551\n-0.0969\n6.219\n\n\nblme (REML)\n106.568\n6.186\n10.787\n0.512\n-0.160\n5.949\n\n\nrjags (Gibbs)\n106.344\n6.188\n14.623\n0.518\n-\n6.073\n\n\nMCMCglmm (MCMC)\n106.40\n6.19\n11.14\n0.53\n-0.13\n6.18\n\n\n\n\n\n\n其中，INLA 结果的转化未完成，表格中暂缺。rstan 、 cmdstanr 和 rjags 未考虑随机截距和随机斜率的相关性，因此，相关系数暂缺。MCMC 是一种随机优化算法，在不同的实现中，可重复性的要求不同，设置随机数种子仅是其中的一个必要条件，故而，每次运行程序结果可能略微不同，但不影响结论。Stan 相关的 R 包输出结果中，rstan 保留 1 位小数，cmdstanr 保留 3 位有效数字，brms 保留 2 位小数，rstanarm 小数点后保留 3 位有效数字，各不相同，暂未统一处理。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#sec-hierarchical-models-exercises",
    "href": "hierarchical-normal-models.html#sec-hierarchical-models-exercises",
    "title": "35  分层正态模型",
    "section": "\n35.7 习题",
    "text": "35.7 习题\n\n\n四个组的重复测量数据，如下表所示，建立贝叶斯线性混合效应模型/分层正态模型分析数据，与 nlme 包拟合的结果对比。\n\n\n\n表格 35.4: 实验数据\n\n\n\n\n编号\n第1组\n第2组\n第3组\n第4组\n\n\n\n1\n62\n63\n68\n56\n\n\n2\n60\n67\n66\n62\n\n\n3\n63\n71\n71\n60\n\n\n4\n59\n64\n67\n61\n\n\n5\n\n65\n68\n63\n\n\n6\n\n66\n68\n64\n\n\n7\n\n\n\n63\n\n\n8\n\n\n\n59\n\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\ny_{ij}   \\sim \\mathcal{N}(\\theta_i, \\sigma^2) &\\quad\n\\theta_i \\sim \\mathcal{N}(\\mu, \\tau^2) \\\\\n(\\mu,\\log \\sigma, \\tau) &\\sim \\mathrm{uniform\\ prior} \\\\\ni = 1,2,3,4 &\\quad j = 1,2, \\ldots, n_i\n\\end{aligned}\n\\]\n\\(y_{ij}\\) 表示第 \\(i\\) 组的第 \\(j\\) 个测量值，\\(\\theta_i\\) 表示第 \\(i\\) 组的均值，\\(\\mu\\) 表示整体的均值，\\(\\sigma^2\\) 表示组内的方差，\\(\\tau^2\\) 表示组内的方差。\n\nlibrary(nlme)\nfit_lme &lt;- lme(data = dat, fixed = y ~ 1, random = ~ 1 | group)\nsummary(fit_lme)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: dat \n#&gt;        AIC      BIC    logLik\n#&gt;   121.7804 125.1869 -57.89019\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | group\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    3.419288 2.366309\n#&gt; \n#&gt; Fixed effects:  y ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 64.01266  1.780313 20 35.95584       0\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -2.18490896 -0.59921167  0.09332131  0.54077636  2.17507789 \n#&gt; \n#&gt; Number of Observations: 24\n#&gt; Number of Groups: 4\n\n\n随机效应（组间标准差）\\(\\tau^2\\) 3.419288 、残差效应（组内标准差）\\(\\sigma^2\\) 2.366309。截距 \\(\\mu\\) 64.01266 代表整体的均值。各组的均值如下：\n\n64.01266 + ranef(fit_lme)\n\n#&gt;   (Intercept)\n#&gt; 1    61.32214\n#&gt; 2    65.85309\n#&gt; 3    67.70525\n#&gt; 4    61.17016\n\n\n也可以调用 rjags 包连接 JAGS 软件做贝叶斯推理，JAGS 代码如下：\nmodel {\n  ## specify the distribution for observations\n  for(i in 1:n){\n    y[i] ~ dnorm(theta[group[i]], 1/sigma2)\n  }\n\n  ## specify the prior for theta\n  for(j in 1:J){\n    theta[j] ~ dnorm(mu, 1/tau2)\n  }\n\n  ## specify the prior for hyperparameters\n  mu ~ dunif(55, 75)\n\n  log_sigma ~ dunif(-10, 3)\n  sigma2 &lt;- exp(2*log_sigma)\n  sigma &lt;- exp(log_sigma)\n\n  tau ~ dunif(0, 8)\n  tau2 &lt;- pow(tau, 2)\n}\n完整的运行代码如下：\n\nlibrary(rjags)\n# 参考值\nmu_a &lt;- min(y)\nmu_b &lt;- max(y)\nlog_sigma_b &lt;- 2 * log(sd(y))\ntau_b &lt;- 2 * sd(y)\n\nJ &lt;- 4            # 4 个组\nn &lt;- length(y)    # 观察值数量\nN &lt;- 1500         # 总采样数\nnthin &lt;- 1        # 采样间隔\nnchains &lt;- 2      # 2 条链\nndiscard &lt;- N / 2 # 预处理阶段 warm-up / burn-in\n\n# 初始值\njags_inits &lt;- list(\n  list(\".RNG.name\" = \"base::Marsaglia-Multicarry\", \n       \".RNG.seed\" = 20222022, \n       \"theta\" = rep(3, 4), \"mu\" = 60, \"log_sigma\" = 0, \"tau\" = 1.5),\n  list(\".RNG.name\" = \"base::Marsaglia-Multicarry\", \n       \".RNG.seed\" = 20232023, \n       \"theta\" = rep(2, 4), \"mu\" = 60, \"log_sigma\" = 1, \"tau\" = 0.375)\n)\n# Call JAGS from R\njags_model &lt;- jags.model(\n  file = \"code/hnm.bugs\",\n  data = list(\"y\" = y, \"group\" = group, \"J\" = J, \"n\" = n),\n  inits = jags_inits, n.chains = nchains, quiet = TRUE\n)\n# burn-in\nupdate(jags_model, n.iter = ndiscard)\n# 抽样\njags_samples &lt;- coda.samples(jags_model,\n  variable.names = c('theta','mu','sigma','tau'), n.iter = N\n)\n# 参数的后验估计\nsummary(jags_samples)\n\n#&gt; \n#&gt; Iterations = 1751:3250\n#&gt; Thinning interval = 1 \n#&gt; Number of chains = 2 \n#&gt; Sample size per chain = 1500 \n#&gt; \n#&gt; 1. Empirical mean and standard deviation for each variable,\n#&gt;    plus standard error of the mean:\n#&gt; \n#&gt;            Mean     SD Naive SE Time-series SE\n#&gt; mu       64.142 2.3470  0.04285        0.05879\n#&gt; sigma     2.473 0.4278  0.00781        0.01117\n#&gt; tau       4.372 1.5995  0.02920        0.05101\n#&gt; theta[1] 61.356 1.2301  0.02246        0.02503\n#&gt; theta[2] 65.877 1.0056  0.01836        0.01928\n#&gt; theta[3] 67.696 1.0247  0.01871        0.02119\n#&gt; theta[4] 61.186 0.8694  0.01587        0.01692\n#&gt; \n#&gt; 2. Quantiles for each variable:\n#&gt; \n#&gt;            2.5%    25%    50%    75%  97.5%\n#&gt; mu       59.145 62.700 64.167 65.510 69.027\n#&gt; sigma     1.795  2.165  2.424  2.718  3.471\n#&gt; tau       1.846  3.128  4.171  5.464  7.652\n#&gt; theta[1] 58.947 60.545 61.342 62.161 63.771\n#&gt; theta[2] 63.866 65.228 65.878 66.548 67.872\n#&gt; theta[3] 65.665 67.046 67.712 68.337 69.692\n#&gt; theta[4] 59.446 60.632 61.189 61.707 62.975\n\n\n\n\n基于 lme4 包中学生对老师的评价数据 InstEval 建立（广义）线性混合效应模型分析数据。将响应变量（学生评价）视为有序的离散型变量，比较观察两个模型拟合效果（lme4、GLMMadaptive、spaMM 都不支持有序的响应变量，brms 则支持各类有序回归，使用语法与 lme4 完全一样。但是，由于数据规模比较大，计算时间数以天计，可考虑用 Stan 直接编码）。再者，从 Stan 实现的贝叶斯模型来看，感受 Stan 建模的灵活性和扩展性。（nlme 包不支持此等交叉随机效应的表达。）\n\ndata(InstEval, package = \"lme4\")\nstr(InstEval)\n\n#&gt; 'data.frame':    73421 obs. of  7 variables:\n#&gt;  $ s      : Factor w/ 2972 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 2 2 3 3 3 3 ...\n#&gt;  $ d      : Factor w/ 1128 levels \"1\",\"6\",\"7\",\"8\",..: 525 560 832 1068 62 406 3 6 19 75 ...\n#&gt;  $ studage: Ord.factor w/ 4 levels \"2\"&lt;\"4\"&lt;\"6\"&lt;\"8\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ lectage: Ord.factor w/ 6 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 2 1 2 2 1 1 1 1 1 1 ...\n#&gt;  $ service: Factor w/ 2 levels \"0\",\"1\": 1 2 1 2 1 1 2 1 1 1 ...\n#&gt;  $ dept   : Factor w/ 14 levels \"15\",\"5\",\"10\",..: 14 5 14 12 2 2 13 3 3 3 ...\n#&gt;  $ y      : int  5 2 5 3 2 4 4 5 5 4 ...\n\n\n\n因子型变量 s 表示 1-2972 位参与评分的学生。\n因子型变量 d 表示 1-2160 位上课的讲师。\n因子型变量 dept 表示课程相关的 1-15 院系。\n因子型变量 service 表示讲师除了授课外，是否承担其它服务。\n数值型变量 y 表示学生给课程的评分，1-5 分对应从坏到很好。\n\n\n# 数值型的响应变量\nfit_lme4 &lt;- lme4::lmer(y ~ 1 + service + (1 | s) + (1 | d) + (1 | dept), data = InstEval)\nsummary(fit_lme4)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ 1 + service + (1 | s) + (1 | d) + (1 | dept)\n#&gt;    Data: InstEval\n#&gt; \n#&gt; REML criterion at convergence: 237733.8\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.0597 -0.7478  0.0404  0.7723  3.1988 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  s        (Intercept) 0.105998 0.32557 \n#&gt;  d        (Intercept) 0.265219 0.51499 \n#&gt;  dept     (Intercept) 0.006912 0.08314 \n#&gt;  Residual             1.386501 1.17750 \n#&gt; Number of obs: 73421, groups:  s, 2972; d, 1128; dept, 14\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)  3.28259    0.02935 111.860\n#&gt; service1    -0.09264    0.01339  -6.919\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;          (Intr)\n#&gt; service1 -0.152\n\n\nlme4 包不支持响应变量为有序分类变量的情形，可用 ordinal 包，此等规模数据，拟合模型需要 5-10 分钟时间。\n\n# 有序因子型的响应变量\nInstEval$y &lt;- factor(InstEval$y, ordered = TRUE)\nlibrary(ordinal)\nfit_ordinal &lt;- clmm(\n  y ~ 1 + service + (1 | s) + (1 | d) + (1 | dept),\n  data = InstEval, link = \"probit\", threshold = \"equidistant\"\n)\nsummary(fit_ordinal)\n\n## MCMCglmm\nlibrary(MCMCglmm)\nprior2 &lt;- list(\n  R = list(V = 1, nu = 0.002),\n  G = list(\n    G1 = list(V = 1, nu = 0.002),\n    G2 = list(V = 1, nu = 0.002),\n    G3 = list(V = 1, nu = 0.002)\n  )\n)\n# 响应变量视为数值变量\nfit_mcmc2 &lt;- MCMCglmm(\n  y ~ service, random = ~ s + d + dept, family = \"gaussian\",\n  data = InstEval, verbose = FALSE, prior = prior2\n)\n# 响应变量视为有序的分类变量\nfit_mcmc3 &lt;- MCMCglmm(\n  y ~ service, random = ~ s + d + dept, family = \"ordinal\",\n  data = InstEval, verbose = FALSE, prior = prior2\n)\n\n当数据量较大时，MCMCglmm 包拟合模型需要很长时间，放弃，此时，Stan 的相对优势可以体现出来了。Stan 适合大型复杂概率统计模型。\n\n\n\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, 和 Steve Walker. 2015. 《Fitting Linear Mixed-Effects Models Using lme4》. Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nChung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, 和 Jingchen Liu. 2013. 《A nondegenerate penalized likelihood estimator for variance parameters in multilevel models》. Psychometrika 78 (4): 685–709. https://doi.org/10.1007/s11336-013-9328-2.\n\n\nGelfand, Alan E., Susan E. Hills, Amy Racine-Poon, 和 Adrian F. M. Smith. 1990. 《Illustration of Bayesian Inference in Normal Data Models Using Gibbs Sampling》. Journal of the American Statistical Association 85 (412): 972–85. https://doi.org/10.2307/2289594.\n\n\nHadfield, Jarrod D. 2010. 《MCMC Methods for Multi-Response Generalized Linear Mixed Models: The MCMCglmm R Package》. Journal of Statistical Software 33 (2): 1–22. https://www.jstatsoft.org/v33/i02/.\n\n\nPlummer, Martyn. 2021. rjags: Bayesian Graphical Models using MCMC. https://CRAN.R-project.org/package=rjags.\n\n\nPlummer, Martyn, Nicky Best, Kate Cowles, 和 Karen Vines. 2006. 《coda: Convergence Diagnosis and Output Analysis for MCMC》. R News 6 (1): 7–11. https://journal.r-project.org/archive/.\n\n\nRönnegård, Lars, Xia Shen, 和 Moudud Alam. 2010. 《hglm: A Package for Fitting Hierarchical Generalized Linear Models》. The R Journal 2 (2): 20–28. https://doi.org/10.32614/RJ-2010-009.\n\n\nRosseel, Yves. 2012. 《lavaan: An R Package for Structural Equation Modeling》. Journal of Statistical Software 48 (2): 1–36. https://doi.org/10.18637/jss.v048.i02.\n\n\nRubin, Donald B. 1981. 《Estimation in Parallel Randomized Experiments》. Journal of Educational Statistics 6 (4): 377–401. https://doi.org/10.3102/10769986006004377.\n\n\nSorensen, Tanner, Sven Hohenstein, 和 Shravan Vasishth. 2016. 《Bayesian linear mixed models using Stan: A tutorial for psychologists, linguists, and cognitive scientists》. The Quantitative Methods for Psychology 12 (3): 175–200. https://doi.org/10.20982/tqmp.12.3.p175.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "hierarchical-normal-models.html#footnotes",
    "href": "hierarchical-normal-models.html#footnotes",
    "title": "35  分层正态模型",
    "section": "",
    "text": "https://stat.ethz.ch/pipermail/r-help/2013-May/354311.html↩︎",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>分层正态模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html",
    "href": "mixed-effects-models.html",
    "title": "36  混合效应模型",
    "section": "",
    "text": "36.1 线性混合效应模型\n线性混合效应模型（Linear Mixed Models or Linear Mixed-Effects Models，简称 LME 或 LMM），介绍模型的基础理论，包括一般形式，矩阵表示，参数估计，假设检验，模型诊断，模型评估。参数方法主要是极大似然估计和限制极大似然估计。一般形式如下：\n\\[\n\\bm{y} = X\\bm{\\beta} + Z\\bm{u} + \\bm{\\epsilon}\n\\]\n其中，\\(\\bm{y}\\) 是一个向量，代表响应变量，\\(X\\) 代表固定效应对应的设计矩阵，\\(\\bm{\\beta}\\) 是一个参数向量，代表固定效应对应的回归系数，\\(Z\\) 代表随机效应对应的设计矩阵，\\(\\bm{u}\\) 是一个参数向量，代表随机效应对应的回归系数，\\(\\bm{\\epsilon}\\) 表示残差向量。\n一般假定随机向量 \\(\\bm{u}\\) 服从多元正态分布，这是无条件分布，随机向量 \\(\\bm{y}|\\bm{u}\\) 服从多元正态分布，这是条件分布。\n\\[\n\\begin{aligned}\n\\bm{u} &\\sim \\mathcal{N}(0,\\Sigma) \\\\\n\\bm{y}|\\bm{u} &\\sim \\mathcal{N}(X\\bm{\\beta} + Z\\bm{u},\\sigma^2W)\n\\end{aligned}\n\\]\n其中，方差协方差矩阵 \\(\\Sigma\\) 必须是半正定的，\\(W\\) 是一个对角矩阵。nlme 和 lme4 等 R 包共用一套表示随机效应的公式语法。\nsleepstudy 数据集来自 lme4 包，是一个睡眠研究项目的实验数据。实验对象都是有失眠情况的人，有的人有严重的失眠问题（一天只有 3 个小时的睡眠时间）。进入实验后的前10 天的情况，记录平均反应时间、睡眠不足的天数。\ndata(sleepstudy, package = \"lme4\")\nstr(sleepstudy)\n\n#&gt; 'data.frame':    180 obs. of  3 variables:\n#&gt;  $ Reaction: num  250 259 251 321 357 ...\n#&gt;  $ Days    : num  0 1 2 3 4 5 6 7 8 9 ...\n#&gt;  $ Subject : Factor w/ 18 levels \"308\",\"309\",\"310\",..: 1 1 1 1 1 1 1 1 1 1 ...\nReaction 表示平均反应时间（毫秒），数值型，Days 表示进入实验后的第几天，数值型，Subject 表示参与实验的个体编号，因子型。\nxtabs(~ Days + Subject, data = sleepstudy)\n\n#&gt;     Subject\n#&gt; Days 308 309 310 330 331 332 333 334 335 337 349 350 351 352 369 370 371 372\n#&gt;    0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    3   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    4   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    5   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    6   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    7   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    8   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#&gt;    9   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n每个个体每天产生一条数据，下 图 36.1 中每条折线代表一个个体。\nlibrary(ggplot2)\nggplot(data = sleepstudy, aes(x = Days, y = Reaction, group = Subject)) +\n  geom_line() +\n  scale_x_continuous(n.breaks = 6) +\n  theme_bw() +\n  labs(x = \"睡眠不足的天数\", y = \"平均反应时间\")\n\n\n\n\n\n\n图 36.1: sleepstudy 数据集\n对于连续重复测量的数据（continuous repeated measurement outcomes），也叫纵向数据（longitudinal data），针对不同个体 Subject，相比于上图，下面绘制反应时间 Reaction 随睡眠时间 Days 的变化趋势更合适。图中趋势线是简单线性回归的结果，分面展示不同个体Subject 之间对比。\nggplot(data = sleepstudy, aes(x = Days, y = Reaction)) +\n  geom_point() +\n  geom_smooth(formula = \"y ~ x\", method = \"lm\", se = FALSE) +\n  scale_x_continuous(n.breaks = 6) +\n  theme_bw() +\n  facet_wrap(facets = ~Subject, labeller = \"label_both\", ncol = 6) +\n  labs(x = \"睡眠不足的天数\", y = \"平均反应时间\")\n\n\n\n\n\n\n图 36.2: 分面展示 sleepstudy 数据集",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html#sec-lmm",
    "href": "mixed-effects-models.html#sec-lmm",
    "title": "36  混合效应模型",
    "section": "",
    "text": "I think what we are seeking is the marginal variance-covariance matrix of the parameter estimators (marginal with respect to the random effects random variable, B), which would have the form of the inverse of the crossproduct of a \\((q+p)\\) by \\(p\\) matrix composed of the vertical concatenation of \\(-L^{-1}RZXRX^{-1}\\) and \\(RX^{-1}\\). (Note: You do not want to calculate the first term by inverting \\(L\\), use solve(L, RZX, system = \"L\")\n\n[…] don’t even think about using solve(L)\ndon’t!, don’t!, don’t!\nhave I made myself clear?\ndon’t do that (and we all know that someone will do exactly that for a very large \\(L\\) and then send out messages about “R is SOOOOO SLOOOOW!!!!” :-) )\n\n— Douglas Bates 2\n\n\n\n\n\n\n\n提示\n\n\n\n\n一般的模型结构和假设\n一般的模型表达公式\n\nnlme 包的函数 lme()\n\n公式语法和示例模型表示\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n36.1.1 nlme\n考虑两水平的混合效应模型，其中随机截距 \\(\\beta_{0j}\\) 和随机斜率 \\(\\beta_{1j}\\)，指标 \\(j\\) 表示分组的编号，也叫变截距和变斜率模型\n\\[\n\\begin{aligned}\n\\mathrm{Reaction}_{ij} &= \\beta_{0j} + \\beta_{1j} \\cdot \\mathrm{Days}_{ij} + \\epsilon_{ij} \\\\\n\\beta_{0j} &= \\gamma_{00} + U_{0j} \\\\\n\\beta_{1j} &= \\gamma_{10} + U_{1j} \\\\\n\\begin{pmatrix}\nU_{0j} \\\\\nU_{1j}\n\\end{pmatrix} &\\sim \\mathcal{N}\n\\begin{bmatrix}\n\\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix}\n,\n\\begin{pmatrix}\n\\tau^2_{00} & \\tau_{01} \\\\\n\\tau_{01} & \\tau^2_{10}\n\\end{pmatrix}\n\\end{bmatrix} \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2) \\\\\ni = 0,1,\\cdots,9 &\\quad j = 308,309,\\cdots, 372.\n\\end{aligned}\n\\]\n下面用 nlme 包 (Pinheiro 和 Bates 2000) 拟合模型。\n\nlibrary(nlme)\nsleep_nlme &lt;- lme(Reaction ~ Days, random = ~ Days | Subject, data = sleepstudy)\nsummary(sleep_nlme)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: sleepstudy \n#&gt;        AIC      BIC    logLik\n#&gt;   1755.628 1774.719 -871.8141\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~Days | Subject\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev    Corr  \n#&gt; (Intercept) 24.740241 (Intr)\n#&gt; Days         5.922103 0.066 \n#&gt; Residual    25.591843       \n#&gt; \n#&gt; Fixed effects:  Reaction ~ Days \n#&gt;                 Value Std.Error  DF  t-value p-value\n#&gt; (Intercept) 251.40510  6.824516 161 36.83853       0\n#&gt; Days         10.46729  1.545783 161  6.77151       0\n#&gt;  Correlation: \n#&gt;      (Intr)\n#&gt; Days -0.138\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -3.95355735 -0.46339976  0.02311783  0.46339621  5.17925089 \n#&gt; \n#&gt; Number of Observations: 180\n#&gt; Number of Groups: 18\n\n\n随机效应（Random effects）部分：\n\n# 前 6 个 subject\nhead(ranef(sleep_nlme))\n\n#&gt;     (Intercept)       Days\n#&gt; 308    2.258754  9.1989366\n#&gt; 309  -40.398490 -8.6197167\n#&gt; 310  -38.960098 -5.4489048\n#&gt; 330   23.690228 -4.8142826\n#&gt; 331   22.259981 -3.0698548\n#&gt; 332    9.039458 -0.2721585\n\n\n固定效应（Fixed effects）部分：\n\nfixef(sleep_nlme)\n\n#&gt; (Intercept)        Days \n#&gt;   251.40510    10.46729\n\n\nggeffects 包的函数 ggpredict() 和 ggeffect() 可以用来绘制混合效应模型的边际效应（ Marginal Effects），ggPMX 包 可以用来绘制混合效应模型的诊断图。下 图 36.3 展示关于变量 Days 的边际效应图。\n\nlibrary(ggeffects)\nmydf &lt;- ggpredict(sleep_nlme, terms = \"Days\")\nggplot(mydf, aes(x = x, y = predicted)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n  scale_x_continuous(n.breaks = 6) +\n  theme_bw() +\n  labs(x = \"Days\", y = \"Reaction\")\n\n\n\n\n\n\n图 36.3: 边际效应图\n\n\n\n\n\n36.1.2 MASS\n\nsleep_mass &lt;- MASS::glmmPQL(Reaction ~ Days,\n  random = ~ Days | Subject, verbose = FALSE,\n  data = sleepstudy, family = gaussian\n)\nsummary(sleep_mass)\n\n#&gt; Linear mixed-effects model fit by maximum likelihood\n#&gt;   Data: sleepstudy \n#&gt;   AIC BIC logLik\n#&gt;    NA  NA     NA\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~Days | Subject\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev    Corr  \n#&gt; (Intercept) 23.780376 (Intr)\n#&gt; Days         5.716807 0.081 \n#&gt; Residual    25.591842       \n#&gt; \n#&gt; Variance function:\n#&gt;  Structure: fixed weights\n#&gt;  Formula: ~invwt \n#&gt; Fixed effects:  Reaction ~ Days \n#&gt;                 Value Std.Error  DF  t-value p-value\n#&gt; (Intercept) 251.40510  6.669396 161 37.69533       0\n#&gt; Days         10.46729  1.510647 161  6.92901       0\n#&gt;  Correlation: \n#&gt;      (Intr)\n#&gt; Days -0.138\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -3.94156355 -0.46559311  0.02894656  0.46361051  5.17933587 \n#&gt; \n#&gt; Number of Observations: 180\n#&gt; Number of Groups: 18\n\n\n\n36.1.3 lme4\n\nsleep_lme4 &lt;- lme4::lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)\nsummary(sleep_lme4)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Reaction ~ Days + (Days | Subject)\n#&gt;    Data: sleepstudy\n#&gt; \n#&gt; REML criterion at convergence: 1743.6\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.9536 -0.4634  0.0231  0.4634  5.1793 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr\n#&gt;  Subject  (Intercept) 612.10   24.741       \n#&gt;           Days         35.07    5.922   0.07\n#&gt;  Residual             654.94   25.592       \n#&gt; Number of obs: 180, groups:  Subject, 18\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)  251.405      6.825  36.838\n#&gt; Days          10.467      1.546   6.771\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;      (Intr)\n#&gt; Days -0.138\n\n\n\n36.1.4 blme\n\nsleep_blme &lt;- blme::blmer(\n  Reaction ~ Days + (Days | Subject), data = sleepstudy,\n  control = lme4::lmerControl(check.conv.grad = \"ignore\"),\n  cov.prior = NULL)\nsummary(sleep_blme)\n\n#&gt; Prior dev  : 0\n#&gt; \n#&gt; Linear mixed model fit by REML ['blmerMod']\n#&gt; Formula: Reaction ~ Days + (Days | Subject)\n#&gt;    Data: sleepstudy\n#&gt; Control: lme4::lmerControl(check.conv.grad = \"ignore\")\n#&gt; \n#&gt; REML criterion at convergence: 1743.6\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.9536 -0.4634  0.0231  0.4634  5.1793 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr\n#&gt;  Subject  (Intercept) 612.10   24.741       \n#&gt;           Days         35.07    5.922   0.07\n#&gt;  Residual             654.94   25.592       \n#&gt; Number of obs: 180, groups:  Subject, 18\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)  251.405      6.825  36.838\n#&gt; Days          10.467      1.546   6.771\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;      (Intr)\n#&gt; Days -0.138\n\n\n\n36.1.5 brms\n\nsleep_brms &lt;- brms::brm(Reaction ~ Days + (Days | Subject), data = sleepstudy)\nsummary(sleep_brms)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Reaction ~ Days + (Days | Subject) \n   Data: sleepstudy (Number of observations: 180) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Subject (Number of levels: 18) \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)          27.03      6.60    15.88    42.13 1.00     1728     2469\nsd(Days)                6.61      1.50     4.18     9.97 1.00     1517     2010\ncor(Intercept,Days)     0.08      0.29    -0.46     0.65 1.00      991     1521\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   251.26      7.42   236.27   266.12 1.00     1982     2687\nDays         10.36      1.77     6.85    13.85 1.00     1415     1982\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    25.88      1.54    22.99    29.06 1.00     3204     2869\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n# predictions\nconds &lt;- brms::make_conditions(sleep_brms, \"Subject\")\nsleep_brms |&gt;\n  brms::marginal_effects(\n    re_formula = NULL,\n    conditions = conds\n  ) |&gt;\n  plot(points = TRUE, ncol = 6)\n\n\n36.1.6 MCMCglmm\nMCMCglmm 包拟合变截距、变斜率模型，随机截距和随机斜率之间存在相关性。\n\n## 变截距、变斜率模型\nprior1 &lt;- list(\n  R = list(V = 1, fix = 1),\n  G = list(G1 = list(V = diag(2), nu = 0.002))\n)\nset.seed(20232023)\nsleep_mcmcglmm &lt;- MCMCglmm::MCMCglmm(\n  Reaction ~ Days, random = ~ us(1 + Days):Subject, prior = prior1,\n  data = sleepstudy, family = \"gaussian\", verbose = FALSE\n)\nsummary(sleep_mcmcglmm)\n\n#&gt; \n#&gt;  Iterations = 3001:12991\n#&gt;  Thinning interval  = 10\n#&gt;  Sample size  = 1000 \n#&gt; \n#&gt;  DIC: 94714.46 \n#&gt; \n#&gt;  G-structure:  ~us(1 + Days):Subject\n#&gt; \n#&gt;                                 post.mean l-95% CI u-95% CI eff.samp\n#&gt; (Intercept):(Intercept).Subject   1005.69   454.97  1840.04   1000.0\n#&gt; Days:(Intercept).Subject           -34.44  -167.15    84.09   1000.0\n#&gt; (Intercept):Days.Subject           -34.44  -167.15    84.09   1000.0\n#&gt; Days:Days.Subject                   52.36    22.74    95.60    902.3\n#&gt; \n#&gt;  R-structure:  ~units\n#&gt; \n#&gt;       post.mean l-95% CI u-95% CI eff.samp\n#&gt; units         1        1        1        0\n#&gt; \n#&gt;  Location effects: Reaction ~ Days \n#&gt; \n#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n#&gt; (Intercept)   251.374  235.935  265.961     1000 &lt;0.001 ***\n#&gt; Days           10.419    7.262   13.976     1000 &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n固定随机效应 R-structure 方差。固定效应 Location effects 截距 (Intercept) 为 251.374，斜率 Days 为 10.419 。\n\n36.1.7 INLA\n将数据集 sleepstudy 中的 Reaction 除以 1000，目的是数值稳定性，减小迭代序列的相关性。先考虑变截距模型\n\nlibrary(INLA)\ninla.setOption(short.summary = TRUE)\n# 做尺度变换\nsleepstudy$Reaction &lt;- sleepstudy$Reaction / 1000\n# 变截距\nsleep_inla1 &lt;- inla(Reaction ~ Days + f(Subject, model = \"iid\", n = 18), \n                  family = \"gaussian\", data = sleepstudy)\n# 输出结果\nsummary(sleep_inla1)\n\n#&gt; Fixed effects:\n#&gt;              mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; (Intercept) 0.251 0.010      0.232    0.251      0.270 0.251   0\n#&gt; Days        0.010 0.001      0.009    0.010      0.012 0.010   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                                            mean     sd 0.025quant 0.5quant\n#&gt; Precision for the Gaussian observations 1054.07 116.99     840.14  1048.46\n#&gt; Precision for Subject                    843.97 300.88     391.25   798.36\n#&gt;                                         0.975quant    mode\n#&gt; Precision for the Gaussian observations    1300.13 1038.99\n#&gt; Precision for Subject                      1559.54  714.37\n#&gt; \n#&gt;  is computed\n\n\n再考虑变截距和变斜率模型\n\n# https://inla.r-inla-download.org/r-inla.org/doc/latent/iid.pdf\n# 二维高斯随机效应的先验为 Wishart prior\nsleepstudy$Subject &lt;- as.integer(sleepstudy$Subject)\nsleepstudy$slopeid &lt;- 18 + sleepstudy$Subject\n# 变截距、变斜率\nsleep_inla2 &lt;- inla(\n  Reaction ~ 1 + Days + f(Subject, model = \"iid2d\", n = 2 * 18) + f(slopeid, Days, copy = \"Subject\"),\n  data = sleepstudy, family = \"gaussian\"\n)\n# 输出结果\nsummary(sleep_inla2)\n\n#&gt; Fixed effects:\n#&gt;              mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; (Intercept) 0.251 0.055      0.142    0.251      0.360 0.251   0\n#&gt; Days        0.010 0.054     -0.097    0.010      0.118 0.010   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                                             mean      sd 0.025quant 0.5quant\n#&gt; Precision for the Gaussian observations 1549.520 181.250   1218.051 1540.849\n#&gt; Precision for Subject (component 1)       20.871   6.507     10.626   20.024\n#&gt; Precision for Subject (component 2)       21.224   6.611     10.803   20.367\n#&gt; Rho1:2 for Subject                        -0.001   0.213     -0.414   -0.002\n#&gt;                                         0.975quant     mode\n#&gt; Precision for the Gaussian observations   1930.575 1527.261\n#&gt; Precision for Subject (component 1)         35.970   18.479\n#&gt; Precision for Subject (component 2)         36.554   18.806\n#&gt; Rho1:2 for Subject                           0.413   -0.003\n#&gt; \n#&gt;  is computed",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html#sec-glmm",
    "href": "mixed-effects-models.html#sec-glmm",
    "title": "36  混合效应模型",
    "section": "\n36.2 广义线性混合效应模型",
    "text": "36.2 广义线性混合效应模型\n当响应变量分布不再是高斯分布，线性混合效应模型就扩展到广义线性混合效应模型。有一些 R 包可以拟合此类模型，MASS 包的函数 glmmPQL() ，mgcv 包的函数 gam()，lme4 包的函数 glmer() ，GLMMadaptive 包的函数 mixed_model() ，brms 包的函数 brm() 等。\n\n\n表格 36.1: 响应变量的分布\n\n\n\n响应变量分布\nMASS\nmgcv\nlme4\nGLMMadaptive\nbrms\n\n\n\n伯努利分布\n支持\n支持\n支持\n支持\n支持\n\n\n二项分布\n支持\n支持\n支持\n支持\n支持\n\n\n泊松分布\n支持\n支持\n支持\n支持\n支持\n\n\n负二项分布\n不支持\n支持\n支持\n支持\n支持\n\n\n伽马分布\n支持\n支持\n支持\n支持\n支持\n\n\n\n\n\n\n函数 glmmPQL() 支持的分布族见函数 glm() 的参数 family ，lme4 包的函数 glmer.nb() 和 GLMMadaptive 包的函数 negative.binomial() 都可用于拟合响应变量服从负二项分布的情况。除了这些常规的分布，GLMMadaptive 和 brms 包还支持许多常见的分布，比如零膨胀的泊松分布、二项分布等，还可以自定义分布。\n\n伯努利分布 family = binomial(link = \"logit\")\n\n二项分布 family = binomial(link = \"logit\")\n\n泊松分布 family = poisson(link = \"log\")\n\n负二项分布 lme4::glmer.nb() 或 GLMMadaptive::negative.binomial()\n\n伽马分布 family = Gamma(link = \"inverse\")\n\n\nGLMMadaptive 包 (Rizopoulos 2023) 的主要函数 mixed_model() 是用来拟合广义线性混合效应模型的。下面以牛传染性胸膜肺炎（Contagious bovine pleuropneumonia，简称 CBPP）数据 cbpp 介绍函数 mixed_model() 的用法，该数据集来自 lme4 包。\n\ndata(cbpp, package = \"lme4\")\nstr(cbpp)\n\n#&gt; 'data.frame':    56 obs. of  4 variables:\n#&gt;  $ herd     : Factor w/ 15 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 2 2 2 3 3 3 ...\n#&gt;  $ incidence: num  2 3 4 0 3 1 1 8 2 0 ...\n#&gt;  $ size     : num  14 12 9 5 22 18 21 22 16 16 ...\n#&gt;  $ period   : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 3 4 1 2 3 1 2 3 ...\n\n\nherd 牛群编号，period 时间段，incidence 感染的数量，size 牛群大小。疾病在种群内扩散\n\nggplot(data = cbpp, aes(x = herd, y = period)) +\n  geom_tile(aes(fill = incidence / size)) +\n  scale_fill_viridis_c(label = scales::percent_format(), \n                       option = \"C\", name = \"\") +\n  theme_minimal()\n\n\n\n\n\n\n图 36.4: 感染比例随变量 herd 和 period 的变化\n\n\n\n\n\n36.2.1 MASS\n\ncbpp_mass &lt;- MASS::glmmPQL(\n  cbind(incidence, size - incidence) ~ period,\n  random = ~ 1 | herd, verbose = FALSE,\n  data = cbpp, family = binomial(\"logit\")\n)\nsummary(cbpp_mass)\n\n#&gt; Linear mixed-effects model fit by maximum likelihood\n#&gt;   Data: cbpp \n#&gt;   AIC BIC logLik\n#&gt;    NA  NA     NA\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | herd\n#&gt;         (Intercept) Residual\n#&gt; StdDev:   0.5563535 1.184527\n#&gt; \n#&gt; Variance function:\n#&gt;  Structure: fixed weights\n#&gt;  Formula: ~invwt \n#&gt; Fixed effects:  cbind(incidence, size - incidence) ~ period \n#&gt;                 Value Std.Error DF   t-value p-value\n#&gt; (Intercept) -1.327364 0.2390194 38 -5.553372  0.0000\n#&gt; period2     -1.016126 0.3684079 38 -2.758156  0.0089\n#&gt; period3     -1.149984 0.3937029 38 -2.920944  0.0058\n#&gt; period4     -1.605217 0.5178388 38 -3.099839  0.0036\n#&gt;  Correlation: \n#&gt;         (Intr) perid2 perid3\n#&gt; period2 -0.399              \n#&gt; period3 -0.373  0.260       \n#&gt; period4 -0.282  0.196  0.182\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.0591168 -0.6493095 -0.2747620  0.5170492  2.6187632 \n#&gt; \n#&gt; Number of Observations: 56\n#&gt; Number of Groups: 15\n\n\n\n36.2.2 GLMMadaptive\n\nlibrary(GLMMadaptive)\ncbpp_glmmadaptive &lt;- mixed_model(\n  fixed = cbind(incidence, size - incidence) ~ period,\n  random = ~ 1 | herd, data = cbpp, family = binomial(link = \"logit\")\n)\nsummary(cbpp_glmmadaptive)\n\n#&gt; \n#&gt; Call:\n#&gt; mixed_model(fixed = cbind(incidence, size - incidence) ~ period, \n#&gt;     random = ~1 | herd, data = cbpp, family = binomial(link = \"logit\"))\n#&gt; \n#&gt; Data Descriptives:\n#&gt; Number of Observations: 56\n#&gt; Number of Groups: 15 \n#&gt; \n#&gt; Model:\n#&gt;  family: binomial\n#&gt;  link: logit \n#&gt; \n#&gt; Fit statistics:\n#&gt;    log.Lik      AIC     BIC\n#&gt;  -91.98337 193.9667 197.507\n#&gt; \n#&gt; Random effects covariance matrix:\n#&gt;                StdDev\n#&gt; (Intercept) 0.6475934\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std.Err z-value    p-value\n#&gt; (Intercept)  -1.3995  0.2335 -5.9923    &lt; 1e-04\n#&gt; period2      -0.9914  0.3068 -3.2316 0.00123091\n#&gt; period3      -1.1278  0.3268 -3.4513 0.00055793\n#&gt; period4      -1.5795  0.4276 -3.6937 0.00022101\n#&gt; \n#&gt; Integration:\n#&gt; method: adaptive Gauss-Hermite quadrature rule\n#&gt; quadrature points: 11\n#&gt; \n#&gt; Optimization:\n#&gt; method: EM\n#&gt; converged: TRUE\n\n\n\n36.2.3 glmmTMB\n\ncbpp_glmmtmb &lt;- glmmTMB::glmmTMB(\n  cbind(incidence, size - incidence) ~ period + (1 | herd),\n  data = cbpp, family = binomial, REML = TRUE\n)\nsummary(cbpp_glmmtmb)\n\n#&gt;  Family: binomial  ( logit )\n#&gt; Formula:          cbind(incidence, size - incidence) ~ period + (1 | herd)\n#&gt; Data: cbpp\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;    196.4    206.5    -93.2    186.4       55 \n#&gt; \n#&gt; Random effects:\n#&gt; \n#&gt; Conditional model:\n#&gt;  Groups Name        Variance Std.Dev.\n#&gt;  herd   (Intercept) 0.4649   0.6819  \n#&gt; Number of obs: 56, groups:  herd, 15\n#&gt; \n#&gt; Conditional model:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  -1.3670     0.2376  -5.752 8.79e-09 ***\n#&gt; period2      -0.9693     0.3055  -3.173 0.001509 ** \n#&gt; period3      -1.1045     0.3255  -3.393 0.000691 ***\n#&gt; period4      -1.5519     0.4265  -3.639 0.000274 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n36.2.4 lme4\n\ncbpp_lme4 &lt;- lme4::glmer(\n  cbind(incidence, size - incidence) ~ period + (1 | herd),\n  family = binomial(\"logit\"), data = cbpp\n)\nsummary(cbpp_lme4)\n\n#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace\n#&gt;   Approximation) [glmerMod]\n#&gt;  Family: binomial  ( logit )\n#&gt; Formula: cbind(incidence, size - incidence) ~ period + (1 | herd)\n#&gt;    Data: cbpp\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;    194.1    204.2    -92.0    184.1       51 \n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.3816 -0.7889 -0.2026  0.5142  2.8791 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups Name        Variance Std.Dev.\n#&gt;  herd   (Intercept) 0.4123   0.6421  \n#&gt; Number of obs: 56, groups:  herd, 15\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  -1.3983     0.2312  -6.048 1.47e-09 ***\n#&gt; period2      -0.9919     0.3032  -3.272 0.001068 ** \n#&gt; period3      -1.1282     0.3228  -3.495 0.000474 ***\n#&gt; period4      -1.5797     0.4220  -3.743 0.000182 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;         (Intr) perid2 perid3\n#&gt; period2 -0.363              \n#&gt; period3 -0.340  0.280       \n#&gt; period4 -0.260  0.213  0.198\n\n\n\n36.2.5 mgcv\n或使用 mgcv 包，可以得到近似的结果。随机效应部分可以看作可加的惩罚项\n\nlibrary(mgcv)\ncbpp_mgcv &lt;- gam(\n  cbind(incidence, size - incidence) ~ period + s(herd, bs = \"re\"),\n  data = cbpp, family = binomial(link = \"logit\"), method = \"REML\"\n)\nsummary(cbpp_mgcv)\n\n#&gt; \n#&gt; Family: binomial \n#&gt; Link function: logit \n#&gt; \n#&gt; Formula:\n#&gt; cbind(incidence, size - incidence) ~ period + s(herd, bs = \"re\")\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  -1.3670     0.2358  -5.799 6.69e-09 ***\n#&gt; period2      -0.9693     0.3040  -3.189 0.001428 ** \n#&gt; period3      -1.1045     0.3241  -3.407 0.000656 ***\n#&gt; period4      -1.5519     0.4251  -3.651 0.000261 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;          edf Ref.df Chi.sq  p-value    \n#&gt; s(herd) 9.66     14  32.03 3.21e-05 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.515   Deviance explained =   53%\n#&gt; -REML = 93.199  Scale est. = 1         n = 56\n\n\n下面给出随机效应的标准差的估计及其上下限，和前面 GLMMadaptive 包和 lme4 包给出的结果也是接近的。\n\ngam.vcomp(cbpp_mgcv)\n\n#&gt; \n#&gt; Standard deviations and 0.95 confidence intervals:\n#&gt; \n#&gt;           std.dev     lower    upper\n#&gt; s(herd) 0.6818673 0.3953145 1.176135\n#&gt; \n#&gt; Rank: 1/1\n\n\n\n36.2.6 blme\n\ncbpp_blme &lt;- blme::bglmer(\n  cbind(incidence, size - incidence) ~ period + (1 | herd),\n  family = binomial(\"logit\"), data = cbpp\n)\nsummary(cbpp_blme)\n\n#&gt; Cov prior  : herd ~ wishart(df = 3.5, scale = Inf, posterior.scale = cov, common.scale = TRUE)\n#&gt; Prior dev  : 0.9901\n#&gt; \n#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace\n#&gt;   Approximation) [bglmerMod]\n#&gt;  Family: binomial  ( logit )\n#&gt; Formula: cbind(incidence, size - incidence) ~ period + (1 | herd)\n#&gt;    Data: cbpp\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;    194.2    204.3    -92.1    184.2       51 \n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.3670 -0.8121 -0.1704  0.4971  2.7969 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups Name        Variance Std.Dev.\n#&gt;  herd   (Intercept) 0.5168   0.7189  \n#&gt; Number of obs: 56, groups:  herd, 15\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  -1.4142     0.2466  -5.736  9.7e-09 ***\n#&gt; period2      -0.9803     0.3037  -3.227 0.001249 ** \n#&gt; period3      -1.1171     0.3233  -3.455 0.000549 ***\n#&gt; period4      -1.5667     0.4222  -3.710 0.000207 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;         (Intr) perid2 perid3\n#&gt; period2 -0.342              \n#&gt; period3 -0.320  0.282       \n#&gt; period4 -0.246  0.215  0.199\n\n\n\n36.2.7 brms\n表示二项分布，公式语法与前面的 lme4 等包不同。\n\ncbpp_brms &lt;- brms::brm(\n  incidence | trials(size) ~ period + (1 | herd),\n  family = binomial(\"logit\"), data = cbpp\n)\nsummary(cbpp_brms)\n\n Family: binomial \n  Links: mu = logit \nFormula: incidence | trials(size) ~ period + (1 | herd) \n   Data: cbpp (Number of observations: 56) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~herd (Number of levels: 15) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.76      0.22     0.39     1.29 1.00     1483     1962\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -1.40      0.26    -1.92    -0.88 1.00     2440     2542\nperiod2      -1.00      0.31    -1.63    -0.41 1.00     5242     2603\nperiod3      -1.14      0.34    -1.83    -0.50 1.00     4938     3481\nperiod4      -1.61      0.44    -2.49    -0.81 1.00     4697     2966\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n36.2.8 MCMCglmm\n\nset.seed(20232023)\ncbpp_mcmcglmm &lt;- MCMCglmm::MCMCglmm(\n  cbind(incidence, size - incidence) ~ period, random = ~herd,\n  data = cbpp, family = \"multinomial2\", verbose = FALSE\n)\nsummary(cbpp_mcmcglmm)\n\n#&gt; \n#&gt;  Iterations = 3001:12991\n#&gt;  Thinning interval  = 10\n#&gt;  Sample size  = 1000 \n#&gt; \n#&gt;  DIC: 538.4141 \n#&gt; \n#&gt;  G-structure:  ~herd\n#&gt; \n#&gt;      post.mean  l-95% CI u-95% CI eff.samp\n#&gt; herd    0.0244 1.256e-16   0.1347    186.5\n#&gt; \n#&gt;  R-structure:  ~units\n#&gt; \n#&gt;       post.mean l-95% CI u-95% CI eff.samp\n#&gt; units     1.098   0.2471    2.158    273.9\n#&gt; \n#&gt;  Location effects: cbind(incidence, size - incidence) ~ period \n#&gt; \n#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n#&gt; (Intercept)   -1.5314  -2.1484  -0.8507   1000.0 &lt;0.001 ***\n#&gt; period2       -1.2596  -2.2129  -0.1495    854.7  0.006 ** \n#&gt; period3       -1.3827  -2.3979  -0.2851    691.0  0.012 *  \n#&gt; period4       -1.9612  -3.3031  -0.7745    572.6 &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n对于服从非高斯分布的响应变量，MCMCglmm 总是假定存在过度离散的情况，即存在一个与分类变量无关的随机变量，或者说存在一个残差服从正态分布的随机变量（效应），可以看作测量误差，这种假定对真实数据建模是有意义的，所以，与以上 MCMCglmm 代码等价的 lme4 包模型代码如下：\n\ncbpp$id &lt;- as.factor(1:dim(cbpp)[1])\ncbpp_lme4 &lt;- lme4::glmer(\n  cbind(incidence, size - incidence) ~ period + (1 | herd) + (1 | id),\n  family = binomial, data = cbpp\n)\nsummary(cbpp_lme4)\n\n#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace\n#&gt;   Approximation) [glmerMod]\n#&gt;  Family: binomial  ( logit )\n#&gt; Formula: cbind(incidence, size - incidence) ~ period + (1 | herd) + (1 |  \n#&gt;     id)\n#&gt;    Data: cbpp\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;    186.6    198.8    -87.3    174.6       50 \n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2866 -0.5989 -0.1181  0.3575  1.6216 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups Name        Variance Std.Dev.\n#&gt;  id     (Intercept) 0.79400  0.8911  \n#&gt;  herd   (Intercept) 0.03384  0.1840  \n#&gt; Number of obs: 56, groups:  id, 56; herd, 15\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  -1.5003     0.2967  -5.056 4.27e-07 ***\n#&gt; period2      -1.2265     0.4803  -2.554  0.01066 *  \n#&gt; period3      -1.3288     0.4939  -2.690  0.00713 ** \n#&gt; period4      -1.8662     0.5936  -3.144  0.00167 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;         (Intr) perid2 perid3\n#&gt; period2 -0.559              \n#&gt; period3 -0.537  0.373       \n#&gt; period4 -0.441  0.327  0.314\n\n\n贝叶斯的结果与频率派的结果相近，但还是有明显差异。MCMCglmm 总是假定存在残差，残差的分布服从 0 均值的高斯分布，下面将残差分布的方差固定，重新拟合模型，之后再根据残差方差为 0 调整估计结果。\n\nprior2 &lt;- list(\n  R = list(V = 1, fix = 1),\n  G = list(G1 = list(V = 1, nu = 0.002))\n)\nset.seed(20232023)\ncbpp_mcmcglmm &lt;- MCMCglmm::MCMCglmm(\n  cbind(incidence, size - incidence) ~ period, random = ~herd, prior = prior2,\n  data = cbpp, family = \"multinomial2\", verbose = FALSE\n)\nsummary(cbpp_mcmcglmm)\n\n#&gt; \n#&gt;  Iterations = 3001:12991\n#&gt;  Thinning interval  = 10\n#&gt;  Sample size  = 1000 \n#&gt; \n#&gt;  DIC: 536.3978 \n#&gt; \n#&gt;  G-structure:  ~herd\n#&gt; \n#&gt;      post.mean  l-95% CI u-95% CI eff.samp\n#&gt; herd   0.09136 0.0001426   0.4399    312.5\n#&gt; \n#&gt;  R-structure:  ~units\n#&gt; \n#&gt;       post.mean l-95% CI u-95% CI eff.samp\n#&gt; units         1        1        1        0\n#&gt; \n#&gt;  Location effects: cbind(incidence, size - incidence) ~ period \n#&gt; \n#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n#&gt; (Intercept)   -1.5568  -2.1070  -0.8795    841.0 &lt;0.001 ***\n#&gt; period2       -1.2424  -2.2081  -0.1868    843.2  0.014 *  \n#&gt; period3       -1.3416  -2.4066  -0.3783    888.0  0.006 ** \n#&gt; period4       -1.8745  -3.1598  -0.7545    644.5 &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n下面对结果进行调整\n\n# 调整常数\nc2 &lt;- ((16 * sqrt(3)) / (15 * pi))^2\n# 固定效应\ncbpp_sol_adj &lt;- cbpp_mcmcglmm$Sol / sqrt(1 + c2 * cbpp_mcmcglmm$VCV[, 2])\nsummary(cbpp_sol_adj)\n\n#&gt; \n#&gt; Iterations = 3001:12991\n#&gt; Thinning interval = 10 \n#&gt; Number of chains = 1 \n#&gt; Sample size per chain = 1000 \n#&gt; \n#&gt; 1. Empirical mean and standard deviation for each variable,\n#&gt;    plus standard error of the mean:\n#&gt; \n#&gt;               Mean     SD Naive SE Time-series SE\n#&gt; (Intercept) -1.342 0.2831 0.008953       0.009763\n#&gt; period2     -1.071 0.4468 0.014128       0.015386\n#&gt; period3     -1.156 0.4603 0.014555       0.015445\n#&gt; period4     -1.616 0.5256 0.016621       0.020703\n#&gt; \n#&gt; 2. Quantiles for each variable:\n#&gt; \n#&gt;               2.5%    25%    50%     75%   97.5%\n#&gt; (Intercept) -1.847 -1.552 -1.347 -1.1431 -0.7918\n#&gt; period2     -1.921 -1.352 -1.061 -0.7827 -0.1840\n#&gt; period3     -2.066 -1.478 -1.136 -0.8395 -0.3173\n#&gt; period4     -2.702 -1.970 -1.608 -1.2584 -0.5811\n\n# 方差成分\ncbpp_vcv_adj &lt;- cbpp_mcmcglmm$VCV / (1 + c2 * cbpp_mcmcglmm$VCV[, 2])\nsummary(cbpp_vcv_adj)\n\n#&gt; \n#&gt; Iterations = 3001:12991\n#&gt; Thinning interval = 10 \n#&gt; Number of chains = 1 \n#&gt; Sample size per chain = 1000 \n#&gt; \n#&gt; 1. Empirical mean and standard deviation for each variable,\n#&gt;    plus standard error of the mean:\n#&gt; \n#&gt;          Mean     SD Naive SE Time-series SE\n#&gt; herd  0.06788 0.1335 0.004221        0.00755\n#&gt; units 0.74303 0.0000 0.000000        0.00000\n#&gt; \n#&gt; 2. Quantiles for each variable:\n#&gt; \n#&gt;            2.5%      25%     50%     75%  97.5%\n#&gt; herd  0.0005777 0.004345 0.01809 0.07155 0.4584\n#&gt; units 0.7430287 0.743029 0.74303 0.74303 0.7430\n\n\n可以看到，调整后固定效应的部分和前面 lme4 等的输出非常接近，方差成分仍有差距。\n\n36.2.9 INLA\n表示二项分布，公式语法与前面的 brms 包和 lme4 等包都不同。\n\ncbpp_inla &lt;- inla(\n  formula = incidence ~ period + f(herd, model = \"iid\", n = 15),\n  Ntrials = size, family = \"binomial\", data = cbpp\n)\nsummary(cbpp_inla)\n\n#&gt; Fixed effects:\n#&gt;               mean    sd 0.025quant 0.5quant 0.975quant   mode kld\n#&gt; (Intercept) -1.382 0.224     -1.845   -1.375     -0.957 -1.375   0\n#&gt; period2     -1.032 0.304     -1.628   -1.032     -0.434 -1.032   0\n#&gt; period3     -1.174 0.324     -1.809   -1.174     -0.537 -1.174   0\n#&gt; period4     -1.662 0.425     -2.495   -1.662     -0.827 -1.662   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                    mean   sd 0.025quant 0.5quant 0.975quant mode\n#&gt; Precision for herd 5.10 6.39       1.02     3.29      18.55 2.17\n#&gt; \n#&gt;  is computed",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html#sec-nlmm",
    "href": "mixed-effects-models.html#sec-nlmm",
    "title": "36  混合效应模型",
    "section": "\n36.3 非线性混合效应模型",
    "text": "36.3 非线性混合效应模型\nLoblolly 数据集来自 R 内置的 datasets 包，记录了 14 颗火炬树种子的生长情况。\n\n\n\n表格 36.2: Loblolly 数据集\n\n\n\n\nSeed\n3\n5\n10\n15\n20\n25\n\n\n\n301\n4.51\n10.89\n28.72\n41.74\n52.70\n60.92\n\n\n303\n4.55\n10.92\n29.07\n42.83\n53.88\n63.39\n\n\n305\n4.79\n11.37\n30.21\n44.40\n55.82\n64.10\n\n\n307\n3.91\n9.48\n25.66\n39.07\n50.78\n59.07\n\n\n309\n4.81\n11.20\n28.66\n41.66\n53.31\n63.05\n\n\n311\n3.88\n9.40\n25.99\n39.55\n51.46\n59.64\n\n\n315\n4.32\n10.43\n27.16\n40.85\n51.33\n60.07\n\n\n319\n4.57\n10.57\n27.90\n41.13\n52.43\n60.69\n\n\n321\n3.77\n9.03\n25.45\n38.98\n49.76\n60.28\n\n\n323\n4.33\n10.79\n28.97\n42.44\n53.17\n61.62\n\n\n325\n4.38\n10.48\n27.93\n40.20\n50.06\n58.49\n\n\n327\n4.12\n9.92\n26.54\n37.82\n48.43\n56.81\n\n\n329\n3.93\n9.34\n26.08\n37.79\n48.31\n56.43\n\n\n331\n3.46\n9.05\n25.85\n39.15\n49.12\n59.49\n\n\n\n\n\n\n\n\n火炬树种子基本决定了树的长势，不同种子预示最后的高度，并且在生长期也是很稳定地生长\n\nggplot(data = Loblolly, aes(x = age, y = height, color = Seed)) +\n  geom_point() +\n  geom_line() +\n  theme_bw() +\n  labs(x = \"age (yr)\", y = \"height (ft)\")\n\n\n\n\n\n\n图 36.5: 火炬松树的高度（英尺）随时间（年）的变化\n\n\n\n\n\n36.3.1 nlme\n非线性回归\n\nnfm1 &lt;- nls(height ~ SSasymp(age, Asym, R0, lrc),\n           data = Loblolly, subset = Seed == 329)\nsummary(nfm1)\n\n#&gt; \n#&gt; Formula: height ~ SSasymp(age, Asym, R0, lrc)\n#&gt; \n#&gt; Parameters:\n#&gt;      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; Asym  94.1282     8.4030  11.202 0.001525 ** \n#&gt; R0    -8.2508     1.2261  -6.729 0.006700 ** \n#&gt; lrc   -3.2176     0.1386 -23.218 0.000175 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7493 on 3 degrees of freedom\n#&gt; \n#&gt; Number of iterations to convergence: 0 \n#&gt; Achieved convergence tolerance: 3.972e-07\n\n\n非线性函数 SSasymp() 的内容如下\n\\[\n\\mathrm{Asym}+(\\mathrm{R0}-\\mathrm{Asym})\\times\\exp\\big(-\\exp(\\mathrm{lrc})\\times\\mathrm{input}\\big)\n\\]\n其中，\\(\\mathrm{Asym}\\) 、\\(\\mathrm{R0}\\) 、\\(\\mathrm{lrc}\\) 是参数，\\(\\mathrm{input}\\) 是输入值。\n示例来自 nlme 包的函数 nlme() 帮助文档\n\nnfm2 &lt;- nlme(height ~ SSasymp(age, Asym, R0, lrc),\n  data = Loblolly,\n  fixed = Asym + R0 + lrc ~ 1,\n  random = Asym ~ 1,\n  start = c(Asym = 103, R0 = -8.5, lrc = -3.3)\n)\nsummary(nfm2)\n\n#&gt; Nonlinear mixed-effects model fit by maximum likelihood\n#&gt;   Model: height ~ SSasymp(age, Asym, R0, lrc) \n#&gt;   Data: Loblolly \n#&gt;        AIC      BIC    logLik\n#&gt;   239.4856 251.6397 -114.7428\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: Asym ~ 1 | Seed\n#&gt;             Asym  Residual\n#&gt; StdDev: 3.650642 0.7188625\n#&gt; \n#&gt; Fixed effects:  Asym + R0 + lrc ~ 1 \n#&gt;          Value Std.Error DF   t-value p-value\n#&gt; Asym 101.44960 2.4616951 68  41.21128       0\n#&gt; R0    -8.62733 0.3179505 68 -27.13420       0\n#&gt; lrc   -3.23375 0.0342702 68 -94.36052       0\n#&gt;  Correlation: \n#&gt;     Asym   R0    \n#&gt; R0   0.704       \n#&gt; lrc -0.908 -0.827\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -2.23601930 -0.62380854  0.05917466  0.65727206  1.95794425 \n#&gt; \n#&gt; Number of Observations: 84\n#&gt; Number of Groups: 14\n\n# 更新模型的随机效应部分\nnfm3 &lt;- update(nfm2, random = pdDiag(Asym + lrc ~ 1))\nsummary(nfm3)\n\n#&gt; Nonlinear mixed-effects model fit by maximum likelihood\n#&gt;   Model: height ~ SSasymp(age, Asym, R0, lrc) \n#&gt;   Data: Loblolly \n#&gt;        AIC      BIC    logLik\n#&gt;   238.9662 253.5511 -113.4831\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: list(Asym ~ 1, lrc ~ 1)\n#&gt;  Level: Seed\n#&gt;  Structure: Diagonal\n#&gt;             Asym        lrc  Residual\n#&gt; StdDev: 2.806185 0.03449969 0.6920003\n#&gt; \n#&gt; Fixed effects:  Asym + R0 + lrc ~ 1 \n#&gt;          Value Std.Error DF   t-value p-value\n#&gt; Asym 101.85205 2.3239828 68  43.82651       0\n#&gt; R0    -8.59039 0.3058441 68 -28.08747       0\n#&gt; lrc   -3.24011 0.0345017 68 -93.91167       0\n#&gt;  Correlation: \n#&gt;     Asym   R0    \n#&gt; R0   0.727       \n#&gt; lrc -0.902 -0.796\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -2.06072906 -0.69785679  0.08721706  0.73687722  1.79015782 \n#&gt; \n#&gt; Number of Observations: 84\n#&gt; Number of Groups: 14\n\n\n\n36.3.2 lme4\nlme4 的公式语法是与 nlme 包不同的。\n\nlob_lme4 &lt;- lme4::nlmer(\n  height ~ SSasymp(age, Asym, R0, lrc) ~ (Asym + R0 + lrc) + (Asym | Seed),\n  data = Loblolly,\n  start = c(Asym = 103, R0 = -8.5, lrc = -3.3)\n)\nsummary(lob_lme4)\n\n#&gt; Nonlinear mixed model fit by maximum likelihood  ['nlmerMod']\n#&gt; Formula: height ~ SSasymp(age, Asym, R0, lrc) ~ (Asym + R0 + lrc) + (Asym |  \n#&gt;     Seed)\n#&gt;    Data: Loblolly\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;    239.4    251.5   -114.7    229.4       79 \n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -2.24149 -0.62546  0.08326  0.67711  1.91351 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name Variance Std.Dev.\n#&gt;  Seed     Asym 13.5121  3.6759  \n#&gt;  Residual       0.5161  0.7184  \n#&gt; Number of obs: 84, groups:  Seed, 14\n#&gt; \n#&gt; Fixed effects:\n#&gt;        Estimate Std. Error t value\n#&gt; Asym 102.119832   0.012378  8249.9\n#&gt; R0    -8.549401   0.012354  -692.0\n#&gt; lrc   -3.243973   0.008208  -395.2\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     Asym   R0    \n#&gt; R0   0.000       \n#&gt; lrc -0.008 -0.034\n\n\n\n36.3.3 brms\n根据数据的情况，设定参数的先验分布\n\nlob_prior &lt;- c(\n  brms::set_prior(\"normal(101, 0.1)\", nlpar = \"Asym\", lb = 100, ub = 102),\n  brms::set_prior(\"normal(-8, 1)\", nlpar = \"R0\", lb = -10),\n  brms::set_prior(\"normal(-3, 3)\", nlpar = \"lrc\", lb = -9),\n  brms::set_prior(\"normal(3, 0.2)\", class = \"sigma\")\n)\n\n根据模型表达式编码\n\nlob_formula &lt;- brms::bf(\n  height ~ Asym + (R0 - Asym) * exp( - exp(lrc) * age),\n  # Nonlinear variables\n  # Fixed effects: Asym R0 lrc\n  R0 + lrc ~ 1,\n  # Nonlinear variables\n  # Random effects: Seed\n  Asym ~ 1 + (1 | Seed),\n  # Nonlinear fit\n  nl = TRUE\n)\n\n\nlob_brms &lt;- brms::brm(lob_formula, data = Loblolly, prior = lob_prior)\nsummary(lob_brms)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height ~ Asym + (R0 - Asym) * exp(-exp(lrc) * age) \n         R0 ~ 1\n         lrc ~ 1\n         Asym ~ 1 + (1 | Seed)\n   Data: Loblolly (Number of observations: 84) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Seed (Number of levels: 14) \n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Asym_Intercept)     3.90      1.09     2.24     6.51 1.00     1033     1647\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nR0_Intercept      -8.53      0.43    -9.37    -7.68 1.00     2236     1434\nlrc_Intercept     -3.23      0.02    -3.27    -3.20 1.00      981     1546\nAsym_Intercept   101.00      0.10   100.80   101.20 1.00     4443     2907\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.68      0.25     1.20     2.17 1.00     1910     2258\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html#sec-mixed-effects-simulation",
    "href": "mixed-effects-models.html#sec-mixed-effects-simulation",
    "title": "36  混合效应模型",
    "section": "\n36.4 模拟实验比较（补充）",
    "text": "36.4 模拟实验比较（补充）\n从广义线性混合效应模型生成模拟数据，用至少 6 个不同的 R 包估计模型参数，比较和归纳不同估计方法和实现算法的效果。举例：带漂移项的泊松型广义线性混合效应模型。\\(y_{ij}\\) 表示响应变量，\\(\\bm{u}\\) 表示随机效应，\\(o_{ij}\\) 表示漂移项。\n\\[\n\\begin{aligned}\ny_{ij}|\\bm{u} &\\sim \\mathrm{Poisson}(o_{ij}\\lambda_{ij}) \\\\\n\\log(\\lambda_{ij}) &= \\beta_{ij}x_{ij} + u_{j} \\\\\nu_j &\\sim \\mathcal{N}(0, \\sigma^2) \\\\\ni = 1,2,\\ldots, n &\\quad j = 1,2,\\ldots,q\n\\end{aligned}\n\\]\n首先准备数据\n\nset.seed(2023)\nNgroups &lt;- 25 # 一个随机效应分 25 个组\nNperGroup &lt;- 100 # 每个组 100 个观察值\n# 样本量\nN &lt;- Ngroups * NperGroup\n# 截距和两个协变量的系数\nbeta &lt;- c(0.5, 0.3, 0.2)\n# 两个协变量\nX &lt;- MASS::mvrnorm(N, mu = rep(0, 2), Sigma = matrix(c(1, 0.8, 0.8, 1), 2))\n# 漂移项\no &lt;- rep(c(2, 4), each = N / 2)\n# 分 25 个组 每个组 100 个观察值\ng &lt;- factor(rep(1:Ngroups, each = NperGroup))\nu &lt;- rnorm(Ngroups, sd = .5) # 随机效应的标准差 0.5\n# 泊松分布的期望\nlambda &lt;- o * exp(cbind(1, X) %*% beta + u[g])\n# 响应变量的值\ny &lt;- rpois(N, lambda = lambda)\n# 模拟的数据集\nsim_data &lt;- data.frame(y, X, o, g)\ncolnames(sim_data) &lt;- c(\"y\", \"x1\", \"x2\", \"o\", \"g\")\n\n\n36.4.1 lme4\n\n# 模型拟合\nfit_lme4 &lt;- lme4::glmer(y ~ x1 + x2 + (1 | g),\n  data = sim_data, offset = log(o), family = poisson(link = \"log\")\n)\nsummary(fit_lme4)\n\n#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace\n#&gt;   Approximation) [glmerMod]\n#&gt;  Family: poisson  ( log )\n#&gt; Formula: y ~ x1 + x2 + (1 | g)\n#&gt;    Data: sim_data\n#&gt;  Offset: log(o)\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;  11065.6  11088.9  -5528.8  11057.6     2496 \n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.0650 -0.7177 -0.0827  0.6334  4.0103 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups Name        Variance Std.Dev.\n#&gt;  g      (Intercept) 0.4074   0.6383  \n#&gt; Number of obs: 2500, groups:  g, 25\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  0.55608    0.12805   4.343 1.41e-05 ***\n#&gt; x1           0.28442    0.01280  22.214  &lt; 2e-16 ***\n#&gt; x2           0.20851    0.01294  16.117  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;    (Intr) x1    \n#&gt; x1 -0.008       \n#&gt; x2 -0.008 -0.821\n\n\n\n36.4.2 GLMMadaptive\n对随机效应采用 adaptive Gauss-Hermite quadrature 积分\n\nlibrary(GLMMadaptive)\nfit_glmmadaptive &lt;- mixed_model(\n  fixed = y ~ x1 + x2 + offset(log(o)), \n  random = ~ 1 | g, data = sim_data,\n  family = poisson(link = \"log\")\n)\nsummary(fit_glmmadaptive)\n\n#&gt; \n#&gt; Call:\n#&gt; mixed_model(fixed = y ~ x1 + x2 + offset(log(o)), random = ~1 | \n#&gt;     g, data = sim_data, family = poisson(link = \"log\"))\n#&gt; \n#&gt; Data Descriptives:\n#&gt; Number of Observations: 2500\n#&gt; Number of Groups: 25 \n#&gt; \n#&gt; Model:\n#&gt;  family: poisson\n#&gt;  link: log \n#&gt; \n#&gt; Fit statistics:\n#&gt;   log.Lik      AIC      BIC\n#&gt;  -5528.78 11065.56 11070.44\n#&gt; \n#&gt; Random effects covariance matrix:\n#&gt;                StdDev\n#&gt; (Intercept) 0.6417329\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std.Err z-value p-value\n#&gt; (Intercept)   0.5647  0.1288  4.3863 &lt; 1e-04\n#&gt; x1            0.2844  0.0128 22.2059 &lt; 1e-04\n#&gt; x2            0.2085  0.0129 16.1096 &lt; 1e-04\n#&gt; \n#&gt; Integration:\n#&gt; method: adaptive Gauss-Hermite quadrature rule\n#&gt; quadrature points: 11\n#&gt; \n#&gt; Optimization:\n#&gt; method: hybrid EM and quasi-Newton\n#&gt; converged: TRUE\n\n\n\n36.4.3 glmmTMB\n\nfit_glmmtmb &lt;- glmmTMB::glmmTMB(\n  y ~ x1 + x2 + (1 | g), offset = log(o),\n  data = sim_data, family = poisson, REML = TRUE\n)\nsummary(fit_glmmtmb)\n\n#&gt;  Family: poisson  ( log )\n#&gt; Formula:          y ~ x1 + x2 + (1 | g)\n#&gt; Data: sim_data\n#&gt;  Offset: log(o)\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;  11082.7  11106.0  -5537.3  11074.7     2499 \n#&gt; \n#&gt; Random effects:\n#&gt; \n#&gt; Conditional model:\n#&gt;  Groups Name        Variance Std.Dev.\n#&gt;  g      (Intercept) 0.4245   0.6515  \n#&gt; Number of obs: 2500, groups:  g, 25\n#&gt; \n#&gt; Conditional model:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  0.55710    0.13069   4.263 2.02e-05 ***\n#&gt; x1           0.28442    0.01281  22.206  &lt; 2e-16 ***\n#&gt; x2           0.20851    0.01294  16.111  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n36.4.4 hglm\nhglm 包的名称是 Hierarchical Generalized Linear Models 的首字母缩写拼成的。\n\n# extended quasi likelihood (EQL) method\nfit_hglm &lt;- hglm::hglm(\n  fixed =  y ~ x1 + x2, random = ~ 1 | g,\n  family = poisson(link = \"log\"), \n  offset = log(o), data = sim_data\n)\nsummary(fit_hglm)\n\n#&gt; Call: \n#&gt; hglm.formula(family = poisson(link = \"log\"), fixed = y ~ x1 + \n#&gt;     x2, random = ~1 | g, data = sim_data, offset = log(o))\n#&gt; \n#&gt; ----------\n#&gt; MEAN MODEL\n#&gt; ----------\n#&gt; \n#&gt; Summary of the fixed effects estimates:\n#&gt; \n#&gt;             Estimate Std. Error t-value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.55720    0.13058   4.267 2.05e-05 ***\n#&gt; x1           0.28442    0.01316  21.609  &lt; 2e-16 ***\n#&gt; x2           0.20851    0.01330  15.678  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; Note: P-values are based on 2473 degrees of freedom\n#&gt; \n#&gt; Summary of the random effects estimates:\n#&gt; \n#&gt;    Estimate Std. Error\n#&gt; g1   0.6643     0.1352\n#&gt; g2  -0.1421     0.1402\n#&gt; g3   0.9560     0.1344\n#&gt; ...\n#&gt; NOTE: to show all the random effects, use print(summary(hglm.object), print.ranef = TRUE).\n#&gt; \n#&gt; ----------------\n#&gt; DISPERSION MODEL\n#&gt; ----------------\n#&gt; \n#&gt; NOTE: h-likelihood estimates through EQL can be biased.\n#&gt; \n#&gt; Dispersion parameter for the mean model:\n#&gt; [1] 1.055997\n#&gt; \n#&gt; Model estimates for the dispersion term:\n#&gt; \n#&gt; Link = log \n#&gt; \n#&gt; Effects:\n#&gt;   Estimate Std. Error \n#&gt;     0.0545     0.0284 \n#&gt; \n#&gt; Dispersion = 1 is used in Gamma model on deviances to calculate the standard error(s).\n#&gt; \n#&gt; Dispersion parameter for the random effects:\n#&gt; [1] 0.4236\n#&gt; \n#&gt; Dispersion model for the random effects:\n#&gt; \n#&gt; Link = log\n#&gt; \n#&gt; Effects:\n#&gt; .|Random1 \n#&gt;   Estimate Std. Error \n#&gt;    -0.8589     0.2895 \n#&gt; \n#&gt; Dispersion = 1 is used in Gamma model on deviances to calculate the standard error(s).\n#&gt; \n#&gt; EQL estimation converged in 3 iterations.\n#&gt; \n#&gt; !! Observation 302 is too influential! Estimates are likely unreliable !!\n\n\n\n36.4.5 glmmML\nglmmML 包 Maximum Likelihood and numerical integration via Gauss-Hermite quadrature\n\nfit_glmmml &lt;- glmmML::glmmML(\n  formula = y ~ x1 + x2, family = poisson,\n  data = sim_data, offset = log(o), cluster = g\n)\nsummary(fit_glmmml)\n\nCall:  glmmML::glmmML(formula = y ~ x1 + x2, family = poisson, data = sim_data,      cluster = g, offset = log(o)) \n\n\n             coef se(coef)     z Pr(&gt;|z|)\n(Intercept) 0.556   0.1281  4.34  1.4e-05\nx1          0.284   0.0128 22.21  0.0e+00\nx2          0.209   0.0129 16.11  0.0e+00\n\nScale parameter in mixing distribution:  0.638 gaussian \nStd. Error:                              0.0865 \n\n        LR p-value for H_0: sigma = 0:  0 \n\nResidual deviance: 2770 on 2496 degrees of freedom  AIC: 2780 \n\n36.4.6 glmm\nglmm 包对随机效应的积分采用 Monte Carlo Likelihood Approximation 近似\n\n# 对迭代时间没有给出预估，一旦执行，不知道什么时候会跑完\nset.seed(2023)\n# 设置双核并行迭代\nclust &lt;- parallel::makeCluster(2)\nfit_glmm &lt;- glmm::glmm(y ~ x1 + x2 + offset(log(o)),\n  random = list(~ 1 + g), # 随机效应\n  varcomps.names = \"G\", # 给随机效应取个名字\n  data = sim_data,\n  family.glmm = glmm::poisson.glmm, # 泊松型\n  m = 10^4, debug = TRUE, cluster = clust\n)\nparallel::stopCluster(clust)\nsummary(fit_glmm)\n\nglmm 包的帮助文档中的示例如下，可复现结果，运行时间 1-2 分钟。\n\nset.seed(1234)\nclust &lt;- makeCluster(2)\nsal &lt;- glmm(\n  Mate ~ 0 + Cross, random = list(~ 0 + Female, ~ 0 + Male),\n  varcomps.names = c(\"F\", \"M\"), data = salamander,\n  family.glmm = bernoulli.glmm, m = 10^4, debug = TRUE, cluster = clust\n)\nsummary(sal)\nstopCluster(clust)\n\nCall:\nglmm(fixed = Mate ~ 0 + Cross, random = list(~0 + Female, ~0 + Male), \n    varcomps.names = c(\"F\", \"M\"), data = salamander, \n    family.glmm = bernoulli.glmm, m = 10^4, debug = TRUE, cluster = clust)\n\nLink is: \"logit (log odds)\"\n\nFixed Effects:\n         Estimate Std. Error z value Pr(&gt;|z|)    \nCrossR/R    1.230      0.300   4.045 5.24e-05 ***\nCrossR/W    0.320      0.267   1.198  0.23077    \nCrossW/R   -2.000      0.330  -6.042 1.52e-09 ***\nCrossW/W    0.920      0.300   3.084  0.00204 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nVariance Components for Random Effects (P-values are one-tailed):\n  Estimate Std. Error z value Pr(&gt;|z|)/2    \nF     1.46       0.31   4.695   1.33e-06 ***\nM     1.64       0.33   4.918   4.36e-07 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n36.4.7 gee\ngee 包采用广义估计方程（Generalized Estimation Equation）方法\n\nfit_gee &lt;- gee::gee(y ~ x1 + x2 + offset(log(o)), id = g, \n  data = sim_data, family = poisson(link = \"log\"), corstr = \"exchangeable\"\n)\n# 输出\nfit_gee\n\n GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n gee S-function, version 4.13 modified 98/01/27 (1998) \n\nModel:\n Link:                      Logarithm \n Variance to Mean Relation: Poisson \n Correlation Structure:     Exchangeable \n\nCall:\ngee::gee(formula = y ~ x1 + x2 + offset(log(o)), id = g, data = sim_data, \n    family = poisson(link = \"log\"), corstr = \"exchangeable\")\n\nNumber of observations :  2500 \nMaximum cluster size   :  100 \n\nCoefficients:\n(Intercept)          x1          x2 \n  0.6098935   0.3003721   0.2165055 \n\nEstimated Scale Parameter:  4.979956\nNumber of Iterations:  3\n\nWorking Correlation[1:4,1:4]\n          [,1]      [,2]      [,3]      [,4]\n[1,] 1.0000000 0.7220617 0.7220617 0.7220617\n[2,] 0.7220617 1.0000000 0.7220617 0.7220617\n[3,] 0.7220617 0.7220617 1.0000000 0.7220617\n[4,] 0.7220617 0.7220617 0.7220617 1.0000000\n\nReturned Error Value:\n[1] 0\n输出结果中，尺度参数（Estimated Scale Parameter）的估计结果与随机效应的方差的联系？\n\n36.4.8 geepack\ngeepack 包类似 gee 包。\n\nfit_geepack &lt;- geepack::geeglm(\n  formula = y ~ x1 + x2, family = poisson(link = \"log\"),\n  id = g, offset = log(o), data = sim_data,\n  corstr = \"exchangeable\", scale.fix = FALSE\n)\nsummary(fit_geepack)\n\nCall:\ngeepack::geeglm(formula = y ~ x1 + x2, family = poisson(link = \"log\"), \n    data = sim_data, offset = log(o), id = g, corstr = \"exchangeable\", \n    scale.fix = FALSE)\n\n Coefficients:\n            Estimate Std.err  Wald Pr(&gt;|W|)    \n(Intercept)  0.60964 0.17310  12.4 0.000428 ***\nx1           0.30040 0.02353 163.1  &lt; 2e-16 ***\nx2           0.21653 0.01458 220.6  &lt; 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)    4.975    1.39\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha    0.723 0.06703\nNumber of clusters:   25  Maximum cluster size: 100 \n\n36.4.9 blme\nblme 包采用贝叶斯估计\n\nfit_blme &lt;- blme::bglmer(\n  formula = y ~ x1 + x2 + (1 | g),\n  data = sim_data, offset = log(o),\n  family = poisson(link = \"log\")\n)\nsummary(fit_blme)\n\n#&gt; Cov prior  : g ~ wishart(df = 3.5, scale = Inf, posterior.scale = cov, common.scale = TRUE)\n#&gt; Prior dev  : 1.2531\n#&gt; \n#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace\n#&gt;   Approximation) [bglmerMod]\n#&gt;  Family: poisson  ( log )\n#&gt; Formula: y ~ x1 + x2 + (1 | g)\n#&gt;    Data: sim_data\n#&gt;  Offset: log(o)\n#&gt; \n#&gt;      AIC      BIC   logLik deviance df.resid \n#&gt;  11065.6  11088.9  -5528.8  11057.6     2496 \n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.0651 -0.7180 -0.0816  0.6335  4.0103 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups Name        Variance Std.Dev.\n#&gt;  g      (Intercept) 0.4337   0.6586  \n#&gt; Number of obs: 2500, groups:  g, 25\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  0.55595    0.13209   4.209 2.57e-05 ***\n#&gt; x1           0.28442    0.01280  22.214  &lt; 2e-16 ***\n#&gt; x2           0.20851    0.01294  16.117  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;    (Intr) x1    \n#&gt; x1 -0.008       \n#&gt; x2 -0.007 -0.821\n\n\nGLMMadaptive、glmmML、gee、geepack 和 lme4 的模型输出结果是接近的。\n\n36.4.10 brms\n\nfit_brms &lt;- brms::brm(\n  y ~ x1 + x2 + (1 | g) + offset(log(o)),\n  data = sim_data, family = poisson(link = \"log\"),\n  silent = 2, refresh = 0, seed = 20232023\n)\nsummary(fit_brms)\n\n Family: poisson \n  Links: mu = log \nFormula: y ~ x1 + x2 + (1 | g) + offset(log(o)) \n   Data: sim_data (Number of observations: 2500) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~g (Number of levels: 25) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.68      0.11     0.51     0.94 1.01      295      491\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.56      0.14     0.31     0.85 1.02      297      344\nx1            0.28      0.01     0.26     0.31 1.00     1053     1625\nx2            0.21      0.01     0.18     0.23 1.01     1071     1298\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n36.4.11 MCMCglmm\nMCMCglmm 包采用贝叶斯估计\n\nprior1 &lt;- list(\n  R = list(V = 1, fix = 1), \n  G = list(G1 = list(V = 1, nu = 0.002))\n)\nset.seed(20232023)\nfit_mcmcglmm &lt;- MCMCglmm::MCMCglmm(\n  fixed = y ~ x1 + x2 + offset(log(o)),\n  random = ~g, family = \"poisson\", \n  data = sim_data, verbose = FALSE, prior = prior1\n)\nsummary(fit_mcmcglmm)\n\n#&gt; \n#&gt;  Iterations = 3001:12991\n#&gt;  Thinning interval  = 10\n#&gt;  Sample size  = 1000 \n#&gt; \n#&gt;  DIC: 12397.82 \n#&gt; \n#&gt;  G-structure:  ~g\n#&gt; \n#&gt;   post.mean l-95% CI u-95% CI eff.samp\n#&gt; g    0.5443   0.2753   0.8924     1000\n#&gt; \n#&gt;  R-structure:  ~units\n#&gt; \n#&gt;       post.mean l-95% CI u-95% CI eff.samp\n#&gt; units         1        1        1        0\n#&gt; \n#&gt;  Location effects: y ~ x1 + x2 + offset(log(o)) \n#&gt; \n#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n#&gt; (Intercept)    1.4315   1.1536   1.7161   1000.0 &lt;0.001 ***\n#&gt; x1             0.3099   0.2405   0.3892    925.6 &lt;0.001 ***\n#&gt; x2             0.2234   0.1465   0.3017    877.7 &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n随机效应的方差 G-structure 为 0.5443，则标准差为 0.738。\n对于离散型响应变量，MCMCglmm 包默认添加一个可加的随机变量表示过度离散，如何将其去掉？将残差方差设置为常数，不再作为参数去估计，fix = 1 表示在 R-structure 中固定方差， V = 1 表示残差方差为 1。\n\n# 固定效应参数的后验分布\n# plot(fit_mcmcglmm$Sol)\nplot(fit_mcmcglmm$VCV)\n\n\n\n\n\n\n图 36.6: 方差协方差参数的后验分布\n\n\n\n\n根据响应变量的服从的分布类型，确定调整因子。固定效应乘以调整因子的平方根，随机效应的方差乘以调整因子，详见 (Peter Diggle 和 Zeger 2002) 第 136-137 页。二项分布联系函数对应的调整因子如下：\n\\[\n\\frac{1 + c^2\\sigma^2_{\\epsilon}}{1 + c^2\\sigma^2_{\\mathrm{units}}}\n\\]\n其中， \\(c\\) 是与联系函数有关的常数，二项分布联系函数对应 \\(c = 16\\sqrt{3}/(15\\pi)\\)。此处，假定 \\(\\sigma^2_{\\epsilon} = 0\\) ，代入泊松分布对应的调整因子。调整后的固定效应（回归系数）、随机效应的方差如下：\n\n# 调整公式中的调整因子 c2 取决于联系函数\nc2 &lt;- ((16 * sqrt(3))/(15 * pi))^2 # 需要修改为泊松分布对应的值\n# 固定效应的调整\nadjusted_sol &lt;- fit_mcmcglmm$Sol / sqrt(1 + c2 * fit_mcmcglmm$VCV[, 2])\nplot(adjusted_sol)\n# 随机效应的方差调整\nadjusted_vcv &lt;- fit_mcmcglmm$VCV[, 1] / (1 + c2 * fit_mcmcglmm$VCV[, 2])\nplot(adjusted_vcv)\n\n\n36.4.12 INLA\n\nlibrary(INLA)\nfit_inla &lt;- inla(\n  formula = y ~ x1 + x2 + f(g, model = \"iid\", n = 25),\n  E = o, family = \"poisson\", data = sim_data\n)\nsummary(fit_inla)\n\n#&gt; Fixed effects:\n#&gt;              mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; (Intercept) 0.556 0.130      0.300    0.556      0.812 0.556   0\n#&gt; x1          0.284 0.013      0.259    0.284      0.310 0.284   0\n#&gt; x2          0.209 0.013      0.183    0.209      0.234 0.209   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                 mean    sd 0.025quant 0.5quant 0.975quant mode\n#&gt; Precision for g 2.56 0.713       1.36     2.49       4.14 2.36\n#&gt; \n#&gt;  is computed\n\n\n随机效应的标准（偏）差为 \\(1/\\sqrt{\\mathrm{Precision}}\\) ，即 0.625。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html#sec-mixed-effects-summary",
    "href": "mixed-effects-models.html#sec-mixed-effects-summary",
    "title": "36  混合效应模型",
    "section": "\n36.5 总结",
    "text": "36.5 总结\n本章介绍函数 MASS::glmmPQL()、 nlme::lme()、lme4::lmer() 和 brms::brm() 的用法，以及它们求解线性混合效应模型的区别和联系。在贝叶斯估计方法中，brms 包和 INLA 包都支持非常丰富的模型种类，前者是贝叶斯精确推断，后者是贝叶斯近似推断，brms 基于概率编程语言 Stan 框架打包了许多模型的 Stan 实现，INLA 基于求解随机偏微分方程的有限元方法和拉普拉斯近似技巧，将各类常见统计模型统一起来，计算速度快，计算结果准确。\n\n函数 nlme::lme() 提供极大似然估计和限制极大似然估计。\n函数 MASS::glmmPQL() 惩罚拟似然估计，MASS 是依赖 nlme 包， nlme 不支持模型中添加漂移项，所以函数 glmmPQL() 也不支持添加漂移项。\n函数 lme4::lmer() 拉普拉斯近似关于随机效应的高维积分。\n函数 brms::brm() 汉密尔顿蒙特卡罗抽样。HMC 方法结合自适应步长的采样器 NUTS 来抽样。\n函数 INLA::inla() 集成嵌套拉普拉斯近似。\n\n\n\n表格 36.3: 混合效应模型及相关 R 包拟合函数\n\n\n\n\n\n\n\n\n\n\n\n模型\nnlme\nMASS\nlme4\nGLMMadaptive\nbrms\n\n\n\n线性混合效应模型\nlme()\nglmmPQL()\nlmer()\n不支持\nbrm()\n\n\n广义线性混合效应模型\n不支持\nglmmPQL()\nglmer()\nmixed_model()\nbrm()\n\n\n非线性混合效应模型\nnlme()\n不支持\nnlmer()\n不支持\nbrm()\n\n\n\n\n\n\n通过对频率派和贝叶斯派方法的比较，发现一些有意思的结果。与 Stan 不同，INLA 包做近似贝叶斯推断，计算效率很高。\nINLA 软件能处理上千个高斯随机效应，但最多只能处理 15 个超参数，因为 INLA 使用 CCD 处理超参数。如果使用 MCMC 处理超参数，就有可能处理更多的超参数，Daniel Simpson 等把 Laplace approximation 带入 Stan，这样就可以处理上千个超参数。 更多理论内容见 2009 年 INLA 诞生的论文和《Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA》中第一章的估计方法 CCD。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html#sec-mixed-effects-models-exercise",
    "href": "mixed-effects-models.html#sec-mixed-effects-models-exercise",
    "title": "36  混合效应模型",
    "section": "\n36.6 习题",
    "text": "36.6 习题\n\n基于奥克兰火山地形数据集 volcano ，随机拆分成训练数据和测试数据，训练数据可以看作采样点的观测数据，建立高斯过程回归模型，比较测试数据与未采样的位置上的预测数据，在计算速度、准确度、易用性等方面总结 Stan 和 INLA 的特点。\n\n基于 PlantGrowth 数据集，比较将 group 变量视为随机变量与随机效应的异同？\n\nfit_lm &lt;- lm(weight ~ group, data = PlantGrowth)\nsummary(fit_lm)\nfit_lme &lt;- nlme::lme(weight ~ 1, random = ~ 1 | group, data = PlantGrowth)\nsummary(fit_lme)\nfit_lme4 &lt;- lme4::lmer(weight ~ 1 + (1 | group), data = PlantGrowth)\nsummary(fit_lme4)\n\n\n\nMASS 包的数据集 epil 记录癫痫发作的次数及病人的特征，请建立混合效应模型分析癫痫病发作的风险与病人特征之间的关系。\n\n代码data(epil, package = \"MASS\")\nepil_glm &lt;- glm(y ~ lbase * trt + lage + V4,\n  family = poisson, data = epil\n)\nsummary(epil_glm)\n\nepil_mass &lt;- MASS::glmmPQL(y ~ lbase * trt + lage + V4,\n  random = ~ 1 | subject, family = poisson, data = epil\n)\nsummary(epil_mass)\n\nepil_lme4 &lt;- lme4::glmer(\n  y ~ lbase * trt + lage + V4 + (1 | subject),\n  family = poisson, data = epil\n)\nsummary(epil_lme4)\n\nepil_glmmtmb &lt;- glmmTMB::glmmTMB(\n  y ~ lbase * trt + lage + V4 + (1 | subject),\n  data = epil, family = poisson, REML = TRUE\n)\nsummary(epil_glmmtmb)\n\nepil_glmmadaptive &lt;- GLMMadaptive::mixed_model(\n  fixed = y ~ lbase * trt + lage + V4,\n  random = ~ 1 | subject, data = epil,\n  family = poisson()\n)\nsummary(epil_glmmadaptive)\n\n\n\n\n基于数据集 Puromycin 分析酶促反应的反应速率（提示：Michaelis-Menten 模型和函数 SSmicmen()）。\n\nggplot(data = Puromycin, aes(x = conc, y = rate, color = state)) +\n  geom_point() +\n  geom_line() +\n  theme_minimal() +\n  labs(\n    x = \"Substrate concentration (ppm)\",\n    y = \"Reaction velocity (counts/min/min)\"\n  )\n\n\n\n\n\n\n图 36.7: Puromycin 反应速率变化趋势\n\n\n\n\n\n\n基于 MASS 包的地形数据集 topo，建立高斯过程回归模型，比较贝叶斯预测与克里金插值预测的效果。\n\n代码data(topo, package = \"MASS\")\nset.seed(20232023)\nnchains &lt;- 2 # 2 条迭代链\n# 给每条链设置不同的参数初始值\ninits_data_gaussian &lt;- lapply(1:nchains, function(i) {\n  list(\n    beta = rnorm(1),\n    sigma = runif(1),\n    phi = runif(1),\n    tau = runif(1)\n  )\n})\n# 预测区域网格化\nnx &lt;- ny &lt;- 27\ntopo_grid_df &lt;- expand.grid(\n  x = seq(from = 0, to = 6.5, length.out = nx),\n  y = seq(from = 0, to = 6.5, length.out = ny)\n)\n# 对数高斯模型\ntopo_gaussian_d &lt;- list(\n  N1 = nrow(topo), # 观测记录的条数\n  N2 = nrow(topo_grid_df),\n  D = 2, # 2 维坐标\n  x1 = topo[, c(\"x\", \"y\")], # N x 2 坐标矩阵\n  x2 = topo_grid_df[, c(\"x\", \"y\")],\n  y1 = topo[, \"z\"] # N 向量\n)\nlibrary(cmdstanr)\n# 编码\nmod_topo_gaussian &lt;- cmdstan_model(\n  stan_file = \"code/gaussian_process_pred.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n# 高斯过程回归模型\nfit_topo_gaussian &lt;- mod_topo_gaussian$sample(\n  data = topo_gaussian_d,   # 观测数据\n  init = inits_data_gaussian,   # 迭代初值\n  iter_warmup = 500,            # 每条链预处理迭代次数\n  iter_sampling = 1000,         # 每条链总迭代次数\n  chains = nchains,             # 马尔科夫链的数目\n  parallel_chains = 2,      # 指定 CPU 核心数，可以给每条链分配一个\n  threads_per_chain = 1,    # 每条链设置一个线程\n  show_messages = FALSE,    # 不显示迭代的中间过程\n  refresh = 0,              # 不显示采样的进度\n  output_dir = \"data-raw/\",\n  seed = 20232023           \n)\n# 诊断\nfit_topo_gaussian$diagnostic_summary()\n# 对数高斯模型\nfit_topo_gaussian$summary(\n  variables = c(\"lp__\", \"beta\", \"sigma\", \"phi\", \"tau\"),\n  .num_args = list(sigfig = 4, notation = \"dec\")\n)\n# 未采样的位置的预测值\nypred &lt;- fit_topo_gaussian$summary(variables = \"ypred\", \"mean\")\n# 预测值\ntopo_grid_df$ypred &lt;- ypred$mean\n# 整理数据\nlibrary(sf)\ntopo_grid_sf &lt;- st_as_sf(topo_grid_df, coords = c(\"x\", \"y\"), dim = \"XY\")\nlibrary(stars)\n# 26x26 的网格\ntopo_grid_stars &lt;- st_rasterize(topo_grid_sf, nx = 26, ny = 26)\n\nlibrary(ggplot2)\nggplot() +\n  geom_stars(data = topo_grid_stars, aes(fill = ypred)) +\n  scale_fill_viridis_c(option = \"C\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, 和 Steve Walker. 2015. 《Fitting Linear Mixed-Effects Models Using lme4》. Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nDemidenko, Eugene. 2013. Mixed Models: Theory and Applications with R. 2nd 本. Hoboken, New Jersey: John Wiley & Sons. https://doi.org/10.1002/9781118651537.\n\n\nGałecki, Andrzej, 和 Tomasz Burzykowski. 2013. Linear Mixed-Effects Models Using R: A Step-by-Step Approach. 1st 本. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4614-3900-4.\n\n\nJiang, Jiming, 和 Thuan Nguyen. 2021. Linear and Generalized Linear Mixed Models and Their Applications. 2nd 本. New York, NY: Springer New York. https://doi.org/10.1007/978-1-0716-1282-8.\n\n\nPeter Diggle, Kung-Yee Liang, Patrick Heagerty, 和 Scott Zeger. 2002. Analysis of longitudinal data. 2nd 本. Oxford: Oxford University Press.\n\n\nPinheiro, JoséC., 和 Douglas M. Bates. 2000. Mixed-Effects Models in S and S-PLUS. New York, NY: Springer-Verlag.\n\n\nRizopoulos, Dimitris. 2023. GLMMadaptive: Generalized Linear Mixed Models using Adaptive Gaussian Quadrature. https://CRAN.R-project.org/package=GLMMadaptive.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "mixed-effects-models.html#footnotes",
    "href": "mixed-effects-models.html#footnotes",
    "title": "36  混合效应模型",
    "section": "",
    "text": "https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q1/019945.html↩︎\nhttps://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003615.html↩︎",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>混合效应模型</span>"
    ]
  },
  {
    "objectID": "generalized-additive-models.html",
    "href": "generalized-additive-models.html",
    "title": "37  广义可加模型",
    "section": "",
    "text": "37.1 案例：模拟摩托车事故",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>广义可加模型</span>"
    ]
  },
  {
    "objectID": "generalized-additive-models.html#sec-mcycle-gam",
    "href": "generalized-additive-models.html#sec-mcycle-gam",
    "title": "37  广义可加模型",
    "section": "",
    "text": "37.1.1 mgcv\nMASS 包的 mcycle 数据集\n\ndata(mcycle, package = \"MASS\")\nstr(mcycle)\n\n#&gt; 'data.frame':    133 obs. of  2 variables:\n#&gt;  $ times: num  2.4 2.6 3.2 3.6 4 6.2 6.6 6.8 7.8 8.2 ...\n#&gt;  $ accel: num  0 -1.3 -2.7 0 -2.7 -2.7 -2.7 -1.3 -2.7 -2.7 ...\n\n\n\nlibrary(ggplot2)\nggplot(data = mcycle, aes(x = times, y = accel)) +\n  geom_point() +\n  theme_classic() +\n  labs(x = \"时间（ms）\", y = \"加速度（g）\")\n\n\n\n\n\n\n图 37.1: mcycle 数据集\n\n\n\n\n样条回归\n\nlibrary(mgcv)\nmcycle_mgcv &lt;- gam(accel ~ s(times), data = mcycle, method = \"REML\")\nsummary(mcycle_mgcv)\n\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; accel ~ s(times)\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  -25.546      1.951  -13.09   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;            edf Ref.df    F p-value    \n#&gt; s(times) 8.625  8.958 53.4  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.783   Deviance explained = 79.7%\n#&gt; -REML = 616.14  Scale est. = 506.35    n = 133\n\n\n方差成分\n\ngam.vcomp(mcycle_mgcv, rescale = FALSE)\n\n#&gt; \n#&gt; Standard deviations and 0.95 confidence intervals:\n#&gt; \n#&gt;            std.dev     lower      upper\n#&gt; s(times) 807.88726 480.66162 1357.88215\n#&gt; scale     22.50229  19.85734   25.49954\n#&gt; \n#&gt; Rank: 2/2\n\n\n\nplot(mcycle_mgcv)\n\n\n\n\n\n\n图 37.2: mcycle 数据集\n\n\n\n\nggplot2 包的平滑图层函数 geom_smooth() 集成了 mgcv 包的函数 gam() 的功能。\n\nlibrary(ggplot2)\nggplot(data = mcycle, aes(x = times, y = accel)) +\n  geom_point() +\n  geom_smooth(method = \"gam\", formula = y ~ s(x, bs = \"tp\"), method.args = list(method = \"REML\"))\n\n\n\n\n\n\n图 37.3: ggplot2 平滑\n\n\n\n\n\n37.1.2 cmdstanr\n\nlibrary(cmdstanr)\n\n\n37.1.3 rstanarm\nrstanarm 可以拟合一般的广义可加（混合）模型。\n\nlibrary(rstanarm)\nmcycle_rstanarm &lt;- stan_gamm4(accel ~ s(times),\n  data = mcycle, family = gaussian(), cores = 2, seed = 20232023,\n  iter = 4000, warmup = 1000, thin = 10, refresh = 0,\n  adapt_delta = 0.99\n)\nsummary(mcycle_rstanarm)\n\nModel Info:\n function:     stan_gamm4\n family:       gaussian [identity]\n formula:      accel ~ s(times)\n algorithm:    sampling\n sample:       1200 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 133\n\nEstimates:\n                       mean    sd      10%     50%     90%  \n(Intercept)            -25.6     2.1   -28.4   -25.5   -23.0\ns(times).1             340.4   232.9    61.1   340.8   634.7\ns(times).2           -1218.9   243.3 -1529.2 -1218.8  -913.5\ns(times).3            -567.8   147.0  -765.2  -567.1  -385.3\ns(times).4            -619.8   133.8  -791.1  -617.0  -458.9\ns(times).5           -1056.2    85.8 -1162.8 -1055.7  -945.1\ns(times).6             -89.2    49.8  -154.4   -89.4   -27.6\ns(times).7            -232.2    33.8  -274.7  -232.2  -189.5\ns(times).8              17.3   105.8  -121.0    15.5   150.1\ns(times).9               4.1    33.1   -25.8     1.0    39.1\nsigma                   24.7     1.6    22.6    24.6    26.8\nsmooth_sd[s(times)1]   399.9    59.2   327.6   395.4   479.1\nsmooth_sd[s(times)2]    25.2    25.4     2.9    17.5    56.6\n\nFit Diagnostics:\n           mean   sd    10%   50%   90%\nmean_PPD -25.5    3.0 -29.3 -25.5 -21.8\n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                     mcse Rhat n_eff\n(Intercept)          0.1  1.0  1052 \ns(times).1           7.0  1.0  1103 \ns(times).2           6.7  1.0  1329 \ns(times).3           4.4  1.0  1101 \ns(times).4           3.8  1.0  1230 \ns(times).5           2.5  1.0  1137 \ns(times).6           1.5  1.0  1128 \ns(times).7           1.0  1.0  1062 \ns(times).8           3.1  1.0  1147 \ns(times).9           1.0  1.0  1052 \nsigma                0.0  1.0  1154 \nsmooth_sd[s(times)1] 1.8  1.0  1136 \nsmooth_sd[s(times)2] 0.7  1.0  1157 \nmean_PPD             0.1  1.0   997 \nlog-posterior        0.1  1.0  1122 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n计算 LOO 值\n\nloo(mcycle_rstanarm)\n\nComputed from 1200 by 133 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -611.0  8.8\np_loo         7.3  1.2\nlooic      1222.0 17.5\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nplot_nonlinear(mcycle_rstanarm)\npp_check(mcycle_rstanarm)\n\n\n37.1.4 brms\n另一个综合型的贝叶斯分析扩展包是 brms 包\n\n# 拟合模型\nmcycle_brms &lt;- brms::brm(accel ~ s(times),\n  data = mcycle, family = gaussian(), cores = 2, seed = 20232023,\n  iter = 4000, warmup = 1000, thin = 10, refresh = 0, silent = 2,\n  control = list(adapt_delta = 0.99)\n)\n# 模型输出\nsummary(mcycle_brms)\n\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: accel ~ s(times) \n#&gt;    Data: mcycle (Number of observations: 133) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 10;\n#&gt;          total post-warmup draws = 1200\n#&gt; \n#&gt; Smooth Terms: \n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sds(stimes_1)   722.94    193.12   455.20  1174.52 1.00     1088     1246\n#&gt; \n#&gt; Population-Level Effects: \n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   -25.43      1.95   -29.35   -21.58 1.00     1118     1254\n#&gt; stimes_1    122.17    289.80  -465.71   668.34 1.00     1210     1197\n#&gt; \n#&gt; Family Specific Parameters: \n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma    22.76      1.46    20.20    25.79 1.00     1083     1173\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n固定效应\n\nbrms::fixef(mcycle_brms)\n\n#&gt;            Estimate  Est.Error       Q2.5    Q97.5\n#&gt; Intercept -25.43013   1.946244  -29.34629 -21.5809\n#&gt; stimes_1  122.16814 289.800852 -465.70761 668.3376\n\n\nLOO 值与 rstanarm 包计算的值很接近。\n\nbrms::loo(mcycle_brms)\n\n#&gt; \n#&gt; Computed from 1200 by 133 log-likelihood matrix\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo   -608.3 10.2\n#&gt; p_loo         8.8  1.5\n#&gt; looic      1216.7 20.4\n#&gt; ------\n#&gt; Monte Carlo SE of elpd_loo is 0.1.\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.5).\n#&gt; See help('pareto-k-diagnostic') for details.\n\n\n模型中样条平滑的效应\nplot(brms::conditional_smooths(mcycle_brms))\nbrms::pp_check(mcycle_brms, ndraws = 50)\n\n\n\n\n\n\n\n\n\n(a) 样条平滑效应\n\n\n\n\n\n\n\n\n\n(b) 后验预测分布\n\n\n\n\n\n\n图 37.4: 后验预测分布检查\n\n\n\n37.1.5 GINLA\nmgcv 包的简化版 INLA 算法用于贝叶斯计算\n\nlibrary(mgcv)\nmcycle_mgcv &lt;- gam(accel ~ s(times), data = mcycle, fit = FALSE)\n# 简化版 INLA\nmcycle_ginla &lt;- ginla(G = mcycle_mgcv)\nstr(mcycle_ginla)\n\n#&gt; List of 2\n#&gt;  $ density: num [1:10, 1:100] 2.04e-04 2.13e-05 8.21e-06 3.47e-05 1.14e-05 ...\n#&gt;  $ beta   : num [1:10, 1:100] -32.8 -133.4 -139.4 -152.5 -153.3 ...\n\n\n提取最大后验估计\n\nidx &lt;- apply(mcycle_ginla$density, 1, function(x) x == max(x))\nmcycle_ginla$beta[t(idx)]\n\n#&gt;  [1]  -64.502391 -110.258456   89.506696   -9.449407 -110.635738   16.145715\n#&gt;  [7]  -25.472566   43.025985  -21.992372   35.893285\n\n\n\n37.1.6 INLA\n\nlibrary(INLA)\nlibrary(splines)",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>广义可加模型</span>"
    ]
  },
  {
    "objectID": "generalized-additive-models.html#sec-rongelap-gamm",
    "href": "generalized-additive-models.html#sec-rongelap-gamm",
    "title": "37  广义可加模型",
    "section": "\n37.2 案例：朗格拉普岛核污染",
    "text": "37.2 案例：朗格拉普岛核污染\n从线性到可加，意味着从线性到非线性，可加模型容纳非线性的成分，比如高斯过程、样条。\n\n37.2.1 mgcv\n本节复用 章节 28 朗格拉普岛核污染数据，相关背景不再赘述，下面首先加载数据到 R 环境。\n\n# 加载数据\nrongelap &lt;- readRDS(file = \"data/rongelap.rds\")\nrongelap_coastline &lt;- readRDS(file = \"data/rongelap_coastline.rds\")\n\n接着，将岛上各采样点的辐射强度展示出来，算是简单回顾一下数据概况。\n\n代码library(plot3D)\nwith(rongelap, {\n  opar &lt;- par(mar = c(.1, 2.5, .1, .1), no.readonly = TRUE)\n  rongelap_coastline$cZ &lt;- 0\n  scatter3D(\n    x = cX, y = cY, z = counts / time, \n    xlim = c(-6500, 50), ylim = c(-3800, 110),\n    xlab = \"\\n横坐标（米）\", ylab = \"\\n纵坐标（米）\",\n    zlab = \"\\n辐射强度\", lwd = 0.5, cex = 0.8,\n    pch = 16, type = \"h\", ticktype = \"detailed\",\n    phi = 40, theta = -30, r = 50, d = 1,\n    expand = 0.5, box = TRUE, bty = \"b\",\n    colkey = F, col = \"black\",\n    panel.first = function(trans) {\n      XY &lt;- trans3D(\n        x = rongelap_coastline$cX,\n        y = rongelap_coastline$cY,\n        z = rongelap_coastline$cZ,\n        pmat = trans\n      )\n      lines(XY, col = \"gray50\", lwd = 2)\n    }\n  )\n  rongelap_coastline$cZ &lt;- NULL\n  on.exit(par(opar), add = TRUE)\n})\n\n\n\n\n\n\n图 37.5: 岛上各采样点的辐射强度\n\n\n\n\n在这里，从广义可加混合效应模型的角度来对核污染数据建模，空间效应仍然是用高斯过程来表示，响应变量服从带漂移项的泊松分布。采用 mgcv 包 (S. N. Wood 2004) 的函数 gam() 拟合模型，其中，含 49 个参数的样条近似高斯过程，高斯过程的核函数为默认的梅隆型。更多详情见 mgcv 包的函数 s() 帮助文档参数的说明，默认值是梅隆型相关函数及默认的范围参数，作者自己定义了一套符号约定。\n\nlibrary(nlme)\nlibrary(mgcv)\nfit_rongelap_gam &lt;- gam(\n  counts ~ s(cX, cY, bs = \"gp\", k = 50), offset = log(time), \n  data = rongelap, family = poisson(link = \"log\")\n)\n# 模型输出\nsummary(fit_rongelap_gam)\n\n#&gt; \n#&gt; Family: poisson \n#&gt; Link function: log \n#&gt; \n#&gt; Formula:\n#&gt; counts ~ s(cX, cY, bs = \"gp\", k = 50)\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) 1.976815   0.001642    1204   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;            edf Ref.df Chi.sq p-value    \n#&gt; s(cX,cY) 48.98     49  34030  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.876   Deviance explained = 60.7%\n#&gt; UBRE = 153.78  Scale est. = 1         n = 157\n\n# 随机效应\ngam.vcomp(fit_rongelap_gam)\n\n#&gt; s(cX,cY) \n#&gt; 2543.376\n\n\n值得一提的是核函数的类型和默认参数的选择，参数 m 接受一个向量， m[1] 取值为 1 至 5，分别代表球型 spherical, 幂指数 power exponential 和梅隆型 Matern with \\(\\kappa\\) = 1.5, 2.5 or 3.5 等 5 种相关/核函数。\n\n# 球型相关函数及范围参数为 0.5\nfit_rongelap_gam &lt;- gam(\n  counts ~ s(cX, cY, bs = \"gp\", k = 50, m = c(1, .5)),\n  offset = log(time), data = rongelap, family = poisson(link = \"log\")\n)\n\n接下来，基于岛屿的海岸线数据划分出网格，将格点作为新的预测位置。\n\nlibrary(sf)\n\n#&gt; Linking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(abind)\nlibrary(stars)\n# 类型转化\nrongelap_sf &lt;- st_as_sf(rongelap, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_coastline_sf &lt;- st_as_sf(rongelap_coastline, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_coastline_sfp &lt;- st_cast(st_combine(st_geometry(rongelap_coastline_sf)), \"POLYGON\")\n# 添加缓冲区\nrongelap_coastline_buffer &lt;- st_buffer(rongelap_coastline_sfp, dist = 50)\n# 构造带边界约束的网格\nrongelap_coastline_grid &lt;- st_make_grid(rongelap_coastline_buffer, n = c(150, 75))\n# 将 sfc 类型转化为 sf 类型\nrongelap_coastline_grid &lt;- st_as_sf(rongelap_coastline_grid)\nrongelap_coastline_buffer &lt;- st_as_sf(rongelap_coastline_buffer)\nrongelap_grid &lt;- rongelap_coastline_grid[rongelap_coastline_buffer, op = st_intersects]\n# 计算网格中心点坐标\nrongelap_grid_centroid &lt;- st_centroid(rongelap_grid)\n# 共计 1612 个预测点\nrongelap_grid_df &lt;- as.data.frame(st_coordinates(rongelap_grid_centroid))\ncolnames(rongelap_grid_df) &lt;- c(\"cX\", \"cY\")\n\n模型对象 fit_rongelap_gam 在新的格点上预测核辐射强度，接着整理预测结果数据。\n\n# 预测\nrongelap_grid_df$ypred &lt;- as.vector(predict(fit_rongelap_gam, newdata = rongelap_grid_df, type = \"response\")) \n# 整理预测数据\nrongelap_grid_sf &lt;- st_as_sf(rongelap_grid_df, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_grid_stars &lt;- st_rasterize(rongelap_grid_sf, nx = 150, ny = 75)\nrongelap_stars &lt;- st_crop(x = rongelap_grid_stars, y = rongelap_coastline_sfp)\n\n最后，将岛上各个格点的核辐射强度绘制出来，给出全岛核辐射强度的空间分布。\n\n代码library(ggplot2)\nggplot() +\n  geom_stars(data = rongelap_stars, aes(fill = ypred), na.action = na.omit) +\n  geom_sf(data = rongelap_coastline_sfp, fill = NA, color = \"gray50\", linewidth = 0.5) +\n  scale_fill_viridis_c(option = \"C\") +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", fill = \"预测值\")\n\n\n\n\n\n\n图 37.6: 核辐射强度的预测分布\n\n\n\n\n\n37.2.2 cmdstanr\nFRK 包 (Sainsbury-Dale, Zammit-Mangion, 和 Cressie 2022)（Fixed Rank Kriging，固定秩克里金） 可对有一定规模的（时空）空间区域数据和点参考数据集建模，响应变量的分布从高斯分布扩展到指数族，放在（时空）空间广义线性混合效应模型的框架下统一建模。然而，不支持带漂移项的泊松分布。\nbrms 包支持一大类贝叶斯统计模型，但是对高斯过程建模十分低效，当遇到有一定规模的数据，建模是不可行的，因为经过对 brms 包生成的模型代码的分析，发现它采用潜变量高斯过程（latent variable GP）模型，这也是采样效率低下的一个关键因素。\n\n# 预计运行 1 个小时以上\nrongelap_brm &lt;- brms::brm(counts ~ gp(cX, cY) + offset(log(time)),\n  data = rongelap, family = poisson(link = \"log\")\n)\n# 基样条近似拟合也很慢\nrongelap_brm &lt;- brms::brm(\n  counts ~ gp(cX, cY, c = 5/4, k = 5) + offset(log(time)),\n  data = rongelap, family = poisson(link = \"log\")\n)\n\n当设置 \\(k = 5\\) 时，用 5 个基函数来近似高斯过程，编译完成后，采样速度很快，但是结果不可靠，采样过程中的问题很多。当将横、纵坐标值同时缩小 6000 倍，采样效率并未得到改善。当设置 \\(k = 15\\) 时，运行时间明显增加，采样过程的诊断结果类似 \\(k = 5\\) 的情况，还是不可靠。截止写作时间，函数 gp() 的参数 cov 只能取指数二次核函数（exponentiated-quadratic kernel） 。说明 brms 包不适合处理含高斯过程的模型。\n实际上，Stan 没有现成的有效算法或扩展包做有规模的高斯过程建模，详见 Bob Carpenter 在 2023 年 Stan 大会的报告，因此，必须采用一些近似方法，通过 Stan 编码实现。接下来，分别手动实现低秩和基样条两种方法近似边际高斯过程（marginal likelihood GP）(Rasmussen 和 Williams 2006)，用 Stan 编码模型。代码文件分别是 rongelap_poisson_lr.stan 和 rongelap_poisson_splines.stan 。\n\nlibrary(cmdstanr)\n\n\n37.2.3 GINLA\nmgcv 包的函数 ginla() 实现简化版的 Integrated Nested Laplace Approximation, INLA (Simon N. Wood 2019)。\n\nrongelap_gam &lt;- gam(\n  counts ~ s(cX, cY, bs = \"gp\", k = 50), offset = log(time), \n  data = rongelap, family = poisson(link = \"log\"), fit = FALSE\n)\n# 简化版 INLA\nrongelap_ginla &lt;- ginla(G = rongelap_gam)\nstr(rongelap_ginla)\n\n#&gt; List of 2\n#&gt;  $ density: num [1:50, 1:100] 2.49e-01 9.03e-06 3.51e-06 1.97e-06 1.17e-06 ...\n#&gt;  $ beta   : num [1:50, 1:100] 1.97 -676.61 -572.67 4720.77 240.12 ...\n\n\n其中， \\(k = 50\\) 表示 49 个样条参数，每个参数的分布对应有 100 个采样点，另外，截距项的边际后验概率密度分布如下：\n\nplot(\n  rongelap_ginla$beta[1, ], rongelap_ginla$density[1, ],\n  type = \"l\", xlab = \"截距项\", ylab = \"概率密度\"\n)\n\n\n\n\n\n\n图 37.7: 截距项的边际后验概率密度分布\n\n\n\n\n不难看出，截距项在 1.976 至 1.978 之间，50个参数的最大后验估计分别如下：\n\nidx &lt;- apply(rongelap_ginla$density, 1, function(x) x == max(x))\nrongelap_ginla$beta[t(idx)]\n\n#&gt;  [1]  1.977019e+00 -5.124099e+02  5.461183e+03  1.515296e+03 -2.822166e+03\n#&gt;  [6] -1.598371e+04 -6.417855e+03  1.938121e+02 -4.270878e+03  3.769951e+03\n#&gt; [11] -1.002035e+04  1.914717e+03 -9.721572e+03 -3.794461e+04 -1.401549e+04\n#&gt; [16] -5.376582e+04 -1.585899e+04 -2.338235e+04  6.239053e+04 -3.574500e+02\n#&gt; [21] -4.587927e+04  1.723604e+04 -4.514781e+03  9.184026e-02  3.496526e-01\n#&gt; [26] -1.477406e+02  4.585057e+03  9.153647e+03  1.929387e+04 -1.116512e+04\n#&gt; [31] -1.166149e+04  8.079451e+02  3.627369e+03 -9.835680e+03  1.357777e+04\n#&gt; [36]  1.487742e+04  3.880562e+04 -1.708858e+03  2.775844e+04  2.527415e+04\n#&gt; [41] -3.932957e+04  3.548123e+04 -1.116341e+04  1.630910e+04 -9.789381e+02\n#&gt; [46] -2.011250e+04  2.699657e+04 -4.744393e+04  2.753347e+04  2.834356e+04\n\n\n\n37.2.4 INLA\n接下来，介绍完整版的近似贝叶斯推断方法 INLA — 集成嵌套拉普拉斯近似 (Integrated Nested Laplace Approximations，简称 INLA) (Rue, Martino, 和 Chopin 2009)。根据研究区域的边界构造非凸的内外边界，处理边界效应。\n\nlibrary(INLA)\nlibrary(splancs)\n# 构造非凸的边界\nboundary &lt;- list(\n  inla.nonconvex.hull(\n    points = as.matrix(rongelap_coastline[,c(\"cX\", \"cY\")]), \n    convex = 100, concave = 150, resolution = 100),\n  inla.nonconvex.hull(\n    points = as.matrix(rongelap_coastline[,c(\"cX\", \"cY\")]), \n    convex = 200, concave = 200, resolution = 200)\n)\n\n根据研究区域的情况构造网格，边界内部三角网格最大边长为 300，边界外部最大边长为 600，边界外凸出距离为 100 米。\n\n# 构造非凸的网格\nmesh &lt;- inla.mesh.2d(\n  loc = as.matrix(rongelap[, c(\"cX\", \"cY\")]), offset = 100,\n  max.edge = c(300, 600), boundary = boundary\n)\n\n构建 SPDE，指定自协方差函数为指数型，则 \\(\\nu = 1/2\\) ，因是二维平面，则 \\(d = 2\\) ，根据 \\(\\alpha = \\nu + d/2\\) ，从而 alpha = 3/2 。\n\nspde &lt;- inla.spde2.matern(mesh = mesh, alpha = 3/2, constr = TRUE)\n\n生成 SPDE 模型的指标集，也是随机效应部分。\n\nindexs &lt;- inla.spde.make.index(name = \"s\", n.spde = spde$n.spde)\nlengths(indexs)\n\n#&gt;       s s.group  s.repl \n#&gt;     691     691     691\n\n\n投影矩阵，三角网格和采样点坐标之间的投影。观测数据 rongelap 和未采样待预测的位置数据 rongelap_grid_df\n\n# 观测位置投影到三角网格上\nA &lt;- inla.spde.make.A(mesh = mesh, loc = as.matrix(rongelap[, c(\"cX\", \"cY\")]) )\n# 预测位置投影到三角网格上\ncoop &lt;- as.matrix(rongelap_grid_df[, c(\"cX\", \"cY\")])\nAp &lt;- inla.spde.make.A(mesh = mesh, loc = coop)\n# 1612 个预测位置\ndim(Ap)\n\n#&gt; [1] 1612  691\n\n\n准备观测数据和预测位置，构造一个 INLA 可以使用的数据栈 Data Stack。\n\n# 在采样点的位置上估计 estimation stk.e\nstk.e &lt;- inla.stack(\n  tag = \"est\",\n  data = list(y = rongelap$counts, E = rongelap$time),\n  A = list(rep(1, 157), A),\n  effects = list(data.frame(b0 = 1), s = indexs)\n)\n\n# 在新生成的位置上预测 prediction stk.p\nstk.p &lt;- inla.stack(\n  tag = \"pred\",\n  data = list(y = NA, E = NA),\n  A = list(rep(1, 1612), Ap),\n  effects = list(data.frame(b0 = 1), s = indexs)\n)\n\n# 合并数据 stk.full has stk.e and stk.p\nstk.full &lt;- inla.stack(stk.e, stk.p)\n\n指定响应变量与漂移项、联系函数、模型公式。\n\n# 精简输出\ninla.setOption(short.summary = TRUE)\n# 模型拟合\nres &lt;- inla(formula = y ~ 0 + b0 + f(s, model = spde),\n  data = inla.stack.data(stk.full),\n  E = E, # E 已知漂移项\n  control.family = list(link = \"log\"),\n  control.predictor = list(\n    compute = TRUE, \n    link = 1, # 与 control.family 联系函数相同\n    A = inla.stack.A(stk.full)\n  ),\n  control.compute = list(\n    cpo = TRUE, \n    waic = TRUE, # WAIC 统计量 通用信息准则\n    dic = TRUE   # DIC 统计量 偏差信息准则\n  ),\n  family = \"poisson\"\n)\n# 模型输出\nsummary(res)\n\n#&gt; Fixed effects:\n#&gt;     mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; b0 1.828 0.061      1.706    1.828      1.948 1.828   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;               mean    sd 0.025quant 0.5quant 0.975quant  mode\n#&gt; Theta1 for s  2.00 0.062       1.88     2.00       2.12  2.00\n#&gt; Theta2 for s -4.85 0.130      -5.11    -4.85      -4.59 -4.85\n#&gt; \n#&gt; Deviance Information Criterion (DIC) ...............: 1834.57\n#&gt; Deviance Information Criterion (DIC, saturated) ....: 314.90\n#&gt; Effective number of parameters .....................: 156.46\n#&gt; \n#&gt; Watanabe-Akaike information criterion (WAIC) ...: 1789.32\n#&gt; Effective number of parameters .................: 80.06\n#&gt; \n#&gt;  is computed\n\n\n\nkld 表示 Kullback-Leibler divergence (KLD) 它的值描述标准高斯分布与 Simplified Laplace Approximation 之间的差别，值越小越表示拉普拉斯的近似效果好。\nDIC 和 WAIC 指标都是评估模型预测表现的。另外，还有两个量计算出来了，但是没有显示，分别是 CPO 和 PIT 。CPO 表示 Conditional Predictive Ordinate (CPO)，PIT 表示 Probability Integral Transforms (PIT) 。\n\n固定效应（截距）和超参数部分\n\n# 截距\nres$summary.fixed\n\n#&gt;        mean         sd 0.025quant 0.5quant 0.975quant     mode          kld\n#&gt; b0 1.828027 0.06147358   1.706422 1.828283   1.948169 1.828279 1.782546e-08\n\n# 超参数\nres$summary.hyperpar\n\n#&gt;                   mean         sd 0.025quant  0.5quant 0.975quant      mode\n#&gt; Theta1 for s  2.000684 0.06235053   1.876512  2.001169   2.122006  2.003209\n#&gt; Theta2 for s -4.851258 0.12973413  -5.105060 -4.851807  -4.594251 -4.854095\n\n\n提取预测数据，并整理数据。\n\n# 预测值对应的指标集合\nindex &lt;- inla.stack.index(stk.full, tag = \"pred\")$data\n# 提取预测结果，后验均值\n# pred_mean &lt;- res$summary.fitted.values[index, \"mean\"]\n# 95% 预测下限\n# pred_ll &lt;- res$summary.fitted.values[index, \"0.025quant\"]\n# 95% 预测上限\n# pred_ul &lt;- res$summary.fitted.values[index, \"0.975quant\"]\n# 整理数据\nrongelap_grid_df$ypred &lt;- res$summary.fitted.values[index, \"mean\"]\n# 预测值数据\nrongelap_grid_sf &lt;- st_as_sf(rongelap_grid_df, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_grid_stars &lt;- st_rasterize(rongelap_grid_sf, nx = 150, ny = 75)\nrongelap_stars &lt;- st_crop(x = rongelap_grid_stars, y = rongelap_coastline_sfp)\n\n最后，类似之前 mgcv 建模的最后一步，将 INLA 的预测结果绘制出来。\n\nggplot() +\n  geom_stars(data = rongelap_stars, aes(fill = ypred), na.action = na.omit) +\n  geom_sf(data = rongelap_coastline_sfp, fill = NA, color = \"gray50\", linewidth = 0.5) +\n  scale_fill_viridis_c(option = \"C\") +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", fill = \"预测值\")\n\n\n\n\n\n\n图 37.8: 核辐射强度的预测分布",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>广义可加模型</span>"
    ]
  },
  {
    "objectID": "generalized-additive-models.html#sec-topsoil-mgamm",
    "href": "generalized-additive-models.html#sec-topsoil-mgamm",
    "title": "37  广义可加模型",
    "section": "\n37.3 案例：城市土壤重金属污染",
    "text": "37.3 案例：城市土壤重金属污染\n介绍多元地统计（Multivariate geostatistics）建模分析与 INLA 实现。分析某城市地表土壤重金属污染情况，找到污染最严重的地方，即寻找重金属污染的源头。\n\ncity_df &lt;- readRDS(file = \"data/cumcm2011A.rds\")\nlibrary(sf)\ncity_sf &lt;- st_as_sf(city_df, coords = c(\"x(m)\", \"y(m)\"), dim = \"XY\")\ncity_sf\n\n#&gt; Simple feature collection with 319 features and 12 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 28654 ymax: 18449\n#&gt; CRS:           NA\n#&gt; First 10 features:\n#&gt;    编号 功能区 海拔(m) 功能区名称 As (μg/g) Cd (ng/g) Cr (μg/g) Cu (μg/g)\n#&gt; 1     1      4       5     交通区      7.84     153.8     44.31     20.56\n#&gt; 2     2      4      11     交通区      5.93     146.2     45.05     22.51\n#&gt; 3     3      4      28     交通区      4.90     439.2     29.07     64.56\n#&gt; 4     4      2       4     工业区      6.56     223.9     40.08     25.17\n#&gt; 5     5      4      12     交通区      6.35     525.2     59.35    117.53\n#&gt; 6     6      2       6     工业区     14.08    1092.9     67.96    308.61\n#&gt; 7     7      4      15     交通区      8.94     269.8     95.83     44.81\n#&gt; 8     8      2       7     工业区      9.62    1066.2    285.58   2528.48\n#&gt; 9     9      4      22     交通区      7.41    1123.9     88.17    151.64\n#&gt; 10   10      4       7     交通区      8.72     267.1     65.56     29.65\n#&gt;    Hg (ng/g) Ni (μg/g) Pb (μg/g) Zn (μg/g)          geometry\n#&gt; 1        266      18.2     35.38     72.35    POINT (74 781)\n#&gt; 2         86      17.2     36.18     94.59  POINT (1373 731)\n#&gt; 3        109      10.6     74.32    218.37 POINT (1321 1791)\n#&gt; 4        950      15.4     32.28    117.35    POINT (0 1787)\n#&gt; 5        800      20.2    169.96    726.02 POINT (1049 2127)\n#&gt; 6       1040      28.2    434.80    966.73 POINT (1647 2728)\n#&gt; 7        121      17.8     62.91    166.73 POINT (2883 3617)\n#&gt; 8      13500      41.7    381.64   1417.86 POINT (2383 3692)\n#&gt; 9      16000      25.8    172.36    926.84 POINT (2708 2295)\n#&gt; 10        63      21.7     36.94    100.41 POINT (2933 1767)\n\n\n\nggplot(data = city_sf) +\n  geom_sf(aes(color = `功能区名称`, size = `海拔(m)`)) +\n  theme_classic()\n\n\n\n\n\n\n图 37.9: 某城市的地形\n\n\n\n\n类似 章节 37.2.1 ，下面根据数据构造城市边界以及对城市区域划分，以便预测城市中其它地方的重金属浓度。\n\n# 由点构造多边形\ncity_sfp &lt;- st_cast(st_combine(st_geometry(city_sf)), \"POLYGON\")\n# 由点构造凸包\ncity_hull &lt;- st_convex_hull(st_geometry(city_sfp))\n# 添加缓冲区作为城市边界\ncity_buffer &lt;- st_buffer(city_hull, dist = 1000)\n# 构造带边界约束的网格\ncity_grid &lt;- st_make_grid(city_buffer, n = c(150, 75))\n# 将 sfc 类型转化为 sf 类型\ncity_grid &lt;- st_as_sf(city_grid)\ncity_buffer &lt;- st_as_sf(city_buffer)\ncity_grid &lt;- city_grid[city_buffer, op = st_intersects]\n# 计算网格中心点坐标\ncity_grid_centroid &lt;- st_centroid(city_grid)\n# 共计 8494 个预测点\ncity_grid_df &lt;- as.data.frame(st_coordinates(city_grid_centroid))\n\n城市边界线\n\nggplot() +\n  geom_sf(data = city_sf, aes(color = `功能区名称`, size = `海拔(m)`)) +\n  geom_sf(data = city_hull, fill = NA) +\n  geom_sf(data = city_buffer, fill = NA) +\n  theme_classic()\n\n\n\n\n\n\n图 37.10: 某城市边界线\n\n\n\n\n根据横、纵坐标和海拔数据，通过高斯过程回归（当然可以用其他办法，这里仅做示意）拟合获得城市其他位置的海拔，绘制等高线图，一目了然地获得城市地形信息。\n\nlibrary(mgcv)\n# 提取部分数据\ncity_topo &lt;- subset(city_df, select = c(\"x(m)\", \"y(m)\", \"海拔(m)\"))\ncolnames(city_topo) &lt;- c(\"x\", \"y\", \"z\")\n# 高斯过程拟合\nfit_city_mgcv &lt;- gam(z ~ s(x, y, bs = \"gp\", k = 50), \n  data = city_topo, family = gaussian(link = \"identity\")\n)\n# 绘制等高线图\n# vis.gam(fit_city_mgcv, color = \"cm\", plot.type = \"contour\", n.grid = 50)\ncolnames(city_grid_df) &lt;- c(\"x\", \"y\")\n# 预测\ncity_grid_df$zpred &lt;- as.vector(predict(fit_city_mgcv, newdata = city_grid_df, type = \"response\")) \n# 转化数据\ncity_grid_sf &lt;- st_as_sf(city_grid_df, coords = c(\"x\", \"y\"), dim = \"XY\")\nlibrary(stars)\ncity_stars &lt;- st_rasterize(city_grid_sf, nx = 150, ny = 75)\n\n\nggplot() +\n  geom_stars(data = city_stars, aes(fill = zpred), na.action = na.omit) +\n  geom_sf(data = city_buffer, fill = NA, color = \"gray50\", linewidth = .5) +\n  scale_fill_viridis_c(option = \"C\") +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", fill = \"海拔（米）\")\n\n\n\n\n\n\n图 37.11: 某城市地形图\n\n\n\n\nlibrary(ggplot2)\nggplot(data = city_sf) +\n  geom_sf(aes(color = `功能区名称`, size = `As (μg/g)`)) +\n  theme_classic()\nggplot(data = city_sf) +\n  geom_sf(aes(color = `功能区名称`, size = `Cd (ng/g)`)) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) 重金属砷 As\n\n\n\n\n\n\n\n\n\n\n\n(b) 重金属镉 Cd\n\n\n\n\n\n\n图 37.12: 重金属砷 As 和镉 Cd 的浓度分布\n\n\n为了便于建模，对数据做标准化处理。\n\n# 根据背景值将各个重金属浓度列进行转化\ncity_sf &lt;- within(city_sf, {\n  `As (μg/g)` &lt;- (`As (μg/g)` - 3.6) / 0.9\n  `Cd (ng/g)` &lt;- (`Cd (ng/g)` - 130) / 30\n  `Cr (μg/g)` &lt;- (`Cr (μg/g)` - 31) / 9\n  `Cu (μg/g)` &lt;- (`Cu (μg/g)` - 13.2) / 3.6\n  `Hg (ng/g)` &lt;- (`Hg (ng/g)` - 35) / 8\n  `Ni (μg/g)` &lt;- (`Ni (μg/g)` - 12.3) / 3.8\n  `Pb (μg/g)` &lt;- (`Pb (μg/g)` - 31) / 6\n  `Zn (μg/g)` &lt;- (`Zn (μg/g)` - 69) / 14\n})\n\n当我们逐一检查各个重金属的浓度分布时，发现重金属汞 Hg 在四个地方的浓度极高，暗示着如果数据采集没有问题，那么这几个地方很可能是污染源。\n\nggplot(data = city_sf) +\n  geom_sf(aes(color = `功能区名称`, size = `Hg (ng/g)`)) +\n  theme_classic()\n\n\n\n\n\n\n图 37.13: 重金属汞 Hg 的浓度分布\n\n\n\n\n\n37.3.1 mgcv\nmgcv 包用于多元空间模型中样条参数估计和选择 (Simon N. Wood, Pya, 和 Säfken 2016)。\n\n# ?mvn\n\n\n37.3.2 INLA\nINLA 包用于多元空间模型的贝叶斯推断 (Palmí-Perales 等 2022) 。\n\n\n\n\nPalmí-Perales, Francisco, Virgilio Gómez-Rubio, Roger S. Bivand, Michela Cameletti, 和 Håvard Rue. 2022. 《Bayesian Inference for Multivariate Spatial Models with R-INLA》. The R Journal. https://doi.org/10.48550/arXiv.2212.10976.\n\n\nRasmussen, Carl Edward, 和 Christopher K. I. Williams. 2006. Gaussian Processes for Machine Learning. Cambridge, Massachusetts: MIT Press. https://gaussianprocess.org/gpml/.\n\n\nRue, Håvard, Sara Martino, 和 Nicholas Chopin. 2009. 《Approximate Bayesian Inference for Latent Gaussian Models Using Integrated Nested Laplace Approximations (with discussion)》. Journal of the Royal Statistical Society, Series B 71 (2): 319–92.\n\n\nSainsbury-Dale, Matthew, Andrew Zammit-Mangion, 和 Noel Cressie. 2022. 《Modelling Big, Heterogeneous, Non-Gaussian Spatial and Spatio-Temporal Data using FRK》. Journal of Statistical Software. https://doi.org/10.48550/arXiv.2110.02507.\n\n\nWood, S. N. 2004. 《Stable and efficient multiple smoothing parameter estimation for generalized additive models》. Journal of the American Statistical Association 99 (467): 673–86.\n\n\nWood, Simon N. 2019. 《Simplified integrated nested Laplace approximation》. Biometrika 107 (1): 223–30. https://doi.org/10.1093/biomet/asz044.\n\n\nWood, Simon N., Natalya Pya, 和 Benjamin Säfken. 2016. 《Smoothing Parameter and Model Selection for General Smooth Models》. Journal of the American Statistical Association 111 (516): 1548–63. https://doi.org/10.1080/01621459.2016.1180986.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>广义可加模型</span>"
    ]
  },
  {
    "objectID": "gaussian-processes-regression.html",
    "href": "gaussian-processes-regression.html",
    "title": "38  高斯过程回归",
    "section": "",
    "text": "38.1 多元正态分布\n设随机向量 \\(\\bm{X} = (X_1, X_2, \\cdots, X_p)^{\\top}\\) 服从多元正态分布 \\(\\mathrm{MVN}(\\bm{\\mu}, \\Sigma)\\) ，其联合密度函数如下\n\\[\n\\begin{aligned}\n  p(\\boldsymbol x) = (2\\pi)^{-\\frac{p}{2}} |\\Sigma|^{-\\frac12}\n    \\exp\\left\\{ -\\frac12 (\\boldsymbol x - \\boldsymbol \\mu)^T \\Sigma^{-1} (\\boldsymbol x - \\boldsymbol \\mu) \\right\\},\n  \\ \\boldsymbol x \\in \\mathbb{R}^p\n\\end{aligned}\n\\]\n其中，协方差矩阵 \\(\\Sigma\\) 是正定的，其 Cholesky 分解为 \\(\\Sigma = CC^{\\top}\\) ，这里 \\(C\\) 为下三角矩阵。设 \\(\\bm{Z} = (Z_1, Z_2, \\cdots, Z_p)^{\\top}\\) 服从 \\(p\\) 元标准正态分布 \\(\\mathrm{MVN}(\\bm{0}, I)\\) ，则 \\(\\bm{X} = \\bm{\\mu} + C\\bm{Z}\\) 服从多元正态分布 \\(\\mathrm{MVN}(\\bm{\\mu}, \\Sigma)\\) 。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>高斯过程回归</span>"
    ]
  },
  {
    "objectID": "gaussian-processes-regression.html#sec-multi-normal",
    "href": "gaussian-processes-regression.html#sec-multi-normal",
    "title": "38  高斯过程回归",
    "section": "",
    "text": "38.1.1 多元正态分布模拟\n可以用 Stan 函数 multi_normal_cholesky_rng 生成随机数模拟多元正态分布。\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; D;\n  vector[D] mu;\n  matrix[D, D] Sigma;\n}\ntransformed data {\n  matrix[D, D] L_K = cholesky_decompose(Sigma);\n}\nparameters {\n}\nmodel {\n}\ngenerated quantities {\n  array[N] vector[D] yhat;\n  for (n in 1:N){\n    yhat[n] = multi_normal_cholesky_rng(mu, L_K); \n  }\n}\n上述代码块可以同时模拟多组服从多元正态分布的随机数。其中，参数块 parameters 和模型块 model 是空白的，这是因为模拟随机数不涉及模型推断，只是采样。核心部分 generated quantities 代码块负责生成随机数。\n\n# 给定二元正态分布的参数值\nmulti_normal_d &lt;- list(\n  N = 1, # 一组随机数\n  D = 2, # 维度\n  mu = c(3, 2), # 均值向量\n  Sigma = rbind(c(4, 1), c(1, 1)) # 协方差矩阵\n)\nlibrary(cmdstanr)\n# 编译多元正态分布模型\nmod_multi_normal &lt;- cmdstan_model(\n  stan_file = \"code/multi_normal_simu.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\n抽样生成 1000 个服从二元正态分布的随机数。\n\nsimu_multi_normal &lt;- mod_multi_normal$sample(\n  data = multi_normal_d,\n  iter_warmup = 500,    # 每条链预处理迭代次数\n  iter_sampling = 1000, # 样本量\n  chains = 1,           # 马尔科夫链的数目\n  parallel_chains = 1,  # 指定 CPU 核心数，可以给每条链分配一个\n  threads_per_chain = 1, # 每条链设置一个线程\n  show_messages = FALSE, # 不显示迭代的中间过程\n  refresh = 0,        # 不显示采样的进度\n  fixed_param = TRUE, # 固定参数\n  seed = 20232023     # 设置随机数种子，不要使用 set.seed() 函数\n)\n\n值得注意，这里，不需要设置参数初始值，但要设置 fixed_param = TRUE，表示根据模型生成模拟数据。\n\n# 原始数据\nsimu_multi_normal$draws(variables = \"yhat\", format = \"array\")\n\n# A draws_array: 1000 iterations, 1 chains, and 2 variables\n, , variable = yhat[1,1]\n\n         chain\niteration   1\n        1 2.6\n        2 5.3\n        3 1.4\n        4 3.1\n        5 7.6\n\n, , variable = yhat[1,2]\n\n         chain\niteration    1\n        1 0.65\n        2 3.70\n        3 4.36\n        4 1.85\n        5 2.32\n\n# ... with 995 more iterations\n\n# 数据概览\nsimu_multi_normal$summary(.num_args = list(sigfig = 4, notation = \"dec\"))\n\n# A tibble: 2 × 10\n  variable   mean median    sd    mad      q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 yhat[1,1] 3.076  2.979 2.038 1.916  -0.3290 6.535 1.001   1140.    1023. \n2 yhat[1,2] 1.990  1.964 1.018 0.9765  0.2323 3.680 1.002    966.5    982.1\n\n\n以生成第一个服从二元正态分布的随机数（样本点）为例，这个随机数是通过采样获得的，采样过程中产生一个采样序列，采样序列的轨迹和分布如下：\n\nlibrary(ggplot2)\nlibrary(bayesplot)\nmcmc_trace(simu_multi_normal$draws(c(\"yhat[1,1]\", \"yhat[1,2]\")),\n  facet_args = list(\n    labeller = ggplot2::label_parsed, strip.position = \"top\", ncol = 1\n  )\n) + theme_bw(base_size = 12)\n\nmcmc_dens(simu_multi_normal$draws(c(\"yhat[1,1]\", \"yhat[1,2]\")),\n  facet_args = list(\n    labeller = ggplot2::label_parsed, strip.position = \"top\", ncol = 1\n  )\n) + theme_bw(base_size = 12)\n\n\n\n\n\n\n图 38.1: 采样序列的轨迹和分布\n\n\n\n\n\n\n\n\n\n图 38.2: 采样序列的轨迹和分布\n\n\n\n\n这就是一组来自二元正态分布的随机数。\n\nmcmc_scatter(simu_multi_normal$draws(c(\"yhat[1,1]\", \"yhat[1,2]\"))) +\n  theme_bw(base_size = 12) +\n  labs(x = expression(x[1]), y = expression(x[2]))\n\n\n\n\n\n\n图 38.3: 生成二元正态分布的随机数\n\n\n\n\n提取采样数据，整理成矩阵。\n\n# 抽取原始采样数据\nyhat &lt;- simu_multi_normal$draws(c(\"yhat[1,1]\", \"yhat[1,2]\"))\n# 合并多条链\nyhat_mean &lt;- apply(yhat, c(1, 3), mean)\n# 整理成二维矩阵\nx &lt;- as.matrix(yhat_mean)\n# 样本均值\ncolMeans(x)\n\nyhat[1,1] yhat[1,2] \n 3.076281  1.990465 \n\n# 样本方差-协方差矩阵\nvar(x)\n\n          yhat[1,1] yhat[1,2]\nyhat[1,1]  4.152065  1.031544\nyhat[1,2]  1.031544  1.035985\n\n\n\n38.1.2 多元正态分布拟合\n一般地，协方差矩阵的 Cholesky 分解的矩阵表示如下：\n\\[\n\\begin{aligned}\n  \\Sigma &= \\begin{bmatrix}\n\\sigma^2_1 & \\rho_{12}\\sigma_1\\sigma_2 & \\rho_{13}\\sigma_1\\sigma_3 \\\\\n\\rho_{12}\\sigma_1\\sigma_2 & \\sigma_2^2 & \\rho_{23}\\sigma_2\\sigma_3 \\\\\n\\rho_{13}\\sigma_1\\sigma_3 & \\rho_{23}\\sigma_2\\sigma_3 & \\sigma_3^2\n\\end{bmatrix} \\\\\n& = \\begin{bmatrix}\n\\sigma_1 & 0 & 0 \\\\\n0 & \\sigma_2 & 0 \\\\\n0 & 0 & \\sigma_3\n\\end{bmatrix}\n\\underbrace{\n\\begin{bmatrix}\n1 & \\rho_{12} & \\rho_{13} \\\\\n\\rho_{12} & 1 & \\rho_{23} \\\\\n\\rho_{13} & \\rho_{23} & 1\n\\end{bmatrix}\n}_{R}\n\\begin{bmatrix}\n\\sigma_1 & 0 & 0 \\\\\n0 & \\sigma_2 & 0 \\\\\n0 & 0 & \\sigma_3\n\\end{bmatrix} \\\\\n& = \\begin{bmatrix}\n\\sigma_1 & 0 & 0 \\\\\n0 & \\sigma_2 & 0 \\\\\n0 & 0 & \\sigma_3\n\\end{bmatrix}\n\\underbrace{L_u L_u^{\\top}}_{R}\n\\begin{bmatrix}\n\\sigma_1 & 0 & 0 \\\\\n0 & \\sigma_2 & 0 \\\\\n0 & 0 & \\sigma_3\n\\end{bmatrix}\n\\end{aligned}\n\\]\ndata {\n  int&lt;lower=1&gt; N; // number of observations\n  int&lt;lower=1&gt; K; // dimension of observations\n  array[N] vector[K] y; // observations: a list of N vectors (each has K elements)\n}\nparameters {\n  vector[K] mu;\n  cholesky_factor_corr[K] Lcorr; // cholesky factor (L_u matrix for R)\n  vector&lt;lower=0&gt;[K] sigma;\n}\ntransformed parameters {\n  corr_matrix[K] R; // correlation matrix\n  cov_matrix[K] Sigma; // VCV matrix\n  R = multiply_lower_tri_self_transpose(Lcorr); // R = Lcorr * Lcorr'\n  Sigma = quad_form_diag(R, sigma); // quad_form_diag: diag_matrix(sig) * R * diag_matrix(sig)\n}\nmodel {\n  sigma ~ cauchy(0, 5); // prior for sigma\n  Lcorr ~ lkj_corr_cholesky(2.0); // prior for cholesky factor of a correlation matrix\n  y ~ multi_normal(mu, Sigma);\n}\n代码中， 核心部分是关于多元正态分布的协方差矩阵的参数化，先将协方差矩阵中的方差和相关矩阵剥离，然后利用 Cholesky 分解将相关矩阵分解。在 Stan 里，这是一套高效的组合。\n\n类型 cholesky_factor_corr 表示相关矩阵的 Cholesky 分解后的矩阵 \\(L_u\\)\n类型 corr_matrix 表示相关矩阵 \\(R\\) 。\n类型 cov_matrix 表示协方差矩阵 \\(\\Sigma\\) 。\n函数 lkj_corr_cholesky 为相关矩阵 Cholesky 分解后的矩阵 \\(L_u\\) 服从的分布，详见 Cholesky LKJ correlation distribution。函数名中的 lkj 是以三个人的人名的首字母命名的 Lewandowski, Kurowicka, and Joe 2009。\n函数 multiply_lower_tri_self_transpose 为下三角矩阵与它的转置的乘积，详见 Correlation Matrix Distributions。\n函数 multi_normal 为多元正态分布的抽样语句，详见 Multivariate normal distribution。\n\n矩阵 \\(L_u\\) 是相关矩阵 \\(R\\) 的 Cholesky 分解的结果，在贝叶斯框架内，参数都是随机的，相关矩阵是一个随机矩阵，矩阵 \\(L_u\\) 是一个随机矩阵，它的分布用 Stan 代码表示为如下：\nL ~ lkj_corr_cholesky(2.0); # implies L * L' ~ lkj_corr(2.0);\nLKJ 分布有一个参数 \\(\\eta\\) ，此处 \\(\\eta = 2\\) ，意味着变量之间的相关性较弱，LKJ 分布的概率密度函数正比于相关矩阵的行列式的 \\(\\eta-1\\) 次幂 \\((\\det{R})^{\\eta-1}\\)，LKJ 分布的详细说明见Lewandowski-Kurowicka-Joe (LKJ) distribution。\n有了上面的背景知识，下面先在 R 环境中模拟一组来自多元正态分布的样本。\n\nset.seed(20232023)\n# 均值\nmu &lt;- c(1, 2, -5) \n# 相关矩阵 (R)\nR &lt;- matrix(c(\n  1, 0.7, 0.2, \n  0.7, 1, -0.5,\n  0.2, -0.5, 1\n), 3)\n# sd1 = 0.5, sd2 = 1.2, sd3 = 2.3\nsigmas &lt;- c(0.5, 1.2, 2.3) \n# 方差-协方差矩阵\nSigma &lt;- diag(sigmas) %*% R %*% diag(sigmas) \n# 模拟 1000 个样本数据\ndat &lt;- MASS::mvrnorm(1000, mu = mu, Sigma = Sigma) \n\n根据 1000 个样本点，估计多元正态分布的均值参数和方差协方差参数。\n\n# 来自多元正态分布的一组观测数据\nmulti_normal_chol_d &lt;- list(\n  N = 1000, # 样本量\n  K = 3,    # 三维\n  y = dat\n)\n# 编译多元正态分布模型\nmod_multi_normal_chol &lt;- cmdstan_model(\n  stan_file = \"code/multi_normal_fitted.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n# 拟合多元正态分布模型\nfit_multi_normal &lt;- mod_multi_normal_chol$sample(\n  data = multi_normal_chol_d,\n  iter_warmup = 500,    # 每条链预处理迭代次数\n  iter_sampling = 1000, # 每条链采样次数\n  chains = 2,           # 马尔科夫链的数目\n  parallel_chains = 1,  # 指定 CPU 核心数\n  threads_per_chain = 1,  # 每条链设置一个线程\n  show_messages = FALSE,  # 不显示迭代的中间过程\n  refresh = 0,            # 不显示采样的进度\n  seed = 20232023     # 设置随机数种子\n)\n\n均值向量 \\(\\bm{\\mu}\\) 和协方差矩阵 \\(\\Sigma\\) 估计结果如下：\n\nfit_multi_normal$summary(c(\"mu\", \"Sigma\"), .num_args = list(sigfig = 3, notation = \"dec\"))\n\n# A tibble: 12 × 10\n   variable     mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 mu[1]       0.985  0.985 0.0156 0.0151  0.958  1.01  0.999    1966.    1379.\n 2 mu[2]       1.92   1.92  0.0376 0.0377  1.85   1.98  1.00     1471.     937.\n 3 mu[3]      -4.89  -4.89  0.0723 0.0724 -5.00  -4.76  1.00     1940.    1019.\n 4 Sigma[1,1]  0.255  0.255 0.0109 0.0107  0.238  0.275 1.00     1893.    1105.\n 5 Sigma[2,1]  0.419  0.418 0.0219 0.0215  0.385  0.457 1.00     1470.    1216.\n 6 Sigma[3,1]  0.250  0.249 0.0383 0.0373  0.188  0.315 1.00     1862.    1157.\n 7 Sigma[1,2]  0.419  0.418 0.0219 0.0215  0.385  0.457 1.00     1470.    1216.\n 8 Sigma[2,2]  1.42   1.42  0.0629 0.0643  1.32   1.52  1.00     1594.    1298.\n 9 Sigma[3,2] -1.35  -1.34  0.0986 0.0980 -1.51  -1.19  1.00     1939.    1531.\n10 Sigma[1,3]  0.250  0.249 0.0383 0.0373  0.188  0.315 1.00     1862.    1157.\n11 Sigma[2,3] -1.35  -1.34  0.0986 0.0980 -1.51  -1.19  1.00     1939.    1531.\n12 Sigma[3,3]  5.33   5.32  0.241  0.240   4.96   5.73  1.00     1858.    1496.\n\n\n均值向量 \\(\\bm{\\mu} = (\\mu_1,\\mu_2,\\mu_3)^{\\top}\\) 各个分量及其两两相关性，如下图所示。\n\nmcmc_pairs(\n  fit_multi_normal$draws(c(\"mu[1]\", \"mu[2]\", \"mu[3]\")),\n  diag_fun = \"dens\", off_diag_fun = \"hex\"\n)\n\n\n\n\n\n\n图 38.4: 三元正态分布",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>高斯过程回归</span>"
    ]
  },
  {
    "objectID": "gaussian-processes-regression.html#sec-gaussian-processes",
    "href": "gaussian-processes-regression.html#sec-gaussian-processes",
    "title": "38  高斯过程回归",
    "section": "\n38.2 二维高斯过程",
    "text": "38.2 二维高斯过程\n高斯过程定义\n\n38.2.1 二维高斯过程模拟\n二维高斯过程 \\(\\mathcal{S}\\) 的均值向量为 0 向量，自协方差函数为指数型，如下\n\\[\n\\mathsf{Cov}\\{S(x_i), S(x_j)\\} = \\sigma^2 \\exp\\big( -\\frac{\\|x_i -x_j\\|_{2}}{\\phi} \\big)\n\\]\n其中，不妨设参数 \\(\\sigma = 10, \\phi = 1\\) 。模拟高斯过程的 Stan 代码如下\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; D;\n  array[N] vector[D] X;\n  vector[N] mu;\n  real&lt;lower=0&gt; sigma;\n  real&lt;lower=0&gt; phi;\n}\ntransformed data {\n  real delta = 1e-9;\n  matrix[N, N] L;\n  matrix[N, N] K = gp_exponential_cov(X, sigma, phi) + diag_matrix(rep_vector(delta, N));\n  L = cholesky_decompose(K);\n}\nparameters {\n  vector[N] eta;\n}\nmodel {\n  eta ~ std_normal();\n}\ngenerated quantities {\n  vector[N] y;\n  y = mu + L * eta;\n}\n在二维规则网格上采样，采样点数量为 225。\n\nn &lt;- 15\ngaussian_process_d &lt;- list(\n  N = n^2,\n  D = 2,\n  mu = rep(0, n^2),\n  sigma = 10,\n  phi = 1,\n  X = expand.grid(x1 = 1:n / n, x2 = 1:n / n)\n)\n# 编译二维高斯过程模型\nmod_gaussian_process_simu &lt;- cmdstan_model(\n  stan_file = \"code/gaussian_process_simu.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\n模拟 1 个样本，因为是模拟数据，不需要设置多条链。\n\nfit_multi_normal_gp &lt;- mod_gaussian_process_simu$sample(\n  data = gaussian_process_d,\n  iter_warmup = 500,       # 每条链预处理迭代次数\n  iter_sampling = 1000,    # 样本量\n  chains = 1,              # 马尔科夫链的数目\n  parallel_chains = 1,    # 指定 CPU 核心数\n  threads_per_chain = 1,  # 每条链设置一个线程\n  show_messages = FALSE,  # 不显示迭代的中间过程\n  refresh = 0,            # 不显示采样的进度\n  seed = 20232023         # 设置随机数种子\n)\n\n位置 1 和 2 处的随机变量的迭代轨迹，均值为 0 ，标准差 10 左右。\n\nmcmc_trace(fit_multi_normal_gp$draws(c(\"y[1]\", \"y[2]\")),\n  facet_args = list(\n    labeller = ggplot2::label_parsed,\n    strip.position = \"top\", ncol = 1\n  )\n) + theme_bw(base_size = 12)\n\n\n\n\n\n\n图 38.5: 位置 1 和 2 处的迭代轨迹\n\n\n\n\n位置 1 处的随机变量及其分布\n\ny1 &lt;- fit_multi_normal_gp$draws(c(\"y[1]\"), format = \"draws_array\")\n# 合并链条结果\ny1_mean &lt;- apply(y1, c(1, 3), mean)\n# y[1] 的方差\nvar(y1_mean)\n\n         y[1]\ny[1] 103.9116\n\n# y[1] 的标准差\nsd(y1_mean)\n\n[1] 10.1937\n\n\n100 次迭代获得 100 个样本点，每次迭代采集一个样本点，每个样本点是一个 225 维的向量。\n\n# 抽取原始的采样数据\ny_array &lt;- fit_multi_normal_gp$draws(variables = \"y\", format = \"array\")\n# 合并链条\ny_mean &lt;- apply(y_array, c(1, 3), mean)\n\n从 100 次迭代中任意提取某一个样本点，比如预采样之后的第一次下迭代的结果，接着整理数据。\n\n# 整理数据\nsim_gp_data &lt;- cbind.data.frame(gaussian_process_d$X, ysim = y_mean[1, ])\n\n绘制二维高斯过程图形。\n\nggplot(data = sim_gp_data, aes(x = x1, y = x2)) +\n  geom_point(aes(color = ysim)) +\n  scale_color_distiller(palette = \"Spectral\") +\n  theme_bw() +\n  labs(x = expression(x[1]), y = expression(x[2]))\n\n\n\n\n\n\n图 38.6: 二维高斯过程\n\n\n\n\n\n38.2.2 二维高斯过程拟合\n二维高斯过程拟合代码如下\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; D;\n  array[N] vector[D] x;\n  vector[N] y;\n}\ntransformed data {\n  real delta = 1e-9;\n  vector[N] mu = rep_vector(0, N);\n}\nparameters {\n  real&lt;lower=0&gt; phi;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  matrix[N, N] L_K;\n  {\n    matrix[N, N] K = gp_exponential_cov(x, sigma, phi) + diag_matrix(rep_vector(delta, N));\n    L_K = cholesky_decompose(K);\n  }\n  \n  phi ~ std_normal();\n  sigma ~ std_normal();\n\n  y ~ multi_normal_cholesky(mu, L_K);\n}\n\n# 二维高斯过程模型\ngaussian_process_d &lt;- list(\n  D = 2,\n  N = nrow(sim_gp_data), # 观测记录的条数\n  x = sim_gp_data[, c(\"x1\", \"x2\")],\n  y = sim_gp_data[, \"ysim\"]\n)\n\nnchains &lt;- 2\nset.seed(20232023)\n# 给每条链设置不同的参数初始值\ninits_gaussian_process &lt;- lapply(1:nchains, function(i) {\n  list(\n    sigma = runif(1), phi = runif(1)\n  )\n})\n\n# 编译模型\nmod_gaussian_process &lt;- cmdstan_model(\n  stan_file = \"code/gaussian_process_fitted.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\n# 拟合二维高斯过程\nfit_gaussian_process &lt;- mod_gaussian_process$sample(\n  data = gaussian_process_d,     # 观测数据\n  init = inits_gaussian_process, # 迭代初值\n  iter_warmup = 1000,   # 每条链预处理迭代次数\n  iter_sampling = 2000, # 每条链总迭代次数\n  chains = nchains,     # 马尔科夫链的数目\n  parallel_chains = 2,  # 指定 CPU 核心数，可以给每条链分配一个\n  threads_per_chain = 2, # 每条链设置一个线程\n  show_messages = FALSE, # 不显示迭代的中间过程\n  refresh = 0,           # 不显示采样的进度\n  seed = 20232023        # 设置随机数种子，不要使用 set.seed() 函数\n)\n# 诊断\nfit_gaussian_process$diagnostic_summary()\n\n$num_divergent\n[1] 0 0\n\n$num_max_treedepth\n[1] 0 0\n\n$ebfmi\n[1] 1.111623 1.059357\n\n\n输出结果\n\nfit_gaussian_process$summary()\n\n# A tibble: 3 × 10\n  variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -358.    -357.    1.03   0.744  -360.    -357.     1.00    1542.\n2 phi         0.540    0.532 0.0752 0.0728    0.432    0.677  1.00    1191.\n3 sigma       6.50     6.48  0.415  0.405     5.87     7.25   1.00    1046.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>高斯过程回归</span>"
    ]
  },
  {
    "objectID": "gaussian-processes-regression.html#sec-gaussian-processes-regression",
    "href": "gaussian-processes-regression.html#sec-gaussian-processes-regression",
    "title": "38  高斯过程回归",
    "section": "\n38.3 高斯过程回归",
    "text": "38.3 高斯过程回归\n\n38.3.1 模型介绍\n朗格拉普岛是位于太平洋上的一个小岛，因美国在比基尼群岛的氢弹核试验受到严重的核辐射影响，数十年之后，科学家登岛采集核辐射强度数据以评估当地居民重返该岛的可能性。朗格拉普岛是一个十分狭长且占地面积只有几平方公里的小岛。\n根据 \\({}^{137}\\mathrm{Cs}\\) 放出伽马射线，在 \\(n=157\\) 个采样点，分别以时间间隔 \\(t_i\\) 测量辐射量 \\(y(x_i)\\)，建立泊松型空间广义线性混合效应模型(Diggle, Tawn, 和 Moyeed 1998)。\n\\[\n\\begin{aligned}\n\\log\\{\\lambda(x_i)\\} & =  \\beta + S(x_{i})\\\\\ny(x_{i}) &\\sim \\mathrm{Poisson}\\big(t_i\\lambda(x_i)\\big)\n\\end{aligned}\n\\]\n其中，\\(\\beta\\) 表示截距，相当于平均水平，\\(\\lambda(x_i)\\) 表示位置 \\(x_i\\) 处的辐射强度，\\(S(x_{i})\\) 表示位置 \\(x_i\\) 处的空间效应，\\(S(x),x \\in \\mathcal{D} \\subset{\\mathbb{R}^2}\\) 是二维平稳空间高斯过程 \\(\\mathcal{S}\\) 的具体实现。 \\(\\mathcal{D}\\) 表示研究区域，可以理解为朗格拉普岛，它是二维实平面 \\(\\mathbb{R}^2\\) 的子集。\n随机过程 \\(S(x)\\) 的自协方差函数常用的有指数型、幂二次指数型（高斯型）和梅隆型，形式如下：\n\\[\n\\begin{aligned}\n\\mathsf{Cov}\\{S(x_i), S(x_j)\\} &= \\sigma^2 \\exp\\big( -\\frac{\\|x_i -x_j\\|_{2}}{\\phi} \\big) \\\\\n\\mathsf{Cov}\\{ S(x_i), S(x_j) \\} &= \\sigma^2 \\exp\\big( -\\frac{\\|x_i -x_j\\|_{2}^{2}}{2\\phi^2} \\big) \\\\\n\\mathsf{Cov}\\{ S(x_i), S(x_j) \\} &= \\sigma^2 \\frac{2^{1 - \\nu}}{\\Gamma(\\nu)}\n\\left(\\sqrt{2\\nu}\\frac{\\|x_i -x_j\\|_{2}}{\\phi}\\right)^{\\nu}\nK_{\\nu}\\left(\\sqrt{2\\nu}\\frac{\\|x_i -x_j\\|_{2}}{\\phi}\\right) \\\\\nK_{\\nu}(x) &= \\int_{0}^{\\infty}\\exp(-x \\cosh t) \\cosh (\\nu t) \\mathrm{dt}\n\\end{aligned}\n\\]\n待估参数：代表方差的 \\(\\sigma^2\\) 和代表范围的 \\(\\phi\\) 。当 \\(\\nu = 1/2\\) 时，梅隆型退化为指数型。\n\n38.3.2 观测数据\n\n# 加载数据\nrongelap &lt;- readRDS(file = \"data/rongelap.rds\")\nrongelap_coastline &lt;- readRDS(file = \"data/rongelap_coastline.rds\")\n# 准备输入数据\nrongelap_poisson_d &lt;- list(\n  N = nrow(rongelap), # 观测记录的条数\n  D = 2, # 2 维坐标\n  X = rongelap[, c(\"cX\", \"cY\")] / 6000, # N x 2 矩阵\n  y = rongelap$counts, # 响应变量\n  offsets = rongelap$time # 漂移项\n)\n# 准备参数初始化数据\nset.seed(20232023)\nnchains &lt;- 2 # 2 条迭代链\ninits_data_poisson &lt;- lapply(1:nchains, function(i) {\n  list(\n    beta = rnorm(1), sigma = runif(1),\n    phi = runif(1), lambda = rnorm(157)\n  )\n})\n\n\n38.3.3 预测数据\n预测未采样的位置的核辐射强度，根据海岸线数据网格化全岛，以格点代表未采样的位置\n\nlibrary(sf)\nlibrary(abind)\nlibrary(stars)\n# 类型转化\nrongelap_sf &lt;- st_as_sf(rongelap, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_coastline_sf &lt;- st_as_sf(rongelap_coastline, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_coastline_sfp &lt;- st_cast(st_combine(st_geometry(rongelap_coastline_sf)), \"POLYGON\")\n# 添加缓冲区\nrongelap_coastline_buffer &lt;- st_buffer(rongelap_coastline_sfp, dist = 50)\n# 构造带边界约束的网格\nrongelap_coastline_grid &lt;- st_make_grid(rongelap_coastline_buffer, n = c(150, 75))\n# 将 sfc 类型转化为 sf 类型\nrongelap_coastline_grid &lt;- st_as_sf(rongelap_coastline_grid)\nrongelap_coastline_buffer &lt;- st_as_sf(rongelap_coastline_buffer)\nrongelap_grid &lt;- rongelap_coastline_grid[rongelap_coastline_buffer, op = st_intersects]\n# 计算网格中心点坐标\nrongelap_grid_centroid &lt;- st_centroid(rongelap_grid)\n# 共计 1612 个预测点\nrongelap_grid_df &lt;- as.data.frame(st_coordinates(rongelap_grid_centroid))\ncolnames(rongelap_grid_df) &lt;- c(\"cX\", \"cY\")\n\n未采样的位置 rongelap_grid_df\n\nhead(rongelap_grid_df)\n\n         cX        cY\n1 -5685.942 -3606.997\n2 -5643.145 -3606.997\n3 -5600.347 -3606.997\n4 -5557.549 -3606.997\n5 -5514.751 -3606.997\n6 -5471.953 -3606.997\n\n\n朗格拉普岛网格化生成格点\n\nggplot() +\n  geom_point(data = rongelap_grid_df, aes(x = cX, y = cY), cex = 0.3) +\n  geom_path(data = rongelap_coastline, aes(x = cX, y = cY)) +\n  coord_fixed() +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\")\n\n\n\n\n\n\n图 38.7: 朗格拉普岛\n\n\n\n\n\n38.3.4 模型编码\n指定各个参数 \\(\\beta,\\sigma,\\phi\\) 的先验分布\n\\[\n\\begin{aligned}\n\\beta  &\\sim \\mathrm{std\\_normal}(0,1) \\\\\n\\sigma &\\sim \\mathrm{inv\\_gamma}(5,5) \\\\\n\\phi   &\\sim \\mathrm{half\\_std\\_normal}(0,1) \\\\\n\\bm{\\lambda} | \\beta,\\sigma &\\sim \\mathrm{multivariate\\_normal}(\\bm{\\beta}, \\sigma^2 \\Sigma) \\\\\n\\bm{y} | \\bm{\\lambda} &\\sim \\mathrm{poisson\\_log}\\big(\\log(\\text{offsets})+\\bm{\\lambda}\\big)\n\\end{aligned}\n\\]\n其中，\\(\\beta,\\sigma,\\phi,\\Sigma\\) 的含义同前，\\(\\lambda\\) 代表辐射强度，\\(\\mathrm{offsets}\\) 代表漂移项，这里是时间段，\\(\\bm{y}\\) 表示观测的辐射粒子数，\\(\\mathrm{poisson\\_log}\\) 表示泊松分布的对数参数化，将频率参数 rate 的对数 \\(\\lambda\\) 作为参数，详见 Stan 函数手册中泊松分布的对数函数表示。\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; D;\n  array[N] vector[D] X;\n  array[N] int&lt;lower = 0&gt; y;\n  vector[N] offsets;\n}\ntransformed data {\n  real delta = 1e-12;\n  vector[N] log_offsets = log(offsets);\n}\nparameters {\n  real beta;\n  real&lt;lower=0&gt; sigma;\n  real&lt;lower=0&gt; phi;\n  vector[N] lambda;\n}\ntransformed parameters {\n  vector[N] mu = rep_vector(beta, N);\n}\nmodel {\n  matrix[N, N] L_K;\n  {\n    matrix[N, N] K = gp_exponential_cov(X, sigma, phi) + diag_matrix(rep_vector(delta, N));\n    L_K = cholesky_decompose(K);\n  }\n  \n  beta ~ std_normal();\n  sigma ~ inv_gamma(5, 5);\n  phi ~ std_normal();\n  \n  lambda ~ multi_normal_cholesky(mu, L_K);\n  y ~ poisson_log(log_offsets + lambda);\n}\n\n# 编译模型\nmod_rongelap_poisson &lt;- cmdstan_model(\n  stan_file = \"code/rongelap_poisson_processes.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n# 泊松对数模型\nfit_rongelap_poisson &lt;- mod_rongelap_poisson$sample(\n  data = rongelap_poisson_d,  # 观测数据\n  init = inits_data_poisson,  # 迭代初值\n  iter_warmup = 500,    # 每条链预处理迭代次数\n  iter_sampling = 1000, # 每条链总迭代次数\n  chains = nchains,     # 马尔科夫链的数目\n  parallel_chains = 2,  # 指定 CPU 核心数，可以给每条链分配一个\n  threads_per_chain = 2, # 每条链设置一个线程\n  show_messages = FALSE, # 不显示迭代的中间过程\n  refresh = 0,           # 不显示采样的进度\n  seed = 20232023\n)\n# 诊断\nfit_rongelap_poisson$diagnostic_summary()\n\n$num_divergent\n[1] 0 0\n\n$num_max_treedepth\n[1] 0 0\n\n$ebfmi\n[1] 1.029395 1.036886\n\n\n\n# 泊松对数模型\nfit_rongelap_poisson$summary(\n  variables = c(\"lp__\", \"beta\", \"sigma\", \"phi\"),\n  .num_args = list(sigfig = 3, notation = \"dec\")\n)\n\n# A tibble: 4 × 10\n  variable         mean       median     sd      mad           q5          q95\n  &lt;chr&gt;           &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 lp__     3402193.     3402190      9.40   14.8     3402180      3402210     \n2 beta           1.77         1.79   0.160   0.125         1.53         1.98  \n3 sigma          0.640        0.615  0.118   0.0784        0.517        0.861 \n4 phi            0.0276       0.0239 0.0154  0.00782       0.0147       0.0549\n# ℹ 3 more variables: rhat &lt;dbl&gt;, ess_bulk &lt;dbl&gt;, ess_tail &lt;dbl&gt;\n\n\n\n# 参数的迭代轨迹\nmcmc_trace(\n  fit_rongelap_poisson$draws(c(\"sigma\", \"phi\")),\n  facet_args = list(\n    labeller = ggplot2::label_parsed, strip.position = \"top\", ncol = 1\n  )\n) + theme_bw(base_size = 12)\n\n\n\n\n\n\n图 38.8: \\(\\sigma\\) 和 \\(\\phi\\) 的迭代轨迹\n\n\n\n\n\n# 参数的后验分布\nmcmc_dens(\n  fit_rongelap_poisson$draws(c(\"sigma\", \"phi\")),\n  facet_args = list(\n    labeller = ggplot2::label_parsed, strip.position = \"top\", ncol = 1\n  )\n) + theme_bw(base_size = 12)\n\n\n\n\n\n\n图 38.9: \\(\\sigma\\) 和 \\(\\phi\\) 的后验分布\n\n\n\n\n\n38.3.5 预测分布\n核辐射预测模型的 Stan 代码\nfunctions {\n  vector gp_pred_rng(array[] vector x2,\n                     vector lambda,\n                     array[] vector x1,\n                     real beta,\n                     real sigma,\n                     real phi,\n                     real delta) {\n    int N1 = rows(lambda);\n    int N2 = size(x2);\n    vector[N2] f2;\n    {\n      matrix[N1, N1] L_K;\n      vector[N1] K_div_lambda;\n      matrix[N1, N2] k_x1_x2;\n      matrix[N1, N2] v_pred;\n      vector[N2] f2_mu;\n      matrix[N2, N2] cov_f2;\n      matrix[N2, N2] diag_delta;\n      matrix[N1, N1] K;\n      K = gp_exponential_cov(x1, sigma, phi);\n      L_K = cholesky_decompose(K);\n      K_div_lambda = mdivide_left_tri_low(L_K, lambda - beta);\n      K_div_lambda = mdivide_right_tri_low(K_div_lambda', L_K)';\n      k_x1_x2 = gp_exponential_cov(x1, x2, sigma, phi);\n      f2_mu = beta + (k_x1_x2' * K_div_lambda);\n      v_pred = mdivide_left_tri_low(L_K, k_x1_x2);\n      cov_f2 = gp_exponential_cov(x2, sigma, phi) - v_pred' * v_pred;\n      diag_delta = diag_matrix(rep_vector(delta, N2));\n\n      f2 = multi_normal_rng(f2_mu, cov_f2 + diag_delta);\n    }\n    return f2;\n  }\n}\ndata {\n  int&lt;lower=1&gt; D;\n  int&lt;lower=1&gt; N1;\n  array[N1] vector[D] x1;\n  array[N1] int&lt;lower = 0&gt; y1;\n  vector[N1] offsets1;\n  int&lt;lower=1&gt; N2;\n  array[N2] vector[D] x2;\n  vector[N2] offsets2;\n}\ntransformed data {\n  real delta = 1e-12;\n  vector[N1] log_offsets1 = log(offsets1);\n  vector[N2] log_offsets2 = log(offsets2);\n  \n  int&lt;lower=1&gt; N = N1 + N2;\n  array[N] vector[D] x;\n  \n  for (n1 in 1:N1) {\n    x[n1] = x1[n1];\n  }\n  for (n2 in 1:N2) {\n    x[N1 + n2] = x2[n2];\n  }\n}\nparameters {\n  real beta;\n  real&lt;lower=0&gt; sigma;\n  real&lt;lower=0&gt; phi;\n  vector[N1] lambda1;\n}\ntransformed parameters {\n  vector[N1] mu = rep_vector(beta, N1);\n}\nmodel {\n  matrix[N1, N1] L_K;\n  {\n    matrix[N1, N1] K = gp_exponential_cov(x1, sigma, phi) + diag_matrix(rep_vector(delta, N1));\n    L_K = cholesky_decompose(K);\n  }\n\n  beta ~ std_normal();\n  sigma ~ inv_gamma(5, 5);\n  phi ~ std_normal();\n  \n  lambda1 ~ multi_normal_cholesky(mu, L_K);\n  y1 ~ poisson_log(log_offsets1 + lambda1);\n}\ngenerated quantities {\n  vector[N1] yhat;     // Posterior predictions for each location\n  vector[N1] log_lik;  // Log likelihood for each location\n  vector[N1] RR1 = log_offsets1 + lambda1;\n  \n  for(n in 1:N1) {\n    log_lik[n] = poisson_log_lpmf(y1[n] | RR1[n]);\n    yhat[n] = poisson_log_rng(RR1[n]);\n  }\n  \n  vector[N2] ypred; \n  vector[N2] lambda2 = gp_pred_rng(x2, lambda1, x1, beta, sigma, phi, delta);\n  vector[N2] RR2 = log_offsets2 + lambda2;\n  \n  for(n in 1:N2) {\n    ypred[n] = poisson_log_rng(RR2[n]);\n  }\n}\n准备数据、拟合模型\n\n# 固定漂移项\nrongelap_grid_df$time &lt;- 100\n# 对数高斯模型\nrongelap_poisson_pred_d &lt;- list(\n  D = 2,\n  N1 = nrow(rongelap), # 观测记录的条数\n  x1 = rongelap[, c(\"cX\", \"cY\")] / 6000,\n  y1 = rongelap[, \"counts\"],\n  offsets1 = rongelap[, \"time\"],\n  N2 = nrow(rongelap_grid_df), # 2 维坐标\n  x2 = rongelap_grid_df[, c(\"cX\", \"cY\")] / 6000,\n  offsets2 = rongelap_grid_df[, \"time\"]\n)\n# 迭代链数目\nnchains &lt;- 2\n# 给每条链设置不同的参数初始值\ninits_data_poisson_pred &lt;- lapply(1:nchains, function(i) {\n  list(\n    beta = rnorm(1), sigma = runif(1),\n    phi = runif(1), lambda = rnorm(157)\n  )\n})\n# 编译模型\nmod_rongelap_poisson_pred &lt;- cmdstan_model(\n  stan_file = \"code/rongelap_poisson_pred.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n# 泊松模型\nfit_rongelap_poisson_pred &lt;- mod_rongelap_poisson_pred$sample(\n  data = rongelap_poisson_pred_d,   # 观测数据\n  init = inits_data_poisson_pred,   # 迭代初值\n  iter_warmup = 500,            # 每条链预处理迭代次数\n  iter_sampling = 1000,         # 每条链总迭代次数\n  chains = nchains,             # 马尔科夫链的数目\n  parallel_chains = 2,      # 指定 CPU 核心数，可以给每条链分配一个\n  threads_per_chain = 2,    # 每条链设置一个线程\n  show_messages = FALSE,    # 不显示迭代的中间过程\n  refresh = 0,              # 不显示采样的进度\n  seed = 20232023           # 设置随机数种子，不要使用 set.seed() 函数\n)\n# 诊断信息\nfit_rongelap_poisson_pred$diagnostic_summary()\n\n$num_divergent\n[1] 0 0\n\n$num_max_treedepth\n[1] 0 0\n\n$ebfmi\n[1] 1.1374258 0.9375103\n\n\n参数的后验估计\n\nfit_rongelap_poisson_pred$summary(variables = c(\"beta\", \"sigma\", \"phi\"))\n\n# A tibble: 3 × 10\n  variable   mean median     sd     mad     q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 beta     1.78   1.79   0.139  0.110   1.55   1.97    1.00    1736.     685.\n2 sigma    0.629  0.607  0.103  0.0728  0.512  0.820   1.00    1075.     601.\n3 phi      0.0260 0.0229 0.0131 0.00701 0.0145 0.0471  1.00    1127.     609.\n\n\n模型评估 LOO-CV\n\nfit_rongelap_poisson_pred$loo(variables = \"log_lik\", cores = 2)\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\n\nComputed from 2000 by 157 log-likelihood matrix\n\n         Estimate  SE\nelpd_loo   -932.9 3.9\np_loo       118.5 2.5\nlooic      1865.8 7.7\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)       1    0.6%   182       \n (0.5, 0.7]   (ok)        21   13.4%   60        \n   (0.7, 1]   (bad)      108   68.8%   8         \n   (1, Inf)   (very bad)  27   17.2%   3         \nSee help('pareto-k-diagnostic') for details.\n\n\n检查辐射强度分布的拟合效果\n\n# 抽取 yrep 数据\nyrep &lt;- fit_rongelap_poisson_pred$draws(variables = \"yhat\", format = \"draws_matrix\")\n# Posterior predictive checks\npp_check(rongelap$counts / rongelap$time,\n  yrep = sweep(yrep[1:50, ], MARGIN = 2, STATS = rongelap$time, FUN = `/`),\n  fun = ppc_dens_overlay\n) +\n  theme_classic()\n\n\n\n\n\n\n图 38.10: 后验预测诊断图（密度图）\n\n\n\n\n后 1000 次迭代是平稳的，可取任意一个链条的任意一次迭代，获得采样点处的预测值\n\nyhat_array &lt;- fit_rongelap_poisson_pred$draws(variables = \"yhat\", format = \"array\")\nlambda1_array &lt;- fit_rongelap_poisson_pred$draws(variables = \"lambda1\", format = \"array\")\nrongelap_sf$lambda &lt;- as.vector(lambda1_array[1,1,])\nrongelap_sf$yhat &lt;- as.vector(yhat_array[1,1,])\n\n数据集 rongelap_sf 的概况\n\nrongelap_sf\n\nSimple feature collection with 157 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -6050 ymin: -3430 xmax: -50 ymax: 0\nCRS:           NA\nFirst 10 features:\n   counts time            geometry    lambda yhat\n1      75  300 POINT (-6050 -3270) -1.297860   86\n2     371  300 POINT (-6050 -3165)  0.213031  368\n3    1931  300 POINT (-5925 -3320)  1.811760 1855\n4    4357  300 POINT (-5925 -3165)  2.686520 4321\n5    2114  300 POINT (-5800 -3350)  1.968820 2127\n6    2318  300 POINT (-5800 -3165)  2.031670 2271\n7    1975  300 POINT (-5625 -3350)  1.880950 1983\n8    1912  300 POINT (-5700 -3260)  1.869390 2044\n9    1902  300 POINT (-5700 -3220)  1.847840 1988\n10   1882  300 POINT (-5700 -3180)  1.837910 1916\n\n\n观测值和预测值的情况\n\nsummary(rongelap_sf$counts / rongelap_sf$time)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.250   5.890   7.475   7.604   9.363  15.103 \n\nsummary(rongelap_sf$yhat / rongelap_sf$time)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2867  5.7167  7.4033  7.5876  9.3750 15.1767 \n\n\n展示采样点处的预测值\n\n代码ggplot(data = rongelap_sf)+\n  geom_sf(aes(color = yhat / time), cex = 0.5) +\n  scale_colour_viridis_c(option = \"C\", breaks = 3*0:5,\n    guide = guide_colourbar(\n      barwidth = 15, barheight = 1.5,\n      title.position = \"top\" # 图例标题位于图例上方\n    )) +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", colour = \"辐射强度\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside = c(0.75, 0.1),\n    legend.direction = \"horizontal\",\n    legend.background = element_blank()\n  )\n\n\n\n\n\n\n图 38.11: 朗格拉普岛核辐射强度的分布\n\n\n\n\n未采样点的预测\n\n# 后验估计\nypred_tbl &lt;- fit_rongelap_poisson_pred$summary(variables = \"ypred\", \"mean\")\nrongelap_grid_df$ypred &lt;- ypred_tbl$mean\n# 查看预测结果\nhead(rongelap_grid_df)\n\n         cX        cY time    ypred\n1 -5685.942 -3606.997  100 768.8440\n2 -5643.145 -3606.997  100 771.4865\n3 -5600.347 -3606.997  100 779.3855\n4 -5557.549 -3606.997  100 795.9160\n5 -5514.751 -3606.997  100 807.5435\n6 -5471.953 -3606.997  100 808.6240\n\n# 预测值的分布范围\nsummary(rongelap_grid_df$ypred / rongelap_grid_df$time)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.5005  6.2115  7.3946  7.3060  8.5578 12.8099 \n\n\n转化数据类型，去掉缓冲区内的预测位置，准备绘制辐射强度预测值的分布\n\nrongelap_grid_sf &lt;- st_as_sf(rongelap_grid_df, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_grid_stars &lt;- st_rasterize(rongelap_grid_sf, nx = 150, ny = 75)\nrongelap_stars &lt;- st_crop(x = rongelap_grid_stars, y = rongelap_coastline_sfp)\n\n\n代码# 虚线框数据\ndash_sfp &lt;- st_polygon(x = list(rbind(\n  c(-6000, -3600),\n  c(-6000, -2600),\n  c(-5000, -2600),\n  c(-5000, -3600),\n  c(-6000, -3600)\n)), dim = \"XY\")\n# 主体内容\np3 &lt;- ggplot() +\n  geom_stars(\n    data = rongelap_stars, na.action = na.omit,\n    aes(fill = ypred / time)\n  ) +\n  # 海岸线\n  geom_sf(\n    data = rongelap_coastline_sfp,\n    fill = NA, color = \"gray30\", linewidth = 0.5\n  ) +\n  # 图例\n  scale_fill_viridis_c(\n    option = \"C\", breaks = 0:13,\n    guide = guide_colourbar(\n      barwidth = 15, barheight = 1.5,\n      title.position = \"top\" # 图例标题位于图例上方\n    )\n  ) +\n  # 虚线框\n  geom_sf(data = dash_sfp, fill = NA, linewidth = 0.75, lty = 2) +\n  # 箭头\n  geom_segment(\n    data = data.frame(x = -5500, xend = -5000, y = -2600, yend = -2250),\n    aes(x = x, y = y, xend = xend, yend = yend),\n    arrow = arrow(length = unit(0.03, \"npc\"))\n  ) +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", fill = \"辐射强度\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside = c(0.75, 0.1),\n    legend.direction = \"horizontal\",\n    legend.background = element_blank()\n  )\n\np4 &lt;- ggplot() +\n  geom_stars(\n    data = rongelap_stars, na.action = na.omit,\n    aes(fill = ypred / time), show.legend = FALSE\n  ) +\n  geom_sf(\n    data = rongelap_coastline_sfp,\n    fill = NA, color = \"gray30\", linewidth = 0.75\n  ) +\n  scale_fill_viridis_c(option = \"C\", breaks = 0:13) +\n  # 虚线框\n  geom_sf(data = dash_sfp, fill = NA, linewidth = 0.75, lty = 2) +\n  theme_void() +\n  coord_sf(expand = FALSE, xlim = c(-6000, -5000), ylim = c(-3600, -2600))\n# 叠加图形\np3\nprint(p4, vp = grid::viewport(x = .3, y = .65, width = .45, height = .45))\n\n\n\n\n\n\n图 38.12: 朗格拉普岛核辐射强度的分布",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>高斯过程回归</span>"
    ]
  },
  {
    "objectID": "gaussian-processes-regression.html#sec-gaussian-processes-summary",
    "href": "gaussian-processes-regression.html#sec-gaussian-processes-summary",
    "title": "38  高斯过程回归",
    "section": "\n38.4 总结",
    "text": "38.4 总结\n从模型是否含有块金效应、不同的自相关函数和参数估计方法等方面比较。\n\nlibrary(nlme)\n# 高斯分布、指数型自相关结构\nfit_exp_reml &lt;- gls(log(counts / time) ~ 1,\n  correlation = corExp(value = 200, form = ~ cX + cY, nugget = FALSE),\n  data = rongelap, method = \"REML\"\n)\nfit_exp_ml &lt;- gls(log(counts / time) ~ 1,\n  correlation = corExp(value = 200, form = ~ cX + cY, nugget = FALSE),\n  data = rongelap, method = \"ML\"\n)\nfit_exp_reml_nugget &lt;- gls(log(counts / time) ~ 1,\n  correlation = corExp(value = c(200, 0.1), form = ~ cX + cY, nugget = TRUE),\n  data = rongelap, method = \"REML\"\n)\nfit_exp_ml_nugget &lt;- gls(log(counts / time) ~ 1,\n  correlation = corExp(value = c(200, 0.1), form = ~ cX + cY, nugget = TRUE),\n  data = rongelap, method = \"ML\"\n)\n\n# 高斯分布、高斯型自相关结构\nfit_gaus_reml &lt;- gls(log(counts / time) ~ 1,\n  correlation = corGaus(value = 200, form = ~ cX + cY, nugget = FALSE),\n  data = rongelap, method = \"REML\"\n)\nfit_gaus_ml &lt;- gls(log(counts / time) ~ 1,\n  correlation = corGaus(value = 200, form = ~ cX + cY, nugget = FALSE),\n  data = rongelap, method = \"ML\"\n)\nfit_gaus_reml_nugget &lt;- gls(log(counts / time) ~ 1,\n  correlation = corGaus(value = c(200, 0.1), form = ~ cX + cY, nugget = TRUE),\n  data = rongelap, method = \"REML\"\n)\nfit_gaus_ml_nugget &lt;- gls(log(counts / time) ~ 1,\n  correlation = corGaus(value = c(200, 0.1), form = ~ cX + cY, nugget = TRUE),\n  data = rongelap, method = \"ML\"\n)\n\n汇总结果见下表。\n\n\n\n表格 38.1: 不同模型与参数估计方法的比较\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n响应变量分布\n空间自相关结构\n块金效应\n估计方法\n\\(\\beta\\)\n\\(\\sigma^2\\)\n\\(\\phi\\)\n对数似然值\n\n\n\n高斯分布\n指数型\n无\nREML\n1.826\n0.3172\n110.8\n-89.07\n\n\n高斯分布\n指数型\n无\nML\n1.828\n0.3064\n105.4\n-87.56\n\n\n高斯分布\n指数型\n0.03598\nREML\n1.813\n0.2935\n169.7472\n-88.22\n\n\n高斯分布\n指数型\n0.03312\nML\n1.828\n0.2779\n150.1324\n-86.88\n\n\n高斯分布\n高斯型\n无\nREML\n1.878\n0.2523\n41.96\n-100.7\n\n\n高斯分布\n高斯型\n无\nML\n1.879\n0.25\n41.81\n-98.62\n\n\n高斯分布\n高斯型\n0.07055\nREML\n1.831\n0.2532\n139.1431\n-84.91\n\n\n高斯分布\n高斯型\n0.07053\nML\n1.832\n0.2459\n137.0980\n-83.32\n\n\n\n\n\n\n\n\n相比于其他参数，REML 和 ML 估计方法对参数 \\(\\phi\\) 影响很大，ML 估计的 \\(\\phi\\) 和对数似然函数值更大。高斯型自相关结构中，REML 和 ML 估计方法对参数 \\(\\phi\\) 的估计结果差不多。函数 gls() 对初值要求不高，以上初值选取比较随意，只是符合要求函数定义。\n对普通用户来说，想要流畅地使用 Stan 框架，需要面对很多挑战。\n\n软件安装和配置过程复杂。rstan 包内置的 Stan 版本常低于最新发布的 Stan 版本。\n编译和运行模型的参数控制选项很多。编译模型，OpenCL 和多线程支持，HMC（NUTS）、L-BFGS 和 VI 三大推理算法的参数设置\n模型参数先验分布设置技巧高。模型参数的先验对数据的依赖非常高，仅对线性和广义线性模型依赖较小。即使是面对模拟的简单广义线性混合效应模型，抽样过程也发散严重。\n面对大规模数据扩展困难。以朗格拉普岛的核污染预测任务为例，处理 157 维的积分显得吃力，对 1600 个参数的后验分布模拟和推断低效。\n\n2020 年 Stan 大会 Wade Brorsen 介绍采用 Stan 实现的贝叶斯克里金（Kriging）平滑算法估计和预测各郡县的作物产量。Stan 实现的贝叶斯空间分层正态模型，回归参数随空间区域位置变化，参数的先验分布与空间区域相关，引入大量带超参数的先验分布，运行效率不高，跑模型花费很多时间。假定所有的参数随空间位置变化，模型参数个数瞬间爆炸，跑模型花费 31 天 (Niyizibi, Brorsen, 和 Park 2018)。\nStan 总有些优势吧！\n\nStan 非常灵活。Stan 同时是一门概率编程语言，只要统计模型可以被 Stan 编码，理论上就可以编译、运行、获得结果。\nStan 功能很多。Stan 还可以解刚性的常微分方程、积分方程等。 非常灵活，非常适合学术研究工作者，计算层面，可以方便地在前人的工作上扩展。\nStan 文档很全。函数手册 提供 Stan 内建的各类函数说明。编程手册 提供 Stan 编程语法、程序块的说明，教用户如何使用 Stan 写代码。用户手册 提供 Stan 支持的各类统计模型、代数和微分方程的使用示例。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>高斯过程回归</span>"
    ]
  },
  {
    "objectID": "gaussian-processes-regression.html#sec-gaussian-processes-exercise",
    "href": "gaussian-processes-regression.html#sec-gaussian-processes-exercise",
    "title": "38  高斯过程回归",
    "section": "\n38.5 习题",
    "text": "38.5 习题\n\n\n对核辐射污染数据，建立对数高斯过程模型，用 Stan 编码模型，预测全岛的核辐射强度分布。\n\\[\n\\begin{aligned}\n\\beta  &\\sim \\mathrm{std\\_normal}(0,1) \\\\\n\\sigma &\\sim \\mathrm{inv\\_gamma}(5,5) \\\\\n\\phi   &\\sim \\mathrm{half\\_std\\_normal}(0,1) \\\\\n\\tau   &\\sim \\mathrm{half\\_std\\_normal}(0,1) \\\\\n\\bm{y} &\\sim \\mathrm{multivariate\\_normal}(\\bm{\\beta}, \\sigma^2 \\Sigma+ \\tau^2 I)\n\\end{aligned}\n\\]\n其中，\\(\\beta\\) 代表截距，先验分布为标准正态分布，\\(\\sigma\\) 代表高斯过程的方差参数（信号），先验分布为逆伽马分布，\\(\\phi\\) 代表高斯过程的范围参数，先验分布为半标准正态分布，\\(y\\) 代表辐射强度的对数，给定参数和数据的条件分布为多元正态分布，\\(\\Sigma\\) 代表协方差矩阵，\\(I\\) 代表与采样点数量相同的单位矩阵， \\(\\tau^2\\) 是块金效应。\nfunctions {\n  vector gp_pred_rng(array[] vector x2,\n                     vector y1,\n                     array[] vector x1,\n                     real sigma,\n                     real phi,\n                     real tau,\n                     real delta) {\n    int N1 = rows(y1);\n    int N2 = size(x2);\n    vector[N2] f2;\n    {\n      matrix[N1, N1] L_K;\n      vector[N1] K_div_y1;\n      matrix[N1, N2] k_x1_x2;\n      matrix[N1, N2] v_pred;\n      vector[N2] f2_mu;\n      matrix[N2, N2] cov_f2;\n      matrix[N2, N2] diag_delta;\n      matrix[N1, N1] K;\n      K = gp_exponential_cov(x1, sigma, phi);\n      for (n in 1:N1) {\n        K[n, n] = K[n, n] + square(tau);\n      }\n      L_K = cholesky_decompose(K);\n      K_div_y1 = mdivide_left_tri_low(L_K, y1);\n      K_div_y1 = mdivide_right_tri_low(K_div_y1', L_K)';\n      k_x1_x2 = gp_exponential_cov(x1, x2, sigma, phi);\n      f2_mu = (k_x1_x2' * K_div_y1);\n      v_pred = mdivide_left_tri_low(L_K, k_x1_x2);\n      cov_f2 = gp_exponential_cov(x2, sigma, phi) - v_pred' * v_pred;\n      diag_delta = diag_matrix(rep_vector(delta, N2));\n\n      f2 = multi_normal_rng(f2_mu, cov_f2 + diag_delta);\n    }\n    return f2;\n  }\n}\ndata {\n  int&lt;lower=1&gt; D;\n  int&lt;lower=1&gt; N1;\n  array[N1] vector[D] x1;\n  vector[N1] y1;\n  int&lt;lower=1&gt; N2;\n  array[N2] vector[D] x2;\n}\ntransformed data {\n  real delta = 1e-9;\n}\nparameters {\n  real beta;\n  real&lt;lower=0&gt; phi;\n  real&lt;lower=0&gt; sigma;\n  real&lt;lower=0&gt; tau;\n}\ntransformed parameters {\n  vector[N1] mu = rep_vector(beta, N1);\n}\nmodel {\n  matrix[N1, N1] L_K;\n  {\n    matrix[N1, N1] K = gp_exponential_cov(x1, sigma, phi);\n    real sq_tau = square(tau);\n\n    // diagonal elements\n    for (n1 in 1:N1) {\n      K[n1, n1] = K[n1, n1] + sq_tau;\n    }\n\n    L_K = cholesky_decompose(K);\n  }\n\n  beta ~ std_normal();\n  phi ~ std_normal();\n  sigma ~ inv_gamma(5, 5);\n  tau ~ std_normal();\n\n  y1 ~ multi_normal_cholesky(mu, L_K);\n}\ngenerated quantities {\n  vector[N2] f2;\n  vector[N2] ypred;\n\n  f2 = gp_pred_rng(x2, y1, x1, sigma, phi, tau, delta);\n  for (n2 in 1:N2) {\n    ypred[n2] = normal_rng(f2[n2], tau);\n  }\n}\n代码中，gp_exponential_cov 表示空间相关性结构选择了指数型，详见 Stan 函数手册中的指数型核函数表示。cholesky_decompose 表示对协方差矩阵做 Cholesky 分解，分解出来的下三角矩阵作为多元正态分布的参数，详见 Stan 函数手册中的 Cholesky 分解。 multi_normal_cholesky 表示基于 Cholesky 分解的多元正态分布。详见 Stan 函数手册中的多元正态分布的 Cholesky 参数化表示。\n\n代码set.seed(20232023)\nnchains &lt;- 2 # 2 条迭代链\n# 给每条链设置不同的参数初始值\ninits_data_gaussian &lt;- lapply(1:nchains, function(i) {\n  list(\n    beta = rnorm(1), sigma = runif(1),\n    phi = runif(1), tau = runif(1)\n  )\n})\n\n# 对数高斯模型\nrongelap_gaussian_d &lt;- list(\n  N1 = nrow(rongelap), # 观测记录的条数\n  N2 = nrow(rongelap_grid_df),\n  D = 2, # 2 维坐标\n  x1 = rongelap[, c(\"cX\", \"cY\")] / 6000, # N x 2 坐标矩阵\n  x2 = rongelap_grid_df[, c(\"cX\", \"cY\")] / 6000,\n  y1 = log(rongelap$counts / rongelap$time) # N 向量\n)\n# 编码\nmod_rongelap_gaussian &lt;- cmdstan_model(\n  stan_file = \"code/gaussian_process_pred.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n\n# 对数高斯模型\nfit_rongelap_gaussian &lt;- mod_rongelap_gaussian$sample(\n  data = rongelap_gaussian_d,   # 观测数据\n  init = inits_data_gaussian,   # 迭代初值\n  iter_warmup = 500,            # 每条链预处理迭代次数\n  iter_sampling = 1000,         # 每条链总迭代次数\n  chains = nchains,             # 马尔科夫链的数目\n  parallel_chains = 2,      # 指定 CPU 核心数，可以给每条链分配一个\n  threads_per_chain = 1,    # 每条链设置一个线程\n  show_messages = FALSE,    # 不显示迭代的中间过程\n  refresh = 0,              # 不显示采样的进度\n  seed = 20232023           # 设置随机数种子，不要使用 set.seed() 函数\n)\n\n# 诊断\nfit_rongelap_gaussian$diagnostic_summary()\n# 对数高斯模型\nfit_rongelap_gaussian$summary(\n  variables = c(\"lp__\", \"beta\", \"sigma\", \"phi\", \"tau\"),\n  .num_args = list(sigfig = 4, notation = \"dec\")\n)\n\n# 未采样的位置的核辐射强度预测值\nypred &lt;- fit_rongelap_gaussian$summary(variables = \"ypred\", \"mean\")\n# 预测值\nrongelap_grid_df$ypred &lt;- exp(ypred$mean)\n# 整理数据\nrongelap_grid_sf &lt;- st_as_sf(rongelap_grid_df, coords = c(\"cX\", \"cY\"), dim = \"XY\")\nrongelap_grid_stars &lt;- st_rasterize(rongelap_grid_sf, nx = 150, ny = 75)\nrongelap_stars &lt;- st_crop(x = rongelap_grid_stars, y = rongelap_coastline_sfp)\n\n# 虚线框数据\ndash_sfp &lt;- st_polygon(x = list(rbind(\n  c(-6000, -3600),\n  c(-6000, -2600),\n  c(-5000, -2600),\n  c(-5000, -3600),\n  c(-6000, -3600)\n)), dim = \"XY\")\n# 主体内容\np3 &lt;- ggplot() +\n  geom_stars(\n    data = rongelap_stars, aes(fill = ypred), na.action = na.omit\n  ) +\n  # 海岸线\n  geom_sf(\n    data = rongelap_coastline_sfp,\n    fill = NA, color = \"gray30\", linewidth = 0.5\n  ) +\n  # 图例\n  scale_fill_viridis_c(\n    option = \"C\", breaks = 0:12,\n    guide = guide_colourbar(\n      barwidth = 15, barheight = 1.5,\n      title.position = \"top\" # 图例标题位于图例上方\n    )\n  ) +\n  # 虚线框\n  geom_sf(data = dash_sfp, fill = NA, linewidth = 0.75, lty = 2) +\n  # 箭头\n  geom_segment(\n    data = data.frame(x = -5500, xend = -5000, y = -2600, yend = -2250),\n    aes(x = x, y = y, xend = xend, yend = yend),\n    arrow = arrow(length = unit(0.03, \"npc\"))\n  ) +\n  theme_bw() +\n  labs(x = \"横坐标（米）\", y = \"纵坐标（米）\", fill = \"辐射强度\") +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.75, 0.1),\n    legend.direction = \"horizontal\",\n    legend.background = element_blank()\n  )\n\np4 &lt;- ggplot() +\n  geom_stars(\n    data = rongelap_stars, na.action = na.omit,\n    aes(fill = ypred), show.legend = FALSE\n  ) +\n  geom_sf(\n    data = rongelap_coastline_sfp,\n    fill = NA, color = \"gray30\", linewidth = 0.75\n  ) +\n  scale_fill_viridis_c(option = \"C\", breaks = 0:12) +\n  # 虚线框\n  geom_sf(data = dash_sfp, fill = NA, linewidth = 0.75, lty = 2) +\n  theme_void() +\n  coord_sf(expand = FALSE, xlim = c(-6000, -5000), ylim = c(-3600, -2600))\n# 叠加图形\np3\nprint(p4, vp = grid::viewport(x = .3, y = .65, width = .45, height = .45))\n\n\n\n\n\n\n\n\nDiggle, P. J., J. A. Tawn, 和 R. A. Moyeed. 1998. 《Model-based geostatistics》. Journal of the Royal Statistical Society: Series C (Applied Statistics) 47 (3): 299–350. https://doi.org/10.1111/1467-9876.00113.\n\n\nNiyizibi, Bart, Wade Brorsen, 和 Eunchun Park. 2018. 《Using Bayesian Kriging for Spatial Smoothing of Trends in the Means and Variances of Crop Yield Densities》. Economic Geography. https://doi.org/10.22004/ag.econ.274403.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>高斯过程回归</span>"
    ]
  },
  {
    "objectID": "time-series-regression.html",
    "href": "time-series-regression.html",
    "title": "39  时间序列回归",
    "section": "",
    "text": "39.1 随机波动率模型\n随机波动率模型主要用于股票时间序列数据建模。本节以美团股价数据为例介绍随机波动率模型，并分别以 Stan 框架和 fGarch 包拟合模型。\n# 美团上市至 2023-07-15\nmeituan &lt;- readRDS(file = \"data/meituan.rds\")\nlibrary(zoo)\nlibrary(xts)\nlibrary(ggplot2)\nautoplot(meituan[, \"3690.HK.Adjusted\"]) +\n  theme_classic() +\n  labs(x = \"日期\", y = \"股价\")\n\n\n\n\n\n\n图 39.1: 美团股价走势\n对数收益率的计算公式如下：\n\\[\n\\text{对数收益率} = \\ln(\\text{今日收盘价} / \\text{昨日收盘价} ) = \\ln (1 + \\text{普通收益率})\n\\]\n下图给出股价对数收益率变化和股价对数收益率的分布，可以看出在不同时间段，收益率波动幅度是不同的，美团股价对数收益率的分布可以看作正态分布。\n检查对数收益率序列的自相关图\nacf(meituan_log_return, main = \"\")\n\n\n\n\n\n\n图 39.3: 对数收益率的自相关图\n发现，滞后 2、3、6、26 阶都有出界，滞后 17 阶略微出界，其它的自相关都在零水平线的界限内。\nBox.test(meituan_log_return, lag = 12, type = \"Ljung\")\n\n#&gt; \n#&gt;  Box-Ljung test\n#&gt; \n#&gt; data:  meituan_log_return\n#&gt; X-squared = 35.669, df = 12, p-value = 0.0003661\n在 0.05 水平下拒绝了白噪声检验，说明对数收益率序列存在相关性。同理，也注意到对数收益率的绝对值和平方序列都不是独立的，存在相关性。\n# ARCH 效应的检验\nBox.test((meituan_log_return - mean(meituan_log_return))^2, \n         lag = 12, type = \"Ljung\")\n\n#&gt; \n#&gt;  Box-Ljung test\n#&gt; \n#&gt; data:  (meituan_log_return - mean(meituan_log_return))^2\n#&gt; X-squared = 124.54, df = 12, p-value &lt; 2.2e-16\n结果高度显著，说明有 ARCH 效应。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>时间序列回归</span>"
    ]
  },
  {
    "objectID": "time-series-regression.html#随机波动率模型",
    "href": "time-series-regression.html#随机波动率模型",
    "title": "39  时间序列回归",
    "section": "",
    "text": "meituan_log_return &lt;- diff(log(meituan[, \"3690.HK.Adjusted\"]))[-1]\nautoplot(meituan_log_return) +\n  theme_classic() +\n  labs(x = \"日期\", y = \"对数收益率\")\nggplot(data = meituan_log_return, aes(x = `3690.HK.Adjusted`)) +\n  geom_histogram(color = \"black\", fill = \"gray\", bins = 30) +\n  theme_classic() +\n  labs(x = \"对数收益率\", y = \"频数（天数）\")\n\n\n\n\n\n\n\n\n\n(a) 对数收益率的变动\n\n\n\n\n\n\n\n\n\n(b) 对数收益率的分布\n\n\n\n\n\n\n图 39.2: 美团股价对数收益率的情况\n\n\n\n\n\n\n\n\n\n\n39.1.1 Stan 框架\n随机波动率模型如下\n\\[\n\\begin{aligned}\ny_t        &=    \\epsilon_t \\exp(h_t / 2) \\\\\nh_{t+1}    &=    \\mu + \\phi (h_t - \\mu) + \\delta_t \\sigma \\\\\nh_1        &\\sim \\textsf{normal}\\left( \\mu, \\frac{\\sigma}{\\sqrt{1 - \\phi^2}} \\right) \\\\\n\\epsilon_t &\\sim \\textsf{normal}(0,1) \\\\\n\\delta_t   &\\sim \\textsf{normal}(0,1)\n\\end{aligned}\n\\]\n其中， \\(y_t\\) 表示在时间 \\(t\\) 时股价的回报（对数收益率），\\(\\epsilon_t\\) 表示股价回报在时间 \\(t\\) 时的白噪声扰/波动，\\(\\delta_t\\) 表示波动率在时间\\(t\\) 时的波动。\\(h_t\\) 表示对数波动率，带有参数 \\(\\mu\\) （对数波动率的均值），\\(\\phi\\) （对数波动率的趋势）。代表波动率的序列 \\(\\{h_t\\}\\) 假定是平稳 \\((|\\phi| &lt; 1)\\) 的随机过程，\\(h_1\\) 来自平稳的分布（此处为正态分布），\\(\\epsilon_t\\) 和 \\(\\delta_t\\) 是服从不相关的标准正态分布。\nStan 代码如下\ndata {\n  int&lt;lower=0&gt; T;   // # time points (equally spaced)\n  vector[T] y;      // mean corrected return at time t\n}\nparameters {\n  real mu;                     // mean log volatility\n  real&lt;lower=-1, upper=1&gt; phi; // persistence of volatility\n  real&lt;lower=0&gt; sigma;         // white noise shock scale\n  vector[T] h_std;             // std log volatility time t\n}\ntransformed parameters {\n  vector[T] h = h_std * sigma;  // now h ~ normal(0, sigma)\n  h[1] /= sqrt(1 - phi * phi);  // rescale h[1]\n  h += mu;\n  for (t in 2:T) {\n    h[t] += phi * (h[t - 1] - mu);\n  }\n}\nmodel {\n  phi ~ uniform(-1, 1);\n  sigma ~ cauchy(0, 5);\n  mu ~ cauchy(0, 10);\n  \n  h_std ~ std_normal();\n  y ~ normal(0, exp(h / 2));\n}\n编译和拟合模型\n\nlibrary(cmdstanr)\n# 编译模型\nmod_volatility_normal &lt;- cmdstan_model(\n  stan_file = \"code/stochastic_volatility_models.stan\",\n  compile = TRUE, cpp_options = list(stan_threads = TRUE)\n)\n# 准备数据\nmdata = list(T = 1274, y = as.vector(meituan_log_return))\n# 拟合模型\nfit_volatility_normal &lt;- mod_volatility_normal$sample(\n  data = mdata,\n  chains = 2,\n  parallel_chains = 2,\n  iter_warmup = 1000, \n  iter_sampling = 1000, \n  threads_per_chain = 2, \n  seed = 20232023,\n  show_messages = FALSE,\n  refresh = 0\n)\n# 输出结果\nfit_volatility_normal$summary(c(\"mu\", \"phi\", \"sigma\", \"lp__\"))\n\n#&gt; # A tibble: 4 × 10\n#&gt;   variable     mean   median      sd     mad       q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu         -6.86    -6.86   0.116   0.111    -7.04    -6.67   1.00    1536.\n#&gt; 2 phi         0.912    0.917  0.0342  0.0314    0.850    0.957  1.01     287.\n#&gt; 3 sigma       0.299    0.294  0.0613  0.0575    0.209    0.407  1.00     309.\n#&gt; 4 lp__     3089.    3089.    29.1    29.8    3039.    3135.     1.00     548.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\n39.1.2 fGarch 包\n《金融时间序列分析讲义》两个波动率建模方法\n\n自回归条件异方差模型（Autoregressive Conditional Heteroskedasticity，简称 ARCH）。\n广义自回归条件异方差模型 （Generalized Autoregressive Conditional Heteroskedasticity，简称 GARCH ）\n\n确定 ARCH 模型的阶，观察残差的平方的 ACF 和 PACF 。\nacf((meituan_log_return - mean(meituan_log_return))^2, main = \"\")\npacf((meituan_log_return - mean(meituan_log_return))^2, main = \"\")\n\n\n\n\n\n\n\n\n\n(a) 自相关图\n\n\n\n\n\n\n\n\n\n(b) 偏自相关图\n\n\n\n\n\n\n图 39.4: 对数收益率的残差平方\n\n\n发现 ACF 在滞后 1、2、3 阶比较突出，PACF 在滞后 1、2、16、18、29 阶比较突出。所以下面先来考虑低阶的 ARCH(2) 模型，设 \\(r_t\\) 为对数收益率。\n\\[\n\\begin{aligned}\nr_t &= \\mu + a_t, \\quad a_t = \\sigma_t \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0,1) \\\\\n\\sigma_t^2 &= \\alpha_0 + \\alpha_1 a_{t-1}^2\n  + \\alpha_2 a_{t-2}^2.\n\\end{aligned}\n\\]\n拟合 ARCH 模型，比较模型估计结果，根据系数显著性的结果，采纳 ARCH(2) 模型。\n\nlibrary(fGarch)\nmeituan_garch1 &lt;- garchFit(\n  formula = ~ 1 + garch(2, 0),\n  data = meituan_log_return, trace = FALSE, cond.dist = \"std\"\n)\nsummary(meituan_garch1)\n\n#&gt; \n#&gt; Title:\n#&gt;  GARCH Modelling \n#&gt; \n#&gt; Call:\n#&gt;  garchFit(formula = ~1 + garch(2, 0), data = meituan_log_return, \n#&gt;     cond.dist = \"std\", trace = FALSE) \n#&gt; \n#&gt; Mean and Variance Equation:\n#&gt;  data ~ 1 + garch(2, 0)\n#&gt; &lt;environment: 0x7fa3a32273c8&gt;\n#&gt;  [data = meituan_log_return]\n#&gt; \n#&gt; Conditional Distribution:\n#&gt;  std \n#&gt; \n#&gt; Coefficient(s):\n#&gt;        mu      omega     alpha1     alpha2      shape  \n#&gt; 0.0002577  0.0010729  0.1119940  0.1382923  4.9356152  \n#&gt; \n#&gt; Std. Errors:\n#&gt;  based on Hessian \n#&gt; \n#&gt; Error Analysis:\n#&gt;         Estimate  Std. Error  t value Pr(&gt;|t|)    \n#&gt; mu     2.577e-04   8.970e-04    0.287  0.77390    \n#&gt; omega  1.073e-03   9.432e-05   11.375  &lt; 2e-16 ***\n#&gt; alpha1 1.120e-01   4.292e-02    2.609  0.00907 ** \n#&gt; alpha2 1.383e-01   4.725e-02    2.927  0.00343 ** \n#&gt; shape  4.936e+00   7.008e-01    7.043 1.88e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Log Likelihood:\n#&gt;  2459.345    normalized:  1.930412 \n#&gt; \n#&gt; Description:\n#&gt;  Tue Jan 23 08:15:54 2024 by user:  \n#&gt; \n#&gt; \n#&gt; Standardised Residuals Tests:\n#&gt;                                  Statistic      p-Value\n#&gt;  Jarque-Bera Test   R    Chi^2  260.647924 0.000000e+00\n#&gt;  Shapiro-Wilk Test  R    W        0.975911 9.515126e-14\n#&gt;  Ljung-Box Test     R    Q(10)   21.212778 1.965775e-02\n#&gt;  Ljung-Box Test     R    Q(15)   24.773595 5.306786e-02\n#&gt;  Ljung-Box Test     R    Q(20)   33.252167 3.165160e-02\n#&gt;  Ljung-Box Test     R^2  Q(10)   17.362563 6.671658e-02\n#&gt;  Ljung-Box Test     R^2  Q(15)   29.329034 1.458467e-02\n#&gt;  Ljung-Box Test     R^2  Q(20)   53.703334 6.400548e-05\n#&gt;  LM Arch Test       R    TR^2    19.254073 8.257864e-02\n#&gt; \n#&gt; Information Criterion Statistics:\n#&gt;       AIC       BIC       SIC      HQIC \n#&gt; -3.852975 -3.832764 -3.853006 -3.845384\n\n\n函数 garchFit() 的参数 cond.dist 默认值为 \"norm\" 表示标准正态分布，cond.dist = \"std\" 表示标准 t 分布。模型均值的估计值接近 0 是符合预期的，且显著性没通过，对数收益率在 0 上下波动。将估计结果代入模型，得到\n\\[\n\\begin{aligned}\nr_t &= -5.665 \\times 10^{-5} + a_t, \\quad a_t = \\sigma_t \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0,1) \\\\\n\\sigma_t^2 &= 1.070 \\times 10^{-3} + 0.1156 a_{t-1}^2 + 0.1438a_{t-2}^2.\n\\end{aligned}\n\\]\n下面考虑 GARCH(1,1) 模型\n\\[\n\\begin{aligned}\nr_t &= \\mu + a_t, \\quad a_t = \\sigma_t \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0,1) \\\\\n\\sigma_t^2 &= \\alpha_0 + \\alpha_1 a_{t-1}^2\n  + \\beta_1 \\sigma_{t-1}^2.\n\\end{aligned}\n\\]\n\nmeituan_garch2 &lt;- garchFit(\n  formula = ~ 1 + garch(1, 1),\n  data = meituan_log_return, trace = FALSE, cond.dist = \"std\"\n)\nsummary(meituan_garch2)\n\n#&gt; \n#&gt; Title:\n#&gt;  GARCH Modelling \n#&gt; \n#&gt; Call:\n#&gt;  garchFit(formula = ~1 + garch(1, 1), data = meituan_log_return, \n#&gt;     cond.dist = \"std\", trace = FALSE) \n#&gt; \n#&gt; Mean and Variance Equation:\n#&gt;  data ~ 1 + garch(1, 1)\n#&gt; &lt;environment: 0x7fa3888e4f60&gt;\n#&gt;  [data = meituan_log_return]\n#&gt; \n#&gt; Conditional Distribution:\n#&gt;  std \n#&gt; \n#&gt; Coefficient(s):\n#&gt;         mu       omega      alpha1       beta1       shape  \n#&gt; 2.8296e-04  3.4454e-05  5.9798e-02  9.1678e-01  5.4352e+00  \n#&gt; \n#&gt; Std. Errors:\n#&gt;  based on Hessian \n#&gt; \n#&gt; Error Analysis:\n#&gt;         Estimate  Std. Error  t value Pr(&gt;|t|)    \n#&gt; mu     2.830e-04   8.702e-04    0.325  0.74505    \n#&gt; omega  3.445e-05   1.937e-05    1.779  0.07525 .  \n#&gt; alpha1 5.980e-02   1.855e-02    3.224  0.00127 ** \n#&gt; beta1  9.168e-01   2.784e-02   32.933  &lt; 2e-16 ***\n#&gt; shape  5.435e+00   8.137e-01    6.680 2.39e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Log Likelihood:\n#&gt;  2478.473    normalized:  1.945427 \n#&gt; \n#&gt; Description:\n#&gt;  Tue Jan 23 08:15:54 2024 by user:  \n#&gt; \n#&gt; \n#&gt; Standardised Residuals Tests:\n#&gt;                                   Statistic      p-Value\n#&gt;  Jarque-Bera Test   R    Chi^2  226.7198909 0.000000e+00\n#&gt;  Shapiro-Wilk Test  R    W        0.9781165 5.582467e-13\n#&gt;  Ljung-Box Test     R    Q(10)   16.0489249 9.824041e-02\n#&gt;  Ljung-Box Test     R    Q(15)   19.6491086 1.858104e-01\n#&gt;  Ljung-Box Test     R    Q(20)   27.2460587 1.284822e-01\n#&gt;  Ljung-Box Test     R^2  Q(10)    7.8054550 6.478332e-01\n#&gt;  Ljung-Box Test     R^2  Q(15)    9.8336579 8.300707e-01\n#&gt;  Ljung-Box Test     R^2  Q(20)   24.7640454 2.106076e-01\n#&gt;  LM Arch Test       R    TR^2     9.5999700 6.510091e-01\n#&gt; \n#&gt; Information Criterion Statistics:\n#&gt;       AIC       BIC       SIC      HQIC \n#&gt; -3.883004 -3.862792 -3.883034 -3.875413\n\n\n波动率的贡献主要来自 \\(\\sigma_{t-1}^2\\) ，其系数 \\(\\beta_1\\) 为 0.918。通过对数似然的比较，可以发现 GARCH(1,1) 模型比 ARCH(2) 模型更好。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>时间序列回归</span>"
    ]
  },
  {
    "objectID": "time-series-regression.html#贝叶斯可加模型",
    "href": "time-series-regression.html#贝叶斯可加模型",
    "title": "39  时间序列回归",
    "section": "\n39.2 贝叶斯可加模型",
    "text": "39.2 贝叶斯可加模型\n大规模时间序列回归，观察值是比较多的，可达数十万、数百万，乃至更多。粗粒度时时间跨度往往很长，比如数十年的天粒度数据，细粒度时时间跨度可短可长，比如数年的半小时级数据，总之，需要包含多个季节的数据，各种季节性重复出现。通过时序图可以观察到明显的季节性，而且往往是多种周期不同的季节性混合在一起，有时还包含一定的趋势性。举例来说，比如 2018-2023 年美国旧金山犯罪事件报告数据，事件数量的变化趋势，除了上述季节性因素，特殊事件疫情肯定会影响，数据规模约 200 M 。再比如 2018-2023 年美国境内和跨境旅游业中的航班数据，原始数据非常大，R 包 nycflights13 提供纽约机场的部分航班数据。\n为简单起见，下面以 R 内置的数据集 AirPassengers 为例，介绍 Stan 框架和 INLA 框架建模的过程。数据集 AirPassengers 包含周期性（季节性）和趋势性。作为对比的基础，下面建立非线性回归模型，趋势项和周期项是可加的形式：\n\\[\ny = at + b + c \\sin(\\frac{t}{12} \\times 2\\pi) + d \\cos(\\frac{t}{12} \\times 2\\pi) + \\epsilon\n\\]\n根据数据变化的周期规律，设置周期为 12，还可以在模型中添加周期为 3 或 4 的小周期。其中，\\(y\\) 代表观察值， \\(a,b,c,d\\) 为待定的参数，\\(\\epsilon\\) 代表服从标准正态分布的随机误差。\n\nair_passengers_df &lt;- data.frame(y = as.vector(AirPassengers), t = 1:144)\nfit_lm1 &lt;- lm(y ~ t + sin(t / 12 * 2 * pi) + cos(t / 12 * 2 * pi), data = air_passengers_df)\nfit_lm2 &lt;- update(fit_lm1, . ~ . +\n  sin(t / 12 * 2 * 2 * pi) + cos(t / 12 * 2 * 2 * pi), data = air_passengers_df\n)\nfit_lm3 &lt;- update(fit_lm2, . ~ . +\n  sin(t / 12 * 3 * 2 * pi) + cos(t / 12 * 3 * 2 * pi), data = air_passengers_df\n)\nplot(y ~ t, air_passengers_df, type = \"l\")\nlines(x = air_passengers_df$t, y = fit_lm1$fitted.values, col = \"red\")\nlines(x = air_passengers_df$t, y = fit_lm2$fitted.values, col = \"green\")\nlines(x = air_passengers_df$t, y = fit_lm3$fitted.values, col = \"orange\")\n\n\n\n\n\n\n图 39.5: 非线性回归\n\n\n\n\n模型 1 已经很好地捕捉到趋势和周期信息，当添加小周期后，略有改善，继续添加更多的小周期，不再有明显改善。实际上，小周期对应的回归系数也将不再显著。所以，这类模型的优化空间见顶了，需要进一步观察和利用残差的规律，使用更加复杂的模型。\n\n39.2.1 Stan 框架\n非线性趋势、多季节性（多个周期混合）、特殊节假日、突发热点事件、残差成分（平稳），能同时应对这五种情况的建模方法是贝叶斯可加模型和神经网络模型，比如基于 Stan 实现的 prophet 包和 tensorflow 框架。\n\n\n\n\n\n\n提示\n\n\n\nprophet 包是如何同时处理这些情况，是否可以在 cmdstanr 包中实现，是否可以在 mgcv 和 INLA 中实现？\n\n\n\nlibrary(cmdstanr)\n\n\n39.2.2 INLA 框架\n阿卜杜拉国王科技大学（King Abdullah University of Science and Technology 简称 KAUST）的 Håvard Rue 等开发了 INLA 框架 (Rue, Martino, 和 Chopin 2009)。《贝叶斯推断与 INLA 》的第3章混合效应模型中随机游走部分 (Gómez-Rubio 2020)，一个随机过程（如随机游走、AR(p) 过程）作为随机效应。AirPassengers 的方差在变大，取对数尺度后，方差基本保持不变，一阶差分后基本保持平稳。\nlibrary(ggfortify)\nautoplot(log(AirPassengers)) +\n  theme_classic() +\n  labs(x = \"年月\", y = \"对数值\")\nautoplot(diff(log(AirPassengers))) +\n  theme_classic() +\n  labs(x = \"年月\", y = \"差分对数值\")\n\n\n\n\n\n\n\n\n\n(a) 对数尺度\n\n\n\n\n\n\n\n\n\n(b) 一阶差分\n\n\n\n\n\n\n图 39.6: AirPassengers 的时序图\n\n\n因此，下面基于对数尺度建模。首先考虑 RW1 随机游走模型，而后考虑季节性。RW1 模型意味着取对数、一阶差分后序列平稳高斯过程，序列值服从高斯分布。下面设置似然函数的高斯先验 \\(\\mathcal{N}(1,0.2)\\) ，目的是防止过拟合。\n\nlibrary(INLA)\ninla.setOption(short.summary = TRUE)\nair_passengers_df &lt;- data.frame(\n  y = as.vector(AirPassengers),\n  year = as.factor(rep(1949:1960, each = 12)),\n  month = as.factor(rep(1:12, times = 12)),\n  ID = 1:length(AirPassengers)\n)\nmod_inla_rw1 &lt;- inla(\n  formula = log(y) ~ year + f(ID, model = \"rw1\"),\n  family = \"gaussian\", data = air_passengers_df,\n  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),\n  control.predictor = list(compute = TRUE)\n)\nsummary(mod_inla_rw1)\n\n#&gt; Fixed effects:\n#&gt;              mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; (Intercept) 5.159 0.252      4.666    5.158      5.657 5.158   0\n#&gt; year1950    0.050 0.134     -0.215    0.050      0.313 0.050   0\n#&gt; year1951    0.174 0.190     -0.201    0.174      0.546 0.174   0\n#&gt; year1952    0.262 0.233     -0.198    0.262      0.717 0.262   0\n#&gt; year1953    0.330 0.269     -0.201    0.331      0.857 0.331   0\n#&gt; year1954    0.357 0.301     -0.236    0.358      0.945 0.358   0\n#&gt; year1955    0.442 0.329     -0.208    0.443      1.086 0.443   0\n#&gt; year1956    0.510 0.356     -0.193    0.511      1.206 0.511   0\n#&gt; year1957    0.567 0.380     -0.184    0.568      1.311 0.568   0\n#&gt; year1958    0.576 0.403     -0.219    0.577      1.365 0.577   0\n#&gt; year1959    0.647 0.425     -0.191    0.648      1.478 0.648   0\n#&gt; year1960    0.683 0.445     -0.195    0.684      1.555 0.685   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                                           mean    sd 0.025quant 0.5quant\n#&gt; Precision for the Gaussian observations 101.38 18.14      69.78    99.99\n#&gt; Precision for ID                        155.14 40.70      92.68   149.33\n#&gt;                                         0.975quant   mode\n#&gt; Precision for the Gaussian observations     140.94  97.59\n#&gt; Precision for ID                            251.69 137.50\n#&gt; \n#&gt;  is computed\n\n\n这里，将年份作为因子型变量，从输出结果可以看出，以1949年作为参照，回归系数的后验均值在逐年变大，这符合 AirPassengers 时序图呈现的趋势。\n存在周期性的波动规律，考虑季节性\n\nmod_inla_sea &lt;- inla(\n  formula = log(y) ~ year + f(ID, model = \"seasonal\", season.length = 12),\n  family = \"gaussian\", data = air_passengers_df,\n  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),\n  control.predictor = list(compute = TRUE)\n)\nsummary(mod_inla_sea)\n\n#&gt; Fixed effects:\n#&gt;              mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n#&gt; (Intercept) 4.836 0.020      4.797    4.836      4.875 4.836   0\n#&gt; year1950    0.095 0.028      0.039    0.095      0.150 0.095   0\n#&gt; year1951    0.295 0.028      0.240    0.295      0.351 0.295   0\n#&gt; year1952    0.441 0.028      0.386    0.441      0.496 0.441   0\n#&gt; year1953    0.573 0.028      0.517    0.573      0.628 0.573   0\n#&gt; year1954    0.630 0.028      0.575    0.630      0.686 0.630   0\n#&gt; year1955    0.803 0.028      0.748    0.803      0.859 0.803   0\n#&gt; year1956    0.948 0.028      0.893    0.948      1.004 0.948   0\n#&gt; year1957    1.062 0.028      1.007    1.062      1.118 1.062   0\n#&gt; year1958    1.094 0.028      1.039    1.094      1.150 1.094   0\n#&gt; year1959    1.212 0.028      1.157    1.212      1.268 1.212   0\n#&gt; year1960    1.318 0.028      1.263    1.318      1.373 1.318   0\n#&gt; \n#&gt; Model hyperparameters:\n#&gt;                                             mean       sd 0.025quant 0.5quant\n#&gt; Precision for the Gaussian observations   213.04    27.49     163.50   211.48\n#&gt; Precision for ID                        42046.17 27441.51   10108.28 35358.49\n#&gt;                                         0.975quant     mode\n#&gt; Precision for the Gaussian observations     271.53   208.76\n#&gt; Precision for ID                         113181.83 24344.42\n#&gt; \n#&gt;  is computed\n\n\n最后，将两个模型的拟合结果展示出来，见下图，黑线表示原对数值，红线表示拟合值，灰色区域表示在置信水平 95% 下的区间。区间更短说明季节性模型更好。\nmod_inla_rw1_fitted &lt;- data.frame(\n  ID = 1:length(AirPassengers),\n  y = as.vector(log(AirPassengers)),\n  mean = mod_inla_rw1$summary.fitted.values$mean,\n  `0.025quant` = mod_inla_rw1$summary.fitted.values$`0.025quant`,\n  `0.975quant` = mod_inla_rw1$summary.fitted.values$`0.975quant`,\n  check.names = FALSE\n)\nmod_inla_sea_fitted &lt;- data.frame(\n  ID = 1:length(AirPassengers),\n  y = as.vector(log(AirPassengers)),\n  mean = mod_inla_sea$summary.fitted.values$mean,\n  `0.025quant` = mod_inla_sea$summary.fitted.values$`0.025quant`,\n  `0.975quant` = mod_inla_sea$summary.fitted.values$`0.975quant`,\n  check.names = FALSE\n)\nggplot(data = mod_inla_rw1_fitted, aes(ID)) +\n  geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), fill = \"gray\") +\n  geom_line(aes(y = y)) +\n  geom_line(aes(y = mean), color = \"red\") +\n  theme_classic() +\n  labs(x = \"序号\", y = \"对数值\")\nggplot(data = mod_inla_sea_fitted, aes(ID)) +\n  geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), fill = \"gray\") +\n  geom_line(aes(y = y)) +\n  geom_line(aes(y = mean), color = \"red\") +\n  theme_classic() +\n  labs(x = \"序号\", y = \"对数值\")\n\n\n\n\n\n\n\n\n\n(a) 随机游走模型\n\n\n\n\n\n\n\n\n\n(b) 季节效应模型\n\n\n\n\n\n\n图 39.7: AirPassengers 的拟合图",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>时间序列回归</span>"
    ]
  },
  {
    "objectID": "time-series-regression.html#一些非参数模型",
    "href": "time-series-regression.html#一些非参数模型",
    "title": "39  时间序列回归",
    "section": "\n39.3 一些非参数模型",
    "text": "39.3 一些非参数模型\n\n39.3.1 mgcv 包\nmgcv 包 (S. N. Wood 2017) 是 R 软件内置的推荐组件，由 Simon Wood 开发和维护，历经多年，成熟稳定。函数 bam() 相比于函数 gam() 的优势是可以处理大规模的时间序列数据。对于时间序列数据预测，数万和百万级观测值都可以 (Simon N. Wood, Goude, 和 Shaw 2015)。\n\nair_passengers_tbl &lt;- data.frame(\n  y = as.vector(AirPassengers),\n  year = rep(1949:1960, each = 12),\n  month = rep(1:12, times = 12)\n)\nmod1 &lt;- gam(y ~ s(year) + s(month, bs = \"cr\", k = 12),\n  data = air_passengers_tbl, family = gaussian\n)\nsummary(mod1)\n\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; y ~ s(year) + s(month, bs = \"cr\", k = 12)\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  280.299      1.957   143.2   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;            edf Ref.df      F p-value    \n#&gt; s(year)  6.102  7.265 441.39  &lt;2e-16 ***\n#&gt; s(month) 8.796 10.097  38.25  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.962   Deviance explained = 96.6%\n#&gt; GCV =  619.9  Scale est. = 551.47    n = 144\n\n\n观察年和月的趋势变化，逐年增长趋势基本是线性的，略有波动，逐月变化趋势比较复杂，不过，可以明显看出在 7-9 月是高峰期，11 月和1-3月是低谷期。\n\nlayout(matrix(1:2, nrow = 1))\nplot(mod1, shade = TRUE)\n\n\n\n\n\n\n图 39.8: 年和月的趋势变化\n\n\n\n\n将拟合效果绘制出来，见下图，整体上，捕捉到了趋势和周期，不过，存在欠拟合，年周期内波动幅度随时间有变化趋势，趋势和周期存在交互作用。\n\nair_passengers_ts &lt;- ts(mod1$fitted.values, start = c(1949, 1), frequency = 12)\nplot(AirPassengers)\nlines(air_passengers_ts, col = \"red\")\n\n\n\n\n\n\n图 39.9: 趋势拟合效果\n\n\n\n\n整体上，乘客数逐年呈线性增长，每年不同月份呈现波动，淡季和旺季出行的流量有很大差异，近年来，这种差异的波动在扩大。为了刻画这种情况，考虑年度趋势和月度波动的交互作用。\n\nmod2 &lt;- gam(y ~ s(year, month), data = air_passengers_tbl, family = gaussian)\nsummary(mod2)\n\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; y ~ s(year, month)\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  280.299      1.059   264.7   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;                 edf Ref.df     F p-value    \n#&gt; s(year,month) 28.21  28.96 435.5  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.989   Deviance explained = 99.1%\n#&gt; GCV = 202.62  Scale est. = 161.52    n = 144\n\n\n可以看到，调整的 \\(R^2\\) 明显增加，拟合效果更好，各年各月份的乘客数变化，见下图。\n\nop &lt;- par(mar = c(4, 4, 2, 0))\nplot(mod2)\non.exit(par(op), add = TRUE) \n\n\n\n\n\n\n图 39.10: 交互作用\n\n\n\n\n上图是轮廓图，下面用透视图展示趋势拟合的效果。\n\nop &lt;- par(mar = c(0, 1.5, 0, 0))\nvis.gam(mod2, theta = -35, phi = 20, ticktype = \"detailed\", expand = .65, zlab = \"\")\non.exit(par(op), add = TRUE) \n\n\n\n\n\n\n图 39.11: 趋势拟合效果\n\n\n\n\n最后，在原始数据的基础上，添加拟合数据，得到如下拟合趋势图，与前面的拟合图比较，可以看出效果提升很明显。\n\nair_passengers_ts &lt;- ts(mod2$fitted.values, start = c(1949, 1), frequency = 12)\nplot(AirPassengers)\nlines(air_passengers_ts, col = \"red\")\n\n\n\n\n\n\n图 39.12: 趋势拟合效果\n\n\n\n\n\n39.3.2 tensorflow 框架\n前面介绍的模型都具有非常强的可解释性，比如各个参数对模型的作用。对于复杂的时间序列数据，比较适合用复杂的模型来拟合，看重模型的泛化能力，而不那么关注模型的机理。\n多层感知机是一种全连接层的前馈神经网络。nnet 包的函数 nnet() 实现了单隐藏层的简单前馈神经网络，可用于时间序列预测，也可用于分类数据的预测。作为对比的基础，下面先用 nnet 包训练和预测数据。\n\n# 准备数据\nair_passengers &lt;- as.matrix(embed(AirPassengers, 4))\ncolnames(air_passengers) &lt;- c(\"y\", \"x3\", \"x2\", \"x1\")\ndata_size &lt;- nrow(air_passengers)\n# 拆分数据集\ntrain_size &lt;- floor(data_size * 0.67)\ntrain_data &lt;- air_passengers[1:train_size, ]\ntest_data &lt;- air_passengers[train_size:data_size, ]\n\n# 随机数种子对结果的影响非常大 试试 set.seed(20232023) \nset.seed(20222022) \n# 单隐藏层 8 个神经元\nmod_nnet &lt;- nnet::nnet(\n  y ~ x1 + x2 + x3,\n  data = air_passengers, # 数据集\n  subset = 1:train_size, # 训练数据的指标向量\n  linout = TRUE, size = 4, rang = 0.1,\n  decay = 5e-4, maxit = 400, trace = FALSE\n)\n# 预测\ntrain_pred &lt;- predict(mod_nnet, newdata = air_passengers[1:train_size,], type = \"raw\")\n# 训练集 RMSE\nsqrt(mean((air_passengers[1:train_size, \"y\"] - train_pred )^2))\n\n#&gt; [1] 21.59392\n\n# 预测\ntest_pred &lt;- predict(mod_nnet, newdata = air_passengers[-(1:train_size),], type = \"raw\")\n# 测试集 RMSE\nsqrt(mean((air_passengers[-(1:train_size), \"y\"] - test_pred)^2))\n\n#&gt; [1] 53.79107\n\n\n下面将原观测序列，训练集和测试集上的预测序列放在一张图上展示。图中，红色曲线表示训练集上的预测结果，绿色曲线为测试集上预测结果。\n\ntrain_pred_ts &lt;- ts(data = train_pred, start = c(1949, 3), frequency = 12)\ntest_pred_ts &lt;- ts(data = test_pred, start = c(1957, 1), frequency = 12)\nplot(AirPassengers)\nlines(train_pred_ts, col = \"red\")\nlines(test_pred_ts, col = \"green\")\n\n\n\n\n\n\n图 39.13: 单层感知机预测\n\n\n\n\n由图可知，在测试集上，随着时间拉长，预测越来越不准。\n下面使用 tensorflow 包构造多层感知机训练数据和预测。\n\nlibrary(tensorflow)\nlibrary(keras)\nset_random_seed(20222022)\n# 模型结构\nmod_mlp &lt;- keras_model_sequential() |&gt; \n  layer_dense(units = 12, activation = \"relu\", input_shape = c(3)) |&gt; \n  layer_dense(units = 8, activation = \"relu\") |&gt; \n  layer_dense(units = 1)\n# 训练目标\ncompile(mod_mlp,\n  loss = \"mse\", # 损失函数\n  optimizer = \"adam\", # 优化器\n  metrics = \"mae\" # 监控度量\n)\n# 模型概览\nsummary(mod_mlp)\n\n#&gt; Model: \"sequential\"\n#&gt; ________________________________________________________________________________\n#&gt;  Layer (type)                       Output Shape                    Param #     \n#&gt; ================================================================================\n#&gt;  dense_2 (Dense)                    (None, 12)                      48          \n#&gt;  dense_1 (Dense)                    (None, 8)                       104         \n#&gt;  dense (Dense)                      (None, 1)                       9           \n#&gt; ================================================================================\n#&gt; Total params: 161 (644.00 Byte)\n#&gt; Trainable params: 161 (644.00 Byte)\n#&gt; Non-trainable params: 0 (0.00 Byte)\n#&gt; ________________________________________________________________________________\n\n\n输入层为 3 个节点，中间两个隐藏层，第一层为 12 个节点，第二层为 8 个节点，全连接网络，最后输出为一层单节点，意味着单个输出。每一层都有节点和权重，参数总数为 161。\n\n# 拟合模型\nfit(mod_mlp,\n  x = train_data[, c(\"x1\", \"x2\", \"x3\")],\n  y = train_data[, \"y\"],\n  epochs = 200,\n  batch_size = 10, # 每次更新梯度所用的样本量\n  validation_split = 0.2, # 从训练数据中拆分一部分用作验证集\n  verbose = 0 # 不显示训练进度\n)\n# 将测试数据代入模型，计算损失函数和监控度量\nevaluate(mod_mlp, test_data[, c(\"x1\", \"x2\", \"x3\")], test_data[, \"y\"])\n\n#&gt; 2/2 - 0s - loss: 2517.1836 - mae: 40.8876 - 17ms/epoch - 9ms/step\n\n\n#&gt;       loss        mae \n#&gt; 2517.18359   40.88759\n\n# 测试集上的预测\nmlp_test_pred &lt;- predict(mod_mlp, test_data[, c(\"x1\", \"x2\", \"x3\")]) \n\n#&gt; 2/2 - 0s - 64ms/epoch - 32ms/step\n\nmlp_train_pred &lt;- predict(mod_mlp, train_data[, c(\"x1\", \"x2\", \"x3\")]) \n\n#&gt; 3/3 - 0s - 16ms/epoch - 5ms/step\n\nsqrt(mean((test_data[, \"y\"] - mlp_test_pred)^2)) # 计算均方根误差\n\n#&gt; [1] 50.17154\n\n\n从 RMSE 来看，MLP（多层感知机）预测效果比单层感知机稍好些，可网络复杂度是增加很多的。\n\nmlp_train_pred_ts &lt;- ts(data = mlp_train_pred, start = c(1949, 3), frequency = 12)\nmlp_test_pred_ts &lt;- ts(data = mlp_test_pred, start = c(1957, 1), frequency = 12)\nplot(AirPassengers)\nlines(mlp_train_pred_ts, col = \"red\")\nlines(mlp_test_pred_ts, col = \"green\")\n\n\n\n\n\n\n图 39.14: 多层感知机预测\n\n\n\n\n下面用 LSTM （长短期记忆）神经网络来训练时间序列数据，预测未来一周的趋势。输出不再是一天（单点输出），而是 7 天的预测值（多点输出）。参考 tensorflow 包的官网中 RNN 递归神经网络的介绍。",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>时间序列回归</span>"
    ]
  },
  {
    "objectID": "time-series-regression.html#习题",
    "href": "time-series-regression.html#习题",
    "title": "39  时间序列回归",
    "section": "\n39.4 习题",
    "text": "39.4 习题\n\n\n基于 R 软件内置的数据集 sunspots 和 sunspot.month 比较 INLA 和 mgcv 框架的预测效果。\n\n代码sunspots_tbl &lt;- broom::tidy(sunspots)\nsunspots_month_tbl &lt;- broom::tidy(sunspot.month)\nggplot() +\n  geom_line(data = sunspots_month_tbl, aes(x = index, y = value), color = \"red\") +\n  geom_line(data = sunspots_tbl, aes(x = index, y = value)) +\n  theme_bw() +\n  labs(x = \"年月\", y = \"数量\")\n\n\n\n\n\n\n图 39.15: 预测月粒度太阳黑子数量\n\n\n\n\n图中黑线和红线分别表示 1749-1983 年、1984-2014 年每月太阳黑子数量。\n\n\n\n\n\n\nGómez-Rubio, Virgilio. 2020. Bayesian inference with INLA. Boca Raton, Florida: Chapman; Hall/CRC. https://becarioprecario.bitbucket.io/inla-gitbook/.\n\n\nRue, Håvard, Sara Martino, 和 Nicholas Chopin. 2009. 《Approximate Bayesian Inference for Latent Gaussian Models Using Integrated Nested Laplace Approximations (with discussion)》. Journal of the Royal Statistical Society, Series B 71 (2): 319–92.\n\n\nWood, S. N. 2017. Generalized Additive Models: An Introduction with R. 2nd 本. Chapman; Hall/CRC. https://www.maths.ed.ac.uk/~swood34/igam/.\n\n\nWood, Simon N., Yannig Goude, 和 Simon Shaw. 2015. 《Generalized Additive Models for Large Data Sets》. Journal of the Royal Statistical Society Series C: Applied Statistics 64 (1): 139–55. https://doi.org/10.1111/rssc.12068.",
    "crumbs": [
      "贝叶斯建模",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>时间序列回归</span>"
    ]
  },
  {
    "objectID": "classification-problems.html",
    "href": "classification-problems.html",
    "title": "40  分类问题",
    "section": "",
    "text": "40.1 多项回归模型\nlibrary(nnet) # 多项逻辑回归\niris_multinom &lt;- multinom(Species ~ ., data = iris, trace = FALSE)\nsummary(iris_multinom)\n\nCall:\nmultinom(formula = Species ~ ., data = iris, trace = FALSE)\n\nCoefficients:\n           (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width\nversicolor    18.69037    -5.458424   -8.707401     14.24477   -3.097684\nvirginica    -23.83628    -7.923634  -15.370769     23.65978   15.135301\n\nStd. Errors:\n           (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width\nversicolor    34.97116     89.89215    157.0415     60.19170    45.48852\nvirginica     35.76649     89.91153    157.1196     60.46753    45.93406\n\nResidual Deviance: 11.89973 \nAIC: 31.89973\ntable(predict(iris_multinom, iris[, -5], type = \"class\"), iris[, 5])\n\n            \n             setosa versicolor virginica\n  setosa         50          0         0\n  versicolor      0         49         1\n  virginica       0          1        49\n在有的数据中，观测变量之间存在共线性，采用变量选择方法，比如 Lasso 方法压缩掉一部分变量。\nlibrary(glmnet) # 多项回归\niris_glmnet &lt;- glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\")\n选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80] 。\ncoef(iris_glmnet, s = 0.0002796185)\n\n$setosa\n5 x 1 sparse Matrix of class \"dgCMatrix\"\n                     1\n(Intercept)  17.015429\nSepal.Length  .       \nSepal.Width   4.486992\nPetal.Length -3.250342\nPetal.Width  -3.315393\n\n$versicolor\n5 x 1 sparse Matrix of class \"dgCMatrix\"\n                    1\n(Intercept)  8.132656\nSepal.Length 2.123980\nSepal.Width  .       \nPetal.Length .       \nPetal.Width  .       \n\n$virginica\n5 x 1 sparse Matrix of class \"dgCMatrix\"\n                      1\n(Intercept)  -25.148085\nSepal.Length   .       \nSepal.Width   -5.176029\nPetal.Length   7.536940\nPetal.Width   14.481524\niris_pred_glmnet &lt;- predict(\n  object = iris_glmnet, newx = as.matrix(iris[, -5]),\n  s = 0.0002796185, type = \"class\"\n)\ntable(iris_pred_glmnet, iris[, 5])\n\n                \niris_pred_glmnet setosa versicolor virginica\n      setosa         50          0         0\n      versicolor      0         49         1\n      virginica       0          1        49",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-multinomial-regression-models",
    "href": "classification-problems.html#sec-multinomial-regression-models",
    "title": "40  分类问题",
    "section": "",
    "text": "plot(iris_glmnet)\nplot(iris_glmnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\n\n\n\n(a) 回归系数 setosa 的迭代路径\n\n\n\n\n\n\n\n\n\n(b) 回归系数 versicolor 的迭代路径\n\n\n\n\n\n\n\n\n\n\n\n(c) 回归系数 virginica 的迭代路径\n\n\n\n\n\n\n\n\n\n(d) 惩罚系数的迭代路径\n\n\n\n\n\n\n图 40.1: 迭代路径",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-linear-discriminant-analysis",
    "href": "classification-problems.html#sec-linear-discriminant-analysis",
    "title": "40  分类问题",
    "section": "\n40.2 线性判别分析",
    "text": "40.2 线性判别分析\n\nlibrary(MASS)\n# lda\niris_lda &lt;- lda(Species ~ ., data=iris)\niris_lda\n\nCall:\nlda(Species ~ ., data = iris)\n\nPrior probabilities of groups:\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nGroup means:\n           Sepal.Length Sepal.Width Petal.Length Petal.Width\nsetosa            5.006       3.428        1.462       0.246\nversicolor        5.936       2.770        4.260       1.326\nvirginica         6.588       2.974        5.552       2.026\n\nCoefficients of linear discriminants:\n                    LD1         LD2\nSepal.Length  0.8293776 -0.02410215\nSepal.Width   1.5344731 -2.16452123\nPetal.Length -2.2012117  0.93192121\nPetal.Width  -2.8104603 -2.83918785\n\nProportion of trace:\n   LD1    LD2 \n0.9912 0.0088 \n\n# 预测\niris_lda_pred &lt;- predict(iris_lda, iris[, -5])$class\n\n\n# 预测结果\ntable(iris_lda_pred, iris[, 5])\n\n             \niris_lda_pred setosa versicolor virginica\n   setosa         50          0         0\n   versicolor      0         48         1\n   virginica       0          2        49",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-quadratic-discriminant-analysis",
    "href": "classification-problems.html#sec-quadratic-discriminant-analysis",
    "title": "40  分类问题",
    "section": "\n40.3 二次判别分析",
    "text": "40.3 二次判别分析\n\n# Quadratic Discriminant Analysis 二次判别分析\niris_qda &lt;- qda(Species ~ ., data=iris)\niris_qda\n\nCall:\nqda(Species ~ ., data = iris)\n\nPrior probabilities of groups:\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nGroup means:\n           Sepal.Length Sepal.Width Petal.Length Petal.Width\nsetosa            5.006       3.428        1.462       0.246\nversicolor        5.936       2.770        4.260       1.326\nvirginica         6.588       2.974        5.552       2.026\n\n# 预测\niris_qda_pred &lt;- predict(iris_qda, iris[, -5])$class\n\n\n# 预测结果\ntable(iris_qda_pred, iris[, 5])\n\n             \niris_qda_pred setosa versicolor virginica\n   setosa         50          0         0\n   versicolor      0         48         1\n   virginica       0          2        49\n\n\n\n代码library(mda)\n# Mixture Discriminant Analysis 混合判别分析\niris_mda &lt;- mda(Species ~ ., data = iris)\n# 预测\niris_mda_pred &lt;- predict(iris_mda, newdata = iris[, -5])\n# 预测结果\ntable(iris_mda_pred, iris[, 5])\n\n# Flexible Discriminant Analysis 灵活判别分析\niris_fda &lt;- fda(Species ~ ., data = iris)\n# 预测\niris_fda_pred &lt;- predict(iris_fda, newdata = iris[, -5])\n# 预测结果\ntable(iris_fda_pred, iris[, 5])\n\n# Regularized Discriminant Analysis 正则判别分析\nlibrary(klaR)\niris_rda &lt;- rda(Species ~ ., data = iris, gamma = 0.05, lambda = 0.01)\n# 输出结果\nsummary(iris_rda)\n# 预测\niris_rda_pred &lt;- predict(iris_rda, newdata = iris[, -5])$class\n# 预测结果\ntable(iris_rda_pred, iris[, 5])",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-naive-bayes",
    "href": "classification-problems.html#sec-naive-bayes",
    "title": "40  分类问题",
    "section": "\n40.4 朴素贝叶斯",
    "text": "40.4 朴素贝叶斯\n\nlibrary(e1071) # 朴素贝叶斯\niris_nb &lt;- naiveBayes(Species ~ ., data = iris)\niris_nb\n\n\nNaive Bayes Classifier for Discrete Predictors\n\nCall:\nnaiveBayes.default(x = X, y = Y, laplace = laplace)\n\nA-priori probabilities:\nY\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\nConditional probabilities:\n            Sepal.Length\nY             [,1]      [,2]\n  setosa     5.006 0.3524897\n  versicolor 5.936 0.5161711\n  virginica  6.588 0.6358796\n\n            Sepal.Width\nY             [,1]      [,2]\n  setosa     3.428 0.3790644\n  versicolor 2.770 0.3137983\n  virginica  2.974 0.3224966\n\n            Petal.Length\nY             [,1]      [,2]\n  setosa     1.462 0.1736640\n  versicolor 4.260 0.4699110\n  virginica  5.552 0.5518947\n\n            Petal.Width\nY             [,1]      [,2]\n  setosa     0.246 0.1053856\n  versicolor 1.326 0.1977527\n  virginica  2.026 0.2746501\n\n# 预测\niris_nb_pred &lt;- predict(iris_nb, newdata = iris, type = \"class\")\n# 预测结果\ntable(iris_nb_pred, iris[, 5])\n\n            \niris_nb_pred setosa versicolor virginica\n  setosa         50          0         0\n  versicolor      0         47         3\n  virginica       0          3        47",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-support-vector-machines",
    "href": "classification-problems.html#sec-support-vector-machines",
    "title": "40  分类问题",
    "section": "\n40.5 支持向量机",
    "text": "40.5 支持向量机\ne1071 包也提供支持向量机\n\n# e1071\niris_svm &lt;- svm(Species ~ ., data = iris)\niris_svm\n\n\nCall:\nsvm(formula = Species ~ ., data = iris)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  radial \n       cost:  1 \n\nNumber of Support Vectors:  51\n\n# 预测\niris_svm_pred &lt;- predict(iris_svm, newdata = iris, probability = FALSE)\n# 预测结果\ntable(iris_svm_pred, iris[, 5])\n\n             \niris_svm_pred setosa versicolor virginica\n   setosa         50          0         0\n   versicolor      0         48         2\n   virginica       0          2        48\n\n\nkernlab 包提供核支持向量机。\n\nlibrary(kernlab)\niris_ksvm &lt;- ksvm(Species ~ ., data = iris)\niris_ksvm\n\nSupport Vector Machine object of class \"ksvm\" \n\nSV type: C-svc  (classification) \n parameter : cost C = 1 \n\nGaussian Radial Basis kernel function. \n Hyperparameter : sigma =  0.822026563301033 \n\nNumber of Support Vectors : 59 \n\nObjective Function Value : -4.591 -5.1217 -20.2409 \nTraining error : 0.026667 \n\n\nkernlab 包 (Karatzoglou 等 2004) 的绘图函数 plot() 仅支持二分类模型。\n\niris_pred_svm &lt;- predict(iris_ksvm, iris[, -5], type = \"response\")\ntable(iris_pred_svm, iris[, 5])\n\n             \niris_pred_svm setosa versicolor virginica\n   setosa         50          0         0\n   versicolor      0         48         2\n   virginica       0          2        48",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-k-nearest-neighbour",
    "href": "classification-problems.html#sec-k-nearest-neighbour",
    "title": "40  分类问题",
    "section": "\n40.6 K 最近邻",
    "text": "40.6 K 最近邻\n\n# 将 iris3 数据集拆分为训练集和测试集\niris_train &lt;- rbind(iris3[1:25, , 1], iris3[1:25, , 2], iris3[1:25, , 3])\niris_test &lt;- rbind(iris3[26:50, , 1], iris3[26:50, , 2], iris3[26:50, , 3])\niris_species &lt;- factor(rep(c(\"setosa\", \"versicolor\", \"virginica\"), each = 25))\n\n\nlibrary(class)\n# 分 3 类\niris_knn &lt;- knn(\n  train = iris_train, test = iris_test,\n  cl = iris_species, k = 3, prob = TRUE\n)\n# 分类结果汇总\ntable(iris_knn, iris_species) \n\n            iris_species\niris_knn     setosa versicolor virginica\n  setosa         25          0         0\n  versicolor      0         23         4\n  virginica       0          2        21",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-neural-networks",
    "href": "classification-problems.html#sec-neural-networks",
    "title": "40  分类问题",
    "section": "\n40.7 神经网络",
    "text": "40.7 神经网络\n\nlibrary(nnet)\niris_nnet &lt;- nnet(Species ~ ., data = iris, size = 4, trace = FALSE)\nsummary(iris_nnet)\n\na 4-4-3 network with 35 weights\noptions were - softmax modelling \n  b-&gt;h1  i1-&gt;h1  i2-&gt;h1  i3-&gt;h1  i4-&gt;h1 \n 222.66  -12.27  -10.10   -3.62  -54.87 \n  b-&gt;h2  i1-&gt;h2  i2-&gt;h2  i3-&gt;h2  i4-&gt;h2 \n-474.30 -186.70 -162.45  344.16  245.69 \n  b-&gt;h3  i1-&gt;h3  i2-&gt;h3  i3-&gt;h3  i4-&gt;h3 \n  -1.29   -6.37   -2.26   -6.43   -2.22 \n  b-&gt;h4  i1-&gt;h4  i2-&gt;h4  i3-&gt;h4  i4-&gt;h4 \n   1.30    1.86   10.97  -17.97   -6.88 \n  b-&gt;o1  h1-&gt;o1  h2-&gt;o1  h3-&gt;o1  h4-&gt;o1 \n -68.08    1.97   59.02    7.67  207.09 \n  b-&gt;o2  h1-&gt;o2  h2-&gt;o2  h3-&gt;o2  h4-&gt;o2 \n 105.47   67.36 -169.42   -2.30 -202.49 \n  b-&gt;o3  h1-&gt;o3  h2-&gt;o3  h3-&gt;o3  h4-&gt;o3 \n -38.30  -68.51  111.61   -5.05   -5.13 \n\n\nsize 隐藏层中的神经元数量\n\niris_pred_nnet &lt;- predict(iris_nnet, newdata = iris[,-5], type = \"class\")\ntable(iris_pred_nnet, iris[, 5])\n\n              \niris_pred_nnet setosa versicolor virginica\n    setosa         50          0         0\n    versicolor      0         49         0\n    virginica       0          1        50",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-recursive-partitioning",
    "href": "classification-problems.html#sec-recursive-partitioning",
    "title": "40  分类问题",
    "section": "\n40.8 决策树",
    "text": "40.8 决策树\n\nlibrary(rpart)\niris_rpart &lt;- rpart(Species ~ ., data = iris)\niris_rpart\n\nn= 150 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 150 100 setosa (0.33333333 0.33333333 0.33333333)  \n  2) Petal.Length&lt; 2.45 50   0 setosa (1.00000000 0.00000000 0.00000000) *\n  3) Petal.Length&gt;=2.45 100  50 versicolor (0.00000000 0.50000000 0.50000000)  \n    6) Petal.Width&lt; 1.75 54   5 versicolor (0.00000000 0.90740741 0.09259259) *\n    7) Petal.Width&gt;=1.75 46   1 virginica (0.00000000 0.02173913 0.97826087) *\n\n\n\nlibrary(rpart.plot)\nrpart.plot(iris_rpart)\n\n\n\n\n\n\n图 40.2: 分类回归树\n\n\n\n\n预测结果，训练误差\n\n# 预测\niris_pred_rpart &lt;- predict(iris_rpart, iris[, -5], type = \"class\")\n# 预测结果\ntable(iris_pred_rpart, iris[, 5])\n\n               \niris_pred_rpart setosa versicolor virginica\n     setosa         50          0         0\n     versicolor      0         49         5\n     virginica       0          1        45\n\n\nparty 包和 partykit 包也提供类似的功能，前者是基于 C 语言实现，后者基于 R 语言实现。\n\n代码# 与 rpart 包分类的结果一样\nlibrary(partykit)\niris_party &lt;- ctree(Species ~ ., data = iris)\nplot(iris_party)\niris_pred_party &lt;- predict(iris_party, iris[, -5], type = \"response\")\ntable(iris_pred_party, iris[, 5])\n\n# PART 算法\nlibrary(RWeka)\niris_weka &lt;- PART(Species ~ ., data = iris)\n# 输出拟合结果\nsummary(iris_weka)\n# 预测\niris_pred_weka &lt;- predict(iris_weka, newdata = iris[, -5], type = \"class\")\n# 预测结果\ntable(iris_pred_weka, iris[, 5])\n\n# Bagging CART\nlibrary(ipred)\niris_ipred &lt;- bagging(Species ~ ., data = iris)\n# 输出拟合结果\n# summary(iris_ipred)\n# 预测\niris_pred_ipred &lt;- predict(iris_ipred, newdata = iris[, -5], type = \"class\")\n# 预测结果\ntable(iris_pred_ipred, iris[, 5])\n\n# Boosted C5.0\nlibrary(C50)\niris_C50 &lt;- C5.0(Species ~ ., data = iris)\n# 预测\niris_pred_C50 &lt;- predict(iris_C50, newdata = iris[, -5])\n# 预测结果\ntable(iris_pred_C50, iris[, 5])\n\n# Gradient Boosted Machine\n# Warning message:\n# Setting `distribution = \"multinomial\"` is ill-advised \n# as it is currently broken. \n# It exists only for backwards compatibility. Use at your own risk. \nlibrary(gbm)\niris_gbm &lt;- gbm(Species ~ ., data = iris, distribution = \"multinomial\")\n# 预测\niris_pred_gbm &lt;- predict(iris_gbm, newdata = iris[, -5], n.trees = 1, type = \"response\")\n# 转化为与响应变量一样的取值\npred_gbm &lt;- colnames(iris_pred_gbm)[apply(iris_pred_gbm, 1, which.max)]\n# 预测结果\ntable(pred_gbm, iris[, 5])",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-random-forests",
    "href": "classification-problems.html#sec-random-forests",
    "title": "40  分类问题",
    "section": "\n40.9 随机森林",
    "text": "40.9 随机森林\n\nlibrary(randomForest) # 随机森林\niris_rf &lt;- randomForest(\n  Species ~ ., data = iris,\n  importance = TRUE, proximity = TRUE\n)\n# 分类结果\nprint(iris_rf)\n\n\nCall:\n randomForest(formula = Species ~ ., data = iris, importance = TRUE,      proximity = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 4%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa         50          0         0        0.00\nversicolor      0         47         3        0.06\nvirginica       0          3        47        0.06\n\n\n\n代码op &lt;- par(mar = c(4, 4, 1.5, 0.1))\nplot(iris_rf, main = \"\")\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 40.3: 随机森林\n\n\n\n\n\nvarImpPlot(iris_rf, main = \"变量重要性\")\n\n\n\n\n\n\n图 40.4: 变量重要性\n\n\n\n\n\niris_pred_rf &lt;- predict(iris_rf, iris[, -5], type = \"response\")\ntable(iris_pred_rf, iris[, 5])\n\n            \niris_pred_rf setosa versicolor virginica\n  setosa         50          0         0\n  versicolor      0         50         0\n  virginica       0          0        50",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#集成学习",
    "href": "classification-problems.html#集成学习",
    "title": "40  分类问题",
    "section": "\n40.10 集成学习",
    "text": "40.10 集成学习\n在训练模型之前，需要先对数据集做预处理，包括分组采样、类别编码、数据拆分、类型转换等。\n制作一个函数对数据集添加新列 mark 作为训练集 train 和测试集 test 的采样标记，返回数据。\n\n# 输入数据 x 和采样比例 prop\nadd_mark &lt;- function(x = iris, prop = 0.7) {\n  idx &lt;- sample(x = nrow(x), size = floor(nrow(x) * prop))\n  rbind(\n    cbind(x[idx, ], mark = \"train\"),\n    cbind(x[-idx, ], mark = \"test\")\n  )\n}\n\n为了使采样结果可重复，设置随机数种子，然后对 iris 数据集按列 Species 分组添加采样标记，分组随机抽取 70% 的样本作为训练数据，余下的作为测试数据。就 iris 数据集来说，训练集有 35*3 = 105 条记录，测试集有 15*3 = 45 条记录。\n\nset.seed(20232023)\niris_df &lt;- do.call(rbind, lapply(split(iris, iris$Species), add_mark, prop = 0.7))\n\n为了使用函数 fcase() 对分类变量 Species 做重编码操作，加载 data.table 包，将数据集 iris_df 转为 data.table 类型。值得注意，xgboost 包要求分类变量的类别序号必须从 0 开始。\n\n# 数据准备\nlibrary(data.table)\niris_dt &lt;- as.data.table(iris_df)\niris_dt &lt;- iris_dt[, Species := fcase(\n  Species == \"setosa\", 0,\n  Species == \"versicolor\", 1,\n  Species == \"virginica\", 2\n)]\n\n将数据 iris_dt 拆分成训练集和测试集，并以列表结构存储数据，样本数据及标签以矩阵类型存储。\n\n# 训练数据\niris_train &lt;- list(\n  data = as.matrix(iris_dt[iris_dt$mark == \"train\", -c(\"mark\", \"Species\")]),\n  label = as.matrix(iris_dt[iris_dt$mark == \"train\", \"Species\"])\n)\n# 测试数据\niris_test &lt;- list(\n  data = as.matrix(iris_dt[iris_dt$mark == \"test\", -c(\"mark\", \"Species\")]),\n  label = as.matrix(iris_dt[iris_dt$mark == \"test\", \"Species\"])\n)\n\n数据准备好后，加载 xgboost 包，设置训练参数，开始训练分类模型。此分类任务中类别超过 2，是多分类任务，学习任务是分类，目标函数可以是 objective = \"multi:softprob\" 或者 objective = \"multi:softmax\"，相应的评估指标可以是 eval_metric = \"mlogloss\" 或者 eval_metric = \"merror\"。iris 数据集的分类变量 Species 共有 3 类，所以 num_class = 3 。\n\nlibrary(xgboost)\niris_xgb &lt;- xgboost(\n  data = iris_train$data, \n  label = iris_train$label,\n  objective = \"multi:softmax\",  # 学习任务\n  eval_metric = \"mlogloss\",     # 评估指标\n  nrounds = 2,   # 提升迭代的最大次数\n  num_class = 3  # 分类数\n)\n\n[1] train-mlogloss:0.747373 \n[2] train-mlogloss:0.540389 \n\n\n将训练好的模型放在测试集数据上进行预测。\n\n# ?predict.xgb.Booster\niris_pred &lt;- predict(object = iris_xgb, newdata = iris_test$data)\n\n将预测结果与测试集中的样本标签对比，检查分类效果。\n\ntable(iris_test$label, iris_pred)\n\n   iris_pred\n     0  1  2\n  0 15  0  0\n  1  0 14  1\n  2  0  2 13",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-classification-problems-summary",
    "href": "classification-problems.html#sec-classification-problems-summary",
    "title": "40  分类问题",
    "section": "\n40.11 总结",
    "text": "40.11 总结\n不同的分类算法分布在不同的 R 包中，在使用方式上既有相通之处，又有不同之处。下表对多个 R 包的使用做了归纳。R 包之间的不一致性，计算预测分类的概率的语法。\n\n\n\n\n\n\n\n函数\nR 包\n代码\n\n\n\nlda()\nMASS\npredict(obj)\n\n\nglm()\nstats\npredict(obj, type = \"response\")\n\n\ngbm()\ngbm\npredict(obj, type = \"response\", n.trees)\n\n\nnaiveBayes()\ne1071\npredict(obj, type = \"class\")\n\n\nsvm()\ne1071\npredict(obj, probability = FALSE)\n\n\nksvm()\nkernlab\npredict(obj, type = \"response\")\n\n\nmda()\nmda\npredict(obj, type = \"posterior\")\n\n\nrpart()\nrpart\npredict(obj, type = \"prob\")\n\n\nWeka()\nRWeka\npredict(obj, type = \"probability\")\n\n\nctree()\npartykit\npredict(obj, type = \"response\")\n\n\nbagging()\nipred\npredict(obj, type = \"class\")",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "classification-problems.html#sec-exercise-classification",
    "href": "classification-problems.html#sec-exercise-classification",
    "title": "40  分类问题",
    "section": "\n40.12 习题",
    "text": "40.12 习题\n\n\ntitanic 包整理了来自 kaggle 的 Titanic 数据集，详细记录了 891 位乘客的信息，它比 Base R 内置的 Titanic 数据集更加原始，细节更多，信息更加丰富。原数据集拆分为训练集 titanic_train 和测试集 titanic_test。因为有每个乘客的原始信息，我们可以在个体水平上建模，采用更加复杂的模型分析泰坦尼克号乘客存活率及其影响因素。\n\n\n\n\n\nFisher, R. A. 1936. 《The Use Of Multiple Measurements In Taxonomic Problems》. Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\nKaratzoglou, Alexandros, Alex Smola, Kurt Hornik, 和 Achim Zeileis. 2004. 《kernlab: An S4 Package for Kernel Methods in R》. Journal of Statistical Software 11 (9): 1–20. https://doi.org/10.18637/jss.v011.i09.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An introduction. Cambridge, Massachusetts: MIT Press. https://probml.github.io/pml-book/book1.html.",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>分类问题</span>"
    ]
  },
  {
    "objectID": "clustering-problems.html",
    "href": "clustering-problems.html",
    "title": "41  聚类问题",
    "section": "",
    "text": "41.1 层次聚类\n来自 stats 包的函数 hclust() 和来自 cluster 包的函数 agnes() 和函数 diana() (Kaufman 和 Rousseeuw 1990)",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>聚类问题</span>"
    ]
  },
  {
    "objectID": "clustering-problems.html#sec-partitioning-clustering",
    "href": "clustering-problems.html#sec-partitioning-clustering",
    "title": "41  聚类问题",
    "section": "41.2 快速聚类",
    "text": "41.2 快速聚类\n来自 stats 包的函数 kmeans() 和来自 cluster 包的函数 pam() ，kernlab 包 (Karatzoglou 等 2004) 的 K-means 聚类函数 kkmeans() 和谱聚类函数 specc() 。",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>聚类问题</span>"
    ]
  },
  {
    "objectID": "clustering-problems.html#sec-fuzzy-clustering",
    "href": "clustering-problems.html#sec-fuzzy-clustering",
    "title": "41  聚类问题",
    "section": "41.3 模糊聚类",
    "text": "41.3 模糊聚类\n来自 e1071 包 (Meyer 等 2023) 的 fuzzy clustering 模糊聚类 和 bagged clustering 装袋聚类两种聚类方法",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>聚类问题</span>"
    ]
  },
  {
    "objectID": "clustering-problems.html#sec-model-based-clustering",
    "href": "clustering-problems.html#sec-model-based-clustering",
    "title": "41  聚类问题",
    "section": "41.4 基于模型的聚类",
    "text": "41.4 基于模型的聚类\n来自 mclust 包 (Scrucca 等 2016) 有限混合模型",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>聚类问题</span>"
    ]
  },
  {
    "objectID": "clustering-problems.html#sec-density-based-clusting",
    "href": "clustering-problems.html#sec-density-based-clusting",
    "title": "41  聚类问题",
    "section": "41.5 基于密度的聚类",
    "text": "41.5 基于密度的聚类\n来自 dbscan 包 (Hahsler, Piekenbrock, 和 Doran 2019)\n\n\n\n\nHahsler, Michael, Matthew Piekenbrock, 和 Derek Doran. 2019. 《dbscan: Fast Density-Based Clustering with R》. Journal of Statistical Software 91 (1): 1–30. https://doi.org/10.18637/jss.v091.i01.\n\n\nKaratzoglou, Alexandros, Alex Smola, Kurt Hornik, 和 Achim Zeileis. 2004. 《kernlab: An S4 Package for Kernel Methods in R》. Journal of Statistical Software 11 (9): 1–20. https://doi.org/10.18637/jss.v011.i09.\n\n\nKaufman, Leonard, 和 Peter J. Rousseeuw. 1990. Finding Groups in Data: An Introduction to Cluster Analysis. 1 本. Wiley Series in Probability and Statistics. Wiley. https://doi.org/10.1002/9780470316801.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, 和 Friedrich Leisch. 2023. e1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, 和 Adrian E. Raftery. 2016. 《mclust 5: clustering, classification and density estimation using Gaussian finite mixture models》. The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>聚类问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html",
    "href": "regression-problems.html",
    "title": "42  回归问题",
    "section": "",
    "text": "42.1 线性回归\n对于线性回归问题，为了处理变量之间的相关关系，衍生出许多处理办法。有的办法是线性的，有的办法是非线性的。",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html#sec-linear-regressions",
    "href": "regression-problems.html#sec-linear-regressions",
    "title": "42  回归问题",
    "section": "",
    "text": "42.1.1 最小二乘回归\n\\[\n\\mathcal{L}(\\bm{\\beta}) = \\sum_{i=1}^{n}(y_i - \\bm{x}_i^{\\top}\\bm{\\beta})^2\n\\]\n\nfit_lm &lt;- lm(medv ~ ., data = Boston)\nsummary(fit_lm)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = medv ~ ., data = Boston)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -15.595  -2.730  -0.518   1.777  26.199 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\n#&gt; crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \n#&gt; zn           4.642e-02  1.373e-02   3.382 0.000778 ***\n#&gt; indus        2.056e-02  6.150e-02   0.334 0.738288    \n#&gt; chas         2.687e+00  8.616e-01   3.118 0.001925 ** \n#&gt; nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\n#&gt; rm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\n#&gt; age          6.922e-04  1.321e-02   0.052 0.958229    \n#&gt; dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\n#&gt; rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\n#&gt; tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \n#&gt; ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\n#&gt; black        9.312e-03  2.686e-03   3.467 0.000573 ***\n#&gt; lstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.745 on 492 degrees of freedom\n#&gt; Multiple R-squared:  0.7406, Adjusted R-squared:  0.7338 \n#&gt; F-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\n\n\n42.1.2 逐步回归\n逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。\n\n\ndirection = \"both\" 双向\n\ndirection = \"backward\" 向后\n\ndirection = \"forward\" 向前\n\n\nfit_step &lt;- step(fit_lm, direction = \"both\", trace = 0)\nsummary(fit_step)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n#&gt;     tax + ptratio + black + lstat, data = Boston)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -15.5984  -2.7386  -0.5046   1.7273  26.2373 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  36.341145   5.067492   7.171 2.73e-12 ***\n#&gt; crim         -0.108413   0.032779  -3.307 0.001010 ** \n#&gt; zn            0.045845   0.013523   3.390 0.000754 ***\n#&gt; chas          2.718716   0.854240   3.183 0.001551 ** \n#&gt; nox         -17.376023   3.535243  -4.915 1.21e-06 ***\n#&gt; rm            3.801579   0.406316   9.356  &lt; 2e-16 ***\n#&gt; dis          -1.492711   0.185731  -8.037 6.84e-15 ***\n#&gt; rad           0.299608   0.063402   4.726 3.00e-06 ***\n#&gt; tax          -0.011778   0.003372  -3.493 0.000521 ***\n#&gt; ptratio      -0.946525   0.129066  -7.334 9.24e-13 ***\n#&gt; black         0.009291   0.002674   3.475 0.000557 ***\n#&gt; lstat        -0.522553   0.047424 -11.019  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.736 on 494 degrees of freedom\n#&gt; Multiple R-squared:  0.7406, Adjusted R-squared:  0.7348 \n#&gt; F-statistic: 128.2 on 11 and 494 DF,  p-value: &lt; 2.2e-16\n\n\n\n42.1.3 偏最小二乘回归\n偏最小二乘回归适用于存在多重共线性问题或变量个数远大于样本量的情况。\n10 折交叉验证，ncomp = 6 表示 6 个主成分，拟合方法 kernelpls 表示核算法，validation = \"CV\" 表示采用交叉验证的方式调整参数。\n\nfit_pls &lt;- pls::plsr(medv ~ ., ncomp = 6, data = Boston, validation = \"CV\")\nsummary(fit_pls)\n\n#&gt; Data:    X dimension: 506 13 \n#&gt;  Y dimension: 506 1\n#&gt; Fit method: kernelpls\n#&gt; Number of components considered: 6\n#&gt; \n#&gt; VALIDATION: RMSEP\n#&gt; Cross-validated using 10 random segments.\n#&gt;        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n#&gt; CV           9.206    8.022    7.884    7.624    6.513    5.887    5.727\n#&gt; adjCV        9.206    8.020    7.884    7.622    6.507    5.882    5.725\n#&gt; \n#&gt; TRAINING: % variance explained\n#&gt;       1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n#&gt; X       80.51    94.45    98.97    99.34    99.80    99.91\n#&gt; medv    24.23    26.94    32.05    51.05    60.08    62.49\n\n\n交叉验证的方法还可选留一交叉验证 validation = \"LOO\" 。预测的均方根误差 RMSEP 来评估交叉验证的结果。\n\npls::validationplot(fit_pls, val.type = \"RMSEP\")\n\n\n\n\n\n\n图 42.1: RMSE 随成分数量的变化\n\n\n\n\n\n42.1.4 主成分回归\n主成分回归采用降维的方法处理高维和多重共线性问题。\n10 折交叉验证，6 个主成分，拟合方法 svdpc 表示奇异值分解算法。\n\nfit_pcr &lt;- pls::pcr(medv ~ ., ncomp = 6, data = Boston, validation = \"CV\")\nsummary(fit_pcr)\n\n#&gt; Data:    X dimension: 506 13 \n#&gt;  Y dimension: 506 1\n#&gt; Fit method: svdpc\n#&gt; Number of components considered: 6\n#&gt; \n#&gt; VALIDATION: RMSEP\n#&gt; Cross-validated using 10 random segments.\n#&gt;        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n#&gt; CV           9.206    8.045    8.024    7.811    7.793    7.675    6.068\n#&gt; adjCV        9.206    8.044    8.023    7.808    7.789    7.686    6.059\n#&gt; \n#&gt; TRAINING: % variance explained\n#&gt;       1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n#&gt; X       80.58    96.89    99.02    99.72    99.85    99.92\n#&gt; medv    23.71    24.28    28.77    29.33    32.71    57.77",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html#sec-penalty-regression",
    "href": "regression-problems.html#sec-penalty-regression",
    "title": "42  回归问题",
    "section": "\n42.2 惩罚回归",
    "text": "42.2 惩罚回归\n本节主要介绍 4 个 R 包的使用，分别是 glmnet 包 (Friedman, Tibshirani, 和 Hastie 2010)、 ncvreg 包 (Breheny 和 Huang 2011) 、 lars 包 (Bradley Efron 和 Tibshirani 2004) 和 abess 包 (Zhu 等 2022)。\n\n\n表格 42.1: 惩罚回归的 R 包实现\n\n\n\nR 包\n惩罚方法\n函数实现\n\n\n\nglmnet\n岭回归\nglmnet(...,alpha = 0)\n\n\nglmnet\nLasso 回归\nglmnet(...,alpha = 1)\n\n\nglmnet\n弹性网络回归\nglmnet(...,alpha)\n\n\nglmnet\n自适应 Lasso 回归\nglmnet(...,penalty.factor)\n\n\nglmnet\n松驰 Lasso 回归\nglmnet(...,relax = TRUE)\n\n\nncvreg\nMCP\nncvreg(...,penalty = \"MCP\")\n\n\nncvreg\nSCAD\nncvreg(...,penalty = \"SCAD\")\n\n\nlars\n最小角回归\nlars(...,type = \"lar\")\n\n\nabess\n最优子集回归\nabess()\n\n\n\n\n\n\n函数 glmnet() 的参数 penalty.factor 表示惩罚因子，默认值为全 1 向量，自适应 Lasso 回归中需要指定。弹性网络回归要求参数 alpha 介于 0-1 之间。\n\n42.2.1 岭回归\n岭回归\n\\[\n\\mathcal{L}(\\bm{\\beta}) = \\sum_{i=1}^{n}(y_i - \\bm{x}_i^{\\top}\\bm{\\beta})^2 + \\lambda\\|\\bm{\\beta}\\|_2^2\n\\]\n\nlibrary(glmnet)\nfit_ridge &lt;- glmnet(x = Boston[, -14], y = Boston[, \"medv\"], family = \"gaussian\", alpha = 0)\n\nplot(fit_ridge)\nplot(fit_ridge$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\n\n\n\n(a) 回归系数的迭代路径\n\n\n\n\n\n\n\n\n\n(b) 惩罚系数的迭代路径\n\n\n\n\n\n\n图 42.2: 岭回归\n\n\n\nfit_ridge$lambda[60]\n\n#&gt; [1] 28.00535\n\ncoef(fit_ridge, s = 28.00535)\n\n#&gt; 14 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       s1\n#&gt; (Intercept) 23.047750109\n#&gt; crim        -0.045815821\n#&gt; zn           0.014330186\n#&gt; indus       -0.063634086\n#&gt; chas         1.358311700\n#&gt; nox         -3.075514644\n#&gt; rm           1.653490217\n#&gt; age         -0.009926222\n#&gt; dis         -0.025465898\n#&gt; rad         -0.026390778\n#&gt; tax         -0.002435665\n#&gt; ptratio     -0.331740062\n#&gt; black        0.004145613\n#&gt; lstat       -0.151396406\n\n\n\n42.2.2 Lasso 回归\nLasso 回归\n\\[\n\\mathcal{L}(\\bm{\\beta}) = \\sum_{i=1}^{n}(y_i - \\bm{x}_i^{\\top}\\bm{\\beta})^2 + \\lambda\\|\\bm{\\beta}\\|_1\n\\]\n\nfit_lasso &lt;- glmnet(x = Boston[, -14], y = Boston[, \"medv\"], family = \"gaussian\", alpha = 1)\n\nplot(fit_lasso)\nplot(fit_lasso$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\",\n  main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\n\n\n\n(a) 回归系数的迭代路径\n\n\n\n\n\n\n\n\n\n(b) 惩罚系数的迭代路径\n\n\n\n\n\n\n图 42.3: Lasso 回归\n\n\n\nfit_lasso$lambda[60]\n\n#&gt; [1] 0.02800535\n\ncoef(fit_lasso, s = 0.02800535)\n\n#&gt; 14 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                        s1\n#&gt; (Intercept)  34.426424733\n#&gt; crim         -0.098346337\n#&gt; zn            0.041441612\n#&gt; indus         .          \n#&gt; chas          2.685187735\n#&gt; nox         -16.306645191\n#&gt; rm            3.866938879\n#&gt; age           .          \n#&gt; dis          -1.396021610\n#&gt; rad           0.252686499\n#&gt; tax          -0.009826799\n#&gt; ptratio      -0.929988657\n#&gt; black         0.009025875\n#&gt; lstat        -0.522499839\n\n\n\n42.2.3 弹性网络\n弹性网络 (Zou 和 Hastie 2005)\n\\[\n\\mathcal{L}(\\bm{\\beta}) = \\sum_{i=1}^{n}(y_i - \\bm{x}_i^{\\top}\\bm{\\beta})^2 + \\lambda(\\frac{1-\\alpha}{2}\\|\\bm{\\beta}\\|_2^2 + \\alpha \\|\\bm{\\beta}\\|_1)\n\\]\n\nfit_elasticnet &lt;- glmnet(x = Boston[, -14], y = Boston[, \"medv\"], family = \"gaussian\")\n\nplot(fit_elasticnet)\nplot(fit_elasticnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\",\n  main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\n\n\n\n(a) 回归系数的迭代路径\n\n\n\n\n\n\n\n\n\n(b) 惩罚系数的迭代路径\n\n\n\n\n\n\n图 42.4: 弹性网络\n\n\n\nfit_elasticnet$lambda[60]\n\n#&gt; [1] 0.02800535\n\ncoef(fit_elasticnet, s = 0.02800535)\n\n#&gt; 14 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                        s1\n#&gt; (Intercept)  34.426424733\n#&gt; crim         -0.098346337\n#&gt; zn            0.041441612\n#&gt; indus         .          \n#&gt; chas          2.685187735\n#&gt; nox         -16.306645191\n#&gt; rm            3.866938879\n#&gt; age           .          \n#&gt; dis          -1.396021610\n#&gt; rad           0.252686499\n#&gt; tax          -0.009826799\n#&gt; ptratio      -0.929988657\n#&gt; black         0.009025875\n#&gt; lstat        -0.522499839\n\n\n\n42.2.4 自适应 Lasso\n自适应 Lasso (Zou 2006)\n\\[\n\\mathcal{L}(\\bm{\\beta}) = \\sum_{i=1}^{n}(y_i - \\bm{x}_i^{\\top}\\bm{\\beta})^2 + \\lambda_n\\sum_{j=1}^{p}\\frac{1}{w_j}|\\beta_j|\n\\]\n普通最小二乘估计或岭回归估计的结果作为适应性 Lasso 回归的权重。其中 \\(w_j = (|\\hat{\\beta}_{ols_j}|)^{\\gamma}\\) 或 \\(w_j = (|\\hat{\\beta}_{ridge_j}|)^{\\gamma}\\) ， \\(\\gamma\\) 是一个用于调整自适应权重向量的正常数，一般建议的正常数是 0.5，1 或 2。\n\n# 岭权重 gamma = 1\ng &lt;- 1\nset.seed(20232023)\n## 岭回归\nridge_model &lt;- cv.glmnet(\n  x = as.matrix(Boston[, -14]),\n  y = Boston[, 14], alpha = 0\n)\nridge_coef &lt;- as.matrix(coef(ridge_model, s = ridge_model$lambda.min))\nridge_weight &lt;- 1 / (abs(ridge_coef[-1, ]))^g\n\n## Adaptive Lasso\nset.seed(20232023)\nfit_adaptive_lasso &lt;- cv.glmnet(\n  x = as.matrix(Boston[, -14]),\n  y = Boston[, 14], alpha = 1,\n  penalty.factor = ridge_weight # 惩罚权重\n)\n\n岭回归和自适应 Lasso 回归模型的超参数\nplot(ridge_model)\nplot(fit_adaptive_lasso)\n\n\n\n\n\n\n\n\n\n(a) 岭回归\n\n\n\n\n\n\n\n\n\n(b) 自适应 Lasso 回归\n\n\n\n\n\n\n图 42.5: 自适应 Lasso 回归模型的超参数选择\n\n\n\\(\\lambda\\) 超参数\n\nfit_adaptive_lasso$lambda.min\n\n#&gt; [1] 0.2273152\n\n\n自适应 Lasso 回归参数\n\ncoef(fit_adaptive_lasso, s = fit_adaptive_lasso$lambda.min)\n\n#&gt; 14 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                        s1\n#&gt; (Intercept)  38.291419779\n#&gt; crim         -0.098901950\n#&gt; zn            0.023328430\n#&gt; indus        -0.016769750\n#&gt; chas          3.119585761\n#&gt; nox         -20.461629406\n#&gt; rm            3.946726706\n#&gt; age           .          \n#&gt; dis          -1.354180874\n#&gt; rad           0.100046239\n#&gt; tax           .          \n#&gt; ptratio      -1.019940695\n#&gt; black         0.002119703\n#&gt; lstat        -0.545149921\n\n\n预测\n\npred_medv_adaptive_lasso &lt;- predict(\n  fit_adaptive_lasso, newx = as.matrix(Boston[, -14]),\n  s = fit_adaptive_lasso$lambda.min, type = \"response\"\n)\n\n预测的均方根误差\n\nrmse(Boston[, 14], pred_medv_adaptive_lasso)\n\n#&gt; [1] 4.77706\n\n\n\n42.2.5 松弛 Lasso\nLasso 回归倾向于将回归系数压缩到 0，松弛 Lasso\n\\[\n\\hat{\\beta}_{relax}(\\lambda,\\gamma) = \\gamma \\hat{\\beta}_{lasso}(\\lambda) + (1 - \\gamma)\\hat{\\beta}_{ols}(\\lambda)\n\\]\n其中，\\(\\gamma \\in[0,1]\\) 是一个超参数。\n\nfit_relax_lasso &lt;- cv.glmnet(\n  x = as.matrix(Boston[, -14]), \n  y = Boston[, \"medv\"], relax = TRUE\n)\n\n\nplot(fit_relax_lasso)\n\n\n\n\n\n\n图 42.6: 回归系数的迭代路径\n\n\n\n\nCV 交叉验证筛选出来的超参数 \\(\\lambda\\) 和 \\(\\gamma\\) ，\\(\\gamma = 0\\) 意味着松弛 Lasso 退化为 OLS 估计\n\nfit_relax_lasso$relaxed$lambda.min\n\n#&gt; [1] 0.1240811\n\nfit_relax_lasso$relaxed$gamma.min\n\n#&gt; [1] 0\n\n\n松弛 Lasso 回归系数与 OLS 估计的结果一样\n\ncoef(fit_relax_lasso, s = \"lambda.min\", gamma = \"gamma.min\")\n\n#&gt; 14 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                        s1\n#&gt; (Intercept)  36.386415340\n#&gt; crim         -0.107642467\n#&gt; zn            0.046225884\n#&gt; indus         0.019914638\n#&gt; chas          2.692467531\n#&gt; nox         -17.703655696\n#&gt; rm            3.817657573\n#&gt; age           .          \n#&gt; dis          -1.478133649\n#&gt; rad           0.303685310\n#&gt; tax          -0.012233266\n#&gt; ptratio      -0.951640287\n#&gt; black         0.009315797\n#&gt; lstat        -0.523702685\n\n\n松弛 Lasso 预测\n\npred_medv_relax_lasso &lt;- predict(\n  fit_relax_lasso,\n  newx = as.matrix(Boston[, -14]),\n  s = \"lambda.min\", gamma = \"gamma.min\"\n)\n\n\nrmse(Boston[, 14], pred_medv_relax_lasso)\n\n#&gt; [1] 4.679209\n\n\n\n42.2.6 MCP\nncvreg 包 (Breheny 和 Huang 2011) 提供额外的两种非凸/凹惩罚类型，分别是 MCP （minimax concave penalty）和 SCAD（smoothly clipped absolute deviation）。\n\nlibrary(ncvreg)\nfit_mcp &lt;- ncvreg(X = Boston[, -14], y = Boston[, \"medv\"], penalty = \"MCP\")\n\n\nplot(fit_mcp)\n\n\n\n\n\n\n图 42.7: 回归系数的迭代路径\n\n\n\n\n回归系数\n\ncoef(fit_mcp, lambda = 0.85)\n\n#&gt; (Intercept)        crim          zn       indus        chas         nox \n#&gt;  14.9613035   0.0000000   0.0000000   0.0000000   0.2355167   0.0000000 \n#&gt;          rm         age         dis         rad         tax     ptratio \n#&gt;   4.6134961   0.0000000   0.0000000   0.0000000   0.0000000  -0.7607830 \n#&gt;       black       lstat \n#&gt;   0.0000000  -0.5847017\n\nsummary(fit_mcp, lambda = 0.85)\n\n#&gt; Using a basic kernel estimate for local fdr; consider installing the ashr package for more accurate estimation.  See ?local_mfdr\n\n\n#&gt; MCP-penalized linear regression with n=506, p=13\n#&gt; At lambda=0.8500:\n#&gt; -------------------------------------------------\n#&gt;   Nonzero coefficients         :   4\n#&gt;   Expected nonzero coefficients:   0.01\n#&gt;   Average mfdr (4 features)    :   0.001\n#&gt; \n#&gt;         Estimate       z      mfdr Selected\n#&gt; lstat    -0.5847 -17.956   &lt; 1e-04        *\n#&gt; rm        4.6135  13.940   &lt; 1e-04        *\n#&gt; ptratio  -0.7608  -8.381   &lt; 1e-04        *\n#&gt; chas      0.2355   3.831 0.0051025        *\n\n\n10 折交叉验证，选择超参数 \\(\\lambda\\)\n\nfit_mcp_cv &lt;- cv.ncvreg(\n  X = Boston[, -14], y = Boston[, \"medv\"], \n  penalty = \"MCP\", seed = 20232023\n)\nsummary(fit_mcp_cv)\n\n#&gt; MCP-penalized linear regression with n=506, p=13\n#&gt; At minimum cross-validation error (lambda=0.1800):\n#&gt; -------------------------------------------------\n#&gt;   Nonzero coefficients: 11\n#&gt;   Cross-validation error (deviance): 23.45\n#&gt;   R-squared: 0.72\n#&gt;   Signal-to-noise ratio: 2.60\n#&gt;   Scale estimate (sigma): 4.843\n#&gt; MCP-penalized linear regression with n=506, p=13\n#&gt; At lambda=0.1800:\n#&gt; -------------------------------------------------\n#&gt;   Nonzero coefficients         :  11\n#&gt;   Expected nonzero coefficients:   0.08\n#&gt;   Average mfdr (11 features)   :   0.007\n#&gt; \n#&gt;          Estimate       z      mfdr Selected\n#&gt; lstat    -0.52253 -17.314   &lt; 1e-04        *\n#&gt; dis      -1.49319 -14.590   &lt; 1e-04        *\n#&gt; rm        3.80092  12.392   &lt; 1e-04        *\n#&gt; rad       0.29997  12.118   &lt; 1e-04        *\n#&gt; ptratio  -0.94664  -9.510   &lt; 1e-04        *\n#&gt; nox     -17.38650  -9.347   &lt; 1e-04        *\n#&gt; tax      -0.01179  -9.220   &lt; 1e-04        *\n#&gt; zn        0.04587   4.963   &lt; 1e-04        *\n#&gt; crim     -0.10852  -4.330 0.0010795        *\n#&gt; black     0.00929   3.936 0.0053435        *\n#&gt; chas      2.71850   3.204 0.0713275        *\n\n\n在 \\(\\lambda = 0.1362\\) 时，交叉验证的误差最小，非 0 回归系数 11 个。\n\nplot(fit_mcp_cv)\n\n\n\n\n\n\n图 42.8: 惩罚系数的迭代路径\n\n\n\n\n\n42.2.7 SCAD\n\nfit_scad &lt;- ncvreg(X = Boston[, -14], y = Boston[, \"medv\"], penalty = \"SCAD\")\n\n\nplot(fit_scad)\n\n\n\n\n\n\n图 42.9: 回归系数的迭代路径\n\n\n\n\n\ncoef(fit_scad, lambda = 0.85)\n\n#&gt;   (Intercept)          crim            zn         indus          chas \n#&gt;  9.3713059437  0.0000000000  0.0000000000  0.0000000000  0.3518918853 \n#&gt;           nox            rm           age           dis           rad \n#&gt;  0.0000000000  4.7729149463  0.0000000000  0.0000000000  0.0000000000 \n#&gt;           tax       ptratio         black         lstat \n#&gt;  0.0000000000 -0.5040003090  0.0002038813 -0.6030152355\n\nsummary(fit_scad, lambda = 0.85)\n\n#&gt; SCAD-penalized linear regression with n=506, p=13\n#&gt; At lambda=0.8500:\n#&gt; -------------------------------------------------\n#&gt;   Nonzero coefficients         :   5\n#&gt;   Expected nonzero coefficients:   0.01\n#&gt;   Average mfdr (5 features)    :   0.002\n#&gt; \n#&gt;           Estimate       z      mfdr Selected\n#&gt; lstat   -0.6030152 -18.329   &lt; 1e-04        *\n#&gt; rm       4.7729149  14.274   &lt; 1e-04        *\n#&gt; ptratio -0.5040003  -7.888   &lt; 1e-04        *\n#&gt; chas     0.3518919   4.002 0.0027534        *\n#&gt; black    0.0002039   3.673 0.0093789        *\n\n\n10 折交叉验证，选择超参数 \\(\\lambda\\)\n\nfit_scad_cv &lt;- cv.ncvreg(\n  X = Boston[, -14], y = Boston[, \"medv\"], \n  penalty = \"SCAD\", seed = 20232023\n)\nsummary(fit_scad_cv)\n\n#&gt; SCAD-penalized linear regression with n=506, p=13\n#&gt; At minimum cross-validation error (lambda=0.1362):\n#&gt; -------------------------------------------------\n#&gt;   Nonzero coefficients: 11\n#&gt;   Cross-validation error (deviance): 23.45\n#&gt;   R-squared: 0.72\n#&gt;   Signal-to-noise ratio: 2.60\n#&gt;   Scale estimate (sigma): 4.843\n#&gt; SCAD-penalized linear regression with n=506, p=13\n#&gt; At lambda=0.1362:\n#&gt; -------------------------------------------------\n#&gt;   Nonzero coefficients         :  11\n#&gt;   Expected nonzero coefficients:   0.08\n#&gt;   Average mfdr (11 features)   :   0.007\n#&gt; \n#&gt;           Estimate       z      mfdr Selected\n#&gt; lstat    -0.522521 -17.314   &lt; 1e-04        *\n#&gt; dis      -1.492829 -14.586   &lt; 1e-04        *\n#&gt; rm        3.801459  12.393   &lt; 1e-04        *\n#&gt; rad       0.299790  12.111   &lt; 1e-04        *\n#&gt; ptratio  -0.946635  -9.509   &lt; 1e-04        *\n#&gt; nox     -17.381556  -9.345   &lt; 1e-04        *\n#&gt; tax      -0.011784  -9.215   &lt; 1e-04        *\n#&gt; zn        0.045846   4.961   &lt; 1e-04        *\n#&gt; crim     -0.108459  -4.328 0.0010887        *\n#&gt; black     0.009291   3.936 0.0053408        *\n#&gt; chas      2.718640   3.204 0.0712933        *\n\n\n在 \\(\\lambda = 0.1362\\) 时，交叉验证的误差最小，非 0 回归系数 11 个。\n\nplot(fit_scad_cv)\n\n\n\n\n\n\n图 42.10: 惩罚系数的迭代路径\n\n\n\n\n\n42.2.8 最小角回归\nlars 包提供 Lasso 回归和最小角（Least Angle）回归(Bradley Efron 和 Tibshirani 2004)。\n\nlibrary(lars)\n# Lasso 回归\nfit_lars_lasso &lt;- lars(\n  x = as.matrix(Boston[, -14]), y = as.matrix(Boston[, \"medv\"]),\n  type = \"lasso\", trace = FALSE, normalize = TRUE, intercept = TRUE\n)\n# LAR 回归\nfit_lars_lar &lt;- lars(\n  x = as.matrix(Boston[, -14]), y = as.matrix(Boston[, \"medv\"]),\n  type = \"lar\", trace = FALSE, normalize = TRUE, intercept = TRUE\n)\n\n参数 type = \"lasso\" 表示采用 Lasso 回归，参数 trace = FALSE 表示不显示迭代过程，参数 normalize = TRUE 表示每个变量都标准化，使得它们的 L2 范数为 1，参数 intercept = TRUE 表示模型中包含截距项，且不参与惩罚。\nLasso 和最小角回归系数的迭代路径见下图。\nplot(fit_lars_lasso)\nplot(fit_lars_lar)\n\n\n\n\n\n\n\n\n\n(a) Lasso 回归\n\n\n\n\n\n\n\n\n\n(b) 最小角回归\n\n\n\n\n\n\n图 42.11: Lasso 和最小角回归系数的迭代路径\n\n\n采用 10 折交叉验证筛选变量\nset.seed(20232023)\ncv.lars(\n  x = as.matrix(Boston[, -14]), y = as.matrix(Boston[, \"medv\"]),\n  type = \"lasso\", trace = FALSE, plot.it = TRUE, K = 10\n)\nset.seed(20232023)\ncv.lars(\n  x = as.matrix(Boston[, -14]), y = as.matrix(Boston[, \"medv\"]),\n  type = \"lar\", trace = FALSE, plot.it = TRUE, K = 10\n)\n\n\n\n\n\n\n\n\n\n(a) Lasso 回归\n\n\n\n\n\n\n\n\n\n(b) 最小角回归\n\n\n\n\n\n\n图 42.12: 交叉验证均方误差的变化\n\n\n\n42.2.9 最优子集回归\n\\[\n\\mathcal{L}(\\bm{\\beta}) = \\sum_{i=1}^{n}(y_i - \\bm{x}_i^{\\top}\\bm{\\beta})^2 + \\lambda\\|\\bm{\\beta}\\|_0\n\\]\n最优子集回归，添加 L0 惩罚，abess 包 (Zhu 等 2022) 支持线性回归、泊松回归、逻辑回归、多项回归等模型，可以非常高效地做最优子集筛选变量。\n\nlibrary(abess)\nfit_abess &lt;- abess(medv ~ ., data = Boston, family = \"gaussian\", \n                   tune.type = \"cv\", nfolds = 10, seed = 20232023)\n\n参数 tune.type = \"cv\" 表示交叉验证的方式确定超参数来筛选变量，参数 nfolds = 10 表示将数据划分为 10 份，采用 10 折交叉验证，参数 seed 用来设置随机数，以便可重复交叉验证 CV 的结果。惩罚系数的迭代路径见下左图。使用交叉验证筛选变量个数，不同的 support size 表示进入模型中的变量数目。\nplot(fit_abess, label = TRUE, main = \"惩罚系数的迭代路径\")\nplot(fit_abess, type = \"tune\", main = \"交叉验证筛选变量个数\")\n\n\n\n\n\n\n\n\n\n(a) 惩罚系数的迭代路径\n\n\n\n\n\n\n\n\n\n(b) 交叉验证筛选变量个数\n\n\n\n\n\n\n图 42.13: 最优子集回归\n\n\n从上右图可以看出，选择 6 个变量是比较合适的，作为最终的模型。\n\nbest_model &lt;- extract(fit_abess, support.size = 6)\n# 模型的结果，惩罚参数值、各个变量的系数\nstr(best_model)\n\n#&gt; List of 7\n#&gt;  $ beta        :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n#&gt;   .. ..@ i       : int [1:6] 3 4 5 7 10 12\n#&gt;   .. ..@ p       : int [1:2] 0 6\n#&gt;   .. ..@ Dim     : int [1:2] 13 1\n#&gt;   .. ..@ Dimnames:List of 2\n#&gt;   .. .. ..$ : chr [1:13] \"crim\" \"zn\" \"indus\" \"chas\" ...\n#&gt;   .. .. ..$ : chr \"6\"\n#&gt;   .. ..@ x       : num [1:6] 3.24 -18.74 4.11 -1.14 -1 ...\n#&gt;   .. ..@ factors : list()\n#&gt;  $ intercept   : num 36.9\n#&gt;  $ support.size: num 6\n#&gt;  $ support.vars: chr [1:6] \"chas\" \"nox\" \"rm\" \"dis\" ...\n#&gt;  $ support.beta: num [1:6] 3.24 -18.74 4.11 -1.14 -1 ...\n#&gt;  $ dev         : num 12\n#&gt;  $ tune.value  : num 12.9",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html#sec-svm-regression",
    "href": "regression-problems.html#sec-svm-regression",
    "title": "42  回归问题",
    "section": "\n42.3 支持向量机",
    "text": "42.3 支持向量机\n\nlibrary(kernlab)\nfit_ksvm &lt;- ksvm(medv ~ ., data = Boston)\nfit_ksvm\n\n#&gt; Support Vector Machine object of class \"ksvm\" \n#&gt; \n#&gt; SV type: eps-svr  (regression) \n#&gt;  parameter : epsilon = 0.1  cost C = 1 \n#&gt; \n#&gt; Gaussian Radial Basis kernel function. \n#&gt;  Hyperparameter : sigma =  0.106705860301404 \n#&gt; \n#&gt; Number of Support Vectors : 339 \n#&gt; \n#&gt; Objective Function Value : -79.4329 \n#&gt; Training error : 0.095826\n\n\n\n# 预测\npred_medv_svm &lt;- predict(fit_ksvm, newdata = Boston)\n# RMSE\nrmse(Boston$medv, pred_medv_svm)\n\n#&gt; [1] 2.847038",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html#sec-nnet-regression",
    "href": "regression-problems.html#sec-nnet-regression",
    "title": "42  回归问题",
    "section": "\n42.4 神经网络",
    "text": "42.4 神经网络\n单隐藏层的神经网络\n\nlibrary(nnet)\nfit_nnet &lt;- nnet(medv ~ .,\n  data = Boston, trace = FALSE,\n  size = 12, # 隐藏层单元数量\n  maxit = 500, # 最大迭代次数\n  linout = TRUE, # 线性输出单元\n  decay = 0.01 # 权重下降的参数\n)\npred_medv_nnet &lt;- predict(fit_nnet, newdata = Boston[, -14], type = \"raw\")\nrmse(Boston$medv, pred_medv_nnet)\n\n#&gt; [1] 3.198783",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html#sec-rpart-regression",
    "href": "regression-problems.html#sec-rpart-regression",
    "title": "42  回归问题",
    "section": "\n42.5 决策树",
    "text": "42.5 决策树\n\nlibrary(rpart)\nfit_rpart &lt;- rpart(medv ~ .,\n  data = Boston, control = rpart.control(minsplit = 5)\n)\n\npred_medv_rpart &lt;- predict(fit_rpart, newdata = Boston[, -14])\n\nrmse(Boston$medv, pred_medv_rpart)\n\n#&gt; [1] 3.565888\n\n\n\nlibrary(rpart.plot)\nrpart.plot(fit_rpart)\n\n\n\n\n\n\n图 42.14: 分类回归树",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html#sec-rf-regression",
    "href": "regression-problems.html#sec-rf-regression",
    "title": "42  回归问题",
    "section": "\n42.6 随机森林",
    "text": "42.6 随机森林\n\nlibrary(randomForest)\nfit_rf &lt;- randomForest(medv ~ ., data = Boston)\nprint(fit_rf)\n\n#&gt; \n#&gt; Call:\n#&gt;  randomForest(formula = medv ~ ., data = Boston) \n#&gt;                Type of random forest: regression\n#&gt;                      Number of trees: 500\n#&gt; No. of variables tried at each split: 4\n#&gt; \n#&gt;           Mean of squared residuals: 10.06723\n#&gt;                     % Var explained: 88.07\n\npred_medv_rf &lt;- predict(fit_rf, newdata = Boston[, -14])\nrmse(Boston$medv, pred_medv_rf)\n\n#&gt; [1] 1.400047",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "regression-problems.html#sec-boosting-regression",
    "href": "regression-problems.html#sec-boosting-regression",
    "title": "42  回归问题",
    "section": "\n42.7 集成学习",
    "text": "42.7 集成学习\n\n# 输入数据 x 和采样比例 prop\nadd_mark &lt;- function(x = Boston, prop = 0.7) {\n  idx &lt;- sample(x = nrow(x), size = floor(nrow(x) * prop))\n  rbind(\n    cbind(x[idx, ], mark = \"train\"),\n    cbind(x[-idx, ], mark = \"test\")\n  )\n}\n\nset.seed(20232023)\nBoston_df &lt;- add_mark(Boston, prop = 0.7)\n\nlibrary(data.table)\nBoston_dt &lt;- as.data.table(Boston_df)\n\n# 训练数据\nBoston_train &lt;- list(\n  data = as.matrix(Boston_dt[Boston_dt$mark == \"train\", -c(\"mark\", \"medv\")]),\n  label = as.matrix(Boston_dt[Boston_dt$mark == \"train\", \"medv\"])\n)\n# 测试数据\nBoston_test &lt;- list(\n  data = as.matrix(Boston_dt[Boston_dt$mark == \"test\", -c(\"mark\", \"medv\")]),\n  label = as.matrix(Boston_dt[Boston_dt$mark == \"test\", \"medv\"])\n)\n\n\nlibrary(xgboost)\nBoston_xgb &lt;- xgboost(\n  data = Boston_train$data, \n  label = Boston_train$label,\n  objective = \"reg:squarederror\",  # 学习任务\n  eval_metric = \"rmse\",    # 评估指标\n  nrounds = 6\n)\n\n#&gt; [1]  train-rmse:17.424982 \n#&gt; [2]  train-rmse:12.641765 \n#&gt; [3]  train-rmse:9.241521 \n#&gt; [4]  train-rmse:6.833056 \n#&gt; [5]  train-rmse:5.139463 \n#&gt; [6]  train-rmse:3.949495\n\n\n\n# ?predict.xgb.Booster\nBoston_pred &lt;- predict(object = Boston_xgb, newdata = Boston_test$data)\n# RMSE\nrmse(Boston_test$label, Boston_pred)\n\n#&gt; [1] 4.509274\n\n\n\n\n\n\nBradley Efron, Iain Johnstone, Trevor Hastie, 和 Robert Tibshirani. 2004. 《Least Angle Regression》. Annals of Statistics 32 (2): 407–99. https://hastie.su.domains/Papers/LARS/LeastAngle_2002.pdf.\n\n\nBreheny, Patrick, 和 Jian Huang. 2011. 《Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection》. Annals of Applied Statistics 5 (1): 232–53. https://doi.org/10.1214/10-AOAS388.\n\n\nFriedman, Jerome, Robert Tibshirani, 和 Trevor Hastie. 2010. 《Regularization Paths for Generalized Linear Models via Coordinate Descent》. Journal of Statistical Software 33 (1): 1–22. https://doi.org/10.18637/jss.v033.i01.\n\n\nZhu, Jin, Xueqin Wang, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Shiyun Lin, 和 Junxian Zhu. 2022. 《abess: A Fast Best Subset Selection Library in Python and R》. Journal of Machine Learning Research 23 (202): 1–7. https://www.jmlr.org/papers/v23/21-1060.html.\n\n\nZou, Hui. 2006. 《The Adaptive Lasso and Its Oracle Properties》. Journal of the American Statistical Association 101 (476): 407–99. https://doi.org/10.1198/016214506000000735.\n\n\nZou, Hui, 和 Trevor Hastie. 2005. 《Regularization and Variable Selection Via the Elastic Net》. Journal of the Royal Statistical Society Series B: Statistical Methodology 67 (2): 301–20. https://doi.org/10.1111/j.1467-9868.2005.00503.x.",
    "crumbs": [
      "机器学习",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>回归问题</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "Abril-Pla O, Carroll C, Andreani V. 2023. “PyMC: A\nModern, and Comprehensive Probabilistic Programming Framework in\nPython.” PeerJ Computer Science 9 (e1516). https://doi.org/10.7717/peerj-cs.1516.\n\n\nAgresti, Alan. 2007. An Introduction to Categorical Data\nAnalysis. 2nd ed. Hoboken, New Jersey: John Wiley & Sons, Inc.\n\n\nAllaire, JJ, Romain Francois, Kevin Ushey, Gregory Vandenbrouck, Marcus\nGeelnard, and Intel. 2023. RcppParallel: Parallel\nProgramming Tools for Rcpp. https://CRAN.R-project.org/package=RcppParallel.\n\n\nAnsari, A. R., and R. A. Bradley. 1960. “Rank-Sum Tests for\nDispersions.” The Annals of Mathematical Statistics 31\n(4): 1174–89. https://doi.org/10.1214/aoms/1177705688.\n\n\nAnscombe, F. J. 1973. “Graphs in Statistical Analysis.”\nThe American Statistician 27 (1): 17. https://doi.org/10.2307/2682899.\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra\nThemes, Scales and Geoms for ggplot2.\nhttps://CRAN.R-project.org/package=ggthemes.\n\n\nAttali, Dean, and Christopher Baker. 2022. ggExtra: Add Marginal Histograms to ggplot2, and More ggplot2 Enhancements. https://CRAN.R-project.org/package=ggExtra.\n\n\nBai, H., L. Wang, W. Pan, and M. Frey. 2009. “Measuring\nMathematics Anxiety: Psychometric Analysis of a Bidimensional Affective\nScale.” Journal of Instructional Psychology 36 (3):\n185–93.\n\n\nBates, Douglas M., and Donald G. Watts. 1988. Nonlinear Regression\nAnalysis and Its Applications. New York, NY: John Wiley & Sons.\nhttps://doi.org/10.1002/9780470316757.app2.\n\n\nBates, Douglas, and Dirk Eddelbuettel. 2013. “Fast and Elegant\nNumerical Linear Algebra Using the RcppEigen\nPackage.” Journal of Statistical Software 52 (5): 1–24.\nhttps://doi.org/10.18637/jss.v052.i05.\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.\n“Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical\nSoftware 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBerkelaar, Michel et al. 2023. lpSolve:\nInterface to Lp_solve v. 5.5 to Solve\nLinear/Integer Programs. https://CRAN.R-project.org/package=lpSolve.\n\n\nBhadra, Anindya, Jyotishka Datta, Nicholas G. Polson, and Brandon\nWillard. 2019. “Lasso Meets Horseshoe: A\nSurvey.” Statistical Science 34 (3): 405–27. https://doi.org/10.1214/19-STS700.\n\n\nBickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. “Sex Bias\nin Graduate Admissions: Data from Berkeley.” Science 187\n(4175): 398–404. https://doi.org/10.1126/science.187.4175.398.\n\n\nBiecek, Przemyslaw. 2023. DrWhy: Explain, Explore and\nDebug Predictive Machine Learning Models. https://github.com/ModelOriented/DrWhy.\n\n\nBion, Ricardo. 2018. ggtech: ggplot2 Tech Themes and Scales.\n\n\nBivand, Roger. 2001. “More on Spatial Data Analysis.” R\nNews 1 (3): 13–17. https://www.r-project.org/doc/Rnews/Rnews_2001-3.pdf.\n\n\nBlangiardo, Marta, Michela Cameletti, Gianluca Baio, and Håvard Rue.\n2013. “Spatial and Spatio-Temporal Models with\nR-INLA.” Spatial and Spatio-Temporal\nEpidemiology 7 (December): 39–55. https://doi.org/10.1016/j.sste.2013.07.003.\n\n\nBlyth, Colin R., and David W. Hutchinson. 1960. “Table of\nNeyman-Shortest Unbiased Confidence Intervals for the Binomial\nParameter.” Biometrika 47 (3/4): 381–91. https://www.jstor.org/stable/2333308.\n\n\nBox, G. E. P., and D. R. Cox. 1964. “An Analysis of\nTransformations (with Discussion).” Journal of the Royal\nStatistical Society, Series B 26 (2): 211–52. https://www.jstor.org/stable/2984418.\n\n\nBradley Efron, Iain Johnstone, Trevor Hastie, and Robert Tibshirani.\n2004. “Least Angle Regression.” Annals of\nStatistics 32 (2): 407–99. https://hastie.su.domains/Papers/LARS/LeastAngle_2002.pdf.\n\n\nBrandao, Filipe. 2023. rAMPL:\nAMPL API for r. https://github.com/ampl/rAMPL.\n\n\nBreheny, Patrick, and Jian Huang. 2011. “Coordinate Descent\nAlgorithms for Nonconvex Penalized Regression, with Applications to\nBiological Feature Selection.” Annals of Applied\nStatistics 5 (1): 232–53. https://doi.org/10.1214/10-AOAS388.\n\n\nBrown, Lawrence D., T. Tony Cai, and Anirban DasGupta. 2001.\n“Interval Estimation for a Binomial Proportion.”\nStatistical Science, no. 2: 101–33. https://projecteuclid.org/euclid.ss/1009213286.\n\n\nBrunson, Jason Cory. 2020. “ggalluvial: Layered Grammar for Alluvial\nPlots.” Journal of Open Source Software 5 (49): 2017. https://doi.org/10.21105/joss.02017.\n\n\nBürkner, Paul-Christian. 2017. “brms:\nAn R Package for Bayesian Multilevel Models\nUsing Stan.” Journal of Statistical\nSoftware 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01.\n\n\nCabral, Rafael, David Bolin, and Håvard Rue. 2022. “Controlling\nthe Flexibility of Non-Gaussian Processes Through Shrinkage\nPriors.” Bayesian Analysis -1 (-1): 1–24. https://doi.org/10.1214/22-BA1342.\n\n\nCarpenter, Bob, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben\nGoodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li,\nand Allen Riddell. 2017. “Stan: A Probabilistic\nProgramming Language.” Journal of Statistical Software\n76 (1): 1–32. https://doi.org/10.18637/jss.v076.i01.\n\n\nCarpenter, Bob, Matthew D. Hoffman, Marcus Brubaker, Daniel Lee, Peter\nLi, and Michael Betancourt. 2015. “The Stan Math Library:\nReverse-Mode Automatic Differentiation in c++.” https://arxiv.org/abs/1509.07164.\n\n\nChristensen, O. F., and P. J. Ribeiro Jr. 2002. “geoRglm: A Package for Generalised Linear Spatial\nModels.” R News 2 (2): 26–28.\n\n\nChung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and\nJingchen Liu. 2013. “A Nondegenerate Penalized Likelihood\nEstimator for Variance Parameters in Multilevel Models.”\nPsychometrika 78 (4): 685–709. https://doi.org/10.1007/s11336-013-9328-2.\n\n\nClopper, C. J., and E. S. Pearson. 1934. “The Use of Confidence or\nFiducial Limits Illustrated in the Case of the Binomial.”\nBiometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nCohen, Jacob. 1994. “The Earth Is Round (p &lt; .05).” American\nPsychologist 49 (12): 997–1003. https://doi.org/10.1037/0003-066x.49.12.997.\n\n\nConstantin, Ahlmann-Eltze, and Indrajeet Patil. 2021. “ggsignif: R Package for Displaying Significance\nBrackets for ggplot2.”\nPsyArxiv. https://doi.org/10.31234/osf.io/7awm6.\n\n\nDavies, Rhian, Steph Locke, and Lucy D’Agostino McGowan. 2022. datasauRus: Datasets from the Datasaurus\nDozen. https://CRAN.R-project.org/package=datasauRus.\n\n\nDemidenko, Eugene. 2013. Mixed Models: Theory and Applications with\nR. 2nd ed. Hoboken, New Jersey: John Wiley & Sons.\nhttps://doi.org/10.1002/9781118651537.\n\n\nDiggle, P. J., J. A. Tawn, and R. A. Moyeed. 1998. “Model-Based\nGeostatistics.” Journal of the Royal Statistical Society:\nSeries C (Applied Statistics) 47 (3): 299–350. https://doi.org/10.1111/1467-9876.00113.\n\n\nDobson, Annette J. 1983. An Introduction to Statistical\nModelling. 1st ed. London: Chapman; Hall/CRC. https://doi.org/10.1007/978-1-4899-3174-0.\n\n\nDonegan, Connor. 2022. “geostan: An r\nPackage for Bayesian Spatialanalysis.” Journal of Open Source\nSoftware 7 (79): 4716. https://doi.org/10.21105/joss.04716.\n\n\nDunning, Iain, Joey Huchette, and Miles Lubin. 2017.\n“JuMP: A Modeling Language for Mathematical\nOptimization.” SIAM Review 59 (2): 295–320. https://doi.org/10.1137/15M1020575.\n\n\nEddelbuettel, Dirk, and James Joseph Balamuta. 2018. “Extending R with C++: A Brief\nIntroduction to Rcpp.” The American\nStatistician 72 (1): 28–36. https://doi.org/10.1080/00031305.2017.1375990.\n\n\nEddelbuettel, Dirk, John W. Emerson, and Michael J. Kane. 2023.\nBH: Boost c++ Header Files. https://CRAN.R-project.org/package=BH.\n\n\nEddelbuettel, Dirk, and Romain François. 2011. “Rcpp:\nSeamless R and C++ Integration.”\nJournal of Statistical Software 40 (8): 1–18. https://doi.org/10.18637/jss.v040.i08.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, and Robert Tibshirani.\n2004. “Least angle regression.”\nThe Annals of Statistics 32 (2): 407–99. https://doi.org/10.1214/009053604000000067.\n\n\nEpps, T. W., and Lawrence B. Pulley. 1983. “A Test for Normality\nBased on the Empirical Characteristic Function.”\nBiometrika 70 (3): 723–26. https://doi.org/10.2307/2336512.\n\n\nFeinerer, Ingo, Kurt Hornik, and David Meyer. 2008. “Text Mining\nInfrastructure in R.” Journal of Statistical\nSoftware 25 (5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nFeng, Dai, and Luke Tierney. 2008. “Computing and Displaying\nIsosurfaces in R.” Journal of Statistical\nSoftware 28 (1). https://doi.org/10.18637/jss.v028.i01.\n\n\nFisher, R. A. 1936. “The Use of Multiple Measurements in Taxonomic\nProblems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\nFligner, Michael A., and Timothy J. Killeen. 1976.\n“Distribution-Free Two-Sample Tests for Scale.” Journal\nof the American Statistical Association 71 (353): 210–13. https://doi.org/10.1080/01621459.1976.10481517.\n\n\nFriedman, Jerome, Robert Tibshirani, and Trevor Hastie. 2010.\n“Regularization Paths for Generalized Linear Models via Coordinate\nDescent.” Journal of Statistical Software 33 (1): 1–22.\nhttps://doi.org/10.18637/jss.v033.i01.\n\n\nFriendly, Michael. 2021. HistData: Data Sets from the\nHistory of Statistics and Data Visualization. https://CRAN.R-project.org/package=HistData.\n\n\nFriendly, Michael, and David Meyer. 2016. Discrete Data Analysis\nwith r: Visualization and Modeling Techniques for Categorical and Count\nData. 1st ed. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nFu, Anqi, and Balasubramanian Narasimhan. 2023.\nECOSolveR: Embedded Conic Solver in r. https://CRAN.R-project.org/package=ECOSolveR.\n\n\nGabry, Jonah, Rok Češnovar, and Andrew Johnson. 2023. cmdstanr: R Interface to\nCmdStan. https://mc-stan.org/cmdstanr/.\n\n\nGabry, Jonah, Daniel Simpson, Aki Vehtari, Michael Betancourt, and\nAndrew Gelman. 2019. “Visualization in Bayesian Workflow.”\nJournal of the Royal Statistical Society Series A: Statistics in\nSociety 182: 389–402. https://doi.org/10.1111/rssa.12378.\n\n\nGałecki, Andrzej, and Tomasz Burzykowski. 2013. Linear Mixed-Effects\nModels Using R: A Step-by-Step Approach. 1st ed. New\nYork, NY: Springer New York. https://doi.org/10.1007/978-1-4614-3900-4.\n\n\nGalton, F. 1886. “Regression Towards Mediocrity in Hereditary\nStature.” Journal of the Anthropological Institute 15:\n246–63.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, et al. 2021.\nviridis: Colorblind-Friendly Color Maps\nfor R. https://doi.org/10.5281/zenodo.4679424.\n\n\nGelfand, Alan E., Susan E. Hills, Amy Racine-Poon, and Adrian F. M.\nSmith. 1990. “Illustration of Bayesian Inference in Normal Data\nModels Using Gibbs Sampling.” Journal of the American\nStatistical Association 85 (412): 972–85. https://doi.org/10.2307/2289594.\n\n\nGelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A\nProbabilistic Programming Language for Bayesian Inference and\nOptimization.” Journal of Educational and Behavioral\nStatistics 40 (5): 530–43. https://doi.org/10.3102/1076998615606113.\n\n\nGeyer, Charles J., and Glen D. Meeden. 2005. “Fuzzy and Randomized\nConfidence Intervals and p-Values.” Statistical Science\n20 (4): 358–66. https://www.jstor.org/stable/20061193.\n\n\nGómez-Rubio, Virgilio. 2020. Bayesian Inference with INLA. Boca\nRaton, Florida: Chapman; Hall/CRC. https://becarioprecario.bitbucket.io/inla-gitbook/.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2023.\n“rstanarm: Bayesian\nApplied Regression Modeling via Stan.” https://mc-stan.org/rstanarm/.\n\n\nGross, Calli, and Philipp Ottolinger. 2016. ggThemeAssist: Add-in to Customize ggplot2 Themes. https://CRAN.R-project.org/package=ggThemeAssist.\n\n\nGrün, Bettina, and Kurt Hornik. 2011. “topicmodels: An R Package for Fitting\nTopic Models.” Journal of Statistical Software 40 (13):\n1–30. https://doi.org/10.18637/jss.v040.i13.\n\n\nHadfield, Jarrod D. 2010. “MCMC Methods for\nMulti-Response Generalized Linear Mixed Models: The\nMCMCglmm R Package.” Journal of\nStatistical Software 33 (2): 1–22. https://www.jstatsoft.org/v33/i02/.\n\n\nHahsler, Michael, and Kurt Hornik. 2007. “TSP:\nInfrastructure for the Traveling Salesperson\nProblem.” Journal of Statistical Software 23 (2): 1–21.\nhttps://doi.org/10.18637/jss.v023.i02.\n\n\nHahsler, Michael, Matthew Piekenbrock, and Derek Doran. 2019.\n“dbscan: Fast Density-Based Clustering\nwith R.” Journal of Statistical Software 91\n(1): 1–30. https://doi.org/10.18637/jss.v091.i01.\n\n\nHanley, James A. 2004. “’Transmuting’ Women into Men: Galton’s\nFamily Data on Human Stature.” The American Statistician\n58 (3): 237–43.\n\n\nHart, William E, Jean-Paul Watson, and David L Woodruff. 2011.\n“Pyomo: Modeling and Solving Mathematical Programs in\nPython.” Mathematical Programming\nComputation 3 (3): 219–60.\n\n\nHasselblad, Victor. 1969. “Estimation of Finite Mixtures of\nDistributions from the Exponential Family.” Journal of the\nAmerican Statistical Association 64 (328): 1459–71. https://doi.org/10.1080/01621459.1969.10501071.\n\n\nHawkins, Oliver. 2022. pilot: A Minimal\nggplot2 Theme with an Accessible Discrete\nColor Palette. https://github.com/olihawkins/pilot.\n\n\nHeyde, C. C., E. Seneta, P. Crépel, S. E. Fienberg, and J. Gani. 2001.\nStatisticians of the Centuries. New York, NY: Springer-Verlag.\nhttps://doi.org/10.1007/978-1-4613-0179-0.\n\n\nHoaglin, David C., and Roy E. Welsch. 1978. “The Hat Matrix in\nRegression and ANOVA.” The American Statistician 32 (1):\n17–22. https://www.jstor.org/stable/2683469.\n\n\nHolt, Charles C. 2004. “Forecasting Seasonals and Trends by\nExponentially Weighted Moving Averages.” International\nJournal of Forecasting 20 (1): 5–10. https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nHSU, P. L. 1938. “Contribution to the Theory of \"Student’s\" T-Test as Applied to the Problem of\nTwo Samples.” Statistical Research Memoirs 2: 1–24.\n\n\n———. 1983. Collected Papers. New York, NY: Springer-Verlag.\n\n\nHvitfeldt, Emil. 2021. paletteer:\nComprehensive Collection of Color Palettes. https://github.com/EmilHvitfeldt/paletteer.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine Learning\nfor Text Analysis in R. New York: Chapman; Hall/CRC.\nhttps://smltar.com/.\n\n\nJiang, Jiming, and Thuan Nguyen. 2021. Linear and Generalized Linear\nMixed Models and Their Applications. 2nd ed. New York, NY: Springer\nNew York. https://doi.org/10.1007/978-1-0716-1282-8.\n\n\nJohnson, Steven G. 2023. The NLopt Nonlinear\nOptimization Package. https://CRAN.R-project.org/package=nloptr.\n\n\nJosé. Chacón, Tarn Duong. 2018. Multivariate Kernel Smoothing and\nIts Applications. Boca Raton, Florida: Chapman; Hall/CRC. https://www.mvstat.net/mvksa/.\n\n\nJoshua V. Dillon, Dustin Tran, Ian Langmore. 2017.\n“TensorFlow Distributions.” https://arxiv.org/abs/1711.10604.\n\n\nKabacoff, Robert I. 2022. R in Action: Data Analysis\nand Graphics with R and Tidyverse. 3rd\ned. Shelter Island, NY: Manning Publications Co.\n\n\nKarambelkar, Bhaskar. 2016. colormap:\nColor Palettes Using Colormaps Node Module. https://CRAN.R-project.org/package=colormap.\n\n\nKaratzoglou, Alexandros, Alex Smola, Kurt Hornik, and Achim Zeileis.\n2004. “kernlab: An S4\nPackage for Kernel Methods in R.” Journal of\nStatistical Software 11 (9): 1–20. https://doi.org/10.18637/jss.v011.i09.\n\n\nKassambara, Alboukadel. 2022. ggpubr:\nggplot2 Based Publication Ready Plots.\nhttps://CRAN.R-project.org/package=ggpubr.\n\n\nKaufman, Leonard, and Peter J. Rousseeuw. 1990. Finding Groups in\nData: An Introduction to Cluster Analysis. 1st ed. Wiley Series in\nProbability and Statistics. Wiley. https://doi.org/10.1002/9780470316801.\n\n\nKay, Matthew. 2022. ggdist:\nVisualizations of Distributions and Uncertainty. https://doi.org/10.5281/zenodo.3879620.\n\n\nKim, Seock-Ho, and Allan S. Cohen. 1998. “On the Behrens-Fisher\nProblem: A Review.” Journal of Educational and Behavioral\nStatistics 23 (4): 356–77. https://doi.org/10.2307/1165281.\n\n\nKim, Yongdai, Hosik Choi, and Hee-Seok Oh. 2008. “Smoothly Clipped\nAbsolute Deviation on High Dimensions.” Journal of the\nAmerican Statistical Association 103 (484): 1665–73. https://doi.org/10.1198/016214508000001066.\n\n\nKolaczyk, Eric D., and Gábor Csárdi. 2020. Statistical Analysis of\nNetwork Data with R. 2nd ed. Springer, New York, NY.\nhttps://doi.org/10.1007/978-3-030-44129-6.\n\n\nKothari, Aditya. 2022. ggTimeSeries:\nTime Series Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggTimeSeries.\n\n\nKuhn, Max, and Hadley Wickham. 2020. Tidymodels: A Collection of\nPackages for Modeling and Machine Learning Using Tidyverse\nPrinciples. https://www.tidymodels.org.\n\n\nLang, Michel, and Patrick Schratz. 2023. mlr3verse: Easily Install and Load the mlr3 Package Family. https://CRAN.R-project.org/package=mlr3verse.\n\n\nLemon, Jim. 2006. “plotrix: A Package\nin the Red Light District of R.” R-News 6\n(4): 8–12.\n\n\nLigges, Uwe, and Martin Mächler. 2003. “scatterplot3d: An R Package for\nVisualizing Multivariate Data.” Journal of Statistical\nSoftware 8 (11): 1–20. https://doi.org/10.18637/jss.v008.i11.\n\n\nLikert, Rensis. 1932. “A Technique for the Measurement of\nAttitudes.” Archives of Psychology 142 (1): 1–55.\n\n\nLüdecke, Daniel. 2019. strengejacke:\nLoad Packages Associated with Strenge Jacke! https://github.com/strengejacke/strengejacke.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Brenton M.\nWiernik, Etienne Bacher, Rémi Thériault, and Dominique Makowski. 2022.\n“easystats: Framework for Easy\nStatistical Modeling, Visualization, and Reporting.”\nCRAN. https://easystats.github.io/easystats/.\n\n\nMarron, J. S., and Ian L. Dryden. 2022. Object Oriented Data\nAnalysis. 1st ed. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nMcGill, Tukey, R., and W. A. Larsen. 1978. “Variations of Box\nPlots.” The American Statistician 32 (1): 12–16. https://www.jstor.org/stable/2683468.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and\nFriedrich Leisch. 2023. e1071: Misc\nFunctions of the Department of Statistics, Probability Theory Group\n(Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMeyer, David, Achim Zeileis, and Kurt Hornik. 2006. “The Strucplot\nFramework: Visualizing Multi-Way Contingency Tables with vcd.” Journal of Statistical\nSoftware 17 (3): 1–48. https://doi.org/10.18637/jss.v017.i03.\n\n\nMood, A. M. 1954. “On the Asymptotic Efficiency of Certain\nNonparametric Two-Sample Tests.” The Annals of Mathematical\nStatistics 25 (3): 514–22. https://doi.org/10.1214/aoms/1177728719.\n\n\nMoraga, Paula. 2020. Geospatial Health Data: Modeling and\nVisualization with R-INLA and Shiny. Boca Raton,\nFlorida: Chapman; Hall/CRC. https://www.paulamoraga.com/book-geospatial/.\n\n\nMorris, Mitzi, Katherine Wheeler-Martin, Dan Simpson, Stephen J. Mooney,\nAndrew Gelman, and Charles DiMaggio. 2019. “Bayesian Hierarchical\nSpatial Models: Implementing the Besag York Mollié Model in\nStan.” Spatial and Spatio-Temporal Epidemiology 31\n(November): 100301. https://doi.org/10.1016/j.sste.2019.100301.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An\nIntroduction. Cambridge, Massachusetts: MIT Press. https://probml.github.io/pml-book/book1.html.\n\n\nNeitmann, Thomas. 2020. ggcharts:\nShorten the Distance from Data Visualization Idea to Actual Plot.\nhttps://CRAN.R-project.org/package=ggcharts.\n\n\nNeuwirth, Erich. 2022. RColorBrewer:\nColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.\n\n\nNewcombe, Robert G. 1998. “Interval Estimation for the Difference\nBetween Independent Proportions: Comparison of Eleven Methods.”\nStatistics in Medicine 17 (8): 873–90. https://doi.org/10.1002/(SICI)1097-0258(19980430)17:8&lt;873::AID-SIM779&gt;3.0.CO;2-I.\n\n\nNiyizibi, Bart, Wade Brorsen, and Eunchun Park. 2018. “Using\nBayesian Kriging for Spatial Smoothing of Trends in the Means and\nVariances of Crop Yield Densities.” Economic Geography.\nhttps://doi.org/10.22004/ag.econ.274403.\n\n\nO’Donoghue, Brendan, Eric Chu, Parikh Neal, and Stephen Boyd. 2016.\n“Operator Splitting for Conic Optimization via Homogeneous\nSelf-Dual Embedding.” Journal of Optimization Theory and\nApplications 169 (3): 1042–68. https://doi.org/10.1007/s10957-016-0892-3.\n\n\nOtto, James, and David Kahle. 2023. “ggdensity: Improved Bivariate Density\nVisualization in R.” The R Journal 15:\n220–36. https://doi.org/10.32614/RJ-2023-048.\n\n\nPalmí-Perales, Francisco, Virgilio Gómez-Rubio, Roger S. Bivand, Michela\nCameletti, and Håvard Rue. 2022. “Bayesian Inference for\nMultivariate Spatial Models with r-INLA.” The R\nJournal. https://doi.org/10.48550/arXiv.2212.10976.\n\n\nPatil, Indrajeet. 2021. “Visualizations with\nstatistical details: The ggstatsplot\napproach.” Journal of Open Source\nSoftware 6 (61): 3167. https://doi.org/10.21105/joss.03167.\n\n\nPebesma, Edzer. 2018. “Simple Features for R:\nStandardized Support for Spatial Vector Data.” The R\nJournal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\n———. 2022. stars: Spatiotemporal Arrays,\nRaster and Vector Data Cubes. https://CRAN.R-project.org/package=stars.\n\n\nPedersen, Thomas Lin, and Fabio Crameri. 2022. scico: Colour Palettes Based on the Scientific\nColour-Maps. https://CRAN.R-project.org/package=scico.\n\n\nPeter Diggle, Kung-Yee Liang, Patrick Heagerty, and Scott Zeger. 2002.\nAnalysis of Longitudinal Data. 2nd ed. Oxford: Oxford\nUniversity Press.\n\n\nPiironen, Juho, Markus Paasiniemi, and Aki Vehtari. 2020.\n“Projective Inference in High-Dimensional Problems:\nPrediction and Feature Selection.” Electronic\nJournal of Statistics 14 (1): 2155–97. https://doi.org/10.1214/20-EJS1711.\n\n\nPiironen, Juho, and Aki Vehtari. 2017a. “Comparison of\nBayesian Predictive Methods for Model Selection.”\nStatistics and Computing 27 (3): 711–35. https://doi.org/10.1007/s11222-016-9649-y.\n\n\n———. 2017b. “Sparsity Information and Regularization in the\nHorseshoe and Other Shrinkage Priors.” Electronic Journal of\nStatistics 11 (2): 5018–51. https://doi.org/10.1214/17-EJS1337SI.\n\n\nPinheiro, JoséC., and Douglas M. Bates. 2000. Mixed-Effects Models\nin S and S-PLUS. New York, NY:\nSpringer-Verlag.\n\n\nPlummer, Martyn. 2021. rjags: Bayesian\nGraphical Models Using MCMC. https://CRAN.R-project.org/package=rjags.\n\n\nPlummer, Martyn, Nicky Best, Kate Cowles, and Karen Vines. 2006.\n“coda: Convergence Diagnosis and\nOutput Analysis for MCMC.” R News 6 (1):\n7–11. https://journal.r-project.org/archive/.\n\n\nPu, Xiaoying, and Matthew Kay. 2020. “A Probabilistic Grammar of\nGraphics.” In Proceedings of the 2020 CHI\nConference on Human Factors in Computing Systems, 1–13. ACM. https://doi.org/10.1145/3313831.3376466.\n\n\nRasmussen, Carl Edward, and Christopher K. I. Williams. 2006.\nGaussian Processes for Machine Learning. Cambridge,\nMassachusetts: MIT Press. https://gaussianprocess.org/gpml/.\n\n\nRigby, R. A., and D. M. Stasinopoulos. 2005. “Generalized Additive\nModels for Location, Scale and Shape (with Discussion).”\nJournal of the Royal Statistical Society: Series C (Applied\nStatistics) 54 (3): 507–54. https://doi.org/10.1111/j.1467-9876.2005.00510.x.\n\n\nRizopoulos, Dimitris. 2023. GLMMadaptive: Generalized\nLinear Mixed Models Using Adaptive Gaussian Quadrature. https://CRAN.R-project.org/package=GLMMadaptive.\n\n\nRönnegård, Lars, Xia Shen, and Moudud Alam. 2010. “hglm: A Package for Fitting Hierarchical\nGeneralized Linear Models.” The R Journal 2 (2): 20–28.\nhttps://doi.org/10.32614/RJ-2010-009.\n\n\nRosseel, Yves. 2012. “lavaan: An\nR Package for Structural Equation Modeling.”\nJournal of Statistical Software 48 (2): 1–36. https://doi.org/10.18637/jss.v048.i02.\n\n\nRubin, Donald B. 1981. “Estimation in Parallel Randomized\nExperiments.” Journal of Educational Statistics 6 (4):\n377–401. https://doi.org/10.3102/10769986006004377.\n\n\nRue, Håvard, Sara Martino, and Nicholas Chopin. 2009. “Approximate\nBayesian Inference for Latent Gaussian Models\nUsing Integrated Nested Laplace Approximations (with\nDiscussion).” Journal of the Royal Statistical Society,\nSeries B 71 (2): 319–92.\n\n\nRyan, Jeffrey A., and Joshua M. Ulrich. 2022. quantmod: Quantitative Financial Modelling\nFramework. https://CRAN.R-project.org/package=quantmod.\n\n\nS original by Berwin A. Turlach, Fortran contributions from Cleve Moler\ndpodi/LINPACK), R port by Andreas Weingessel. 2019. quadprog: Functions to Solve Quadratic Programming\nProblems. https://CRAN.R-project.org/package=quadprog.\n\n\nSainsbury-Dale, Matthew, Andrew Zammit-Mangion, and Noel Cressie. 2022.\n“Modelling Big, Heterogeneous, Non-Gaussian Spatial and\nSpatio-Temporal Data Using FRK.” Journal of\nStatistical Software. https://doi.org/10.48550/arXiv.2110.02507.\n\n\nSarkar, Deepayan. 2008. lattice:\nMultivariate Data Visualization with R. New York:\nSpringer. http://lmdvr.r-forge.r-project.org.\n\n\nSchilling, Walter. 1947. “A Frequency Distribution Represented as\nthe Sum of Two Poisson Distributions.” Journal of the\nAmerican Statistical Association 42 (239): 407–24.\n\n\nSchwendinger, Florian, and Hans W. Borchers. 2023. CRAN Task\nView: Optimization and Mathematical Programming. https://CRAN.R-project.org/view=Optimization.\n\n\nSchwendinger, Florian, and Dirk Schumacher. 2023. highs: HiGHS Optimization\nSolver. https://CRAN.R-project.org/package=highs.\n\n\nScrucca, Luca. 2013. “GA: A Package for Genetic\nAlgorithms in R.” Journal of Statistical\nSoftware 53 (4): 1–37. https://doi.org/10.18637/jss.v053.i04.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery.\n2016. “mclust 5: Clustering,\nClassification and Density Estimation Using Gaussian Finite\nMixture Models.” The R Journal 8 (1):\n289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShapiro, S. S., and M. B. Wilk. 1965. “An Analysis of Variance\nTest for Normality (Complete Samples).” Biometrika 52\n(3-4): 591–611. https://doi.org/10.1093/biomet/52.3-4.591.\n\n\nSidiropoulos, Nikos, Sina Hadi Sohi, Thomas Lin Pedersen, Bo Torben\nPorse, Ole Winther, Nicolas Rapin, and Frederik Otzen Bagger. 2018.\n“SinaPlot: An Enhanced Chart for Simple and Truthful\nRepresentation of Single Observations over Multiple Classes.”\nJournal of Computational and Graphical Statistics 27 (3):\n673–76. https://doi.org/10.1080/10618600.2017.1366914.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR. New York: O’Reilly Media, Inc. https://www.tidytextmining.com/.\n\n\nSimon, Noah, Jerome H. Friedman, Trevor Hastie, and Rob Tibshirani.\n2011. “Regularization Paths for Cox’s Proportional Hazards Model\nvia Coordinate Descent.” Journal of Statistical Software\n39 (5): 1–13. https://doi.org/10.18637/jss.v039.i05.\n\n\nSlowikowski, Kamil. 2021. ggrepel:\nAutomatically Position Non-Overlapping Text Labels with ggplot2. https://CRAN.R-project.org/package=ggrepel.\n\n\nSoetaert, Karline. 2021. plot3D:\nPlotting Multi-Dimensional Data. https://CRAN.R-project.org/package=plot3D.\n\n\nSorensen, Tanner, Sven Hohenstein, and Shravan Vasishth. 2016.\n“Bayesian Linear Mixed Models Using Stan: A Tutorial for\nPsychologists, Linguists, and Cognitive Scientists.” The\nQuantitative Methods for Psychology 12 (3): 175–200. https://doi.org/10.20982/tqmp.12.3.p175.\n\n\nStan Development Team. 2023a. “RStan: The\nR Interface to Stan.” https://mc-stan.org/.\n\n\n———. 2023b. “StanHeaders: Headers for the\nR Interface to Stan.” https://mc-stan.org/.\n\n\n\"Student\". 1908. “The Probable Error of a Mean.”\nBiometrika 6: 1–25.\n\n\nStylianou, Nassos, Will Dahlgreen, Robert Cuffe, Tom Calver, and Ransome\nMpini. 2022. bbplot: Making ggplot2 Graphics in BBC NEWS\nStyle.\n\n\nTang, Yuan, Masaaki Horikoshi, and Wenxuan Li. 2016. “ggfortify: Unified Interface to Visualize\nStatistical Result of Popular r Packages.” The R Journal\n8 (2): 474–85. https://doi.org/10.32614/RJ-2016-060.\n\n\nTerry M. Therneau, and Patricia M. Grambsch. 2000. Modeling Survival\nData: Extending the Cox Model. New York: Springer.\n\n\nTheussl, Stefan, and Kurt Hornik. 2023. Rglpk: R/GNU\nLinear Programming Kit Interface. https://CRAN.R-project.org/package=Rglpk.\n\n\nTheußl, Stefan, Florian Schwendinger, and Kurt Hornik. 2020.\n“ROI: An Extensible R Optimization\nInfrastructure.” Journal of Statistical Software 94\n(15): 1–64. https://doi.org/10.18637/jss.v094.i15.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via\nthe Lasso.” Journal of the Royal Statistical\nSociety. Series B (Methodological) 58 (1): 267–88. http://www.jstor.org/stable/2346178.\n\n\nTobin, Ciaran. 2020. ggthemr: Themes for\nggplot2.\n\n\nTobin, J. 1958. “Estimation of Relationships for Limited Dependent\nVariables.” Econometrica 26 (1): 24–36. https://doi.org/10.2307/1907382.\n\n\nTobler, Waldo. 1970. “A Computer Movie Simulating Urban Growth in\nthe Detroit Region.” Economic Geography 46 (Supplement):\n234–40. https://doi.org/10.2307/143141.\n\n\nTyner, Sam, François Briatte, and Heike Hofmann. 2017. “Network\nVisualization with ggplot2.”\nThe R Journal 9 (1): 27–59. https://doi.org/10.32614/RJ-2017-023.\n\n\nVaradhan, Ravi, and Paul Gilbert. 2009. “BB: An\nR Package for Solving a Large System of Nonlinear Equations\nand for Optimizing a High-Dimensional Nonlinear Objective\nFunction.” Journal of Statistical Software 32 (4): 1–26.\nhttps://www.jstatsoft.org/v32/i04/.\n\n\nVehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical\nBayesian Model Evaluation Using Leave-One-Out Cross-Validation and\nWAIC.” Statistics and Computing 27: 1413–32. https://doi.org/10.1007/s11222-016-9696-4.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and\nPaul-Christian Bürkner. 2021. “Rank-Normalization, Folding, and Localization: An\nImproved R̂ for Assessing\nConvergence of MCMC (with Discussion).” Bayesian\nAnalysis 16 (2): 667–718. https://doi.org/10.1214/20-BA1221.\n\n\nWand, M. P., and M. C. Jones. 1995. Kernel Smoothing. 1st ed.\nBoca Raton, Florida: Chapman; Hall/CRC. http://matt-wand.utsacademics.info/webWJbook/.\n\n\nWarnes, J. J., and B. D. Ripley. 1987. “Problems with Likelihood\nEstimation of Covariance Functions of Spatial Gaussian\nProcesses.” Biometrika 74 (3): 640–42.\n\n\nWickham, Charlotte. 2018. munsell:\nUtilities for Using Munsell Colours. https://CRAN.R-project.org/package=munsell.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant\nGraphics for Data Analysis. 2nd ed. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science: Import, Tidy, Transform, Visualize,\nand Model Data. 2nd ed. Sebastopol, California: O’Reilly Media,\nInc. https://r4ds.hadley.nz/.\n\n\nWickham, Hadley, Danielle Navarro, and Thomas Lin Pedersen. 2024.\nggplot2: Elegant Graphics for Data\nAnalysis. 3rd ed. Springer-Verlag New York. https://ggplot2-book.org/.\n\n\nWickham, Hadley, and Dana Seidel. 2022. scales: Scale Functions for Visualization. https://CRAN.R-project.org/package=scales.\n\n\nWilke, Claus O. 2020. ggtext: Improved\nText Rendering Support for ggplot2. https://CRAN.R-project.org/package=ggtext.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession,\nand Statistical Inference.” Journal of the American\nStatistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nWinters, Peter R. 1960. “Forecasting Sales by Exponentially\nWeighted Moving Averages.” Management Science 6 (3):\n324–42. https://doi.org/10.1287/mnsc.6.3.324.\n\n\nWood, S. N. 2004. “Stable and Efficient Multiple Smoothing\nParameter Estimation for Generalized Additive Models.”\nJournal of the American Statistical Association 99 (467):\n673–86.\n\n\n———. 2017. Generalized Additive Models: An Introduction with\nR. 2nd ed. Chapman; Hall/CRC. https://www.maths.ed.ac.uk/~swood34/igam/.\n\n\nWood, Simon N. 2019. “Simplified Integrated Nested Laplace\nApproximation.” Biometrika 107 (1): 223–30. https://doi.org/10.1093/biomet/asz044.\n\n\nWood, Simon N., Yannig Goude, and Simon Shaw. 2015. “Generalized\nAdditive Models for Large Data Sets.” Journal of the Royal\nStatistical Society Series C: Applied Statistics 64 (1): 139–55. https://doi.org/10.1111/rssc.12068.\n\n\nWood, Simon N., Natalya Pya, and Benjamin Säfken. 2016. “Smoothing\nParameter and Model Selection for General Smooth Models.”\nJournal of the American Statistical Association 111 (516):\n1548–63. https://doi.org/10.1080/01621459.2016.1180986.\n\n\nXiao, Nan. 2018. ggsci: Scientific\nJournal and Sci-Fi Themed Color Palettes for ggplot2. https://CRAN.R-project.org/package=ggsci.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and\nKnitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.\n\n\nYu, Guangchuang. 2022. ggimage: Use\nImage in ggplot2. https://CRAN.R-project.org/package=ggimage.\n\n\nYutani, Hiroaki. 2022. string2path:\nRendering Font into data.frame. https://CRAN.R-project.org/package=string2path.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D.\nMcWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020.\n“colorspace: A Toolbox for\nManipulating and Assessing Colors and Palettes.” Journal of\nStatistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, David Meyer, and Kurt Hornik. 2007.\n“Residual-Based Shadings for Visualizing (Conditional)\nIndependence.” Journal of Computational and Graphical\nStatistics 16 (3): 507–25. https://doi.org/10.1198/106186007X237856.\n\n\nZhang, Cun-Hui. 2010. “Nearly Unbiased Variable Selection Under\nMinimax Concave Penalty.” The Annals of Statistics 38\n(2): 894–942. https://doi.org/10.1214/09-AOS729.\n\n\nZhu, Jin, Xueqin Wang, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang\nZhang, Shiyun Lin, and Junxian Zhu. 2022. “abess: A Fast Best Subset Selection Library in\nPython and R.” Journal of Machine\nLearning Research 23 (202): 1–7. https://www.jmlr.org/papers/v23/21-1060.html.\n\n\nZou, Hui. 2006. “The Adaptive Lasso and Its Oracle\nProperties.” Journal of the American Statistical\nAssociation 101 (476): 407–99. https://doi.org/10.1198/016214506000000735.\n\n\nZou, Hui, and Trevor Hastie. 2005. “Regularization and Variable\nSelection via the Elastic Net.” Journal of the Royal\nStatistical Society Series B: Statistical Methodology 67 (2):\n301–20. https://doi.org/10.1111/j.1467-9868.2005.00503.x.\n\n\n宋泽熙. 2011. “两个二项总体成功概率的比较.”\n中国校外教育（理论） z1: 81. https://doi.org/10.3969/j.issn.1004-8502-B.2011.z1.0919.\n\n\n赵鹏, 谢益辉, and 黄湘云. 2021. 现代统计图形. 北京:\n人民邮电出版社. https://bookdown.org/xiangyun/msg.\n\n\n韦博成. 2009.\n“《红楼梦》前80回与后40回某些文风差异的统计分析（两个独立二项总体等价性检验的一个应用）.”\n应用概率统计 25 (4): 441–48. https://doi.org/10.3969/j.issn.1001-4268.2009.04.012.",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "notations.html",
    "href": "notations.html",
    "title": "附录 A — 数学符号",
    "section": "",
    "text": "\\[\n\\def\\bm#1{{\\boldsymbol #1}}\n\\]\n\n\n\n\n表格 A.1: 数学符号表\n\n\n\n\n\n符号\n含义\n\n\n\n\n\\(\\mathbb{R}^n\\)\n\\(n\\) 维实数\n\n\n\\(\\mathbb{R}^{n\\times p}\\)\n\\(n\\times p\\) 维实矩阵\n\n\n\\(\\mathbb{Z}\\)\n整数\n\n\n\\(\\mathcal{N}\\)\n正态分布\n\n\n\\(\\mathcal{D}\\)\n研究区域\n\n\n\\(\\mathcal{S}\\)\n随机过程\n\n\n\\(\\mathcal{G}\\)\n图\n\n\n\\(\\mathcal{L}\\)\n似然\n\n\n\\(\\mathrm{MVN}\\)\n多元正态分布\n\n\n\\(\\Sigma\\)\n协方差矩阵\n\n\n\\(x\\)\n标量\n\n\n\\(\\bm{x}\\)\n向量\n\n\n\\(X\\)\n矩阵\n\n\n\\(X^{\\top}\\)\n矩阵转置\n\n\n\\(X^{-1}\\)\n矩阵求逆\n\n\n\\(I\\)\n单位矩阵\n\n\n\\(J\\)\n全 1 矩阵\n\n\n\\(\\bm{1}\\)\n全 1 向量\n\n\n\\(\\bm{0}\\)\n全 0 向量\n\n\n\\(\\beta\\)\n截距\n\n\n\\(\\bm{\\beta}\\)\n系数向量\n\n\n\\(\\ell\\)\n对数似然\n\n\n\\(\\mathsf{E}\\)\n期望\n\n\n\\(\\mathsf{Var}\\)\n方差\n\n\n\\(\\mathsf{Cov}\\)\n协方差\n\n\n\\(\\mathrm{Bernoulli}\\)\n伯努利分布\n\n\n\\(\\mathrm{Binomial}\\)\n二项分布\n\n\n\\(\\mathrm{Poisson}\\)\n泊松分布\n\n\n\\(\\mathrm{Gamma}\\)\n伽马分布\n\n\n\\(\\mathrm{Beta}\\)\n贝塔分布\n\n\n\\(\\Gamma\\)\n伽马函数\n\n\n\\(\\|\\bm{x}\\|_0\\)\n向量的 0 范数\n\n\n\\(\\|\\bm{x}\\|_1\\)\n向量的 1 范数\n\n\n\\(\\|\\bm{x}\\|_2\\)\n向量的 2 范数\n\n\n\\(\\|\\bm{x}\\|_p\\)\n向量的 \\(p\\) 范数\n\n\n\n\n\n\n全书英文字母表示数据，希腊字母表示参数，加粗表示向量，大写表示矩阵，花体字母各有含义。所有的向量都是列向量，如上表中的 \\(\\bm{x}\\) ，而 \\(\\bm{x}^{\\top}\\) 则表示行向量。\n下表给出本书用到的一些统计术语的英文缩写。\n\n\n\n表格 A.2: 统计术语的英文缩写\n\n\n\n\n\n统计术语\n英文缩写\n\n\n\n\n最小二乘估计\nLSE\n\n\n极大似然估计\nMLE\n\n\n最佳线性无偏估计\nBLUE\n\n\n最小方差无偏估计\nMVUE\n\n\n一致最小方差无偏估计\nUMVUE\n\n\n最小范数二次无偏估计\nMINQUE\n\n\n普通最小二乘估计\nOLS\n\n\n偏最小二乘估计\nPLS\n\n\n广义最小二乘估计\nGLS\n\n\n带权最小二乘估计\nWLS\n\n\nLasso 估计\nLASSO\n\n\n均方误差\nMSE\n\n\n均方根误差\nRMSE\n\n\n平均绝对误差\nMAE\n\n\n惩罚拟似然\nPQL\n\n\n剖面极大似然\nPML\n\n\n限制极大似然\nREML\n\n\n线性模型\nLM\n\n\n广义线性模型\nGLM\n\n\n广义可加模型\nGAM\n\n\n线性混合效应模型\nLMM\n\n\n广义线性混合效应模型\nGLMM\n\n\n广义可加混合效应模型\nGAMM",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>数学符号</span>"
    ]
  },
  {
    "objectID": "matrix-operations.html",
    "href": "matrix-operations.html",
    "title": "附录 B — 矩阵运算",
    "section": "",
    "text": "B.1 基础运算\n约定符号\n\\[\nA = \\begin{bmatrix}\na_{11} & a_{12}  & a_{13} \\\\\na_{21} & a_{22}  & a_{23} \\\\\na_{31} & a_{32}  & a_{33}\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>矩阵运算</span>"
    ]
  },
  {
    "objectID": "matrix-operations.html#sec-basic-matrix-operations",
    "href": "matrix-operations.html#sec-basic-matrix-operations",
    "title": "附录 B — 矩阵运算",
    "section": "",
    "text": "B.1.1 加、减、乘\n矩阵 \\(A\\)\n\nA &lt;- matrix(c(1, 1.2, 1.2, 3), nrow = 2)\nA\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\nB &lt;- matrix(c(1, 2, 3, 4), nrow =2)\nB\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\n\nA + A # 对应元素相加\n\n     [,1] [,2]\n[1,]  2.0  2.4\n[2,]  2.4  6.0\n\nA - A # 对应元素相减\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    0    0\n\nA %*% A # 矩阵乘法\n\n     [,1]  [,2]\n[1,] 2.44  4.80\n[2,] 4.80 10.44\n\n\n\nB.1.2 对数、指数与幂\n矩阵 \\(A\\) 的对数 \\(\\log A\\) ，就是找一个矩阵 \\(L\\) 使得 \\(A = \\mathrm{e}^L\\)\n\nexpm::logm(A)\n\n           [,1]      [,2]\n[1,] -0.4485660 0.8050907\n[2,]  0.8050907 0.8932519\n\n\n矩阵 \\(A\\) 的指数 \\(\\mathrm{e}^{A}\\) 的定义\n\\[\n\\mathrm{e}^{A} = \\sum_{k=1}^{\\infty}\\frac{A^k}{k!}\n\\]\nexpm 包可以计算矩阵的指数、开方、对数等。\n\nexpm::expm(A)\n\n         [,1]     [,2]\n[1,]  7.60987 12.93908\n[2,] 12.93908 29.17501\n\n\n或者使用奇异值分解 \\(A = UDV^{\\top}\\) ，则 \\(\\mathrm{e}^A = U\\mathrm{e}^DV^{\\top}\\) ，其中，D 是对角矩阵。\n\n(res &lt;- svd(A))\n\n$d\n[1] 3.5620499 0.4379501\n\n$u\n           [,1]       [,2]\n[1,] -0.4241554 -0.9055894\n[2,] -0.9055894  0.4241554\n\n$v\n           [,1]       [,2]\n[1,] -0.4241554 -0.9055894\n[2,] -0.9055894  0.4241554\n\nres$u %*% diag(exp(res$d)) %*% res$v\n\n         [,1]     [,2]\n[1,]  7.60987 12.93908\n[2,] 12.93908 29.17501\n\n\n矩阵 \\(A\\) 的 \\(n\\) 次幂 \\(A^n\\) ，利用奇异值分解 \\(A = UDV^{\\top}\\)\n\\[\n\\begin{aligned}\nA^n &= A \\times A \\times \\cdots \\times A \\\\\n& = UDV^{\\top} UDV^{\\top} \\cdots UDV^{\\top}\n\\end{aligned}\n\\]\n计算 \\(A^3\\)\n\nres$u %*% (diag(res$d)^3) %*% res$v\n\n       [,1]   [,2]\n[1,]  8.200 17.328\n[2,] 17.328 37.080\n\n\n\nB.1.3 迹、秩、条件数\n矩阵 \\(A\\) 的迹 \\(\\operatorname{tr}(A) = \\sum_{i=1}^{n}a_{ii}\\)\n\nsum(diag(A))\n\n[1] 4\n\nqr(A)$rank\n\n[1] 2\n\nkappa(A)\n\n[1] 10.41469\n\n\n\nB.1.4 求逆与广义逆\nMoore-Penrose Generalized Inverse 摩尔广义逆 \\(A^-\\)。\n\\[\nA^- = (A^{\\top}A)^{-1}A\n\\]\n如果 A 可逆，则广义逆就是逆。\n\nsolve(A) # 逆\n\n           [,1]       [,2]\n[1,]  1.9230769 -0.7692308\n[2,] -0.7692308  0.6410256\n\nMASS::ginv(A) # 广义逆\n\n           [,1]       [,2]\n[1,]  1.9230769 -0.7692308\n[2,] -0.7692308  0.6410256\n\n\n\nB.1.5 行列式与伴随\n矩阵必须是方阵\n伴随矩阵 \\(A*A^{\\star} = A^{\\star} *A = |A|*I, A^{\\star} = |A|*A^{-1}\\)\n\n\\(|A^{\\star}| = |A|^{n-1}, A \\in \\mathbb{R}^{n\\times n},n \\geq 2\\)\n\\((A^{\\star})^{\\star} = |A|^{n-2}A, A \\in \\mathbb{R}^{n\\times n},n \\geq 2\\)\n\n\\((A^{\\star})^{\\star}\\) A 的 n 次伴随是？\n\n\ndet(A)\n\n[1] 1.56\n\ndet(A) * solve(A)\n\n     [,1] [,2]\n[1,]  3.0 -1.2\n[2,] -1.2  1.0\n\n\n\nB.1.6 外积、直积与交叉积\n通常的矩阵乘法也叫矩阵内积\n\nA %*% B\n\n     [,1] [,2]\n[1,]  3.4  7.8\n[2,]  7.2 15.6\n\n\n外积\n\nA %o% B # outer(A, B, FUN = \"*\")\n\n, , 1, 1\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\n, , 2, 1\n\n     [,1] [,2]\n[1,]  2.0  2.4\n[2,]  2.4  6.0\n\n, , 1, 2\n\n     [,1] [,2]\n[1,]  3.0  3.6\n[2,]  3.6  9.0\n\n, , 2, 2\n\n     [,1] [,2]\n[1,]  4.0  4.8\n[2,]  4.8 12.0\n\n\n直积/克罗内克积\n\nA %x% B # kronecker(A, B, FUN = \"*\")\n\n     [,1] [,2] [,3] [,4]\n[1,]  1.0  3.0  1.2  3.6\n[2,]  2.0  4.0  2.4  4.8\n[3,]  1.2  3.6  3.0  9.0\n[4,]  2.4  4.8  6.0 12.0\n\n\n交叉积 \\(A^{\\top}A\\)\n\ncrossprod(A, A)  #  t(x) %*% y\n\n     [,1]  [,2]\n[1,] 2.44  4.80\n[2,] 4.80 10.44\n\ntcrossprod(A, A) #  x %*% t(y)\n\n     [,1]  [,2]\n[1,] 2.44  4.80\n[2,] 4.80 10.44\n\n\n\nB.1.7 Hadamard 积\nHadamard 积（法国数学家 Jacques Hadamard）也叫 Schur 积（德国数学家 Issai Schur ）或 entrywise 积是两个维数相同的矩阵对应元素相乘，特别地，\\(A^2\\) 表示将矩阵 \\(A\\) 的每个元素平方\n\\[\n(A\\circ B)_{ij} = (A)_{ij}(B)_{ij}\n\\]\n\\[\n\\begin{bmatrix}\na_{11} & a_{12}  & a_{13} \\\\\na_{21} & a_{22}  & a_{23} \\\\\na_{31} & a_{32}  & a_{33}\n\\end{bmatrix}\n\\circ\n\\begin{bmatrix}\nb_{11} & b_{12}  & b_{13} \\\\\nb_{21} & b_{22}  & b_{23} \\\\\nb_{31} & b_{32}  & b_{33}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na_{11}b_{11} & a_{12}b_{12}  & a_{13}b_{13} \\\\\na_{21}b_{21} & a_{22}b_{22}  & a_{23}b_{23} \\\\\na_{31}b_{31} & a_{32}b_{32}  & a_{33}b_{33}\n\\end{bmatrix}\n\\]\n\nfastmatrix::hadamard(A, B)\n\n     [,1] [,2]\n[1,]  1.0  3.6\n[2,]  2.4 12.0\n\n\n\nA^2     # 每个元素平方 a_ij ^ 2\n\n     [,1] [,2]\n[1,] 1.00 1.44\n[2,] 1.44 9.00\n\nA ** A  # 每个元素的幂 a_ij ^ a_ij\n\n         [,1]      [,2]\n[1,] 1.000000  1.244565\n[2,] 1.244565 27.000000\n\n2^A     # 每个元素的指数 2 ^ a_ij\n\n         [,1]     [,2]\n[1,] 2.000000 2.297397\n[2,] 2.297397 8.000000\n\nexp(A)  # 每个元素的指数 exp(a_ij)\n\n         [,1]      [,2]\n[1,] 2.718282  3.320117\n[2,] 3.320117 20.085537\n\n\n\nB.1.8 矩阵范数\n矩阵的范数，包括 1，2，无穷范数\n\n\n\\(1\\)-范数\n\n列和绝对值最大的\n\n\n\\(2\\) - 范数\n\n又称谱范数，矩阵最大的奇异值，如果是方阵，就是最大的特征值\n\n\n\\(\\infty\\) - 范数\n\n行和绝对值最大的\n\nFrobenius - 范数\n\nEuclidean 范数\n\n\n\\(M\\) - 范数\n\n矩阵里模最大的元素，矩阵里面的元素可能含有复数，所以取模最大\n\n\n\nnorm(A, type = \"1\") # max(abs(colSums(A)))\n\n[1] 4.2\n\nnorm(A, type = \"I\") # max(abs(rowSums(A)))\n\n[1] 4.2\n\nnorm(A, type = \"F\")\n\n[1] 3.588872\n\nnorm(A, type = \"M\") #\n\n[1] 3\n\nnorm(A, type = \"2\") # max(svd(A)$d)\n\n[1] 3.56205\n\n\n\nB.1.9 转置与旋转\n矩阵 \\(A\\)\n\nt(A) # 转置\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\n\n\nB.1.10 正交与投影\n矩阵 \\(A\\) 的投影\n\\[\nI - A(A^{\\top}A)^{-1}A^{\\top}\n\\]\n\ndiag(rep(1, 2)) - A %*% solve(t(A) %*% A) %*% t(A)\n\n              [,1]          [,2]\n[1,] -4.440892e-16  4.440892e-16\n[2,]  3.330669e-16 -2.220446e-16\n\n\n\nB.1.11 Givens 变换(*)\n\nGivens 旋转\n帽子矩阵在统计中的应用，回归与方差分析 (Hoaglin 和 Welsch 1978)\n\n\nB.1.12 Householder 变换(*)\nHouseholder 变换是平面反射的一般情况： 要计算 \\(N\\times P\\) 维矩阵 \\(X\\) 的 QR 分解，我们采用 Householder 变换\n\\[\n\\mathbf{H}_{u} = \\mathbf{I} -2\\mathbf{u}\\mathbf{u}^{\\top}\n\\]\n其中 \\(I\\) 是 \\(N\\times N\\) 维的单位矩阵，\\(u\\) 是 \\(N\\) 维单位向量，即 \\(\\| \\mathbf{u}\\| = \\sqrt{\\mathbf{u}\\mathbf{u}^{\\top}} = 1\\)。则 \\(H_u\\) 是对称正交的，因为\n\\[\n\\mathbf{H}_{u}^{\\top} = \\mathbf{I}^{\\top} - 2\\mathbf{u}\\mathbf{u}^{\\top} = \\mathbf{H}_{u}\n\\]\n并且\n\\[\n\\mathbf{H}_{u}^{\\top}\\mathbf{H}_{u} =  \\mathbf{I} -4\\mathbf{u}\\mathbf{u}^{\\top} + 4\\mathbf{u}\\mathbf{u}^{\\top}\\mathbf{u}\\mathbf{u}^{\\top} = \\mathbf{I}\n\\]\n让 \\(\\mathbf{H}_{u}\\) 乘以向量 \\(\\mathbf{y}\\)，即\n\\[\n\\mathbf{H}_{u}\\mathbf{y} = \\mathbf{y} - 2\\mathbf{u}\\mathbf{u}^{\\top}\\mathbf{y}\n\\]\n它是 \\(y\\) 关于垂直于过原点的 \\(u\\) 的直线的反射，只要\n\\[\n\\begin{aligned}\n\\mathbf{u} = \\frac{\\mathbf{y} - \\| \\mathbf{y} \\|\\mathbf{e}_{1}}{\\| \\mathbf{y} - \\| \\mathbf{y} \\|\\mathbf{e}_{1}\\|}\n\\end{aligned}\n\\tag{B.1}\\]\n或者\n\\[\n\\begin{aligned}\n\\mathbf{u} = \\frac{\\mathbf{y} + \\| \\mathbf{y} \\|\\mathbf{e}_{1}}{\\| \\mathbf{y} + \\| \\mathbf{y} \\|\\mathbf{e}_{1}\\|}\n\\end{aligned}\n\\tag{B.2}\\]\n其中 \\(\\mathbf{e}_{1} = (1,0,\\ldots,0)^{\\top}\\)，Householder 变换使得向量 \\(y\\) 成为 \\(x\\) 轴，在新的坐标系统中，向量 \\(H_{u}y\\) 的坐标为 \\((\\pm\\|y\\|, 0, \\ldots, 0)^\\top\\)\n举个例子\n借助 Householder 变换做 QR 分解的优势：\n\n更快、数值更稳定比直接构造 Q，特别当 N 大于 P 的时候\n相比于存储矩阵 Q 的 \\(N^2\\) 个元素，Householder 变换只存储 P 个向量 \\(u_1,\\ldots,u_P\\)\n\nQR 分解的真实实现，比如在 LINPACK 中，定义 \\(u\\) 的时候， 方程式 B.1 或 方程式 B.2 的选择基于 \\(y\\) 的第一个坐标的符号。如果坐标是负的，使用 方程式 B.1 ，如果是正的，使用 方程式 B.2 ， 这个做法可以使得数值计算更加稳定。\n\n用 Householder 变换做 QR 分解 (Bates 和 Watts 1988) 及其 R 语言、Eigen 实现。\n\nB.1.13 单位矩阵\n矩阵对角线上全是1，其余位置都是0\n\\[\nA = \\begin{bmatrix}\n1 & 0  & 0 \\\\\n0 & 1  & 0 \\\\\n0 & 0  & 1\n\\end{bmatrix}\n\\]\n\ndiag(rep(3))\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\n\n而全1矩阵是所有元素都是1的矩阵，可以借助外积运算构造，如3阶全1矩阵\n\nrep(1,3) %o% rep(1,3) \n\n     [,1] [,2] [,3]\n[1,]    1    1    1\n[2,]    1    1    1\n[3,]    1    1    1\n\n\n\nB.1.14 对角矩阵\n\ndiag(A)       # 矩阵的对角\n\n[1] 1 3\n\ndiag(x = c(1, 2, 3)) # 构造对角矩阵\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    2    0\n[3,]    0    0    3\n\n\n\nB.1.15 稀疏矩阵\n稀疏矩阵的典型构造方式是通过三元组。\n\ni &lt;- c(1, 3:8) # 行指标\nj &lt;- c(2, 9, 6:10) # 列指标\nx &lt;- 7 * (1:7) # 数据\nMatrix::sparseMatrix(i, j, x = x)\n\n8 x 10 sparse Matrix of class \"dgCMatrix\"\n                             \n[1,] . 7 . . .  .  .  .  .  .\n[2,] . . . . .  .  .  .  .  .\n[3,] . . . . .  .  .  . 14  .\n[4,] . . . . . 21  .  .  .  .\n[5,] . . . . .  . 28  .  .  .\n[6,] . . . . .  .  . 35  .  .\n[7,] . . . . .  .  .  . 42  .\n[8,] . . . . .  .  .  .  . 49\n\n\n\nB.1.16 上、下三角矩阵\n\nm &lt;- A\nm\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\nupper.tri(m) # 矩阵上三角\n\n      [,1]  [,2]\n[1,] FALSE  TRUE\n[2,] FALSE FALSE\n\nm[upper.tri(m)]\n\n[1] 1.2\n\nm[lower.tri(m)] &lt;- 0 # 获得上三角矩阵\nm\n\n     [,1] [,2]\n[1,]    1  1.2\n[2,]    0  3.0\n\n\n矩阵 A 的下三角矩阵\n\nm &lt;- matrix(c(1, 2, 2, 3), nrow = 2)\nm[row(m) &lt; col(m)] &lt;- 0\nm\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    2    3",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>矩阵运算</span>"
    ]
  },
  {
    "objectID": "matrix-operations.html#sec-matrix-decomposition",
    "href": "matrix-operations.html#sec-matrix-decomposition",
    "title": "附录 B — 矩阵运算",
    "section": "\nB.2 矩阵分解",
    "text": "B.2 矩阵分解\n\nB.2.1 LU 分解\n矩阵 \\(A\\) 的 LU 分解 \\(A = LU\\) ， \\(L\\) 是下三角矩阵，\\(U\\) 是上三角矩阵\n\nMatrix::lu(A)\n\nLU factorization of Formal class 'denseLU' [package \"Matrix\"] with 4 slots\n  ..@ x       : num [1:4] 1.2 0.833 3 -1.3\n  ..@ perm    : int [1:2] 2 2\n  ..@ Dim     : int [1:2] 2 2\n  ..@ Dimnames:List of 2\n  .. ..$ : NULL\n  .. ..$ : NULL\n\n\n\nB.2.2 Schur 分解\n矩阵 \\(A\\) 的 Schur 分解 \\(A = QTQ^{\\top}\\)\n\n(res &lt;- Matrix::Schur(A))\n\n$Q\n           [,1]       [,2]\n[1,] -0.9055894 -0.4241554\n[2,]  0.4241554 -0.9055894\n\n$T\n          [,1]    [,2]\n[1,] 0.4379501 0.00000\n[2,] 0.0000000 3.56205\n\n$EValues\n[1] 0.4379501 3.5620499\n\n\n其中 \\(Q\\) 是一个正交矩阵 \\(QQ = I\\) ，\\(T\\) 是一个分块上三角矩阵\n\nres$Q %*% t(res$Q)\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n\n\nres$Q %*% res$T %*% t(res$Q)\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\n\n\nB.2.3 QR 分解\n矩阵 \\(A\\) 的 QR 分解 \\(A = QR\\)\n\n(res &lt;- qr(A))\n\n$qr\n           [,1]       [,2]\n[1,] -1.5620499 -3.0728851\n[2,]  0.7682213  0.9986877\n\n$rank\n[1] 2\n\n$qraux\n[1] 1.6401844 0.9986877\n\n$pivot\n[1] 1 2\n\nattr(,\"class\")\n[1] \"qr\"\n\n\nQR 分解结果中的 Q\n\nqr.Q(res)\n\n           [,1]       [,2]\n[1,] -0.6401844 -0.7682213\n[2,] -0.7682213  0.6401844\n\n\nQR 分解结果中的 R\n\nqr.R(res)\n\n         [,1]       [,2]\n[1,] -1.56205 -3.0728851\n[2,]  0.00000  0.9986877\n\n\n恢复矩阵 \\(A\\)\n\nqr.Q(res) %*% qr.R(res)\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\n\n\nB.2.4 Cholesky 分解\n矩阵 \\(A\\) 的 Cholesky 分解 \\(A = L^{\\top}L\\) ，其中 \\(L\\) 是上三角矩阵\n\n(res &lt;- chol(A))\n\n     [,1]  [,2]\n[1,]    1 1.200\n[2,]    0 1.249\n\n\n\nt(res) %*% res\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\n\n\nB.2.5 特征值分解\n特征值分解（Eigenvalues Decomposition）也叫谱分解（Spectral Decomposition）\n矩阵 \\(A\\) 的特征值分解 \\(A = V\\Lambda V^{-1}\\)\n\n(res &lt;- eigen(A))\n\neigen() decomposition\n$values\n[1] 3.5620499 0.4379501\n\n$vectors\n          [,1]       [,2]\n[1,] 0.4241554 -0.9055894\n[2,] 0.9055894  0.4241554\n\n\n返回值列表中的元素 vectors 就是 \\(V\\)\n\nres$vectors %*% diag(res$values) %*% solve(res$vectors)\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\n\n计算特征值，即求解如下一元 \\(n\\) 次方程\n\\(|A - \\lambda I| = 0\\)\n\nrootSolve::uniroot.all(\n  f = function(x) (x - 1) * (x - 3) - 1.2^2,\n  lower = -10, upper = 10\n)\n\n[1] 0.4379747 3.5620253\n\n\n\nB.2.6 SVD 分解\n矩阵 \\(A\\) 的 SVD 分解 \\(A = UDV^{\\top}\\) ，矩阵 U 和 V 是正交的，矩阵 D 是对角的，矩阵 D 的对角元素是按降序排列的奇异值。\n当矩阵是对称矩阵时，SVD 分解和特征值分解结果是一样的。\n\n(res &lt;- svd(A))\n\n$d\n[1] 3.5620499 0.4379501\n\n$u\n           [,1]       [,2]\n[1,] -0.4241554 -0.9055894\n[2,] -0.9055894  0.4241554\n\n$v\n           [,1]       [,2]\n[1,] -0.4241554 -0.9055894\n[2,] -0.9055894  0.4241554\n\n\n\n# A = U D V'\nres$u %*% diag(res$d) %*% t(res$v)\n\n     [,1] [,2]\n[1,]  1.0  1.2\n[2,]  1.2  3.0\n\n# D = U'AV\nt(res$u) %*% A %*% res$v\n\n              [,1]          [,2]\n[1,]  3.562050e+00 -2.220446e-16\n[2,] -5.551115e-17  4.379501e-01\n\n# I = VV'\nres$v %*% t(res$v)\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n# I = UU'\nres$u %*% t(res$u)\n\n              [,1]          [,2]\n[1,]  1.000000e+00 -5.551115e-17\n[2,] -5.551115e-17  1.000000e+00",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>矩阵运算</span>"
    ]
  },
  {
    "objectID": "matrix-operations.html#sec-eigen-library",
    "href": "matrix-operations.html#sec-eigen-library",
    "title": "附录 B — 矩阵运算",
    "section": "\nB.3 Eigen 库",
    "text": "B.3 Eigen 库\nEigen 是一个高性能的线性代数计算库，基于 C++ 编写，有 R 语言接口 RcppEigen 包。示例来自 RcppEigen 包，本文增加了特征向量，下面介绍如何借助 RcppEigen 包调用 Eigen 库做 SVD 矩阵分解。\n#include &lt;RcppEigen.h&gt;\n\n// [[Rcpp::depends(RcppEigen)]]\n\nusing Eigen::Map;                       // 'maps' rather than copies\nusing Eigen::MatrixXd;                  // variable size matrix, double precision\nusing Eigen::VectorXd;                  // variable size vector, double precision\nusing Eigen::SelfAdjointEigenSolver;    // one of the eigenvalue solvers\n\n// [[Rcpp::export]]\nVectorXd getEigenValues(Map&lt;MatrixXd&gt; M) {\n  SelfAdjointEigenSolver&lt;MatrixXd&gt; es(M);\n  return es.eigenvalues();\n}\n// [[Rcpp::export]]\nMatrixXd getEigenVectors(Map&lt;MatrixXd&gt; M) {\n  SelfAdjointEigenSolver&lt;MatrixXd&gt; es(M);\n  return es.eigenvectors();\n}\n对上面的代码做几点说明：\n\n\n// [[Rcpp::depends(RcppEigen)]] 可以看作一种标记，表示依赖 RcppEigen 包提供的 C++ 头文件，并导入到 C++ 命名空间中。// [[Rcpp::export]] 也可以看作一种标记，表示下面的函数需要导出到 R 语言环境中，这样 C++ 中定义的函数可以在 R 语言环境中使用。\n\nMatrixXd 和 VectorXd 分别是 Eigen 库中定义的可变大小的双精度矩阵、向量类型。\n\nSelfAdjointEigenSolver 是 Eigen 库中关于特征值分解方法中的一个求解器，特征值分解的结果有两个部分：一个是由特征值构成的向量，一个是特征向量构成的矩阵。求解器 SelfAdjointEigenSolver 名称中 SelfAdjoint 是伴随的意思，它是做矩阵 \\(A\\) 的伴随矩阵 \\(A^{\\star}\\) 的特征值分解。\n\ngetEigenValues 和 getEigenVectors 是用户自定义的两个函数名称，分别计算特征值和特征向量。\n\n伴随矩阵的特征值分解和原矩阵的特征值分解有何关系？为什么不直接求原矩阵的特征值分解呢？\n\n伴随矩阵的特征值与原矩阵是一样的。\n伴随矩阵的特征向量有一个符号差异。\n\nRcppEigen 包封装了 Eigen 库，它在 RcppEigen 包的源码路径为\nRcppEigen/inst/include/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h\n在 Eigen 库的源码路径如下：\nEigen/src/Eigenvalues/SelfAdjointEigenSolver.h 。\n如何使用 RcppEigen 包加速计算？还是要看 Eigen 库的文档和源码，通过阅读源码，可以知道有哪些求解器，比如名称 SelfAdjointEigenSolver ，以及求解器包含的方法，比如 eigenvalues() 和 eigenvectors()，还有参数和返回值类型等。以特征值分解器 SelfAdjointEigenSolver 为例，编译上面的 C++ 代码，获得在 R 语言环境中可直接使用的函数 getEigenValues() 。\n\n# 编译代码\nRcpp::sourceCpp(file = \"code/rcpp_eigen.cpp\")\n\n然后，函数 getEigenValues() 计算特征值，返回一个向量。\n\n# 计算特征值\ngetEigenValues(A)\n\n[1] 0.4379501 3.5620499\n\n\n返回一个矩阵，列是特征向量。\n\n# 计算特征向量\ngetEigenVectors(A)\n\n           [,1]       [,2]\n[1,] -0.9055894 -0.4241554\n[2,]  0.4241554 -0.9055894\n\n\n根据上述分解结果计算矩阵 A 的伴随矩阵 \\(A^{\\star}\\) 。\n\nt(getEigenVectors(A)) %*% diag(getEigenValues(A)) %*% getEigenVectors(A)\n\n     [,1] [,2]\n[1,]  1.0 -1.2\n[2,] -1.2  3.0",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>矩阵运算</span>"
    ]
  },
  {
    "objectID": "matrix-operations.html#sec-matrix-linear-regression",
    "href": "matrix-operations.html#sec-matrix-linear-regression",
    "title": "附录 B — 矩阵运算",
    "section": "\nB.4 应用",
    "text": "B.4 应用\n以线性模型为例讲述一些初步的计算性能提升办法。回顾一下线性回归的矩阵表示。\n\\[\n\\begin{aligned}\n&\\boldsymbol{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\\\\n&\\boldsymbol{\\epsilon} \\sim \\mathrm{MVN}(\\boldsymbol{0}, \\sigma^2I)\n\\end{aligned}\n\\]\n模型中 \\(\\boldsymbol{\\beta}, \\sigma^2\\) 是待估的参数，它们的最小二乘估计分别记为 \\(\\hat{\\boldsymbol{\\beta}},\\hat{\\sigma^2}\\) 。\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{\\beta}} &= (X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y} \\\\\n\\hat{\\sigma^2} &= \\frac{\\boldsymbol{y}^{\\top}(I - X(X^{\\top}X)^{-1}X^{\\top})\\boldsymbol{y}}{n - \\mathrm{rank}(X)}\n\\end{aligned}\n\\]\n在获得参数的估计后，响应变量 \\(\\boldsymbol{y}\\) 的预测 \\(\\hat{\\boldsymbol{y}}\\) 及其预测方差 \\(\\mathsf{Var}(\\hat{\\boldsymbol{y}})\\) 如下。\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{y}} &= X(X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y} \\\\\n\\mathsf{Var}(\\hat{\\boldsymbol{y}}) & = \\sigma^2 X(X^{\\top}X)^{-1}X^{\\top}\n\\end{aligned}\n\\]\n\nset.seed(2023)\nn &lt;- 200\np &lt;- 50\nx &lt;- matrix(rnorm(n * p), n)\ny &lt;- rnorm(n)\nfit_lm &lt;- lm(y ~ x + 0)\n\n下面不同的方法来计算预测值 \\(\\hat{\\boldsymbol{y}}\\) ，从慢到快地优化。教科书版就是从左至右依次计算。\n\nfit_base = function(x, y) {\n  x %*% solve(t(x) %*% x) %*% t(x) %*% y\n}\n\n矩阵乘向量比矩阵乘矩阵快。虽然矩阵乘法没有交换律，但是有结合律。先向量计算，然后矩阵计算。\n\\[\n\\hat{\\boldsymbol{y}} = X(X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y}\n\\]\n\nfit_vector &lt;- function(x, y) {\n  x %*% (solve(t(x) %*% x) %*% (t(x) %*% y))\n}\n\n解线性方程组比求逆快。 \\(X^{\\top}X\\) 是对称的，通过解线性方程组来避免求逆。\n\\[\n\\hat{\\boldsymbol{y}} = X(X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y}\n\\]\n\nfit_inv &lt;- function(x, y) {\n  x %*% solve(crossprod(x), crossprod(x, y))\n}\n\nQR 分解。 \\(X_{n\\times p} = Q_{n\\times p} R_{p\\times p}\\)，\\(n &gt; p\\)，\\(Q^{\\top}Q = I\\)，\\(R\\) 是上三角矩阵。\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{y}} &= X(X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y} \\\\\n& = QR \\big((QR)^{\\top}QR\\big)^{-1}(QR)^{\\top}\\boldsymbol{y} \\\\\n& = QR(R^{\\top}R)^{-1}R^{\\top}Q^{\\top}\\boldsymbol{y} \\\\\n& = QQ^{\\top}\\boldsymbol{y}\n\\end{aligned}\n\\]\n\nfit_qr &lt;- function(x, y) {\n  decomp &lt;- qr(x)\n  qr.qy(decomp, qr.qty(decomp, y))\n}\nfit_qr2 &lt;- lm.fit(x, y)\n\n其中，函数 qr.qy(decomp, y) 表示 Q %*% y ，函数 qr.qty(decomp, y) 表示 t(Q) %*% y 。实际上，Base R 提供的线性回归拟合函数 lm() 就采用 QR 分解。\nCholesky 分解。记 \\(A = X^{\\top}X\\) ，若 \\(A\\) 是正定矩阵，则 \\(A\\) 可做 Cholesky 分解。不妨设\\(A = L^{\\top}L\\)，其中 \\(L\\) 是上三角矩阵。\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{y}} &= X(X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y} \\\\\n& = X\\big(L^{\\top}L\\big)^{-1}X^{\\top}\\boldsymbol{y} \\\\\n& = XL^{-1}(L^{\\top})^{-1}X^{\\top}\\boldsymbol{y}\n\\end{aligned}\n\\]\n\nfit_chol &lt;- function(x, y) {\n  decomp &lt;- chol(crossprod(x))\n  lxy &lt;- backsolve(decomp, crossprod(x, y), transpose = TRUE)\n  b &lt;- backsolve(decomp, lxy)\n  x %*% b\n}\n\n函数 backsolve() 求解上三角线性方程组。\n\n\n\n\nBates, Douglas M., 和 Donald G. Watts. 1988. Nonlinear Regression Analysis and Its Applications. New York, NY: John Wiley & Sons. https://doi.org/10.1002/9780470316757.app2.\n\n\nHoaglin, David C., 和 Roy E. Welsch. 1978. 《The Hat Matrix in Regression and ANOVA》. The American Statistician 32 (1): 17–22. https://www.jstor.org/stable/2683469.",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>矩阵运算</span>"
    ]
  },
  {
    "objectID": "matrix-operations.html#footnotes",
    "href": "matrix-operations.html#footnotes",
    "title": "附录 B — 矩阵运算",
    "section": "",
    "text": "https://stat.ethz.ch/pipermail/r-help/2006-March/101596.html↩︎",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>矩阵运算</span>"
    ]
  },
  {
    "objectID": "git-github.html",
    "href": "git-github.html",
    "title": "附录 C — Git 和 Github",
    "section": "",
    "text": "C.1 安装配置",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-setup",
    "href": "git-github.html#sec-setup",
    "title": "附录 C — Git 和 Github",
    "section": "",
    "text": "C.1.1 创建账户\n登陆 Github 官网 (https://github.com/)，点击左上角注册按钮，开始注册 Github 账户。\n\n\n\n\n\n\n图 C.1: 点击注册\n\n\n\n接着，输入注册用的邮箱地址，比如 Outlook 和 Gmail 等。\n\n\n\n\n\n\n图 C.2: 输入邮箱\n\n\n\n除了邮箱外，继续输入密码、用户名等，密码可以选用浏览器自动生成的复杂字符串，只要没有被别人占用，用户名可以按着自己的喜好填写。\n\n\n\n\n\n\n图 C.3: 输入用户名\n\n\n\n接着，系统要验证来注册 Github 账户的人是否是真人。\n\n\n\n\n\n\n图 C.4: 回答问题\n\n\n\n正确回答界面上出现的问题后，进入下一步，系统会给你之前提供的邮箱发送一个验证码。\n\n\n\n\n\n\n图 C.5: 输入验证码\n\n\n\n将收到的验证码输入进去，完成账户验证。\n\n\n\n\n\n\n图 C.6: 验证账户\n\n\n\n创建账户后，将自动进入如下界面，接下来，可以创建代码仓库了。\n\n\n\n\n\n\n图 C.7: 创建代码仓库\n\n\n\n\n\nC.1.2 安装 Git\n在 MacOS 系统上，系统自带 Git 工具，无需安装。在 Ubuntu 系统上，安装最新稳定版的命令如下：\nsudo add-apt-repository -y ppa:git-core/ppa\nsudo apt update && sudo apt install git\n在 Windows 系统上，安装最新稳定版的命令如下：\nwinget install --id Git.Git -e --source winget\n\n\nC.1.3 配置密钥\n在配置 GitHub 账户和安装完 Git 客户端后，接着配置密钥，以便将本地的代码推送到远程 Github 账户下的代码仓库。\ngit config --global user.name \"用户名\"\ngit config --global user.email \"邮箱地址\"\n\n\nC.1.4 (*) 账户共存\n在公司往往会有自己的一套代码管理系统，比如 Gitlab 或者某种类似 Gitlab 的工具。本节介绍如何使 Gitlab / Github 账户共存在一台机器上。\n如何生成 SSH 密钥见 Github 文档 — 使用 SSH 连接到 GitHub。有了密钥之后只需在目录 ~/.ssh 下创建一个配置文件 config。\nGithub 对应个人的私有邮箱，Gitlab 对应公司分配的个人邮箱。\n生成 SSH Key\nssh-keygen -t rsa -f ~/.ssh/id_rsa_github -C \"个人邮箱地址\"\nssh-keygen -t rsa -f ~/.ssh/id_rsa_gitlab -C \"公司邮箱地址\"\n将 GitHub/GitLab 公钥分别上传至服务器，然后创建配置文件\ntouch ~/.ssh/config\n配置文件内容如下\n#\n# Github\n#\nHost github.com // Github 代码仓库的服务器地址\nHostName github.com\nUser XiangyunHuang\nIdentityFile ~/.ssh/id_rsa_github\n\n#\n# company\n#\nHost xx.xx.xx.xx // 公司代码仓库的服务器地址\nIdentityFile ~/.ssh/id_rsa_gitlab\n配置成功，你会看到\nssh -T git@xx.xx.xx.xx\nWelcome to GitLab, xiangyunhuang!\n和\nssh -T git@github.com\nHi XiangyunHuang! You've successfully authenticated, but GitHub does not provide shell access.",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-basic-git-operations",
    "href": "git-github.html#sec-basic-git-operations",
    "title": "附录 C — Git 和 Github",
    "section": "C.2 基本操作",
    "text": "C.2 基本操作\n\nC.2.1 初始化仓库\ngit init\n\n\nC.2.2 添加文件\ngit add\n追踪当前目录下的内容\ngit add .\n追踪被修改(modified)文件，不包括新添加的文件和被删除(deleted)的文件，-u 是 --update 的缩写\ngit add -u\n添加所有文件，-A 是 --all 的缩写\ngit add -A\n\n\nC.2.3 记录修改\ngit commit\ngit commit -m \"添加提交说明\"\n\n\nC.2.4 推送修改\ngit push\ngit push -u origin master\n\n\nC.2.5 克隆项目\n克隆项目 git clone\ngit clone git@github.com:XiangyunHuang/data-analysis-in-action.git\n有的项目包含子模块，添加选项 --recursive 可以将子模块也克隆下来。\ngit clone --recursive git@github.com:cosname/cosx.org.git",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-pr-operations",
    "href": "git-github.html#sec-pr-operations",
    "title": "附录 C — Git 和 Github",
    "section": "C.3 分支操作",
    "text": "C.3 分支操作\n对每一个新的问题，创建新的分支，提交新的 PR。\n与人协作开发代码项目，往往涉及 Git 分支操作。通常有两个场景，其一是独立地在分支上进行开发，包含创建分支、修改分支、提交分支、合并分支和删除分支。其二是与人合作互相评审代码修改分支，除了之前的基础操作，还包含在分支上解决代码冲突，同步分支内容。\n\n\n\n\n\n\nflowchart LR\n  A[创建分支] --&gt; B[修改分支]\n  B --&gt; C[提交分支]\n  C --&gt; D[合并分支]\n  D --&gt; E[删除分支]\n\n\n\n\n图 C.8: Git 分支操作\n\n\n\n\n\n\nC.3.1 创建分支\ngit checkout -b 分支名称\n\n\nC.3.2 分支切换\ngit checkout 分支名称\n\n\nC.3.3 修改 PR\n# 拉取合作者的 PR\ngit fetch origin refs/pull/771/head:patch-2\n# 771 是 PR 对应的编号\ngit checkout patch-2\n\n# 你的修改\n\ngit add -u # 追踪修改的内容\ngit commit -m \"描述修改内容\"\n\ngit remote add LalZzy https://github.com/LalZzy/cosx.org.git\ngit push --set-upstream LalZzy patch-2\n\n\nC.3.4 (*) 创建 gh-pages 分支\n基于 GitHub Pages 创建站点用于存放图片和数据。\n\n在 Github 上创建一个空的仓库，命名为 uploads。\n在本地创建目录 uploads。\n切换到 uploads 目录下，执行如下命令。\n\ngit init \ngit checkout -b gh-pages\ngit remote add origin https://github.com/XiangyunHuang/uploads.git\n添加图片或者数据，并推送到 gh-pages 分支。\ngit add README.md\ngit commit \"消息\" \ngit push --set-upstream origin gh-pages\n这样仓库 uploads 只包含 gh-pages 分支，README.md 文件地址为\nhttps://xiangyunhuang.github.io/uploads/README.md",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-r-to-git",
    "href": "git-github.html#sec-r-to-git",
    "title": "附录 C — Git 和 Github",
    "section": "C.4 R 与 Git 交互",
    "text": "C.4 R 与 Git 交互\nusethis 包将 Git 操作封装了，特别是一些复杂的操作，比如修改他人的 PR\n\nC.4.1 从 R 操作 Git\n拉取编号为 1019 的 PR\nusethis::pr_fetch(1019)\n1019 是 PR 的编号，修改完，清理\nusethis::pr_finish()\n\n\nC.4.2 分析 Git 记录\n给我的仓库点赞的人有哪些，如果有很多，仅显示第一页。\nlibrary(gh)\nmy_repos &lt;- gh(\"GET /repos/:owner/:repo/stargazers\", \n               owner = \"XiangyunHuang\", page = 1, \n               repo = \"data-analysis-in-action\")\nvapply(my_repos, \"[[\", \"\", \"login\")\nJeroen Ooms 开发的 gert 包，提供了 git_rm()、 git_status()、 git_add() 和 git_commit() 等函数，其中包含 git_reset() 、git_branch_*() 等高级 Git 操作。查看最近的 5 条提交记录。\nlibrary(gert)\ngit_log(max = 5)\n更多内容，读者请看 Gert: A minimal git client for R。\ngit2r 包对 Git 仓库进行概要。\nsummary(git2r::repository())\ngitdown 包将 Git 提交日志转化为 GitBook\n截止 2023 年 6 月 1 日，统计之都的主站仓库，提交量最大的 10 个人。\ngit shortlog -sn | head -n 10\n 153    Dawei Lang\n 127    Yihui Xie\n 101    Ryan Feng Lin\n  93    Beilei Bian\n  65    Xiangyun Huang\n  46    王佳\n  42    雷博文\n  39    Miao YU\n  35    xiangyun\n  32    fanchao",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-git-extensions",
    "href": "git-github.html#sec-git-extensions",
    "title": "附录 C — Git 和 Github",
    "section": "C.5 (*) 辅助工具",
    "text": "C.5 (*) 辅助工具\nGit 扩展 git-delta 和 tig 是两款辅助工具。 tig 用于查看提交的历史日志。\n\nC.5.1 语法高亮\ngit-delta\nbrew install git-delta\n对 git diff 的输出提供语法高亮\n\n\nC.5.2 文本接口\n在 MacOS 上，推荐用 Homebrew 安装\nbrew install tig\n\n\nC.5.3 大文件存储\nGit Large File Storage (LFS) Git LFS\n# MacOS\nbrew install git-lfs\n# Ubuntu\nsudo apt install git-lfs\n配置 Git LFS\ngit lfs install\n项目中的大型数据文件\ngit lfs track \"*.csv\"\ngit add .gitattributes\ngit commit -m \"Git LFS 追踪数据文件\"\ngit push origin master",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  }
]