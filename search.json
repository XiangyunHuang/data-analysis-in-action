[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R 语言数据分析实战",
    "section": "",
    "text": "欢迎\n\n\n\n\n\n\n警告\n\n\n\nBook in early development. Planned release in 2024.\n\n\n本书初稿是在 RStudio IDE 内使用 Quarto 编辑的，Quarto 是继R Markdown之后，一个新的开源的科学和技术发布系统，它基于 Pandoc支持输出多种格式的书稿，比如 HTML 网页、EPUB 电子书、DOCX 文档和 PDF 便携式文档等。Quarto 吸收了过去 10 年 R Markdown 取得的经验和教训，在书籍写作、创建博客、制作简历和幻灯片等系列场景中支持更加统一的使用语法，一份源文档输出多种格式，使文档内容在不同场景中的迁移成本更低。了解更多 Quarto 特性，请访问 https://quarto.org/。\n书中的代码字体采用美观的 Source Code Pro 字体， 为方便跨操作系统编译书籍电子版，正文的中文字体采用开源的 fandol 字体。此外，考虑到美观性，本书图形使用了 Noto 系列中英文字体，它们来自 Google Fonts 字体库，分别是 Noto Sans 无衬线英文字体和 Noto Serif SC 宋体中文字体。\n书中 R 包名以粗体表示，如 knitr 包，函数名以等宽体表示，如 plot()，函数的参数名同理。代码块内注释用 # 表示，运行结果每一行开头以 #&gt; 标记。本书写作过程中，依赖 knitr (Xie 2015)、ggplot2 (Wickham 2016) 和 lattice (Sarkar 2008) 等众多 R 包。考虑到要同时支持 DOCX、EPUB、PDF 和 HTML 四种书籍格式，书中使用 knitr 包和 gt 包制作静态的表格。\n为方便测试贡献者提供的 PR，本书托管在 Github 上，同时启用 Github Action 服务，为书籍自定义了一个可复现全书内容的运行环境，包括 R 软件、扩展包和系统软件依赖，详见仓库中的 DESCRIPTION 文件。你现在看到的是在线编译版本，使用 Quarto 1.4.550，最新一次编译时间是 2024-03-14 23:25:46。\n\nxfun::session_info(packages = c(\n  \"ggplot2\", \"gganimate\", \"ggrepel\", \"ggdensity\",\n  \"ggridges\", \"ggsignif\", \"ggforce\", \"ggbeeswarm\",\n  \"ggeffects\", \"ggnewscale\", \"patchwork\", \"shiny\",\n  \"plotly\", \"lattice\", \"igraph\", \"tidygraph\", \"ggraph\",\n  \"dplyr\", \"purrr\", \"tidyr\", \"httr\", \"data.table\",\n  \"rsconnect\", \"knitr\", \"rmarkdown\", \"gt\", \"DT\",\n  \"showtext\", \"gifski\", \"tinytex\", \"magick\"\n), dependencies = FALSE)\n\n#&gt; R version 4.3.3 (2024-02-29)\n#&gt; Platform: x86_64-pc-linux-gnu (64-bit)\n#&gt; Running under: Ubuntu 22.04.4 LTS\n#&gt; \n#&gt; Locale:\n#&gt;   LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n#&gt;   LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n#&gt;   LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n#&gt;   LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n#&gt; \n#&gt; Package version:\n#&gt;   data.table_1.15.2 dplyr_1.1.4       DT_0.32           gganimate_1.0.9  \n#&gt;   ggbeeswarm_0.7.2  ggdensity_1.0.0   ggeffects_1.5.0   ggforce_0.4.2    \n#&gt;   ggnewscale_0.4.10 ggplot2_3.5.0     ggraph_2.2.1      ggrepel_0.9.5    \n#&gt;   ggridges_0.5.6    ggsignif_0.6.4    gifski_1.12.0.2   gt_0.10.1        \n#&gt;   httr_1.4.7        igraph_2.0.3      knitr_1.45        lattice_0.22.5   \n#&gt;   magick_2.8.3      patchwork_1.2.0   plotly_4.10.4     purrr_1.0.2      \n#&gt;   rmarkdown_2.26    rsconnect_1.2.1   shiny_1.8.0       showtext_0.9.7   \n#&gt;   tidygraph_1.3.1   tidyr_1.3.1       tinytex_0.49     \n#&gt; \n#&gt; Pandoc version: 3.1.11\n#&gt; \n#&gt; LaTeX version used: \n#&gt;   TeX Live 2024 (TinyTeX) with tlmgr 2024-02-23\n\n\n\n\n\n\nSarkar, Deepayan. 2008. lattice: Multivariate Data Visualization with R. New York: Springer. http://lmdvr.r-forge.r-project.org.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant Graphics for Data Analysis. 2nd 本. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and knitr. 2nd 本. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.",
    "crumbs": [
      "欢迎"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "前言",
    "section": "",
    "text": "为什么是 R 语言？\nR 语言在统计图形方面不仅走得早还走得远，当然，Python 语言也不错，近年来新起的 Julia 语言也很好。R 语言在统计图形方面的沉淀是非常深厚的，近年来，我发现越是简洁的越是优美，灵活的东西使用起来还非常简单，以 R 包 datasets内的数据集 PlantGrowth 为例，一般地，展示数据的分布会想到箱线图、直方图、密度图等，R 函数的泛型设计可以根据数据对象和变量的类型自动选择合适的图形， 图 12.7 是泛型函数 plot() 调用普通函数 boxplot() 和 spineplot() 绘制的。\n所以，直接调用相应的绘图函数也是可以的，如下：\nboxplot(weight ~ group, data = PlantGrowth, \n        ylab = \"植物干重\", xlab = \"组\")\nspineplot(cut(weight, 2) ~ group, data = PlantGrowth, \n          ylab = \"植物干重\", xlab = \"组\")\n脊柱图是马赛克图的一种特殊情况，也可以看做是堆积条形图的推广形式或者直方图的扩展。上面 cut() 函数的作用是将数值型变量 weight 分桶，对照组（control，简写 ctrl）和两个不同的实验组（treatment，简写 trt）都按同样的划分方式分作两桶。\ndat &lt;- transform(PlantGrowth, weight_bucket = cut(weight, 2))\naggregate(data = dat, weight ~ weight_bucket + group, FUN = length)\n\n#&gt;   weight_bucket group weight\n#&gt; 1   (3.59,4.95]  ctrl      4\n#&gt; 2   (4.95,6.31]  ctrl      6\n#&gt; 3   (3.59,4.95]  trt1      8\n#&gt; 4   (4.95,6.31]  trt1      2\n#&gt; 5   (3.59,4.95]  trt2      1\n#&gt; 6   (4.95,6.31]  trt2      9",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-why-r",
    "href": "preface.html#sec-why-r",
    "title": "前言",
    "section": "",
    "text": "(a) 箱线图\n\n\n\n\n\n\n\n\n\n(b) 脊柱图\n\n\n\n\n\n\n图 1: 影响植物生长的因素",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-why-book",
    "href": "preface.html#sec-why-book",
    "title": "前言",
    "section": "为什么写这本书？",
    "text": "为什么写这本书？\n近年来，数字经济成为热门词汇，企业数字化转型离不开数据，精细化运营更离不开数据分析，数据分析受到越来越多的关注。在数据分析领域，R 语言越来越流行，一本以 R 语言为依托，以实战为导向的数据分析书，市面上还不多。\n\n提供完整可复现的书籍源码，书中示例可以在 R 语言环境下复现。\n数据可视化部分，以一个真实数据串联绘图的基本要素，从图形的用途出发，将图形分类，结合真实数据介绍图形。\n展现数据分析的完整工作流，数据获取、操作、处理、可视化探索和分析、展示交流、建模分析、解释。\n将工作流应用于特定领域的数据分析，覆盖网络数据、文本数据、时序数据、空间数据等四大常见且重要的场景。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-how-book",
    "href": "preface.html#sec-how-book",
    "title": "前言",
    "section": "本书是怎么写的？",
    "text": "本书是怎么写的？\n\n本书在写作风格上借鉴了以下书籍\n\n《现代统计图形》 (赵鹏, 谢益辉, 和 黄湘云 2021) 讲清楚统计图形的来龙去脉，提供丰富的实战案例。\n《R in Action》(Kabacoff 2022) 根据入门、进阶和高阶将书籍内容分出层次。\n《R for Data Science》 (Wickham, Çetinkaya-Rundel, 和 Grolemund 2023) 根据数据分析的整个工作流拆分各个部分、章节。\n\n本书的写作素材来源非常广泛，比如\n\n大量的原始论文、书籍，回顾经典理论、数据案例，追根溯源\n大量的 R 包帮助文档，配合真实数据提供软件工具的使用说明\n一些国内外政府网站发布的权威数据，提供大量的实际案例数据\n从国内外论坛、书店搜集数据操作、展示和交流等方面的高频问题",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-intrinsical-motivation",
    "href": "preface.html#sec-intrinsical-motivation",
    "title": "前言",
    "section": "写作理念是什么？",
    "text": "写作理念是什么？\n\n\n以真实的数据为基础，介绍数据分析所用到的软件工具、统计方法和算法模型，对经典的数据分析案例，力求还原历史，讲清楚故事背景，数据处理的过程，不单单是分析方法和结果。\n尽可能选用来自社会、经济、文化、历史等方面的真实的、最新的或经典的数据，在讲数据分析技术的同时，也了解一点我们所处的社会，希望给读者一些启发，勾起读者的兴趣，主动探寻有趣的问题，收集整理所需的数据，做自己的研究，找到问题的答案，享受数据探索分析的过程，摸索出适合自己的分析方法和分析工具。\n结合多年使用 R 语言的经验以及最近几年在互联网行业工作的体会，形成数据分析师的技能栈，梳理知识体系，沉淀一套数据分析的方法。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-who-book",
    "href": "preface.html#sec-who-book",
    "title": "前言",
    "section": "目标读者是哪些？",
    "text": "目标读者是哪些？\n\n\n想通过编程实现数据分析的完整过程，使得整个过程可以复现，可以重复利用。\n对数据分析的实战有兴趣，想将数据分析技能应用于解决实际问题。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-what-book",
    "href": "preface.html#sec-what-book",
    "title": "前言",
    "section": "本书有哪些内容？",
    "text": "本书有哪些内容？\n\n入门部分：介绍软件 R、 RStudio 和 VS Code 的安装配置过程，常见的基本数据结构和类型，循环、判断、函数等基本的编程知识。\n数据部分：从本地文件、远程数据库、网页爬取等数据获取方式，筛选、变换、重塑、排序等基础的数据操作，离群值、异常值检测，缺失值处理等基础的数据处理\n展示部分：ggplot2 基础、统计图形、实战应用、经验总结\n交流部分：交互的图形、表格和应用，动态的 HTML 网页、PDF 文档和办公文档。\n建模部分：线性模型、广义线性模型、混合效应模型、数据挖掘算法和神经网络模型\n应用部分：网络数据、文本数据、时序数据、空间数据的分析\n其它部分：参数估计、假设检验和抽样分布等基础的统计推断，L-BFGS 算法、EM 算法等统计计算，自助法、重抽样等统计模拟。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-finding-public-datasets",
    "href": "preface.html#sec-finding-public-datasets",
    "title": "前言",
    "section": "公开数据从哪找？",
    "text": "公开数据从哪找？\n\n各国、各级政府的统计局，比如美国人口调查局、中国国家统计局等。\n国际、国内各类组织机构，比如世界银行、美国疾病预防控制中心等。\n各类网站提供的数据集，比如 GitHub 开放数据集列表 awesome-public-datasets，kaggle 网站提供大量数据分析竞赛及相应的数据集。\nR 包内置数据集，已整理得很好，比如 spData 包 收集整理了很多空间统计方面的数据集。Rdatasets 更是收集约 1900 个数据集，全部来自 CRAN 上发布的 R 包。\n一些 R 包封装数据下载的接口，比如tidyBdE包可以下载西班牙银行开放的数据，WDI 可以下载世界银行开放的数据。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-asking-the-right-questions",
    "href": "preface.html#sec-asking-the-right-questions",
    "title": "前言",
    "section": "学会有效地提问？",
    "text": "学会有效地提问？\n\n想清楚自己的问题是什么？尽力做好拆解和界定。\n去掉枝叶，保留主干，提供最小的可重复的示例。\n有耐心地等待社区的回应，积极地与社区沟通。\n为社区提供力所能及的帮助，提升自己的影响力。\n\n\n\n\n\nKabacoff, Robert I. 2022. R in Action: Data Analysis and graphics with R and Tidyverse. 3rd 本. Shelter Island, NY: Manning Publications Co.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, 和 Garrett Grolemund. 2023. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 2nd 本. Sebastopol, California: O’Reilly Media, Inc. https://r4ds.hadley.nz/.\n\n\n赵鹏, 谢益辉, 和 黄湘云. 2021. 现代统计图形. 北京: 人民邮电出版社. https://bookdown.org/xiangyun/msg.",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "介绍",
    "section": "",
    "text": "数据探索和分析\n数据可视化是数据探索和分析的一个手段，数据可视化的主要目的有两个：其一是探索 Explore，其二是解释 Explain。\n探索是面向数据分析师自己，而展示是面向数据分析的消费者。面对不同的角色，可视化的目的是不一样的，探索是了解数据，展示是传递信息。了解数据的分布、隐藏的模式、缺失情况、异常情况，步步深入地挖掘数据的潜在规律。展示是传递数据分析的结论和洞见，强调美观、效率、效果，除了数据分析师本人几乎没人想看探索数据过程中产生的数以十计的中间图形。\n数据可视化是通过计算机程序绘制图形来展示数据，有时是在图上展示原始数据，比如散点图，有时展示汇总数据，比如直方图，有时借助一些数据变换，比如对数变换，甚至更为复杂的统计变换。数据可视化主要是描述、提炼和汇总原始数据，从数据中获取信息。\n除了选择合适的工具（Base R / grid / lattice / ggplot2）绘制图形（提供 R 代码实现），选择图形（30+多种常见图形）和解释图形（真实数据背景）往往比想的更加困难，本书试图去回答这些问题。\n大多教科书侧重理论和方法，计算机强调编程，数值计算是精确的，图形是粗燥的。然而，只有模型和方法，缺乏数据探索的分析和建模，计算的结果和分析的结论可能是不正确的，数据可能在欺骗你(Anscombe 1973)。\ndatasauRus 包 (Davies, Locke, 和 D’Agostino McGowan 2022) 内置了一个数据集 datasaurus_dozen，它整合了 13 个子数据集，它们在均值、标准差等描述性统计量方面十分接近，见下 表格 1 。其中 \\(\\bar{x},\\sigma_x\\) 分别代表预测变量 \\(X\\) 的均值和标准差，\\(\\bar{y},\\sigma_y\\) 代表响应变量 \\(Y\\) 的均值和标准差，\\(\\beta_0,\\beta_1\\) 代表回归方程 方程式 1 的截距和斜率，\\(R^2\\) 代表模型拟合数据的程度。\n\\[\ny = \\beta_0 + \\beta_1 x + \\epsilon\n\\tag{1}\\]\n表格 1: datasaurus_dozen 数据集的一些描述性统计量和线性回归结果\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n子数据集\n\\(\\bar{x}\\)\n\\(\\sigma_x\\)\n\\(\\bar{y}\\)\n\\(\\sigma_y\\)\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(R^2\\)\n\n\n\ndino\n54.263\n16.765\n47.832\n26.935\n53.453\n-0.104\n0.004\n\n\naway\n54.266\n16.770\n47.835\n26.940\n53.425\n-0.103\n0.004\n\n\nh_lines\n54.261\n16.766\n47.830\n26.940\n53.211\n-0.099\n0.004\n\n\nv_lines\n54.270\n16.770\n47.837\n26.938\n53.891\n-0.112\n0.005\n\n\nx_shape\n54.260\n16.770\n47.840\n26.930\n53.554\n-0.105\n0.004\n\n\nstar\n54.267\n16.769\n47.840\n26.930\n53.327\n-0.101\n0.004\n\n\nhigh_lines\n54.269\n16.767\n47.835\n26.940\n53.809\n-0.110\n0.005\n\n\ndots\n54.260\n16.768\n47.840\n26.930\n53.098\n-0.097\n0.004\n\n\ncircle\n54.267\n16.760\n47.838\n26.930\n53.797\n-0.110\n0.005\n\n\nbullseye\n54.269\n16.769\n47.831\n26.936\n53.809\n-0.110\n0.005\n\n\nslant_up\n54.266\n16.769\n47.831\n26.939\n53.813\n-0.110\n0.005\n\n\nslant_down\n54.268\n16.767\n47.836\n26.936\n53.850\n-0.111\n0.005\n\n\nwide_lines\n54.267\n16.770\n47.832\n26.938\n53.635\n-0.107\n0.004\n诸多统计量都难以发现它们的差异，透过数据可视化这面照妖镜，却可以使数据的本来面目无所遁形，如 图 1 所示。可见，单个统计量就好比管窥蠡测，稍有不慎，我们就成了盲人摸象。\n图 1: 数据可视化为何如此重要\n数据可视化的重要性在于探索数据的真实分布，为数据建模提供假设和依据，也为验证、评估模型的效果。结合 图 1 也解释了为什么线性回归模型在解释数据方面的无能为力，即 \\(R^2\\) 介于 0.004 至 0.005 之间，数据根本不符合线性模型的条件。\n有时候是有的数据符合模型假设，而有的不符合，我们没有上帝之眼，看不到哪些符合哪些不符合。在数据集不多的情况下，可以全部展示出来，数据集很多的时候，可以抽样一部分，再展示。下面再举一个例子，anscombe 数据集来自 R 软件内置的 R 包 datasets，它包含四组数据 \\((x_i, y_i), i =1,2,3,4\\)，如 表格 2 所示。\n表格 2: anscombe 数据集\n\n\n\n\n\n\n\n\n第1组\n第2组\n第3组\n第4组\n\n\nx1\ny1\nx2\ny2\nx3\ny3\nx4\ny4\n\n\n\n\n10\n8.04\n10\n9.14\n10\n7.46\n8\n6.58\n\n\n8\n6.95\n8\n8.14\n8\n6.77\n8\n5.76\n\n\n13\n7.58\n13\n8.74\n13\n12.74\n8\n7.71\n\n\n9\n8.81\n9\n8.77\n9\n7.11\n8\n8.84\n\n\n11\n8.33\n11\n9.26\n11\n7.81\n8\n8.47\n\n\n14\n9.96\n14\n8.10\n14\n8.84\n8\n7.04\n\n\n6\n7.24\n6\n6.13\n6\n6.08\n8\n5.25\n\n\n4\n4.26\n4\n3.10\n4\n5.39\n19\n12.50\n\n\n12\n10.84\n12\n9.13\n12\n8.15\n8\n5.56\n\n\n7\n4.82\n7\n7.26\n7\n6.42\n8\n7.91\n\n\n5\n5.68\n5\n4.74\n5\n5.73\n8\n6.89\n用统计的方法发现四组数据的样本均值、方差、相关系数和回归系数几乎是相同的，实际上，借助散点 图 2 分别描述各组数据的关系时，却发现四组数据之间有极大的差异，且只有第一组数据看起来符合线性模型的条件 (Anscombe 1973)。\n图形还告诉我们第二组数据的更适合二次非线性回归，第三组数据受到离群点的重大影响，第四组数据自变量只有两个取值，像是两个分布按不同比例混合的结果。",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "intro.html#sec-exploration-explaination",
    "href": "intro.html#sec-exploration-explaination",
    "title": "介绍",
    "section": "",
    "text": "(a) 第一组数据\n\n\n\n\n\n\n\n\n\n(b) 第二组数据\n\n\n\n\n\n\n\n\n\n\n\n(c) 第三组数据\n\n\n\n\n\n\n\n\n\n(d) 第四组数据\n\n\n\n\n\n\n图 2: 数据可视化为何如此重要",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "intro.html#sec-data-communication",
    "href": "intro.html#sec-data-communication",
    "title": "介绍",
    "section": "数据展示和交流",
    "text": "数据展示和交流\n无论是数据表格还是交互图形，首先都承担着数据展示的基础作用，通过趋势、对比继而传递更加明确的信息和洞见，采用合适的表达方式可以高效准确地传递信息，促进交流，获取反馈，从而改善已有的分析方法和结论。\n数据展示和交流主要分两大部分：其一是用户可与之交互的图形、表格和应用，其二是文档内容可重复的 HTML 动态网页文档、PDF 便携式文档、 Office 办公文档。涵盖完整数据分析过程的网页文档， 用于毕业的学位论文、投稿的期刊论文、出版的书籍初稿、交流的演示文稿，无论是 LaTeX 编译的 PDF 格式文档还是 DOCX 文档，R 语言社区都有非常先进的工具满足需求。\n6  交互图形 首先介绍 plotly 包绘图的基础语法以及与 ggplot2 包绘图 的关系，其次介绍制作常用的交互图形，如条形图、直方图、箱线图、曲线图等，最后介绍一些常用的技巧，如导出静态图片、添加水印徽标等。\n7  交互表格 首先介绍 DT 包制作交互表格的基础语法，其次介绍常用的功能，如列分层分组、按列配色、列格式化、搜索排序、数据导出等，最后介绍一些基础的 CSS 和 JavaScript 知识，支持一些中高级的表格定制功能。\n8  交互应用 首先介绍 shiny 包制作交互应用的整体概览，如前端布局、后端计算、筛选器、模块交互等，其次从易到难介绍一个完整的数据应用，最后介绍生产级的 Shiny 应用开发的技术栈。\n9  HTML 文档 首先回顾 R 语言社区陆续出现的 R Sweave、R Markdown 和 Quarto 三套创作工具，其次介绍 Quarto 的基础用法，如 Markdown 基础和 Pandoc 的基础，接着根据使用场景分别介绍 HTML、PDF 和 Office 文档的特性。\n\n\n\n\nAnscombe, F. J. 1973. 《Graphs in Statistical Analysis》. The American Statistician 27 (1): 17. https://doi.org/10.2307/2682899.\n\n\nDavies, Rhian, Steph Locke, 和 Lucy D’Agostino McGowan. 2022. datasauRus: Datasets from the Datasaurus Dozen. https://CRAN.R-project.org/package=datasauRus.\n\n\nRigby, R. A., 和 D. M. Stasinopoulos. 2005. 《Generalized additive models for location, scale and shape (with discussion)》. Journal of the Royal Statistical Society: Series C (Applied Statistics) 54 (3): 507–54. https://doi.org/10.1111/j.1467-9876.2005.00510.x.",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "wrangling-objects.html",
    "href": "wrangling-objects.html",
    "title": "1  数据对象",
    "section": "",
    "text": "1.1 数据类型",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-objects.html#sec-data-type",
    "href": "wrangling-objects.html#sec-data-type",
    "title": "1  数据对象",
    "section": "",
    "text": "1.1.1 整型\n\nc(1L, 2L)\n\n[1] 1 2\n\n\n\n1.1.2 逻辑型\n\nc(TRUE, FALSE)\n\n[1]  TRUE FALSE\n\n\n\n1.1.3 字符型\n\nc(\"A\", \"B\")\n\n[1] \"A\" \"B\"\n\n\n\n1.1.4 日期型\n\nc(as.Date(\"2022-01-01\"), as.Date(\"2022-01-02\"))\n\n[1] \"2022-01-01\" \"2022-01-02\"\n\n\n\n1.1.5 数值型\n\nc(1,1.2)\n\n[1] 1.0 1.2",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-objects.html#sec-data-structure",
    "href": "wrangling-objects.html#sec-data-structure",
    "title": "1  数据对象",
    "section": "\n1.2 数据结构",
    "text": "1.2 数据结构\n\n1.2.1 向量\n所有元素都是同一类型\n\n1.2.2 矩阵\n所有元素都是同一类型\n\n1.2.3 数组\n所有元素都是同一类型\n\n1.2.4 列表\n元素可以属于不同类型\n\n1.2.5 因子\n\n1.2.6 数据框\n同列的元素类型必须一致，不同列的元素类型可以不同。\n\n1.2.7 ts\nts 类型用于表示时间序列数据，是继承自数组类型的。给定数据、采样初始时间、采样频率的情况下，利用内置的函数 ts() 构造一个 ts 类型的分钟级的时间序列对象。\n\nx &lt;- ts(\n  data = rnorm(100), \n  start = c(2017, 1), \n  frequency = 365.25 * 24 * 60, \n  class = \"ts\", names = \"Time_Series\"\n)\n\nts() 函数的 start 和 frequency 参数很关键，前者指定了时间单位是天，后者指定每个时间单位下的数据点的数量。其中 365.25 是因为每隔 4 年有 366 天，平均下来，每年算 365.25 天。每隔 1 / (24 * 60) 天（即 1 分钟）采样一个点。如果初始时间不是从一年的第1分钟开始，而是从此时此刻 2023-01-31 10:43:30 CST 开始，则可以换算成今年的第 30 * 24 * 60 + 9 * 60 + 43 = 43783 分钟，则 Start = c(2023, 43783)。\n以数据集 x 为例，它是一个 ts 类型的时间序列数据对象。时间序列对象有很多方法，如函数 class() 、 mode() 和 str() 分别可以查看其数据类型、存储类型和数据结构。\n\n# 数据类型\nclass(x)\n\n[1] \"ts\"\n\n# 存储类型\nmode(x)\n\n[1] \"numeric\"\n\n# 数据结构\nstr(x)\n\n Time-Series [1:100] from 2017 to 2017: 1.31088 -0.00582 0.48111 -1.56845 -0.03549 ...\n\n\n函数 start() 和 end() 查看开始和结束的时间点。\n\nc(start(x), end(x))\n\n[1] 2017    1 2017  100\n\n\n函数 time() 可以查看在以上时间区间的划分。\n\ntime(x)\n\nTime Series:\nStart = c(2017, 1) \nEnd = c(2017, 100) \nFrequency = 525960 \n  [1] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [16] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [31] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [46] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [61] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [76] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [91] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n\n\n函数 tsp() 可以查看其期初、期末和周期。\n\ntsp(x)\n\n[1]   2017   2017 525960",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html",
    "href": "wrangling-collection.html",
    "title": "2  数据获取",
    "section": "",
    "text": "2.1 从本地文件读取\n利用 Base R 提供的基础函数从各类文件导入数据",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-file",
    "href": "wrangling-collection.html#sec-file",
    "title": "2  数据获取",
    "section": "",
    "text": "2.1.1 csv 文件\n小的 csv 文件，可用 Base R 提供的 read.csv() 函数读取。 大型 csv 文件，可用 data.table 的 fread() 函数读取。\n\n2.1.2 xlsx 文件\nreadxl 读 xls 和 xlsx 文件，writexl 写 xlsx。\nopenxlsx 读/写 xlsx 文件\n\n2.1.3 arrow 文件\nApache Arrow 的 R 语言接口 arrow 超出内存的大规模数据操作。比如在时空数据处理场景，数据文件往往比较大，需要在远程服务器上处理超出本地计算机内存的数据，geoarrow包和sfarrow包都是应对此类需求。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-database",
    "href": "wrangling-collection.html#sec-database",
    "title": "2  数据获取",
    "section": "\n2.2 从数据库中导入",
    "text": "2.2 从数据库中导入\n从各类数据库导入数据，比如 RSQLite 等\n\n2.2.1 RSQLite\n\n2.2.2 odbc\n\n2.2.3 RJDBC\n很多数据库都有 Java 接口驱动",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-web-scraping",
    "href": "wrangling-collection.html#sec-web-scraping",
    "title": "2  数据获取",
    "section": "\n2.3 从各类网页中抓取",
    "text": "2.3 从各类网页中抓取\nrvest 包从网页、网站抓取数据， 再用 xml2 和 httr2 解析处理网页数据。\n\n2.3.1 豆瓣排行榜\n\n2.3.2 链家二手房",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-rest-api",
    "href": "wrangling-collection.html#sec-rest-api",
    "title": "2  数据获取",
    "section": "\n2.4 从数据接口中获取",
    "text": "2.4 从数据接口中获取\n\n2.4.1 Github\n从 Github API 接口中获取托管在 Github 上的 R 包的信息，比如点赞、关注和转发的数量。首先从 CRAN 上获得 R 包元数据信息，接着筛选出托管在 Github 上的 R 包，清理出 R 包在 Github 上的网址。\n\npdb &lt;- readRDS(file = \"data/cran-package-db-20231231.rds\")\n# 过滤出 Github \npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package) & grepl(pattern = \"github\", x = BugReports),\n  select = c(\"Package\", \"Maintainer\", \"Title\", \"BugReports\")\n)\n# 掐头去尾\npdb$repo &lt;- sub(x =  pdb$BugReports, pattern = \"(http|https)://(www\\\\.){0,1}github\\\\.com/\", replacement = \"\")\npdb$repo &lt;- sub(x = pdb$repo, pattern = \"/{1,}(issues|blob).*\", replacement = \"\")\npdb$repo &lt;- sub(x = pdb$repo, pattern = \"/{1,}(discussions|wiki)\", replacement = \"\")\npdb$repo &lt;- sub(x = pdb$repo, pattern = \"/$\", replacement = \"\")\n\n获取某代码仓库信息的 Github API 是 https://api.github.com/repos ，为了批量地访问 API ，收集想要的数据，将数据请求、结果整理的过程打包成一个函数。\n\ngithub_stats &lt;- function(repo) {\n  url &lt;- paste(\"https://api.github.com/repos\", repo, sep = \"/\")\n  # 最多允许失败 5 次，每失败一次休息 5s\n  req &lt;- xfun::retry(curl::curl_fetch_memory, url = url, .times = 5, .pause = 5)\n  x &lt;- jsonlite::fromJSON(rawToChar(req$content))\n  # 爬失败的标记一下\n  if(is.null(x$stargazers_count)) x$stargazers_count &lt;- x$subscribers_count &lt;- x$forks_count &lt;- -1\n  # 爬一个休息 1s\n  Sys.sleep(1)\n  data.frame(\n    repo = repo,\n    # 点赞 仓库上 star 的人数\n    stargazers_count = x$stargazers_count,\n    # 关注 仓库上 watch 的人数\n    subscribers_count = x$subscribers_count,\n    # 转发 仓库上 fork 的人数\n    forks_count = x$forks_count\n  )\n}\n\n下面测试一下这段代码，获取代码仓库 yihui/knitr 的点赞、关注和转发的人数。\n\n# 测试代码\ngithub_stats(repo = \"yihui/knitr\")\n\n         repo stargazers_count subscribers_count forks_count\n1 yihui/knitr             2334               115         872\n\n\n理论上，使用函数 lapply() 遍历所有 R 包可得所需数据，将数据收集函数应用到每一个 R 包上再合并结果，即如下操作。\n\n# 合并数据\ngh_repo_db &lt;- data.table::rbindlist(lapply(pdb$repo, github_stats))\n\n实际上，在没有访问令牌的情况下，Github API 的访问次数是有限制的，只有 60 次（一段时间内）。首先在 Github 开发者设置中申请一个应用，获得应用名称（appname）、客户端 ID（key）和密钥（secret），下面借助 httr 包配置 OAuth 凭证。\n\nlibrary(httr)\n# Github API Oauth2\noauth_endpoints(\"github\")\n# 应用名称（appname）、客户端 ID（key）和密钥（secret）\nmyapp &lt;- oauth_app(\n  appname = \"Application Name\", key = \"Client ID\",\n  secret = \"Client Secrets\"\n)\n# 获取 OAuth 凭证\ngithub_token &lt;- oauth2.0_token(oauth_endpoints(\"github\"), myapp)\n# 使用 API\ngtoken &lt;- config(token = github_token)\n\n修改函数 github_stats() 中请求 Github API 的一行代码，发送带密钥的 GET 请求。\n\nreq &lt;- xfun::retry(GET, url = url, config = gtoken, .times = 5, .pause = 5)\n\n此外，请求难免出现意外，按照上面的方式，一旦报错，数据都将丢失。因此，要预先准备存储空间，每获取一条数据就存进去，如果报错了，就打个标记。\n\n# 准备存储数据\ngh_repo_db &lt;- data.frame(\n  repo = pdb$repo, stargazers_count = rep(-1, length(pdb$repo)),\n  subscribers_count = rep(-1, length(pdb$repo)),\n  forks_count = rep(-1, length(pdb$repo))\n)\n# 不断更新数据\nwhile (any(gh_repo_db$stargazers_count == -1)) {\n  tmp &lt;- gh_repo_db[gh_repo_db$stargazers_count == -1, ]\n  for (repo in tmp$repo) {\n    gh_repo_db[gh_repo_db$repo == repo, ] &lt;- github_stats(repo = repo)\n  }\n  if(repo == tmp$repo[length(tmp$repo)]) break\n}\n\n最后，将收集整理好的数据保存到磁盘上，下面按点赞数量给 R 包排序，篇幅所限，仅展示前 20。\n\ngh_repo_db &lt;- readRDS(file = \"data/gh-repo-db-2023.rds\")\ngh_repo_db &lt;- gh_repo_db[!duplicated(gh_repo_db$repo),]\ngh_repo_db &lt;- gh_repo_db[order(gh_repo_db$stargazers_count, decreasing = T),] \nhead(gh_repo_db, 20)\n\n                      repo stargazers_count subscribers_count forks_count\n8434          dmlc/xgboost            25266               909        8707\n5553      facebook/prophet            17415               425        4474\n4307         mlflow/mlflow            16365               292        3793\n3807    Microsoft/LightGBM            15821               437        3798\n265           apache/arrow            13080               356        3220\n3080           h2oai/h2o-3             6624               384        2016\n2790     tidyverse/ggplot2             6210               308        2028\n3430 interpretml/interpret             5894               141         706\n6921         rstudio/shiny             5180               339        1818\n4317         mlpack/mlpack             4668               185        1577\n1754       tidyverse/dplyr             4612               246        2131\n640       rstudio/bookdown             3565               122        1263\n1430 Rdatatable/data.table             3437               170         977\n6316     rstudio/rmarkdown             2758               146         977\n2269          wesm/feather             2708                97         174\n5324       plotly/plotly.R             2467               117         628\n5084   thomasp85/patchwork             2344                49         159\n1389        r-lib/devtools             2340               120         760\n3658           yihui/knitr             2326               115         877\n6868      satijalab/seurat             2034                75         867\n\n\n将发布在 Github 上的受欢迎的 R 包列出来了，方便读者选用，也看到一些有意思的结果。\n\n机器学习相关的 R 包靠在最前面，实际上，它们（占十之七八）多是对应软件的 R 语言接口，点赞的数目应当算上其它语言接口的贡献。\n在机器学习之后，依次是数据可视化（ggplot2、shiny、plotly.R、patchwork）、数据操作（dplyr、data.table、feather）和可重复性计算（bookdown、rmarkdown、knitr）、R 包开发（devtools）和生物信息（seurat）。\n\n最后，简要说明数据的情况：以上观察结果是基于 CRAN 在 2023-12-31 发布的 R 包元数据，8475 个 R 包在 Github 托管源代码，这些 R 包的点赞、关注和转发数据是在 2024-01-30 爬取的。其中，共有 29 个 R 包不按规矩填写、改名字、换地方、甚至删库了，这些 R 包是可忽略的。当然，也存在一些 R 包并未托管在 Github 上，但质量不错，比如 glmnet 包、colorspace 包、fGarch 包等，应当是少量的。\n\n2.4.2 中国地震台网\n中国地震台网 可以想象后台有一个数据库，在页面的小窗口中输入查询条件，转化为某种 SQL 语句，传递给数据库管理系统，执行查询语句，返回查询结果，即数据。\n\n2.4.3 美国地质调查局\n美国地质调查局提供一些选项窗口，可供选择数据范围，直接下载 CSV 或 XLS 文件。\n\n2.4.4 美国人口调查局\n美国人口调查局\ntidycensus 需要注册账号，获取使用 API 接口的访问令牌，可以想象后台不仅有一个数据库，在此之上，还有一层数据鉴权。\n\n2.4.5 世界银行\n世界银行和国际货币基金组织\nwbstats 包封装世界银行提供的数据接口 REST API",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html",
    "href": "wrangling-cleaning.html",
    "title": "3  数据清洗",
    "section": "",
    "text": "3.1 正则表达式",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html#sec-regexp",
    "href": "wrangling-cleaning.html#sec-regexp",
    "title": "3  数据清洗",
    "section": "",
    "text": "3.1.1 量词\n\n\n3.1.2 级联\n\n\n3.1.3 断言\n正向查找 / 反向查找\n\n\n3.1.4 反向引用\n\n\n3.1.5 命名捕捉",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html#sec-string-operations",
    "href": "wrangling-cleaning.html#sec-string-operations",
    "title": "3  数据清洗",
    "section": "3.2 字符串操作",
    "text": "3.2 字符串操作\n\n3.2.1 查找\ngrep() / grepl() 返回是否匹配的结果\n\n\n3.2.2 替换\nsub() / gsub() 替换一次和多次\n\n\n3.2.3 提取\nregexpr() / gregexpr()\nregexec() / gregexec()",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html",
    "href": "wrangling-manipulation.html",
    "title": "4  数据操作",
    "section": "",
    "text": "4.1 操作工具\n本节所用数据来自世界银行，介绍 Base R、data.table、dplyr 的简介、特点、对比",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-tools",
    "href": "wrangling-manipulation.html#sec-tools",
    "title": "4  数据操作",
    "section": "",
    "text": "4.1.1 Base R\n在 data.frame 的基础上，提供一系列辅助函数实现各类数据操作。\n\naggregate(iris, Sepal.Length ~ Species, FUN = length)\n\n     Species Sepal.Length\n1     setosa           50\n2 versicolor           50\n3  virginica           50\n\n\n\n4.1.2 data.table\ndata.table 包在 Base R 的基础上，扩展和加强了原有函数的功能，提供一套完整的链式操作语法。\n\nlibrary(data.table)\niris_dt &lt;- as.data.table(iris)\niris_dt[ ,.(cnt = length(Sepal.Length)) , by = \"Species\"]\n\n      Species   cnt\n       &lt;fctr&gt; &lt;int&gt;\n1:     setosa    50\n2: versicolor    50\n3:  virginica    50\n\n\n\n4.1.3 dplyr\ndplyr 包提供一套全新的数据操作语法，与 purrr 包和 tidyr 包一起形成完备的数据操作功能。在 R 环境下，dplyr 包提供一套等价的表示，代码如下：\n\niris |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count()\n\n# A tibble: 3 × 2\n# Groups:   Species [3]\n  Species        n\n  &lt;fct&gt;      &lt;int&gt;\n1 setosa        50\n2 versicolor    50\n3 virginica     50\n\n\n\n4.1.4 SQL\n实际工作中，SQL （结构化查询语言）是必不可少的基础性工具，比如 SQLite、 Hive 和 Spark 等都提供基于 SQL 的数据查询引擎，没有重点介绍 SQL 操作是因为本书以 R 语言为数据分析的主要工具，而不是它不重要。以 dplyr 来说吧，它的诸多语义动词就是对标 SQL 的。\n\nlibrary(DBI)\nconn &lt;- DBI::dbConnect(RSQLite::SQLite(),\n  dbname = system.file(\"db\", \"datasets.sqlite\", package = \"RSQLite\")\n)\n\n按 Species 分组统计数据条数， SQL 查询语句如下：\n\nSELECT COUNT(1) AS cnt, Species\nFROM iris\nGROUP BY Species;\n\nSQL 代码执行的结果如下：\n\niris_preview\n\n  cnt    Species\n1  50     setosa\n2  50 versicolor\n3  50  virginica\n\n\ndplyr 包能连接数据库，以上 SQL 代码也可以翻译成等价的 dplyr 语句。\n\ndplyr::tbl(conn, \"iris\") |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count()\n\n# Source:   SQL [3 x 2]\n# Database: sqlite 3.45.0 [/home/runner/work/_temp/Library/RSQLite/db/datasets.sqlite]\n# Groups:   Species\n  Species        n\n  &lt;chr&gt;      &lt;int&gt;\n1 setosa        50\n2 versicolor    50\n3 virginica     50\n\n\ndplyr 包的函数 show_query() 可以将 dplyr 语句转化为查询语句，这有助于排错。\n\ndplyr::tbl(conn, \"iris\") |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count() |&gt; \n  dplyr::show_query()\n\n&lt;SQL&gt;\nSELECT `Species`, COUNT(*) AS `n`\nFROM `iris`\nGROUP BY `Species`\n\n\nglue 包可以使用 R 环境中的变量，相比于 sprintf() 函数，可以组合更大型的 SQL 语句，这在生产环境中广泛使用。\n\n# R 环境中的变量\ngroup &lt;- \"Species\"\n# 组合 SQL\nquery &lt;- glue::glue(\"\n  SELECT COUNT(1) AS cnt, Species\n  FROM iris\n  GROUP BY ({group})\n\")\n# 将 SQL 语句传递给数据库，执行 SQL 语句\nDBI::dbGetQuery(conn, query)\n\n  cnt    Species\n1  50     setosa\n2  50 versicolor\n3  50  virginica\n\n\n用完后，关闭连接通道。\n\ndbDisconnect(conn = conn)\n\n更多关于 SQL 语句的使用介绍见书籍《Become a SELECT star》。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-basic-operator",
    "href": "wrangling-manipulation.html#sec-basic-operator",
    "title": "4  数据操作",
    "section": "\n4.2 Base R 操作",
    "text": "4.2 Base R 操作\n介绍最核心的 Base R 数据操作，如筛选、排序、变换、聚合、重塑等\n\n4.2.1 筛选\n筛选操作可以用函数 subset() 或 [ 实现\n\nsubset(iris, subset = Species == \"setosa\" & Sepal.Length &gt; 5.5, select = c(\"Sepal.Length\", \"Sepal.Width\"))\n\n   Sepal.Length Sepal.Width\n15          5.8         4.0\n16          5.7         4.4\n19          5.7         3.8\n\n\n\niris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5.5, c(\"Sepal.Length\", \"Sepal.Width\")]\n\n   Sepal.Length Sepal.Width\n15          5.8         4.0\n16          5.7         4.4\n19          5.7         3.8\n\n\n\n4.2.2 变换\n变换操作可以用函数 within()/transform() 实现。最常见的变换操作是类型转化，比如从字符串型转为因子型、整型或日期型等。\n\n# iris2 &lt;- transform(iris, Species_N = as.integer(Species))[1:3, ]\niris2 &lt;- within(iris, {\n  Species_N &lt;- as.integer(Species)\n})\nstr(iris2)\n\n'data.frame':   150 obs. of  6 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Species_N   : int  1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n4.2.3 排序\n排序操作可以用函数 order() 实现\n\niris[order(iris$Sepal.Length, decreasing = FALSE)[1:3], ]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n14          4.3         3.0          1.1         0.1  setosa\n9           4.4         2.9          1.4         0.2  setosa\n39          4.4         3.0          1.3         0.2  setosa\n\n\n\n4.2.4 聚合\n聚合操作可以用函数 aggregate() 实现\n\naggregate(iris, Sepal.Length ~ Species, mean)\n\n     Species Sepal.Length\n1     setosa        5.006\n2 versicolor        5.936\n3  virginica        6.588\n\n\n\n4.2.5 合并\n两个数据框的合并操作可以用函数 merge() 实现\n\ndf1 &lt;- data.frame(a1 = c(1, 2, 3), a2 = c(\"A\", \"B\", \"C\"))\ndf2 &lt;- data.frame(b1 = c(2, 3, 4), b2 = c(\"A\", \"B\", \"D\"))\n# LEFT JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all.x = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  C  3 NA\n\n# RIGHT JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all.y = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  D NA  4\n\n# INNER JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all = FALSE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n\n# FULL JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  C  3 NA\n4  D NA  4\n\n\n\n4.2.6 重塑\n将数据集从宽格式转为长格式，可以用函数 reshape() 实现，反之，亦然。\n\n# 长格式\ndf3 &lt;- data.frame(\n  extra = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4),\n  group = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),\n  id = c(1, 2, 3, 1, 2, 3)\n)\n# 长转宽\nreshape(df3, direction = \"wide\", timevar = \"group\", idvar = \"id\")\n\n  id extra.A extra.B\n1  1     0.7    -1.2\n2  2    -1.6    -0.1\n3  3    -0.2     3.4\n\n# 也可以指定组合变量的列名\nreshape(df3, direction = \"wide\", timevar = \"group\", idvar = \"id\",\n        v.names = \"extra\", sep = \"_\")\n\n  id extra_A extra_B\n1  1     0.7    -1.2\n2  2    -1.6    -0.1\n3  3    -0.2     3.4\n\n\n提取并整理分组线性回归系数。函数 split() 将数据集 iris 按分类变量 Species 拆分成列表， 函数 lapply() 将线性回归操作 lm() 应用于列表的每一个元素上，再次用函数 lapply() 将函数 coef() 应用于线性回归后的列表上，提取回归系数，用函数 do.call() 将系数合并成矩阵，最后，用函数as.data.frame() 转化成数据框。\n\ns1 &lt;- split(iris, ~Species)\ns2 &lt;- lapply(s1, lm, formula = Sepal.Length ~ Sepal.Width)\ns3 &lt;- lapply(s2, coef)\ns4 &lt;- do.call(\"rbind\", s3)\ns5 &lt;- as.data.frame(s4)\ns5\n\n           (Intercept) Sepal.Width\nsetosa        2.639001   0.6904897\nversicolor    3.539735   0.8650777\nvirginica     3.906836   0.9015345\n\ndo.call(\n  \"rbind\",\n  lapply(\n    lapply(\n      split(iris, ~Species), lm,\n      formula = Sepal.Length ~ Sepal.Width\n    ),\n    coef\n  )\n)\n\n           (Intercept) Sepal.Width\nsetosa        2.639001   0.6904897\nversicolor    3.539735   0.8650777\nvirginica     3.906836   0.9015345",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-data-table",
    "href": "wrangling-manipulation.html#sec-data-table",
    "title": "4  数据操作",
    "section": "\n4.3 data.table 操作",
    "text": "4.3 data.table 操作\n掌握此等基础性的工具，再去了解新工具也不难，更重要的是，只要将一种工具掌握的足够好，也就足以应付绝大多数的情况。\n\n介绍 data.table 基础语法，对标 Base R，介绍基础操作，同时给出等价的 dplyr 实现，但不运行代码。\ndata.table 扩展 Base R 数据操作，介绍常用的操作 8 个，讲清楚出现的具体场景，同时给出等价的 dplyr 实现，但不运行代码。\ndata.table 特有的高级数据操作 on、.SD 、.I 、.J 等。\n\n\n4.3.1 筛选\ndata.table 扩展了函数 [ 功能，简化 iris$Species == \"setosa\" 代码 Species == \"setosa\"\n\niris_dt[Species == \"setosa\" & Sepal.Length &gt; 5.5, c(\"Sepal.Length\", \"Sepal.Width\")]\n\n   Sepal.Length Sepal.Width\n          &lt;num&gt;       &lt;num&gt;\n1:          5.8         4.0\n2:          5.7         4.4\n3:          5.7         3.8\n\n\n\n4.3.2 变换\n变换操作可以用函数 :=\n\niris_dt[, Species_N := as.integer(Species)]\nstr(iris_dt)\n\nClasses 'data.table' and 'data.frame':  150 obs. of  6 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Species_N   : int  1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\n\n\n4.3.3 排序\n排序操作可以用函数 order()\n\niris_dt[order(Sepal.Length, decreasing = FALSE)[1:3], ]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Species_N\n          &lt;num&gt;       &lt;num&gt;        &lt;num&gt;       &lt;num&gt;  &lt;fctr&gt;     &lt;int&gt;\n1:          4.3         3.0          1.1         0.1  setosa         1\n2:          4.4         2.9          1.4         0.2  setosa         1\n3:          4.4         3.0          1.3         0.2  setosa         1\n\n\n\n4.3.4 聚合\n聚合操作用函数 .() 和 by 组合\n\niris_dt[, .(mean = mean(Sepal.Length)), by = \"Species\"]\n\n      Species  mean\n       &lt;fctr&gt; &lt;num&gt;\n1:     setosa 5.006\n2: versicolor 5.936\n3:  virginica 6.588\n\n\n\n4.3.5 合并\n合并操作也是用函数 merge() 来实现。\n\ndt1 &lt;- data.table(a1 = c(1, 2, 3), a2 = c(\"A\", \"B\", \"C\"))\ndt2 &lt;- data.table(b1 = c(2, 3, 4), b2 = c(\"A\", \"B\", \"D\"))\n# LEFT JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all.x = TRUE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n3:      C     3    NA\n\n# RIGHT JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all.y = TRUE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n3:      D    NA     4\n\n# INNER JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all = FALSE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n\n# FULL JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all = TRUE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n3:      C     3    NA\n4:      D    NA     4\n\n\n\n4.3.6 重塑\n将数据集从宽格式转为长格式，可以用函数 dcast() 实现，反之，可以用函数 melt() 实现。\n\n# 长格式\ndt3 &lt;- data.table(\n  extra = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4),\n  group = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),\n  id = c(1, 2, 3, 1, 2, 3)\n)\n# 长转宽\ndcast(dt3, id ~ group, value.var = \"extra\")\n\nKey: &lt;id&gt;\n      id     A     B\n   &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:     1   0.7  -1.2\n2:     2  -1.6  -0.1\n3:     3  -0.2   3.4\n\n\n类似 Base R，也用 data.table 来实现 iris 分组线性回归\n\niris_dt[, as.list(coef(lm(Sepal.Length ~ Sepal.Width))), by = \"Species\"]\n\n      Species (Intercept) Sepal.Width\n       &lt;fctr&gt;       &lt;num&gt;       &lt;num&gt;\n1:     setosa    2.639001   0.6904897\n2: versicolor    3.539735   0.8650777\n3:  virginica    3.906836   0.9015345",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html",
    "href": "wrangling-processing.html",
    "title": "5  数据处理",
    "section": "",
    "text": "5.1 缺失值处理\n缺失是一种非常常见的数据问题。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-missing-data",
    "href": "wrangling-processing.html#sec-missing-data",
    "title": "5  数据处理",
    "section": "",
    "text": "5.1.1 查找\n缺失值在数据框中的位置\n\n\n5.1.2 汇总\n缺失值的占比、分布情况，可视化获得缺失的结构 VIM\n\n\n5.1.3 替换\n替换数据框中的缺失值\n\n\n5.1.4 插补\nmice Multivariate Imputation by Chained Equations 缺失值插补",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-exception-data",
    "href": "wrangling-processing.html#sec-exception-data",
    "title": "5  数据处理",
    "section": "5.2 异常值处理",
    "text": "5.2 异常值处理\n提及异常，一般会联想到数据本身出问题了，比如数据错误。比较常见的情况是业务有异动，导致数据异常波动，需要及时捕捉到这种异常波动，找到异常的原因，进而采取措施。\n\n5.2.1 检测\n\n\n5.2.2 识别\n\n\n5.2.3 处理",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-outlier-data",
    "href": "wrangling-processing.html#sec-outlier-data",
    "title": "5  数据处理",
    "section": "5.3 离群值处理",
    "text": "5.3 离群值处理\n离群，并不是数据本身出问题，而是数据隐藏着特殊信息，与平时不一样的情况，与大家伙不一样的情况。比如情人节鲜花和蛋糕的需求量激增，端午节粽子的需求激增，这和平时很不一样。需求数据本身没有问题，如实反应了现实情况。因此，需要根据现实情况，调整预测模型，做出更加准确的需求预测，提前安排供给。\n\n5.3.1 检测\n\n\n5.3.2 识别\n\n\n5.3.3 处理",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html",
    "href": "interactive-graphics.html",
    "title": "6  交互图形",
    "section": "",
    "text": "6.1 基础元素",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-interactive-elements",
    "href": "interactive-graphics.html#sec-interactive-elements",
    "title": "6  交互图形",
    "section": "",
    "text": "6.1.1 图层\nplotly 包封装了许多图层函数，可以绘制各种各样的统计图形，见下 表格 6.1 。\n\n\n表格 6.1: plotly 包可以绘制丰富的统计图形\n\n\n\nadd_annotations\nadd_histogram\nadd_polygons\n\n\nadd_area\nadd_histogram2d\nadd_ribbons\n\n\nadd_bars\nadd_histogram2dcontour\nadd_scattergeo\n\n\nadd_boxplot\nadd_image\nadd_segments\n\n\nadd_choropleth\nadd_lines\nadd_sf\n\n\nadd_contour\nadd_markers\nadd_surface\n\n\nadd_data\nadd_mesh\nadd_table\n\n\nadd_fun\nadd_paths\nadd_text\n\n\nadd_heatmap\nadd_pie\nadd_trace\n\n\n\n\n\n下面以散点图为例，使用方式非常类似 ggplot2 包，函数 plot_ly() 类似 ggplot()，而函数 add_markers() 类似 geom_point()，效果如 图 6.1 所示。\n\n# https://plotly.com/r/reference/scatter/\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers()\n\n\n\n\n\n\n\n\n图 6.1: 默认风格的简单散点图\n\n\n\n\n或者使用函数 add_trace()，层层添加图形元素，效果和上 图 6.1 是一样的。\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_trace(type = \"scatter\", mode = \"markers\")\n\n\n\n\n\n\n\n提示\n\n\n\nplotly 包的函数 plot_ly() 又与 ggplot2 包中函数 qplot() 类似，可以将大部分设置塞进去。\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  type = \"scatter\", mode = \"markers\"\n)\n\n所以，总的来说， add_markers() 、add_trace(type = \"scatter\", mode = \"markers\") 和 plot_ly(type = \"scatter\", mode = \"markers\") 是等价的。\n\n\n\n6.1.2 配色\n在 图 6.1 的基础上，将颜色映射到震级变量上。\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers(color = ~mag)\n\n\n\n\n\n\n图 6.2: 给散点图配色\n\n\n\n\n6.1.3 刻度\n东经和南纬\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers(color = ~mag) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\", ticksuffix = 'E'),\n    yaxis = list(title = \"纬度\", ticksuffix = 'S')\n  )\n\n\n\n\n\n\n图 6.3: 设置刻度及标签\n\n\n\n\n6.1.4 标签\n添加横轴、纵轴以及主副标题\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  marker = list(\n    color = ~mag,\n    colorscale = \"Viridis\",\n    colorbar = list(title = list(text = \"震级\"))\n  )\n) |&gt;\n  plotly::add_markers() |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\"),\n    title = \"斐济及其周边地区的地震活动\"\n  )\n\n\n\n\n\n\n图 6.4: 添加各处标题\n\n\n\n\n6.1.5 主题\nplotly 内置了一些主题风格\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  marker = list(\n    color = ~mag,\n    colorscale = \"Viridis\",\n    colorbar = list(title = list(text = \"震级\"))\n  )\n) |&gt;\n  plotly::add_markers() |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\"),\n    title = \"斐济及其周边地区的地震活动\"\n  )\n\n\n\n\n\n\n图 6.5: 设置主题风格\n\n\n\n\n6.1.6 字体\n\n6.1.7 图例",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-plotly-common-graphics",
    "href": "interactive-graphics.html#sec-plotly-common-graphics",
    "title": "6  交互图形",
    "section": "\n6.2 常用图形",
    "text": "6.2 常用图形\n\n6.2.1 散点图\nplotly 包支持绘制许多常见的散点图，从直角坐标系 scatter 到极坐标系 scatterpolar 和地理坐标系 scattergeo，从二维平面 scatter 到三维空间 scatter3d，借助 WebGL 可以渲染大规模的数据点 scattergl。\n\n\n表格 6.2: plotly 包支持绘制的散点图类型\n\n\n\n类型\n名称\n\n\n\nscatter\n二维平面散点图\n\n\nscatter3d\n三维立体散点图\n\n\nscattergl\n散点图（WebGL 版）\n\n\nscatterpolar\n极坐标下散点图\n\n\nscatterpolargl\n极坐标下散点图（WebGL 版）\n\n\nscattergeo\n地理坐标下散点图\n\n\nscattermapbox\n地理坐标下散点图（MapBox 版）\n\n\nscattercarpet\n地毯图\n\n\nscatterternary\n三元图\n\n\n\n\n\n\n图 6.6 展示斐济及其周边的地震分布\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  type = \"scatter\", mode = \"markers\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\")\n  )\n\n\n\n\n\n\n\n\n图 6.6: 普通散点图\n\n\n\n\n\n6.2.2 柱形图\n\n# https://plotly.com/r/reference/bar/\nplotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"bar\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\n\n\n\n\n\n图 6.7: 柱形图\n\n\n\n\n6.2.3 曲线图\n\nplotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"scatter\",\n  mode = \"markers+lines\", line = list(shape = \"spline\")\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\n\n\n\n\n\n图 6.8: 曲线图\n\n\n\n\n6.2.4 直方图\n地震次数随震级的分布变化，下 图 6.9 为频数分布图\n\n# https://plotly.com/r/reference/histogram/\nplotly::plot_ly(quakes, x = ~mag, type = \"histogram\") |&gt; \n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"次数\")\n  )\n\n\n\n\n\n\n\n\n图 6.9: 地震震级的频数分布图\n\n\n\n\n地震震级的概率分布，下 图 6.10 为频率分布图\n\nplotly::plot_ly(\n  data = quakes, x = ~mag, type = \"histogram\",\n  histnorm = \"probability\",\n  marker = list(\n    color = \"lightblue\",\n    line = list(color = \"white\", width = 2)\n  )\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"频率\")\n  )\n\n\n\n\n\n\n\n\n图 6.10: 地震震级的频率分布图\n\n\n\n\nhistnorm = \"probability\" 意味着纵轴表示频率，即每个窗宽下地震次数占总地震次数的比例。地震常常发生在地下，不同的深度对应着不同的地质构造、不同的地震成因，下 图 6.11 展示海平面下不同深度的地震震级分布。\n\nquakes$depth_bin &lt;- cut(quakes$depth, breaks = 150 * 0:5)\n\n\nplotly::plot_ly(quakes,\n  x = ~mag, colors = \"viridis\",\n  color = ~depth_bin, type = \"histogram\"\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"次数\")\n  )\n\n\n\n\n\n\n\n\n图 6.11: 地震震级的频率分布图\n\n\n\n\n\n6.2.5 箱线图\n\nplotly::plot_ly(quakes,\n  x = ~depth_bin, y = ~mag, colors = \"viridis\",\n  color = ~depth_bin, type = \"box\"\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"深度\"),\n    yaxis = list(title = \"震级\")\n  )\n\n\n\n\n\n\n图 6.12: 不同深度下地震震级的分布\n\n\n\n\nplotly::plot_ly(quakes,\n  x = ~depth_bin, y = ~mag, split = ~depth_bin,\n  type = \"violin\", color = ~depth_bin, colors = \"viridis\",\n  box = list(visible = TRUE),\n  meanline = list(visible = TRUE)\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"深度\"),\n    yaxis = list(title = \"震级\")\n  )\n\n\n\n\n\n\n图 6.13: 不同深度下地震震级的分布\n\n\n\n\n6.2.6 热力图\nplotly 整合了开源的 Mapbox GL JS，可以使用 Mapbox 提供的瓦片地图服务（Mapbox Tile Maps），对空间点数据做核密度估计，展示热力分布，如 图 6.14 所示。图左上角为所罗门群岛（Solomon Islands）、瓦努阿图（Vanuatu）和新喀里多尼亚（New Caledonia），图下方为新西兰北部的威灵顿（Wellington）和奥克兰（Auckland），图中部为斐济（Fiji）。\n\nplotly::plot_ly(\n  data = quakes, lat = ~lat, lon = ~long, radius = 10,\n  type = \"densitymapbox\", coloraxis = \"coloraxis\"\n) |&gt;\n  plotly::layout(\n    mapbox = list(\n      style = \"stamen-terrain\", zoom = 3,\n      center = list(lon = 180, lat = -25)\n    ),\n    coloraxis = list(colorscale = \"Viridis\")\n  )\n\n\n\n\n\n\n\n\n图 6.14: 空间点数据的核密度估计\n\n\n\n\n图中设置瓦片地图的风格 style 为 \"stamen-terrain\"，还可以使用其他开放的栅格瓦片地图服务，比如 \"open-street-map\" 和 \"carto-positron\"。如果使用 MapBox 提供的矢量瓦片地图服务，则需要访问令牌 Mapbox Access Token。图中设置中心坐标 center 以及缩放倍数 zoom，目的是突出图片中的数据区域。设置调色板 Viridis 展示热力分布，黄色团块的地方表示地震频次高。\n\n6.2.7 面量图\n在之前我们介绍过用 ggplot2 绘制地区分布图，实际上，地区分布图还有别名，如围栏图、面量图等。本节使用 plotly 绘制交互式的地区分布图，如 图 6.15 所示。\n\n# https://plotly.com/r/reference/choropleth/\ndat &lt;- data.frame(state.x77,\n  stats = rownames(state.x77),\n  stats_abbr = state.abb\n)\n# 绘制图形\nplotly::plot_ly(\n  data = dat,\n  type = \"choropleth\",\n  locations = ~stats_abbr,\n  locationmode = \"USA-states\",\n  colorscale = \"Viridis\",\n  colorbar = list(title = list(text = \"人均收入\")),\n  z = ~Income\n) |&gt;\n  plotly::layout(\n    geo = list(scope = \"usa\"),\n    title = \"1974年美国各州的人均收入\"\n  )\n\n\n\n\n\n\n\n\n图 6.15: 1974 年美国各州的人均收入\n\n\n\n\n\n6.2.8 动态图\n本节参考 plotly 包的官方示例渐变动画，数据来自 SVN 代码提交日志，统计 Martin Maechler 和 Brian Ripley 的年度代码提交量，他们是 R Core Team 非常重要的两位成员，长期参与维护 R 软件及社区。下图展示 1999-2022 年 Martin Maechler 和 Brian Ripley 的代码提交量变化。\n\n# https://plotly.com/r/animations/\ntrunk_year_author &lt;- aggregate(data = svn_trunk_log, revision ~ year + author, FUN = length)\n# https://plotly.com/r/cumulative-animations/\naccumulate_by &lt;- function(dat, var) {\n  var &lt;- lazyeval::f_eval(f = var, data = dat)\n  lvls &lt;- plotly:::getLevels(var) \n  dats &lt;- lapply(seq_along(lvls), function(x) {\n    cbind(dat[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])\n  })\n  dplyr::bind_rows(dats)\n}\n\nsubset(trunk_year_author, year &gt;= 1999 & author %in% c(\"ripley\", \"maechler\")) |&gt;\n  accumulate_by(~year) |&gt;\n  plotly::plot_ly(\n    x = ~year, y = ~revision, split = ~author,\n    frame = ~frame, type = \"scatter\", mode = \"lines\",\n    line = list(simplyfy = F)\n  ) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  ) |&gt;\n  plotly::animation_opts(\n    frame = 100, transition = 0, redraw = FALSE\n  ) |&gt;\n  plotly::animation_button(\n    visible = TRUE, # 显示播放按钮\n    label = \"播放\", # 按钮文本\n    font = list(color = \"gray\")# 文本颜色\n  ) |&gt;\n  plotly::animation_slider(\n    currentvalue = list(\n      prefix = \"年份 \",\n      xanchor = \"right\",\n      font = list(color = \"gray\", size = 30)\n    )\n  )\n\n\n\n\n\n\n图 6.16: 1999-2022 年 Martin Maechler 和 Brian Ripley 的代码提交量变化\n\n\n\nlazyeval 的非标准计算采用 Base R 实现，目前，已经可以被 rlang 替代。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-plotly-common-tricks",
    "href": "interactive-graphics.html#sec-plotly-common-tricks",
    "title": "6  交互图形",
    "section": "\n6.3 常用技巧",
    "text": "6.3 常用技巧\n\n6.3.1 数学公式\n正态分布的概率密度函数形式如下：\n\\[\n\\begin{aligned}\n& f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\{-\\frac{(x -\\mu)^2}{2\\sigma^2}\\}\n\\end{aligned}\n\\]\n下图展示两个正态分布，分别是 \\(\\mathcal{N}(3, 1^2)\\) 和 \\(\\mathcal{N}(2, 1.5^2)\\) 。函数 plotly::TeX() 包裹 LaTeX 书写的数学公式，plotly 包调用 MathJax 库渲染图中的公式符号。\n\n代码x &lt;- seq(from = -4, to = 8, length.out = 193)\ny1 &lt;- dnorm(x, mean = 3, sd = 1)\ny2 &lt;- dnorm(x, mean = 2, sd = 1.5)\n\nplotly::plot_ly(\n  x = x, y = y1, type = \"scatter\", mode = \"lines\",\n  fill = \"tozeroy\", fillcolor = \"rgba(0, 204, 102, 0.2)\",\n  text = ~ paste0(\n    \"x：\", x, \"&lt;br&gt;\",\n    \"y：\", round(y1, 3), \"&lt;br&gt;\"\n  ),\n  hoverinfo = \"text\",\n  name = plotly::TeX(\"\\\\mathcal{N}(3,1^2)\"),\n  line = list(shape = \"spline\", color = \"#009B95\")\n) |&gt; \n  plotly::add_trace(\n    x = x, y = y2, type = \"scatter\", mode = \"lines\",\n    fill = \"tozeroy\", fillcolor = \"rgba(51, 102, 204, 0.2)\",\n    text = ~ paste0(\n      \"x：\", x, \"&lt;br&gt;\",\n      \"y：\", round(y2, 3), \"&lt;br&gt;\"\n    ),\n    hoverinfo = \"text\",\n    name = plotly::TeX(\"\\\\mathcal{N}(2, 1.5^2)\"),\n    line = list(shape = \"spline\", color = \"#403173\")\n  ) |&gt; \n  plotly::layout(\n    xaxis = list(showgrid = F, title = plotly::TeX(\"x\")),\n    yaxis = list(showgrid = F, title = plotly::TeX(\"f(x)\")),\n    legend = list(x = 0.8, y = 1, orientation = \"v\")\n  ) |&gt; \n  plotly::config(mathjax = \"cdn\", displayModeBar = FALSE)\n\n\n\n\n\n\n\n\n\n图 6.17: 设置数学公式\n\n\n\n\n\n6.3.2 动静转化\n在出版书籍，发表期刊文章，打印纸质文稿等场景中，需要将交互图形导出为静态图形，再插入到正文之中。\n\nlibrary(ggplot2)\np &lt;- ggplot(data = quakes, aes(x = long, y = lat)) +\n  geom_point()\np\n\n\n\n\n\n\n图 6.18: ggplot2 绘制的静态图形\n\n\n\n\n将 ggplot2 包绘制的散点图转化为交互式的散点图，只需调用 plotly 包的函数 ggplotly()。\n\nplotly::ggplotly(p)\n\n\n\n\n\n当使用配置函数 config() 设置参数选项 staticPlot = TRUE，可将原本交互式的动态图形转为非交互式的静态图形。\n\nplotly::ggplotly(p) |&gt; \n  plotly::config(staticPlot = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n函数 style() 设置动态点的注释，比如点横纵坐标、坐标文本，以及整个注释标签的样式，如背景色。\n\nplotly::ggplotly(p, dynamicTicks = \"y\") |&gt; \n  plotly::style(hoveron = \"points\", hoverinfo = \"x+y+text\", \n        hoverlabel = list(bgcolor = \"white\"))\n\n\n\n\n\n\n\norca (Open-source Report Creator App) 软件针对 plotly.js 库渲染的图形具有很强的导出功能，安装 orca 后，plotly::orca() 函数可以将基于 htmlwidgets 的 plotly 图形对象导出为 PNG、PDF 和 SVG 等格式的高质量静态图片。\n\n# orca\nplotly::orca(p, \"plotly-quakes.svg\")\n# kaleido\nplotly::save_image(p, \"plotly-quakes.svg\")\n\n\n6.3.3 坐标系统\nquakes 是一个包含空间位置的数据集，plotly 的 scattergeo 图层 针对空间数据提供多边形矢量边界地图数据，支持设定坐标参考系。下 图 6.19 增加了地震震级维度，在空间坐标参考系下绘制散点。\n\nplotly::plot_ly(\n  data = quakes,\n  lon = ~long, lat = ~lat,\n  type = \"scattergeo\", mode = \"markers\",\n  text = ~ paste0(\n    \"站点：\", stations, \"&lt;br&gt;\",\n    \"震级：\", mag\n  ),\n  marker = list(\n    color = ~mag, colorscale = \"Viridis\",\n    size = 10, opacity = 0.8,\n    line = list(color = \"white\", width = 1)\n  )\n) |&gt;\n  plotly::layout(geo = list(\n    showland = TRUE,\n    landcolor = plotly::toRGB(\"gray95\"),\n    countrycolor = plotly::toRGB(\"gray85\"),\n    subunitcolor = plotly::toRGB(\"gray85\"),\n    countrywidth = 0.5,\n    subunitwidth = 0.5,\n    lonaxis = list(\n      showgrid = TRUE,\n      gridwidth = 0.5,\n      range = c(160, 190),\n      dtick = 5\n    ),\n    lataxis = list(\n      showgrid = TRUE,\n      gridwidth = 0.5,\n      range = c(-40, -10),\n      dtick = 5\n    )\n  ))\n\n\n\n\n\n\n\n\n图 6.19: 空间点数据图\n\n\n\n\n\n6.3.4 添加水印\n在图片右下角添加水印图片\n\nplotly::plot_ly(quakes,\n  x = ~long, y = ~lat, color = ~mag, \n  type = \"scatter\", mode = \"markers\"\n) |&gt; \n  plotly::config(staticPlot = TRUE) |&gt; \n  plotly::layout(\n    images = list( # 水印图片\n      source = \"https://images.plot.ly/language-icons/api-home/r-logo.png\",\n      xref = \"paper\", # 页面参考\n      yref = \"paper\",\n      x = 0.90, # 横坐标\n      y = 0.20, # 纵坐标\n      sizex = 0.2, # 长度\n      sizey = 0.2, # 宽度\n      opacity = 0.5 # 透明度\n    )\n  )\n\n\n\n\n\n\n图 6.20: 添加水印图片\n\n\n\n\n6.3.5 多图布局\n将两个图形做上下排列\n\np1 &lt;- plotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"bar\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\np2 &lt;- plotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"scatter\",\n  mode = \"markers+lines\", line = list(shape = \"spline\")\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\nhtmltools::tagList(p1, p2)\n\n\n\n\n\n\n\n图 6.21: 上下布局\n\n\n\nplotly 包提供的函数 subplot() 专门用于布局排列，下图的上下子图共享 x 轴。\n\nplotly::subplot(plotly::style(p1, showlegend = FALSE), \n                plotly::style(p2, showlegend = FALSE), \n                nrows = 2, margin = 0.05, shareX = TRUE, titleY = TRUE)\n\n\n\n\n\n\n图 6.22: 上下布局\n\n\n\n下图展示更加灵活的布局形式，嵌套使用布局函数 subplot() 实现。\n\np11 &lt;- plotly::subplot(plotly::style(p1, showlegend = FALSE),\n  plotly::style(p2, showlegend = FALSE),\n  nrows = 1, margin = 0.05, shareY = TRUE, titleX = TRUE\n)\n\nplotly::subplot(p11,\n  plotly::style(p2, showlegend = FALSE),\n  nrows = 2, margin = 0.05, shareY = FALSE, titleX = FALSE\n)\n\n\n\n\n\n\n图 6.23: 灵活布局\n\n\n\n\n6.3.6 图表联动\ncrosstalk 包可将 plotly 包绘制的图形和 DT 包制作的表格联动起来。plotly 绘制交互图形，在图形上用套索工具筛选出来的数据显示在表格中。\n\nlibrary(crosstalk)\n# quakes 数据变成可共享的\nquakes_sd &lt;- SharedData$new(quakes)\n# 绘制交互图形\np &lt;- plotly::plot_ly(quakes_sd, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers() |&gt; \n  plotly::highlight(on = \"plotly_selected\", off = \"plotly_deselect\")\n# 制作表格\nd &lt;- DT::datatable(quakes_sd, options = list(dom = \"tp\"))\n# 将图表组合一起展示\nbscols(list(p, d))\n\n\n\n\n\n\n\n\n\n\n\n\n\n图 6.24: 图表联动",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html",
    "href": "interactive-tables.html",
    "title": "7  交互表格",
    "section": "",
    "text": "7.1 基础功能",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-basic",
    "href": "interactive-tables.html#sec-table-basic",
    "title": "7  交互表格",
    "section": "",
    "text": "7.1.1 创建表格\n\n7.1.2 添加标题\n\n7.1.3 添加注释\n\n7.1.4 水平滚动\n\n7.1.5 垂直滚动\n\n7.1.6 数据分页\n\n7.1.7 适应宽度\n\n7.1.8 行列分组\n\n7.1.9 列格式化\n\n7.1.10 数据配色\n\nlibrary(tibble)\n\ndat &lt;- tribble(\n  ~name1, ~name2,\n  as.character(htmltools::tags$b(\"加粗\")), as.character(htmltools::a(href = \"https://rstudio.com\", \"超链\")), # 支持超链接\n  as.character(htmltools::em(\"强调\")), '&lt;a href=\"#\" onclick=\"alert(\\'Hello World\\');\"&gt;Hello&lt;/a&gt;',\n  as.character(htmltools::span(style = \"color:red\", \"正常\")), \"正常\"\n)\n\n根据数据的大小配上颜色\n\ncolorize_num &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", x),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", x)\n  )\n}\ncolorize_pct &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", scales::percent(x, accuracy = 0.01)),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", scales::percent(x, accuracy = 0.01))\n  )\n}\n\ncolorize_pp &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", paste0(round(100*x, digits = 2), \"PP\")),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", paste0(round(100*x, digits = 2), \"PP\"))\n  )\n}\n\ncolorize_text &lt;- function(x, color = \"red\") {\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", color, x )\n}\n\n\nlibrary(DT)\ndatatable(\n  data = dat, escape = FALSE, \n  colnames = c(colorize_text(\"第1列\", \"red\"), \n               as.character(htmltools::em(\"第2列\"))),\n  options = list(\n    pageLength = 5, # 每页显示5行\n    dom = \"t\"\n  )\n)\n\n\n表格 7.1: 数据配色\n\n\n\n\n\n\n\n\n\nBase R 内置的 R 包含有丰富的数据集，非常适合演示图形和阐述统计理论，后面技术和理论部分的介绍大多围绕内置的数据集展开，数据集及其描述如下表所示：\n\n# 抽取 R 包信息\nPkgs &lt;- sapply(list.files(R.home(\"library\")), function(x) {\n  packageDescription(pkg = x, fields = \"Priority\")\n})\n# 抽取内置 R 包列表\nCorePkgs &lt;- names(Pkgs[Pkgs %in% c(\"base\", \"recommended\") & !is.na(Pkgs)])\n# 抽取 R 包的数据集\nBaseDataSets &lt;- data(package = CorePkgs)$results[, c(\"Package\", \"Item\", \"Title\")]\n\nlibrary(DT)\ndatatable(BaseDataSets,\n  rownames = FALSE, # 不显示行名\n  extensions = c(\"Buttons\", \"RowGroup\"),\n  options = list(\n    pageLength = 10, # 每页显示的行数\n    language = list(url = \"//cdn.datatables.net/plug-ins/1.10.11/i18n/Chinese.json\"), # 汉化\n    dom = \"Bfrtp\", # 去掉显示行数 i、过滤 f 的能力，翻页用 p 表示\n    ordering = F, # 去掉列排序\n    buttons = c(\"copy\", \"csv\", \"excel\", \"print\"), # 提供打印按钮\n    rowGroup = list(dataSrc = 0), # 按 Package 列分组\n    columnDefs = list(\n      list(className = \"dt-center\", targets = 0), # 不显示行名，则 targets 从 0 开始，否则从 1 开始\n      list(visible = FALSE, targets = 0) # 不显示 Package 列\n    )\n  )\n)\n\n\n表格 7.2: Base R 包内置的数据集",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-extend",
    "href": "interactive-tables.html#sec-table-extend",
    "title": "7  交互表格",
    "section": "\n7.2 扩展功能",
    "text": "7.2 扩展功能\n\n7.2.1 汉化表格\n\n7.2.2 下载数据",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-reactable",
    "href": "interactive-tables.html#sec-table-reactable",
    "title": "7  交互表格",
    "section": "\n7.3 其它工具",
    "text": "7.3 其它工具",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html",
    "href": "interactive-applications.html",
    "title": "8  交互应用",
    "section": "",
    "text": "8.1 简单示例\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  sliderInput(inputId = \"n\", label = \"观测记录的数目\", \n              min = 1, max = nrow(faithful), value = 100),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    hist(faithful$eruptions[seq_len(input$n)],\n      breaks = 40,\n      main = \"美国黄石公园喷泉\",\n      xlab = \"喷发持续时间\"\n    )\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-demo",
    "href": "interactive-applications.html#sec-shiny-demo",
    "title": "8  交互应用",
    "section": "",
    "text": "8.1.1 UI 前端\n\n8.1.2 Server 后端",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-widget",
    "href": "interactive-applications.html#sec-shiny-widget",
    "title": "8  交互应用",
    "section": "\n8.2 Shiny 组件",
    "text": "8.2 Shiny 组件\n组件又很多，下面想重点介绍 4 个，它们使用频次很高，很有代表性。\n\n8.2.1 筛选器\n单个筛选器、独立筛选器、筛选器联动\n\n8.2.2 输入框\n数值型、文本型\n\n8.2.3 动作按钮\n提交按钮、响应按钮\n\n8.2.4 书签\n书签记录输入状态，链接可以指向页面状态\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  sliderInput(inputId = \"n\", label = \"观测记录的数目\", \n              min = 1, max = nrow(faithful), value = 100),\n  plotOutput(\"plot\"),\n  bookmarkButton(id = \"bookmark1\", label = \"书签\", title = \"记录、分享此时应用的状态\")\n)\n\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    hist(faithful$eruptions[seq_len(input$n)],\n      breaks = 40,\n      main = \"美国黄石公园喷泉\",\n      xlab = \"喷发持续时间\"\n    )\n  })\n}\n\nenableBookmarking(store = \"url\")\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-extensions",
    "href": "interactive-applications.html#sec-shiny-extensions",
    "title": "8  交互应用",
    "section": "\n8.3 Shiny 扩展",
    "text": "8.3 Shiny 扩展\n页面布局\n\n\nshinydashboard / shinydashboardPlus Shiny 应用\n\nflexdashboard R Markdown 文档中制作 Shiny 应用\nbs4Dash\n\n交互表格\n\nDT\nreactable\n\n交互图形\n\nplotly\nggiraph\n\n\n8.3.1 页面布局\n\n8.3.2 交互表格\n下面在 Shiny 应用中插入 DT 包制作的交互表格\n\n# 前端\nlibrary(shiny)\nui &lt;- fluidPage(\n  # 应用的标题名称\n  titlePanel(\"鸢尾花数据集\"),\n  # 边栏\n  fluidRow(\n    column(12, DT::dataTableOutput(\"table\"))\n  )\n)\n\n# 服务端\nserver &lt;- function(input, output, session) {\n  output$table &lt;- DT::renderDataTable(iris,\n    options = list(\n      pageLength = 5, # 每页显示5行\n      initComplete = I(\"function(settings, json) {alert('Done.');}\")\n    ), server = F\n  )\n}\n\nshinyApp(ui, server)\n\n\n\n\n\n\n\n重要\n\n\n\n加载 shiny 包后再加载 DT 包，函数 dataTableOutput() 和renderDataTable() 显示冲突，因为两个 R 包都有这两个函数。在创建 shiny 应用的过程中，如果我们需要呈现动态表格，就需要使用 DT 包的 DT::dataTableOutput() 和 DT::renderDataTable() ，否则会报错，详见 https://github.com/rstudio/shiny/issues/2653。\n\n\nreactable 基于 JS 库 React Table 提供交互式表格渲染，和 shiny 无缝集成，是替代 DT 的不二选择，在 app.R 用 reactable 包的 reactableOutput() 和 renderReactable() 函数替代 shiny 里面的 dataTableOutput() 和 renderDataTable()。 再也不用忍受 DT 和 shiny 的函数冲突了，且其覆盖测试达到 99%。\n\nlibrary(shiny)\n\n下面在 Shiny 应用中插入 reactable 包制作的交互表格\n\nlibrary(shiny)\nlibrary(reactable)\n\nui &lt;- fluidPage(\n  reactableOutput(\"table\")\n)\n\nserver &lt;- function(input, output) {\n  output$table &lt;- renderReactable({\n    reactable(iris,\n      filterable = TRUE, # 过滤\n      searchable = TRUE, # 搜索\n      showPageSizeOptions = TRUE, # 页面大小\n      pageSizeOptions = c(5, 10, 15), # 页面大小可选项\n      defaultPageSize = 10, # 默认显示10行\n      highlight = TRUE, # 高亮选择\n      striped = TRUE, # 隔行高亮\n      fullWidth = FALSE, # 默认不要全宽填充，适应数据框的宽度\n      defaultSorted = list(\n        Sepal.Length = \"asc\", # 由小到大排序\n        Petal.Length = \"desc\" # 由大到小\n      ),\n      columns = list(\n        Sepal.Width = colDef(style = function(value) { \n          # Sepal.Width 添加颜色标记\n          if (value &gt; 3.5) {\n            color &lt;- \"#008000\"\n          } else if (value &gt; 2) {\n            color &lt;- \"#e00000\"\n          } else {\n            color &lt;- \"#777\"\n          }\n          list(color = color, fontWeight = \"bold\") # 字体加粗\n        })\n\n      )\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n除了 DT 和 reactable 包，其它支持 Shiny 集成的 R 包还有 gt 、formattable 和 kableExtra 等。\n\n8.3.3 交互图形\nggiraph 包",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-dashboard",
    "href": "interactive-applications.html#sec-shiny-dashboard",
    "title": "8  交互应用",
    "section": "\n8.4 Shiny 仪表盘",
    "text": "8.4 Shiny 仪表盘\ndashboard 翻译过来叫仪表盘，就是驾驶仓的那个玩意，形象地表达作为掌舵者应该关注的对象。R 包 shiny 出现后，仪表盘的制作显得非常容易，也很快形成了一个生态，比如 shinydashboard、 flexdashboard 等，此外 bs4Dash 基于 Bootstrap 4 的仪表盘，目前 shiny 和 rmarkdown 都在向 Bootstrap 4 升级，这是未来的方向。 shinydashboardPlus 主要目的在于扩展 shinydashboard 包\n\n8.4.1 shinydashboard 包\n将如下内容保存为 app.R 文件。\n\nlibrary(shiny)\nlibrary(shinydashboard)\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Basic dashboard\"),\n  ## 边栏\n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Dashboard\", tabName = \"dashboard\", icon = icon(\"dashboard\")),\n      menuItem(\"Widgets\", tabName = \"widgets\", icon = icon(\"th\"))\n    )\n  ),\n  ## 主体内容\n  dashboardBody(\n    tabItems(\n      # 第一个 Tab 页内容\n      tabItem(\n        tabName = \"dashboard\",\n        fluidRow(\n          box(plotOutput(\"plot1\", height = 250)),\n          box(\n            title = \"Controls\",\n            sliderInput(\"slider\", \"Number of observations:\", 1, 100, 50)\n          )\n        )\n      ),\n\n      # 第二个 Tab 页内容\n      tabItem(\n        tabName = \"widgets\",\n        h2(\"Widgets tab content\")\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  set.seed(122)\n  histdata &lt;- rnorm(500)\n\n  output$plot1 &lt;- renderPlot({\n    data &lt;- histdata[seq_len(input$slider)]\n    hist(data)\n  })\n}\n\nshinyApp(ui, server)\n\n\n8.4.2 shinydashboardPlus 包\nshinydashboardPlus 包的函数 descriptionBlock()\n\nlibrary(shiny)\nlibrary(shinydashboard)\nlibrary(shinydashboardPlus)\n\nshinyApp(\n  ui = dashboardPage(\n    dashboardHeader(),\n    dashboardSidebar(),\n    dashboardBody(\n      box(\n        solidHeader = FALSE,\n        title = \"状态概览\",\n        background = NULL,\n        width = 4,\n        status = \"danger\",\n        footer = fluidRow(\n          column(\n            width = 6,\n            descriptionBlock(\n              number = \"17%\",\n              numberColor = \"green\",\n              numberIcon = \"fa fa-caret-up\",\n              header = \"$35,210.43\",\n              text = \"总收入\",\n              rightBorder = TRUE,\n              marginBottom = FALSE\n            )\n          ),\n          column(\n            width = 6,\n            descriptionBlock(\n              number = \"18%\",\n              numberColor = \"red\",\n              numberIcon = \"fa fa-caret-down\",\n              header = \"1200\",\n              text = \"目标完成\",\n              rightBorder = FALSE,\n              marginBottom = FALSE\n            )\n          )\n        )\n      )\n    ),\n    title = \"Description Blocks\"\n  ),\n  server = function(input, output) { }\n)\n\n\n8.4.3 bs4Dash 包\n\nlibrary(bs4Dash)\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Basic dashboard\"),\n  dashboardSidebar(),\n  dashboardBody(\n    # Boxes need to be put in a row (or column)\n    fluidRow(\n      box(plotOutput(\"plot1\", height = 250)),\n      \n      box(\n        title = \"Controls\",\n        sliderInput(\"slider\", \"Number of observations:\", 1, 100, 50)\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  set.seed(122)\n  histdata &lt;- rnorm(500)\n  \n  output$plot1 &lt;- renderPlot({\n    data &lt;- histdata[seq_len(input$slider)]\n    hist(data)\n  })\n}\n\nshinyApp(ui, server)\n\n\n8.4.4 miniUI 包\nminiUI 包制作迷你版 Shiny 应用，适用于小屏幕显示。\n\nlibrary(shiny)\nlibrary(miniUI)\nlibrary(leaflet)\nlibrary(ggplot2)\n\nui &lt;- miniPage(\n  gadgetTitleBar(\"Shiny gadget example\"),\n  miniTabstripPanel(\n    miniTabPanel(title = \"参数\",\n      icon = icon(\"sliders\"),\n      miniContentPanel(\n        sliderInput(\"year\", \"年份\", 1978, 2010, c(2000, 2010), sep = \"\")\n      )\n    ),\n    miniTabPanel(title = \"可视化\",\n      icon = icon(\"area-chart\"),\n      miniContentPanel(\n        plotOutput(\"quakes\", height = \"100%\")\n      )\n    ),\n    miniTabPanel(title = \"地图\",\n      icon = icon(\"map-o\"),\n      miniContentPanel(\n        padding = 0,\n        leafletOutput(\"map\", height = \"100%\")\n      ),\n      miniButtonBlock(\n        actionButton(\"resetMap\", \"Reset\")\n      )\n    ),\n    miniTabPanel(title = \"数据\",\n      icon = icon(\"table\"),\n      miniContentPanel(\n        DT::dataTableOutput(\"table\")\n      )\n    ),\n    selected = \"Map\"\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  output$quakes &lt;- renderPlot({\n    ggplot(quakes, aes(long, lat)) +\n      geom_point()\n  })\n\n  output$map &lt;- renderLeaflet({\n    force(input$resetMap)\n\n    leaflet(quakes, height = \"100%\") |&gt;\n      addTiles() |&gt;\n      addMarkers(lng = ~long, lat = ~lat)\n  })\n\n  output$table &lt;- DT::renderDataTable({\n    quakes\n  })\n\n  observeEvent(input$done, {\n    stopApp(TRUE)\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-themes",
    "href": "interactive-applications.html#sec-shiny-themes",
    "title": "8  交互应用",
    "section": "\n8.5 Shiny 主题",
    "text": "8.5 Shiny 主题\n\n8.5.1 bslib 包\n\nbslib\n\n8.5.2 shinymaterial 包\nshinymaterial 包实现 Material Design\n\nlibrary(shiny)\nlibrary(shinymaterial)\n\nui &lt;- material_page(\n  title = \"用户画像\",\n  nav_bar_fixed = TRUE,\n  # 每个 sidebar 内容\n  material_side_nav(\n    fixed = TRUE,\n    # Place side-nav tabs within side-nav\n    material_side_nav_tabs(\n      side_nav_tabs = c(\n        \"数据汇总\" = \"tab_1\",\n        \"趋势信息\" = \"tab_2\"\n      ),\n      icons = c(\"cast\", \"insert_chart\")\n    )\n  ),\n  # 每个 tab 页面的内容\n  material_side_nav_tab_content(\n    side_nav_tab_id = \"tab_1\",\n    tags$h2(\"第一个tab页\")\n  ),\n  material_side_nav_tab_content(\n    side_nav_tab_id = \"tab_2\",\n    tags$h2(\"第二个tab页\")\n  )\n)\n\nserver &lt;- function(input, output) {\n\n}\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-faster",
    "href": "interactive-applications.html#sec-shiny-faster",
    "title": "8  交互应用",
    "section": "\n8.6 Shiny 优化",
    "text": "8.6 Shiny 优化\n提升 shiny 仪表盘访问性能的4个建议",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-deployment",
    "href": "interactive-applications.html#sec-shiny-deployment",
    "title": "8  交互应用",
    "section": "\n8.7 Shiny 部署",
    "text": "8.7 Shiny 部署\n\n8.7.1 promises 并发\nshiny 异步编程实现并发访问，多人同时访问 Shiny 应用的情况下，解决必须等另一个人完成访问的情况下才能继续访问的问题。\n\nlibrary(shiny)\nlibrary(future)\nlibrary(promises)\n\nplan(multiprocess)\n\nui &lt;- fluidPage(\n  h2(\"测试异步下载\"),\n  tags$ol(\n    tags$li(\"Verify that plot appears below\"),\n    tags$li(\"Verify that pressing Download results in 5 second delay, then rock.csv being downloaded\"),\n    tags$li(\"Check 'Throw on download?' checkbox and verify that pressing Download results in 5 second delay, then error, as well as stack traces in console\")\n  ),\n  hr(),\n  checkboxInput(\"throw\", \"Throw on download?\"),\n  downloadButton(\"download\", \"下载 (等待5秒)\"),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output, session) {\n  output$download &lt;- downloadHandler(\"rock.csv\", function(file) {\n    future({Sys.sleep(5)}) %...&gt;%\n      {\n        if (input$throw) {\n          stop(\"boom\")\n        } else {\n          write.csv(rock, file)\n        }\n      }\n  })\n\n  output$plot &lt;- renderPlot({\n    plot(cars)\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-alternative",
    "href": "interactive-applications.html#sec-shiny-alternative",
    "title": "8  交互应用",
    "section": "\n8.8 Shiny 替代品",
    "text": "8.8 Shiny 替代品\nR Markdown + Shiny 文档\n\ncrosstalk 交互\nflexdashboard 布局\nDT 交互表格\nleaflet 交互地图\nggiraph 交互图形\n\nQuarto Dashboard 文档",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-showcases",
    "href": "interactive-applications.html#sec-shiny-showcases",
    "title": "8  交互应用",
    "section": "\n8.9 Shiny 案例",
    "text": "8.9 Shiny 案例\n\n\nradiant 探索性数据分析解决方案",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-summary",
    "href": "interactive-applications.html#sec-shiny-summary",
    "title": "8  交互应用",
    "section": "\n8.10 总结",
    "text": "8.10 总结\n事实上，作为 BI 工程师，相当一部分工作是与数据开发结合的。从 Kafka 接入埋点上报的原始日志（ODS 层）、清洗抽取特定业务/领域内的数据（Fact 事实层）、面向某一类任务的主题数据（ topic 主题层）、面向特定数据产品的应用数据 （app 应用层）。\n\n数据仓库 Hive 数据开发：事实、主题和应用层\n数据计算 Spark 数据开发工具 Spark SQL / Hive SQL 任务调度\n数据报表 MySQL / Doris 数据同步工具 Hive2MySQL 同步应用层数据\n数据展示 Dashboard 应用开发工具 Shiny RStudio Shiny Server\n\n报表开发从数据仓库的 DWD 层开始，可能一些业务原因，我们需要从 ODS 层甚至从点击流的日志数据开始，经过数据清洗、提取、聚合成为支撑BI报表最底层的基础表，存储在 Hive 中，然后对这一系列的基础表根据BI展示的需要进行第二层聚合形成中间表，这两层数据根据业务情况做增量更新或者全量更新，并将中间表同步到 MySQL 仓库中，全量更新的情况，往往更新数据比较大，建议用 sqoop 做数据的同步。创建第二层的中间表稍有些灵活性，原则是在中间表之上对应的数据操作和可视化是容易实现且效率较高的，否则应该构造第三层的中间表，绝不能将大规模的数据集直接导入 R 中进行分析和可视化，拖慢前端展示的速度，占用过多的服务器资源。\n\n\n\n\n\n\n\n图 8.1: Shiny 生态系统\n\n\n\n\n连接数据库。根据数据库的情况选择相应的 R 接口包，比如连接 MySQL 数据库可以用 RMySQL 包，值得一提， odbc 包支持连接相当多的数据库。\n数据操作。根据需要处理的数据规模，可以选择 Base R、 data.table 或者 dplyr 做数据操作，推荐和管道操作一起使用，增加代码可读性。\n交互表格。推荐 reactable 和 DT 包做数据呈现。\n交互图形。推荐功能强大的 plotly 包，可以先用 ggplot2 绘制，然后调用 plotly 包的 ggplotly() 函数将静态图转化为交互图。\n针对特定应用场景的其它交互可视化工具包，比如 leaflet 可以将地图嵌入 Shiny 应用， dygraphs 可以将时间序列塞进去。\nShiny 组件。shinyFeedback 提供用户输入的反馈。shinyWidgets 提供自定义 widget 的功能。miniUI 专为小屏设计，shinyMobile 在 IOS 和安卓手机上访问 shiny 应用。\nShiny 主题。比如 shinythemes 包可以统一配色，dashboardthemes 提供更加深度的主题，shinytableau 提供仿 Tableau 的 dashboard 框架。sass 在 CSS 样式层面重定义风格。bslib 通过 Bootstrap 3/4/5 定制 Shiny 和 R Markdown 主题。\nShiny 权限。shinymanager / shinyauthr 支持单个 shiny 应用的权限管理，firebase 提供访问权限设置 https://firebase.john-coene.com/。\nShiny 框架。ShinyStudio 打造基于容器架构的协作开发环境的开源解决方案，golem 构建企业级 shiny 应用的框架，RinteRface 开发的系列 R 包也试图打造一套完整的解决方案，并配有速查小抄 cheatsheets。\nShiny 部署。shiny-server 以网络服务的方式支持 shiny 应用，shinyproxy 提供企业级部署 shiny 应用的开源解决方案。\n\n自 RStudio 推出 Shiny 系列产品以来，一些公司进一步根据所需扩展和定制，比如 Appsilon、RinteRface、ThinkR-open、dreamRs 和datastorm-open 等。经过商业公司和个人开发者的努力，Shiny 生态非常庞大，资源非常丰富。\n\nShiny 入门 https://shiny.posit.co/r/getstarted/。\nShiny 扩展包 https://github.com/nanxstats/awesome-shiny-extensions。\nShiny 常用技巧和提示 https://github.com/daattali/advanced-shiny。\nShiny 各类资源列表 https://github.com/grabear/awesome-rshiny。\n\n特别值得一提，Shiny 方面的三本专著。\n\nHadley Wickham 的书 Mastering Shiny。\nColin Fay, Sébastien Rochette, Vincent Guyader, Cervan Girard 的书 Engineering Production-Grade Shiny Apps。\nDavid Granjon 的书 Outstanding User Interfaces with Shiny。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "documents-html.html",
    "href": "documents-html.html",
    "title": "9  HTML 文档",
    "section": "",
    "text": "9.1 文档元素\n无论是 R Markdown 还是 Quarto，都是站在巨人 Pandoc 的肩膀上，Pandoc 在普通 Markdown 的基础上提供了许多扩展支持，通过一些简单的标记，大大丰富了文档内容，下面介绍的内容适用于 R Markdown 和 Quarto，无论文档最终的输出格式如何。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-doc-elements",
    "href": "documents-html.html#sec-doc-elements",
    "title": "9  HTML 文档",
    "section": "",
    "text": "9.1.1 样式\n文字样式，如加粗、倾斜、上下标等。\n\n\n\n\n\n\nMarkdown 语法\n输出\n\n\n\n*斜体*, **加粗**, ***粗斜体***\n\n斜体, 加粗, 粗斜体\n\n\n\n上角标^2^ / 下角标~2~\n上角标2 / 下角标2\n\n\n\n~~删除线~~\n删除线\n\n\n`代码`\n代码\n\n\n\n9.1.2 图片\n其一插入现成的图片，其二插入代码生成的图片\n\n\n\n\n\n\n\n\n\n(a) versicolor 杂色鸢尾\n\n\n\n\n\n\n\n\n\n(b) setosa 山鸢尾\n\n\n\n\n\n\n\n\n\n(c) virginica 弗吉尼亚鸢尾\n\n\n\n\n\n\n图 9.1: 三种鸢尾花\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n图 9.2: 流程图\n\n\n\n\nggplot2 绘制的图形\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(aes(color = Species)) +\n  theme_classic()\n\n\n\n\n\n\n图 9.3: 一幅简单的 ggplot2 图形\n\n\n\n\n\n9.1.3 表格\nMarkdown 原生支持的表格和 knitr 包制作的表格。\n\n\n表格 9.1: 鸢尾花数据集\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n\n\n\n\n\nknitr::kable(head(iris, 3))\n\n\n表格 9.2: 鸢尾花数据集\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n\n\n\n\n\n\n\n\n9.1.4 列表\n常见的列表有无序列表、有序列表及其嵌套。\n\n\n表格 9.3: 几种列表\n\n\n\n\n\n\n\nMarkdown 语法\n输出\n\n\n\n* 无序列表\n    + 子条目 1\n    + 子条目 2\n        - 子子条目 1\n\n无序列表\n\n子条目 1\n子条目 2\n\n子子条目 1\n\n\n\n\n\n\n\n*   条目 2\n\n    继续 (缩进 4 格)\n\n\n条目 2\n继续 (缩进 4 格)\n\n\n\n\n1. 有序列表\n2. 条目 2\n    i) 子条目 1\n         A.  子子条目 1\n\n有序列表\n条目 2\n\n子条目 1\n\n子子条目 1\n\n\n\n\n\n\n\n(@)  第一个人是好的\n\n第二个人是坏的\n\n(@)  第三个人是丑陋的\n\n\n第一个人是好的\n\n第二个人是坏的\n\n第三个人是丑陋的\n\n\n\n\n::: {}\n1. 一个列表\n:::\n\n::: {}\n1. 又一个列表\n:::\n\n\n\n一个列表\n\n\n\n\n又一个列表\n\n\n\n\n\n术语\n: 定义\n\n术语\n\n定义\n\n\n\n\n\n\n\n\n在 (@) 中添加标识符，如 (@good) 就可以引用列表中的条目 (1)。\n\n9.1.5 引用\n除了引用外部书籍、文章、刊物等的内容，还有长文档内部的交叉引用，这项功能是非常需要的，涉及图、表、公式、定理，参考文献，列表条目等。\n\n9.1.6 脚注\n\nIf you imagine that this pen is Trellis, then Lattice is not this pen.1\n— Paul Murrell\n\n\n9.1.7 公式\n公式分两种情况，其一是行内公式，其二是行间公式。前者一对美元符号夹住数学公式，美元符号与字母之间不能有空格，比如 $\\beta$ 渲染出来的效果是 \\(\\beta\\) 。后者是两对美元符号夹住公式，比如 $$\\beta$$ 渲染出来的效果如下：\n\\[\\beta\\]\n行内公式一般用来写数学符号，行间公式一般用来排版数学公式，特别是多行公式。行间公式可以编号，也可以不编号，编号通常是了交叉引用。\n\\[\\mathbf{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\]\n排版行间公式有很多不同的 LaTeX 环境，最常见的有两种，一种是多个公式逐行排，一种是长公式折行，常常都要求对齐。举例来说，线性模型的两种表示方式，一种是矩阵向量式，一种是数据结构式，见 方程式 9.1 。\n\\[\n\\begin{aligned}\n\\mathbf{y} &= X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\\\\ny_i &= \\mathbf{x}_i\\boldsymbol{\\beta} + \\epsilon_i\n\\end{aligned}\n\\tag{9.1}\\]\n在行间公式中，使用 split 公式环境排版一个长公式，这个公式是折成多行的，表达一个计算过程。举例来说，线性模型回归系数的最小二乘估计 \\(\\hat{\\boldsymbol{\\beta}}\\) 的方差的计算过程，见 方程式 9.2 。\n\\[\n\\begin{split}\n\\mathsf{Var}\\{\\hat{\\boldsymbol{\\beta}}\\} & =\\mathsf{Var}\\{(X{^\\top}X)^{-1}X{^\\top}\\mathbf{y}\\}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\mathsf{Var}\\{\\mathbf{y}\\}\\big((X{^\\top}X)^{-1}X{^\\top}\\big){^\\top}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\mathsf{Var}\\{\\mathbf{y}\\}X(X{^\\top}X)^{-1}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\sigma^{2}IX(X{^\\top}X)^{-1}\\\\\n& =(X{^\\top}X)^{-1}\\sigma^{2}\n\\end{split}\n\\tag{9.2}\\]\n值得注意，\n\nLaTeX 命令 \\mathbf 只对英文字母 \\(a,b,c,A,B,C\\) 加粗，对希腊字母 \\(\\theta,\\alpha,\\beta,\\ldots,\\gamma\\) 加粗应该使用命令 \\boldsymbol。\nQuarto 文档中将行间公式中成对 $$ 转化为 LaTeX 中的 equation 环境。Quarto 不支持在多行公式逐行编号，也不支持在多行公式中对某一（些）行编号。而在 LaTeX 文档中，这些全都支持，可以说公式排版是 LaTeX 最突出的优势。\n\nMathJax 支持公式宏定义，如定义命令 \\bm 对希腊字母加粗。在 Quarto 文档中插入如下代码，用命令 \\boldsymbol 定义一个新的命令 \\bm，这种做法很常见，用来简少公式排版的工作量。\n$$\n\\def\\bm#1{{\\boldsymbol #1}}\n$$",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-report",
    "href": "documents-html.html#sec-quarto-report",
    "title": "9  HTML 文档",
    "section": "\n9.2 制作报告",
    "text": "9.2 制作报告\nQuarto Report 文档\n\n9.2.1 SQL 查询\n\nlibrary(DBI)\nconn &lt;- DBI::dbConnect(RSQLite::SQLite(),\n  dbname = system.file(\"db\", \"datasets.sqlite\", package = \"RSQLite\")\n)\n\nBase R 内置的数据集都整合进 RSQLite 的样例数据库里了，\n\ndbListTables(conn)\n\n [1] \"BOD\"              \"CO2\"              \"ChickWeight\"      \"DNase\"           \n [5] \"Formaldehyde\"     \"Indometh\"         \"InsectSprays\"     \"LifeCycleSavings\"\n [9] \"Loblolly\"         \"Orange\"           \"OrchardSprays\"    \"PlantGrowth\"     \n[13] \"Puromycin\"        \"Theoph\"           \"ToothGrowth\"      \"USArrests\"       \n[17] \"USJudgeRatings\"   \"airquality\"       \"anscombe\"         \"attenu\"          \n[21] \"attitude\"         \"cars\"             \"chickwts\"         \"esoph\"           \n[25] \"faithful\"         \"freeny\"           \"infert\"           \"iris\"            \n[29] \"longley\"          \"morley\"           \"mtcars\"           \"npk\"             \n[33] \"pressure\"         \"quakes\"           \"randu\"            \"rock\"            \n[37] \"sleep\"            \"stackloss\"        \"swiss\"            \"trees\"           \n[41] \"warpbreaks\"       \"women\"           \n\n\n随意选择 5 行数据记录，将结果保存到变量 iris_preview\n\nSELECT * FROM iris LIMIT 5;\n\n查看变量 iris_preview 的内容\n\niris_preview\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n\n\n结束后关闭连接\n\ndbDisconnect(conn = conn)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-presentation",
    "href": "documents-html.html#sec-quarto-presentation",
    "title": "9  HTML 文档",
    "section": "\n9.3 制作演示",
    "text": "9.3 制作演示\nQuarto Presentation",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-book",
    "href": "documents-html.html#sec-quarto-book",
    "title": "9  HTML 文档",
    "section": "\n9.4 编写书籍",
    "text": "9.4 编写书籍\nQuarto Book 网页格式",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#footnotes",
    "href": "documents-html.html#footnotes",
    "title": "9  HTML 文档",
    "section": "",
    "text": "(on the difference of Lattice (which eventually was called grid) and Trellis) DSC 2001, Wien (March 2001)↩︎",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html",
    "href": "documents-latex.html",
    "title": "10  PDF 文档",
    "section": "",
    "text": "10.1 LaTeX 基础\nLaTeX 是一个非常方便用户使用的排版工具，提供一套精确的编程语言，下面是一个简单示例。短短 14 行代码展示了大量的常用功能，生成文章标题、作者、目录，设置文档布局、排版公式、交叉引用等。\n接下来，逐行解释上面的 LaTeX 代码。\n所有的 LaTeX 命令都是以反斜杠 \\ 开头的。文类和红包的选项说明可查看其帮助文档。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-tex-elements",
    "href": "documents-latex.html#sec-tex-elements",
    "title": "10  PDF 文档",
    "section": "",
    "text": "\\documentclass[b5paper]{article}\n\\usepackage[heading=true, UTF8]{ctex} % 设置中文环境\n\\usepackage{amsmath,bm} % 处理数学公式\n\\title{LaTeX 入门}\n\\author{张三}\n\\begin{document}\n\\maketitle\n\\tableofcontents\n\\section{线性模型} \\label{sec:lm}\n第 \\ref{sec:lm} 节介绍线性模型，线性模型的矩阵表示见公式 \\ref{eq:lm} 。\n\\begin{align} \\label{eq:lm}\n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n\\end{align}\n\\end{document}\n\n\n\n\\documentclass 命令用来加载文类，常用的有 article、 report、 book 等，文类的选项 b5paper 表示布局为 B5 纸。\n\n\\usepackage 命令用来加载 LaTeX 宏包，上面的第2行设置中文环境，加载了 ctex 宏包，并设置了两个选项 heading=true 和 UTF8 。\n\n\\title 和 \\author 命令分别用来设置文档标题和作者。\\documentclass 和 \\begin{document} 之间的部分叫导言区，常常用来加载宏包和自定义 LaTeX 命令。\\begin{document} 和 \\end{document} 之间的部分叫正文。\n\n\\maketitle 和 \\tableofcontents 命令分别用来生成标题和文档目录。\\section 命令设置小节的标题。\\label 命令设置小节标签，用于交叉引用。\n\n\\begin{align} 和 \\end{align} 是一个公式环境，其间的命令 \\bm 来自 bm 宏包，用于加粗数学符号，命令 \\mathsf 、 \\beta 和 \\epsilon 都来自 amsmath 宏包。\n\n\\begin{align} 之后的命令 \\label{eq:lm} 设置公式标签，eq:lm 是用户指定的唯一标识符，不同公式不能重复使用同一标签，\\ref{eq:lm} 在正文中交叉引用公式。\n\n\n\n10.1.1 中英字体\n大部分情况下，加载 ctex 宏包就够了，但也有的场景需要使用特定的中文字体，比如学位论文排版、项目申请书等，这些对文档格式有极其严格的要求。此时，可以在导言区使用 xecjk 宏包配置字体，或者加载 ctex 宏包时添加选项 fontset=none ，加载 ctex 宏包会自动加载 xecjk 宏包。\n\\usepackage[heading=true, fontset=none, UTF8]{ctex} % 设置中文环境\n下面的代码表示在 LaTeX 文档里使用黑体、宋体、仿宋、楷体四款中文字体。正文字体是宋体，中文没有斜体，倾斜中文使用楷体，加粗中文使用黑体，等宽字体使用仿宋。\n\\setCJKmainfont[ItalicFont={KaiTi_GB2312}, BoldFont={SimHei}]{SimSun}\n\\setCJKsansfont{SimHei}\n\\setCJKmonofont{FangSong_GB2312}\n% 黑体\n\\setCJKfamilyfont{heiti}{SimHei}             \n\\newcommand{\\heiti}{\\CJKfamily{heiti}}\n% 楷体 GB2312\n\\setCJKfamilyfont{kaishu}{KaiTi_GB2312}             \n\\newcommand{\\kaishu}{\\CJKfamily{kaishu}}\n% 宋体\n\\setCJKfamilyfont{songti}{SimSun}             \n\\newcommand{\\songti}{\\CJKfamily{songti}}\n% 仿宋 GB2312\n\\setCJKfamilyfont{fangsong}{FangSong_GB2312}             \n\\newcommand{\\fangsong}{\\CJKfamily{fangsong}}\nLaTeX 提供很多字体宏包，支持英文字体、数学字体单独设定。在加载 amsmath 宏包后，加载 mathpazo 设置数学字体，加载 palatino 设置正文中的英文字体，加载 courier 设置代码中的等宽字体，加载 fontenc 设置字体编码方式。确保已安装 dvips 宏包，它用来处理字体文件。\n\\usepackage{mathpazo} % 数学符号\n\\usepackage{palatino} % 英文衬线字体\n\\usepackage{courier}  % 英文无衬线字体\n\\usepackage[T1]{fontenc} % 字体编码 T1\n\n10.1.2 数学公式\n排版数学公式分三部分，其一是排版的环境，其二是使用的符号、其三是使用的字体。公式环境都是由成对的命令组成，前面已经提及 align 环境，这是一个可对公式编号的适用于对齐多行公式的排版环境。\n\nLaTeX 公式排版环境\n\n可编号\n无编号\n作用\n\n\n\nalign\nalign*\n多行公式对齐\n\n\nequation\nequation*\n可与 split / cases 等环境嵌套使用\n\n\nmultline\nmultline*\n长公式折行\n\n\ngather\ngather*\n多行公式居中\n\n\n\n不可编号的排版环境，行内公式排版，用一对美元符号 $ $或一对小括号 \\( \\)。行间公式排版，用一对双美元符号 $$ $$ 或一对中括号 \\[ \\] 。\nLaTeX 支持丰富的数学符号大、小写英文字母，大、小写希腊字母，字母可以加粗、倾斜，字母也可以设置为等宽字体或衬线字体，还可以设置花体、空心体等。一些常用的数学符号样式见下表。\n\n\n\n\n\n\n\n\n\n大写\n小写\n加粗\n无衬线\n\n\n\\(X\\)\n\\(x\\)\n\\(\\boldsymbol{X}\\)\n\\(\\mathsf{X}\\)\n\n\n衬线\n花体\n空心体\n花体\n\n\n\\(\\mathrm{X}\\)\n\\(\\mathcal{X}\\)\n\\(\\mathbb{X}\\)\n\\(\\mathscr{X}\\)\n\n\n大写\n小写\n加粗\n无衬线\n\n\n\\(\\Gamma\\)\n\\(\\gamma\\)\n\\(\\boldsymbol{\\gamma}\\)\n\\(\\mathsf{\\Gamma}\\)\n\n\n\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2}\n\\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } \n+ \\sqrt{XY} \\Bigg)^3\n\\]\namsmath 宏包渲染效果如下：\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2} \\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } + \\sqrt{XY} \\Bigg)^3\n\\]\nnewtxtext 和 newtxmath 宏包常组合在一起，提供一套 New Times 字体风格的文本和数学公式，一种介于。\n\\documentclass[b5paper]{article}\n\\usepackage{amsmath}\n\\usepackage{newtxtext,newtxmath}\n\\begin{document}\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2}\n\\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } \n+ \\sqrt{XY} \\Bigg)^3\n\\]\n\\end{document}\nnewtxmath 宏包渲染效果如下：\n\n\n\n\n\n图 10.1: newtxmath 包渲染的公式效果\n\n\n\n10.1.3 代码抄录\nverbatim 环境是用来抄录代码的。\n\\begin{verbatim}\nlibrary(stats) % 提供 lowess, rpois, rnorm 等函数\nlibrary(graphics) % 提供 plot 方法\nplot(cars)\nlines(lowess(cars))\n\\end{verbatim}\n渲染出来的效果如下：\n\n\n\n\n\n图 10.2: verbatim 抄录环境\n\n\nlistings 宏包提供丰富的配置，下面在导言区设置代码字体样式和大小，代码块的背景、代码块的行号。\n\\usepackage{xcolor}\n\\definecolor{shadecolor}{rgb}{.97, .97, .97}\n\\usepackage{listings}\n\\lstset{\n  basicstyle=\\ttfamily, % 代码是等宽字体\n  backgroundcolor=\\color{shadecolor},  % 代码块的背景颜色\n  breaklines=true, % 可以段行\n  numbers=left,    % 行序号\n  numberstyle=\\footnotesize, % 行序号字体大小\n  commentstyle=\\ttfamily     % 注释是等宽字体\n}\n启用 lstlisting 环境抄录代码，设置参数 language=R 指定抄录环境中的编程语言类型，以便提供语法高亮。\n\\begin{lstlisting}[language=R]\nlibrary(stats)    % 提供 lowess, rpois, rnorm 等函数\nlibrary(graphics) % 提供 plot 方法\nplot(cars)\nlines(lowess(cars))\n\\end{lstlisting}\n渲染出来的效果如下：\n\n\n\n\n\n图 10.3: lstlisting 抄录环境\n\n\n\n10.1.4 插入图表\n首先在导言区加载 graphicx 宏包，然后可以使用 \\includegraphics 命令插入图片，该命令有一些选项，[width=.65\\textwidth] 表示插入的图片占页面宽度的 65%。\n\\usepackage{graphicx}\n在正文中 figure 环境是专门用来处理的图片，选项 [h] 表示将图片就插入此处，不要浮动。 center 环境将图片居中，\\caption 和 \\label 命令分别用来指定图片的标题和标签。\n\\begin{figure}[h]\n  \\begin{center}\n    \\includegraphics[width=.65\\textwidth]{images/peaks.png}\n    \\caption{图片的标题}\n    \\label{fig:figure}\n  \\end{center}\n\\end{figure}\n渲染效果如下\n\n\n\n\n\n图 10.4: 图片的标题\n\n\ntable 环境用于制作控制表格位置，tabular 用于制作表格，控制表头、每个列和每个格子。\n\\begin{table}[h!]\n  \\begin{center}\n    \\begin{tabular}{|c c c|} \n     \\hline\n      列1 & 列2 & 列3 \\\\ \n      \\hline\n      1 & 6 & 77 \\\\ \n      2 & 7 & 15 \\\\\n      3 & 8 & 44 \\\\\n      \\hline\n    \\end{tabular}\n  \\caption{表格的标题}\n  \\label{tbl:table}\n  \\end{center}\n\\end{table}\n\\begin{table}[h!] 表格环境中 [h!] 让表格不要浮动， center 环境使表格居中，\\begin{tabular}{|c c c|} 表格各个列的元素居中，表格整体封闭， \\hline 制作水平线，\\\\ 用于换行， & 用于表格格子对齐，\\caption 添加表格的标题，\\label 添加表格标识符，以便后续引用。\n渲染出来的效果如下：\n\n\n表格 10.1: 表格的标题\n\n\n\n列 1\n列 2\n列 3\n\n\n\n1\n6\n77\n\n\n2\n7\n15\n\n\n3\n8\n44\n\n\n\n\n\n\n\n10.1.5 交叉引用\n\\ref 命令用于图、表、公式、章节的交叉引用，引用图片 \\ref{fig:figure} 、引用表格 \\ref{tbl:table} 、引用公式 \\ref{eq:lm} 等。\n\\cite 命令用于参考文献的引用。\n\n10.1.6 PDF-A/X\n启用 PDF/X 或 PDF/A 标准，导言区加载 pdfx 宏包\n% PDF/A-1b 标准\n\\usepackage[a-1b]{pdfx}\n示例文档内容如下：\n\\documentclass[b5paper]{article}\n\\usepackage{amsmath} % boldsymbol\n\\usepackage[a-1b]{pdfx}\n\\title{Math in LaTeX}\n\\author{Zhang San}\n\\begin{document}\n\\maketitle\n\\tableofcontents\n\\section{Math}\n\\begin{align}\n\\boldsymbol{x},\\mathbf{x},\\mathsf{x},x\n\\end{align}\n\\begin{verbatim}\nrequire(stats) # for lowess, rpois, rnorm\nrequire(graphics) # for plot methods\nplot(cars)\nlines(lowess(cars))\n\\end{verbatim}\n\\end{document}\n编译 LaTeX 文档的命令如下：\nxelatex --shell-escape -output-driver=\"xdvipdfmx -z 0\" &lt;filename&gt;.tex",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-rmarkdown-elements",
    "href": "documents-latex.html#sec-rmarkdown-elements",
    "title": "10  PDF 文档",
    "section": "\n10.2 R Markdown 基础",
    "text": "10.2 R Markdown 基础\n\n\n---\ntitle: \"R Markdown 入门\"\nauthor: \"张三\"\ndocumentclass: article\noutput: \n  bookdown::pdf_book: \n    extra_dependencies:\n      ctex: \n        - UTF8\n        - heading=true\n      bm: null\n    toc: yes\n    template: null\n    base_format: rmarkdown::pdf_document\n    latex_engine: xelatex\n    number_sections: yes\nmathspec: true\ncolorlinks: yes\nclassoptions: \"b5paper\"    \n---\n\n# 线性模型 {#sec:lm}\n\n第 \\@ref(sec:lm) 节介绍线性模型，线性模型的矩阵表示见公式 \\@ref(eq:lm) 。\n\n```{=tex}\n\\begin{align} \n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n(\\#eq:lm)\n\\end{align}\n```\n\n\n\n10.2.1 中英字体\n\n10.2.2 数学公式\n\n10.2.3 代码抄录\n\n10.2.4 插入图表\n\n10.2.5 交叉引用\n\n10.2.6 布局排版\n\n\n---\ntitle: \"R Markdown 双栏排版\"\nsubtitle: \"副标题\"\nauthor: \"张三\"\ndate: \"`r Sys.Date()`\"\nmathspec: yes\nfontsize: 10pt\ngraphics: yes\nlof: yes\ngeometry: margin=1.18in\noutput: \n  bookdown::pdf_book: \n    number_sections: yes\n    toc: yes\n    fig_crop: no\n    latex_engine: xelatex\n    base_format: rmarkdown::pdf_document\n    citation_package: natbib\n    template: null\n    extra_dependencies:\n      sourcecodepro:\n       - scale=0.85\n      ctex:\n       - heading=true\n       - fontset=fandol\n      caption:\n       - labelfont=bf\n       - singlelinecheck=off\n       - textfont=it\n       - justification=centering\n      Alegreya: null\nkeywords: \n  - 动态文档\n  - 双栏排版\nsubject: \"可重复研究与动态文档\"\nabstract: |\n  这里是摘要内容\nbibliography: \n - packages.bib\nbiblio-style: plainnat\nnatbiboptions: \"authoryear,round\"\nlink-citations: true\ncolorlinks: true\nclassoption: \"UTF8,a4paper,twocolumn\"\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n# R Markdown\n\nR Markdown 文档混合了代码、图形和文字内容[@rmarkdown]。\n\n## 代码 {#sec:code}\n\n```{r cars}\nsummary(cars)\n```\n\n## 插图 {#sec:plot}\n\n```{r}\n#| fig-iris, \n#| fig.cap=\"鸢尾花数据集\", \n#| fig.width=5, \n#| fig.height=4,\n#| fig.showtext=TRUE, \n#| out.width=\"95%\", \n#| echo=FALSE\n\nlibrary(ggplot2)\nggplot(iris, aes(Sepal.Length, Sepal.Width)) +\n  geom_point(aes(colour = Species)) +\n  scale_colour_brewer(palette = \"Set1\") +\n  labs(\n    title = \"鸢尾花数据的散点图\",\n    x = \"萼片长度\", y = \"萼片宽度\", colour = \"鸢尾花类别\",\n    caption = \"鸢尾花数据集最早见于 Edgar Anderson (1935) \"\n  )\n```\n\n# 参考文献 {#chap:refer}",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-quarto-elements",
    "href": "documents-latex.html#sec-quarto-elements",
    "title": "10  PDF 文档",
    "section": "\n10.3 Quarto 基础",
    "text": "10.3 Quarto 基础\n\n\n---\ntitle: \"Quarto 入门\"\nauthor: \"张三\"\nlang: zh\nformat:\n  pdf:\n    include-in-header:\n      - text: |\n          \\usepackage[heading=true,UTF8]{ctex} \n          \\usepackage{amsmath,bm}\n    toc: true\n    mathspec: true\n    number-sections: true\n    colorlinks: true\n    documentclass: article\n    papersize: b5paper\n---\n\n# 线性模型 {#sec-lm}\n\n@sec-lm 介绍线性模型，线性模型的矩阵表示见 @eq-lm 。\n\n$$\n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n$$ {#eq-lm}\n\n\n\n10.3.1 中英字体\n\n10.3.2 数学公式\n\n10.3.3 代码抄录\n\n10.3.4 插入图表\n插入图片的语法是 ![](){}，中括号内是插图标题，小括号内是插图存放路径，大括号内是插图的标识符和属性，比如 width=\"65%\" 设置图片的宽度为页面宽度的 65%。\n![An Elephant](images/peaks.png){#fig-quarto-figure width=\"65%\"}\n渲染效果如下：\n\n\n\n\n\n图 10.5: Peaks 函数图像\n\n\n表格默认左对齐，冒号加虚线、虚线加冒号、虚线两侧加冒号分别对应左对齐、右对齐和居中对齐。\n| Default | Left | Right | Center |\n|---------|:-----|------:|:------:|\n| 12      | 12   |    12 |   12   |\n| 123     | 123  |   123 |  123   |\n| 1       | 1    |     1 |   1    |\n\n: 制作表格的管道语法 {#tbl-quarto-table}\n渲染效果如下：\n\n\n表格 10.2: 制作表格的管道语法\n\n\n\nDefault\nLeft\nRight\nCenter\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n10.3.5 交叉引用\n@tbl-quarto-table 插入 表格 10.2 ，@fig-quarto-figure 插入 图 10.5 。引用表格的标识符前缀必须是 tbl，引用插图的标识符前缀必须是 fig，后以连字符连接其它内容。对比 LaTeX 文档中的图、表引用 \\ref{fig:figure} ，Quarto 中的 @ 符号对应于命令 \\ref 。值得注意，在 LaTeX 文档中，对标识符的命名没有这般要求，但为了区分引用内容，通常会加上不同的前缀。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-quarto-beamer",
    "href": "documents-latex.html#sec-quarto-beamer",
    "title": "10  PDF 文档",
    "section": "\n10.4 Quarto beamer",
    "text": "10.4 Quarto beamer\nQuarto 制作 beamer 幻灯片\n\n\n---\ntitle: \"Quarto 幻灯片模版\"\nauthor:\n  - 张三\n  - 李四\ninstitute: \n  - XX 大学\n  - XX 学院\ndate: today\ndate-format: long\ndocumentclass: beamer\nclassoption: \n  - 11pt\n  - compress\n  - xcolor=x11names\n  - UTF8\nlang: zh\nformat:\n  beamer:\n    theme: Singapore\n    fonttheme: structurebold\n    pdf-engine: lualatex\n    include-in-header: \n      text: |\n        \\usecolortheme[named=SpringGreen4]{structure}\n        \\usepackage[fontset=fandol]{ctex}\n    keep-tex: false\n    mathspec: true\n    toc: true\n    navigation: horizontal\n    latex-min-runs: 2\n    latex-auto-install: false\nlink-citations: true\n---\n\n# In the morning\n\n## Getting up\n\n-   Turn off alarm\n-   Get out of bed\n\n## Breakfast\n\n-   Eat eggs\n-   Drink coffee\n\n# In the evening\n\n## Dinner\n\n-   Eat spaghetti\n-   Drink wine\n\n## Going to sleep\n\n-   Get in bed\n-   Count sheep\n\n\nPandoc’s Markdown 制作 beamer 幻灯片\n\n\n---\ntitle: \"Quarto 幻灯片模版\"\nauthor:\n  - 张三\n  - 李四\ninstitute: \n  - XX 大学\n  - XX 学院\nmathspec: true\ntoc: true\ntoc-title: \"目录\"\n---\n\n# In the morning\n\n## Getting up\n\n-   Turn off alarm\n-   Get out of bed\n\n## Breakfast\n\n-   Eat eggs\n-   Drink coffee\n\n# In the evening\n\n## Dinner\n\n-   Eat spaghetti\n-   Drink wine\n\n## Going to sleep\n\n-   Get in bed\n-   Count sheep\n\n\n将 Markdown 文档转化为 beamer 幻灯片的命令\n\npandoc --pdf-engine lualatex -t beamer \\\n  --variable theme=\"Singapore\" --variable fonttheme=\"structurebold\" \\\n  --variable classoption=\"xcolor=x11names\" \\\n  --variable header-includes=\"\\usecolortheme[named=SpringGreen4]{structure}\" \\\n  --variable header-includes=\"\\usepackage[fontset=fandol]{ctex}\" \\\n  -f markdown pandoc-beamer.md -o pandoc-beamer.pdf",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html",
    "href": "documents-office.html",
    "title": "11  Office 文档",
    "section": "",
    "text": "11.1 Word 文档",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-words",
    "href": "documents-office.html#sec-office-words",
    "title": "11  Office 文档",
    "section": "",
    "text": "11.1.1 Markdown 制作 Word 文档\n本节探索 (R) Markdown + Pandoc 以 Word 格式作为最终交付的可能性。\n\n\n11.1.2 R Markdown 制作 Word 文档\ndocxtools、officer 和 officedown 大大扩展了 rmarkdown 包在制作 Word/PPT 方面的功能。\n\n\n11.1.3 自定义 Word 模版\nR Markdown 借助 Pandoc 将 Markdown 转化为 Word 文档，继承自 Pandoc 的扩展性， R Markdown 也支持自定义 Word 模版，那如何自定义呢？首先，我们需要知道 Pandoc 内建的 Word 模版长什么样子，然后我们依样画葫芦，制作适合实际需要的模版。获取 Pandoc 自带的 Word 和 PPT 模版，只需在命令行中执行\n# DOCX 模版\npandoc -o custom-reference.docx --print-default-data-file reference.docx\n# PPTX 模版\npandoc -o custom-reference.pptx --print-default-data-file reference.pptx\n这里其实是将 Pandoc 自带的 docx 文档 reference.docx 拷贝一份到 custom-reference.docx，而后将 custom-reference.docx 文档自定义一番，但仅限于借助 MS Word 去自定义样式。\n\nWord 文档的 YAML 元数据定义\n如何深度自定义文档模版\n\nbookdown 提供的函数 word_document2() 相比于 rmarkdown 提供的 word_document() 支持图表的交叉引用，更多细节详见帮助 ?bookdown::word_document2。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-powerpoints",
    "href": "documents-office.html#sec-office-powerpoints",
    "title": "11  Office 文档",
    "section": "11.2 PowerPoint 演示",
    "text": "11.2 PowerPoint 演示",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-emails",
    "href": "documents-office.html#sec-office-emails",
    "title": "11  Office 文档",
    "section": "11.3 电子邮件",
    "text": "11.3 电子邮件\nRahul Premraj 基于 rJava 包开发的 mailR 虽然还未在 CRAN 上正式发布，但是已得到很多人的关注，也被广泛的使用，目前作者已经不维护了，继续使用有一定风险。 RStudio 公司 Richard Iannone 新开发的 blastula 扔掉了 Java 的重依赖，更加轻量化、现代化，支持发送群组邮件。\n\n11.3.1 curl 包\ncurl 包提供的函数 send_mail() 本质上是在利用 curl 软件发送邮件，举个例子，邮件内容如下：\nFrom: \"张三\" &lt;邮箱地址&gt;\nTo: \"李四\" &lt;邮箱地址&gt;\nSubject: 测试邮件\n\n你好：\n\n这是一封测试邮件！\n将邮件内容保存为 mail.txt 文件，然后使用 curl 命令行工具将邮件内容发出去。\ncurl --url 'smtp://公司邮件服务器地址:开放的端口号' \\\n  --ssl-reqd --mail-from '发件人邮箱地址' \\\n  --mail-rcpt '收件人邮箱地址' \\\n  --upload-file data/mail.txt \\\n  --user '发件人邮箱地址:邮箱登陆密码'\n\n\n\n\n\n\n注释\n\n\n\nGmail 出于安全性考虑，不支持这种发送邮件的方式，会将邮件内容阻挡，进而接收不到邮件。\n\n\n\n\n11.3.2 blastula 包\n下面以 blastula 包为例怎么支持 Gmail、Outlook、QQ 等邮件发送，先安装系统软件依赖，CentOS 8 上安装依赖\nsudo dnf install -y libsecret-devel libsodium-devel\n然后安装 keyring 和 blastula\ninstall.packages(c(\"keyring\", \"blastula\"))\n接着配置邮件帐户，这一步需要邮件账户名和登陆密码，配置一次就够了，不需要每次发送邮件的时候都配置一次\nlibrary(blastula)\ncreate_smtp_creds_key(\n  id = \"outlook\", \n  user = \"zhangsan@outlook.com\",\n  provider = \"outlook\"\n)\n第二步，准备邮件内容，包括邮件主题、发件人、收件人、抄送人、密送人、邮件主体和附件等。\nattachment &lt;- \"data/mail.txt\" # 如果没有附件，引号内留空即可。\n# 这个Rmd文件渲染后就是邮件的正文，交互图形和交互表格不适用\nbody &lt;- \"examples/html-document.Rmd\" \n# 渲染邮件内容，生成预览\nemail &lt;- render_email(body) |&gt; \n  add_attachment(file = attachment)\nemail\n最后，发送邮件\nsmtp_send(\n  from = c(\"张三\" = \"xxx@outlook.com\"), # 发件人\n  to = c(\"李四\" = \"xxx@foxmail.com\",\n         \"王五\" = \"xxx@gmail.com\"), # 收件人\n  cc = c(\"赵六\" = \"xxx@outlook.com\"), # 抄送人\n  subject = \"这是一封测试邮件\",\n  email = email,\n  credentials = creds_key(id = \"outlook\")\n)\n密送人实现群发单显，即一封邮件同时发送给多个人，每个收件人只能看到发件人地址而看不到其它收件人地址。\nemail &lt;- compose_email(\n  body = md(\"\nMarkdown 格式的邮件内容\n\")\n)\n\nsmtp_send(\n  from = c(\"发件人\" = \"xx@outlook.com\"),\n  to = c(\"收件人\" = \"xx@outlook.com\"),\n  bcc = c(\n    \"抄送人\" = \"xx@outlook.com\"\n    ),\n  subject = \"邮件主题\",\n  email = email,\n  credentials = creds_key(id = \"outlook\")\n)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html",
    "href": "common-statistical-tests.html",
    "title": "12  常见的统计检验",
    "section": "",
    "text": "12.1 单样本检验\nflowchart LR\n  A(单样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D1(方差已知) --&gt; E1(Z 检验)\n  C1 --&gt; D2(方差未知) --&gt; E2(t 检验)\n  B1 --&gt; C2(方差检验) --&gt; E3(卡方检验)\n  B2 --&gt; C3(均值检验) --&gt; E4(Wilcoxon 秩和检验)\n  B2 --&gt; C4(方差检验) --&gt; E5[无检验方法]\n\n\n\n\n图 12.1: 单样本检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-one-sample",
    "href": "common-statistical-tests.html#sec-one-sample",
    "title": "12  常见的统计检验",
    "section": "",
    "text": "12.1.1 正态总体均值检验\n\n12.1.1.1 方差已知\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu - \\mu_0 \\leq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu - \\mu_0 \\geq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu - \\mu_0 = 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 \\neq 0\n\\end{aligned}\n\\]\n设 \\(x_1,\\cdots,x_n\\) 是来自总体 \\(\\mathcal{N}(\\mu,\\sigma^2)\\) 的样本，样本均值和方差分别\n\\(\\bar{x} = \\frac{\\sum_{i=1}^{n}x_i}{n}\\) ，\\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\)\n考虑到 \\(\\bar{x} \\sim \\mathcal{N}(\\mu,\\sigma^2 / n)\\) ，则检验统计量服从正态分布\n\\[\nu = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n\\]\n假定 \\(\\mu_0 = 1\\) 对于检验问题 I 拒绝域 \\(\\{u \\geq u_{1-\\alpha}\\}\\)\n\nset.seed(20232023)\nn &lt;- 20\n# 样本\nx &lt;- rnorm(n, mean = 1.8, sd = 2)\n# 检验统计量\nu &lt;- (mean(x) - 1) / (2 / sqrt(n))\n# 临界值\nqnorm(p = 1 - 0.05, mean = 0, sd = 1)\n\n#&gt; [1] 1.644854\n\n# P 值\n1 - pnorm(q = u)\n\n#&gt; [1] 0.005082465\n\n\n\n\n\n\n\n\n重要\n\n\n\n随机变量 \\(X\\) 服从标准正态分布，它的概率分布函数如下：\n\\[\nP(X \\leq u)= \\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{u}\\mathrm{e}^{-t^2/2}\\mathrm{dt}\n\\]\n若已知概率 \\(p = 0.95\\) ，则对应的下分位点可用函数 qnorm() 计算。\n\nqnorm(p = 0.95, mean = 0, sd = 1)\n\n#&gt; [1] 1.644854\n\n\n\n\n\n12.1.1.2 方差未知\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu - \\mu_0 \\leq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu - \\mu_0 \\geq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu - \\mu_0 = 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 \\neq 0\n\\end{aligned}\n\\]\n考虑到\n\\[\n\\begin{aligned}\n& \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0,1) \\\\\n& \\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi^2(n-1) \\\\\n& \\mathsf{E}\\{s^2\\} = \\sigma^2 \\quad \\mathsf{Var}\\{s^2\\} = \\frac{2\\sigma^4}{n-1}\n\\end{aligned}\n\\]\n根据 t 分布的定义，检验统计量服从 t 分布，即 \\(t \\sim t(n-1)\\)\n\\[\nt = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\n\\]\n假定 \\(\\mu_0 = 1\\) 对于检验问题 I ，拒绝域 \\(\\{t \\geq t_{1-\\alpha}(n-1)\\}\\)\n\n# 检验统计量\nt0 &lt;- (mean(x) - 1) / sqrt(var(x) / n)\n# 临界值\nqt(p = 1 - 0.05, df = n - 1)\n\n#&gt; [1] 1.729133\n\n# P 值\n1 - pt(q = t0, df = n - 1)\n\n#&gt; [1] 0.01569596\n\n\n\n\n\n\n\n\n注释\n\n\n\n英国统计学家 William Sealy Gosset (1876-1937) 于 1908 年在杂志 《Biometrics》 上以笔名 Student 发表论文《The Probable Error of a Mean》(\"Student\" 1908)，论文中展示了独立同正态分布的样本 \\(x_1, \\ldots, x_n \\stackrel{i.i.d}{\\sim} \\mathcal{N}(\\mu,\\sigma^2)\\) 的样本方差 \\(s^2\\) 和样本标准差 \\(s\\) 的抽样分布，根据均值和标准差不相关的性质导出 t 分布，宣告 t 分布的诞生，因其在小样本领域的突出贡献，W. S. Gosset 进入世纪名人录 (Heyde 等 2001)。\n\n\n\n\n\n表格 12.1: \\(t\\) 分布的分位数表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.75\n0.8\n0.9\n0.95\n0.975\n0.99\n0.995\n0.999\n\n\n\n1\n1.0000\n1.3764\n3.0777\n6.3138\n12.7062\n31.8205\n63.6567\n318.3088\n\n\n2\n0.8165\n1.0607\n1.8856\n2.9200\n4.3027\n6.9646\n9.9248\n22.3271\n\n\n3\n0.7649\n0.9785\n1.6377\n2.3534\n3.1824\n4.5407\n5.8409\n10.2145\n\n\n4\n0.7407\n0.9410\n1.5332\n2.1318\n2.7764\n3.7469\n4.6041\n7.1732\n\n\n5\n0.7267\n0.9195\n1.4759\n2.0150\n2.5706\n3.3649\n4.0321\n5.8934\n\n\n6\n0.7176\n0.9057\n1.4398\n1.9432\n2.4469\n3.1427\n3.7074\n5.2076\n\n\n7\n0.7111\n0.8960\n1.4149\n1.8946\n2.3646\n2.9980\n3.4995\n4.7853\n\n\n8\n0.7064\n0.8889\n1.3968\n1.8595\n2.3060\n2.8965\n3.3554\n4.5008\n\n\n9\n0.7027\n0.8834\n1.3830\n1.8331\n2.2622\n2.8214\n3.2498\n4.2968\n\n\n10\n0.6998\n0.8791\n1.3722\n1.8125\n2.2281\n2.7638\n3.1693\n4.1437\n\n\n\n\n\n\n\n\n\n12.1.2 正态总体方差检验\n卡方检验 \\(\\chi^2\\) 检验统计量服从卡方分布。\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\sigma^2 - \\sigma^2_0 \\leq 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\sigma^2 - \\sigma^2_0 \\geq 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\sigma^2 - \\sigma^2_0 = 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 \\neq 0\n\\end{aligned}\n\\]\n一般假定均值 \\(\\mu\\) 是未知的。检验统计量服从卡方分布 \\(\\chi^2(n-1)\\)\n\\[\n\\chi^2 = \\frac{(n-1)s^2}{\\sigma^2_0}\n\\]\n设 \\(\\sigma^2_0 = 1.5^2\\) ，考虑检验问题 I\n\n# 检验统计量\nchi &lt;- (n - 1) * var(x) / 1.5^2\n# 临界值\nqchisq(p = 1 - 0.05, df = n -1)\n\n#&gt; [1] 30.14353\n\n# P 值\n1 - pchisq(q = chi, df = n -1)\n\n#&gt; [1] 0.002183653\n\n\nR 软件提供很多统计分布的计算，因此，不再需要查分位数表，现算即可。计算自由度为 \\(n\\) 概率为 \\(p\\) 的 \\(\\chi^2\\) 分布的分位数 \\(\\chi^2_p(n)\\) ，即\n\\[\nP(\\chi^2(n) \\leq \\chi^2_p(n)) = p\n\\]\n若已知自由度为 1 ，概率为 0.05，则可借助分位数函数 qchisq() 计算对应的（下）分位点。\n\nqchisq(p = 0.05, df = 1)\n\n#&gt; [1] 0.00393214\n\n\n同理，也可以获得 \\(\\chi^2\\) 分布的分位数 表格 12.2 ，计算出来的分位数保留 4 位小数。\n\n\n\n表格 12.2: \\(\\chi^2\\) 分布的分位数表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n0.01\n0.025\n0.05\n0.1\n0.9\n0.95\n0.975\n0.99\n0.995\n\n\n\n1\n0.0000\n0.0002\n0.0010\n0.0039\n0.0158\n2.7055\n3.8415\n5.0239\n6.6349\n7.8794\n\n\n2\n0.0100\n0.0201\n0.0506\n0.1026\n0.2107\n4.6052\n5.9915\n7.3778\n9.2103\n10.5966\n\n\n3\n0.0717\n0.1148\n0.2158\n0.3518\n0.5844\n6.2514\n7.8147\n9.3484\n11.3449\n12.8382\n\n\n4\n0.2070\n0.2971\n0.4844\n0.7107\n1.0636\n7.7794\n9.4877\n11.1433\n13.2767\n14.8603\n\n\n5\n0.4117\n0.5543\n0.8312\n1.1455\n1.6103\n9.2364\n11.0705\n12.8325\n15.0863\n16.7496\n\n\n6\n0.6757\n0.8721\n1.2373\n1.6354\n2.2041\n10.6446\n12.5916\n14.4494\n16.8119\n18.5476\n\n\n7\n0.9893\n1.2390\n1.6899\n2.1673\n2.8331\n12.0170\n14.0671\n16.0128\n18.4753\n20.2777\n\n\n8\n1.3444\n1.6465\n2.1797\n2.7326\n3.4895\n13.3616\n15.5073\n17.5345\n20.0902\n21.9550\n\n\n9\n1.7349\n2.0879\n2.7004\n3.3251\n4.1682\n14.6837\n16.9190\n19.0228\n21.6660\n23.5894\n\n\n10\n2.1559\n2.5582\n3.2470\n3.9403\n4.8652\n15.9872\n18.3070\n20.4832\n23.2093\n25.1882\n\n\n\n\n\n\n\n\n\n12.1.3 总体未知均值检验\n有了均值和方差，为什么还要位置参数和尺度参数？为了更一般地描述问题，扩展范围。特别是在总体分布未知或知之甚少的情况下做检验，不再仅限于均值和方差这样的特征量。\n考虑前面正态总体均值检验中的假设 I 的形式，若总体的分布形式未知，则需要 Wilcoxon （威尔科克森）秩和检验 wilcox.test() 来做均值的比较。\n\nwilcox.test(x = x, mu = 1, alternative = \"greater\")\n\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  x\n#&gt; V = 163, p-value = 0.01479\n#&gt; alternative hypothesis: true location is greater than 1\n\n\n相比于 t 检验，P 值更小。\n\n12.1.4 总体未知方差检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-two-samples",
    "href": "common-statistical-tests.html#sec-two-samples",
    "title": "12  常见的统计检验",
    "section": "\n12.2 两样本检验",
    "text": "12.2 两样本检验\n\n\n\n\n\nflowchart LR\n  A(两样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D1(方差已知) --&gt; E1(Z 检验)\n  C1 --&gt; D2(方差未知但相等) --&gt; E2(t 检验)\n  C1 --&gt; D3(方差未知且不等) --&gt; E3(Welch t 检验)\n  B1 --&gt; C2(方差检验) --&gt; E4(F 检验)\n  C2 --&gt; E7(Bartlett 检验)\n  B2 --&gt; C3(均值检验) --&gt; E5(Wilcoxon 符号秩检验\\nKruskal-Wallis 秩和检验)\n  B2 --&gt; C4(方差检验) --&gt; E8(Ansari-Bradley 检验\\nMood 检验\\nFligner-Killeen 检验)\n\n\n\n\n图 12.2: 两样本检验\n\n\n\n\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的样本。\n\n12.2.1 正态总体均值检验\n两样本均值之差的检验\n\n代码library(ggplot2)\n# 绘制虚线所需的数据\nconst &lt;- 1 / sqrt(2 * pi)\ndat &lt;- data.frame(\n  x = c(-1, -1, 3, 3),\n  y = c(const, 0, const / 1.5, 0),\n  group = c(\"dnorm1\", \"dnorm1\", \"dnorm2\", \"dnorm2\"),\n  upper = c(const, 0, const / 1.5, 0),\n  lower = c(0, 0, 0, 0)\n)\nggplot() +\n  geom_function(\n    fun = dnorm, args = list(mean = -1, sd = 1),\n    aes(colour = \"dnorm1\"), linewidth = 1.5, xlim = c(-5, 10)\n  ) +\n  geom_function(\n    fun = dnorm, args = list(mean = 3, sd = 1.5),\n    aes(colour = \"dnorm2\"), linewidth = 1.5, xlim = c(-5, 10)\n  ) +\n  scale_color_brewer(palette = \"Set1\", labels = c(\n    dnorm1 = \"$\\\\mathcal{N}(\\\\mu_1, \\\\sigma_1^2)$\",\n    dnorm2 = \"$\\\\mathcal{N}(\\\\mu_2, \\\\sigma_2^2)$\"\n  )) +\n  geom_linerange(\n    aes(x = x, y = y, ymin = lower, ymax = upper, colour = group),\n    linewidth = 2, lty = 2, show.legend = FALSE, data = dat\n  ) +\n  annotate(\"text\", x = -1, y = 0, label = \"$\\\\mu_1$\", vjust = 2.5) +\n  annotate(\"text\", x = 3, y = 0, label = \"$\\\\mu_2$\", vjust = 2.5) +\n  theme_classic(base_size = 13) +\n  theme(legend.position.inside = c(0.9, 0.9)) +\n  labs(x = \"$x$\", y = \"$f(x)$\", color = \"正态分布\") +\n  coord_cartesian(clip = \"off\")\n\n\n\n\n\n\n图 12.3: 两样本均值之差的检验\n\n\n\n\n常见检验问题\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu_1 - \\mu_2 \\leq 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu_1 - \\mu_2 \\geq 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu_1 - \\mu_2 = 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 \\neq 0\n\\end{aligned}\n\\]\n\n12.2.1.1 方差已知\n\\[\nu = \\frac{(\\bar{x} - \\bar{y}) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}} }\n\\]\n检验统计量服从标准正态分布 \\(u \\sim \\mathcal{N}(0,1)\\)，检验统计量 \\(u\\) 对应的样本值 \\(u_0\\)，检验的拒绝域和 \\(P\\) 值如下\n\\[\nW_1 = \\{u \\geq u_{1 - \\alpha} \\}, \\quad p_1 = 1 - \\varPhi(u_0)\n\\]\n\nn_1 &lt;- 100\nn_2 &lt;- 80\nmu_1 &lt;- 10\nsigma_1 &lt;- 2.5\nmu_2 &lt;- 6\nsigma_2 &lt;- 4.5\n\nset.seed(20232023)\nx1 &lt;- rnorm(n_1, mean = mu_1, sd = sigma_1)\ny1 &lt;- rnorm(n_2, mean = mu_2, sd = sigma_2)\nu0 &lt;- (mean(x1) - mean(y1)) / sqrt(sigma_1^2 / n_1 + sigma_2^2 / n_2)\nu0\n\n#&gt; [1] 6.779039\n\n\n对检验问题 I，给定显著性水平 \\(\\alpha = 0.05\\)，得出拒绝域 \\(\\{ u \\geq 1.645\\}\\)，计算样本观察值得到的检验统计量的值 \\(u_0 = 6.779\\)，而该值落在拒绝域，所以拒绝原假设，即拒绝 \\(\\mu_1 - \\mu_2 \\leq 0\\)，则接受 \\(\\mu_1 - \\mu_2 &gt; 0\\)。\n\n# 计算拒绝域\nqnorm(1 - 0.05)\n\n#&gt; [1] 1.644854\n\n# 计算 P 值\n1 - pnorm(u0)\n\n#&gt; [1] 6.048939e-12\n\n\n\n12.2.1.2 方差未知但相等\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma^2)\\) 的样本。\nt 检验，检验统计量服从自由度为 \\(n_1 + n_2 - 2\\) 的 t 分布\n\\[\nt = \\frac{(\\bar{x} -\\bar{y})-(\\mu_1 - \\mu_2)}{s_0\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\]\n其中，\n\\[\n\\begin{aligned}\n& \\bar{x} = \\sum_{i=1}^{n_1}x_i \\quad \\bar{y} = \\sum_{i=1}^{n_2}y_i \\\\\n& s_0^2 = \\frac{1}{n_1 + n_2 - 2}\\big(\\sum_{i=1}^{n_1}(x_i - \\bar{x})^2 + \\sum_{i=1}^{n_2}(y_i - \\bar{y})^2\\big)\n\\end{aligned}\n\\]\n\ns_w &lt;- sqrt(1 / (n_1 + n_2 - 2) * ((n_1 - 1) * var(x1) + (n_2 - 1) * var(y1)))\nt0 &lt;- (mean(x1) - mean(y1)) / (s_w * sqrt(1 / n_1 + 1 / n_2))\nt0\n\n#&gt; [1] 8.155781\n\n\n样本观察值 \\(t_0 = 8.155 &gt; t_{0.95}(n_1 + n_2 -2) = 1.653\\) 落在拒绝域内，对于检验问题 I 我们要拒绝原假设\n\n# 临界值：0.95 分位点对应的分位数\nqt(1 - 0.05, df = n_1 + n_2 - 2)\n\n#&gt; [1] 1.653459\n\n# p 值\n1 - pt(t0, df = n_1 + n_2 - 2, lower.tail = TRUE)\n\n#&gt; [1] 3.019807e-14\n\n\n利用 R 内置的 t.test() 函数计算\n\nt.test(x = x1, y = y1, alternative = \"greater\", var.equal = TRUE)\n\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  x1 and y1\n#&gt; t = 8.1558, df = 178, p-value = 3.016e-14\n#&gt; alternative hypothesis: true difference in means is greater than 0\n#&gt; 95 percent confidence interval:\n#&gt;  3.036384      Inf\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 10.338905  6.530406\n\n\n检验统计量的值及对应的 P 值都是一样的。睡眠数据 sleep 记录了两种药物对病人睡眠时间的影响，此数据集由 “Student”（哥塞特的笔名） 收集。\n\n# 方差未知但相等\nt.test(extra ~ group, data = sleep, var.equal = TRUE)\n\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -1.8608, df = 18, p-value = 0.07919\n#&gt; alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.363874  0.203874\n#&gt; sample estimates:\n#&gt; mean in group 1 mean in group 2 \n#&gt;            0.75            2.33\n\n\n\n12.2.1.3 方差未知且不等\n两个样本的样本量不是很大，总体方差也未知，两样本均值之差的显著性检验，即著名的 Behrens-Fisher 问题，Welch 在 1938 年提出近似服从自由度为 \\(l\\) 的 t 分布。\n两样本的样本量很大，尽管总体方差未知，两样本均值之差的显著性检验，极限分布是正态分布，可以用 Z 检验。在样本量很大的情况下，Welch t 检验也可以用。\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的 IID 样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的 IID 样本。\nWelch（韦尔奇） t 检验\n\\[\nT = \\frac{(\\bar{x} - \\bar{y}) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{s_x^2}{n_1} + \\frac{s_y^2}{n_2}} }\n\\]\n其中，\\(s_x^2\\) 表示样本 x 的方差 \\(s_x^2 = \\frac{1}{n_1-1}\\sum_{i=1}^{n_1}(x_i -\\bar{x})^2\\) ，\\(s_y^2\\) 表示样本 y 的方差 \\(s_y^2 = \\frac{1}{n_2-1}\\sum_{i=1}^{n_2}(y_i -\\bar{y})^2\\) 。检验统计量 \\(T\\) 服从自由度为 \\(l\\) 的 t 分布。\n\\[\nl = \\frac{s_0^4}{ \\frac{s_x^4}{n_1^2(n_1 - 1)} + \\frac{s_y^4}{n_2^2(n_2-1)} }\n\\]\n其中， \\(s_0^2 = s_x^2 / n_1 + s_y^2/n_2\\)，\\(l\\) 通常不是整数，实际使用时，\\(l\\) 可取最近的整数。\n\ns0 &lt;- var(x1) / n_1 + var(y1) / n_2\nl &lt;- s0^2 / (var(x1)^2 / (n_1^2 * (n_1 - 1)) + var(y1)^2 / (n_2^2 * (n_2 - 1)))\nl\n\n#&gt; [1] 126.7708\n\n\n所以， \\(l\\) 可取 127。检验统计量的值如下\n\nt0 &lt;- (mean(x1) - mean(y1)) / sqrt(s0)\nt0\n\n#&gt; [1] 7.77002\n\n\n\n# 临界值：0.95 分位点对应的分位数\nqt(1 - 0.05, df = 127)\n\n#&gt; [1] 1.65694\n\n# p 值\n1 - pt(t0, df = 126.7708, lower.tail = TRUE) \n\n#&gt; [1] 1.162404e-12\n\n# 就近取整\n1 - pt(t0, df = 127, lower.tail = TRUE)\n\n#&gt; [1] 1.153078e-12\n\n\n与函数 t.test() 比较，值得注意，t 分布的自由度可以为非整数。\n\nt.test(x = x1, y = y1, alternative = \"greater\", var.equal = FALSE)\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  x1 and y1\n#&gt; t = 7.77, df = 126.77, p-value = 1.162e-12\n#&gt; alternative hypothesis: true difference in means is greater than 0\n#&gt; 95 percent confidence interval:\n#&gt;  2.996334      Inf\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 10.338905  6.530406\n\n\n举例：sleep 数据集\n\n\n\n\n\n\n\n图 12.4: 学生睡眠数据的分布\n\n\n\n\n\n# 方差未知且不等\nt.test(extra ~ group, data = sleep, var.equal = FALSE)\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -1.8608, df = 17.776, p-value = 0.07939\n#&gt; alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.3654832  0.2054832\n#&gt; sample estimates:\n#&gt; mean in group 1 mean in group 2 \n#&gt;            0.75            2.33\n\n\n\n\n\n\n\n\n注释\n\n\n\nEgon Pearson 接过他父亲 Karl Pearson 的职位，担任伦敦大学学院的高尔顿统计教授。许宝騄（Pao-Lu Hsu）在 Jerzy Neyman 和 Egon Pearson 主编的杂志《Statistical Research Memoirs》发表第一篇关于 Behrens-Fisher 问题的论文 (HSU 1938)，1998 年关于 Behrens-Fisher 问题的综述 (Kim 和 Cohen 1998)。陈家鼎和郑忠国一起整理了许宝騄的生平事迹和学术成就，见《许宝騄先生的生平和学术成就》。钟开涞（Kai-Lai Chung）将许宝騄的论文集整理出版 (HSU 1983)。\n\n\nt 检验的影响是如此巨大，以至于广泛存在于具有统计功能的软件中，比如办公软件里的 t 检验。以 MacOS 上的 Numbers 表格软件为例，如 图 12.5 所示，首先打开 Numbers 软件，新建工作表，输入两组数值，然后点击空白处，再从顶部导航栏找到「插入」菜单，「公式」选项，点击扩展选项「新建公式」，在弹出的会话条里输入 TTEST，依次选择第一组，第二组值，检验类型和样本类型，最后点击确认，即可得到两样本 t 检验的 P 值结果。\n\n\n\n\n\n\n\n图 12.5: 办公软件 Numbers 的两样本 t 检验\n\n\n\n\n微软 Excel 办公软件也提供 t 检验计算器，和 MacOS 系统上的 Numbers 办公软件类似，它提供 T.TEST 函数，计算结果也一样，此处从略。R 软件自带 t.test() 函数，也是用于做 t 检验，如下：\n\nt.test(x = c(3, 4, 5, 8, 9, 1, 2, 4, 5), y = c(6, 19, 3, 2, 14, 4, 5, 17, 1))\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  c(3, 4, 5, 8, 9, 1, 2, 4, 5) and c(6, 19, 3, 2, 14, 4, 5, 17, 1)\n#&gt; t = -1.3622, df = 10.255, p-value = 0.2023\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -8.767183  2.100516\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  4.555556  7.888889\n\n\n\n12.2.2 正态总体方差检验\n比较两个正态总体的方差是否相等，F 检验。\n\n# 两样本\nvar.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; F = 0.79834, num df = 9, denom df = 9, p-value = 0.7427\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.198297 3.214123\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;          0.7983426\n\n# 或者\nbartlett.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; Bartlett's K-squared = 0.10789, df = 1, p-value = 0.7426\n\n\n注意：函数 bartlett.test() 支持多样本情况。\n\n12.2.3 总体未知均值检验\n在总体分布未知的情况下，比较均值是否相等的检验。\n\n\nwilcox.test() 适用于单样本和两样本的均值检验，单样本 Wilcoxon 秩和检验，两样本 Wilcoxon 符号秩和检验，后者也叫 Mann-Whitney 检验。\n\nkruskal.test() 适用于两样本和多样本，比较多个均值是否相等的检验，Kruskal-Wallis 秩和检验。\n\n单样本和两样本 wilcox.test()。\n\nwilcox.test(extra ~ group, data = sleep)\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; \n#&gt;  Wilcoxon rank sum test with continuity correction\n#&gt; \n#&gt; data:  extra by group\n#&gt; W = 25.5, p-value = 0.06933\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\ncoin 包提供渐进 Wilcoxon-Mann-Whitney 检验\n\n# Asymptotic Wilcoxon-Mann-Whitney Test\nwilcox_test(extra ~ group, data = sleep, conf.int = TRUE)\n\n#&gt; \n#&gt;  Asymptotic Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  extra by group (1, 2)\n#&gt; Z = -1.8541, p-value = 0.06372\n#&gt; alternative hypothesis: true mu is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.500000e+00  1.270214e-10\n#&gt; sample estimates:\n#&gt; difference in location \n#&gt;              -1.347344\n\n# Exact Wilcoxon-Mann-Whitney Test\nwilcox_test(\n  extra ~ group, data = sleep,\n  distribution = \"exact\", conf.int = TRUE\n)\n\n#&gt; \n#&gt;  Exact Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  extra by group (1, 2)\n#&gt; Z = -1.8541, p-value = 0.06582\n#&gt; alternative hypothesis: true mu is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.5  0.0\n#&gt; sample estimates:\n#&gt; difference in location \n#&gt;                  -1.35\n\n\n两样本和多样本 kruskal.test() 。\n\nkruskal.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  extra by group\n#&gt; Kruskal-Wallis chi-squared = 3.4378, df = 1, p-value = 0.06372\n\n\n能用参数检验的一定也可以用非参数检验，一般来说，非参数检验的功效不小于参数检验，非参数检验不要求分布是正态，比如此时 P 值从 0.07939 降至 0.06372。\n\n12.2.4 总体未知方差检验\n对总体没有分布要求的方差齐性检验方法有三个，按适用范围分类，见下 表格 12.3 。\n\n\n表格 12.3: 检验方法分类\n\n\n\n\n\n\n\n两个样本\n多个样本\n\n\n\nAnsari-Bradley 检验 ansari.test()\n\nMood 检验 mood.test()\n\n\n\nFligner-Killeen 检验 fligner.test()\n\n\n\n\n\n\n\n以 A. R. Ansari 和 R. A. Bradley 命名的 Ansari-Bradley 检验 (Ansari 和 Bradley 1960)，对应的 R 函数是 ansari.test() ，以 A. M. Mood 命名的 Mood 检验 (Mood 1954)，对应的 R 函数是 mood.test() ，这两者都属于两样本的非参数检验，检验尺度参数是否相同（齐性）。以 M. A. Fligner 和 T. J. Killeen 命名的 Fligner-Killeen 检验 (Fligner 和 Killeen 1976)，对应的 R 函数是 fligner.test() ，也属于非参数检验，适用于两样本和多样本的情况。非参数检验常涉及位置参数和尺度参数这一对概念，就正态分布而言，位置参数可以理解为均值 \\(\\mu\\) ，尺度参数可以理解为方差 \\(\\sigma^2\\) 。\n\nansari.test(extra ~ group, data = sleep)\n\n#&gt; Warning in ansari.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; \n#&gt;  Ansari-Bradley test\n#&gt; \n#&gt; data:  extra by group\n#&gt; AB = 50.5, p-value = 0.4927\n#&gt; alternative hypothesis: true ratio of scales is not equal to 1\n\nmood.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Mood two-sample test of scale\n#&gt; \n#&gt; data:  extra by group\n#&gt; Z = 0.44761, p-value = 0.6544\n#&gt; alternative hypothesis: two.sided\n\nfligner.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; Fligner-Killeen:med chi-squared = 0.21252, df = 1, p-value = 0.6448",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multi-samples",
    "href": "common-statistical-tests.html#sec-multi-samples",
    "title": "12  常见的统计检验",
    "section": "\n12.3 多样本检验",
    "text": "12.3 多样本检验\n\n\n\n\n\nflowchart LR\n  A(多样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D2(方差相等) --&gt; E2(F 检验)\n  C1 --&gt; D3(方差不等) --&gt; E3(F 检验)\n  B1 --&gt; C2(方差检验) --&gt; E4(Hartley 检验\\n Bartlett 检验\\n 修正的 Bartlett 检验\\n Levene 检验)\n  B2 --&gt; C3(均值检验) --&gt; E5(Kruskal-Wallis 秩和检验\\n Friedman 秩和检验\\n Quade 检验)\n  B2 --&gt; C4(方差检验) --&gt; E7(Fligner-Killeen 检验)\n\n\n\n\n图 12.6: 多样本检验\n\n\n\n\n本节考虑 Base R 内置的 PlantGrowth 数据集，它收集自 Annette J. Dobson 所著书籍《An Introduction to Statistical Modelling》(Dobson 1983) 第 2 章第 2 节的案例 — 研究植物在两种不同试验条件下的生长情况，植物通过光合作用吸收土壤的养分和空气中的二氧化碳，完成积累，故以植物的干重来刻画植物的生长情况，首先将几乎相同的种子随机地分配到实验组和对照组，基于完全随机实验设计（completely randomized experimental design），经过预定的时间后，将植物收割，干燥并称重。\n\nstr(PlantGrowth)\n\n#&gt; 'data.frame':    30 obs. of  2 variables:\n#&gt;  $ weight: num  4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ...\n#&gt;  $ group : Factor w/ 3 levels \"ctrl\",\"trt1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n设立对照组（控制组）ctrl 和实验组 trt1 和 trt2，比较不同的处理方式对植物干重的影响\n\nsummary(PlantGrowth)\n\n#&gt;      weight       group   \n#&gt;  Min.   :3.590   ctrl:10  \n#&gt;  1st Qu.:4.550   trt1:10  \n#&gt;  Median :5.155   trt2:10  \n#&gt;  Mean   :5.073            \n#&gt;  3rd Qu.:5.530            \n#&gt;  Max.   :6.310\n\n\n每个组都有 10 颗植物，生长情况如 图 12.7 所示\n\n## Annette J. Dobson 扩展的 Plant Weight Data 数据，见 59 页\nlibrary(ggplot2)\nggplot(data = PlantGrowth, aes(x = group, y = weight, color = group)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n图 12.7: 植物干重\n\n\n\n\n\n12.3.1 正态总体均值检验\n\n12.3.1.1 假定同方差\n讲清楚原假设和备择假设。讲清楚假设检验、方差分析、一般线性模型（包含广义线性模型和线性混合效应模型）的关系。\n\\(\\sigma_i^2 = \\mathsf{Var}\\{\\epsilon_{ij}\\}, i = 1,2,3\\) 表示第 \\(i\\) 组的方差，\n\\[\ny_{ij} = \\mu + \\epsilon_{ij}, i = 1,2,3\n\\]\n其中 \\(\\mu\\) 是固定的未知参数。单因素方差分析 oneway.test()\n\n# 假设各组方差相同\noneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)\n\n#&gt; \n#&gt;  One-way analysis of means\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 4.8461, num df = 2, denom df = 27, p-value = 0.01591\n\n\n线性模型也假定各个组的方差是相同的，模型显著性检验的结果和上面是一致的。\n\nfit_lm &lt;- lm(weight ~ group, data = PlantGrowth)\nanova(fit_lm) # 或者 summary(fit)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: weight\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  3.7663  1.8832  4.8461 0.01591 *\n#&gt; Residuals 27 10.4921  0.3886                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n模型输出整理成 表格 12.4\n\n\n\n表格 12.4: 线性回归的输出\n\n\n\n\n\n估计值\n标准差\nt 统计量\nP 值\n\n\n\n\\(\\alpha\\)\n5.032\n0.1971\n25.5265\n0.0000\n\n\n\\(\\beta_1\\)\n-0.371\n0.2788\n-1.3308\n0.1944\n\n\n\\(\\beta_2\\)\n0.494\n0.2788\n1.7720\n0.0877\n\n\n\n\n\n\n\n\n\n12.3.1.2 假定异方差\n\n# 计算各个组的方差\naggregate(data = PlantGrowth, weight ~ group, FUN = var)\n\n#&gt;   group    weight\n#&gt; 1  ctrl 0.3399956\n#&gt; 2  trt1 0.6299211\n#&gt; 3  trt2 0.1958711\n\n# 或者\nwith(PlantGrowth, tapply(weight, group, var))\n\n#&gt;      ctrl      trt1      trt2 \n#&gt; 0.3399956 0.6299211 0.1958711\n\n\n各个组的方差确实不太相同。\n\n# 假设各组方差不同\noneway.test(weight ~ group, data = PlantGrowth, var.equal = FALSE)\n\n#&gt; \n#&gt;  One-way analysis of means (not assuming equal variances)\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 5.181, num df = 2.000, denom df = 17.128, p-value = 0.01739\n\n\n线性混合效应模型，假定每一组（层）有不同的方差。\n\nfit_gls &lt;- nlme::gls(weight ~ 1,\n  data = PlantGrowth, method = \"ML\",\n  weights = nlme::varIdent(form = ~ 1 | group)\n)\nsummary(fit_gls)\n\n#&gt; Generalized least squares fit by maximum likelihood\n#&gt;   Model: weight ~ 1 \n#&gt;   Data: PlantGrowth \n#&gt;        AIC      BIC    logLik\n#&gt;   67.99884 73.60363 -29.99942\n#&gt; \n#&gt; Variance function:\n#&gt;  Structure: Different standard deviations per stratum\n#&gt;  Formula: ~1 | group \n#&gt;  Parameter estimates:\n#&gt;      ctrl      trt1      trt2 \n#&gt; 1.0000000 1.6028758 0.9103568 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Value Std.Error  t-value p-value\n#&gt; (Intercept) 5.205999  0.115762 44.97158       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.78654574 -0.92900218 -0.08794552  0.61374803  2.09128348 \n#&gt; \n#&gt; Residual standard error: 0.5798892 \n#&gt; Degrees of freedom: 30 total; 29 residual\n\n\n考虑每个组有不同的方差，放开同方差的假设，发现，从对数似然的角度来看，有一定提升。\n\nlogLik(fit_lm)\n\n#&gt; 'log Lik.' -26.80952 (df=4)\n\nlogLik(fit_gls)\n\n#&gt; 'log Lik.' -29.99942 (df=4)\n\n\n\n12.3.2 正态总体方差检验\n总体服从正态分布，有四种常见的参数检验方法：\n\nHartley 检验：各组样本量必须相等。\nBartlett 检验：各组样本量可以相等或不等，但每个组的样本量必须不低于 5。\n修正的 Bartlett 检验：在样本量较大或较小、相等或不等场合都可使用。\nLevene 检验：相当于单因素组间方差分析，相比于 Bartlett 检验，Levene 检验更加稳健。\n\n\n\n\n\n\n\n提示\n\n\n\n在总体分布未知的情况下，检验方差齐性的非参数方法也都可以用在这里。\n\n\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的样本，设 \\(z_1,\\cdots,z_{n_3}\\) 是来自总体 \\(\\mathcal{N}(\\mu_3,\\sigma_3^2)\\) 的样本。\n\\[\n\\sigma_1^2 = \\sigma_2^2 = \\sigma_3^2 \\quad vs. \\quad \\sigma_1^2,\\sigma_2^2,\\sigma_3^2 \\quad  \\text{不全相等}\n\\]\nBartlett （巴特利特）检验 bartlett.test() 要求总体的分布为正态分布，检验各个组的方差是否有显著性差异，即方差齐性检验，属于参数检验，适用于多个样本的情况。\n\n# 三样本\nbartlett.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Bartlett's K-squared = 2.8786, df = 2, p-value = 0.2371\n\n# 或者\ncar::leveneTest(weight ~ group, data = PlantGrowth)\n\n#&gt; Levene's Test for Homogeneity of Variance (center = median)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  2  1.1192 0.3412\n#&gt;       27\n\n\n\n12.3.3 总体未知均值检验\nKruskal-Wallis 秩和检验 kruskal.test() 检验均值是否齐性。\n\nkruskal.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  weight by group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\n等价的线性模型表示\n\nfit_lm &lt;- lm(rank(weight) ~ group, data = PlantGrowth)\nanova(fit_lm) # summary(fit_lm)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: rank(weight)\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  618.95 309.475  5.1324 0.01291 *\n#&gt; Residuals 27 1628.05  60.298                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFriedman 秩和检验是非参数检验。适用于单因素重复测量数据的方差分析，检验是否存在一组值显著高于或低于其他组。针对 unreplicated blocked data\n典型场景：n 个品酒师对 k 瓶葡萄酒打分，是否存在一组打分显著高于其他组。检验睡眠质量一组人显著好于另一组人。\n\nfriedman.test(extra ~ group | ID, data = sleep)\n\n#&gt; \n#&gt;  Friedman rank sum test\n#&gt; \n#&gt; data:  extra and group and ID\n#&gt; Friedman chi-squared = 9, df = 1, p-value = 0.0027\n\n\nformula 参数取值为 a ~ b | c ，a 表示数据值，b 分组变量 groups，c 表示 blocks。\nQuade 检验 quade.test() 与 Friedman 检验类似，Quade 检验应用于 unreplicated complete block designs。\n\n# 睡眠实验\nquade.test(extra ~ group | ID, data = sleep)\n\n#&gt; \n#&gt;  Quade test\n#&gt; \n#&gt; data:  extra and group and ID\n#&gt; Quade F = 28.557, num df = 1, denom df = 9, p-value = 0.0004661\n\n\n术语涉及实验设计，比如完全区组设计 complete block designs 。1879 年迈克尔逊光速测量数据记录了五次实验，每次试验测量 20 次光速。数据集 morley 中光速 Speed 已经编码过了，为了展示方便，原始观测速度减去了 299000 (km/sec)。\n\n# 光速实验\nquade.test(Speed ~ Expt | Run, data = morley)\n\n#&gt; \n#&gt;  Quade test\n#&gt; \n#&gt; data:  Speed and Expt and Run\n#&gt; Quade F = 3.6494, num df = 4, denom df = 76, p-value = 0.008976\n\n\n\n\nggplot(data = morley, aes(x = Expt, y = Speed, group = Expt)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal() +\n  labs(x = \"Expt\", y = \"Speed (km/sec)\")\n\n\n\n\n\n\n图 12.8: 1879 年迈克尔逊光速实验数据\n\n\n\n\n\n12.3.4 总体未知方差检验\n三个及以上样本的方差齐性检验。进一步地，我们在线性模型的基础上考虑每个实验组有不同的方差，先做方差齐性检验。\n\n# 非参数检验\nfligner.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Fligner-Killeen:med chi-squared = 2.3499, df = 2, p-value = 0.3088\n\n\n检验的结果显示，可以认为三个组的方差没有显著差异。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-pairwise-data",
    "href": "common-statistical-tests.html#sec-pairwise-data",
    "title": "12  常见的统计检验",
    "section": "\n12.4 配对样本检验",
    "text": "12.4 配对样本检验\n配对样本检验算是两样本检验的一种特殊情况。若待检验的样本不止两个，则两两配对检验。\n\n\n表格 12.5: 配对样本检验\n\n\n\n\n\n\n\n样本\nR 函数\n\n\n两样本\n\n\nt.test(paired = TRUE) 正态总体均值检验\n\nwilcox.test(paired = TRUE) 总体未知均值检验\n\n\n\n\n\n\n\n12.4.1 配对 t 检验\n做两个组的配对 t 检验，函数 t.test() 的参数 paired 设置为 TRUE ，两个组的样本当作配对样本处理。\n\nt.test(extra ~ group, data = sleep, paired = TRUE)\n\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -4.0621, df = 9, p-value = 0.002833\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -2.4598858 -0.7001142\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;           -1.58\n\n\n做多个组的两两配对 t 检验，函数 pairwise.t.test() 的参数 paired 设置为 TRUE ，当仅做两个组的配对 t 检验时，检验结果与前面的等价。\n\nwith(sleep, pairwise.t.test(x = extra, g = group, paired = TRUE))\n\n#&gt; \n#&gt;  Pairwise comparisons using paired t tests \n#&gt; \n#&gt; data:  extra and group \n#&gt; \n#&gt;   1     \n#&gt; 2 0.0028\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n输出结果中，组 1 和组 2 配对 t 检验的 P 值为 0.0028。\n\n\n\n\n\n\n提示\n\n\n\n两个组的配对 t 检验还与变截距的线性混合效应模型等价。\n\nlibrary(nlme)\nm &lt;- lme(fixed = extra ~ group, random = ~ 1 | ID, data = sleep)\nsummary(m)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: sleep \n#&gt;        AIC      BIC    logLik\n#&gt;   77.95588 81.51737 -34.97794\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | ID\n#&gt;         (Intercept)  Residual\n#&gt; StdDev:      1.6877 0.8697384\n#&gt; \n#&gt; Fixed effects:  extra ~ group \n#&gt;             Value Std.Error DF  t-value p-value\n#&gt; (Intercept)  0.75 0.6003979  9 1.249172  0.2431\n#&gt; group2       1.58 0.3889588  9 4.062127  0.0028\n#&gt;  Correlation: \n#&gt;        (Intr)\n#&gt; group2 -0.324\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.63372282 -0.34157076  0.03346151  0.31510644  1.83858572 \n#&gt; \n#&gt; Number of Observations: 20\n#&gt; Number of Groups: 10\n\n\n输出结果中，固定效应部分 group2 意味着相对于第 1 组，第 2 组的增加值，其为 1.58，对应的 t 统计量的值为 4.062127， P 值为 0.0028。调用 nlme 包的函数 intervals() 计算固定效应部分 95% 的置信区间。\n\nintervals(m, which = \"fixed\")\n\n#&gt; Approximate 95% confidence intervals\n#&gt; \n#&gt;  Fixed effects:\n#&gt;                  lower est.    upper\n#&gt; (Intercept) -0.6081944 0.75 2.108194\n#&gt; group2       0.7001140 1.58 2.459886\n\n\ngroup2 对应的 95% 的置信区间是 \\((0.7001140, 2.459886)\\) 。\n\n\n\n12.4.2 配对 Wilcoxon 检验\nWilcoxon 检验函数 wilcox.test() 设置 paired = TRUE 可以做配对检验，但是仅限于两个组。\n\n# 不支持\n# wilcox.test(weight ~ group, data = PlantGrowth, paired = TRUE)\n# 支持\nwilcox.test(extra ~ group, data = sleep, paired = TRUE)\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with zeroes\n\n\n#&gt; \n#&gt;  Wilcoxon signed rank test with continuity correction\n#&gt; \n#&gt; data:  extra by group\n#&gt; V = 0, p-value = 0.009091\n#&gt; alternative hypothesis: true location shift is not equal to 0",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multiple-comparisons",
    "href": "common-statistical-tests.html#sec-multiple-comparisons",
    "title": "12  常见的统计检验",
    "section": "\n12.5 多重假设检验",
    "text": "12.5 多重假设检验\n同时检验多个统计假设。\n\n\n表格 12.6: 多重假设检验\n\n\n\n\n\n\n\n样本\nR 函数\n\n\n多样本\n\n\npairwise.t.test() 正态总体均值检验\n\npairwise.prop.test() 二项总体比例检验\n\npairwise.wilcox.test() 总体未知均值检验\n\n\n\n\n\n\n\n12.5.1 多重 t 检验\n数据集 sleep 仅有两个组，数据集 PlantGrowth 包含三个组，下面以数据集 PlantGrowth 为例，介绍做多个组同时进行两两比较的 t 检验。\n\n# 样本成对的情况\nwith(PlantGrowth, pairwise.t.test(x = weight, g = group, paired = TRUE))\n\n#&gt; \n#&gt;  Pairwise comparisons using paired t tests \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.346 -    \n#&gt; trt2 0.220 0.058\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n函数 pairwise.t.test() 以 P 值给出两两配对比较的结果，trt1 和 ctrl 配对比较，P 值为 0.346，trt2 和 ctrl 配对比较，P 值为 0.220，以此类推。\n\n# 样本非成对的情况\nwith(PlantGrowth, pairwise.t.test(x = weight, g = group))\n\n#&gt; \n#&gt;  Pairwise comparisons using t tests with pooled SD \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.194 -    \n#&gt; trt2 0.175 0.013\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n12.5.2 多重比例检验\n对于离散数据，做两两比例检验，采用函数 pairwise.prop.test() ，如下示例含有 4 个组。\n\nsmokers &lt;- c(83, 90, 129, 70)\npatients &lt;- c(86, 93, 136, 82)\npairwise.prop.test(smokers, patients)\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n\n#&gt; \n#&gt;  Pairwise comparisons using Pairwise comparison of proportions \n#&gt; \n#&gt; data:  smokers out of patients \n#&gt; \n#&gt;   1     2     3    \n#&gt; 2 1.000 -     -    \n#&gt; 3 1.000 1.000 -    \n#&gt; 4 0.119 0.093 0.124\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n12.5.3 Wilcoxon 检验\nWilcoxon 检验的是两个总体的均值是否相等。\n函数 pairwise.wilcox.test() 做两个及以上组的两两比较检验。\n\nwith(PlantGrowth, pairwise.wilcox.test(x = weight, g = group))\n\n#&gt; Warning in wilcox.test.default(xi, xj, paired = paired, ...): cannot compute\n#&gt; exact p-value with ties\n\n\n#&gt; \n#&gt;  Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.199 -    \n#&gt; trt2 0.126 0.027\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n12.5.4 Dunn 检验\ndunn.test 包提供函数 dunn.test() 实现 Dunn 检验，将 Kruskal-Wallis 秩和检验用于两两比较。\n\nlibrary(dunn.test)\nwith(PlantGrowth, dunn.test(x = weight, g = group, method = \"holm\", altp = TRUE))\n\n#&gt;   Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data: weight and group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.02\n#&gt; \n#&gt; \n#&gt;                          Comparison of weight by group                         \n#&gt;                                     (Holm)                                     \n#&gt; Col Mean-|\n#&gt; Row Mean |       ctrl       trt1\n#&gt; ---------+----------------------\n#&gt;     trt1 |   1.117725\n#&gt;          |     0.2637\n#&gt;          |\n#&gt;     trt2 |  -1.689289  -2.807015\n#&gt;          |     0.1823    0.0150*\n#&gt; \n#&gt; alpha = 0.05\n#&gt; Reject Ho if p &lt;= alpha",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-distribution-test",
    "href": "common-statistical-tests.html#sec-distribution-test",
    "title": "12  常见的统计检验",
    "section": "\n12.6 总体分布的检验",
    "text": "12.6 总体分布的检验\n前面介绍的检验方法都是对总体的某个特征数（均值、方差）进行检验，下面介绍的检验方法是针对分布的性质。比如样本是否来自正态分布，两个样本是否来自同一分布，样本点之间是否相互独立，样本点列是否平稳等。通过检验方法探索样本的分布性质。\n\n12.6.1 正态性检验\n什么样的数据是正态的，理论上是清楚的，对统计建模来说，更实际的问题是什么样的数据是够正态的！探索性数据分析是不断提出假设和验证假设的过程。\n\nUsually (but not always) doing tests of normality reflect a lack of understanding of the power of rank tests, and an assumption of high power for the tests (qq plots don’t always help with that because of their subjectivity). When possible it’s good to choose a robust method. Also, doing pre-testing for normality can affect the type I error of the overall analysis.\n— Frank Harrell 1\n\n检验：拒绝原假设和接受原假设的风险，数据本身和理论的正态分布的距离，抛开 P 值\nShapiro 和 Wilk 提出的 W 检验 (Shapiro 和 Wilk 1965) ，对应的 R 函数为 shapiro.test()\n\nset.seed(20232023)\nx &lt;- rnorm(100, mean = 5, sd = 3)\nshapiro.test(x)\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.98635, p-value = 0.3954\n\n\n\nThe issue really comes down to the fact that the questions: “exactly normal?”, and “normal enough?” are 2 very different questions (with the difference becoming greater with increased sample size) and while the first is the easier to answer, the second is generally the more useful one.\n— Greg Snow 2\n\nEP 检验对多种备择假设有较高的效率，利用样本的特征函数和正态分布的特征函数的差的模的平方产生的一个加权积分得到 EP 检验统计量 (Epps 和 Pulley 1983)\n\n\n\n\n\n\n提示\n\n\n\n样本量 \\(n \\geq 200\\) EP 检验统计量 \\(T_{EP}\\) 非常接近 \\(n = \\infty\\) 时 \\(T_{EP}\\) 的分位数。\n\n\n设 \\(x_1, \\ldots, x_n\\) 是来自正态总体 \\(\\mathcal{N}(\\mu,\\sigma^2)\\) 的样本， EP 检验统计量定义为\n\\[\nT_{EP} = 1 + \\frac{n}{\\sqrt{3}} + \\frac{2}{n}\\sum_{i=2}^{n}\\sum_{j=1}^{i-1}\\exp\\big\\{ - \\frac{(x_j - x_i)^2}{2s^2_{\\star}}  \\big\\} - \\sqrt{2} \\sum_{i=1}^{n}\\exp\\big\\{- \\frac{(x_i - \\bar{x})^2}{4s^2_{\\star}}  \\big\\}\n\\]\n其中 \\(\\bar{x},s^2_{\\star}\\) 分别是样本均值和（除以 \\(n\\) 的）样本方差。\n\n12.6.2 同分布检验\nLilliefors 检验 3 和单样本的 ks 检验的关系\n\nAs to whether you can do a Lilliefors test for several groups, that depends entirely on your ability to understand what the underlying question would be (see Adams D 1979).\n— Knut M. Wittkowski 4\n\nKolmogorov-Smirnov 检验：单样本或两样本的同分布检验 ks.test()\n\n# 数据 x 与正态分布比较\nks.test(x, y = \"pnorm\")\n\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x\n#&gt; D = 0.85897, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: two-sided\n\n\n\n12.6.3 相关性检验\n样本的相关性检验 cor.test()：Pearson’s 相关系数检验，Kendall’s \\(\\tau\\) 检验或者 Spearman’s \\(\\rho\\) 检验。基于美国高等法院律师对州法官的评级数据集 USJudgeRatings 介绍各项评分之间的相关性。\n\n# cor.test(method = \"pearson\")  # lm(y ~ 1 + x)\ncor.test(~ CONT + INTG, data = USJudgeRatings)\n\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  CONT and INTG\n#&gt; t = -0.8605, df = 41, p-value = 0.3945\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.4168591  0.1741182\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.1331909\n\n\n其中，变量 CONT 表示律师与法官的联系次数，INTG 表示司法公正。\n\n# cor.test(method = \"kendall\")\n# cor.test(method = \"spearman\") # lm(rank(y) ~ 1 + rank(x))\n\n\n12.6.4 独立性检验\n时间序列独立性检验 Box.test() 计算 Box-Pierce 或 Ljung-Box 检验统计量来检查给定时间序列的独立性假设。\n\n12.6.5 平稳性检验\n时间序列单位根检验，检验时间序列平稳性 Phillips-Perron 的单位根检验 PP.test()\n\nPP.test(x, lshort = TRUE)",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multivariate-hypothesis-testing",
    "href": "common-statistical-tests.html#sec-multivariate-hypothesis-testing",
    "title": "12  常见的统计检验",
    "section": "\n12.7 多元分布情形",
    "text": "12.7 多元分布情形\n\nHotelling T2 检验：总体服从多元正态分布，两样本均值之差的检验。\nMauchly 球形检验：总体服从多元正态分布，单样本协方差矩阵的检验。\n\n\n12.7.1 Hotelling T2 检验\nHotelling T2 检验是一维情形下两样本 \\(t\\) 检验的多维推广。\n\n12.7.2 Mauchly 球形检验\nMauchly 球形检验 mauchly.test() 检验：Wishart 分布的协方差矩阵是否正比于给定的矩阵。一组样本来自多元正态分布，样本的协方差矩阵是关于样本的随机矩阵，随机矩阵的分布服从 Wishart 分布。\n如果 \\(\\bm{x_1}, \\bm{x_2}, \\cdots, \\bm{x_m}\\)，\\(\\bm{x_i} \\in \\mathbb{R}^p\\)，\\(\\bm{x_i} \\overset{i.i.d}{\\sim} \\mathrm{MVN}(0,\\Sigma)\\)，即 \\(m\\) 个样本点都服从均值为 \\(0\\)，协方差矩阵为 \\(\\Sigma\\) 的 \\(p\\) 维多元正态分布 \\(\\mathrm{MVN}(0,\\Sigma)\\)，且样本点之间相互独立。则 \\(X = \\bm{x}^{\\top}\\bm{x}\\) 服从参数为 \\(\\Sigma\\) ，自由度为 \\(m\\) 的 Wishart 分布 \\(W_p(\\Sigma, m)\\)。概率密度函数如下\n\\[\nf(X) = \\frac{1}{2^{\\frac{mp}{2}}|\\Sigma|^{\\frac{m}{2}}\\Gamma_{p}(\\frac{m}{2})}|X|^{(m-p-1)/2}\\exp\\{-\\frac{1}{2}\\mathrm{tr}(\\Sigma^{-1}X)\\}\n\\]\n其中， \\(\\Gamma_p\\) 是多元伽马函数，定义如下\n\\[\n\\Gamma_p(\\frac{m}{2}) = \\pi^{p(p-1)/4}\\prod_{j=1}^{p}\\Gamma(\\frac{m}{2} - \\frac{j-1}{2})\n\\]\nR 语言内置了一个模拟数生成器，可以直接模拟出服从 Wishart 分布 \\(W_p(\\Sigma, m)\\) 的样本，\\(m = \\mathrm{df}, \\Sigma = \\mathrm{Sigma}\\)。 R 语言命令如下：\n\nrWishart(n, df, Sigma)\n\n其中，整型参数 n 指定样本量，数值参数 df 指定自由度，正定的 \\(p \\times p\\) 矩阵 Sigma 指定 Wishart 分布的矩阵参数。rWishart() 返回一个 \\(p\\times p \\times n\\) 数组 \\(R\\)，其中 \\(R[,,i]\\) 是正定矩阵，是服从 Wishart 分布 \\(W_p(\\Sigma, m)\\) 的一个样本点，其中 \\(m = \\mathrm{df}, \\Sigma = \\mathrm{Sigma}\\)。\n\nset.seed(2022)\n# 构造 n 个随机矩阵\nS &lt;- matrix(c(1.2, 0.9, 0.9, 1.2), nrow = 2, ncol = 2)\nrWishart(n = 3, df = 2, Sigma = S)\n\n#&gt; , , 1\n#&gt; \n#&gt;          [,1]      [,2]\n#&gt; [1,] 3.213745 1.2445391\n#&gt; [2,] 1.244539 0.5032642\n#&gt; \n#&gt; , , 2\n#&gt; \n#&gt;          [,1]     [,2]\n#&gt; [1,] 4.443057 3.387850\n#&gt; [2,] 3.387850 2.605341\n#&gt; \n#&gt; , , 3\n#&gt; \n#&gt;          [,1]     [,2]\n#&gt; [1,] 3.614911 4.797919\n#&gt; [2,] 4.797919 6.846811\n\n\n随机矩阵 \\(M\\) 的期望 \\(\\mathsf{E}(M) = m \\times \\Sigma\\)，随机矩阵 \\(M\\) 中每个元素的方差\n\\[\n\\mathsf{Var}(M_{ij}) = m (\\Sigma_{ij}^2 + \\Sigma_{ii}\\Sigma_{jj}), \\quad S = \\Sigma\n\\]\n若 \\(p = 1\\)，即 \\(\\Sigma\\) 是一个标量 \\(\\sigma^2\\)，Wishart 分布退化为自由度为 \\(\\mathrm{df}\\) 的卡方分布 \\(\\chi^2\\)，即 \\(W_1(\\sigma^2, m) = \\sigma^2\\chi_{m}^2\\)。下面计算随机矩阵 \\(M\\) 的期望。\n\nset.seed(2022)\nWish &lt;- rWishart(n = 3000, df = 2, Sigma = S)\n# 计算随机矩阵 M 的期望\napply(Wish, MARGIN = 1:2, FUN = mean)\n\n#&gt;          [,1]     [,2]\n#&gt; [1,] 2.375915 1.792558\n#&gt; [2,] 1.792558 2.430074\n\n# 随机矩阵 M 的期望理论值\n2 * S\n\n#&gt;      [,1] [,2]\n#&gt; [1,]  2.4  1.8\n#&gt; [2,]  1.8  2.4\n\n\n接着计算随机矩阵 \\(M\\) 的方差。\n\n# 样本方差\napply(Wish, MARGIN = 1:2, var)\n\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.668746 4.472606\n#&gt; [2,] 4.472606 5.729270\n\n# 理论方差\n2*(S^2 + tcrossprod(diag(S)))\n\n#&gt;      [,1] [,2]\n#&gt; [1,] 5.76 4.50\n#&gt; [2,] 4.50 5.76",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-common-statistical-tests-notes",
    "href": "common-statistical-tests.html#sec-common-statistical-tests-notes",
    "title": "12  常见的统计检验",
    "section": "\n12.8 假设检验的一些注记",
    "text": "12.8 假设检验的一些注记\n真实数据的情况是复杂多样的，本章按照数据情况对检验方法分类，方便读者根据手头的数据情况，快速从众多的方法中定位最合适的检验方法。依次是单样本检验、两样本检验、多样本检验、计数数据检验、配对样本检验。如果已知符合参数检验的条件，优先考虑参数检验。如果不确定是否符合参数检验的条件，对参数检验和非参数检验方法都适用，非参数检验方法的功效更大，方法更优。在总体分布未知的情况下，无论是对均值检验还是对方差检验，大部分情况下都需要非参数检验方法。\n在假设检验理论方面作出贡献的人非常多，自 Karl Pearson 提出卡方统计量、卡方分布和卡方检验以来，陆续涌现出来一批人及载入史册的工作，见下表。不难看出，19 世纪后半叶至20世纪前半叶，假设检验理论经过一个世纪的发展趋于成熟。从假设检验这个细分领域也印证了世界的统计中心从英国逐渐转移到美国，相比而言，中国在这方面的贡献微乎其微。笔者同时也注意到很多检验方法都是以人名命名的，且已经被编写到各类统计软件中。R 语言中有十分丰富的统计检验函数，根据这些函数及其帮助文档可以追溯到检验方法的发明者，再从维基百科中找到学者及其提出的检验方法的详情页，最后，根据学者的出生日期排序整理成表格。\n\n\n表格 12.7: 对假设检验理论有重要贡献的学者\n\n\n\n\n\n\n\n\n\n\n\n姓名\n国籍\n出生\n死亡\n寿命\n贡献\n\n\n\nK. Pearson\n英国\n1857-03-27\n1936-04-27\n79\n卡方分布、卡方检验\n\n\nC. Spearman\n英国\n1863-09-10\n1945-09-17\n82\nSpearman’s \\(\\rho\\)\n\n\n\nW. S. Gosset\n英国\n1876-06-13\n1937-10-16\n61\nt 分布、t 检验\n\n\nR. A. Fisher\n英国\n1890-02-17\n1962-07-29\n72\nF 检验、Fisher 精确检验\n\n\nF. Wilcoxon\n美国\n1892-09-02\n1965-11-18\n73\nWilcoxon 秩检验\n\n\nH. Cramér\n瑞士\n1893-09-25\n1985-10-05\n92\nCramér’s V\n\n\nJ. Neyman\n波兰、美国\n1894-04-16\n1981-08-05\n87\nNeyman-Pearson 引理\n\n\nE. S. Pearson\n英国\n1895-08-11\n1980-06-12\n84\nNeyman-Pearson 引理\n\n\nH. Hotelling\n美国\n1895-09-29\n1973-12-26\n78\nHotelling T2 检验\n\n\nE. J. G. Pitman\n澳大利亚\n1897-10-29\n1993-07-21\n95\nPitman 估计\n\n\nJ. Wishart\n英国\n1898-11-28\n1956-07-14\n57\nWishart 分布\n\n\nQ. M. McNemar\n美国\n1900-02-20\n1986-07-03\n86\nMcNemar 检验\n\n\nF. Yates\n英国\n1902-05-12\n1994-06-17\n92\nYates 矫正\n\n\nA. Wald\n匈牙利\n1902-10-31\n1950-12-13\n48\nWald 检验\n\n\nA. Kolmogorov\n苏联\n1903-04-25\n1987-10-20\n84\nKolmogorov-Smirnov 检验\n\n\nS. S. Wilks\n美国\n1906-06-17\n1964-03-07\n57\nWilks 检验/似然比检验\n\n\nJ. W. Mauchly\n美国\n1907-08-30\n1980-01-08\n72\nMauchly 球形检验\n\n\nM. Kendall\n英国\n1907-09-06\n1983-03-29\n76\nKendall’s \\(\\tau\\)\n\n\n\nW. G. Cochran\n英国、美国\n1909-07-15\n1980-03-29\n70\nCochran–Mantel–Haenszel 检验\n\n\nM. S. Bartlett\n英国\n1910-06-18\n2002-01-08\n91\nBartlett 检验\n\n\nW. M. Haenszel\n美国\n1910-06-19\n1998-03-13\n87\nCochran–Mantel–Haenszel 检验\n\n\nB. L. Welch\n英国\n1911\n1989-12-29\n78\nWelch t 检验\n\n\nH. O. Hartley\n德国\n1912-04-13\n1980-12-30\n68\nHartley 检验\n\n\nM. Friedman\n美国\n1912-07-31\n2006-11-16\n94\nFriedman 秩和检验\n\n\nW. A. Wallis\n美国\n1912-11-05\n1998-10-12\n85\nKruskal-Wallis 检验\n\n\nH. Levene\n美国\n1914-01-17\n2003-07-02\n89\nLevene 检验\n\n\nJ. W. Tukey\n美国\n1915-06-16\n2000-07-26\n85\nTukey’s HSD 检验\n\n\nO. J. Dunn\n美国\n1915-09-01\n2008-01-12\n92\nDunn 检验\n\n\nE. L. Lehmann\n法国、美国\n1917-11-20\n2009-09-12\n91\nLehmann-Scheffé 定理\n\n\nT. W. Anderson\n美国\n1918-06-05\n2016-09-17\n98\nAnderson–Darling 检验\n\n\nN. Mantel\n美国\n1919-02-16\n2002-05-25\n83\nCochran–Mantel–Haenszel 检验\n\n\nW. Kruskal\n美国\n1919-10-10\n2005-04-21\n85\nKruskal-Wallis 检验\n\n\nGeorge E. P. Box\n英国、美国\n1919-10-18\n2013-03-28\n93\nBox-Pierce 检验\n\n\nC. R. Rao\n印度、美国\n1920-09-10\n2023-08-22\n102\nScore 检验\n\n\nM. Wilk\n加拿大\n1922-12-18\n2013-02-19\n90\nShapiro-Wilk 检验\n\n\nJ. Durbin\n英国\n1923-06-30\n2012-06-23\n88\nDurbin 检验\n\n\nL. Le Cam\n法国\n1924-11-18\n2000-04-25\n75\n渐近理论\n\n\nH. Lilliefors\n美国\n1928-06-14\n2008-02-23\n80\nLilliefors 检验\n\n\nS. S. Shapiro\n美国\n1930-07-13\n-\n93\nShapiro-Wilk 检验\n\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n笔者仅根据自己搜集了解的材料制作此表，受一定的局限，或有缺漏和主观。20 世纪 60 年代后，假设检验理论开始成熟起来了，所以仅考虑 1930 年以前出生的。此外，学者需具有一定的名气，至少收录在维基百科词条里。\n\n\n其中，最重要的统计学家及其学术传承关系见下 图 12.9 。\n\n\n\n\n\nflowchart LR\n  F_Galton(F. Galton\\n 1822-1911) --&gt; K_Pearson(K. Pearson\\n 1857-1936)\n  K_Pearson --&gt; R_A_Fisher(R. A. Fisher \\n 1890-1962)\n  R_A_Fisher --&gt; J_Neyman(J. Neyman\\n1894-1981)\n  R_A_Fisher --&gt; E_S_Pearson(E. S. Pearson \\n1895-1980)\n  J_Neyman --&gt; E_L_Lehmann(E. L. Lehmann\\n1917-2009)\n  E_S_Pearson --&gt; A_Wald(A. Wald\\n1902-1950)\n\n\n\n\n图 12.9: 最重要的统计学家及其学术传承关系\n\n\n\n\nF. Galton 是 K. Pearson 的老师，E. S. Pearson 是 K. Pearson 的儿子。E. L. Lehmann 是 J. Neyman 的学生，J. Neyman 和 E. S. Pearson 一起提出 N-P 引理，是置信区间和假设检验理论的奠基人。假设检验和区间估计、决策理论是紧密相关的，A. Wald 是继 J. Neyman 和 E. S. Pearson 之后，继续开疆拓土的一位统计学家，不幸的是，在一场飞机事故中英年早逝。\n\n12.8.1 假设检验和多重比较的关系\nFDR 是 False Discovery Rate 的简称\n\n12.8.2 假设检验和方差分析的关系\n\n12.8.2.1 单因素一元方差分析\n函数 aov() 可以做单、双因素一元方差分析\n\nfit_aov &lt;- aov(weight ~ group, data = PlantGrowth)\n\n两两比较，多重比较\n\nTukeyHSD(fit_aov)\n\n#&gt;   Tukey multiple comparisons of means\n#&gt;     95% family-wise confidence level\n#&gt; \n#&gt; Fit: aov(formula = weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt; $group\n#&gt;             diff        lwr       upr     p adj\n#&gt; trt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711\n#&gt; trt2-ctrl  0.494 -0.1972161 1.1852161 0.1979960\n#&gt; trt2-trt1  0.865  0.1737839 1.5562161 0.0120064\n\n\n自己实现方差分析\n\n# 自由度\ndf1 &lt;- 2\ndf2 &lt;- 27\n# 每组样本量\ngroup.size &lt;- 10\n# 组间方差\nsq.between &lt;- sum(tapply(\n  PlantGrowth$weight, PlantGrowth$group,\n  function(x) (mean(x) - mean(PlantGrowth$weight))^2\n)) * group.size\n\nmean.sq.between &lt;- sq.between / df1\n\n# 组内方差\nsq.within &lt;- sum(tapply(\n  PlantGrowth$weight, PlantGrowth$group,\n  function(x) sum((x - mean(x))^2)\n))\n\nmean.sq.within &lt;- sq.within / df2\n# F 统计量\nf.value &lt;- mean.sq.between / mean.sq.within\nf.value\n\n#&gt; [1] 4.846088\n\n# P 值\np.value &lt;- 1 - pf(f.value, df1, df2)\np.value\n\n#&gt; [1] 0.01590996\n\n\n从假设检验角度看单因素方差分析，方差分析其实是在比较多个组的均值是否有显著差异。\n\noneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)\n\n#&gt; \n#&gt;  One-way analysis of means\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 4.8461, num df = 2, denom df = 27, p-value = 0.01591\n\n\n方差分析还可以纳入线性模型的框架内\n\nfit &lt;- lm(weight ~ group, data = PlantGrowth)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.0710 -0.4180 -0.0060  0.2627  1.3690 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   5.0320     0.1971  25.527   &lt;2e-16 ***\n#&gt; grouptrt1    -0.3710     0.2788  -1.331   0.1944    \n#&gt; grouptrt2     0.4940     0.2788   1.772   0.0877 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.6234 on 27 degrees of freedom\n#&gt; Multiple R-squared:  0.2641, Adjusted R-squared:  0.2096 \n#&gt; F-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\n\nanova(fit)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: weight\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  3.7663  1.8832  4.8461 0.01591 *\n#&gt; Residuals 27 10.4921  0.3886                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n假定各个组来自正态总体，且它们的方差相同，从 F 统计量的值和检验的 P 值看，方差分析 aov() 、假设检验 oneway.test() 和线性模型 lm() 在这里等价了。\n\n12.8.2.2 双因素一元方差分析\n\nwith(ToothGrowth, interaction.plot(supp, dose, len))\n\n\n\n\n\n\n图 12.10: OJ 和 VC 的交互作用\n\n\n\n\n如果 dose = 2， 则 len 与提供的方式 supp 没有关系。\n\nfit_aov &lt;- aov(len ~ supp * dose, data = ToothGrowth)\nfit_aov\n\n#&gt; Call:\n#&gt;    aov(formula = len ~ supp * dose, data = ToothGrowth)\n#&gt; \n#&gt; Terms:\n#&gt;                      supp      dose supp:dose Residuals\n#&gt; Sum of Squares   205.3500 2224.3043   88.9201  933.6349\n#&gt; Deg. of Freedom         1         1         1        56\n#&gt; \n#&gt; Residual standard error: 4.083142\n#&gt; Estimated effects may be unbalanced\n\n\n\n12.8.2.3 单因素多元方差分析\nPlantGrowth 属于一元方差分析，观测变量只有植物干重一个变量。如果推广到多个变量，就是多元方差分析 multivariate analysis of variance 。不同种类的鸢尾花的萼片长度的分布有所不同。\n\nlibrary(ggplot2)\nlibrary(ggridges)\nggplot(data = iris, aes(x = Sepal.Length, y = Species, fill = Species)) +\n  scale_fill_brewer(palette = \"Greys\") +\n  geom_density_ridges(bandwidth = 0.2) +\n  theme_ridges(font_size = 12, font_family = \"sans\")\n\n\n\n\n\n\n图 12.11: 鸢尾花萼片长度的分布\n\n\n\n\n\nfit &lt;- manova(cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, data = iris)\nsummary(fit, test = \"Wilks\")\n\n#&gt;            Df    Wilks approx F num Df den Df    Pr(&gt;F)    \n#&gt; Species     2 0.023439   199.15      8    288 &lt; 2.2e-16 ***\n#&gt; Residuals 147                                              \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nP 值小于 0.0.5，说明 iris 数据集三个组的均值向量有显著差异。关于均值向量的检验方法，请看 ?summary.manova 。\n按 Species 分组统计各个变量的样本均值、样本方差\n\naggregate(data = iris, cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, mean)\n\n#&gt;      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; 1     setosa        5.006       3.428        1.462       0.246\n#&gt; 2 versicolor        5.936       2.770        4.260       1.326\n#&gt; 3  virginica        6.588       2.974        5.552       2.026\n\naggregate(data = iris, cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, var)\n\n#&gt;      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; 1     setosa    0.1242490  0.14368980   0.03015918  0.01110612\n#&gt; 2 versicolor    0.2664327  0.09846939   0.22081633  0.03910612\n#&gt; 3  virginica    0.4043429  0.10400408   0.30458776  0.07543265\n\n\n\n12.8.3 假设检验与区间估计的关系\n区间估计的意义是解决点估计可靠性问题，它用置信系数解决了对估计结果的信心问题，弥补了点估计的不足。置信系数是最大的置信水平。\nBase R 提供的 binom.test() 函数可以精确计算置信区间，即所谓的 Clopper-Pearson 区间，而 prop.test() 函数可近似计算置信区间，即所谓的 Wilson 区间。以单样本的比例检验为例。\n\n# 近似区间估计\nprop.test(x = 2, n = 10, p = 0.95, conf.level = 0.95, correct = TRUE)\n\n#&gt; Warning in prop.test(x = 2, n = 10, p = 0.95, conf.level = 0.95, correct =\n#&gt; TRUE): Chi-squared approximation may be incorrect\n\n\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  2 out of 10, null probability 0.95\n#&gt; X-squared = 103.16, df = 1, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true p is not equal to 0.95\n#&gt; 95 percent confidence interval:\n#&gt;  0.03542694 0.55781858\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.2\n\n# 精确区间估计\nbinom.test(x = 2, n = 10, p = 0.95, conf.level = 0.95)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  2 and 10\n#&gt; number of successes = 2, number of trials = 10, p-value = 1.605e-09\n#&gt; alternative hypothesis: true probability of success is not equal to 0.95\n#&gt; 95 percent confidence interval:\n#&gt;  0.02521073 0.55609546\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                    0.2\n\n\n实际达到的置信度水平随真实的未知参数值和样本量的变化而剧烈波动，这意味着这种参数估计方法在实际应用中不可靠、真实场景中参数真值是永远未知的，样本量是可控的，并且是可以变化的。根本原因在于这类分布是离散的，比如这里的二项分布。当样本数据服从离散的分布，置信区间的端点也是离散的。这种缺陷是无法避免的，清晰的置信区间和离散的数据之间存在无法调和的冲突。\n\n12.8.4 常见的统计检验是线性模型\n两样本的均值检验：非参数检验方法\n\n12.8.4.1 Wilcoxon 符号秩检验\n与 wilcox.test() 等价的线性模型\n\nsigned_rank &lt;- function(x) sign(x) * rank(abs(x))\nfit &lt;- lm(signed_rank(extra) ~ group, data = sleep)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = signed_rank(extra) ~ group, data = sleep)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -14.55  -6.55   0.90   6.90  13.95 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)  \n#&gt; (Intercept)    3.050      2.872   1.062   0.3022  \n#&gt; group2         8.300      4.061   2.044   0.0559 .\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 9.081 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.1884, Adjusted R-squared:  0.1433 \n#&gt; F-statistic: 4.177 on 1 and 18 DF,  p-value: 0.05589\n\n\n\n12.8.4.2 Kruskal-Wallis 秩和检验\n与 kruskal.test() 等价的线性模型表示。\n\nfit &lt;- lm(rank(extra) ~ group, data = sleep)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = rank(extra) ~ group, data = sleep)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -8.450 -3.925 -0.500  5.275  8.950 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)    8.050      1.738   4.633 0.000207 ***\n#&gt; group2         4.900      2.457   1.994 0.061520 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.495 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.1809, Adjusted R-squared:  0.1354 \n#&gt; F-statistic: 3.976 on 1 and 18 DF,  p-value: 0.06152\n\n\n\n12.8.5 假设检验的工业应用\n传统的试验设计为什么不适用于互联网？因为Fisher的实验设计和方差分析，主要针对的是受控对象，比如测试武器、肥料配比、飞机制造等实体的东西。互联网是虚拟经济，实验的对象是人，对平台来说，人的行为是半知半解，更不受控，所以需要成千上万、乃至几十万的样本才能抵消样本内部的随机性。互联网数据的噪声太多、太大了，微小的变化就好像一粒小石子扔进大海里，要获得样本间显著的差异性，需要累积相当的样本量。另一方面，大型的互联网公司，搜索、推荐、广告等业务相对成熟，提升关键指标，拿到好的结果，往往比较困难。成熟的业务几乎不太可能一次实验拿到很好的结果，所以，方向比努力重要，更快地迭代，跑在同行前面，更快地试错（想法），试更多的错（想法），更好地试错（想法），累积更多的经验，做更多地创新，这是 A/B 实验平台的核心价值。\n曾经，在学校里，我总想获得一个全局最优解，并且还有这样的情结，到了厂里，发现没人研究全局最优解，大家都在做 A/B 实验优化自己的子业务和方向。有时候这个细分业务方向甚至也就小几万的用户了。 全局最优解和局部最优解，我们不太可能获得全局最优解，一则全局最优解受影响的因素很多，而这些因素变化很快，所以，即使可以获得全局最优解，代价会非常大，那么，怎么办呢？还不如获取局部最优解，研究一个个局部显然比研究全局要简单的多，此外，研究局部的好处是可以快速地随业务迭代。\n一个完整的实验周期包含提出问题、设计实验、收集数据、组织数据、统计检验、分析结论、数据解读、数据交流、决策行动、业务价值。这是一个闭环，根据业务中发现的问题，提出解决方法，并设计实验验证。问题有时候就是机会，奋斗的方向，解决问题自然就会带来业务价值。实验又可以按业务问题、数据问题和统计问题划分三个阶段。\n\n业务问题：根据目标确定方向，找到有价值的、可以解决的业务问题，再提出合理的统计假设。\n数据问题：数据收集、数据组织、数据管理、数据治理，验证数据流的完整性、一致性等。\n统计问题：设计实验方案，包括分流、实验周期等，利用假设检验、区间估计和功效分析等统计工具完成显著性分析、可靠性分析，撰写数据分析和评估报告。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-common-statistical-tests-exercise",
    "href": "common-statistical-tests.html#sec-common-statistical-tests-exercise",
    "title": "12  常见的统计检验",
    "section": "\n12.9 习题",
    "text": "12.9 习题\n\n分析《红楼梦》的情景描写。参考 2009 年东南大学韦博成教授将两个独立二项总体的等价性检验应用于《红楼梦》前80回与后40回某些文风差异的统计分析 (韦博成 2009)。\n\n根据数据集 chickwts 分析不同喂食方式对小鸡体重的影响。（单因素方差分析）\n\nggplot(data = chickwts, aes(x = feed, y = weight)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n图 12.12: 不同喂食方式对小鸡的影响\n\n\n\n\n\n\n根据数据集 ChickWeight 分析 4 种喂食方式对小鸡体重有影响，每个小鸡本身对喂食方式的接受、吸收程度不一样、它们本身的素质不一样（个体差异），要考察喂食的方式的影响，应该剔除掉个体差异，才是喂食方式的真正影响。\n\nggplot(data = ChickWeight, aes(x = Time, y = weight, group = Chick, color = Diet)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~Diet) +\n  theme_minimal()\n\n\n\n\n\n\n图 12.13: 不同喂食方式对小鸡的影响（续）\n\n\n\n\n\n\n\n\n\n\nAnsari, A. R., 和 R. A. Bradley. 1960. 《Rank-Sum Tests for Dispersions》. The Annals of Mathematical Statistics 31 (4): 1174–89. https://doi.org/10.1214/aoms/1177705688.\n\n\nCohen, Jacob. 1994. 《The Earth Is Round (\\(p &lt; .05\\))》. American Psychologist 49 (12): 997–1003. https://doi.org/10.1037/0003-066x.49.12.997.\n\n\nDobson, Annette J. 1983. An Introduction to Statistical Modelling. 1st 本. London: Chapman; Hall/CRC. https://doi.org/10.1007/978-1-4899-3174-0.\n\n\nEpps, T. W., 和 Lawrence B. Pulley. 1983. 《A Test for Normality Based on the Empirical Characteristic Function》. Biometrika 70 (3): 723–26. https://doi.org/10.2307/2336512.\n\n\nFligner, Michael A., 和 Timothy J. Killeen. 1976. 《Distribution-Free Two-Sample Tests for Scale》. Journal of the American Statistical Association 71 (353): 210–13. https://doi.org/10.1080/01621459.1976.10481517.\n\n\nHeyde, C. C., E. Seneta, P. Crépel, S. E. Fienberg, 和 J. Gani. 2001. Statisticians of the Centuries. New York, NY: Springer-Verlag. https://doi.org/10.1007/978-1-4613-0179-0.\n\n\nHSU, P. L. 1938. 《Contribution to the theory of \"Student’s\" \\(T\\)-test as applied to the problem of two samples》. Statistical Research Memoirs 2: 1–24.\n\n\n———. 1983. Collected Papers. New York, NY: Springer-Verlag.\n\n\nKim, Seock-Ho, 和 Allan S. Cohen. 1998. 《On the Behrens-Fisher Problem: A Review》. Journal of Educational and Behavioral Statistics 23 (4): 356–77. https://doi.org/10.2307/1165281.\n\n\nMood, A. M. 1954. 《On the Asymptotic Efficiency of Certain Nonparametric Two-Sample Tests》. The Annals of Mathematical Statistics 25 (3): 514–22. https://doi.org/10.1214/aoms/1177728719.\n\n\nShapiro, S. S., 和 M. B. Wilk. 1965. 《An analysis of variance test for normality (complete samples)》. Biometrika 52 (3-4): 591–611. https://doi.org/10.1093/biomet/52.3-4.591.\n\n\n\"Student\". 1908. 《The probable error of a mean》. Biometrika 6: 1–25.\n\n\n韦博成. 2009. 《《红楼梦》前80回与后40回某些文风差异的统计分析（两个独立二项总体等价性检验的一个应用）》. 应用概率统计 25 (4): 441–48. https://doi.org/10.3969/j.issn.1001-4268.2009.04.012.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#footnotes",
    "href": "common-statistical-tests.html#footnotes",
    "title": "12  常见的统计检验",
    "section": "",
    "text": "https://stat.ethz.ch/pipermail/r-help/2005-April/070508.html↩︎\nhttps://stat.ethz.ch/pipermail/r-help/2009-May/390164.html↩︎\nhttps://personal.utdallas.edu/~herve/Abdi-Lillie2007-pretty.pdf↩︎\nhttps://stat.ethz.ch/pipermail/r-help/2004-February/045597.html↩︎",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html",
    "href": "regression-and-correlation.html",
    "title": "13  回归与相关分析",
    "section": "",
    "text": "13.1 子代身高与亲代身高的关系\n弗朗西斯·高尔顿（Francis Galton, 1822-1911）是历史上著名的优生学家、心理学家、遗传学家和统计学家，是统计学中相关和回归等一批概念的提出者，是遗传学中回归现象的发现者。1885年，高尔顿以保密和给予金钱报酬的方式，向社会征集了 205 对夫妇及其 928 个成年子女的身高数据(Galton 1886)。\n目前，Michael Friendly 从原始文献中整理后，将该数据集命名为 GaltonFamilies，放在 R 包 HistData (Friendly 2021) 内，方便大家使用。篇幅所限，下 表格 13.1 展示该数据集的部分内容。\n表格 13.1: 高尔顿收集的 205 对夫妇及其子女的身高数据（部分）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n家庭编号\n父亲身高\n母亲身高\n中亲身高\n子女数量\n子女编号\n子女性别\n子女身高\n\n\n\n001\n78.5\n67.0\n75.43\n4\n1\nmale\n73.2\n\n\n001\n78.5\n67.0\n75.43\n4\n2\nfemale\n69.2\n\n\n001\n78.5\n67.0\n75.43\n4\n3\nfemale\n69.0\n\n\n001\n78.5\n67.0\n75.43\n4\n4\nfemale\n69.0\n\n\n002\n75.5\n66.5\n73.66\n4\n1\nmale\n73.5\n\n\n002\n75.5\n66.5\n73.66\n4\n2\nmale\n72.5\n表中子女性别一栏，Male 表示男性，Female 表示女性。表中 1 号家庭父亲身高 78.5 英寸，母亲身高 67.0 英寸，育有 4 个成年子女，1 男 3 女，子女身高依次是 73.2 英寸、 69.2 英寸、 69.0 英寸 和 69.0 英寸。1 英寸相当于 2.54 厘米，78.5 英寸相当于 199.39 厘米，约等于 2 米的身高。\n高尔顿提出「中亲」概念，即父母的平均身高，认为子代身高只与父母平均身高相关，而与父母身高差无关，为了消除性别给身高带来的差异，女性身高均乘以 1.08。\n根据数据统计的均值和协方差，椭圆 level = 0.95\n代码library(ggplot2)\nggplot(data = GaltonFamilies, aes(x = midparentHeight, y = childHeight, color = gender)) +\n  geom_point(aes(fill = gender), pch = 21, color = \"white\", \n             size = 2, alpha = 0.75) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", se = FALSE) +\n  stat_ellipse(type = \"norm\", level = 0.95, linetype = 2) +\n  scale_color_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  scale_fill_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  guides(fill = guide_legend(reverse = TRUE), \n         color = guide_legend(reverse = TRUE)) +\n  labs(x = \"父母平均身高\", y = \"子女身高\", fill = \"性别\", color = \"性别\") +\n  theme_classic()\n\n\n\n\n\n\n图 13.1: 子代身高与亲代身高的关系\n女儿的身高乘以 1.08 后，两条回归线将几乎重合。(Hanley 2004)\n代码GaltonFamilies[, height_children := childHeight * c(\"female\" = 1.08, \"male\" = 1)[gender]] |&gt;\n  ggplot(aes(x = midparentHeight, y = height_children, color = gender)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", se = FALSE) +\n  geom_point(size = 1.5, alpha = 0.75) +\n  stat_ellipse( type = \"norm\", linetype = 2) +\n  scale_color_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  guides(color = guide_legend(reverse = TRUE)) +\n  labs(x = \"父母平均身高\", y = \"子女身高\", color = \"性别\") +\n  theme_classic()\n\n\n\n\n\n\n图 13.2: 子代身高与亲代身高的关系\n\\[\n\\mathrm{height}_{children} = \\alpha + \\beta * \\mathrm{height}_{midparent} + \\epsilon\n\\]\n表格 13.2: 子女身高向中亲平均身高回归\n\n\n\n\n性别\n截距\n中亲身高\n\n\n\nmale\n19.91346\n0.7132745\n\n\nfemale\n19.80016\n0.7136104\n代码data(Galton, package = \"HistData\")\nplot(Galton,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(63.5, 73.5),\n  ylim = c(61, 74.5),\n  col = densCols(Galton,\n    bandwidth = c(1, 1),\n    nbin = c(11L, 11L), colramp = hcl.colors\n  )\n)\nreg &lt;- lm(child ~ parent, data = Galton)\nabline(reg, lwd = 2)\nlines(lowess(x = Galton$parent, y = Galton$child), col = \"blue\", lwd = 2)\nlibrary(KernSmooth)\nden &lt;- bkde2D(x = Galton, bandwidth = c(1, 1), gridsize = c(11L, 11L))\ncontour(den$x1, den$x2, den$fhat, nlevels = 10, add = TRUE, family = \"sans\")\ntitle(xlab = \"父母平均身高\", ylab = \"子女身高\", family = \"Noto Serif CJK SC\")\n\n\n\n\n\n\n图 13.3: 二维核密度估计与二元正态分布\n向均值回归现象最早是高尔顿在甜豌豆实验中发现的，实际上，均值回归现象在社会经济和自然界中广泛存在，比如一个人的智力水平受家族平均水平的影响。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#sec-state-x77",
    "href": "regression-and-correlation.html#sec-state-x77",
    "title": "13  回归与相关分析",
    "section": "\n13.2 预期寿命与人均收入的关系",
    "text": "13.2 预期寿命与人均收入的关系\n\n生物遗传的回归现象，更确切地说是因果而不是相关，是一种近似的函数关系。与回归紧密相连的是另一个统计概念是相关，主要刻画数量指标之间的关系深浅程度，相关系数是其中一个度量。在经济、社会领域中，很多数据指标存在相关性，接下来的这个例子基于 1977 年美国人口调查局发布的统计数据，篇幅所限，下 表格 13.3 展示美国各州的部分统计数据。\n\n\n\n表格 13.3: 1977 年美国人口调查局发布的各州统计数据（部分）\n\n\n\n\n州名\n区域划分\n人口数量\n人均收入\n预期寿命\n\n\n\nAlabama\nSouth\n3615\n3624\n69.05\n\n\nAlaska\nWest\n365\n6315\n69.31\n\n\nArizona\nWest\n2212\n4530\n70.55\n\n\nArkansas\nSouth\n2110\n3378\n70.66\n\n\nCalifornia\nWest\n21198\n5114\n71.71\n\n\nColorado\nWest\n2541\n4884\n72.06\n\n\n\n\n\n\n\n\n该数据集在 R 环境中的结构如下：\n\nstr(state_x77)\n\n#&gt; 'data.frame':    50 obs. of  10 variables:\n#&gt;  $ Population  : num  3615 365 2212 2110 21198 ...\n#&gt;  $ Income      : num  3624 6315 4530 3378 5114 ...\n#&gt;  $ Illiteracy  : num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...\n#&gt;  $ Life Exp    : num  69 69.3 70.5 70.7 71.7 ...\n#&gt;  $ Murder      : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...\n#&gt;  $ HS Grad     : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...\n#&gt;  $ Frost       : num  20 152 15 65 20 166 139 103 11 60 ...\n#&gt;  $ Area        : num  50708 566432 113417 51945 156361 ...\n#&gt;  $ state_name  : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n#&gt;  $ state_region: Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n\n\n它是一个 50 行 10 列的数据框，其中，state_name（州名）是字符型变量， state_region（区域划分）是因子型变量。除了这两个变量外，Population（人口数量，单位：1000），Income（人均收入，单位：美元），Life Exp（预期寿命，单位：岁）等都是数值型的变量。下 图 13.4 展示了1977 年美国各州的预期寿命和人均收入的关系，通过此图，可以初步观察出两个指标存在一些明显的正向相关性，也符合常识。\n\n代码library(ggplot2)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point() +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 13.4: 预期寿命与人均收入的关系图\n\n\n\n\n为了更加清楚地观察到哪些州预期寿命长，哪些州人均收入高，在 图 13.4 基础上，在散点旁边添加州名。此外，为了观察各州的地域差异，根据各州所属区域，给散点分类，最后，将各州人口数量映射给散点的大小，形成如下 图 13.5 所示的分类气泡图。\n\n代码library(ggplot2)\nlibrary(ggrepel)\nlibrary(scales)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系（分地域）\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 13.5: 分地域预期寿命与人均收入的气泡图\n\n\n\n\n整体来说，预期寿命与人均收入息息相关。\n\n代码ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\") +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 13.6: 1977 年美国各州预期寿命与人均收入的关系：回归分析\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n从 图 13.5 到 图 13.6 ，尝试初步量化两个变量之间的相关性之前，有没有想过，回归线应该更加陡峭一些，即回归线的斜率应该更大一些，是什么原因导致平缓了这么多？是阿拉斯加州和内华达州的数据偏离集体太远。那又是什么原因导致阿拉斯加州人均收入全美第一，而预期寿命倒数呢？同样的，内华达州的人均收入也不低，但预期寿命为什么上不去呢？\n\n\n\n代码ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", color = \"red\") +\n  geom_smooth(data = function(x) subset(x, !state_name %in% c(\"Nevada\", \"Alaska\") ), method = \"lm\", formula = \"y~x\", color = \"green\") +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\nm &lt;- lm(data = state_x77, `Life Exp` ~ Income)\nsummary(m)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = `Life Exp` ~ Income, data = state_x77)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -2.96547 -0.76381 -0.03428  0.92876  2.32951 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 6.758e+01  1.328e+00  50.906   &lt;2e-16 ***\n#&gt; Income      7.433e-04  2.965e-04   2.507   0.0156 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.275 on 48 degrees of freedom\n#&gt; Multiple R-squared:  0.1158, Adjusted R-squared:  0.09735 \n#&gt; F-statistic: 6.285 on 1 and 48 DF,  p-value: 0.01562\n\n\n输出结果中各个量的计算公式及 R 语言实现，比如方差 Variance、偏差 Deviance/Bias、残差 Residual Error",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#分析影响入院等待时间的因素",
    "href": "regression-and-correlation.html#分析影响入院等待时间的因素",
    "title": "13  回归与相关分析",
    "section": "\n13.3 分析影响入院等待时间的因素",
    "text": "13.3 分析影响入院等待时间的因素\n医院的床位是非常重要的资源。\n\nhospital_waiting_time &lt;- readRDS(file = \"data/hospital_waiting_time.rds\")\n\n\nstr(hospital_waiting_time)\n\n#&gt; 'data.frame':    2625 obs. of  11 variables:\n#&gt;  $ 等待时间    : num  1 1.2 20 6 8.9 2.9 7.9 2.8 2.7 5 ...\n#&gt;  $ 门诊次      : int  2 7 43 1 3 1 10 3 6 2 ...\n#&gt;  $ 住院次      : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 开住院条日期: int  3 3 3 3 3 3 3 3 3 3 ...\n#&gt;  $ 性别        : int  0 0 1 1 1 1 0 1 1 1 ...\n#&gt;  $ 年龄        : int  42 32 59 9 45 73 50 25 14 20 ...\n#&gt;  $ 入院疾病分类: int  3 1 1 3 3 3 4 1 2 3 ...\n#&gt;  $ 入院目的    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 住院类别    : int  2 2 2 2 2 2 2 2 2 2 ...\n#&gt;  $ 入院病情    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 医生        : int  2 2 2 2 2 4 2 2 4 4 ...",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#sec-exercise-regression-and-correlation",
    "href": "regression-and-correlation.html#sec-exercise-regression-and-correlation",
    "title": "13  回归与相关分析",
    "section": "\n13.4 习题",
    "text": "13.4 习题\n\nR 软件内置的数据集 esoph 是一份关于法国伊勒-维莱讷地区食道癌的数据，请读者根据这份数据研究年龄组、烟草消费量、酒精消费量（每日喝酒量）和患食道癌的关系。\n\n\n\n\n\nFriendly, Michael. 2021. HistData: Data Sets from the History of Statistics and Data Visualization. https://CRAN.R-project.org/package=HistData.\n\n\nGalton, F. 1886. 《Regression Towards Mediocrity in Hereditary Stature》. Journal of the Anthropological Institute 15: 246–63.\n\n\nHanley, James A. 2004. 《’Transmuting’ women into men: Galton’s family data on human stature》. The American Statistician 58 (3): 237–43.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html",
    "href": "categorical-data-analysis.html",
    "title": "14  分类数据的分析",
    "section": "",
    "text": "14.1 比例检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-prop-test",
    "href": "categorical-data-analysis.html#sec-prop-test",
    "title": "14  分类数据的分析",
    "section": "",
    "text": "14.1.1 单样本检验\n比例检验函数 prop.test() 检验比例是否等于给定的值。单样本的比例检验结果中比例的区间估计与 Wilson 区间估计 (Wilson 1927) 是相关的。区间估计与假设检验是有紧密关系的，对于二项分布比例的 11 种区间估计方法的比较 (Newcombe 1998)。\n\n14.1.1.1 近似检验\n\n14.1.1.2 精确检验\n函数 binom.test() 来做二项检验，函数 binom.test() 用来检验伯努利试验中成功概率 \\(p\\) 和给定概率 \\(p_0\\) 的关系，属于精确检验 (Clopper 和 Pearson 1934)。\n比例 \\(p\\) 的检验，做 \\(n\\) 次独立试验，样本 \\(X_1,\\ldots,X_n \\sim b(1, p)\\)，事件发生的总次数 \\(\\sum_{i=1}^{n}X_i\\)。\n\n# 模拟一组样本\nset.seed(20232023)\nx &lt;- sample(x = c(0, 1), size = 100, replace = TRUE, prob = c(0.8, 0.2))\n\n二项分布中成功概率的检验\n\nbinom.test(sum(x), n = 100, p = 0.5)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  sum(x) and 100\n#&gt; number of successes = 23, number of trials = 100, p-value = 5.514e-08\n#&gt; alternative hypothesis: true probability of success is not equal to 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.1517316 0.3248587\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                   0.23\n\n\n检验成功概率 p 是否等于 0.5， P 值 \\(5.514 \\times 10^{-8}\\) 结论是拒绝原假设\n\nbinom.test(sum(x), n = 100, p = 0.2)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  sum(x) and 100\n#&gt; number of successes = 23, number of trials = 100, p-value = 0.4534\n#&gt; alternative hypothesis: true probability of success is not equal to 0.2\n#&gt; 95 percent confidence interval:\n#&gt;  0.1517316 0.3248587\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                   0.23\n\n\n检验成功概率 p 是否等于 0.2， P 值 0.4534 结论是不能拒绝原假设\n切比雪夫不等式（Chebyshev, 1821-1894）。设随机变量 \\(X\\) 的数学期望和方差都存在，则对任意常数 \\(\\epsilon &gt; 0\\)，有\n\\[\n\\begin{aligned}\nP(|X - EX| \\geq \\epsilon) & \\leq \\frac{Var(X)}{\\epsilon^2} \\\\\nP(|X - EX| \\leq \\epsilon) & \\geq 1 - \\frac{Var(X)}{\\epsilon^2}\n\\end{aligned}\n\\]\n\n14.1.2 两样本检验\n关于两样本的比例检验问题\n\\[\n\\begin{aligned}\nH_0: P_A = P_B \\quad vs. \\quad H_1: P_A &gt; P_B \\\\\nH_0: P_A = P_B \\quad vs. \\quad H_1: P_A &lt; P_B\n\\end{aligned}\n\\]\n\\(H_0\\) 成立的情况下，暗示着两个样本来自同一总体。\n比例检验函数 prop.test() 用来检验两组或多组二项分布的成功概率（比例）是否相等。\n设随机变量 X 服从参数为 \\(p\\) 的二项分布 \\(b(n, p)\\)， \\(Y\\) 服从参数为 \\(\\theta\\) 的二项分布 \\(b(m,\\theta)\\)， \\(m,n\\) 都假定为较大的正整数，检验如下问题\n\\[\nH_0: P_A \\geq P_B \\quad vs. \\quad H_1: P_A &lt; P_B\n\\]\n根据中心极限定理\n\\[\n\\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{p(1-p)}{n} + \\frac{\\theta(1-\\theta)}{m}}}\n\\]\n近似服从标准正态分布 \\(N(0,1)\\)。如果用矩估计 \\(\\bar{X}\\) 和 \\(\\bar{Y}\\) 分别替代总体参数 \\(p\\) 和 \\(\\theta\\)，构造检验统计量\n\\[\nT = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n} + \\frac{\\bar{Y}(1-\\bar{Y})}{m}}}\n\\]\n根据 Slutsky 定理，检验统计量 \\(T\\) 近似服从标准正态分布，当 \\(T\\) 偏大时，拒绝 \\(H_0\\)。该方法的优势在于当 \\(n,m\\) 比较大时，二项分布比较复杂，无法建立统计表，利用标准正态分布表来给出检验所需要的临界值，简便易行！\n当 \\(p\\) 和 \\(\\theta\\) 都比较小，上述方法检验效果不好，原因在于由中心极限定理对 \\(\\bar{X}\\) 和 \\(\\bar{Y}\\) 的正态分布近似效果不好，或者间接地导致 \\(\\bar{X}-\\bar{Y}\\) 的方差偏小，进而 \\(T\\) 的分辨都不好，而且当 \\(p,\\theta\\) 很接近 1 时，上述现象也会产生！\n下面介绍新的解决办法，办法来自两个二项总体成功概率的比较 (宋泽熙 2011)。\n上面的检验问题等价于\n\\[\nH_0: \\frac{P_A}{P_B} \\geq 1 \\quad vs. \\quad H_1: \\frac{P_A}{P_B} &lt; 1\n\\]\n引入检验统计量\n\\[\nT^{\\star} = \\frac{\\bar{X}}{\\bar{Y}}\n\\]\n同样由 Slutsky 定理和中心极限定理可知， \\(\\bar{X}/\\bar{Y}\\) 近似服从 正态分布 \\(\\mathcal{N}(1,\\frac{1-\\theta}{m\\theta})\\)\n当 \\((T^\\star - 1)/\\hat\\sigma\\) 偏大时接受 \\(H_0\\)，临界值可通过 \\(\\mathcal{N}(0, \\hat\\sigma^2)\\) 分布表计算得到， \\(\\hat\\sigma^2\\) 是对 \\(\\frac{1-\\theta}{m\\theta}\\) 的估计，比如取 \\(\\hat\\sigma^2 = \\frac{1-\\bar{Y}}{m}\\cdot \\frac{1}{\\bar{Y}}\\) 或取 \\(\\hat\\sigma^2 = \\frac{1-\\bar{Y}}{m}\\cdot \\frac{1}{\\bar{X}}\\)\n由于渐近方差形如 \\(\\frac{1-\\theta}{m\\theta}\\)，因而在 \\(\\theta\\) 较小，渐近方差较大，克服了之前 \\(\\bar{X} - \\bar{Y}\\)的方差较小的问题\n\\(p,\\theta\\) 很接近 1 时，我们取检验统计量\n\\[\nT^{\\star\\star} = \\frac{1-\\bar{Y}}{1-\\bar{X}}\n\\]\n结论和 \\(T^\\star\\) 类似，当 \\(T^{\\star\\star}\\) 偏大时，拒绝 \\(H_0\\)。\n\n14.1.3 多样本检验\n\n14.1.3.1 比例齐性检验\n对多组数据的比例检验，可以理解为比例齐性检验。\n\n14.1.3.2 比例趋势检验\n比例趋势检验函数 prop.trend.test() 的原假设：四个组里面病人中吸烟的比例是相同的。备择假设：四个组的吸烟比例是有趋势的。\n\\[\n\\begin{aligned}\n& H_0: P_1 = P_2 = P_3 = P_4 \\\\\n& H_1: P_1 &lt; P_2 &lt; P_3 &lt; P_4 ~\\text{或者}~ P_1 &gt; P_2 &gt; P_3 &gt; P_4\n\\end{aligned}\n\\]\n\nsmokers &lt;- c(83, 90, 129, 70)\npatients &lt;- c(86, 93, 136, 82)\nprop.test(smokers, patients)\n\n#&gt; \n#&gt;  4-sample test for equality of proportions without continuity correction\n#&gt; \n#&gt; data:  smokers out of patients\n#&gt; X-squared = 12.6, df = 3, p-value = 0.005585\n#&gt; alternative hypothesis: two.sided\n#&gt; sample estimates:\n#&gt;    prop 1    prop 2    prop 3    prop 4 \n#&gt; 0.9651163 0.9677419 0.9485294 0.8536585\n\nprop.trend.test(smokers, patients)\n\n#&gt; \n#&gt;  Chi-squared Test for Trend in Proportions\n#&gt; \n#&gt; data:  smokers out of patients ,\n#&gt;  using scores: 1 2 3 4\n#&gt; X-squared = 8.2249, df = 1, p-value = 0.004132",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-poisson-test",
    "href": "categorical-data-analysis.html#sec-poisson-test",
    "title": "14  分类数据的分析",
    "section": "\n14.2 泊松检验",
    "text": "14.2 泊松检验\n泊松分布是 1837年由法国数学家泊松 （Poisson, 1781-1840） 首次提出。\n\\[\np(x) = \\frac{\\lambda^x\\exp(-\\lambda)}{x!}, x = 0, 1, \\cdots .\n\\]\n泊松分布的期望和方差都是 \\(\\lambda\\) ，一般要求 \\(\\lambda &gt; 0\\)。\n\n14.2.1 单样本\npoisson.test() 泊松分布的参数 \\(\\lambda\\) 的精确检验，适用于单样本和两样本。\n\npoisson.test(x,\n  T = 1, r = 1,\n  alternative = c(\"two.sided\", \"less\", \"greater\"),\n  conf.level = 0.95\n)\n\n参数 T 数据的时间单位\n\n14.2.2 两样本",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#列联表描述",
    "href": "categorical-data-analysis.html#列联表描述",
    "title": "14  分类数据的分析",
    "section": "\n14.3 列联表描述",
    "text": "14.3 列联表描述\n泰坦尼克号乘客生存死亡统计数据，Titanic 数据集\n\nTitanic\n\n#&gt; , , Age = Child, Survived = No\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st     0      0\n#&gt;   2nd     0      0\n#&gt;   3rd    35     17\n#&gt;   Crew    0      0\n#&gt; \n#&gt; , , Age = Adult, Survived = No\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st   118      4\n#&gt;   2nd   154     13\n#&gt;   3rd   387     89\n#&gt;   Crew  670      3\n#&gt; \n#&gt; , , Age = Child, Survived = Yes\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st     5      1\n#&gt;   2nd    11     13\n#&gt;   3rd    13     14\n#&gt;   Crew    0      0\n#&gt; \n#&gt; , , Age = Adult, Survived = Yes\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st    57    140\n#&gt;   2nd    14     80\n#&gt;   3rd    75     76\n#&gt;   Crew  192     20\n\n\n\n14.3.1 行列分组表格\n\n代码# 长格式转宽格式\ntitanic_data &lt;- reshape(\n  data = as.data.frame(Titanic), direction = \"wide\",\n  idvar = c(\"Class\", \"Sex\", \"Age\"),\n  timevar = \"Survived\", v.names = \"Freq\", sep = \"_\"\n)\n\n# 制作表格\ngt::gt(titanic_data) |&gt; \n  gt::cols_label(\n    Freq_Yes = \"存活\",\n    Freq_No = \"死亡\",\n    Class = \"船舱\",\n    Sex = \"性别\",\n    Age = \"年龄\"\n  )\n\n\n表格 14.1: 泰坦尼克号乘客生存死亡统计数据\n\n\n\n\n\n\n\n船舱\n性别\n年龄\n死亡\n存活\n\n\n\n1st\nMale\nChild\n0\n5\n\n\n2nd\nMale\nChild\n0\n11\n\n\n3rd\nMale\nChild\n35\n13\n\n\nCrew\nMale\nChild\n0\n0\n\n\n1st\nFemale\nChild\n0\n1\n\n\n2nd\nFemale\nChild\n0\n13\n\n\n3rd\nFemale\nChild\n17\n14\n\n\nCrew\nFemale\nChild\n0\n0\n\n\n1st\nMale\nAdult\n118\n57\n\n\n2nd\nMale\nAdult\n154\n14\n\n\n3rd\nMale\nAdult\n387\n75\n\n\nCrew\nMale\nAdult\n670\n192\n\n\n1st\nFemale\nAdult\n4\n140\n\n\n2nd\nFemale\nAdult\n13\n80\n\n\n3rd\nFemale\nAdult\n89\n76\n\n\nCrew\nFemale\nAdult\n3\n20\n\n\n\n\n\n\n\n\n\n\n\n14.3.2 百分比堆积图\n泰坦尼克号处女航乘客数量按船舱、性别、年龄和存活情况分层， ggstats 包绘制百分比堆积柱形图展示多维分类数据。\n\n代码library(ggplot2)\nlibrary(ggstats)\nggplot(as.data.frame(Titanic)) +\n  aes(x = Class, fill = Survived, weight = Freq, by = Class) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  geom_text(stat = \"prop\", position = position_fill(.5)) +\n  facet_grid(~Sex) +\n  labs(x = \"船舱\", y = \"比例\", fill = \"存活\")\n\n\n\n\n\n\n图 14.1: 百分比堆积柱形图展示多维分类数据\n\n\n\n\nggstats 包提供的图层 stat_prop() 是 stat_count() 的变种， as.data.frame(Titanic) 中 Age 一列会自动聚合吗？ by = Class 按 Class 分组聚合，统计 Survived 的比例，提供 prop 计算的变量，传递给 geom_text() 以添加注释，position 设置将注释放在柱子的中间\n\n14.3.3 桑基图\n用 ggalluvial 包(Brunson 2020)绘制桑基图展示多维分类数据。\n\n代码library(ggplot2)\nlibrary(ggalluvial)\nggplot(\n  data = as.data.frame(Titanic),\n  aes(axis1 = Class, axis2 = Sex, axis3 = Age, y = Freq)\n) +\n  scale_x_discrete(limits = c(\"Class\", \"Sex\", \"Age\")) +\n  geom_alluvium(aes(fill = Survived)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_classic() +\n  labs(\n    x = \"分层维度\", y = \"人数\", fill = \"存活\",\n    title = \"泰坦尼克号处女航乘客分层情况\"\n  )\n\n\n\n\n\n\n图 14.2: 桑基图展示多维分类数据\n\n\n\n\n\n14.3.4 马赛克图\n\n代码op &lt;- par(mar = c(2.5, 2.5, 1.5, 0.5))\nmosaicplot(~ Class + Sex + Age + Survived,\n  data = Titanic, # shade = TRUE, \n  color = TRUE, border = \"white\",\n  xlab = \"船舱\", ylab = \"性别\", main = \"泰坦尼克号\")\npar(op)\n\n\n\n\n\n\n图 14.3: 马赛克图展示多维分类数据\n\n\n\n\nvcd 包针对分类数据做了很多专门的可视化工作，内置了很多数据集和绘图函数，在 Base R 绘图基础上，整合了许多统计分析功能，提供了一个统一的可视化框架(Meyer, Zeileis, 和 Hornik 2006; Zeileis, Meyer, 和 Hornik 2007)，更多细节见著作《Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data》及其附带的 R 包 vcdExtra(Friendly 和 Meyer 2016)。\n\n代码library(grid)\nlibrary(vcd)\nmosaic(~ Class + Sex + Age + Survived,\n  data = Titanic, shade = TRUE, legend = TRUE\n)\n\n\n\n\n\n\n图 14.4: 马赛克图展示多维分类数据",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-chisq-test",
    "href": "categorical-data-analysis.html#sec-chisq-test",
    "title": "14  分类数据的分析",
    "section": "\n14.4 列联表分析",
    "text": "14.4 列联表分析\n是否应该按照列联表的维度分类？还是应该从分析的目的和作用出发？比如我的目的是检验独立性。二者似乎也并不冲突。\n列联表中的数据服从多项分布，关于独立性检验，有如下几种常见类型：\n\n相互独立 Mutual independence 所有变量之间相互独立，\\(X \\perp Y \\perp Z\\) 。\n联合独立 Joint independence 两个变量的联合与第三个变量独立，\\(XY \\perp Z\\) 。\n边际独立 Marginal independence 当忽略第三个变量时，两个变量是独立的。列联表压缩\n条件独立 Conditional independence 当固定第三个变量时，两个变量是独立的，\\(X \\perp Y | Z\\)。\n\n本节数据来自著作《An Introduction to Categorical Data Analysis》(Agresti 2007) 的第2章习题 2.33，探索 1976-1977 年美国佛罗里达州的凶杀案件中被告肤色和死刑判决的关系。\n\n代码tbl &lt;- expand.grid(\n  Death = c(\"Yes\", \"No\"), # 判决结果 是否死刑\n  Defend = c(\"白人\", \"黑人\"),  # 被告 肤色\n  Victim = c(\"白人\", \"黑人\")   # 原告 （被害人）肤色\n)\nethnicity &lt;- data.frame(tbl, Freq = c(19, 132, 11, 52, 0, 9,  6, 97))\n\n# 长格式转宽格式\ndat1 &lt;- reshape(\n  data = ethnicity, direction = \"wide\",\n  idvar = c(\"Defend\", \"Victim\"),\n  timevar = \"Death\", v.names = \"Freq\", sep = \"_\"\n)\n# 制作表格\ngt::gt(dat1) |&gt; \n  gt::cols_label(\n    Freq_Yes = \"是\",\n    Freq_No = \"否\",\n    Victim = \"被害人\",\n    Defend = \"被告\"\n  ) |&gt; \n  gt::tab_spanner(\n    label = \"死刑\",\n    columns = c(Freq_Yes, Freq_No)\n  ) |&gt; \n  gt::opt_row_striping()\n\n\n表格 14.2: 佛罗里达州的凶杀案件统计数据\n\n\n\n\n\n\n\n\n被告\n被害人\n死刑\n\n\n是\n否\n\n\n\n\n白人\n白人\n19\n132\n\n\n黑人\n白人\n11\n52\n\n\n白人\n黑人\n0\n9\n\n\n黑人\n黑人\n6\n97\n\n\n\n\n\n\n\n\n\n\n\n14.4.1 相互独立性\n皮尔逊卡方检验（ Pearson’s \\(\\chi^2\\) 检验） chisq.test() 常用于列联表独立性检验和方差分析模型的拟合优度检验。下面是一个 \\(2 \\times 2\\) 的列联表。\n\n卡方独立性检验\n\n\n第一列\n第二列\n合计\n\n\n\n第一行\n\\(a\\)\n\\(b\\)\n\\(a+b\\)\n\n\n第二行\n\\(c\\)\n\\(d\\)\n\\(c+d\\)\n\n\n合计\n\\(a+c\\)\n\\(b+d\\)\n\\(a+b+c+d\\)\n\n\n\n\n# Death 死刑与 Defend （被告）独立性检验\nm &lt;- xtabs(Freq ~ Death + Defend, data = ethnicity)\nm\n\n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes   19   17\n#&gt;   No   141  149\n\nchisq.test(m, correct = TRUE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 0.086343, df = 1, p-value = 0.7689\n\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 0.22145, df = 1, p-value = 0.6379\n\n\n当被告是白人时，死刑判决 19 个，占总的死刑判决数量的 19/36 = 52.78%，当被告是黑人时，死刑判决 17 个，占总的死刑判决数量的 17/36 = 47.22%。判决结果与被告种族没有显著关系，但与原告（受害人）种族是有关系的，请继续往下看。\n\n# Death 死刑与 Victim （原告）独立性检验\nm &lt;- xtabs(Freq ~ Death + Victim, data = ethnicity)\nchisq.test(m, correct = TRUE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 4.7678, df = 1, p-value = 0.029\n\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 5.6149, df = 1, p-value = 0.01781\n\n\n当受害人是白人时，死刑判决 30 个，占总的死刑判决数量的 30/36 = 83.33%，当受害人是黑人时，死刑判决 6 个，占总的死刑判决数量的 6/36 = 16.67%。受害人是白人时，死刑判决明显多于黑人。\n多维列联表\n\nm &lt;- xtabs(Freq ~ Death + Defend + Victim, data = ethnicity)\nm\n\n#&gt; , , Victim = 白人\n#&gt; \n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes   19   11\n#&gt;   No   132   52\n#&gt; \n#&gt; , , Victim = 黑人\n#&gt; \n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes    0    6\n#&gt;   No     9   97\n\n\n判决结果、被告种族、原告种族三者是否存在联合独立性，即考虑 (Victim, Death) 是否与 Defend 独立，(Victim, Defend) 是否与 Death 独立，(Death, Defend) 与 Victim 是否相互独立。\n\nfm &lt;- loglin(table = m, margin = list(c(1, 2), c(1, 3), c(2, 3)), print = FALSE)\nfm \n\n#&gt; $lrt\n#&gt; [1] 0.7007504\n#&gt; \n#&gt; $pearson\n#&gt; [1] 0.3751739\n#&gt; \n#&gt; $df\n#&gt; [1] 1\n#&gt; \n#&gt; $margin\n#&gt; $margin[[1]]\n#&gt; [1] \"Death\"  \"Defend\"\n#&gt; \n#&gt; $margin[[2]]\n#&gt; [1] \"Death\"  \"Victim\"\n#&gt; \n#&gt; $margin[[3]]\n#&gt; [1] \"Defend\" \"Victim\"\n\n# 拟合对数线性模型\n# fm &lt;- loglin(m, list(c(1), c(2), c(3)))\n# fm\n\n似然比检验统计量（Likelihood Ratio Test statistic），皮尔逊 \\(\\chi^2\\) 统计量（Pearson X-square Test statistic）\n\n1 - pchisq(fm$lrt, fm$df)\n\n#&gt; [1] 0.4025317\n\n\n拟合对数线性模型\n\nfit_dvp &lt;- glm(Freq ~ ., data = ethnicity, family = poisson(link = \"log\"))\n\n模型输出\n\nsummary(fit_dvp)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ ., family = poisson(link = \"log\"), data = ethnicity)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  2.45087    0.18046  13.582  &lt; 2e-16 ***\n#&gt; DeathNo      2.08636    0.17671  11.807  &lt; 2e-16 ***\n#&gt; Defend黑人   0.03681    0.11079   0.332     0.74    \n#&gt; Victim黑人  -0.64748    0.11662  -5.552 2.83e-08 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 395.92  on 7  degrees of freedom\n#&gt; Residual deviance: 137.93  on 4  degrees of freedom\n#&gt; AIC: 181.61\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\nPearson \\(\\chi^2\\) 统计量\n\nsum(residuals(fit_dvp, type = \"pearson\")^2)\n\n#&gt; [1] 122.3975\n\n\nMASS 包计算模型参数的置信区间\n\nconfint(fit_dvp, trace = FALSE)\n\n#&gt;                  2.5 %     97.5 %\n#&gt; (Intercept)  2.0802598  2.7893934\n#&gt; DeathNo      1.7546021  2.4493677\n#&gt; Defend黑人  -0.1803969  0.2543149\n#&gt; Victim黑人  -0.8790491 -0.4213701\n\n\n对于单元格总样本量小于 40 或 T 小于 1 时，需采用费希尔精确检验（ Fisher ’s Exact 检验）。\n\n14.4.2 边际独立性\n费希尔精确检验：固定边际的情况下，检验列联表行和列之间的独立性 fisher.test() 。\nfisher.test() 函数用法，统计原理和公式，适用范围和条件，概念背景和历史。\n费舍尔 (Sir Ronald Fisher, 1890.2 – 1962.7)1 和一位女士打赌，女士说能品出奶茶中奶和茶的添加顺序。\nfisher.test() 针对计数数据，检验列联表中行和列的独立性。\n\nTeaTasting &lt;- matrix(c(3, 1, 1, 3),\n  nrow = 2,\n  dimnames = list(\n    Guess = c(\"Milk\", \"Tea\"),\n    Truth = c(\"Milk\", \"Tea\")\n  )\n)\nTeaTasting\n\n#&gt;       Truth\n#&gt; Guess  Milk Tea\n#&gt;   Milk    3   1\n#&gt;   Tea     1   3\n\n\n\n# 单边 P 值\nfisher.test(TeaTasting, alternative = \"greater\")\n\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  TeaTasting\n#&gt; p-value = 0.2429\n#&gt; alternative hypothesis: true odds ratio is greater than 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3135693       Inf\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   6.408309\n\n# 双边 P 值\nfisher.test(TeaTasting, alternative = \"two.sided\")\n\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  TeaTasting\n#&gt; p-value = 0.4857\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;    0.2117329 621.9337505\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   6.408309\n\n# 单边 P 值\nsum(dhyper(x = c(3, 4), m = 4, n = 4, k = 4))\n\n#&gt; [1] 0.2428571\n\n\n\n14.4.3 对称性\n用于计数数据的 McNemar 卡方检验（ McNemar \\(\\chi^2\\) 检验）：检验二维列联表行和列的对称性 mcnemar.test()。怎么理解对称性？其实是配对检验。看帮助实例。\n\nPerformance &lt;- matrix(c(794, 86, 150, 570),\n  nrow = 2,\n  dimnames = list(\n    \"1st Survey\" = c(\"Approve\", \"Disapprove\"),\n    \"2nd Survey\" = c(\"Approve\", \"Disapprove\")\n  )\n)\nPerformance\n\n#&gt;             2nd Survey\n#&gt; 1st Survey   Approve Disapprove\n#&gt;   Approve        794        150\n#&gt;   Disapprove      86        570\n\nmcnemar.test(Performance)\n\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  Performance\n#&gt; McNemar's chi-squared = 16.818, df = 1, p-value = 4.115e-05\n\n\n\n14.4.4 条件独立性\n用于分层分类数据的 Cochran-Mantel-Haenszel 卡方检验：两个枚举（分类）变量的条件独立性，假定不存在三个因素的交互作用。Cochran-Mantel-Haenszel 检验 mantelhaen.test()\n\nstr(UCBAdmissions)\n\n#&gt;  'table' num [1:2, 1:2, 1:6] 512 313 89 19 353 207 17 8 120 205 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ Admit : chr [1:2] \"Admitted\" \"Rejected\"\n#&gt;   ..$ Gender: chr [1:2] \"Male\" \"Female\"\n#&gt;   ..$ Dept  : chr [1:6] \"A\" \"B\" \"C\" \"D\" ...\n\n\nUCBAdmissions 数据集是一个 \\(2\\times 2 \\times 6\\) 的三维列联表，R 语言中常用 table 类型表示。实际上，table 类型衍生自 array 数组类型，当把 UCBAdmissions 当作一个数组操作时，1、2、3 分别表示 Admit、Gender、Dept 三个维度。\n\nmantelhaen.test(UCBAdmissions)\n\n#&gt; \n#&gt;  Mantel-Haenszel chi-squared test with continuity correction\n#&gt; \n#&gt; data:  UCBAdmissions\n#&gt; Mantel-Haenszel X-squared = 1.4269, df = 1, p-value = 0.2323\n#&gt; alternative hypothesis: true common odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.7719074 1.0603298\n#&gt; sample estimates:\n#&gt; common odds ratio \n#&gt;         0.9046968\n\n\n没有证据表明院系与性别之间存在关联。在给定院系的情况下，是否录取和性别没有显著关系。\n\n# 按系统计\napply(UCBAdmissions, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))\n\n#&gt;         A         B         C         D         E         F \n#&gt; 0.3492120 0.8025007 1.1330596 0.9212838 1.2216312 0.8278727\n\nwoolf &lt;- function(x) {\n  x &lt;- x + 1 / 2\n  k &lt;- dim(x)[3]\n  or &lt;- apply(x, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))\n  w &lt;- apply(x, 3, function(x) 1 / sum(1 / x))\n  1 - pchisq(sum(w * (log(or) - weighted.mean(log(or), w))^2), k - 1)\n}\nwoolf(UCBAdmissions)\n\n#&gt; [1] 0.0034272",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-ucb-admissions",
    "href": "categorical-data-analysis.html#sec-ucb-admissions",
    "title": "14  分类数据的分析",
    "section": "\n14.5 加州伯克利分校的录取情况",
    "text": "14.5 加州伯克利分校的录取情况\n1973 年加州伯克利分校 6 个最大的院系的录取情况见下 表格 14.3 ，研究目标是加州伯克利分校在招生录取工作中是否有性别歧视？\n\n\n\n表格 14.3: 加州伯克利分校的录取情况\n\n\n\n\n\n\n\n\n院系\n录取\n拒绝\n\n\n男性\n女性\n男性\n女性\n\n\n\n\nA\n512\n89\n313\n19\n\n\nB\n353\n17\n207\n8\n\n\nC\n120\n202\n205\n391\n\n\nD\n138\n131\n279\n244\n\n\nE\n53\n94\n138\n299\n\n\nF\n22\n24\n351\n317\n\n\n\n\n\n\n\n\n\n\n借助马赛克图 图 14.5 可以更加直观的看出数据中的比例关系。\n\n\n\n\n\n\n\n图 14.5: 加州伯克利分校院系录取情况\n\n\n\n\n接下来进行定量的分析，首先，按性别和录取情况统计人数，如下：\n\nm &lt;- xtabs(Freq ~ Gender + Admit, data = as.data.frame(UCBAdmissions))\nm\n\n#&gt;         Admit\n#&gt; Gender   Admitted Rejected\n#&gt;   Male       1198     1493\n#&gt;   Female      557     1278\n\n\n可以看到，申请加州伯克利分校的女生当中，只有 \\(557 / (557 + 1278) = 30.35\\%\\) 录取了，而男生则有 \\(1198 / (1198 + 1493) = 44.52\\%\\) 的录取率。根据皮尔逊 \\(\\chi^2\\) 检验：\n\n# 不带耶茨矫正\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 92.205, df = 1, p-value &lt; 2.2e-16\n\n\n可知 \\(\\chi^2\\) 统计量的值为 \\(92.205\\) 且 P 值远远小于 0.05， 差异达到统计显著性，不是随机因素导致的。因此，加州伯克利分校被指控在招生录取工作中存在性别歧视。然而，当我们细分到各个院系去看录取率（录取人数 / 申请人数），结果显示院系 A 的录取率为 64.41%，院系 B 的录取率为 63.24%，依次类推，各院系情况如下：\n\nproportions(xtabs(Freq ~ Dept + Admit,\n  data = as.data.frame(UCBAdmissions)\n), margin = 1)\n\n#&gt;     Admit\n#&gt; Dept   Admitted   Rejected\n#&gt;    A 0.64415863 0.35584137\n#&gt;    B 0.63247863 0.36752137\n#&gt;    C 0.35076253 0.64923747\n#&gt;    D 0.33964646 0.66035354\n#&gt;    E 0.25171233 0.74828767\n#&gt;    F 0.06442577 0.93557423\n\n\n\n\n\n\n\n\n\n图 14.6: 加州伯克利分校各院系录取情况\n\n\n\n\n对每个院系，单独使用皮尔逊 \\(\\chi^2\\) 检验，发现只有 A 系的男、女生录取率的差异达到统计显著性，其它系的差异都不显著。辛普森悖论在这里出现了，在分类数据的分析中，常常遇到。\n\n# 以 A 系为例\nma &lt;- xtabs(Freq ~ Gender + Admit,\n  subset = Dept == \"A\",\n  data = as.data.frame(UCBAdmissions)\n)\nchisq.test(ma, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  ma\n#&gt; X-squared = 17.248, df = 1, p-value = 3.28e-05\n\n\n为了经一步说明此现象的原因，建立对数线性模型来拟合数据，值得一提的是皮尔逊卡方检验可以从对数线性模型的角度来看，而对数线性模型是一种特殊的广义线性模型，针对计数数据建模。\n\nfit_ucb0 &lt;- glm(Freq ~ Dept + Admit + Gender,\n  family = poisson(link = \"log\"),\n  data = as.data.frame(UCBAdmissions)\n)\nsummary(fit_ucb0)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ Dept + Admit + Gender, family = poisson(link = \"log\"), \n#&gt;     data = as.data.frame(UCBAdmissions))\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)    5.37111    0.03964 135.498  &lt; 2e-16 ***\n#&gt; DeptB         -0.46679    0.05274  -8.852  &lt; 2e-16 ***\n#&gt; DeptC         -0.01621    0.04649  -0.349 0.727355    \n#&gt; DeptD         -0.16384    0.04832  -3.391 0.000696 ***\n#&gt; DeptE         -0.46850    0.05276  -8.879  &lt; 2e-16 ***\n#&gt; DeptF         -0.26752    0.04972  -5.380 7.44e-08 ***\n#&gt; AdmitRejected  0.45674    0.03051  14.972  &lt; 2e-16 ***\n#&gt; GenderFemale  -0.38287    0.03027 -12.647  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2650.1  on 23  degrees of freedom\n#&gt; Residual deviance: 2097.7  on 16  degrees of freedom\n#&gt; AIC: 2272.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n添加性别和院系的交互效应后，对数线性模型的 AIC 下降一半多，说明模型的交互效应是显著的，也就是说性别和院系之间存在非常强的关联。\n\nfit_ucb1 &lt;- glm(Freq ~ Dept + Admit + Gender + Dept * Gender,\n  family = poisson(link = \"log\"),\n  data = as.data.frame(UCBAdmissions)\n)\nsummary(fit_ucb1)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ Dept + Admit + Gender + Dept * Gender, family = poisson(link = \"log\"), \n#&gt;     data = as.data.frame(UCBAdmissions))\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)         5.76801    0.03951 145.992  &lt; 2e-16 ***\n#&gt; DeptB              -0.38745    0.05475  -7.076 1.48e-12 ***\n#&gt; DeptC              -0.93156    0.06549 -14.224  &lt; 2e-16 ***\n#&gt; DeptD              -0.68230    0.06008 -11.356  &lt; 2e-16 ***\n#&gt; DeptE              -1.46311    0.08030 -18.221  &lt; 2e-16 ***\n#&gt; DeptF              -0.79380    0.06239 -12.722  &lt; 2e-16 ***\n#&gt; AdmitRejected       0.45674    0.03051  14.972  &lt; 2e-16 ***\n#&gt; GenderFemale       -2.03325    0.10233 -19.870  &lt; 2e-16 ***\n#&gt; DeptB:GenderFemale -1.07581    0.22860  -4.706 2.52e-06 ***\n#&gt; DeptC:GenderFemale  2.63462    0.12343  21.345  &lt; 2e-16 ***\n#&gt; DeptD:GenderFemale  1.92709    0.12464  15.461  &lt; 2e-16 ***\n#&gt; DeptE:GenderFemale  2.75479    0.13510  20.391  &lt; 2e-16 ***\n#&gt; DeptF:GenderFemale  1.94356    0.12683  15.325  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2650.10  on 23  degrees of freedom\n#&gt; Residual deviance:  877.06  on 11  degrees of freedom\n#&gt; AIC: 1062.1\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n此辛普森悖论现象的解释是女生倾向于申请录取率低的院系，而男生倾向于申请录取率高的院系，最终导致整体上，男生的录取率显著高于女生。至于为什么女生会倾向于申请录取率低的院系？这可能要看具体的院系是哪些，招生政策如何？这已经不是仅仅依靠招生办的统计数字就可以完全解释得了的，更多详情见文献 Bickel, Hammel, 和 O’Connell (1975) 。\n\n\n\n\n\n\n提示\n\n\n\n对数线性模型的皮尔逊 \\(\\chi^2\\) 检验的统计量\n\nsum(residuals(fit_ucb1, type = \"pearson\")^2)\n\n#&gt; [1] 797.7045\n\n\n比较多个广义线性模型的拟合效果，除了看 AIC，还可以看对数似然，它越大越好。可以看到添加性别和院系的交互效应后，对数似然增加了一倍多。\n\n# 基础模型\nlogLik(fit_ucb0)\n\n#&gt; 'log Lik.' -1128.365 (df=8)\n\n# 添加交互效应\nlogLik(fit_ucb1)\n\n#&gt; 'log Lik.' -518.0581 (df=13)",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-titanic",
    "href": "categorical-data-analysis.html#sec-titanic",
    "title": "14  分类数据的分析",
    "section": "\n14.6 分析泰坦尼克号乘客生存率",
    "text": "14.6 分析泰坦尼克号乘客生存率\n分析存活率的影响因素。\n除了从条件独立性检验的角度，下面从逻辑回归模型的角度分析这个高维列联表数据，由此，我们可以知道假设检验和广义线性模型之间的联系，针对复杂高维列联表数据进行关联分析和解释。\n响应变量是乘客的状态，存活还是死亡，titanic_data 是按船舱 Class、性别 Sex 和年龄 Age 分类汇总统计的数据，因此，下面的逻辑回归模型是对乘客群体的建模。\n\n# 建立模型\nfit_titanic &lt;- glm(cbind(Freq_Yes, Freq_No) ~ Class + Sex + Age,\n  data = titanic_data, family = binomial(link = \"logit\")\n)\n\n接着，我们查看模型输出的情况\n\n# 模型输出\nsummary(fit_titanic)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = cbind(Freq_Yes, Freq_No) ~ Class + Sex + Age, family = binomial(link = \"logit\"), \n#&gt;     data = titanic_data)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   0.6853     0.2730   2.510   0.0121 *  \n#&gt; Class2nd     -1.0181     0.1960  -5.194 2.05e-07 ***\n#&gt; Class3rd     -1.7778     0.1716 -10.362  &lt; 2e-16 ***\n#&gt; ClassCrew    -0.8577     0.1573  -5.451 5.00e-08 ***\n#&gt; SexFemale     2.4201     0.1404  17.236  &lt; 2e-16 ***\n#&gt; AgeAdult     -1.0615     0.2440  -4.350 1.36e-05 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 671.96  on 13  degrees of freedom\n#&gt; Residual deviance: 112.57  on  8  degrees of freedom\n#&gt; AIC: 171.19\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n\n\n\n\nAgresti, Alan. 2007. An Introduction to Categorical Data Analysis. 2nd 本. Hoboken, New Jersey: John Wiley & Sons, Inc.\n\n\nBickel, P. J., E. A. Hammel, 和 J. W. O’Connell. 1975. 《Sex Bias in Graduate Admissions: Data from Berkeley》. Science 187 (4175): 398–404. https://doi.org/10.1126/science.187.4175.398.\n\n\nBrunson, Jason Cory. 2020. 《ggalluvial: Layered Grammar for Alluvial Plots》. Journal of Open Source Software 5 (49): 2017. https://doi.org/10.21105/joss.02017.\n\n\nClopper, C. J., 和 E. S. Pearson. 1934. 《The Use of Confidence or Fiducial Limits Illustrated In The Case of The Binomial》. Biometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nFriendly, Michael, 和 David Meyer. 2016. Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data. 1st 本. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nMeyer, David, Achim Zeileis, 和 Kurt Hornik. 2006. 《The Strucplot Framework: Visualizing Multi-Way Contingency Tables with vcd》. Journal of Statistical Software 17 (3): 1–48. https://doi.org/10.18637/jss.v017.i03.\n\n\nNewcombe, Robert G. 1998. 《Interval estimation for the difference between independent proportions: comparison of eleven methods》. Statistics in Medicine 17 (8): 873–90. https://doi.org/10.1002/(SICI)1097-0258(19980430)17:8&lt;873::AID-SIM779&gt;3.0.CO;2-I.\n\n\nWilson, Edwin B. 1927. 《Probable inference, the law of succession, and statistical inference》. Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZeileis, Achim, David Meyer, 和 Kurt Hornik. 2007. 《Residual-based Shadings for Visualizing (Conditional) Independence》. Journal of Computational and Graphical Statistics 16 (3): 507–25. https://doi.org/10.1198/106186007X237856.\n\n\n宋泽熙. 2011. 《两个二项总体成功概率的比较》. 中国校外教育（理论） z1: 81. https://doi.org/10.3969/j.issn.1004-8502-B.2011.z1.0919.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#footnotes",
    "href": "categorical-data-analysis.html#footnotes",
    "title": "14  分类数据的分析",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Ronald_Fisher↩︎",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "power-analysis.html",
    "href": "power-analysis.html",
    "title": "15  统计检验的功效",
    "section": "",
    "text": "15.1 三大检验方法\n统计检验的一般方法。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#三大检验方法",
    "href": "power-analysis.html#三大检验方法",
    "title": "15  统计检验的功效",
    "section": "",
    "text": "15.1.1 Wald 检验\n\n15.1.2 Wilks 检验\n也叫似然比检验\n\n15.1.3 Rao 检验\n也叫得分检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#t-检验的功效",
    "href": "power-analysis.html#t-检验的功效",
    "title": "15  统计检验的功效",
    "section": "\n15.2 t 检验的功效",
    "text": "15.2 t 检验的功效\n检验的功效常用于样本量的计算\npower.t.test() 计算单样本或两样本的 t 检验的功效，或者根据功效计算参数，如样本量\n\n代码library(ggplot2)\nn &lt;- 30 # 样本量（只是一个例子）\nx &lt;- seq(from = 0, to = 12, by = 0.01)\ndat &lt;- data.frame(xx = x / sqrt(n), yy = 2 * (1 - pt(x, n - 1)))\nggplot(data = dat, aes(x = xx, y = yy)) +\n  geom_line(linewidth = 1) +\n  geom_vline(xintercept = c(0.01, 0.2, 0.5, 0.8, 1.2, 2), linetype = 2) +\n  theme_classic(base_size = 13) +\n  labs(x = \"$d = \\\\frac{t}{\\\\sqrt{n}}$\", \n       y = \"$2(1 - \\\\mathrm{pt}(x, n - 1))$\")\n\n\n\n\n\n\n图 15.1: t 检验的功效\n\n\n\n\n\npower.t.test(\n  n = 100, delta = 2.2,\n  sd = 1, sig.level = 0.05,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 100\n#&gt;           delta = 2.2\n#&gt;              sd = 1\n#&gt;       sig.level = 0.05\n#&gt;           power = 1\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\n\n\n表格 15.1: 函数 power.t.test() 的参数及其含义\n\n\n\n\n\n\n\n参数\n含义\n\n\n\nn\n每个组的样本量\n\n\ndelta\n两个组的均值之差\n\n\nsd\n标准差，默认值 1\n\n\nsig.level\n显著性水平，默认是 0.05 （犯第 I 类错误的概率）\n\n\npower\n检验的功效（1 - 犯第 II 类错误的概率）\n\n\ntype\nt 检验的类型 \"two.sample\" 两样本、\"one.sample\" 单样本或 \"paired\" 配对样本\n\n\nalternative\n单边或双边检验，取值为 \"two.sided\" 或 \"one.sided\"\n\n\n\n\n\n\n\n参数 n，delta，power，sd 和 sig.level 必须有一个值为 NULL，为 NULL 的参数是由其它参数决定的。\n\n# 前面 t 检验的等价功效计算\nlibrary(pwr)\npwr.t.test(\n  d = 2.2 / 6.4,\n  n = 100,\n  sig.level = 0.05,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 100\n#&gt;               d = 0.34375\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.6768572\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\nsleep 数据集为例，计算功效\n\n# 分组计算均值\naggregate(data = sleep, extra ~ group, FUN = mean)\n\n#&gt;   group extra\n#&gt; 1     1  0.75\n#&gt; 2     2  2.33\n\n# 分组计算标准差\naggregate(data = sleep, extra ~ group, FUN = sd)\n\n#&gt;   group    extra\n#&gt; 1     1 1.789010\n#&gt; 2     2 2.002249\n\n# 代入计算功效\npower.t.test(\n  delta = 2.33 - 0.75,            # 两组均值之差\n  sd = (2.002249 + 1.789010) / 2, # 标准差\n  sig.level = 0.05,         # 显著性水平\n  type = \"two.sample\",      # 两样本\n  power = 0.95,             # 功效水平\n  alternative = \"two.sided\" # 双边检验\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 38.39795\n#&gt;           delta = 1.58\n#&gt;              sd = 1.89563\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\n经检验，上面取两组的平均方差代替共同方差和下面精确计算的结果差不多。各组至少需要 39 个样本。MKpower 包精确计算 Welch t 检验的功效\n\nlibrary(MKpower)\npower.welch.t.test(\n  delta = 2.33 - 0.75,\n  sd1 = 2.002249,\n  sd2 = 1.789010,\n  sig.level = 0.05,\n  power = 0.95,\n  alternative = \"two.sided\"\n)\n\n我国著名统计学家许宝騄先生对此功效计算方法做出过巨大贡献。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#比例检验的功效",
    "href": "power-analysis.html#比例检验的功效",
    "title": "15  统计检验的功效",
    "section": "\n15.3 比例检验的功效",
    "text": "15.3 比例检验的功效\n\n# power.prop.test()\n\npower.prop.test() 计算两样本比例检验的功效\n功效可以用来计算实验所需要的样本量，检验统计量的功效越大/高，检验方法越好，实验所需要的样本量越少\n\n# p1 &gt;= p2 的检验 单边和双边检验\npower.prop.test(\n  p1 = .65, p2 = 0.6, sig.level = .05,\n  power = 0.90, alternative = \"one.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample comparison of proportions power calculation \n#&gt; \n#&gt;               n = 1603.846\n#&gt;              p1 = 0.65\n#&gt;              p2 = 0.6\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = one.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\npower.prop.test(\n  p1 = .65, p2 = 0.6, sig.level = .05,\n  power = 0.90, alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample comparison of proportions power calculation \n#&gt; \n#&gt;               n = 1968.064\n#&gt;              p1 = 0.65\n#&gt;              p2 = 0.6\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\npwr 包 pwr.2p.test() 函数提供了类似 power.prop.test() 函数的功能\n\nlibrary(pwr)\n# 明确 p1 &gt; p2 的检验\n# 单边检验拆分更加明细，分为大于和小于\npwr.2p.test(\n  h = ES.h(p1 = 0.65, p2 = 0.6),\n  sig.level = 0.05, power = 0.9, alternative = \"greater\"\n)\n\n#&gt; \n#&gt;      Difference of proportion power calculation for binomial distribution (arcsine transformation) \n#&gt; \n#&gt;               h = 0.1033347\n#&gt;               n = 1604.007\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = greater\n#&gt; \n#&gt; NOTE: same sample sizes\n\n\n已知两样本的样本量不等，检验 H_0: \\(p_1 = p_2\\) H_1: \\(p_1 \\neq p_2\\) 的功效\n\npwr.2p2n.test(\n  h = 0.30, n1 = 80, n2 = 245,\n  sig.level = 0.05, alternative = \"greater\"\n)\n\n#&gt; \n#&gt;      difference of proportion power calculation for binomial distribution (arcsine transformation) \n#&gt; \n#&gt;               h = 0.3\n#&gt;              n1 = 80\n#&gt;              n2 = 245\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.7532924\n#&gt;     alternative = greater\n#&gt; \n#&gt; NOTE: different sample sizes\n\n\nh 表示两个样本的差异，计算得到的功效是 0.75",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#方差分析的功效",
    "href": "power-analysis.html#方差分析的功效",
    "title": "15  统计检验的功效",
    "section": "\n15.4 方差分析的功效",
    "text": "15.4 方差分析的功效\npower.anova.test() 计算平衡的单因素方差分析检验的功效\n\npower.anova.test(\n  groups = 4,       #  4 个组  \n  between.var = 1,  # 组间方差为 1\n  within.var = 3,   # 组内方差为 3\n  power = 0.95      # 1 - 犯第二类错误的概率\n)\n\n#&gt; \n#&gt;      Balanced one-way analysis of variance power calculation \n#&gt; \n#&gt;          groups = 4\n#&gt;               n = 18.18245\n#&gt;     between.var = 1\n#&gt;      within.var = 3\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt; \n#&gt; NOTE: n is number in each group\n\n\n\nlibrary(pwr)\n# f 是如何和上面的组间/组内方差等价指定的\npwr.anova.test(\n  k = 4,            # 组数\n  f = 0.5,          # 效应大小\n  sig.level = 0.05, # 显著性水平\n  power = 0.95      # 检验的效\n)\n\n#&gt; \n#&gt;      Balanced one-way analysis of variance power calculation \n#&gt; \n#&gt;               k = 4\n#&gt;               n = 18.18244\n#&gt;               f = 0.5\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt; \n#&gt; NOTE: n is number in each group",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html",
    "href": "analyze-network-data.html",
    "title": "16  网络数据分析",
    "section": "",
    "text": "16.1 R 语言社区的规模\n从 CRAN 上的 R 包及其开发者数量来看目前 R 语言社区规模。\n# 设置就近的 CRAN 镜像站点\nSys.setenv(R_CRAN_WEB = \"https://mirrors.tuna.tsinghua.edu.cn/CRAN\")\n# 获取 R 包元数据\npdb &lt;- tools::CRAN_package_db()\n截止 2022 年 12 月 31 日， CRAN 上发布的 R 包有 18976 个，CRAN 进入年末维护期 2022-12-22 至 2023-01-05。\npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package),\n  select = c(\"Package\", \"Maintainer\", \"Title\", \"Authors@R\", \"Date\", \"Published\")\n)\n距离上次更新的时间分布，有的包是一周内更新的，也有的是 10 多年未更新的。\npdb$date_diff &lt;- as.integer(as.Date(\"2022-12-31\") - as.Date(pdb$Published))\n根据发布日期 Published 构造新的一列 — 发布年份。\npdb$published_year &lt;- as.integer(format(as.Date(pdb$Published), \"%Y\"))\n然后按年统计更新的 R 包数量，如 图 16.1 所示，以 2020 年为例，总数 18976 个 R 包当中有 2470 个 R 包的更新日期停留在 2020 年，占比 2470 / 18976 = 13.02%。过去 1 年内更新的 R 包有 8112 个（包含新出现的 R 包），占总数 8112 / 18976 = 42.75%，过去 2 年内更新的 R 包有 11553 个，占总数 11553 / 18976 = 60.88%，这个占比越高说明社区开发者越活跃。\nlibrary(ggplot2)\naggregate(data = pdb, Package ~ published_year, FUN = length) |&gt;\n  ggplot(aes(x = published_year, y = Package)) +\n  geom_col(fill = NA, color = \"gray20\") +\n  theme_classic() +\n  coord_cartesian(expand = F) +\n  labs(x = \"年份\", y = \"R 包数量\")\n\n\n\n\n\n\n图 16.1: CRAN 上 R 包的更新情况\n截止 2022-12-31，CRAN 上 R 包的维护者有 10067 人，其中有多少人在 2022 年更新了自己的 R 包呢？有 4820 个维护者，占比 47.96%，也就是说 2022 年，有 4820 个开发者更新了 8112 个 R 包，人均更新 1.68 个 R 包，下 图 16.2 按 R 包发布年份统计开发者数量。\n# 清理维护者字段，同一个开发者可能有多个邮箱\nextract_maintainer &lt;- function(x) {\n  x &lt;- gsub(pattern = \"&lt;.*?&gt;\", replacement = \"\", x = x)\n  trimws(x, which = \"both\", whitespace = \"[ \\t\\r\\n]\")\n}\n# 只有 18 个维护者名字有大小写差别\npdb$Maintainer2 &lt;- extract_maintainer(pdb$Maintainer)\n# 维护者总数\nlength(unique(pdb$Maintainer2))\n\n#&gt; [1] 10067\n代码aggregate(\n  data = pdb, Maintainer2 ~ published_year,\n  FUN = function(x) { length(unique(x)) }\n) |&gt;\n  ggplot(aes(x = published_year, y = Maintainer2)) +\n  geom_col(fill = NA, color = \"gray20\") +\n  theme_classic() +\n  coord_cartesian(expand = F) +\n  labs(x = \"年份\", y = \"开发者数量\")\n\n\n\n\n\n\n图 16.2: CRAN 上的维护者活跃情况",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-community-org",
    "href": "analyze-network-data.html#sec-community-org",
    "title": "16  网络数据分析",
    "section": "\n16.2 R 语言社区的组织",
    "text": "16.2 R 语言社区的组织\n除了 RStudio 公司出品的 tidyverse (Wickham 等 2019) 和 tidymodels (Kuhn 和 Wickham 2020)，还有一些数据分析、建模的工具箱，如 mlr3verse (Lang 和 Schratz 2023)、easystats (Lüdecke 等 2022)、strengejacke (Lüdecke 2019) 和 DrWhy (Biecek 2023)。也有的组织基本停止了开发，如 Omegahat。还有的被商业公司收购后，不再活跃了，如 Revolution Analytics。它们作为解决方案大都属于一些组织，还有深藏功与名，有待笔者挖掘的。因不存在明显的规律，下面从开发者的邮箱出发，隶属企业、组织往往有统一的邮箱后缀。\n\nstr_extract &lt;- function(text, pattern, ...) regmatches(text, regexpr(pattern, text, ...))\n# 移除 ORPHANED\npdb &lt;- subset(pdb, subset = Maintainer != \"ORPHANED\")\n# 抽取邮件后缀\nextract_email_suffix &lt;- function(x) {\n  x &lt;- str_extract(text = x, pattern = \"&lt;.*?&gt;\")\n  sub(x = x, pattern = \".*?@(.*?)&gt;\", replacement = \"\\\\1\")\n}\npdb$Email_suffix &lt;- extract_email_suffix(pdb$Maintainer)\n\n按组织统计扩展包的数量（总的 R 包数量约 2 万），即各个组织开发的 R 包。\n\npdb_pkg &lt;- aggregate(\n  data = pdb, Package ~ Email_suffix, FUN = function(x) { length(unique(x)) }\n)\nhead(pdb_pkg[order(pdb_pkg$Package, decreasing = TRUE), ], 20)\n\n#&gt;        Email_suffix Package\n#&gt; 876       gmail.com    6968\n#&gt; 2044    rstudio.com     208\n#&gt; 979     hotmail.com     185\n#&gt; 1825    outlook.com     152\n#&gt; 1971  R-project.org     106\n#&gt; 2           163.com      94\n#&gt; 210    berkeley.edu      91\n#&gt; 2559      umich.edu      91\n#&gt; 2819         uw.edu      74\n#&gt; 1927 protonmail.com      73\n#&gt; 2564        umn.edu      69\n#&gt; 581      debian.org      68\n#&gt; 2951      yahoo.com      68\n#&gt; 1828     outlook.fr      63\n#&gt; 2212   stanford.edu      58\n#&gt; 155  auckland.ac.nz      57\n#&gt; 887          gmx.de      55\n#&gt; 2911       wisc.edu      55\n#&gt; 895  googlemail.com      50\n#&gt; 1970  r-project.org      50\n\n\n不难看出，至少有如下几类：\n\n邮件服务提供商。6968 个 R 包使用 gmail 邮箱作为联系维护者的方式，googlemail.com 也是谷歌提供的服务。hotmail.com 和 outlook.com 都是微软提供的邮箱服务，outlook.fr （法国）也是，除此之外，比较大的邮件服务提供商就是 163.com（网易）、 protonmail.com 和 yahoo.com （雅虎）等。\n商业组织。208 个 R 包来自 RStudio 公司的员工，这些维护者使用 RStudio 公司提供的邮箱。\n开源组织。R-project.org 和 r-project.org 都是 R 语言组织的联系方式，自不必多说，R 语言核心团队成员不仅维护 R 软件源码，还维护了很多 R 包。debian.org 是 Debian 组织的联系方式，都是开源组织（Open Source Org）。\n教育机构。berkeley.edu 、umich.edu 等以 edu 结尾的北美（国）的大学，gmx.de、 posteo.de 等以 de 结尾的德国大学，ucl.ac.uk 等以 uk 结尾的英国的大学，auckland.ac.nz 等以 nz 结尾的新西兰的大学，uwaterloo.ca 等以 ca 结尾的加拿大的大学。\n\n按组织统计开发者的数量（总的开发者数量约 1 万），即各个组织的 R 包开发者。\n\npdb_org &lt;- aggregate(\n  data = pdb, Maintainer2 ~ Email_suffix, FUN = function(x) { length(unique(x)) }\n)\nhead(pdb_org[order(pdb_org$Maintainer2, decreasing = TRUE), ], 20)\n\n#&gt;        Email_suffix Maintainer2\n#&gt; 876       gmail.com        3800\n#&gt; 979     hotmail.com         110\n#&gt; 1825    outlook.com          87\n#&gt; 2           163.com          57\n#&gt; 2559      umich.edu          54\n#&gt; 2951      yahoo.com          51\n#&gt; 2564        umn.edu          47\n#&gt; 1927 protonmail.com          46\n#&gt; 2819         uw.edu          46\n#&gt; 887          gmx.de          34\n#&gt; 210    berkeley.edu          33\n#&gt; 2044    rstudio.com          30\n#&gt; 895  googlemail.com          28\n#&gt; 2212   stanford.edu          27\n#&gt; 468    columbia.edu          26\n#&gt; 1114       inrae.fr          26\n#&gt; 2451      ucl.ac.uk          25\n#&gt; 2964       yale.edu          25\n#&gt; 635        duke.edu          23\n#&gt; 1906      posteo.de          23\n\n\n可见，大部分开发者采用邮件服务提供商的邮件地址。3800 个开发者使用来自谷歌的 gmail.com、197 个开发者使用来自微软的 hotmail.com 或 outlook.com，57 个开发者使用来自网易的 163.com，51 个开发者使用来自雅虎的 yahoo.com，46 个开发者使用来自 Proton 的 protonmail.com。\n无论从开发者数量还是 R 包数量的角度看，都有两个显著特点。其一马太效应，往头部集中，其二，长尾分布，尾部占比接近甚至超过 50%。\n\n16.2.1 美国、英国和加拿大\n1666 个开发者来自以 edu 为后缀的邮箱。各个组织（主要是大学）及其 R 包开发者数据如下：\n\nsum(pdb_org[grepl(pattern = \"edu$\", x = pdb_org$Email_suffix), \"Maintainer2\"])\n\n#&gt; [1] 1666\n\npdb_org_edu &lt;- pdb_org[grepl(pattern = \"edu$\", x = pdb_org$Email_suffix), ]\npdb_org_edu[order(pdb_org_edu$Maintainer2, decreasing = TRUE), ] |&gt; head(20)\n\n#&gt;        Email_suffix Maintainer2\n#&gt; 2559      umich.edu          54\n#&gt; 2564        umn.edu          47\n#&gt; 2819         uw.edu          46\n#&gt; 210    berkeley.edu          33\n#&gt; 2212   stanford.edu          27\n#&gt; 468    columbia.edu          26\n#&gt; 2964       yale.edu          25\n#&gt; 635        duke.edu          23\n#&gt; 2911       wisc.edu          23\n#&gt; 482     cornell.edu          22\n#&gt; 2444    ucdavis.edu          21\n#&gt; 1929        psu.edu          19\n#&gt; 2449   uchicago.edu          19\n#&gt; 2830 vanderbilt.edu          19\n#&gt; 1660       ncsu.edu          18\n#&gt; 1663         nd.edu          18\n#&gt; 1008    iastate.edu          17\n#&gt; 1919  princeton.edu          17\n#&gt; 1815        osu.edu          16\n#&gt; 2523      uiowa.edu          16\n\n\n好吧，几乎全是美国各个 NB 大学的，比如华盛顿大学（ uw.edu）、密歇根大学（umich.edu）、加州伯克利大学（berkeley.edu）等等。顺便一说，美国各个大学的网站，特别是统计院系很厉害的，已经帮大家收集得差不多了，有留学打算的读者自取，邮箱后缀就是学校/院官网。\n有些邮箱后缀带有院系，但是并没有向上合并到学校这一级，比如 stanford.edu 、stat.stanford.edu 和 alumni.stanford.edu 等没有合并统计。实际上，使用 edu 邮箱的教育机构大部份位于美国。有的邮箱来自教育机构，但是不以 edu 结尾，比如新西兰奥克兰大学 auckland.ac.nz 、瑞士苏黎世联邦理工学院 stat.math.ethz.ch 等美国以外的教育机构。下面分别查看英国和加拿大的情况。\n350 个开发者来自以 uk 为后缀的邮箱。各个组织（主要是大学）及其 R 包开发者数据如下：\n\nsum(pdb_org[grepl(pattern = \"uk$\", x = pdb_org$Email_suffix), \"Maintainer2\"])\n\n#&gt; [1] 350\n\npdb_org_uk &lt;- pdb_org[grepl(pattern = \"uk$\", x = pdb_org$Email_suffix), ]\npdb_org_uk[order(pdb_org_uk$Maintainer2, decreasing = TRUE), ] |&gt; head(20)\n\n#&gt;            Email_suffix Maintainer2\n#&gt; 2451          ucl.ac.uk          25\n#&gt; 329           cam.ac.uk          17\n#&gt; 295       bristol.ac.uk          15\n#&gt; 1088     imperial.ac.uk          14\n#&gt; 658            ed.ac.uk          13\n#&gt; 1286    lancaster.ac.uk          11\n#&gt; 1363          lse.ac.uk           9\n#&gt; 1605  mrc-bsu.cam.ac.uk           9\n#&gt; 2878      warwick.ac.uk           9\n#&gt; 870       glasgow.ac.uk           8\n#&gt; 1364        lshtm.ac.uk           8\n#&gt; 1424   manchester.ac.uk           8\n#&gt; 636        durham.ac.uk           7\n#&gt; 744        exeter.ac.uk           7\n#&gt; 2260 statslab.cam.ac.uk           7\n#&gt; 2188        soton.ac.uk           6\n#&gt; 2972         york.ac.uk           6\n#&gt; 978       hotmail.co.uk           5\n#&gt; 1948         qmul.ac.uk           5\n#&gt; 248         bioss.ac.uk           4\n\n\n258 个开发者来自以 ca 为后缀的邮箱。各个组织（主要是大学）及其 R 包开发者数据如下：\n\nsum(pdb_org[grepl(pattern = \"ca$\", x = pdb_org$Email_suffix), \"Maintainer2\"])\n\n#&gt; [1] 258\n\npdb_org_ca &lt;- pdb_org[grepl(pattern = \"ca$\", x = pdb_org$Email_suffix), ]\npdb_org_ca[order(pdb_org_ca$Maintainer2, decreasing = TRUE), ] |&gt; head(10)\n\n#&gt;          Email_suffix Maintainer2\n#&gt; 2822     uwaterloo.ca          19\n#&gt; 1397   mail.mcgill.ca          14\n#&gt; 2123           sfu.ca          12\n#&gt; 2801      utoronto.ca          12\n#&gt; 2426      ualberta.ca          11\n#&gt; 2239      stat.ubc.ca           9\n#&gt; 2434           ubc.ca           9\n#&gt; 2813          uvic.ca           8\n#&gt; 952            hec.ca           7\n#&gt; 1416 mail.utoronto.ca           7\n\n\n\n16.2.2 CRAN 和 RStudio\n下面根据邮箱后缀匹配抽取 CRAN 团队及开发的 R 包，规则也许不能覆盖所有的情况，比如署名 CRAN Team 的维护者代表的是 CRAN 团队，XML 和 RCurl 包就由他们维护。再比如，Brian Ripley 的邮箱 ripley@stats.ox.ac.uk 就不是 CRAN 官网域名。读者若有补充，欢迎 PR 给我。\n代码cran_dev &lt;- subset(pdb,\n  subset = grepl(\n    x = Maintainer,\n    pattern = paste0(c(\n      \"(@[Rr]-project\\\\.org)\", # 官方邮箱\n      \"(ripley@stats.ox.ac.uk)\", # Brian Ripley\n      \"(p.murrell@auckland.ac.nz)\", # Paul Murrell\n      \"(paul@stat.auckland.ac.nz)\", # Paul Murrell\n      \"(maechler@stat.math.ethz.ch)\", # Martin Maechler\n      \"(mmaechler+Matrix@gmail.com)\", # Martin Maechler\n      \"(bates@stat.wisc.edu)\", # Douglas Bates\n      \"(pd.mes@cbs.dk)\", # Peter Dalgaard\n      \"(ligges@statistik.tu-dortmund.de)\", # Uwe Ligges\n      \"(tlumley@u.washington.edu)\", # Thomas Lumley\n      \"(t.lumley@auckland.ac.nz)\", # Thomas Lumley\n      \"(martyn.plummer@gmail.com)\", # Martyn Plummer\n      \"(luke-tierney@uiowa.edu)\", # Luke Tierney\n      \"(stefano.iacus@unimi.it)\", # Stefano M. Iacus\n      \"(murdoch.duncan@gmail.com)\", # Duncan Murdoch\n      \"(michafla@gene.com)\" # Michael Lawrence\n    ), collapse = \"|\")\n  ),\n  select = c(\"Package\", \"Maintainer\")\n) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = '(&lt;([^&lt;&gt;]*)&gt;)|(\")', replacement = \"\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = \"(R-core)|(R Core Team)\", replacement = \"CRAN Team\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer,\n    pattern = \"(S. M. Iacus)|(Stefano M.Iacus)|(Stefano Maria Iacus)\",\n    replacement = \"Stefano M. Iacus\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = \"(Toby Hocking)\",\n    replacement = \"Toby Dylan Hocking\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = \"(John M Chambers)\", replacement = \"John Chambers\"\n  ))\ncran_dev &lt;- aggregate(data = cran_dev, Package ~ Maintainer, FUN = function(x) length(unique(x)))\ncran_dev &lt;- cran_dev[order(cran_dev$Package, decreasing = TRUE), ]\nknitr::kable(head(cran_dev, ceiling(nrow(cran_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\nknitr::kable(tail(cran_dev, floor(nrow(cran_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n\n\n表格 16.1: CRAN 团队开发维护 R 包数量情况\n\n\n\n\n\n(a) 表\n\n\n\n团队成员\nR 包数量\n\n\n\nKurt Hornik\n28\n\n\nSimon Urbanek\n26\n\n\nAchim Zeileis\n25\n\n\nMartin Maechler\n25\n\n\nTorsten Hothorn\n25\n\n\nPaul Murrell\n19\n\n\nToby Dylan Hocking\n17\n\n\nBrian Ripley\n12\n\n\nThomas Lumley\n12\n\n\nUwe Ligges\n9\n\n\nDuncan Murdoch\n7\n\n\nDavid Meyer\n6\n\n\nCRAN Team\n5\n\n\n\n\n\n\n\n\n\n\n(b) 续表\n\n\n\n团队成员\nR 包数量\n\n\n\nFriedrich Leisch\n5\n\n\nLuke Tierney\n5\n\n\nMichael Lawrence\n5\n\n\nStefan Theussl\n5\n\n\nBettina Grün\n3\n\n\nJohn Chambers\n3\n\n\nSimon Wood\n3\n\n\nBettina Gruen\n2\n\n\nDeepayan Sarkar\n2\n\n\nDouglas Bates\n2\n\n\nMartyn Plummer\n2\n\n\nPeter Dalgaard\n1\n\n\n\n\n\n\n\n\n\n\n\nKurt Hornik、Simon Urbanek、Achim Zeileis 等真是高产呐！除了维护 R 语言核心代码，还开发维护了那么多 R 包。以 Brian Ripley 为例，看看他都具体维护了哪些 R 包。\n\n代码subset(pdb,\n  subset = grepl(x = Maintainer, pattern = \"Brian Ripley\"),\n  select = c(\"Package\", \"Title\"), drop = TRUE\n) |&gt;\n  unique(by = \"Package\") |&gt;\n  transform(Title = gsub(pattern = \"(\\\\\\n)\", replacement = \" \", x = Title)) |&gt;\n  knitr::kable(row.names = FALSE)\n\n\n表格 16.2: Brian Ripley 维护的 R 包\n\n\n\n\n\n\n\n\nPackage\nTitle\n\n\n\nboot\nBootstrap Functions (Originally by Angelo Canty for S)\n\n\nclass\nFunctions for Classification\n\n\nfastICA\nFastICA Algorithms to Perform ICA and Projection Pursuit\n\n\ngee\nGeneralized Estimation Equation Solver\n\n\nKernSmooth\nFunctions for Kernel Smoothing Supporting Wand & Jones (1995)\n\n\nMASS\nSupport Functions and Datasets for Venables and Ripley’s MASS\n\n\nmix\nEstimation/Multiple Imputation for Mixed Categorical and Continuous Data\n\n\nnnet\nFeed-Forward Neural Networks and Multinomial Log-Linear Models\n\n\npspline\nPenalized Smoothing Splines\n\n\nRODBC\nODBC Database Access\n\n\nspatial\nFunctions for Kriging and Point Pattern Analysis\n\n\ntree\nClassification and Regression Trees\n\n\n\n\n\n\n\n\n震惊！有一半收录在 R 软件中，所以已经持续维护 20 多年了。下面继续根据邮箱后缀将 RStudio 团队的情况统计出来，结果见下表。\n代码rstudio_dev &lt;- subset(pdb,\n  subset = grepl(x = Maintainer, pattern = \"(posit.co)|(rstudio.com)|(yihui.name)\"),\n  select = c(\"Package\", \"Maintainer\")\n) |&gt;\n  transform(Maintainer = extract_maintainer(Maintainer))\nrstudio_dev &lt;- aggregate(data = rstudio_dev, Package ~ Maintainer, FUN = function(x) length(unique(x)))\nrstudio_dev &lt;- rstudio_dev[order(rstudio_dev$Package, decreasing = TRUE), ]\nknitr::kable(head(rstudio_dev, ceiling(nrow(rstudio_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\nknitr::kable(tail(rstudio_dev, floor(nrow(rstudio_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n\n\n表格 16.3: RStudio 团队开发维护 R 包数量情况（部分）\n\n\n\n\n\n(a) 表\n\n\n\n团队成员\nR 包数量\n\n\n\nHadley Wickham\n48\n\n\nYihui Xie\n22\n\n\nMax Kuhn\n18\n\n\nLionel Henry\n15\n\n\nWinston Chang\n15\n\n\nDaniel Falbel\n13\n\n\nJennifer Bryan\n13\n\n\nDavis Vaughan\n11\n\n\nCarson Sievert\n10\n\n\nTomasz Kalinowski\n8\n\n\nBarret Schloerke\n6\n\n\nThomas Lin Pedersen\n6\n\n\nHannah Frick\n5\n\n\nChristophe Dervieux\n4\n\n\nJoe Cheng\n4\n\n\nJulia Silge\n4\n\n\n\n\n\n\n\n\n\n\n(b) 续表\n\n\n\n团队成员\nR 包数量\n\n\n\nCole Arendt\n3\n\n\nEdgar Ruiz\n3\n\n\nJJ Allaire\n3\n\n\nKevin Kuo\n3\n\n\nKevin Ushey\n3\n\n\nRichard Iannone\n3\n\n\nAron Atkins\n2\n\n\nRomain François\n2\n\n\nYitao Li\n2\n\n\nBrian Smith\n1\n\n\nEmil Hvitfeldt\n1\n\n\nGarrick Aden-Buie\n1\n\n\nJames Blair\n1\n\n\nNathan Stephens\n1\n\n\nNick Strayer\n1\n\n\n\n\n\n\n\n\n\n\n\nCRAN 和 RStudio 团队是 R 语言社区最为熟悉的，其它团队需借助一些网络分析算法挖掘了。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-community-developer",
    "href": "analyze-network-data.html#sec-community-developer",
    "title": "16  网络数据分析",
    "section": "\n16.3 R 语言社区的开发者",
    "text": "16.3 R 语言社区的开发者\n\n16.3.1 最高产的开发者\n继续基于数据集 pdb ，将维护 R 包数量比较多的开发者统计出来。\n\n代码pdb_ctb &lt;- aggregate(data = pdb, Package ~ Maintainer2, FUN = length)\nggplot(data = pdb_ctb[pdb_ctb$Package &gt;= 20, ]) +\n  geom_col(aes(x = Package, y = reorder(Maintainer2, Package)), width = .1) +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\n\n\n\n\n\n\n图 16.3: 高产的 R 包开发者\n\n\n\n\n这些开发者的主页和主要的 R 社区贡献如下：\n\n\nDirk Eddelbuettel 维护了 Rcpp、RcppEigen 等流行的 R 包，通过 Rcpp 包将很多优秀的 C++ 库引入 R 语言社区。\n\nStéphane Laurent 维护了很多与 shiny、htmlwidgets 相关的 R 包，比如 rAmCharts4 包。\n\nGábor Csárdi 维护了 igraph 包以及大量帮助 R 包开发的基础设施，RStudio 雇员。\n\nHadley Wickham 维护了 ggplot2、dplyr、devtools 等流行的 R 包，RStudio 雇员。\n\nJeroen Ooms 维护了 magick、curl 以及大量帮助 R 包开发的基础设施。\n\nScott Chamberlain 维护了很多与 HTTP/Web 相关的 R 包，rOpenSci 联合创始人。\n\nRobin K. S. Hankin 维护了很多与贝叶斯、多元统计相关的 R 包。\n\nHenrik Bengtsson 维护了 future 和 parallelly 等流行的 R 包，在并行计算方面有很多贡献。\n\nJan Wijffels 维护了很多与自然语言处理、图像识别相关的 R 包，比如 udpipe 、BTM 和 word2vec 等包，Bnosac 团队成员。\n\nKurt Hornik 参与维护 R 软件代码并许多与自然语言处理相关的 R 包，R 核心团队成员。\n\nMartin Maechler 维护了 Matrix 包，R 核心团队成员。\n\nMax Kuhn 维护了 tidymodels 等包，RStudio 雇员。\n\nBob Rudis 维护了一些与 ggplot2 相关的 R 包，如 ggalt、hrbrthemes 和 statebins 等。\n\nKartikeya Bolar 维护了很多统计与 shiny 结合的 R 包，比如方差分析、逻辑回归、列联表、聚类分析等。\n\nKirill Müller 维护了 DBI 等大量与数据库连接的 R 包。\n\nShannon T. Holloway 维护了许多与生存分析相关的 R 包。\n\nSimon Urbanek 维护了 rJava、Rserve 等流行的 R 包，R 核心团队成员，负责维护 R 软件中与 MacOS 平台相关的部分。\n\nAchim Zeileis 维护了 colorspace 等流行的 R 包，R 核心团队成员。\n\nMuhammad Yaseen 维护了多个与 Multiple Indicator Cluster Survey 相关的 R 包。\n\nPablo Sanchez 维护了多个与市场营销平台连接的 R 语言接口，Windsor.ai 组织成员。\n\nThomas Lin Pedersen 维护了 patchwork、 gganimate 和 ggraph 等流行的 R 包，RStudio 雇员。\n\nTorsten Hothorn 在统计检验方面贡献了不少内容，比如 coin 和 multcomp 等包，R 核心团队成员。\n\nRichard Cotton 维护了 assertive 和 rebus 系列 R 包，代码可读性检查。\n\nFlorian Schwendinger 维护了大量运筹优化方面的 R 包，扩展了 ROI 包的能力。\n\nGuangchuang Yu 维护了 ggtree 和 ggimage 等 R 包，在生物信息和可视化领域有不少贡献。\n\nWinston Chang 维护了 shiny 等流行的 R 包，RStudio 雇员。\n\nJohn Muschelli 维护了多个关于神经图像的 R 包。\n\nKevin R. Coombes 维护了多个关于生物信息的 R 包，如 oompaBase 和 oompaData 等。\n\nYihui Xie 维护了 knitr 、rmarkdown 等流行的 R 包，RStudio 雇员。\n\nCarl Boettiger 维护了多个接口包，比如 rfishbase 等，rOpenSci 团队成员。\n\nMichael D. Sumner 维护了多个空间统计相关的 R 包。\n\nEmil Hvitfeldt 维护了多个统计学习相关的 R 包，如 fastTextR 包等，RStudio 雇员。\n\nGeorgi N. Boshnakov 维护了多个金融时间序列相关的 R 包，如 fGarch、timeDate 和 timeSeries 等包。\n\nHana Sevcikova 维护了多个与贝叶斯人口统计相关的 R 包。\n\nJoe Thorley 维护了多个与贝叶斯 MCMC 相关的 R 包，Poisson Consulting 雇员。\n\n统计开发者数量随维护 R 包数量的分布，发现，开发 1 个 R 包的开发者有 6732 人，开发 2 个 R 包的开发者有 1685 人，第二名是第一名的五分之一，递减规律非常符合指数分布。\n\ntable(pdb_ctb$Package)\n\n#&gt; \n#&gt;    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n#&gt; 6732 1685  725  328  177   82   80   52   37   37   29   15   18    8   11    7 \n#&gt;   17   18   19   20   21   22   23   24   25   26   27   28   31   32   33   52 \n#&gt;    1    3    4    4    2    3    3    1    5    5    2    1    1    1    1    3 \n#&gt;   58   63   69 \n#&gt;    1    1    1\n\n\n过滤掉非常高产的开发者，可以发现变化规律服从幂律分布。\nggplot(data = pdb_ctb, aes(x = Package)) +\n  geom_histogram(binwidth = 1) +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\nggplot(data = pdb_ctb[pdb_ctb$Package &lt;= 20, ], aes(x = Package)) +\n  geom_histogram(binwidth = 1, fill = NA, color = \"gray20\") +\n  scale_y_log10() +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\n\n\n\n\n\n\n\n\n\n(a) 直方图\n\n\n\n\n\n\n\n\n\n(b) 直方图（对数尺度）\n\n\n\n\n\n\n图 16.4: 开发者数量的分布\n\n\n最高产 Top 1% 的开发者 131 人（开发 R 包超过 10 个的开发者）贡献了 2329 / 18976 = 12.3% 的扩展包 ，高产的是商业公司、开源组织、大学机构。\n\ndim(pdb_ctb[pdb_ctb$Package &gt; 10, ])\n\n#&gt; [1] 131   2\n\nsum(pdb_ctb[pdb_ctb$Package &gt; 10, \"Package\"])\n\n#&gt; [1] 2329\n\n\n最低产 Bottom 的开发者 6732 人（仅开发一个 R 包的开发者）占总开发者的比例 6732 / 10067 = 66.87%， 贡献了 6732 / 18976 = 35.5 % 的扩展包 ，低产的人是主体。\n\n16.3.2 开发者协作关系\n如果一个开发者维护了一个 R 包，就成为维护者。一个 R 包有唯一的一个维护者，可能有一个至多个贡献者，这样，维护者和贡献者之间就形成了有向关系，贡献者可能又是另一个 R 包的维护者，也可能不是。不仅有向而且可能存在环。在一个 R 包中，A 是 B 的贡献者，而在另一个 R 包中，B 是 A 的贡献者，A 和 B 之间可能通过多个 R 包存在多次互相协作关系，这也表明 A 和 B 之间的关系密切。有向环的节点可能有 2 个以上，一个人可能同时属于多个环。\n维护者 A 接受来自多个开发者的贡献，接受次数（所有贡献者人数的累和，A 的每个 R 包的贡献者人数相加）视为 A 的入度。维护者 A 作为开发者给多个维护者贡献，贡献次数（作为开发者给其它 R 包做贡献的次数，向外参与贡献的 R 包数目）视为 A 的出度。注意，A 作为维护者，必然包含 A 作为开发者，忽略 A 到 A 的贡献，只考虑贡献/协作关系。\n\n# 过滤重复和缺失的记录\npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package) & !is.na(`Authors@R`),\n  select = c(\"Package\", \"Maintainer\", \"Authors@R\")\n)\n# 提取维护者的名字\npdb$Maintainer &lt;- extract_maintainer(pdb$Maintainer)\n\n有些包的元数据中没有 Authors@R 字段，有可能是没有贡献者，比如 mgcv 包、gam 包等，但也有可能是有贡献者，只是维护者没有填写这个字段，比如 Rcpp 包、RcppEigen 包等，因此将这些先过滤出来。总之，本文是以 Authors@R 字段作为贡献者的来源，共计 12503 个 R 包含有 Authors@R ，有 6000+ 个 R 包没有该字段，缺失约占 R 包总数的 1/3，在不那么考虑准确性的情况下，也可以使用。Author 字段是一段没有结构的文本，相比于 Author 字段，Authors@R 字段是以 R 语言中的 person 类型为存储结构的，比较规范，因此，提取贡献者的操作比较方便。作为示例，下面提取 Matrix 包的贡献者。\n\ntmp &lt;- eval(parse(text = pdb[pdb$Package == \"Matrix\", \"Authors@R\"]))\ntmp &lt;- unlist(lapply(tmp, function(x) format(x, include = c(\"given\", \"family\"))))\n# 返回一个整洁的数据框\ntmp &lt;- data.frame(Package = \"Matrix\", Maintainer = pdb[pdb$Package == \"Matrix\", \"Maintainer\"], Authors = tmp)\n# 去掉 Authors 是 Maintainer 的记录\nsubset(tmp, subset = Maintainer != Authors)\n\n#&gt;   Package      Maintainer           Authors\n#&gt; 1  Matrix Martin Maechler     Douglas Bates\n#&gt; 3  Matrix Martin Maechler      Mikael Jagan\n#&gt; 4  Matrix Martin Maechler  Timothy A. Davis\n#&gt; 5  Matrix Martin Maechler Jens Oehlschlägel\n#&gt; 6  Matrix Martin Maechler       Jason Riedy\n#&gt; 7  Matrix Martin Maechler       R Core Team\n\n\n数据框包含 R 包（Package 字段）、及其维护者（Maintainer 字段）和贡献者（Authors 字段）。将上述过程写成一个函数，接着，将所有 R 包的贡献者提取出来，形成一个大的数据框。\n\nextract_authors &lt;- function(pkg) {\n  sub_pdb &lt;- pdb[pdb$Package == pkg, ]\n  tmp &lt;- eval(parse(text = sub_pdb[, \"Authors@R\"]))\n  tmp &lt;- unlist(lapply(tmp, function(x) format(x, include = c(\"given\", \"family\"))))\n  tmp &lt;- data.frame(Package = pkg, Maintainer = sub_pdb[, \"Maintainer\"], Authors = tmp)\n  subset(tmp, subset = Maintainer != Authors)\n}\nextract_authors(\"Matrix\")\n\n#&gt;   Package      Maintainer           Authors\n#&gt; 1  Matrix Martin Maechler     Douglas Bates\n#&gt; 3  Matrix Martin Maechler      Mikael Jagan\n#&gt; 4  Matrix Martin Maechler  Timothy A. Davis\n#&gt; 5  Matrix Martin Maechler Jens Oehlschlägel\n#&gt; 6  Matrix Martin Maechler       Jason Riedy\n#&gt; 7  Matrix Martin Maechler       R Core Team\n\n# lapply(c(\"Matrix\", \"gt\"), extract_authors)\n# 抽取所有 R 包的贡献者，运行需要1-2分钟时间\npdb_authors_list &lt;- lapply(pdb[, \"Package\"], extract_authors)\n# 合并列表\npdb_authors_dt &lt;- data.table::rbindlist(pdb_authors_list)\n\n最后整理出来的大数据框 pdb_authors_dt 含有近 26000 条记录，即边的规模大小。考虑到有些维护者和贡献者之间可能存在多次合作的情况，下面统计一下合作次数。\n\npdb_authors_dt[ ,.(cnt = length(Package)) , by = c(\"Maintainer\", \"Authors\")\n                ][cnt &gt;= 10, ][order(cnt, decreasing = T), ]\n\n#&gt;                 Maintainer               Authors   cnt\n#&gt;                     &lt;char&gt;                &lt;char&gt; &lt;int&gt;\n#&gt;  1:         Hadley Wickham               RStudio    36\n#&gt;  2:          Pablo Sanchez            Windsor.ai    25\n#&gt;  3:           Jan Wijffels                BNOSAC    24\n#&gt;  4:           Gábor Csárdi               RStudio    19\n#&gt;  5:               Hong Ooi             Microsoft    16\n#&gt;  6:               Max Kuhn               RStudio    14\n#&gt;  7:           Lionel Henry               RStudio    14\n#&gt;  8:      Robrecht Cannoodt        Wouter Saelens    13\n#&gt;  9:      Scott Chamberlain              rOpenSci    13\n#&gt; 10:            Joe Thorley    Poisson Consulting    13\n#&gt; 11:      Frederic Bertrand Myriam Maumy-Bertrand    12\n#&gt; 12:          Winston Chang               RStudio    12\n#&gt; 13:          Daniel Falbel               RStudio    12\n#&gt; 14:           David Kretch           Adam Banker    12\n#&gt; 15:           David Kretch      Amazon.com, Inc.    12\n#&gt; 16:         Victor Perrier           Fanny Meyer    11\n#&gt; 17:         Jennifer Bryan               RStudio    11\n#&gt; 18: William Michael Landau Eli Lilly and Company    11\n#&gt; 19:        Adrian Baddeley             Ege Rubak    11\n#&gt; 20:           Gábor Csárdi            Jim Hester    10\n#&gt; 21:          Kirill Müller               RStudio    10\n#&gt; 22:         Carson Sievert               RStudio    10\n#&gt; 23:    Thomas Lin Pedersen               RStudio    10\n#&gt; 24:           Lionel Henry        Hadley Wickham    10\n#&gt; 25:        Adrian Baddeley           Rolf Turner    10\n#&gt;                 Maintainer               Authors   cnt\n\n\nAuthors 字段出现了不少组织的名字，这是因为有许多 R 包的维护者受雇于该组织，版权归属于该组织，组织不仅提供持续的资金，而且还提供其它帮助。以 dplyr 包为例，Hadley Wickham 受雇于 RStudio 公司，在 dplyr 包的元数据中，字段 Authors@R 中 RStudio 的角色是 cph 和 fnd ，即版权所有和资金支持。角色 cre 就是维护者，负责与 CRAN 团队的沟通。角色 aut 就是对 R 包有实质贡献的人。\n\nformat(eval(parse(text = pdb[pdb$Package == \"dplyr\", \"Authors@R\"])),\n       include = c(\"given\", \"family\", \"role\"))\n\n#&gt; [1] \"Hadley Wickham [aut, cre]\" \"Romain François [aut]\"    \n#&gt; [3] \"Lionel Henry [aut]\"        \"Kirill Müller [aut]\"      \n#&gt; [5] \"RStudio [cph, fnd]\"\n\n\n此外，同属于一个组织的维护者之间常常合作紧密，从上面的结果可以看到，Gábor Csárdi 和 Jim Hester ，Lionel Henry 和 Hadley Wickham，Carson Sievert 和 Joe Cheng ，Jennifer Bryan 和 Hadley Wickham 等同属于 RStudio 公司，常常协作开发项目。对 RStudio、CRAN Team 和 rOpenSci 不再赘述，下面对排名靠前的其它组织略作说明。\n\n\nWindsor.ai 提供一系列可以连接各大营销平台，获取营销效果数据 R 包。\n\nBNOSAC 提供一系列计算机视觉、图像识别、自然语言处理方面的 R 包，比如 udpipe、word2vec、doc2vec 等包。\nMicrosoft 提供一系列连接和操作 Azure 云套件的 R 包，比如 AzureR 包。\n\nWouter Saelens 提供一系列单细胞轨迹推理（single-cell trajectory inference）相关的 R 包，形成一个 dynverse 家族。\n\n\nPoisson Consulting 提供一系列用于计算生物学和统计生态学的 R 包和相关研究论文。\n\nAmazon.com, Inc. 提供一系列用于存储、管理、操作等 Amazon 云服务的 R 包，形成一个 paws 套件。\n\nEli Lilly and Company 可能是 rOpenSci 的一员，赞助了旗下的 targets 和 jagstargets 等 R 包。\n\n最后，统计协作次数的分布，网络中边的权重的分布。\n\npdb_authors_net &lt;- pdb_authors_dt[, .(cnt = .N), by = c(\"Maintainer\", \"Authors\")]\ntable(pdb_authors_net$cnt)\n\n#&gt; \n#&gt;     1     2     3     4     5     6     7     8     9    10    11    12    13 \n#&gt; 20432  1511   365   121    44    28    14     8     3     6     4     5     3 \n#&gt;    14    16    19    24    25    36 \n#&gt;     2     1     1     1     1     1\n\n\n可以发现，绝大多数人之间协作只有一次。\n\n16.3.3 节点出入度分布\n下面简化这个网络，仅考虑贡献者也是维护者的情况，就是说网络中所有节点既是维护者也是贡献者，这会过滤掉组织机构、大量没有在 CRAN 发过 R 包的贡献者、从没给其它维护者做贡献的维护者。简化后，网络节点的出度、入度的分布图如下。\n# Maintainer 的入度\npdb_authors_net_indegree &lt;- pdb_authors_dt[Authors %in% Maintainer, \n  ][, .(in_degree = length(Authors)), by = \"Maintainer\"]\n# Authors 的出度\npdb_authors_net_outdegree &lt;- pdb_authors_dt[Authors %in% Maintainer, \n  ][, .(out_degree = length(Maintainer)), by = \"Authors\"]\n\nggplot(pdb_authors_net_indegree, aes(x = in_degree)) +\n  geom_histogram(binwidth = 1) +\n  geom_freqpoly(binwidth = 1) +\n  theme_classic()\nggplot(pdb_authors_net_outdegree, aes(x = out_degree)) +\n  geom_histogram(binwidth = 1) +\n  geom_freqpoly(binwidth = 1) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) 入度的分布\n\n\n\n\n\n\n\n\n\n(b) 出度的分布\n\n\n\n\n\n\n图 16.5: 节点的入度和出度的分布\n\n\n\n16.3.4 可视化协作网络\n节点的大小以维护者维护的 R 包数量来表示，边的大小以维护者之间协作次数来表示。为了美观起见，更为了突出重点，仅保留协作次数大于 1 的边。\n\n# 边\npdb_authors_net_edge &lt;- pdb_authors_dt[Authors %in% Maintainer, \n  ][, .(edge_cnt = .N), by = c(\"Authors\", \"Maintainer\")][edge_cnt &gt; 1, ]\npdb_authors_net_edge[order(edge_cnt, decreasing = TRUE),]\n\n#&gt;                      Authors            Maintainer edge_cnt\n#&gt;                       &lt;char&gt;                &lt;char&gt;    &lt;int&gt;\n#&gt;   1:              Jim Hester          Gábor Csárdi       10\n#&gt;   2:          Hadley Wickham          Lionel Henry       10\n#&gt;   3:               Joe Cheng        Carson Sievert        9\n#&gt;   4:          Hadley Wickham        Jennifer Bryan        8\n#&gt;   5: Steven Andrew Culpepper James Joseph Balamuta        8\n#&gt;  ---                                                       \n#&gt; 526:             Aaron Wolen     Scott Chamberlain        2\n#&gt; 527:               Bob Rudis         Simon Garnier        2\n#&gt; 528:           Marco Sciaini         Simon Garnier        2\n#&gt; 529:          Carlos Morales           Martin Chan        2\n#&gt; 530:               Md Yeasin     Ranjit Kumar Paul        2\n\n# 顶点\npdb_authors_net_vertex &lt;- pdb_authors_dt[, .(vertex_cnt = length(unique(Package))), by = \"Maintainer\"\n  ][Maintainer %in% c(pdb_authors_net_edge$Maintainer, pdb_authors_net_edge$Authors),]\npdb_authors_net_vertex[order(vertex_cnt, decreasing = TRUE),]\n\n#&gt;                Maintainer vertex_cnt\n#&gt;                    &lt;char&gt;      &lt;int&gt;\n#&gt;   1:       Hadley Wickham         43\n#&gt;   2:         Gábor Csárdi         33\n#&gt;   3:          Jeroen Ooms         28\n#&gt;   4:    Scott Chamberlain         28\n#&gt;   5:            Yihui Xie         21\n#&gt;  ---                                \n#&gt; 579:    Katriona Goldmann          1\n#&gt; 580:        Carlo Pacioni          1\n#&gt; 581:       Michael Scholz          1\n#&gt; 582: Javier Roca-Pardinas          1\n#&gt; 583:         Xianying Tan          1\n\n\n这是一个有向图，其各个字段含义如下。\n\nMaintainer 维护者（代表流 to）\nAuthors 贡献者（代表源 from）\n\nedge_cnt 边的大小表示维护者 Maintainer 和贡献者 Authors 的协作次数\n\nvertex_cnt 顶点大小表示维护者 Maintainer 维护的 R 包数量\n\n下面先考虑用 igraph 包可视化这个复杂的有向带权网络。pdb_authors_net_edge 和 pdb_authors_net_vertex 都是数据框，首先调用 igraph 包的函数 graph_from_data_frame() 将其转化为网络类型 igraph ，然后使用函数 plot() 绘制网络图。\n\n代码# 构造图\nlibrary(igraph)\npdb_authors_graph &lt;- graph_from_data_frame(d = pdb_authors_net_edge, vertices = pdb_authors_net_vertex, directed = TRUE)\n# 可视化\nop &lt;- par(mar = rep(0, 4))\nplot(pdb_authors_graph,\n  edge.width = (E(pdb_authors_graph)$edge_cnt) / 2,\n  edge.arrow.size = .01,\n  edge.curved = .1,\n  layout = layout.kamada.kawai,\n  vertex.size = (V(pdb_authors_graph)$vertex_cnt) / 8,\n  vertex.label.cex = sqrt(V(pdb_authors_graph)$vertex_cnt) / 8\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 16.6: 开发者的协作关系网络\n\n\n\n\n协作关系弱的开发者占大部分，构成一个「月亮」的造型，其中，不乏维护多个 R 包的开发者，这些人要么单干，要么在专业小领域、小组织内协作。与之相对应的是协作关系较强的开发者，人数虽少，影响力却大，构成一个「太阳」的造型。协作得多往往意味着维护的 R 包也不少，甚至同属于一个组织，因此，高产的开发者、影响力大的组织聚集在一起，如 R Core Team、RStudio、rOpenSci 等。\n\neb &lt;- cluster_edge_betweenness(pdb_authors_graph)\neb\n\n#&gt; IGRAPH clustering edge betweenness, groups: 181, mod: 0.88\n#&gt; + groups:\n#&gt;   $`1`\n#&gt;   [1] \"Matt Nunes\"           \"Daniel Grose\"         \"Guy Nason\"           \n#&gt;   [4] \"Rebecca Killick\"      \"Idris Eckley\"         \"Alessandro Cardinali\"\n#&gt;   \n#&gt;   $`2`\n#&gt;   [1] \"Jin Zhu\"    \"Shiyun Lin\"\n#&gt;   \n#&gt;   $`3`\n#&gt;    [1] \"Julio Trecenti\"       \"Henrik Bengtsson\"     \"Morgane Pierre-Jean\" \n#&gt;    [4] \"Zhian N. Kamvar\"      \"Pierre Neuvial\"       \"Michal Bojanowski\"   \n#&gt;   + ... omitted several groups/vertices\n\n\nigraph 包提供多种社区探测的算法，上面简单使用函数 cluster_edge_betweenness() 来探测，结果显示有 181 个社区。社区 1 包含的成员如下：\n\neb$names[eb$membership == 1]\n\n#&gt; [1] \"Matt Nunes\"           \"Daniel Grose\"         \"Guy Nason\"           \n#&gt; [4] \"Rebecca Killick\"      \"Idris Eckley\"         \"Alessandro Cardinali\"\n\n\n社区 3、14、21、34、46、52、75 的成员是比较多的。其中，社区 3 是以 RStudio 为核心的大社区，社区 14 是以 CRAN 为核心的大社区。\n\n# RStudio 为核心的大社区\neb$names[eb$membership == 3]\n\n#&gt;  [1] \"Julio Trecenti\"       \"Henrik Bengtsson\"     \"Morgane Pierre-Jean\" \n#&gt;  [4] \"Zhian N. Kamvar\"      \"Pierre Neuvial\"       \"Michal Bojanowski\"   \n#&gt;  [7] \"Ian Lyttle\"           \"Thomas Lin Pedersen\"  \"Yihui Xie\"           \n#&gt; [10] \"Dirk Schumacher\"      \"Jeroen Ooms\"          \"Gábor Csárdi\"        \n#&gt; [13] \"Sean Kross\"           \"Carl Boettiger\"       \"Neal Richardson\"     \n#&gt; [16] \"Ryan Hafen\"           \"Matthew Fidler\"       \"Hadley Wickham\"      \n#&gt; [19] \"Mark Edmondson\"       \"Kirill Müller\"        \"Richard Iannone\"     \n#&gt; [22] \"Carson Sievert\"       \"Winston Chang\"        \"Lionel Henry\"        \n#&gt; [25] \"Jennifer Bryan\"       \"Michael Sumner\"       \"Scott Chamberlain\"   \n#&gt; [28] \"Garrick Aden-Buie\"    \"Daniel Falbel\"        \"Matthew B. Jones\"    \n#&gt; [31] \"Hiroaki Yutani\"       \"Taiyun Wei\"           \"Jim Hester\"          \n#&gt; [34] \"Romain François\"      \"Greg Freedman Ellis\"  \"Rhian Davies\"        \n#&gt; [37] \"Bryce Mecum\"          \"Steph Locke\"          \"Christophe Dervieux\" \n#&gt; [40] \"Jonathan Keane\"       \"Thibaut Jombart\"      \"Dewey Dunnington\"    \n#&gt; [43] \"Anne Cori\"            \"Bill Denney\"          \"Jared Huling\"        \n#&gt; [46] \"Wush Wu\"              \"Atsushi Yasumoto\"     \"Barret Schloerke\"    \n#&gt; [49] \"Yuan Tang\"            \"Duncan Garmonsway\"    \"Edzer Pebesma\"       \n#&gt; [52] \"Sebastian Meyer\"      \"Derek Burk\"           \"Tim Taylor\"          \n#&gt; [55] \"Alicia Schep\"         \"Tomasz Kalinowski\"    \"Michael Rustler\"     \n#&gt; [58] \"Joe Cheng\"            \"Bhaskar Karambelkar\"  \"Sebastian Kreutzer\"  \n#&gt; [61] \"JJ Allaire\"           \"JooYoung Seo\"         \"Zachary Foster\"      \n#&gt; [64] \"Malcolm Barrett\"      \"Aaron Wolen\"          \"Bruno Tremblay\"      \n#&gt; [67] \"Justin Wilkins\"       \"Yixuan Qiu\"           \"Johannes Friedrich\"  \n#&gt; [70] \"Kevin Ushey\"          \"Steven M. Mortimer\"   \"Karthik Ram\"         \n#&gt; [73] \"Jorrit Poelen\"        \"Maëlle Salmon\"        \"Aron Atkins\"         \n#&gt; [76] \"Ramnath Vaidyanathan\" \"Thomas Leeper\"        \"Dirk Eddelbuettel\"   \n#&gt; [79] \"Xianying Tan\"\n\n# CRAN 为核心的大社区\neb$names[eb$membership == 14]\n\n#&gt;  [1] \"Achim Zeileis\"        \"Michael Hahsler\"      \"Michel Lang\"         \n#&gt;  [4] \"Nikolaus Umlauf\"      \"Vincent Dorie\"        \"Bettina Gruen\"       \n#&gt;  [7] \"Bernd Bischl\"         \"Ben Bolker\"           \"Marc Becker\"         \n#&gt; [10] \"Friedrich Leisch\"     \"Brian Ripley\"         \"Michael Friendly\"    \n#&gt; [13] \"John Fox\"             \"Kurt Hornik\"          \"Patrick Schratz\"     \n#&gt; [16] \"Volodymyr Melnykov\"   \"Martin Maechler\"      \"George Ostrouchov\"   \n#&gt; [19] \"Drew Schmidt\"         \"Georgi N. Boshnakov\"  \"Wei-Chen Chen\"       \n#&gt; [22] \"Stefan Theussl\"       \"David Meyer\"          \"Jakob Bossek\"        \n#&gt; [25] \"Francois Michonneau\"  \"Marius Hofert\"        \"Florian Schwendinger\"\n#&gt; [28] \"Felix Zimmer\"         \"Martin Binder\"        \"Phil Chalmers\"       \n#&gt; [31] \"Lukas Sablica\"        \"Sebastian Fischer\"    \"Lennart Schneider\"   \n#&gt; [34] \"Jakob Richter\"        \"Florian Wickelmaier\"  \"Rudolf Debelak\"      \n#&gt; [37] \"Duncan Murdoch\"       \"Alexander Brenning\"   \"Ingo Feinerer\"\n\n\n同时，在 RStudio 这个大社区下，有一些与之紧密相关的小社区，比如 Rob Hyndman 等人的时间序列社区、Roger Bivand 等人的空间统计社区。\n\n# 时间序列 Rob Hyndman\neb$names[eb$membership == 52]\n\n#&gt;  [1] \"Asael Alonzo Matamoros\"   \"Nicholas Tierney\"        \n#&gt;  [3] \"Sevvandi Kandanaarachchi\" \"Rob Hyndman\"             \n#&gt;  [5] \"Di Cook\"                  \"Mitchell O'Hara-Wild\"    \n#&gt;  [7] \"Han Lin Shang\"            \"Sayani Gupta\"            \n#&gt;  [9] \"Earo Wang\"                \"Christoph Bergmeir\"\n\n# 空间统计 Roger Bivand\neb$names[eb$membership == 75]\n\n#&gt; [1] \"Sebastian Jeworutzki\" \"Roger Bivand\"         \"Colin Rundel\"        \n#&gt; [4] \"Angela Li\"            \"Gianfranco Piras\"     \"Patrick Giraudoux\"   \n#&gt; [7] \"Giovanni Millo\"\n\n\n结合前面的 图 16.6 ，知道有很多小圈圈，这些放一边，重点关注那些大的圈圈，见下图。\n\n代码op &lt;- par(mar = rep(0, 4))\nplot(eb, pdb_authors_graph,\n  edge.width = (E(pdb_authors_graph)$edge_cnt) / 4,\n  edge.arrow.size = .01,\n  edge.curved = .1,\n  layout = layout.kamada.kawai,\n  vertex.size = (V(pdb_authors_graph)$vertex_cnt) / 8,\n  vertex.label.cex = sqrt(V(pdb_authors_graph)$vertex_cnt) / 8\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 16.7: 探测协作关系网络中的社区\n\n\n\n\n下面使用 tidygraph 包构造图数据、计算节点中心度，dplyr 包操作数据。中心度代表节点（开发者）的影响力（或者重要性）。最后，借助 ggraph 包绘制维护者之间的贡献网络，节点的大小代表维护者影响力的强弱。\n\n代码pdb_authors_g &lt;- tidygraph::as_tbl_graph(pdb_authors_net_edge, directed = T) |&gt; \n dplyr::mutate(Popularity = tidygraph::centrality_degree(mode = 'in'))\nlibrary(ggraph)\nggraph(pdb_authors_g, layout = \"kk\") +\n  geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) +\n  geom_node_point(aes(size = Popularity), alpha = 0.5) +\n  theme_graph(base_family = \"sans\")\n\n\n\n\n\n\n图 16.8: 开发者的影响力网络\n\n\n\n\n前面两个网络图基于同一份数据、同样的网络布局算法，得到非常类似的结果。静态图上的标签相互重叠，影响细节的观察和探索，比如连接 CRAN 和 RStudio 两大阵营的通道。下面使用 visNetwork 包制作交互式网络图形，它是 JS 库 vis-network 的 R 语言接口， 使用 visNetwork 包绘制交互式网络图后，可以在图上使用鼠标放大、拖拽。可以发现在 CRAN 社区的 Achim Zeileis 和 RStudio 社区的 Max Kuhn 之间是由 Andri Signorell 牵线搭桥。此外，读者若有兴趣，可以使用 Richard Iannone 开发的 DiagrammeR 包制作静态的矢量网页图形。\n\n代码library(visNetwork)\n# 将 igraph 对象转为 visNetwork 包可用的数据\ndat &lt;- toVisNetworkData(pdb_authors_graph)\nnodes_df &lt;- dat$nodes\nnodes_df$value &lt;- nodes_df$vertex_cnt\nedges_df &lt;- dat$edges\nedges_df$value &lt;- edges_df$edge_cnt\n# 输入节点和边的数据\nvisNetwork(nodes = nodes_df, edges = edges_df, height = \"600px\") |&gt; \n  visIgraphLayout(randomSeed = 20232023, layout = \"layout.kamada.kawai\")\n\n\n\n\n\n\n图 16.9: 开发者的影响力网络（visNetwork）",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#扩展阅读",
    "href": "analyze-network-data.html#扩展阅读",
    "title": "16  网络数据分析",
    "section": "\n16.4 扩展阅读",
    "text": "16.4 扩展阅读\nR 语言网络分析方面的著作有 Erick Kolaczyk 的书籍《Statistical Analysis of Network Data with R》(Kolaczyk 和 Csárdi 2020)，网络可视化方面，推荐 Hadley Wickham 的著作《ggplot2: Elegant Graphics for Data Analysis》(Wickham, Navarro, 和 Pedersen 2024) 的第七章，Sam Tyner 等人的文章《Network Visualization with ggplot2》(Tyner, Briatte, 和 Hofmann 2017) 也值得一看。\n在网络数据分析方面， igraph 是非常流行的分析框架 ，它是由 C 语言写成的，非常高效。同时，它提供多种语言的接口，其 R 语言接口 igraph 包在 R 语言社区也是网络数据分析的事实标准，被很多其它做网络分析的 R 包所引用。开源的 Gephi 软件适合处理中等规模的网络分析和可视化。大规模图计算可以用 Apache Spark 的 GraphX。R 语言这层，主要还是对应数据分析和数据产品，用在内部咨询和商业分析上。\n企业级的图存储和计算框架，比较有名的是 Neo4j ，它有开源版本和商业版本。Nebula Graph 开源分布式图数据库，具有高扩展性和高可用性，支持千亿节点、万亿条边、毫秒级查询，有中文文档，有企业应用案例（美团图数据库平台建设及业务实践）。阿里研发的 GraphScope 提供一站式大规模图计算系统，支持图神经网络计算。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-analysis-network-data-exercise",
    "href": "analyze-network-data.html#sec-analysis-network-data-exercise",
    "title": "16  网络数据分析",
    "section": "\n16.5 习题",
    "text": "16.5 习题\n\n类似开发者协作关系的分析，可以统计 R 包被多少 R 包依赖，依赖数量的分布。统计 R 包被依赖的深度（若 R 包 A 被 R 包 B 依赖，R 包 B 被 R 包 C 依赖，以此类推）。进而，构建、分析、可视化依赖关系网络，分析 R 包的影响力。\n本文基于 2022 年 12 月 31 日的 R 包元数据进行分析，请与 2023 年 12 月 31 日的数据比较。\n\n\n\n\n\nBates, Douglas, 和 Dirk Eddelbuettel. 2013. 《Fast and Elegant Numerical Linear Algebra Using the RcppEigen Package》. Journal of Statistical Software 52 (5): 1–24. https://doi.org/10.18637/jss.v052.i05.\n\n\nBiecek, Przemyslaw. 2023. DrWhy: Explain, Explore and Debug Predictive Machine Learning Models. https://github.com/ModelOriented/DrWhy.\n\n\nKolaczyk, Eric D., 和 Gábor Csárdi. 2020. Statistical Analysis of Network Data with R. 2nd 本. Springer, New York, NY. https://doi.org/10.1007/978-3-030-44129-6.\n\n\nKuhn, Max, 和 Hadley Wickham. 2020. Tidymodels: a collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org.\n\n\nLang, Michel, 和 Patrick Schratz. 2023. mlr3verse: Easily Install and Load the mlr3 Package Family. https://CRAN.R-project.org/package=mlr3verse.\n\n\nLüdecke, Daniel. 2019. strengejacke: Load Packages Associated with Strenge Jacke! https://github.com/strengejacke/strengejacke.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Brenton M. Wiernik, Etienne Bacher, Rémi Thériault, 和 Dominique Makowski. 2022. 《easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting》. CRAN. https://easystats.github.io/easystats/.\n\n\nTyner, Sam, François Briatte, 和 Heike Hofmann. 2017. 《Network Visualization with ggplot2》. The R Journal 9 (1): 27–59. https://doi.org/10.32614/RJ-2017-023.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, 等. 2019. 《Welcome to the tidyverse》. Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Danielle Navarro, 和 Thomas Lin Pedersen. 2024. ggplot2: Elegant Graphics for Data Analysis. 3rd 本. Springer-Verlag New York. https://ggplot2-book.org/.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html",
    "href": "analyze-text-data.html",
    "title": "17  文本数据分析",
    "section": "",
    "text": "17.1 数据获取\n下载益辉的日志数据\n经过整理后，打包成 Rdata 数据供 R 软件使用。\n# 加载益辉的日志数据\nload(file = \"data/text/yihui.Rdata\")",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#数据获取",
    "href": "analyze-text-data.html#数据获取",
    "title": "17  文本数据分析",
    "section": "",
    "text": "总体规模：益辉每年的日志数量、日志平均字数，益辉发布书籍的年份\n过程细节：发布时间、日志字数的日历图、日志年度主题\n\n\ngit clone git@github.com:yihui/yihui.org.git",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-cn-blog",
    "href": "analyze-text-data.html#sec-cn-blog",
    "title": "17  文本数据分析",
    "section": "\n17.2 日志概况",
    "text": "17.2 日志概况\n\n代码library(ggplot2)\nlibrary(ggrepel)\nggplot() +\n  geom_label_repel(\n    data = df2, aes(x = year, y = file_name, label = event_wrap),\n    max.overlaps = 150, segment.colour = \"gray\", seed = 2023\n  ) +\n  geom_point(data = df1, aes(x = file_year, y = file_name)) +\n  geom_line(data = df1, aes(x = file_year, y = file_name)) +\n  scale_x_continuous(n.breaks = 15) +\n  theme_bw() +\n  labs(x = \"年份\", y = \"篇数\")\n\n\n\n\n\n\n图 17.1: 益辉每年发布的日志数量\n\n\n\n\n2006 年获得中国人民大学学士学位，2009 和 2013 年分别获得中国人民大学硕士和爱荷华州立大学博士学位，在校期间，日志数量持续增加，又陆续创立统计之都，举办中国 R 语言大会。在毕业那年需要完成毕业论文，因此，日志数量明显减少。2013 -2016 年，每年都有书籍出版，期间，有博士毕业、找工作、安家等重要事情，因此，日志数量持续处于低位。稳定后，2017-2018 年除了正常出两本书以外，写了大量的日志，迎来第二个高峰，2018 年，中英文日志数量超过 300 篇。2019-2020 年集中精力在写一本食谱。2021 年第一本中文书《现代统计图形》在10年后出版，这主要是 2007-2011 年的工作。2021-2023 年日志数量（2023年中文日志未发布）处于较低水平。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-text-clean",
    "href": "analyze-text-data.html#sec-text-clean",
    "title": "17  文本数据分析",
    "section": "\n17.3 数据清洗",
    "text": "17.3 数据清洗\n以 2001 年的一篇日志为例，展开数据清洗的过程。移除文章的 YAML 元数据，对于文本分析来说，主要是没啥信息含量。\n\nremove_yaml &lt;- function(x) {\n  x[(max(which(x == \"---\")) + 1):length(x)]\n}\nx &lt;- remove_yaml(x)\n\n移除「我」 「是」 「你」 「的」 「了」 「也」 等高频的人称、助词、虚词。这些词出现的规律对表现个人风格很重要，且看红楼梦关于后40回作者归属的研究，通过比较一些助词、虚词的出现规律，从而看出作者的习惯、文风。这种东西是在长期的潜移默化中形成的，对作者自己来说，都可能是无意识的。\n\nlibrary(jiebaR)\n# jieba_seg &lt;- worker(stop_word = \"data/text/stop_word.txt\")\njieba_seg &lt;- worker(stop_word = \"data/text/cn_stopwords.txt\")\n\n添加新词，比如「歪贼」、「谢益辉」等，主要是人名、外号等实体。\n\nnew_words &lt;- readLines(file(\"data/text/new_word.txt\"))\nnew_user_word(worker = jieba_seg, words = new_words)\n\n#&gt; [1] TRUE\n\n# 分词\nx_seg &lt;- segment(x, jieba_seg)\n\n分词后，再移除数字和英文\n\nremove_number_english &lt;- function(x) {\n  x &lt;- x[!grepl(\"\\\\d{1,}\", x)]\n  x[!grepl(\"[a-zA-Z]\", x)]\n}\nxx &lt;- remove_number_english(x = x_seg)\n\n词频统计\n\ntmp &lt;- freq(x = xx)\ntmp &lt;- tmp[order(tmp$freq, decreasing = T), ]\nhead(tmp)\n\n#&gt;       char freq\n#&gt; 166   一个    7\n#&gt; 238   同学    5\n#&gt; 187   没有    4\n#&gt; 195   一篇    4\n#&gt; 20    鼻音    3\n#&gt; 69  田春雨    3\n\n\nggwordcloud 包绘制词云图可视化词频统计的结果。\n\nlibrary(ggwordcloud)\nhead(tmp, 150) |&gt;\n  ggplot(aes(label = char, size = freq)) +\n  geom_text_wordcloud(seed = 2022, grid_size = 8, max_grid_size = 24) +\n  scale_size_area(max_size = 10)\n\n\n\n\n\n\n图 17.2: 词云可视化词频结果\n\n\n\n\n计算 TF-IDF 值\n\n# tmp = get_idf(x = list(xx))\nget_idf(x = list(xx)) |&gt; head()\n\n#&gt;     name count\n#&gt; 1   杨迪     0\n#&gt; 2   邹瑜     0\n#&gt; 3 蒋前程     0\n#&gt; 4 朱菁菁     0\n#&gt; 5   杨刚     0\n#&gt; 6   邓璋     0",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-topic-models",
    "href": "analyze-text-data.html#sec-topic-models",
    "title": "17  文本数据分析",
    "section": "\n17.4 主题的探索",
    "text": "17.4 主题的探索\n益辉的日志是没有分类和标签的，所以，先聚类，接着逐个分析每个类代表的实际含义。然后，将聚类的结果作为结果标签，再应用多分类回归模型，最后联合聚类、分类模型，从无监督转化到有监督模型。\ntopicmodels (Grün 和 Hornik 2011) 基于 tm (Feinerer, Hornik, 和 Meyer 2008) 支持潜在狄利克雷分配（Latent Dirichlet Allocation，简称 LDA） 和 Correlated Topics Models (CTM) 文本主题建模，这一套工具比较适合英文文本分词、向量化和建模。text2vec 包支持多个统计模型，如LDA 、LSA 、GloVe 等，文本向量化后，结合统计学习模型，可用于分类、回归、聚类等任务，更多详情见 https://text2vec.org。\n接下来使用 David M. Blei 等提出 LDA 算法做主题建模，详情见 LDA 算法原始论文。\n\nlibrary(text2vec)\n\n首先将所有日志分词、向量化，构建文档-词矩阵 document-term matrix (DTM)\n\n# 移除链接\nremove_links &lt;- function(x) {\n  gsub(pattern = \"(&lt;http.*?&gt;)|(\\\\(http.*?\\\\))|(&lt;www.*?&gt;)|(\\\\(www.*?&gt;\\\\))\", replacement = \"\", x)\n}\n# 清理、分词、清理\nfile_list1 &lt;- lapply(file_list, remove_yaml)\nfile_list1 &lt;- lapply(file_list1, remove_links)\nfile_list1 &lt;- lapply(file_list1, segment, jiebar = jieba_seg)\nfile_list1 &lt;- lapply(file_list1, remove_number_english)\n\n去掉没啥实际意义的词（比如单个字），极高频词和极低频词。\n\n# Token 化\nit &lt;- itoken(file_list1, ids = 1:length(file_list1), progressbar = FALSE)\nv &lt;- create_vocabulary(it)\n# 去掉单个字 减少 3K\nv &lt;- v[nchar(v$term) &gt; 1,]\n# 去掉极高频词和极低频词 减少 1.4W\nv &lt;- prune_vocabulary(v, term_count_min = 10, doc_proportion_max = 0.2)\n\n采用 LDA（Latent Dirichlet Allocation）算法建模\n\n# 词向量化\nvectorizer &lt;- vocab_vectorizer(v)\n# 文档-词矩阵 DTM\ndtm &lt;- create_dtm(it, vectorizer, type = \"dgTMatrix\")\n#  10 个主题\nlda_model &lt;- LDA$new(n_topics = 9, doc_topic_prior = 0.1, topic_word_prior = 0.01)\n# 训练模型\ndoc_topic_distr &lt;- lda_model$fit_transform(\n    x = dtm, n_iter = 1000, convergence_tol = 0.001, \n    n_check_convergence = 25, progressbar = FALSE\n  )\n\n#&gt; INFO  [15:28:26.129] early stopping at 175 iteration\n#&gt; INFO  [15:28:26.608] early stopping at 50 iteration\n\n\n下图展示主题的分布，各个主题及其所占比例。\n\nbarplot(\n  doc_topic_distr[1, ], xlab = \"主题\", ylab = \"比例\", \n  ylim = c(0, 1), names.arg = 1:ncol(doc_topic_distr)\n)\n\n\n\n\n\n\n图 17.3: 主题分布\n\n\n\n\n将 9 个主题的 Top 12 词分别打印出来。\n\nlda_model$get_top_words(n = 12, topic_number = 1L:9L, lambda = 0.3)\n\n#&gt;       [,1]   [,2]   [,3]   [,4]     [,5]   [,6]   [,7]   [,8]   [,9]    \n#&gt;  [1,] \"例子\" \"一首\" \"社会\" \"统计\"   \"代码\" \"记得\" \"吱吱\" \"时代\" \"网站\"  \n#&gt;  [2,] \"翻译\" \"歌词\" \"观点\" \"会议\"   \"函数\" \"不知\" \"照片\" \"意义\" \"数据\"  \n#&gt;  [3,] \"字符\" \"手机\" \"痛苦\" \"模型\"   \"文档\" \"同学\" \"好吃\" \"媒体\" \"图形\"  \n#&gt;  [4,] \"特征\" \"这首\" \"教育\" \"论文\"   \"文件\" \"阿姨\" \"我家\" \"文化\" \"域名\"  \n#&gt;  [5,] \"作品\" \"首歌\" \"人类\" \"老师\"   \"变量\" \"居然\" \"家里\" \"现实\" \"软件\"  \n#&gt;  [6,] \"中文\" \"遗憾\" \"追求\" \"分布\"   \"字体\" \"看见\" \"味道\" \"社交\" \"服务器\"\n#&gt;  [7,] \"排版\" \"艺术\" \"思考\" \"小子\"   \"元素\" \"学校\" \"厨房\" \"社区\" \"邮件\"  \n#&gt;  [8,] \"意思\" \"小说\" \"强烈\" \"统计学\" \"语法\" \"路上\" \"在家\" \"眼中\" \"提供\"  \n#&gt;  [9,] \"风格\" \"生活\" \"成功\" \"参加\"   \"编译\" \"听说\" \"黄瓜\" \"避免\" \"编辑\"  \n#&gt; [10,] \"主题\" \"诗词\" \"接受\" \"报告\"   \"图片\" \"印象\" \"包子\" \"造成\" \"系统\"  \n#&gt; [11,] \"伟大\" \"鸡蛋\" \"工作\" \"检验\"   \"参数\" \"当时\" \"叶子\" \"事实\" \"浏览器\"\n#&gt; [12,] \"表示\" \"人间\" \"努力\" \"学生\"   \"生成\" \"名字\" \"辣椒\" \"政治\" \"注册\"\n\n\n结果有点意思，说明益辉喜欢读书写作（主题 1、3、8）、诗词歌赋（主题 2）、统计图形（主题 4）、代码编程（主题 5）、回忆青春（主题 6）、做菜吃饭（7）、倒腾网站（主题 9）。\n\n\n\n\n\n\n注释\n\n\n\n提示：参考论文 (Zhang, Li, 和 Zhang 2023) 根据 perplexities 做交叉验证选择最合适的主题数量。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-similarity",
    "href": "analyze-text-data.html#sec-similarity",
    "title": "17  文本数据分析",
    "section": "\n17.5 相似性度量",
    "text": "17.5 相似性度量\n我与益辉日志的相似性度量",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-analysis-text-data-exercises",
    "href": "analyze-text-data.html#sec-analysis-text-data-exercises",
    "title": "17  文本数据分析",
    "section": "\n17.6 习题",
    "text": "17.6 习题\n\ntext2vec 包内置的电影评论数据集 movie_review 中 sentiment（表示正面或负面评价）列作为响应变量，构建二分类模型，对用户的一段评论分类。（提示：词向量化后，采用 glmnet 包做交叉验证调整参数、模型）\n根据 CRAN 上发布的 R 包元数据分析 R 包的描述字段，实现 R 包主题分类。\n接习题 2，根据任务视图对 R 包的标记，建立有监督的多分类模型，评估模型的分类效果，并对尚未标记的 R 包分类。（提示：一个 R 包可能同时属于多个任务视图，考虑使用 xgboost 包）\n\n\n\n\n\nFeinerer, Ingo, Kurt Hornik, 和 David Meyer. 2008. 《Text Mining Infrastructure in R》. Journal of Statistical Software 25 (5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nGrün, Bettina, 和 Kurt Hornik. 2011. 《topicmodels: An R Package for Fitting Topic Models》. Journal of Statistical Software 40 (13): 1–30. https://doi.org/10.18637/jss.v040.i13.\n\n\nHvitfeldt, Emil, 和 Julia Silge. 2021. Supervised Machine Learning for Text Analysis in R. New York: Chapman; Hall/CRC. https://smltar.com/.\n\n\nSilge, Julia, 和 David Robinson. 2017. Text Mining with R. New York: O’Reilly Media, Inc. https://www.tidytextmining.com/.\n\n\nZhang, Lijin, Xueyang Li, 和 Zhiyong Zhang. 2023. 《Variety and Mainstays of the R Developer Community》. The R Journal 15: 5–25. https://doi.org/10.32614/RJ-2023-060.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html",
    "href": "analyze-time-series-data.html",
    "title": "18  时序数据分析",
    "section": "",
    "text": "18.1 数据获取\nJoshua M. Ulrich 开发维护的 quantmod 包可以下载国内外股票市场的数据。本节主要以美团股价数据为例，美团自 2018-09-20 在香港挂牌上市，股票代码 3690.HK。首先用 quantmod 包 (Ryan 和 Ulrich 2022) 获取美团上市至 2023-11-24 每天的股价数据，包含 Open 开盘价、High 最高价、Low 最低价、Close 闭市价、Adjusted 调整价和 Volume 成交量数据。\nlibrary(quantmod)\n# 美团股票代码 3690\nmeituan &lt;- getSymbols(\"3690.HK\", auto.assign = FALSE, src = \"yahoo\")\n先来看数据的类型，数据类型颇为复杂，是由 xts 和 zoo 两种类型复合而成，xts 类型是继承自 zoo 类型的。\nclass(meituan)\n\n[1] \"xts\" \"zoo\"\n\nstr(meituan)\n\nAn xts object on 2018-09-20 / 2023-11-24 containing: \n  Data:    double [1275, 6]\n  Columns: 3690.HK.Open, 3690.HK.High, 3690.HK.Low, 3690.HK.Close, 3690.HK.Volume ... with 1 more column\n  Index:   Date [1275] (TZ: \"UTC\")\n  xts Attributes:\n    $ src    : chr \"yahoo\"\n    $ updated: POSIXct[1:1], format: \"2023-11-27 06:31:12\"\n数据集 meituan 是一个 xts 类型的时间序列数据对象，时间范围是 2018-09-20 至 2023-11-24，包含 4 个成分，分别如下\n与时间序列数据相关的数据类型有很多，比如 Base R 提供的 Date 和 POSIX 等，扩展包 timeDate 和 chron 也都有自己的一套数据类型及处理方法。xts 包是处理时间序列数据的主要工具之一，xts 是 eXtensible Time Series 的缩写。为了进一步了解用法，下面举个例子，使用该 R 包的函数 xts() 构造时间序列对象。\nlibrary(zoo)\nlibrary(xts)\n# 数据矩阵\nx &lt;- matrix(1:4, ncol = 2, nrow = 2)\n# 日期索引\nidx &lt;- as.Date(c(\"2018-01-01\", \"2019-12-12\"))\n# xts = matrix + index\nxts(x, order.by = idx)\n\n           [,1] [,2]\n2018-01-01    1    3\n2019-12-12    2    4",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#数据获取",
    "href": "analyze-time-series-data.html#数据获取",
    "title": "18  时序数据分析",
    "section": "",
    "text": "Data 部分显示为 906 行 6 列的双精度浮点存储的数值。\nColumns 部分显示列名，依次是 3690.HK.Open、3690.HK.High、 3690.HK.Low 和 3690.HK.Close 等，当列数很多时，显示时会省略。\nIndex 部分表示索引列，有序是时间序列数据的本质特点。示例中索引存储数据点产生的先后顺序，索引是用日期来表示的，日期所在的时区是 “UTC”。\nxts 部分是数据类型的一些属性（元数据），说明数据集的来源，什么时候制作的数据。示例中数据是从雅虎财经下载的，下载时间是 2023-11-27 14:31:12。\n\n\nxts(x = NULL,\n    order.by = index(x),\n    frequency = NULL,\n    unique = TRUE,\n    tzone = Sys.getenv(\"TZ\"),\n    ...)\n\n参数 x 表示数据。\n参数 order.by 表示索引数据。\n参数 frequency 表示频率。\n参数 unique 表示唯一。\n参数 tzone 表示时区。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#数据探索",
    "href": "analyze-time-series-data.html#数据探索",
    "title": "18  时序数据分析",
    "section": "\n18.2 数据探索",
    "text": "18.2 数据探索\n\n18.2.1 zoo\nzoo 包提供 S3 范型函数 autoplot.zoo() 专门可视化 zoo 类型的数据，它接受一个 zoo 类型的数据对象，返回一个 ggplot2 数据对象，然后用户可以添加自定义的绘图设置，更多详情见帮助文档 ?autoplot.zoo() 。\n\n# xts 包需要先加载，否则 Index 不是日期类型而是数值类型\nlibrary(ggplot2)\nautoplot(meituan[, \"3690.HK.Adjusted\"]) +\n  theme_classic() +\n  labs(x = \"日期\", y = \"股价\")\n\n\n\n\n\n\n图 18.1: 美团在香港上市以来的股价走势\n\n\n\n\nzoo 包还提供另一个范型函数 fortify() 将 zoo 数据对象转化为 data.frame ，这可以方便使用 ggplot2 包来展示数据。参数 melt = TRUE 意味着重塑原数据集，将数据从宽格式转长格式。参数 names = c(Index = \"Date\") 表示将 Index 列重命名为 date 列。\n\nmeituan_df &lt;- fortify(\n  meituan[, c(\"3690.HK.Adjusted\", \"3690.HK.High\")],\n  melt = TRUE, names = c(Index = \"Date\")\n)\n\n数据集 meituan_df 中的 Series 列是因子型的，将其标签 3690.HK.Adjusted 、3690.HK.High 调整为调整价、最高价。根据日期字段 Date 提取年份字段 year 和一年中的第几天的字段 day_of_year。\n\nmeituan_df &lt;- within(meituan_df, {\n  # 调整 Series 的标签\n  Series &lt;- factor(Series, labels = c(\"调整价\", \"最高价\"))\n  # 日期字段 Date 获取年份\n  year &lt;- format(Date, \"%Y\")\n  # 日期字段 Date 一年中的第几天\n  day_of_year &lt;- as.integer(format(Date, \"%j\"))\n})\n\n调用 ggplot2 包绘制分面、分组时间序列图，以 day_of_year 为横轴，股价 Value 为纵轴，按 year 分组，按 Series 分面。\n\nggplot(data = meituan_df, aes(x = day_of_year, y = Value)) +\n  geom_line(aes(color = year)) +\n  facet_wrap(~Series, ncol = 1) + \n  theme_classic() +\n  labs(x = \"一年中的第几天\", y = \"调整的股价\", color = \"年份\")\n\n\n\n\n\n\n图 18.2: 美团调整的股价逐年走势\n\n\n\n\n2019 年底开始出现疫情，2020 年整年陆续有疫情，美团股价一路狂飙突进，因疫情，利好外卖业务，市场看好外卖业务。2021 年政府去杠杆，互联网监管趋严，又监又管，受外部大环境，逆全球化趋势影响，整年股价一路走低。进入 2022 年，股价在 200 附近徘徊。\n\n18.2.2 xts\n\nlibrary(xts)\n\nxts 包提供 S3 泛型函数 plot.xts() 专门用来可视化 xts 类型的时间序列数据\n\nplot(meituan[, \"3690.HK.Adjusted\"], main = \"调整的股价\")\n\n\n\n\n\n\n图 18.3: 美团在香港上市以来的股价走势\n\n\n\n\n还可以任意选择一个时间窗口，展示相关数据\n\nplot(meituan[, \"3690.HK.Adjusted\"],\n  subset = \"2022-01-01/2022-12-31\", main = \"调整的股价\"\n)\n\n\n\n\n\n\n图 18.4: 美团 2021 年的股价走势\n\n\n\n\n元旦节三天不开市，所以假期没有数据。\n\n18.2.3 ggfortify\nggfortify (Tang, Horikoshi, 和 Li 2016) 支持快速地可视化 ts、timeSeries 、stl 等多种类型的时序数据， ggplot2 做数据探索会有一些帮助。\n\nlibrary(ggfortify)\nautoplot(meituan[, \"3690.HK.Adjusted\"], ts.geom = \"line\") +\n  scale_x_date(\n    date_breaks = \"1 year\",\n    date_minor_breaks = \"6 months\",\n    date_labels = \"%b\\n%Y\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n图 18.5: 美团股价走势\n\n\n\n\n\n18.2.4 dygraphs\ndygraphs 包专门绘制交互式时间序列图形，它封装了时序数据可视化库 dygraphs ，更多情况见 https://dygraphs.com/。下面以美团股价为例，展示时间窗口筛选、坐标轴名称、刻度标签、注释、事件标注、缩放等功能。\n\nlibrary(dygraphs)\n# 缩放\ndyUnzoom &lt;- function(dygraph) {\n  dyPlugin(\n    dygraph = dygraph,\n    name = \"Unzoom\",\n    path = system.file(\"plugins/unzoom.js\", package = \"dygraphs\")\n  )\n}\n\n# 年月\ngetYearMonth &lt;- '\n  function(d) {\n    var monthNames = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\",\"07\", \"08\", \"09\", \"10\", \"11\", \"12\"];\n    date = new Date(d);\n    return date.getFullYear() + \"-\" + monthNames[date.getMonth()]; \n  }'\n\n# 绘图\ndygraph(meituan[, \"3690.HK.Adjusted\"], main = \"美团股价走势\") |&gt;\n  dyRangeSelector(dateWindow = c(\"2023-01-01\", \"2023-11-24\")) |&gt;\n  dyAxis(name = \"x\", axisLabelFormatter = getYearMonth) |&gt;\n  dyAxis(\"y\", valueRange = c(0, 500), label = \"美团股价\") |&gt;\n  dyEvent(\"2020-01-23\", \"武汉封城\", labelLoc = \"bottom\") |&gt;\n  dyShading(from = \"2020-01-23\", to = \"2020-04-08\", color = \"#FFE6E6\") |&gt;\n  dyAnnotation(\"2020-01-23\", text = \"武汉封城\", tooltip = \"武汉封城\", width = 60) |&gt;\n  dyAnnotation(\"2020-04-08\", text = \"武汉解封\", tooltip = \"武汉解封\", width = 60) |&gt;\n  dyHighlight(highlightSeriesOpts = list(strokeWidth = 2)) |&gt;\n  dySeries(label = \"调整股价\") |&gt;\n  dyLegend(show = \"follow\", hideOnMouseOut = FALSE) |&gt;\n  dyOptions(fillGraph = TRUE, drawGrid = FALSE, gridLineColor = \"lightblue\") |&gt;\n  dyUnzoom()\n\n\n\n\n\n\n图 18.6: 美团股价变化趋势\n\n\n\n上图默认展示 YTD 数据，在一个动态的时间窗口内显示数据，假如今天是 2023-07-15，则展示 2023-01-01 至 2023-07-15 的股价数据。在函数 dyRangeSelector() 中设定时间窗口参数 dateWindow，实现数据范围的筛选。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#平稳性诊断",
    "href": "analyze-time-series-data.html#平稳性诊断",
    "title": "18  时序数据分析",
    "section": "\n18.3 平稳性诊断",
    "text": "18.3 平稳性诊断\n\n18.3.1 自相关图\n\nautoplot(acf(AirPassengers, plot = FALSE)) +\n  theme_classic()\n\n\n\n\n\n\n图 18.7: 乘客数量自相关图\n\n\n\n\n\n18.3.2 偏自相关图\n\nautoplot(pacf(AirPassengers, plot = FALSE)) +\n  theme_classic()\n\n\n\n\n\n\n图 18.8: 乘客数量偏自相关图\n\n\n\n\n\n18.3.3 延迟算子\n\n# 原始序列\nAirPassengers\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\n# 延迟 1 期\nlag(AirPassengers, k = 1)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1948                                             112\n1949 118 132 129 121 135 148 148 136 119 104 118 115\n1950 126 141 135 125 149 170 170 158 133 114 140 145\n1951 150 178 163 172 178 199 199 184 162 146 166 171\n1952 180 193 181 183 218 230 242 209 191 172 194 196\n1953 196 236 235 229 243 264 272 237 211 180 201 204\n1954 188 235 227 234 264 302 293 259 229 203 229 242\n1955 233 267 269 270 315 364 347 312 274 237 278 284\n1956 277 317 313 318 374 413 405 355 306 271 306 315\n1957 301 356 348 355 422 465 467 404 347 305 336 340\n1958 318 362 348 363 435 491 505 404 359 310 337 360\n1959 342 406 396 420 472 548 559 463 407 362 405 417\n1960 391 419 461 472 535 622 606 508 461 390 432    \n\n\n\n18.3.4 差分算子\n函数 diff() 实现差分算子，默认参数 lag = 1 ，differences = 1 表示延迟期数为 1 的一阶差分。\n\n# 延迟 1 期 1 阶差分\ndiff(AirPassengers, lag = 1, differences = 1)\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n1949         6   14   -3   -8   14   13    0  -12  -17  -15   14\n1950   -3   11   15   -6  -10   24   21    0  -12  -25  -19   26\n1951    5    5   28  -15    9    6   21    0  -15  -22  -16   20\n1952    5    9   13  -12    2   35   12   12  -33  -18  -19   22\n1953    2    0   40   -1   -6   14   21    8  -35  -26  -31   21\n1954    3  -16   47   -8    7   30   38   -9  -34  -30  -26   26\n1955   13   -9   34    2    1   45   49  -17  -35  -38  -37   41\n1956    6   -7   40   -4    5   56   39   -8  -50  -49  -35   35\n1957    9  -14   55   -8    7   67   43    2  -63  -57  -42   31\n1958    4  -22   44  -14   15   72   56   14 -101  -45  -49   27\n1959   23  -18   64  -10   24   52   76   11  -96  -56  -45   43\n1960   12  -26   28   42   11   63   87  -16  -98  -47  -71   42\n\n\n\n18.3.5 单位根检验\n\n18.3.6 格兰杰因果检验\n1969 年 Clive Granger 提出格兰杰因果检验，R 语言中 lmtest 包的函数 grangertest() 可以检验序列中变量之间的时间落差的相关性。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-exponential-smoothing",
    "href": "analyze-time-series-data.html#sec-exponential-smoothing",
    "title": "18  时序数据分析",
    "section": "\n18.4 指数平滑模型",
    "text": "18.4 指数平滑模型\n\n18.4.1 指数平滑\n首先来回答何为指数平滑？用历史数据的线性组合预测下一个时期的值，线性组合的权重随距离变远而按指数衰减。不妨设观测序列数据为 \\(\\{x_i\\}\\) ，预测序列数据为 \\(\\{y_i\\}\\)，用数学公式表达，如下：\n\\[\ny_h(1) = wx_h + w^2x_{h-1} + \\cdots = \\sum_{j=1}^{\\infty} w^j x_{h+1-j}\n\\]\n其中，权重 \\(0 &lt; w &lt; 1\\) ，权重越小表示距离远的历史数据对当前预测的贡献越小。线性组合的权重之和等于 1，所以\n\\[\n\\sum_{j=1}^{\\infty} w^j = \\frac{w}{1-w}\n\\]\n则第 \\(j\\) 个权重应为\n\\[\n\\frac{w^j}{\\frac{w}{1-w}} = (1-w)w^{j-1},j=1,2,\\ldots\n\\]\n则根据历史的 \\(h\\) 期数据预测未来的 1 期数据 \\(y_h(1)\\) 如下：\n\\[\ny_h(1) = (1-w)(x_h + wx_{h-1} + w^2x_{h-2} + \\cdots) = (1-w)\\sum_{j=0}^{\\infty}w^j x_{h-j}\n\\]\n以上就是指数平滑（exponential smoothing），在早期应用中，权重 \\(w\\) 的选取主要依靠经验。适用于没有明显趋势性、季节性、周期性的时间序列数据。\n\n18.4.2 函数 filter()\n\n函数 filter() 实现一元时间序列的线性过滤，或者对多元时间序列的单个序列分别做线性变换，它只是根据既定的平滑模型变换数据，没有拟合数据。函数 filter() 实现递归过滤和卷积过滤两种数据变换方式，分别对应自回归和移动平均两种时间序列平滑模型。\n\n递归过滤（自回归）\n\n\\[\ny_{i} = x_{i} + f_1 y_{i-1} +\\cdots+ f_p y_{i-p}\n\\tag{18.1}\\]\n\n卷积过滤（移动平均）\n\n\\[\ny_{i} = f_1 x_{i+o} + \\cdots + f_p x_{i+o-(p-1)}\n\\tag{18.2}\\]\n其中，\\(p\\) 代表模型的阶数， \\(o\\) 代表漂移项，O 表示英文单词 offset 的首字母。下面举个具体的例子来说明函数 filter() 的作用，设输入序列 \\(\\{x_i\\}\\) 是从 1 至 10 的整数。首先考虑自回归的情况，代码如下：\n\nx &lt;- 1:10\n# 自回归\nfilter(x, filter = c(2 / 3, 1 / 6, 1 / 6), method = \"recursive\")\n\nTime Series:\nStart = 1 \nEnd = 10 \nFrequency = 1 \n [1]  1.000000  2.666667  4.944444  7.907407 11.540123 15.835391 20.798182\n [8] 26.428041 32.724289 39.687230\n\n\n参数 x 指定输入的时间序列 \\(\\{x_i\\}\\)，参数 method 指定平滑的方法，method = \"recursive\" 表示使用自回归方法，参数 filter 表示自回归的系数，系数向量的长度代表模型 方程式 18.1 中的 \\(p\\) ，filter = c(2 / 3, 1 / 6, 1 / 6) 对应的模型如下：\n\\[\n\\begin{aligned}\ny_1 &= x_1 \\\\\ny_2 &= x_2 + \\frac{2}{3} y_1 \\\\\ny_3 &= x_3 + \\frac{2}{3} y_2 + \\frac{1}{6} y_1 \\\\\ny_i &= x_i + \\frac{2}{3} y_{i-1} + \\frac{1}{6} y_{i - 2} + \\frac{1}{6} y_{i - 3}, \\quad i \\geq 4 \\\\\n\\end{aligned}\n\\]\n其中，序列 \\(\\{y_i\\}\\) 表示函数 filter() 的输出结果，由上述方程不难看出自回归模型的递归的特点。为了理解自回归和递归的过程，下面依次计算 \\(y_1\\) 至 \\(y_4\\) 。\n\n# y1\n1\n\n[1] 1\n\n# y2\n2 + 2/3 * 1\n\n[1] 2.666667\n\n# y3\n3 + 2/3 * (2 + 2/3 * 1) + 1/6 * 1\n\n[1] 4.944444\n\n# y4\n4 + 2/3 * (3 + 2/3 * (2 + 2/3 * 1) + 1/6 * 1) + 1/6 *(2 + 2/3 * 1) + 1/6 * 1\n\n[1] 7.907407\n\n\n接下来，考虑移动平均的情况，代码如下：\n\n# 移动平均\nfilter(x, filter = c(2 / 3, 1 / 6, 1 / 6), method = \"convolution\", sides = 1)\n\nTime Series:\nStart = 1 \nEnd = 10 \nFrequency = 1 \n [1]  NA  NA 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5\n\n\n参数 method = \"convolution\" 表示使用移动平均。参数 sides 仅适用于卷积过滤，sides = 1 表示系数都是作用于过去的值。为了对比自回归和移动平均，不妨设移动平均的系数同自回归的系数，则移动平均模型如下：\n\\[\n\\begin{aligned}\ny_1 &~~ \\text{不存在}\\\\\ny_2 &~~ \\text{不存在}\\\\\ny_3 &= \\frac{2}{3} x_{3} + \\frac{1}{6} x_2 + \\frac{1}{6} x_1\\\\\ny_i &= \\frac{2}{3} x_{i} + \\frac{1}{6} x_{i - 1} + \\frac{1}{6} x_{i - 2}, \\quad i \\geq 3\n\\end{aligned}\n\\]\n比照模型 方程式 18.2 ，漂移项参数 \\(o\\) 为 0，也就是没有漂移，移动平均作用于过去的 3 期数据，也就是 \\(p = 3\\) 。因输出序列 \\(\\{y_i\\}\\) 中 \\(y_1,y_2\\) 不存在，下面仅计算 \\(y_3,y_4\\) 。\n\n# y3\n2/3 * 3 + 1/6 * 2 + 1/6 * 1\n\n[1] 2.5\n\n# y4\n2/3 * 4 + 1/6 * 3 + 1/6 * 2\n\n[1] 3.5\n\n\nTTR 包提供许多移动平均的计算函数，比如 SMA() ，下面计算过去 3 个观察值的算术平均。\n\nlibrary(TTR)\nSMA(x, n = 3)\n\n [1] NA NA  2  3  4  5  6  7  8  9\n\n\n\n18.4.3 简单指数平滑\n当时间序列不含趋势和季节性成分的时候，可以用简单指数平滑模型来拟合和预测。简单指数平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= b_{t-1} \\\\\ns_{t} &= s_{t-p}\n\\end{aligned}\n\\]\n其中，周期 \\(p\\)\n\nair_passengers_exp &lt;- HoltWinters(AirPassengers, gamma = FALSE, beta = FALSE)\nair_passengers_exp\n\nHolt-Winters exponential smoothing without trend and without seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, beta = FALSE, gamma = FALSE)\n\nSmoothing parameters:\n alpha: 0.9999339\n beta : FALSE\n gamma: FALSE\n\nCoefficients:\n      [,1]\na 431.9972\n\n\n预测的残差平方和 SSE sum-of-squared-errors\n\nair_passengers_exp$SSE\n\n[1] 162510.6\n\n\n\n# plot(air_passengers_exp)\nautoplot(air_passengers_exp) +\n  theme_classic()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 18.9: 简单指数平滑模型\n\n\n\n\n向前预测 5 期\n\nair_passengers_pred &lt;- predict(air_passengers_exp, n.ahead = 10, prediction.interval = TRUE)\n\n预测值及其预测区间\n\nplot(air_passengers_exp, air_passengers_pred)\n\n\n\n\n\n\n图 18.10: 简单指数平滑模型预测\n\n\n\n\n\n18.4.4 Holt 指数平滑\n当时间序列不含季节性成分，可以用 Holt 指数平滑模型拟合和预测 (Holt 2004) 。\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= s_{t-p}\n\\end{aligned}\n\\]\n\nair_passengers_holt &lt;- HoltWinters(AirPassengers, gamma = FALSE)\nair_passengers_holt\n\nHolt-Winters exponential smoothing with trend and without seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, gamma = FALSE)\n\nSmoothing parameters:\n alpha: 1\n beta : 0.003218516\n gamma: FALSE\n\nCoefficients:\n        [,1]\na 432.000000\nb   4.597605\n\n\n可知，\\(\\alpha = 1,\\beta = 0.0032\\)\n\nplot(air_passengers_holt)\n\n\n\n\n\n\n图 18.11: holt 指数平滑模型\n\n\n\n\n\n18.4.5 Holt-Winters 指数平滑\n时间序列同时含有趋势成分、季节性成分、随机成分，可以用 Holt-Winters 平滑模型来拟合和预测。根据趋势和季节性的关系，Holt-Winters 平滑模型分为可加 Holt-Winters 平滑和可乘 Holt-Winters 平滑。R 提供函数 HoltWinters() 拟合 Holt-Winters 平滑模型(Holt 2004; Winters 1960)。\n可加 Holt-Winters 平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= \\gamma (y_{t} - a_{t}) + (1-\\gamma) s_{t-p}\n\\end{aligned}\n\\]\n可乘 Holt-Winters 平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= (a_{t} + h \\times b_{t}) \\times s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} / s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= \\gamma (y_{t} / a_{t}) + (1-\\gamma) s_{t-p}\n\\end{aligned}\n\\]\n其中 \\(\\alpha, \\beta, \\gamma\\) 是参数，\\(p\\) 为周期长度，\\(a_{t}, b_{t}, s_{t}\\) 分别代表水平、趋势和季节性成分。\n\nair_passengers_add &lt;- HoltWinters(AirPassengers, seasonal = \"additive\")\nair_passengers_add\n\nHolt-Winters exponential smoothing with trend and additive seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, seasonal = \"additive\")\n\nSmoothing parameters:\n alpha: 0.2479595\n beta : 0.03453373\n gamma: 1\n\nCoefficients:\n          [,1]\na   477.827781\nb     3.127627\ns1  -27.457685\ns2  -54.692464\ns3  -20.174608\ns4   12.919120\ns5   18.873607\ns6   75.294426\ns7  152.888368\ns8  134.613464\ns9   33.778349\ns10 -18.379060\ns11 -87.772408\ns12 -45.827781\n\n\n可知，\\(\\alpha = 0.248,\\beta = 0.0345,\\gamma = 1\\)\n\nautoplot(air_passengers_add) +\n  theme_classic()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 18.12: 可加 Holt-Winters 平滑模型拟合\n\n\n\n\n\nair_passengers_mult &lt;- HoltWinters(AirPassengers, seasonal = \"mult\")\n\n\nautoplot(air_passengers_mult) +\n  theme_classic()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 18.13: 可乘 Holt-Winters 平滑模型拟合\n\n\n\n\n做一个 Shiny 应用展示参数 \\(\\alpha, \\beta, \\gamma\\) 对 Holt-Winters 平滑预测的影响。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-time-series-decomposition",
    "href": "analyze-time-series-data.html#sec-time-series-decomposition",
    "title": "18  时序数据分析",
    "section": "\n18.5 时间序列分解",
    "text": "18.5 时间序列分解\n\n可加模型\n\n\\[\ny_t = T_t + S_t + e_t\n\\]\n\n可乘模型\n\n\\[\ny_t = T_t \\times S_t \\times e_t\n\\]\n对时间序列 \\(\\{y_t\\}\\) 分解，趋势性成分 \\(T_t\\)、季节性成分 \\(S_t\\)、剩余成分 \\(e_t\\)\n\n18.5.1 函数 decompose()\n\n函数 decompose() 分解\n\nair_decomp_add &lt;- decompose(x = AirPassengers, type = \"additive\")\n\n函数返回一个列表，包含 6 个元素，分别是 x 原始序列，seasonal 季节性成分，figure 估计的季节图，trend 趋势成分，random 剩余成分，type 分解方法。\n\n# plot(air_decomp_add)\nautoplot(air_decomp_add) +\n  theme_classic()\n\nWarning: Removed 24 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 18.14: 变化趋势的分解\n\n\n\n\n去掉季节性部分\n\nAirPassengers_adjusted &lt;- AirPassengers - air_decomp_add$seasonal\nplot(AirPassengers_adjusted)\n\n\n\n\n\n\n图 18.15: 季节性调整\n\n\n\n\n\n18.5.2 函数 stl()\n\n函数 stl() 将时间序列分解为趋势性成分、季节性成分（周期性）、剩余成分。\n\nair_stl &lt;- stl(x = AirPassengers, s.window = 12)\n\n\nautoplot(air_stl) +\n  theme_classic()\n\n\n\n\n\n\n图 18.16: 变化趋势的分解\n\n\n\n\n剩余成分不是平稳序列，是异方差的。\nxts 包的 periodicity() 函数可以检测时间序列数据的周期，但时序数据对象最好是在 xts 框架内。\n\nxts::periodicity(AirPassengers)\n\nMonthly periodicity from Jan 1949 to Dec 1960",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-classic-time-series-models",
    "href": "analyze-time-series-data.html#sec-classic-time-series-models",
    "title": "18  时序数据分析",
    "section": "\n18.6 经典时间序列模型",
    "text": "18.6 经典时间序列模型\n\n18.6.1 自回归模型\n函数 ar() 拟合 AR 模型\n\nar(AirPassengers, order.max = 3)\n\n\nCall:\nar(x = AirPassengers, order.max = 3)\n\nCoefficients:\n      1        2  \n 1.1656  -0.2294  \n\nOrder selected 2  sigma^2 estimated as  1399\n\n\n\n18.6.2 移动平均模型\n将自回归的阶设为 0，函数 arima() 也可以用来拟合 MA 模型。\n\narima(AirPassengers, order = c(0, 1, 3))\n\n\nCall:\narima(x = AirPassengers, order = c(0, 1, 3))\n\nCoefficients:\n         ma1     ma2      ma3\n      0.1309  -0.359  -0.3599\ns.e.  0.0741   0.090   0.0907\n\nsigma^2 estimated as 949.5:  log likelihood = -693.45,  aic = 1394.91\n\n\n\n18.6.3 自回归移动平均模型\n函数 arima() 拟合 ARIMA 模型\n\narima(AirPassengers, order = c(1, 1, 3))\n\n\nCall:\narima(x = AirPassengers, order = c(1, 1, 3))\n\nCoefficients:\n         ar1      ma1      ma2      ma3\n      0.5227  -0.2906  -0.3884  -0.1219\ns.e.  0.1291   0.1284   0.1445   0.1322\n\nsigma^2 estimated as 886:  log likelihood = -688.45,  aic = 1386.89\n\n\nforecast 包提供函数 auto.arima() 自动选择合适的自回归、差分和移动平均的阶来拟合数据。\nforecast::auto.arima(AirPassengers)\nSeries: AirPassengers \nARIMA(2,1,1)(0,1,0)[12] \n\nCoefficients:\n         ar1     ar2      ma1\n      0.5960  0.2143  -0.9819\ns.e.  0.0888  0.0880   0.0292\n\nsigma^2 = 132.3:  log likelihood = -504.92\nAIC=1017.85   AICc=1018.17   BIC=1029.35",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-time-series-summary",
    "href": "analyze-time-series-data.html#sec-time-series-summary",
    "title": "18  时序数据分析",
    "section": "\n18.7 总结",
    "text": "18.7 总结\n方法没有好坏，只有适合与否。Holt-Winter 适合预警任务，算法简单，可以及时出预测结果，仅需要一步预测，不需要给出多步预测，要求快，以便迅速作出反应。Prophet 实现的贝叶斯结构可加模型适合短期预测任务，只要在可容许的时间范围内出结果即可，可以迅速出结果当然更好，需要给出多步预测结果，且结果需要强解释性，以便提前做一些商家供给、平台资源的分配。商分模型常常需要比较强的可解释性，算法策略模型重在预测精准度，对可解释性要求不高。\n在时间序列数据的可视化方面，除了 Base R 提供的绘图方法外，静态的时序图 lattice 和 ggplot2 都不错，而交互式图形推荐使用 plotly 和 dygraphs。\nPortfolioAnalytics 包做投资组合优化，均值-方差，收益和风险权衡。 Rmetrics 提供系列时间序列数据分析和建模的 R 包，包括投资组合优化 fPortfolio、多元分析 fMultivar、自回归条件异方差模型 fGarch、二元相依结构的 Copulae 分析 fCopulae 、市场和基础统计 fBasics 。\nfable 一元到多元时间序列预测问题，提供 ETS、ARIMA、TSLM 等模型，并有书籍时间序列预测原则。值得一提， forecast 包开发者 Rob J Hyndman 称已不再开发新的功能，推荐大家使用 fable 包。feasts 包辅助特征抽取、序列分解、汇总统计和绘制图形等， 插件包 fable.prophet 接入 Prophet 的预测能力。timetk 时间序列数据处理、分析、预测和可视化工具箱，提供一致的操作方式，试图形成完成的解决方案。The Rmetrics Association 开发了一系列 R 包专门处理金融时间序列数据，比如 fGarch 包提供条件自回归异方差模型。\n从时间序列中寻找规律，这样才是真的数据建模，从数据到模型，而不是相反 Finding Patterns in Time Series，识别金融时间序列的模式和统计规律。\n\n\n\n\nHolt, Charles C. 2004. 《Forecasting seasonals and trends by exponentially weighted moving averages》. International Journal of Forecasting 20 (1): 5–10. https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nRyan, Jeffrey A., 和 Joshua M. Ulrich. 2022. quantmod: Quantitative Financial Modelling Framework. https://CRAN.R-project.org/package=quantmod.\n\n\nTang, Yuan, Masaaki Horikoshi, 和 Wenxuan Li. 2016. 《ggfortify: Unified Interface to Visualize Statistical Result of Popular R Packages》. The R Journal 8 (2): 474–85. https://doi.org/10.32614/RJ-2016-060.\n\n\nWinters, Peter R. 1960. 《Forecasting sales by exponentially weighted moving averages》. Management Science 6 (3): 324–42. https://doi.org/10.1287/mnsc.6.3.324.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html",
    "href": "statistical-computation.html",
    "title": "19  统计计算",
    "section": "",
    "text": "19.1 回归问题与优化问题\n1996 年出现 Lasso （Least Absolute Selection and Shrinkage Operator，简称 Lasso）(Tibshirani 1996)，由于缺少高效的求解算法，Lasso 在高维小样本特征选择研究中没有广泛流行，最小角回归（Least Angle Regression，简称 LAR）算法 (Efron 等 2004) 的出现有力促进了 Lasso 在高维小样本数据中的应用。为了解决 Lasso 的有偏估计问题，自适应 Lasso、松弛 Lasso， SCAD （Smoothly Clipped Absolute Deviation，简称 SCAD）(Kim, Choi, 和 Oh 2008)，MCP (Minimax Concave Penalty，简称 MCP)(Zhang 2010) 陆续出现。经典的普通最小二乘、广义最小二乘、岭回归、逐步回归、Lasso 回归、最优子集回归都可转化为优化问题。具体地，一个带 L1 正则项的线性回归模型，其对应的优化问题如下：\n\\[\n\\arg \\min_{\\boldsymbol{\\beta},\\lambda} ~~ \\frac{1}{2} || \\bm{y} - X \\boldsymbol{\\beta} ||_2^2 +  \\lambda ||\\boldsymbol{\\beta}||_1\n\\]\n其中，\\(X \\in \\mathbb{R}^{n\\times k}\\)， \\(\\bm{y} \\in \\mathbb{R}^n\\)，\\(\\boldsymbol{\\beta} \\in \\mathbb{R}^k\\)， \\(0 &lt; \\lambda \\in \\mathbb{R}\\) 。下面以逻辑回归模型为例，介绍 R 语言中求解此类优化问题的方法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-log-likelihood",
    "href": "statistical-computation.html#sec-log-likelihood",
    "title": "19  统计计算",
    "section": "\n19.2 对数似然与损失函数",
    "text": "19.2 对数似然与损失函数\n\n19.2.1 Logistic 分布\n在介绍逻辑回归之前，先了解一下 Logistic 分布。一个均值为 \\(m\\) ，方差为 \\(\\frac{\\pi^2}{3}s^2\\) 的 Logistic 分布函数的形式为\n\\[\nF(x) = \\frac{1}{1 + \\exp(-\\frac{x - m}{s})}\n\\]\n密度函数的形式为\n\\[\nf(x) = \\frac{\\exp(-\\frac{x - m}{s})}{s(1 + \\exp(-\\frac{x-m}{s}))^2} = \\frac{\\exp(\\frac{x - m}{s})}{s(1 + \\exp(\\frac{x-m}{s}))^2}\n\\]\n密度函数与分布函数的关系如下：\n\\[\n\\frac{dF(x)}{dx} = f(x) = sF(x)(1 - F(x))\n\\]\n也就是说 Logistic 分布是上述微分方程的解。\n\n\n\n\n\n\n\n\n\n(a) 概率密度函数\n\n\n\n\n\n\n\n\n\n(b) 概率分布函数\n\n\n\n\n\n\n图 19.1: 逻辑斯谛分布\n\n\nR 语言中分别表示逻辑斯谛分布的密度函数、分布函数、分位函数和随机数生成函数如下：\ndlogis(x, location = 0, scale = 1, log = FALSE)\nplogis(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)\nqlogis(p, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)\nrlogis(n, location = 0, scale = 1)\n如果函数参数 location 或 scale 没有指定，则分别取默认值 0 和 1，就是标准的逻辑斯谛分布。位置参数（类似正态分布中的均值 \\(\\mu\\)）为 location = m ，尺度参数（类似正态分布中的标准差 \\(\\sigma\\)）为 scale = s，逻辑斯谛分布是一个长尾分布。\n\n19.2.2 逻辑回归\n响应变量 \\(Y\\) 服从伯努利分布 \\(\\mathrm{Bernoulli}(p)\\)，取值是 0 或 1，对线性预测 \\(X\\boldsymbol{\\beta}\\) 做 Logistic 变换\n\\[\n\\bm{p} = \\mathsf{E}Y = \\mathrm{Logistic}(X\\boldsymbol{\\beta}) = \\frac{1}{1 + e^{-(\\alpha + X\\boldsymbol{\\beta})}} = \\frac{e^{\\alpha + X\\boldsymbol{\\beta}}}{1 + e^{\\alpha + X\\boldsymbol{\\beta}}}\n\\]\nLogistic 的逆变换\n\\[\n\\mathrm{Logistic}^{-1}(\\bm{p})= \\ln\\big(\\frac{\\bm{p}}{1 - \\bm{p}}\\big) = \\alpha + X\\boldsymbol{\\beta}\n\\]\n记数据矩阵 \\(X\\) 为\n\\[\nX = \\begin{bmatrix}\n    x_{11} & x_{12} & x_{13} & \\dots  & x_{1k} \\\\\n    x_{21} & x_{22} & x_{23} & \\dots  & x_{2k} \\\\\n    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    x_{n1} & x_{n2} & x_{n3} & \\dots  & x_{nk}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\bm{x}_1^{\\top} \\\\\n\\bm{x}_2^{\\top} \\\\\n\\vdots \\\\\n\\bm{x}_n^{\\top}\n\\end{bmatrix}\n\\]\n每一行表示一次观测，每一列表示一个变量的 \\(n\\) 次观测，记 \\(X = (X_1, X_2, \\cdots, X_k)\\) 是一个 \\(n \\times k\\) 数据矩阵，其中 \\(\\bm{x}_i^{\\top}\\) 表示矩阵 \\(X\\) 的第 \\(i\\) 行，一共有 \\(n\\) 行，可以看作是 \\(1 \\times k\\) 的矩阵，\\(X_j, j = 1,2, \\cdots, k\\) 表示矩阵 \\(X\\) 的第 \\(j\\) 列，一共有 \\(k\\) 列。类似地， \\(\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\cdots, \\beta_k)^{\\top}\\) 是一个列向量，可以看作是 \\(k \\times 1\\) 的矩阵，\\(\\beta_j\\) 表示第 \\(j\\) 个变量 \\(X_j\\) 的系数。对第 \\(i\\) 次观测\n\\[\n\\mathrm{Logistic}^{-1}(p_i)= \\ln\\big(\\frac{p_i}{1-p_i}\\big) = \\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}\n\\]\n关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的似然函数如下：\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\alpha,\\boldsymbol{\\beta}) &= \\prod_{i=1}^{n} p_i^{y_i}(1 - p_i)^{1 - y_i} \\\\\n     &= \\prod_{i=1}^{n} \\Big(\\frac{e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}\\Big)^{y_i}\\Big(\\frac{1}{e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}\\Big)^{1-y_i} \\\\\n\\end{aligned}\n\\tag{19.1}\\]\n关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的对数似然函数如下：\n\\[\n\\begin{aligned}\n\\ell(\\alpha,\\boldsymbol{\\beta}) &= \\log \\mathcal{L}(\\alpha,\\boldsymbol{\\beta}) \\\\\n& = \\sum_{i=1}^{n} \\Big[y_i \\log (p_i) + (1 - y_i) \\log(1-p_i)\\Big] \\\\\n&= \\sum_{i=1}^{n} \\Big[y_i \\log \\Big(\\frac{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\Big) + (1 - y_i) \\log\\Big(\\frac{1}{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\Big)\\Big]\n\\end{aligned}\n\\tag{19.2}\\]\n对数似然函数 \\(\\ell(\\alpha,\\boldsymbol{\\beta})\\) 关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的偏导数如下：\n\\[\n\\begin{aligned}\n\\frac{\\partial \\ell(\\alpha,\\boldsymbol{\\beta})}{\\partial \\alpha}  &= \\sum_{i=1}^{n}\\Big[ \\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) \\frac{\\partial p_i}{\\partial \\alpha} \\Big] \\\\\n\\frac{\\partial \\ell(\\alpha,\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} &= \\sum_{i=1}^{n}\\Big[\\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) \\frac{\\partial p_i}{\\partial \\beta} \\Big] \\\\\n& = \\sum_{i=1}^{n}\\Big[\\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) p_i(1- p_i) \\bm{x}_i^{\\top} \\Big]\n\\end{aligned}\n\\tag{19.3}\\]\n其中， \\(p_i = \\frac{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\) ，要使 \\(\\ell(\\alpha,\\boldsymbol{\\beta})\\) 取极大值，一般通过迭代加权最小二乘算法（Iteratively (Re-)Weighted Least Squares，简称 IWLS）求解此优化问题，它可以看作拟牛顿法的一种特殊情况，在 R 语言中，函数 glm() 是求解此类问题的办法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-solvers",
    "href": "statistical-computation.html#sec-solvers",
    "title": "19  统计计算",
    "section": "\n19.3 数值优化问题求解器",
    "text": "19.3 数值优化问题求解器\n\n19.3.1 optim()\n\n从一个逻辑回归模型模拟一组样本，共 2500 条记录，即 \\(n = 2500\\)，10 个观测变量，即 \\(k=10\\)，其中，只有变量 \\(X_1\\) 和 \\(X_2\\) 的系数非零，参数设定为 \\(\\alpha = 1, \\beta_1 = 3,\\beta_2 = -2\\)，而 \\(\\beta_i = 0, i=3, \\cdots, 10\\) 模拟数据的代码如下：\n\nset.seed(2023)\nn &lt;- 2500\nk &lt;- 10\nX &lt;- matrix(rnorm(n * k), ncol = k)\ny &lt;- rbinom(n, size = 1, prob = plogis(1 + 3 * X[, 1] - 2 * X[, 2]))\n\n模拟数据矩阵 X 与上述记号 \\(X\\) 是对应的，记号 \\(\\bm{x_i}^{\\top}\\) 表示数据矩阵的第 \\(i\\) 行。\\(\\alpha\\) 是逻辑回归方程的截距，\\(\\bm{\\beta}\\) 是 \\(k\\) 维列向量，\\(X\\) 是 \\(n \\times k\\) 维的矩阵且 \\(n &gt; k\\)，\\(y\\) 是 \\(n\\) 维向量。极大化对数似然函数 方程式 19.2 ，就是求解一个多维非线性无约束优化问题。方便起见，将 \\(\\alpha\\) 合并进 \\(\\bm{\\beta}\\) 向量，另，函数 optim() 默认求极小，因此在对数似然函数前添加负号。\n\n# 目标函数\nlog_logit_lik &lt;- function(beta) {\n  p &lt;- plogis(cbind(1, X) %*% beta)\n  -sum(y * log(p) + (1 - y) * log(1 - p))\n}\n\n高维情形下，没法绘制似然函数图形，退化到二维，如 图 19.2 所示，二维情形下的逻辑回归模型的负对数似然函数曲面。\n\n\n\n\n\n\n\n图 19.2: 二维情形下的逻辑回归模型的负对数似然函数曲面\n\n\n\n\n当用 Base R 函数 optim() 来求解时，发现 Nelder-Mead 算法收敛慢，易陷入局部最优解，即使迭代 10000 次，与真值仍然相去甚远。当用 SANN （模拟退火算法）求解此 11 维非线性无约束优化问题时，迭代 10000 次后，比较接近真值。\n\noptim(\n  par = rep(1, 11), # 初始值\n  fn = log_logit_lik, # 目标函数\n  method = \"SANN\",\n  control = list(maxit = 10000)\n)\n\n#&gt; $par\n#&gt;  [1]  1.0755086156  3.2857327374 -2.1172404451 -0.0268567120  0.0184306330\n#&gt;  [6]  0.0304496968  0.0045154725  0.1283816433 -0.0746276329 -0.0624193044\n#&gt; [11] -0.0001349772\n#&gt; \n#&gt; $value\n#&gt; [1] 754.1838\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    10000       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n\n\n根据目标函数计算其梯度，有了梯度信息，可以使用迭代效率更高的 L-BFGS-B 算法。\n\n# 梯度函数\nlog_logit_lik_grad &lt;- function(beta) {\n  p &lt;- plogis(cbind(1, X) %*% beta)\n  -t((y / p - (1 - y) / (1 - p)) * p * (1 - p)) %*% cbind(1, X)\n}\n\noptim(\n  par = rep(1, 11), # 初始值\n  fn = log_logit_lik, # 目标函数\n  gr = log_logit_lik_grad, # 目标函数的梯度\n  method = \"L-BFGS-B\"\n)\n\n#&gt; $par\n#&gt;  [1]  1.00802641  3.11296713 -2.00955313  0.05855394 -0.02650585  0.01330428\n#&gt;  [7]  0.02171815  0.10213455 -0.02949774 -0.08633384  0.08098888\n#&gt; \n#&gt; $value\n#&gt; [1] 750.9724\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;       13       13 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH\"\n\n\n相比于函数 optim()，R 包 nloptr 不但可以提供类似的数值优化功能，而且可以处理各类非线性约束，能力更强。仍然基于上面的优化问题， 调用 nloptr 包求解的代码如下：\n\nlibrary(nloptr)\nnlp &lt;- nloptr(\n  x0 = rep(1, 11),\n  eval_f = log_logit_lik,\n  eval_grad_f = log_logit_lik_grad,\n  opts = list(\n    \"algorithm\" = \"NLOPT_LD_LBFGS\",\n    \"xtol_rel\" = 1.0e-8\n  )\n)\nnlp\n\n#&gt; \n#&gt; Call:\n#&gt; \n#&gt; nloptr(x0 = rep(1, 11), eval_f = log_logit_lik, eval_grad_f = log_logit_lik_grad, \n#&gt;     opts = list(algorithm = \"NLOPT_LD_LBFGS\", xtol_rel = 1e-08))\n#&gt; \n#&gt; \n#&gt; Minimization using NLopt version 2.7.1 \n#&gt; \n#&gt; NLopt solver status: 3 ( NLOPT_FTOL_REACHED: Optimization stopped because \n#&gt; ftol_rel or ftol_abs (above) was reached. )\n#&gt; \n#&gt; Number of Iterations....: 23 \n#&gt; Termination conditions:  xtol_rel: 1e-08 \n#&gt; Number of inequality constraints:  0 \n#&gt; Number of equality constraints:    0 \n#&gt; Optimal value of objective function:  750.97235708148 \n#&gt; Optimal value of controls: 1.008028 3.112977 -2.009557 0.05854534 -0.02650855 0.01330416 0.02171839 \n#&gt; 0.1021212 -0.02949994 -0.08632463 0.08098663\n\n\n如果对数似然函数是多模态的，一般的求解器容易陷入局部最优解，推荐用 nloptr 包的全局优化求解器。\n\n19.3.2 glm()\n\nBase R 提供的函数 glm() 拟合模型，指定联系函数为 logit 变换。\n\nfit_r &lt;- glm(y ~ X, family = binomial(link = \"logit\"))\nsummary(fit_r)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = y ~ X, family = binomial(link = \"logit\"))\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  1.00803    0.07395  13.631   &lt;2e-16 ***\n#&gt; X1           3.11298    0.13406  23.222   &lt;2e-16 ***\n#&gt; X2          -2.00956    0.09952 -20.192   &lt;2e-16 ***\n#&gt; X3           0.05855    0.06419   0.912    0.362    \n#&gt; X4          -0.02651    0.06588  -0.402    0.687    \n#&gt; X5           0.01330    0.06461   0.206    0.837    \n#&gt; X6           0.02172    0.06496   0.334    0.738    \n#&gt; X7           0.10212    0.06279   1.626    0.104    \n#&gt; X8          -0.02950    0.06474  -0.456    0.649    \n#&gt; X9          -0.08632    0.06482  -1.332    0.183    \n#&gt; X10          0.08099    0.06385   1.268    0.205    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 3381.4  on 2499  degrees of freedom\n#&gt; Residual deviance: 1501.9  on 2489  degrees of freedom\n#&gt; AIC: 1523.9\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 6\n\n\n或者也可以用函数 glm.fit()，效果类似，使用方式不同罢了。\n\nfit_r2 &lt;- glm.fit(x = cbind(1, X), y = y, family = binomial(link = \"logit\"))\ncoef(fit_r2)\n\n#&gt;  [1]  1.00802820  3.11297679 -2.00955727  0.05854534 -0.02650855  0.01330416\n#&gt;  [7]  0.02171839  0.10212118 -0.02949994 -0.08632463  0.08098663\n\n\n函数 glm() 的参数是一个公式，函数 glm.fit() 的参数是矩阵、向量，用函数 glm() 拟合模型，其内部调用的就是函数 glm.fit()。\n\n19.3.3 glmnet 包\n调用 glmnet 包的函数 glmnet() 拟合模型，指定指数族的具体形式为二项分布，伯努利分布是二项分布的特殊形式，也叫两点分布或0-1分布。\n\nlibrary(Matrix)\nlibrary(glmnet)\nfit_glm &lt;- glmnet(x = X, y = y, family = \"binomial\")\n\n逻辑回归模型系数在 L1 正则下的迭代路径图\n\nplot(fit_glm, ylab = \"回归系数\")\n\n\n\n\n\n\n图 19.3: 回归系数的迭代路径\n\n\n\n\n从图可见，剩余两个系数是非零的，一个是 3， 一个是 -2，其余都被压缩，而接近为 0 了。\n\nplot(fit_glm$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\",\n  main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\n图 19.4: 惩罚系数的迭代路径\n\n\n\n\n随着迭代的进行，惩罚系数 \\(\\lambda\\) 越来越小，接近于 0，这也是符合预期的，因为模型本来就是简单的逻辑回归，不带惩罚项。选择一个迭代趋于稳定时的 \\(\\lambda\\) 比如 0.0005247159，此时各个参数的取值如下：\n\ncoef(fit_glm, s = 0.0005247159)\n\n#&gt; 11 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       s1\n#&gt; (Intercept)  0.997741857\n#&gt; V1           3.076358149\n#&gt; V2          -1.984018387\n#&gt; V3           0.052633923\n#&gt; V4          -0.020195037\n#&gt; V5           0.008065018\n#&gt; V6           0.015936357\n#&gt; V7           0.095722046\n#&gt; V8          -0.023589159\n#&gt; V9          -0.080864640\n#&gt; V10          0.075234011\n\n\n截距 (Intercept) 对应 \\(\\alpha = 0.997741857\\)，而 \\(\\beta_1 = 3.076358149\\) 对应 V1，\\(\\beta_2 = -1.984018387\\) 对应 V2，以此类推。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-evaluation-model-performance",
    "href": "statistical-computation.html#sec-evaluation-model-performance",
    "title": "19  统计计算",
    "section": "\n19.4 评估模型的分类效果",
    "text": "19.4 评估模型的分类效果\n逻辑回归模型是二分类模型，评估模型的分类效果，两个办法。\n\n可以用 AUC 指标或者 ROC 曲线，pROC 包和 ROCR 包都可以绘制 ROC 曲线。\n可以用 Wilcoxon 检验，越显著表示分类效果越好。\n\n\n19.4.1 ROC 曲线和 AUC 值\nROC 是 Receiver Operating Characteristic 简写。随机抽取 2000 个样本作为训练集，余下的数据作为测试集。\n\ndat &lt;- cbind.data.frame(X, y)\nset.seed(20232023)\nidx &lt;- sample(x = 1:nrow(dat), size = 2000, replace = F)\n# 训练集\ndat_train &lt;- dat[idx, ]\n# 测试集\ndat_test &lt;- dat[-idx, ]\n\n函数 glm() 拟合训练集数据\n\nfit_binom &lt;- glm(y ~ ., data = dat_train, family = binomial(link = \"logit\"))\n\n将训练好的模型用于测试集，调用函数 predict() 进行预测，type = \"response\" 获得预测概率值，它是对数几率，比值比的对数。\n\ndat_test$pred &lt;- predict(fit_binom, newdata = dat_test, type = \"response\")\n\n返回值介于 0 - 1 之间，表示预测概率。在测试集上绘制 ROC 曲线。\n\npROC::plot.roc(\n  y ~ pred, data = dat_test,\n  col = \"dodgerblue\", print.auc = TRUE,\n  auc.polygon = TRUE, auc.polygon.col = \"#f6f6f6\",\n  xlab = \"FPR\", ylab = \"TPR\", main = \"预测 ROC 曲线\"\n)\n\n#&gt; Setting levels: control = 0, case = 1\n\n\n#&gt; Setting direction: controls &lt; cases\n\n\n\n\n\n\n\n图 19.5: ROC 曲线\n\n\n\n\nROC 曲线越往左上角拱，表示预测效果越好。FPR 是 False Positive Rate 的缩写，TPR 是 True Positive Rate 的缩写。\n\n# 计算 AUC 值\npROC::auc(y ~ pred, data = dat_test)\n\n#&gt; Setting levels: control = 0, case = 1\n\n\n#&gt; Setting direction: controls &lt; cases\n\n\n#&gt; Area under the curve: 0.9487\n\n\nAUC 是 area under curve 的缩写，表示 ROC 曲线下的面积，所以 AUC 指标越接近 1 越好。\n\n19.4.2 Wilcoxon 检验\n对每个标签的预测概率指定服从均匀分布，相当于随机猜测，所以最后 ROC 会接近对角线，而且样本量越大越接近，AUC 会越来越接近 0.5。如果预测结果比随机猜测要好，Wilcoxon 检验会显著，预测效果越好检验会越显著，表示预测 pred 和观测 y 越接近。\n\nwilcox.test(pred ~ y, data = dat_test)\n\n#&gt; \n#&gt;  Wilcoxon rank sum test with continuity correction\n#&gt; \n#&gt; data:  pred by y\n#&gt; W = 3140, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, 和 Robert Tibshirani. 2004. 《Least angle regression》. The Annals of Statistics 32 (2): 407–99. https://doi.org/10.1214/009053604000000067.\n\n\nKim, Yongdai, Hosik Choi, 和 Hee-Seok Oh. 2008. 《Smoothly Clipped Absolute Deviation on High Dimensions》. Journal of the American Statistical Association 103 (484): 1665–73. https://doi.org/10.1198/016214508000001066.\n\n\nTibshirani, Robert. 1996. 《Regression Shrinkage and Selection via the Lasso》. Journal of the Royal Statistical Society. Series B (Methodological) 58 (1): 267–88. http://www.jstor.org/stable/2346178.\n\n\nZhang, Cun-Hui. 2010. 《Nearly unbiased variable selection under minimax concave penalty》. The Annals of Statistics 38 (2): 894–942. https://doi.org/10.1214/09-AOS729.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html",
    "href": "numerical-optimization.html",
    "title": "20  数值优化",
    "section": "",
    "text": "20.1 线性优化\n线性优化是指目标函数和约束条件都是线性的优化问题。考虑如下线性优化问题：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & -6x_1 -5x_2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    x_1  + 4x_2 \\leq 16\\\\\n    6x_1 + 4x_2 \\leq 28\\\\\n    2x_1 - 5x_2 \\leq 6\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n其中，目标函数是 \\(-6x_1 -5x_2\\)，\\(\\min\\) 表示求目标函数的最小值，\\(\\boldsymbol{x} = (x_1,x_2)^{\\top}\\) 表示决策变量，无特殊说明，决策变量都取实数。\\(\\text{s.t.}\\) 是 subject to 的缩写，专指约束条件。上述线性优化问题写成矩阵形式，如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\n  \\begin{bmatrix}\n  -6  \\\\\n  -5\n  \\end{bmatrix}\n  ^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\left\\{\n\\begin{array}{l}\n  \\begin{bmatrix}\n  1 & 4  \\\\\n  6 & 4  \\\\\n  2 & -5\n  \\end{bmatrix}\n  \\boldsymbol{x} \\leq\n  \\begin{bmatrix}\n   16 \\\\\n   28 \\\\\n   6\n  \\end{bmatrix}\n\\end{array} \\right.\n\\end{aligned}\n\\]\n用 \\(\\boldsymbol{d}\\) 表示目标函数的系数向量，\\(A\\) 表示约束矩阵，\\(\\boldsymbol{b}\\) 表示右手边的向量。上述优化问题用矩阵表示，如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\n  \\boldsymbol{d}^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad &\n  A\\boldsymbol{x} \\leq\n  \\boldsymbol{b}\n\\end{aligned}\n\\]\n用 ROI 包提供的一套使用语法表示该线性优化问题，代码如下：\n# 定义优化问题\nop &lt;- OP(\n  objective = L_objective(L = c(-6, -5)),\n  constraints = L_constraint(\n    L = matrix(c(\n      1, 4,\n      6, 4, \n      2, -5\n    ), ncol = 2, byrow = TRUE),\n    dir = c(\"&lt;=\", \"&lt;=\", \"&lt;=\"),\n    rhs = c(16, 28, 6)\n  ),\n  types = c(\"C\", \"C\"),\n  maximum = FALSE\n)\n# 优化问题描述\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n# 求解优化问题\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1] 2.4 3.4\n\n# 目标函数值\nres$objval\n\n#&gt; [1] -31.4\n函数 OP() 定义一个优化问题，参数如下：\n不同类型的目标函数和约束条件组合在一起可以构成非常丰富的优化问题。ROI 包支持的目标函数、约束条件及相应的代码见下表。后续将根据优化问题，逐个介绍用法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-linear-optimization",
    "href": "numerical-optimization.html#sec-linear-optimization",
    "title": "20  数值优化",
    "section": "",
    "text": "objective ：指定目标函数，用函数 L_objective() 表示线性优化中的目标函数，函数名中 L 表示 Linear（线性），包含数值型向量。\n\nconstraints ：指定约束条件，用函数 L_constraint() 表示线性优化中的约束条件，函数名中 L 表示 Linear（线性），包含约束矩阵 \\(A\\) ，约束分量的方向可为 &gt;= 、&lt;= 或 = ，本例中为 &lt;=，右手边的向量 \\(b\\) 。\n\ntypes ：指定决策变量的类型，分三种情况， B 表示 0-1 变量，字母 B 是 binary 的意思，I 表示整型变量，字母 I 是 integer 的意思，C 表示数值型变量，字母 C 是 continuous 的意思。本例中，两个变量都是连续型的，types = c(\"C\", \"C\") 。\n\nmaximum ：指定目标函数需要求极大还是极小，默认求极小，取值为逻辑值 TRUE 或 FALSE。\n\n\n\n\nROI 包可以表示的目标函数和约束条件\n\n目标函数\n代码\n约束条件\n代码\n\n\n\n线性函数\nL_objective()\n无约束\n留空\n\n\n二次函数\nQ_objective()\n箱式约束\nV_bound()\n\n\n非线性函数\nF_objective()\n线性约束\nL_constraint()\n\n\n\n\n二次约束\nQ_constraint()\n\n\n\n\n锥约束\nC_constraint()\n\n\n\n\n非线性约束\nF_constraint()",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-quadratic-optimization",
    "href": "numerical-optimization.html#sec-quadratic-optimization",
    "title": "20  数值优化",
    "section": "\n20.2 凸二次优化",
    "text": "20.2 凸二次优化\n二次优化分严格凸二次和非严格凸二次优化问题，严格凸要求矩阵对称正定，非严格凸要求矩阵对称半正定。对于矩阵负定的情况，不是凸优化问题，暂不考虑。二次优化的一般形式如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2}\\boldsymbol{x}^{\\top}D\\boldsymbol{x} + \\boldsymbol{d}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{x} \\leq \\boldsymbol{b}\n\\end{aligned}\n\\]\n二次优化不都是凸优化，当且仅当矩阵 \\(D\\) 半正定时，上述二次优化是凸二次优化，当矩阵 \\(D\\) 正定时，上述二次优化是严格凸二次优化。下面举个严格凸二次优化的具体例子，令\n\\[\nD = \\begin{bmatrix}\n2 & -1\\\\\n-1 & 2\n\\end{bmatrix}, \\quad\n\\boldsymbol{d} =  \n\\begin{bmatrix}\n3 \\\\\n-2\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n-1 & -1  \\\\\n1 & -1 \\\\\n0  & 1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n-2 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n即目标函数\n\\[\nQ(x_1,x_2) = x_1^2 + x_2^2 - x_1 x_2 + 3x_1- 2x_2\n\\]\n二次优化中的数据矩阵和向量 \\(D,\\boldsymbol{d},A,\\boldsymbol{b}\\) 依次用 Dmat、dvec、Amat、bvec 表示出来。\n\nDmat &lt;- matrix(c(2, -1, -1, 2), nrow = 2, byrow = TRUE)\ndvec &lt;- c(3, -2)\nAmat &lt;- matrix(c(-1, -1, 1, -1, 0, 1), ncol = 2, byrow = TRUE)\nbvec &lt;- c(-2, 2, 3)\n\n同样，也是在函数 OP()中传递目标函数，约束条件。在函数 Q_objective() 中定义二次优化的目标函数，字母 Q 是 Quadratic 的意思，表示二次部分，字母 L 是 Linear 的意思，表示线性部分。函数 L_constraint() 的使用同线性优化，不再赘述。根据 ROI 包的使用接口定义的参数，定义目标优化。\n\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(L = Amat, dir = rep(\"&lt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\nnloptr 包有许多优化求解器，可用于求解二次优化的也有好几个。对于一个目标优化，函数 ROI_applicable_solvers() 可以找到能够求解此优化问题的求解器。\n\nROI_applicable_solvers(op)\n\n#&gt; [1] \"nloptr.cobyla\" \"nloptr.mma\"    \"nloptr.auglag\" \"nloptr.isres\" \n#&gt; [5] \"nloptr.slsqp\"  \"quadprog\"\n\n\n下面使用其中的 nloptr.slsqp 来求解。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 2))\nnlp$objval\n\n#&gt; [1] -0.08333333\n\nnlp$solution\n\n#&gt; [1] 0.1666667 1.8333333\n\n\n作为对比，移除线性不等式约束，求解无约束优化问题。目标函数仍然是二次型，但是已经没有线性约束条件，所以不是二次优化问题，再用求解器 nloptr.slsqp 求解的结果已不是无约束优化的解。\n\nop2 &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  maximum = FALSE\n)\nop2\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 0 constraints\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\nnlp2 &lt;- ROI_solve(op2, solver = \"nloptr.slsqp\", start = c(1, 2))\nnlp2$objval\n\n#&gt; [1] -1\n\nnlp2$solution\n\n#&gt; [1] 0 1\n\n\n在可行域上画出等高线，标记目标解的位置， 图 20.2 展示无约束和有约束条件下的解。图中橘黄色线围成的三角形区域是可行域，红点表示无约束下求解器 nloptr.slsqp 获得的解 \\((0,1)\\) ，真正的无约束解是蓝点所在位置为 \\((-4/3,1/3)\\) ，黄点表示线性约束下求解器 nloptr.slsqp 获得的解 \\((1/6,11/6)\\) 。所以，不能用二次优化的求解器去求解无约束的二次优化问题。\n\n代码# 约束解\nqp_sol &lt;- nlp$solution\n# 无约束解\nuc_sol &lt;- nlp2$solution\ndat &lt;- expand.grid(x1 = seq(-2, 5.5, length.out = 50), \n                   x2 = seq(-1, 3.5, length.out = 50))\n# 二次优化的目标函数\ndat$fn &lt;- with(dat, x1^2 + x2^2 - x1 * x2 + 3 * x1 - 2 * x2)\nlevelplot(fn ~ x1 * x2, data = dat, aspect = .7,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  xlim = c(-2.2, 5.7), ylim = c(-1.1, 3.6),\n  panel = function(...) {\n    panel.levelplot(...)\n    panel.polygon(x = c(2, 5, -1), y = c(0, 3, 3),\n      border = \"orange\", lwd = 2, col = \"transparent\"\n    )\n    panel.points(\n      x = c(uc_sol[1], qp_sol[1], -4/3),\n      y = c(uc_sol[2], qp_sol[2], 1/3),\n      lwd = 5, col = c(\"red\", \"yellow\", \"blue\"), pch = 19\n    )\n  },\n  # 减少图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = 0, units = \"inches\"),\n      right.padding = list(x = 0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ), contour = TRUE, colorkey = TRUE,\n  col.regions = hcl.colors\n)\n\n\n\n\n\n\n图 20.2: 对比无约束和有约束条件下的解\n\n\n\n\nquadprog 包在求解约束条件下的严格凸二次优化问题时，同时给出无约束条件下的解。这个包自定义了一套二次优化问题的符号，查看求解函数 solve.QP() 的说明，略作对应后，求解上述优化问题的代码如下。\n\nlibrary(quadprog)\nsol &lt;- solve.QP(\n  Dmat = Dmat, dvec = -dvec, Amat = t(-Amat), bvec = -bvec\n)\nsol\n\n#&gt; $solution\n#&gt; [1] 0.1666667 1.8333333\n#&gt; \n#&gt; $value\n#&gt; [1] -0.08333333\n#&gt; \n#&gt; $unconstrained.solution\n#&gt; [1] -1.3333333  0.3333333\n#&gt; \n#&gt; $iterations\n#&gt; [1] 2 0\n#&gt; \n#&gt; $Lagrangian\n#&gt; [1] 1.5 0.0 0.0\n#&gt; \n#&gt; $iact\n#&gt; [1] 1\n\n\n其中，返回值的 unconstrained.solution 表示无约束下的解，与预期的解一致，这就没有疑惑了。可见，约束二次优化问题和无约束二次优化问题的求解器不同。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-cone-optimization",
    "href": "numerical-optimization.html#sec-cone-optimization",
    "title": "20  数值优化",
    "section": "\n20.3 凸锥优化",
    "text": "20.3 凸锥优化\n\n20.3.1 锥与凸锥\n二维平面上，圆盘和扇面是凸锥。三维空间中，球，圆锥、椭球、椭圆锥都是凸锥，如 图 20.3 所示。\n\n\n\n\n\n\n\n图 20.3: 常见的三维凸锥\n\n\n\n\n锥定义在对称的矩阵上，凸锥要求矩阵正定。一个 2 阶对称矩阵 \\(A\\) 是正定的\n\\[\nA = \\begin{bmatrix}\n  a_{11} & a_{12}  \\\\\n  a_{21} & a_{22}  \n  \\end{bmatrix}\n\\]\n意味着 \\(a_{11} &gt; 0, a_{22} &gt; 0, a_{12} = a_{21}, a_{11}a_{22} - a_{12}a_{21} &gt; 0\\) 。一般地，将 \\(n\\) 阶半正定的对称矩阵 \\(A\\) 构成的集合记为 \\(\\mathcal{K}_{+}^n\\) 。\n\\[\n\\mathcal{K}_{+}^n = \\{A \\in \\mathbb{R}^{n \\times n}|\\boldsymbol{x}^{\\top}A\\boldsymbol{x} \\geq 0, ~ \\forall \\boldsymbol{x} \\in \\mathbb{R}^n\\}\n\\]\n目标函数为线性的凸锥优化的一般形式如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\\boldsymbol{d}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{x} + \\boldsymbol{k} = \\boldsymbol{b} \\\\\n& \\boldsymbol{k} \\in \\mathcal{K}.\n\\end{aligned}\n\\]\n其中，集合 \\(\\mathcal{K}\\) 是一个非空的封闭凸锥。在一个凸锥里，寻求一个线性目标函数的最小值。专门求解此类问题的 scs 包也在 ROI 包的支持范围内，可以求解的锥优化包括零锥、线性锥、二阶锥、指数锥、幂锥和半正定锥。\n下面举个例子说明凸锥，含参对称矩阵 \\(A(m_1,m_2,m_3)\\) 如下：\n\\[\nA(m_1,m_2,m_3) = \\begin{bmatrix}\n  1 & m_1 & m_2  \\\\\n  m_1 & 1 & m_3  \\\\\n  m_2 & m_3 & 1\n  \\end{bmatrix}.\n\\]\n而 \\(\\boldsymbol{k} = \\boldsymbol{b} - A\\boldsymbol{x}\\) 是非空封闭凸锥集合 \\(\\mathcal{K}\\) 中的元素。半正定矩阵 \\(A\\) 生成的集合（凸锥） \\(K\\) 如下：\n\\[\nK = \\{ (m_1,m_2,m_3) \\in \\mathbb{R}^3 \\mid A(m_1,m_2,m_3) \\in \\mathcal{K}_{+}^3 \\},\n\\]\n集合 \\(K\\) 是有界半正定的，要求含参矩阵 \\(A\\) 的行列式大于等于 0。 矩阵 \\(A\\) 的行列式如下：\n\\[\n\\det(A(m_1,m_2,m_3)) = - (m_1^2 + m_2^2 + m_3^2 -2m_1 m_2 m_3 -1)\n\\]\n集合 \\(K\\) 的边界可表示为如下方程的解：\n\\[\nm_1^2 + m_2^2 + m_3^2 -2m_1 m_2 m_3 = 1\n\\]\n或等价地表示为如下矩阵形式：\n\\[\n\\begin{split}\\left[\n\\begin{array}{c}\nm_1\\\\m_2\n\\end{array}\\right]^{\\top}\n\\left[\\begin{array}{rr}\n1 & -m_3\\\\-m_3 &1\n\\end{array}\\right]\n\\left[\\begin{array}{c}\nm_1\\\\m_2\n\\end{array}\\right] = 1 - m_3^2.\n\\end{split}\n\\]\n当 \\(m_3 = 0\\) 时，集合 \\(K\\) 的边界表示平面上的一个单位圆，当 \\(m_3 \\in [-1, 1]\\) ，集合 \\(K\\) 的边界表示一个椭圆。为了获得一个直观的印象，将集合 \\(K\\) 的边界绘制出来，如 图 20.3 所示，边界是一个三维曲面，曲面及其内部构成一个凸锥。\n\n代码# 分两部分绘图\nfn1 &lt;- function(x) {\n  x[1] * x[2] + sqrt(x[1]^2 * x[2]^2 - x[1]^2 - x[2]^2 + 1)\n}\n\nfn2 &lt;- function(x) {\n  x[1] * x[2] - sqrt(x[1]^2 * x[2]^2 - x[1]^2 - x[2]^2 + 1)\n}\n\ndf2 &lt;- df1 &lt;- expand.grid(\n  x = seq(-1, 1, length.out = 51),\n  y = seq(-1, 1, length.out = 51)\n)\n\n# 计算函数值\ndf1$fnxy &lt;- apply(df1, 1, fn1)\ndf2$fnxy &lt;- apply(df2, 1, fn2)\n# 添加分组变量\ndf1$group &lt;- \"1\"\ndf2$group &lt;- \"2\"\n# 合并数据\ndf &lt;- rbind(df1, df2)\n\n# 绘图\nwireframe(\n  data = df, fnxy ~ x * y, groups = group,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(m[1]),\n  ylab = expression(m[2]),\n  zlab = expression(m[3]),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 20.4: 锥\n\n\n\n\n\n20.3.2 零锥\n零锥的定义如下：\n\\[\n\\mathcal{K}_{zero} = \\{0\\}\n\\]\n常用于表示线性等式约束。\n\n20.3.3 线性锥\n线性锥（Linear Cone）的定义如下：\n\\[\n\\mathcal{K}_{lin} = \\{x \\in \\mathbb{R}|x \\geq 0\\}\n\\]\n常用于表示线性不等式约束。\n\n20.3.4 二阶锥\n二阶锥（Second-order Cone）的定义如下：\n\\[\n\\mathcal{K}_{soc}^{n} = \\{(t,x) \\in \\mathbb{R}^n|x \\in \\mathbb{R}^{n-1}, t\\in\\mathbb{R},\\| x \\|_2 \\leq t\\}\n\\]\n常用于凸二次优化问题。考虑如下二阶锥优化 SOCP 问题：\n\\[\n\\begin{aligned}\n\\max_{(\\boldsymbol{y},t)} \\quad & y_1 + y_2 \\\\\n\\text{s.t.} \\quad & \\sqrt{(2 + 3y_1)^2 + (4+5y_2)^2} \\leq 6 + 7t \\\\\n& y_1,y_2 \\in \\mathbb{R}, ~~ t \\in (-\\infty,9].\n\\end{aligned}\n\\]\n令 \\(\\boldsymbol{x} = (y_1, y_2, t)^{\\top}\\) ，\\(\\boldsymbol{b} = (b_1,b_2,b_3)^\\top\\)\n\\[\nA = \\begin{bmatrix}\n\\boldsymbol{a_1}^{\\top}\\\\\n\\boldsymbol{a_2}^{\\top}\\\\\n\\boldsymbol{a_3}^{\\top}\n\\end{bmatrix}\n\\]\n上述 SOCP 问题的非线性不等式约束等价于\n\\[\n\\sqrt{(b_2 - \\boldsymbol{a_2}^{\\top}\\boldsymbol{x})^2 + (b_3 -\\boldsymbol{a_3}^{\\top}\\boldsymbol{x})^2} \\leq b_1 - \\boldsymbol{a_1}^{\\top}\\boldsymbol{x}\n\\]\n其中，\n\\[\nA = \\begin{bmatrix}\n0 & 0 & -7  \\\\\n-3 & 0 & 0  \\\\\n0 & -5 & 0\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n6 \\\\\n2 \\\\\n4\n\\end{bmatrix}\n\\]\nscs 包不能求解此类优化问题，下面调用 ECOSolveR 包求解。\n\nlibrary(ROI.plugin.ecos)\nop &lt;- OP(\n  objective = c(1, 1, 0),\n  constraints = C_constraint(\n    L = rbind(\n      c(0, 0, -7),\n      c(-3, 0, 0),\n      c(0, -5, 0)\n    ),\n    cones = K_soc(3), rhs = c(6, 2, 4)\n  ), maximum = TRUE,\n  bounds = V_bound(ld = -Inf, ui = 3, ub = 9, nobj = 3)\n)\nsol &lt;- ROI_solve(op, solver = \"ecos\")\n# 最优解\nsol$solution\n\n#&gt; [1] 19.055671  6.300041  9.000000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 25.35571\n\n\n对决策变量 \\(y_1\\) 添加整数约束，则只有 ECOSolveR 包可以求解。\n\nop &lt;- OP(\n  objective = c(1, 1, 0),\n  constraints = C_constraint(\n    L = rbind(\n      c(0, 0, -7),\n      c(-3, 0, 0),\n      c(0, -5, 0)\n    ),\n    cones = K_soc(3), rhs = c(6, 2, 4)\n  ), maximum = TRUE, \n  # 决策变量约束\n  types = c(\"I\", \"C\", \"C\"), \n  bounds = V_bound(ld = -Inf, ui = 3, ub = 9, nobj = 3)\n)\nsol &lt;- ROI_solve(op, solver = \"ecos\")\n# 最优解\nsol$solution\n\n#&gt; [1] 19.000000  6.355418  9.000000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 25.35542\n\n\n\n20.3.5 指数锥\n指数锥（Exponential Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{expp}} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_2 &gt; 0,x_2\\exp\\big(\\frac{x_1}{x_2}\\big) \\leq x_3\\} \\cup \\{(x_1, 0, x_3) \\in \\mathbb{R}^3 | x_1 \\leq 0, x_3 \\geq 0 \\}\n\\]\n它的对偶如下：\n\\[\n\\mathcal{K}_{\\text{expd}} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1 &lt; 0, - x_1\\exp\\big(\\frac{x_2}{x_1}\\big) \\leq \\exp(1)x_3\\} \\cup \\{(0, x_2, x_3) \\in \\mathbb{R}^3 | x_2 , x_3 \\geq 0 \\}\n\\]\n考虑一个锥优化问题\n\\[\n\\begin{aligned}\n\\max_{(\\boldsymbol{x}, \\boldsymbol{t})} \\quad & x_1 + 2 x_2 \\\\\n\\text{s.t.} \\quad & \\exp(7 + 3x_1 + 5 x_2) \\leq 9 + 11 t_1 + 12t_2 \\\\\n\\quad & x_1,x_2 \\in (-\\infty,20], ~ t_1,t_2 \\in (-\\infty, 50]\n\\end{aligned}\n\\]\n约束条件 \\(\\exp(7 + 3x_1 + 5 x_2) \\leq 9 + 11 t_1 + 12t_2\\) 可以用指数锥来表示\n\\[\n\\begin{aligned}\nu &= 7 + 3y_1 + 5y_2 \\\\\nv &= 1 \\\\\nw &= 9 + 11t_1 + 12t_2\n\\end{aligned}\n\\]\n记 \\(\\boldsymbol{x} = (y_1,y_2,t_1,t_2)^{\\top}\\) ，则线性约束矩阵 \\(A\\) 和约束向量 \\(\\boldsymbol{b}\\) 如下：\n\\[\nA = \\begin{bmatrix}\n-3 & -5 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & -11 & -12\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n7 \\\\\n1 \\\\\n9\n\\end{bmatrix}\n\\]\n指数锥用函数 K_expp() 表示，锥优化问题的代码如下：\n\n# 目标优化\nop &lt;- OP(\n  objective = c(1, 2, 0, 0),\n  # 锥约束\n  constraints = C_constraint(L = rbind(\n    c(-3, -5, 0, 0),\n    c(0, 0, 0, 0),\n    c(0, 0, -11, -12)\n  ), cone = K_expp(1), rhs = c(7, 1, 9)),\n  bounds = V_bound(ld = -Inf, ub = c(20, 20, 50, 50)),\n  maximum = TRUE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 4 with\n#&gt; - 4 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'expp'\n#&gt; - 4 lower and 4 upper non-standard variable bounds.\n\n\n对于锥优化，可以调用 scs 包来求解。\n\n# 调用 scs 包\nlibrary(ROI.plugin.scs)\nsol &lt;- ROI_solve(op, solver = \"scs\")\n# 最优解\nsol$solution\n\n#&gt; [1] -33.3148  20.0000  50.0000  50.0000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 6.685201\n\n\n\n20.3.6 幂锥\n一个三维幂锥（Power Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{powp}}^{\\alpha} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1,x_2 \\geq 0,x_1^{\\alpha}x_2^{1-\\alpha} \\geq |x_3| \\}, \\alpha \\in [0,1]\n\\]\n它的对偶形式如下：\n\\[\n\\mathcal{K}_{\\text{powp}}^{\\alpha} = \\Big\\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1,x_2 \\geq 0,\\big(\\frac{x_1}{\\alpha}\\big)^{\\alpha}\\big(\\frac{x_2}{1 - \\alpha}\\big)^{1-\\alpha} \\geq |x_3| \\Big\\}, \\alpha \\in [0,1]\n\\]\n考虑如下锥优化问题\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & 3x_1 + 5 x_2 \\\\\n\\text{s.t.} \\quad & 5 + x_1 \\leq (2 + x_2)^4 \\\\\n\\quad & x_1 \\geq 0, ~ x_2 \\geq 2\n\\end{aligned}\n\\]\n约束条件 \\(5 + x_1 \\leq (2 + x_2)^4\\) 可以重新表示为幂锥\n\\[\n\\begin{aligned}\nu &= 5 + y_1\\\\\nv &= 1 \\\\\nw &= 2 + y_2 \\\\\n\\alpha &= 1/4\n\\end{aligned}\n\\]\n记 \\(\\boldsymbol{x} = (y_1,y_2)^{\\top}\\) ，约束矩阵和约束向量如下\n\\[\nA = \\begin{bmatrix}\n-1  & 0 \\\\\n0   & 0 \\\\\n0   & -1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n5 \\\\\n1 \\\\\n2\n\\end{bmatrix}\n\\]\n幂锥用函数 K_powp() 表示，锥优化问题的代码如下：\n\nA &lt;- rbind(c(-1, 0), c(0, 0), c(0, -1))\ncpowp &lt;- C_constraint(L = A, cones = K_powp(1 / 4), rhs = c(5, 1, 2))\nop &lt;- OP(\n  objective = c(3, 5),\n  constraints = cpowp,\n  bounds = V_bound(lb = c(0, 2))\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'powp'\n#&gt; - 1 lower and 0 upper non-standard variable bounds.\n\n\n\nsol &lt;- ROI_solve(op, solver = \"scs\", max_iter = 1e6)\n# 最优解\nsol$solution\n\n#&gt; [1] 250.998234   2.000352\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 762.9965\n\n\n\n20.3.7 半正定锥\n如果矩阵 \\(A\\) 是半正定的，记为 \\(A \\succeq 0\\) ，如果矩阵 \\(A\\) 是正定的，记为 \\(A \\succ 0\\) 。记 \\(n\\) 阶实对称矩阵的集合为 \\(\\mathcal{S}^{n}\\) 。半正定锥（Positive Semi Definite Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{psd}}^{n} = \\{A | A \\in \\mathcal{S}^{n}, \\boldsymbol{x}^{\\top}A\\boldsymbol{x} \\geq 0, \\forall \\boldsymbol{x} \\in \\mathbb{R}^n \\}\n\\]\n考虑如下锥优化问题\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & x_1 + x_2 - x_3 \\\\\n\\text{s.t.} \\quad &\nx_1 \\begin{bmatrix}\n10  & 3 \\\\\n3   & 10\n\\end{bmatrix} +\nx_2 \\begin{bmatrix}\n6  & -4 \\\\\n-4   & 10\n\\end{bmatrix} +\nx_3 \\begin{bmatrix}\n8  & 1 \\\\\n1  & 6\n\\end{bmatrix} \\preceq\n\\begin{bmatrix}\n16  & -13 \\\\\n-13  & 60\n\\end{bmatrix}\n\\\\\n\\quad & x_1,x_2,x_3 \\geq 0\n\\end{aligned}\n\\]\n函数 K_psd() 表示半正定锥，函数 vech() 将对称矩阵的上三角部分拉成一个向量。\n\n(A &lt;- toeplitz(x = 3:1))\n\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    3    2    1\n#&gt; [2,]    2    3    2\n#&gt; [3,]    1    2    3\n\nvech(A)\n\n#&gt;      [,1]\n#&gt; [1,]    3\n#&gt; [2,]    2\n#&gt; [3,]    1\n#&gt; [4,]    3\n#&gt; [5,]    2\n#&gt; [6,]    3\n\n\n锥优化的表示如下\n\nF1 &lt;- rbind(c(10, 3), c(3, 10))\nF2 &lt;- rbind(c(6, -4), c(-4, 10))\nF3 &lt;- rbind(c(8, 1), c(1, 6))\nF0 &lt;- rbind(c(16, -13), c(-13, 60))\n# 目标优化\nop &lt;- OP(\n  objective = L_objective(c(1, 1, -1)),\n  constraints = C_constraint(\n    L = vech(F1, F2, F3),\n    cones = K_psd(3),\n    rhs = vech(F0)\n  )\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 3 with\n#&gt; - 3 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'psd'\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n仍然调用 scs 包求解器。\n\nsol &lt;- ROI_solve(op, solver = \"scs\")\n# 最优解\nsol$solution\n\n#&gt; [1] 5.782736e-06 1.065260e-06 1.486444e+00\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] -1.486437",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-nonlinear-optimization",
    "href": "numerical-optimization.html#sec-nonlinear-optimization",
    "title": "20  数值优化",
    "section": "\n20.4 非线性优化",
    "text": "20.4 非线性优化\n非线性优化按是否带有约束，以及约束是线性还是非线性，分为无约束优化、箱式约束优化、线性约束优化和非线性约束优化。箱式约束可看作是线性约束的特殊情况。\n\nR 软件内置的非线性优化函数\n\n\nnlm()\nnlminb()\nconstrOptim()\noptim()\n\n\n\n无约束\n支持\n支持\n不支持\n支持\n\n\n箱式约束\n不支持\n支持\n支持\n支持\n\n\n线性约束\n不支持\n不支持\n支持\n不支持\n\n\n\nR 软件内置的 stats 包有 4 个数值优化方面的函数，函数 nlm() 可求解无约束优化问题，函数 nlminb() 可求解无约束、箱式约束优化问题，函数 constrOptim() 可求解箱式和线性约束优化。函数 optim() 是通用型求解器，包含多个优化算法，可求解无约束、箱式约束优化问题。尽管这些函数在 R 语言中长期存在，在统计中有广泛的使用，如非线性最小二乘 stats::nls()，极大似然估计 stats4::mle() 和广义最小二乘估计 nlme::gls() 等。但是，这些优化函数的求解能力有重合，使用语法不尽相同，对于非线性约束无能为力，下面仍然主要使用 ROI 包来求解多维非线性优化问题。\n\n20.4.1 一元非线性优化\n求如下一维分段非线性函数的最小值，其函数图像见 图 20.5 ，这个函数是不连续的，更不光滑。\n\\[\nf(x) =\n\\begin{cases}\n10 & x \\in (-\\infty,-1]  \\\\\n\\exp(-\\frac{1}{|x-1|}) & x \\in (-1,4) \\\\\n10 & x \\in [4, +\\infty)\n\\end{cases}\n\\]\n\nfn &lt;- function(x) ifelse(x &gt; -1, ifelse(x &lt; 4, exp(-1 / abs(x - 1)), 10), 10)\n\n\n代码op &lt;- par(mar = c(4, 4, 0.5, 0.5))\ncurve(\n  expr = fn, from = -2, to = 5, lwd = 2,\n  panel.first = grid(),\n  xlab = \"$x$\", ylab = \"$f(x)$\"\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 20.5: 一维函数图像\n\n\n\n\n函数 optimize() 可以求解一元函数的极值问题，默认求极小值，参数 f 表示目标函数，参数 interval 表示搜索在此区间内最小值。函数返回一个列表，元素 minimum 表示极小值点，objective 表示极值点对应的目标函数值。\n\noptimize(f = fn, interval = c(-4, 20), maximum = FALSE)\n\n#&gt; $minimum\n#&gt; [1] 19.99995\n#&gt; \n#&gt; $objective\n#&gt; [1] 10\n\noptimize(f = fn, interval = c(-7, 20), maximum = FALSE)\n\n#&gt; $minimum\n#&gt; [1] 0.9992797\n#&gt; \n#&gt; $objective\n#&gt; [1] 0\n\n\n值得注意，对于不连续的分段函数，在不同的区间内搜索极值，可能获得不同的结果，可以绘制函数图像帮助选择最小值。\n\n20.4.2 多元隐函数优化\n这个优化问题来自 1stOpt 软件的帮助文档，下面利用 R 语言来求该多元隐函数的极值。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} y = & ~\\sin\\Big((yx_1 -0.5)^2 + 2x_1 x_2^2 - \\frac{y}{10} \\Big)\\cdot \\\\\n&~\\exp\\Big(-\\Big( \\big(x_1 - 0.5 -\\exp(-x_2 + y)\\big)^2 + x_2^2 - \\frac{y}{5} + 3 \\Big)\\Big)\n\\end{aligned}\n\\]\n其中， \\(x_1 \\in [-1,7],x_2 \\in [-2,2]\\) 。\n对于隐函数 \\(f(x_1,x_2,y)=0\\) ，常规的做法是先计算隐函数的偏导数，并令偏导数为 0，再求解非线性方程组，得到各个驻点，最后，将驻点代入原方程，比较驻点处函数值，根据优化目标选择最大或最小值。\n\\[\n\\begin{aligned}\n\\frac{\\partial f(x_1,x_2,y)}{\\partial x_1} = 0 \\\\\n\\frac{\\partial f(x_1,x_2,y)}{\\partial x_2} = 0\n\\end{aligned}\n\\]\n如果目标函数很复杂，隐函数偏导数难以计算，可以考虑暴力网格搜索。先估计隐函数值 \\(z\\) 的大致范围，给定 \\(x,y\\) 时，计算一元非线性方程的根。\n\nfn &lt;- function(m) {\n  subfun &lt;- function(x) {\n    f1 &lt;- (m[1] * x - 0.5)^2 + 2 * m[1] * m[2]^2 - x / 10\n    f2 &lt;- -((m[1] - 0.5 - exp(-m[2] + x))^2 + m[2]^2 - x / 5 + 3)\n    x - sin(f1) * exp(f2)\n  }\n  uniroot(f = subfun, interval = c(-1, 1))$root\n}\n\n在位置 \\((1,2)\\) 处函数值为 0.0007368468。\n\n# 测试函数 fn\nfn(m = c(1, 2))\n\n#&gt; [1] 0.0007368468\n\n\n将目标区域网格化，通过一元非线性方程求根的方式获得每个格点处的函数值。\n\ndf &lt;- expand.grid(\n  x1 = seq(from = -1, to = 7, length.out = 81),\n  x2 = seq(from = -2, to = 2, length.out = 41)\n)\n# 计算格点处的函数值\ndf$fn &lt;- apply(df, 1, FUN = fn)\n\n在此基础上，绘制隐函数图像，如 图 20.6 所示，可以获得关于隐函数的大致情况。\n\n代码# 绘图\nwireframe(\n  data = df, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 20.6: 隐函数图像\n\n\n\n\n最后，获得暴力网格搜索的结果，目标函数在 \\((2.8,-0.9)\\) 处取得最小值 \\(-0.02159723\\)。总的来说，这是一个近似结果，如果进一步缩小搜索区域，将网格划分得越细，搜索的结果将越接近全局最小值。\n\ndf[df$fn == min(df$fn), ]\n\n#&gt;      x1   x2          fn\n#&gt; 930 2.8 -0.9 -0.02159723\n\n\n将求隐函数极值的问题转为含非线性等式约束的非线性优化问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & y \\\\\n\\text{s.t.} \\quad & f(x_1,x_2,y) = 0\n\\end{aligned}\n\\]\n由于等式约束非常复杂，手动计算等式约束的雅可比矩阵不可行，可以用 numDeriv 包的函数 jacobian() 计算等式约束的雅可比矩阵。考虑到本例中仅含有一个等式约束，雅可比矩阵退化为梯度向量，这可以用 numDeriv 包的另一个函数 grad() 计算。\n\n# 等式约束\nheq &lt;- function(x) {\n  f1 &lt;- (x[1] * x[3] - 0.5)^2 + 2 * x[1] * x[2]^2 - x[3] / 10\n  f2 &lt;- (x[1] - 0.5 - exp(-x[2] + x[3]))^2 + x[2]^2 - x[3] / 5 + 3\n  x[3] - sin(f1) * exp(-f2)\n}\n# 等式约束的梯度\nheq.jac &lt;- function(x) {\n  numDeriv::grad(func = heq, x = x)\n}\n\n函数 L_objective() 表示含 1 个决策变量的线性目标函数，函数 F_constraint() 表示非线性等式约束。\n\n# 定义优化问题\nop &lt;- OP(\n  objective = L_objective(L = c(0, 0, 1)),\n  constraints = F_constraint(\n    # 等式约束\n    F = list(heq = heq),\n    dir = \"==\",\n    rhs = 0,\n    # 等式约束的雅可比\n    J = list(heq.jac = heq.jac)\n  ),\n  bounds = V_bound(\n    ld = -Inf, ud = Inf,\n    li = c(1, 2), ui = c(1, 2),\n    lb = c(-1, -2), ub = c(7, 2),\n    nobj = 3L\n  ),\n  maximum = FALSE # 求最小\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 3 with\n#&gt; - 3 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 1 constraint of type nonlinear.\n#&gt; - 3 lower and 2 upper non-standard variable bounds.\n\n\n将网格搜索的结果作为初值，继续寻找更优的目标函数值。\n\nnlp &lt;- ROI_solve(op,\n  solver = \"nloptr.slsqp\", start = c(2.8, -0.9, -0.02159723)\n)\n# 最优解\nnlp$solution\n\n#&gt; [1]  2.89826224 -0.85731584 -0.02335409\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] -0.02335409\n\n\n可以发现，更优的目标函数值 \\(-0.02335\\) 在 \\((2.898,-0.8573)\\) 取得。\n\n20.4.3 多元无约束优化\n\n20.4.3.1 示例 1\nRastrigin 函数是一个 \\(n\\) 维优化问题测试函数。\n\\[\n\\min_{\\boldsymbol{x}} \\sum_{i=1}^{n}\\big(x_i^2 - 10 \\cos(2\\pi x_i) + 10\\big)\n\\]\n计算函数值的 R 代码如下：\n\nfn &lt;- function(x) {\n  sum(x^2 - 10 * cos(2 * pi * x) + 10)\n}\n\n绘制二维情形下的 Rastrigin 函数图像，如 图 20.7 所示，这是一个多模态的函数，有许多局部极小值。如果采用 BFGS 算法寻优容易陷入局部极值点。\n\n代码df &lt;- expand.grid(\n  x = seq(-4, 4, length.out = 151),\n  y = seq(-4, 4, length.out = 151)\n)\n\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 20.7: 二维 Rastrigin 函数图像\n\n\n\n\n不失一般性，考虑函数维数 \\(n=20\\) ，决策变量 \\(x_i \\in [-50,50], i = 1,2,\\ldots,n\\) 的情况。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 20L),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 20L)\n)\n\n调全局优化器求解优化问题。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\n# 最优解\nnlp$solution\n\n#&gt;  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 0\n\n\n\n代码# R 语言内置的非线性优化函数\n# 无约束\nnlm(f = fn, p = rep(1, 20))\noptim(par = rep(1, 20), fn = fn, method = \"BFGS\")\noptim(par = rep(1, 20), fn = fn, method = \"Nelder-Mead\")\n\n# 箱式约束\noptim(par = rep(1, 20), fn = fn, \n      lower = -50, upper = 50, method = \"L-BFGS-B\")\nnlminb(start = rep(1, 20), objective = fn, lower = -50, upper = 50)\nconstrOptim(\n  theta = rep(1, 20), f = fn, grad = NULL,\n  ui = rbind(diag(rep(1, 20)), diag(rep(-1, 20))),\n  ci = c(rep(-50, 20), rep(-50, 20))\n)\n\n\n\n20.4.3.2 示例 2\n下面这个优化问题来自 1stOpt 软件帮助手册，是一个无约束非线性优化问题，它的目标函数非常复杂，一般的求解器都无法求解。最优解在 \\((7.999982, 7.999982)\\) 取得，目标函数值为 -7.978832。\n\\[\n\\begin{aligned}\n  & \\min_{\\boldsymbol{x}} ~ \\cos(x_1)\\cos(x_2) - \\sum_{i=1}^{5}\\Big( (-1)^i \\cdot i \\cdot 2 \\cdot \\exp\\big(-500 \\cdot ( (x_1 - i \\cdot 2)^2 + (x_2 - i\\cdot 2)^2 ) \\big) \\Big)\n\\end{aligned}\n\\]\n目标函数分两步计算，先计算累加部分的通项，然后代入计算目标函数。\n\nsubfun &lt;- function(i, m) {\n  (-1)^i * i * 2 * exp(-500 * ((m[1] - i * 2)^2 + (m[2] - i * 2)^2))\n}\nfn &lt;- function(x) {\n  cos(x[1]) * cos(x[2]) -\n    sum(mapply(FUN = subfun, i = 1:5, MoreArgs = list(m = x)))\n}\n\n直观起见，绘制目标函数在区域 \\([-50, 50] \\times [-50, 50]\\) 内的图像，如 图 20.8 (a) 所示，可以看到几乎没有变化的梯度，给寻优过程带来很大困难。再将区域 \\([0, 12] \\times [0, 12]\\) 上的三维图像绘制出来，如 图 20.8 (b) 所示，可见，有不少局部陷阱，且分布在 \\(x_2 = x_1\\) 的直线上。\n代码df &lt;- expand.grid(\n  x = seq(-50, 50, length.out = 101),\n  y = seq(-50, 50, length.out = 101)\n)\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\ndf &lt;- expand.grid(\n  x = seq(0, 12, length.out = 151),\n  y = seq(0, 12, length.out = 151)\n)\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90), alpha = 0.75, \n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n\n\n\n(a) 区域 \\([-50,50]\\times[-50,50]\\) 内的函数图像\n\n\n\n\n\n\n\n\n\n\n\n(b) 区域 \\([0,12]\\times[0,12]\\) 内的函数图像\n\n\n\n\n\n\n图 20.8: 局部放大前后的函数图像\n\n\n不失一般性，下面考虑 \\(x_1,x_2 \\in [-50,50]\\) ，面对如此复杂的函数，调用全局优化器 nloptr.directL 寻优。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 2L),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 2L)\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\nnlp$solution\n\n#&gt; [1]  0.00000 22.22222\n\nnlp$objval\n\n#&gt; [1] -0.9734211\n\n\n结果还是陷入局部最优解。运筹优化方面的商业软件，著名的有 Lingo 和 Matlab，下面采用 Lingo 20 求解，Lingo 代码如下：\nSETS:\nP/1..5/;\nEndsets\nMin=@cos(x1) * @cos(x2) - @Sum(P(j): (-1)^j * j * 2 * @exp(-500 * ((x1 - j * 2)^2 + (x2 - j * 2)^2)));\n@Bnd(-50, x1, 50);\n@Bnd(-50, x2, 50);\n启用全局优化求解器后，在 \\((x_1 = 7.999982, x_2 = 7.999982)\\) 取得最小值 -7.978832。而默认未启用全局优化求解器的情况下，在 \\((x_1 = 18.84956, x_2 = -40.84070)\\) 取得局部极小值 -1.000000。\n在这种情况下，数值优化算法遇到瓶颈，可以采用一些全局随机优化算法，比如 GA 包 (Scrucca 2013) 实现的遗传算法。经过对参数的一些调优，可以获得与商业软件几乎一样的结果。\n\nnlp &lt;- GA::ga(\n  type = \"real-valued\",\n  fitness = function(x) -fn(x),\n  lower = c(0, 0), upper = c(12, 12),\n  popSize = 500, maxiter = 100, \n  monitor = FALSE, seed = 20232023\n)\n# 最优解\nnlp@solution\n\n#&gt;            x1       x2\n#&gt; [1,] 7.999982 7.999981\n\n# 目标函数值\nnlp@fitnessValue\n\n#&gt; [1] 7.978832\n\n\n其中，参数 type 指定决策变量的类型，type = \"real-valued\" 表示目标函数中的决策变量是实值连续的，参数 fitness 是目标函数，函数 ga() 对目标函数求极大，所以，对当前优化问题，添加了一个负号。 参数 popSize 控制种群大小，值越大，运行时间越长，搜索范围越广，获得的全局优化解越好。对于复杂的优化问题，可以不断增加种群大小来寻优，直至增加种群大小也不能获得更好的解。参数 maxiter 控制种群进化的次数，值越大，搜索次数可以越多，获得的解越好。参数 popSize 的影响大于参数 maxiter ，减少陷入局部最优解（陷阱）的可能。根据已知条件尽可能缩小可行域，以减少种群数量，进而缩短算法迭代时间。\n\n20.4.4 多元箱式约束优化\n有如下带箱式约束的多元非线性优化问题，该示例来自函数 nlminb() 的帮助文档，如果没有箱式约束，全局极小值点在 \\((1,1,\\cdots,1)\\) 处取得。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & (x_1 - 1)^2 + 4\\sum_{i =1}^{n -1}(x_{i+1} -x_i^2)^2  \\\\\n  \\text{s.t.} \\quad &  2 \\leq x_1,x_2,\\cdots,x_n \\leq 4\n\\end{aligned}\n\\]\nR 语言编码的函数代码如下：\n\nfn &lt;- function(x) {\n  n &lt;- length(x)\n  sum(c(1, rep(4, n - 1)) * (x - c(1, x[-n])^2)^2)\n}\n\n在二维的情形下，可以绘制目标函数的三维图像，见 图 20.9 ，函数曲面和香蕉函数有些相似。\n\n代码dat &lt;- expand.grid(\n  x1 = seq(from = 0, to = 4, length.out = 41),\n  x2 = seq(from = 0, to = 4, length.out = 41)\n)\ndat$fn &lt;- apply(dat, 1, fn)\n\nwireframe(\n  data = dat, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 20.9: 类香蕉函数的曲面图\n\n\n\n\nBase R 有 3 个函数可以求解这个优化问题，分别是 nlminb() 、constrOptim()和optim() ，因此，不妨在这个示例上，用这 3 个函数分别求解该优化问题，介绍它们的用法，最后，介绍 ROI 包实现的方法。这个优化问题的目标函数是 \\(n\\) 维非线性的，不失一般性，又不让问题变得太过简单，下面考虑 25 维的情况，\n\n20.4.4.1 nlminb()\n\n函数 nlminb() 参数 start 指定迭代初始值，参数 objective 指定目标函数，参数 lower 和 upper 分别指定箱式约束中的下界和上界。给定初值 \\((3, 3, \\cdots, 3)\\)，下界 \\((2,2,\\cdots,2)\\) 和上界 \\((4,4,\\cdots,4)\\) 。nlminb() 帮助文档说该函数出于历史兼容性的原因尚且存在，一般来说，这个函数会一直维护下去的。\n\nnlminb(\n  start = rep(3, 25), objective = fn,\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093\n#&gt; [25] 4.000000\n#&gt; \n#&gt; $objective\n#&gt; [1] 368.1059\n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $iterations\n#&gt; [1] 6\n#&gt; \n#&gt; $evaluations\n#&gt; function gradient \n#&gt;       10      177 \n#&gt; \n#&gt; $message\n#&gt; [1] \"relative convergence (4)\"\n\n\n从返回结果来看，求解过程成功收敛，最优解的前 23 个决策变量取值为 2，在箱式约束的边界上，第 24 个分量没有边界上，而在内部，第 25 个决策变量取值为 4，也在边界上。目标函数值为 368.1059。\n\n20.4.4.2 constrOptim()\n\n使用 constrOptim() 函数求解，默认求极小，需将箱式或线性不等式约束写成矩阵形式，即 \\(Ax \\geq b\\) 的形式，参数 ui 是 \\(k \\times n\\) 的约束矩阵 \\(A\\)，ci 是右侧 \\(k\\) 维约束向量 \\(b\\)。以上面的优化问题为例，将箱式约束 \\(2 \\leq x_1,x_2 \\leq 4\\) 转化为矩阵形式，约束矩阵和向量分别为：\n\\[\nA = \\begin{bmatrix}\n1  & 0  \\\\\n0  & 1 \\\\\n-1 & 0 \\\\\n0  & -1\n\\end{bmatrix}, \\quad\nb = \\begin{bmatrix}\n2 \\\\\n2 \\\\\n-4 \\\\\n-4\n\\end{bmatrix}\n\\]\n\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  method = \"Nelder-Mead\", # 没有提供梯度，则必须用 Nelder-Mead 方法\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.006142 2.002260 2.003971 2.003967 2.004143 2.004255 2.001178 2.002990\n#&gt;  [9] 2.003883 2.006029 2.017345 2.009236 2.000949 2.007793 2.025831 2.007896\n#&gt; [17] 2.004514 2.004381 2.008771 2.015695 2.005803 2.009127 2.017988 2.257782\n#&gt; [25] 3.999846\n#&gt; \n#&gt; $value\n#&gt; [1] 378.4208\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    12048       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 1\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 25\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003278963\n\n\n返回结果中 convergence = 1 表示迭代次数到达默认的极限 maxit = 500 。参考函数 nlminb() 的求解结果，可知还没有收敛。如果没有提供梯度，则必须用 Nelder-Mead 方法，下面增加迭代次数到 1000。\n\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  method = \"Nelder-Mead\", \n  control = list(maxit = 1000),\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.000081 2.000142 2.001919 2.000584 2.000007 2.000003 2.001097 2.001600\n#&gt;  [9] 2.000207 2.000042 2.000250 2.000295 2.000580 2.002165 2.000453 2.000932\n#&gt; [17] 2.000456 2.000363 2.000418 2.000474 2.009483 2.001156 2.003173 2.241046\n#&gt; [25] 3.990754\n#&gt; \n#&gt; $value\n#&gt; [1] 370.8601\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    18036       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 1\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 19\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003366467\n\n\n结果有改善，目标函数值从 378.4208 减小到 370.8601，但还是没有收敛，可见 Nelder-Mead 方法在这个优化问题上收敛速度比较慢。下面考虑调用基于梯度的 BFGS 优化算法，这得先计算出来目标函数的梯度。\n\n# 输入 n 维向量，输出 n 维向量\ngr &lt;- function(x) {\n  n &lt;- length(x)\n  c(2 * (x[1] - 2), rep(0, n - 1))\n  +8 * c(0, x[-1] - x[-n]^2)\n  -16 * c(x[-n], 0) * c(x[-1] - x[-n]^2, 0)\n}\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  grad = gr,\n  method = \"BFGS\", \n  control = list(maxit = 1000),\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000001\n#&gt; [25] 3.000000\n#&gt; \n#&gt; $value\n#&gt; [1] 373\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;     3721      464 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 3\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003327104\n\n\n从结果来看，虽然已经收敛，但相比于 Nelder-Mead 方法，目标函数值变大了，可见已陷入局部最优解。\n\n20.4.4.3 optim()\n\n下面再使用函数 optim() 提供的 L-BFGS-B 算法求解优化问题。\n\noptim(\n  par = rep(3, 25), fn = fn, gr = NULL, method = \"L-BFGS-B\",\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093\n#&gt; [25] 4.000000\n#&gt; \n#&gt; $value\n#&gt; [1] 368.1059\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;        6        6 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH\"\n\n\n发现结果和函数 nlminb() 的结果差不多了。\n\noptim(\n  par = rep(3, 25), fn = fn, gr = gr, method = \"L-BFGS-B\",\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n#&gt; \n#&gt; $value\n#&gt; [1] 373\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;        2        2 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: NORM OF PROJECTED GRADIENT &lt;= PGTOL\"\n\n\n然而，当在函数 optim() 里提供梯度信息的时候，虽然目标函数及梯度的计算次数变少了，求解速度提升了，但是最优解反而变差了，最优解和在函数 constrOptim() 中设置 method = \"BFGS\" 算法基本一致。\n\n20.4.4.4 ROI 包\n下面通过 ROI 包，分别调用求解器 nloptr.lbfgs 和 nloptr.directL ，发现前者同样陷入局部最优解，而后者可以获得与 nlminb() 函数一致的结果。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 25L, G = gr),\n  bounds = V_bound(ld = 2, ud = 4, nobj = 25L)\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.lbfgs\", start = rep(3, 25))\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 373\n\n# 最优解\nnlp$solution\n\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n\n\n调全局优化算法。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 368.1061\n\n# 最优解\nnlp$solution\n\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093\n#&gt; [25] 4.000000\n\n\n\n20.4.5 多元线性约束优化\n对于带线性约束的多元非线性优化问题，Base R 提供函数 constrOptim() 来求解，下面的示例来自其帮助文档，这是一个带线性约束的二次规划问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}}\n\\quad &  - \\begin{bmatrix}\n0 \\\\\n5 \\\\\n0\n\\end{bmatrix}^{\\top} \\boldsymbol{x} +\\frac{1}{2} \\boldsymbol{x}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\begin{bmatrix}\n-4  &  2  &  0 \\\\\n-3  &  1  & -2 \\\\\n0  &  0  &  1\n\\end{bmatrix}^{\\top}\\boldsymbol{x} \\geq \\begin{bmatrix}\n-8 \\\\\n2 \\\\\n0\n\\end{bmatrix}\n\\end{aligned}\n\\]\n\nfQP &lt;- function(x) {\n  -sum(c(0, 5, 0) * x) + 0.5 * sum(x * x)\n}\nAmat &lt;- matrix(c(-4, -3, 0, 2, 1, 0, 0, -2, 1),\n  ncol = 3, nrow = 3, byrow = FALSE\n)\nbvec &lt;- c(-8, 2, 0)\n# 目标函数的梯度\ngQP &lt;- function(x) {\n  -c(0, 5, 0) + x\n}\nconstrOptim(\n  theta = c(2, -1, -1), \n  f = fQP, g = gQP, \n  ui = t(Amat), ci = bvec\n)\n\n#&gt; $par\n#&gt; [1] 0.4761908 1.0476188 2.0952376\n#&gt; \n#&gt; $value\n#&gt; [1] -2.380952\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;      406       81 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 3\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.0006243894\n\n\n在上一节，箱式约束可以看作线性约束的一种特殊情况，ROI 包是支持箱式、线性、二次、锥和非线性约束的。因此，下面给出调用 ROI 包求解上述优化问题的代码。\n\nDmat &lt;- diag(rep(1,3))\ndvec &lt;- c(0, 5, 0)\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = -dvec),\n  constraints = L_constraint(L = t(Amat), dir = rep(\"&gt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(0, 1, 2))\n# 最优解\nnlp$solution\n\n#&gt; [1] 0.4761905 1.0476190 2.0952381\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] -2.380952\n\n\n可见输出结果与函数 constrOptim() 是一致的。\n\n代码# quadprog\nlibrary(quadprog)\nsol &lt;- solve.QP(\n  Dmat = Dmat, dvec = dvec, Amat = Amat, bvec = bvec\n)\nsol\n\n\n\n20.4.6 多元非线性约束优化\nnloptr 包的非线性优化能力覆盖开源优化软件 Octave 和 Ipopt 。通过插件包 ROI.plugin.nloptr，ROI 包可以调用 nloptr 包内置的所有求解器，常用的求解器见下表。表中从优化器类型（局部还是全局优化器），支持的约束条件类型（箱式还是非线性），是否需要提供目标函数的梯度、黑塞和约束条件的雅可比矩阵信息等方面归纳各个求解器的能力。\n\n常用的非线性优化求解器\n\n求解器\n类型\n约束\n梯度\n黑塞\n雅可比\n\n\n\nnloptr.lbfgs\n局部\n箱式\n需要\n不需要\n不需要\n\n\nnloptr.slsqp\n局部\n非线性\n需要\n不需要\n需要\n\n\nnloptr.auglag\n局部\n非线性\n需要\n不需要\n需要\n\n\nnloptr.directL\n全局\n箱式\n不需要\n不需要\n不需要\n\n\nnloptr.isres\n全局\n非线性\n不需要\n不需要\n不需要\n\n\n\n\n20.4.6.1 非线性等式约束\n下面这个示例来自 Octave 软件的非线性优化帮助文档，Octave 中的函数 sqp() 使用序列二次优化求解器（successive quadratic programming solver）求解非线性优化问题，示例中该优化问题包含多个非线性等式约束。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &  \\exp\\big(\\prod_{i=1}^{5} x_i\\big) - \\frac{1}{2}(x_1^3 + x_2^3 + 1)^2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n   \\sum_{i=1}^{5}x_i^2 - 10 = 0 \\\\\n   x_2 x_3 - 5x_4 x_5 = 0 \\\\\n   x_1^3 + x_2^3 + 1 = 0\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n目标函数是非线性的，有 5 个变量，约束条件也是非线性的，有 3 个等式约束。先手动计算目标函数的梯度，等式约束的雅可比矩阵。\n\n# 目标函数\nfn &lt;- function(x) {\n  exp(prod(x)) - 0.5 * (x[1]^3 + x[2]^3 + 1)^2\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    exp(prod(x)) * prod(x[-1]) - 3 * (x[1]^3 + x[2]^3 + 1) * x[1]^2,\n    exp(prod(x)) * prod(x[-2]) - 3 * (x[1]^3 + x[2]^3 + 1) * x[2]^2,\n    exp(prod(x)) * prod(x[-3]),\n    exp(prod(x)) * prod(x[-4]),\n    exp(prod(x)) * prod(x[-5])\n  )\n}\n# 等式约束\nheq &lt;- function(x) {\n  c(\n    sum(x^2) - 10,\n    x[2] * x[3] - 5 * x[4] * x[5],\n    x[1]^3 + x[2]^3 + 1\n  )\n}\n# 等式约束的雅可比矩阵\nheq.jac &lt;- function(x) {\n  matrix(c(2 * x[1], 2 * x[2], 2 * x[3], 2 * x[4], 2 * x[5],\n    0, x[3], x[2], -5 * x[5], -5 * x[4],\n    3 * x[1]^2, 3 * x[2]^2, 0, 0, 0),\n    ncol = 5, byrow = TRUE\n  )\n}\n\n在 OP() 函数里定义目标优化的各个成分。\n\n# 定义目标优化\nop &lt;- OP(\n  # 5 个决策变量\n  objective = F_objective(F = fn, n = 5L, G = gr), \n  constraints = F_constraint(\n    F = list(heq = heq),\n    dir = \"==\",\n    rhs = 0,\n    # 等式约束的雅可比矩阵\n    J = list(heq.jac = heq.jac)\n  ),\n  bounds = V_bound(ld = -Inf, ud = Inf, nobj = 5L),\n  maximum = FALSE # 求最小\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a nonlinear objective function of length 5 with\n#&gt; - 5 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 1 constraint of type nonlinear.\n#&gt; - 5 lower and 0 upper non-standard variable bounds.\n\n\n调用 SQP（序列二次优化） 求解器 nloptr.slsqp 。\n\nnlp &lt;- ROI_solve(op,\n  solver = \"nloptr.slsqp\",\n  start = c(-1.8, 1.7, 1.9, -0.8, -0.8)\n)\n# 最优解\nnlp$solution\n\n#&gt; [1] -1.7171435  1.5957096  1.8272458 -0.7636431 -0.7636431\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 0.05394985\n\n\n计算结果和 Octave 的示例一致。\n\n20.4.6.2 多种非线性约束\n\n非线性等式约束\n非线性不等式约束，不等式约束包含等号\n箱式约束\n\n此优化问题来源于 Ipopt 官网的帮助文档，约束条件比较复杂。提供的初始值为 \\(x_0 = (1,5,5,1)\\)，最优解为 \\(x_{\\star} = (1.00000000,4.74299963,3.82114998,1.37940829)\\)。优化问题的具体内容如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} & \\quad x_1 x_4 (x_1 + x_2 + x_3) + x_3 \\\\\n\\text{s.t.} & \\quad \\left\\{\n    \\begin{array}{l}\n     x_1^2 + x_2^2 + x_3^2 + x_4^2 = 40 \\\\\n     x_1 x_2 x_3 x_4 \\geq 25 \\\\\n     1 \\leq x_1, x_2, x_3, x_4 \\leq 5\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n下面用 ROI 调 nloptr 包求解，看结果是否和例子一致，nloptr 支持箱式约束且支持不等式约束包含等号。\n\n# 一个 4 维的目标函数\nfn &lt;- function(x) {\n  x[1] * x[4] * (x[1] + x[2] + x[3]) + x[3]\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    x[4] * (2 * x[1] + x[2] + x[3]), x[1] * x[4],\n    x[1] * x[4] + 1, x[1] * (x[1] + x[2] + x[3])\n  )\n}\n# 等式约束\nheq &lt;- function(x) {\n  sum(x^2)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  2 * c(x[1], x[2], x[3], x[4])\n}\n# 不等式约束\nhin &lt;- function(x) {\n  prod(x)\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x) {\n  c(prod(x[-1]), prod(x[-2]), prod(x[-3]), prod(x[-4]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, n = 4L, G = gr), # 4 个决策变量\n  constraints = F_constraint(\n    F = list(heq = heq, hin = hin),\n    dir = c(\"==\", \"&gt;=\"),\n    rhs = c(40, 25),\n    # 等式和不等式约束的雅可比\n    J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n  ),\n  bounds = V_bound(ld = 1, ud = 5, nobj = 4L),\n  maximum = FALSE # 求最小\n)\n\n作为对比参考，先计算目标函数的初始值和最优值。\n\n# 目标函数初始值\nfn(c(1, 5, 5, 1))\n\n#&gt; [1] 16\n\n# 目标函数最优值\nfn(c(1.00000000, 4.74299963, 3.82114998, 1.37940829))\n\n#&gt; [1] 17.01402\n\n\n求解一般的非线性约束问题。\n\n求解器 nloptr.mma / nloptr.cobyla 仅支持非线性不等式约束，不支持等式约束。\n函数 nlminb() 只支持等式约束。\n\n因此，下面分别调用 nloptr.auglag、nloptr.slsqp 和 nloptr.isres 来求解上述优化问题。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.auglag\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.000000 4.743174 3.820922 1.379440\n\nnlp$objval\n\n#&gt; [1] 17.01402\n\n\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.000000 4.742996 3.821155 1.379408\n\nnlp$objval\n\n#&gt; [1] 17.01402\n\n\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.isres\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.276795 4.607639 3.992841 1.093756\n\nnlp$objval\n\n#&gt; [1] 17.78648\n\n\n可以看出，nloptr 提供的优化能力可以覆盖 Ipopt 求解器，从以上求解的情况来看，推荐使用 nloptr.slsqp 求解器，这也是 Octave 的选择。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-integer-linear-optimization",
    "href": "numerical-optimization.html#sec-integer-linear-optimization",
    "title": "20  数值优化",
    "section": "\n20.5 整数优化",
    "text": "20.5 整数优化\n整数优化情况有很多，篇幅所限，仅考虑以下几类常见情形：\n\n目标函数和约束条件为线性，变量取值都为整数的整数优化。\n目标函数和约束条件为线性，变量取值为 0 或 1 的 0-1 整数优化。\n目标函数和约束条件为线性，部分变量带有整数约束的混合整数线性优化。\n目标函数为凸二次、约束条件为线性，部分变量是整数的混合整数二次优化。\n目标函数和约束条件为非线性，部分变量是整数的混合整数非线性优化。\n\n\n20.5.1 纯整数线性优化\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & -2x_1 - x_2 - 4x_3 -3x_4 -x_5\\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    2x_2 + x_3 + 4x_4 + 2x_5 &lt; 54 \\\\\n    3x_1 + 4x_2 + 5x_3 - x_4 - x_5 &lt; 62 \\\\\n    x_1,x_2 \\in [0,100] \\quad x_3 \\in [3, 100] \\\\\n    x_4 \\in [0,100] \\quad x_5 \\in [2,100] \\\\\n    x_i \\in \\mathbb{Z}, ~ i = 1,2,\\cdots,5.\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n求解器 glpk 还可以求解一些整数优化问题。\n\nop &lt;- OP(\n  objective = L_objective(c(-2, -1, -4, -3, -1)),\n  types = rep(\"I\", 5),\n  constraints = L_constraint(\n    L = matrix(c(\n      0, 2, 1, 4, 2,\n      3, 4, 5, -1, -1\n    ), ncol = 5, byrow = TRUE),\n    dir = c(\"&lt;\", \"&lt;\"),\n    rhs = c(54, 62)\n  ),\n  # 添加约束\n  bounds = V_bound(\n    li = 1:5, ui = 1:5,\n    lb = c(0, 0, 3, 0, 2), ub = rep(100, 5), nobj = 5\n  ),\n  maximum = FALSE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 5 with\n#&gt; - 5 integer objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type linear.\n#&gt; - 2 lower and 5 upper non-standard variable bounds.\n\n# 求解\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1] 15  0  6 11  2\n\n# 目标函数值\nres$objval\n\n#&gt; [1] -89\n\n\n可知，最优解在 \\((15,0,6,11,2)\\) 处取得，目标函数值为 -89 。\n注意：还有一组最优解 \\((19,0,4,10,5)\\) ，目标函数值也为 -89 ，但是 glpk 求解器未能给出。\n\n20.5.2 0-1 整数线性优化\n目标函数是线性的，决策变量的取值要么是 0 要么是 1。指派问题属于典型的 0-1 整数优化问题。有 \\(n\\) 个人需要去完成 \\(n\\) 项任务，每个人完成一项任务，每项任务只由一个人完成，每个人单独完成各项任务所需花费（时间、费用）不同。要求设计一个方案，人和任务之间建立一一对应的关系，使得总花费最少。\n设第 \\(i\\) 个人完成第 \\(j\\) 项任务的花费为 \\(d_{ij}\\) ，当安排第 \\(i\\) 个人完成第 \\(j\\) 项任务时，记为 \\(x_{ij} = 1\\) ，否则，记为 \\(x_{ij} = 0\\) ，指派问题的数学模型如下：\n\\[\n\\begin{aligned}\n\\min \\quad & \\sum_{i=1}^{n}\\sum_{j=1}^{n}d_{ij}x_{ij} \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    \\sum_{i=1}^{n} x_{ij} = 1, ~~ j = 1,2,\\ldots,n\\\\\n    \\sum_{j=1}^{n} x_{ij} = 1, ~~ i = 1,2,\\ldots,n\\\\\n    x_{ij} = 0 ~~\\text{或}~~ 1\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n指派问题在 lpSolve 包 (Berkelaar 等 2023) 做了很好的封装，只需提供花费矩阵，即可调用求解器求解该问题。\n\n# 花费矩阵 D\nD &lt;- matrix(c(\n  2, 7, 7, 2,\n  7, 7, 3, 2,\n  7, 2, 8, 10,\n  1, 9, 8, 2\n), nrow = 4, ncol = 4, byrow = F)\n# 加载 lpSolve 包 \nlibrary(lpSolve)\n# 调用指派问题求解器\nsol &lt;- lp.assign(D)\n# 最优解\nsol$solution\n\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    0    0    0    1\n#&gt; [2,]    0    0    1    0\n#&gt; [3,]    0    1    0    0\n#&gt; [4,]    1    0    0    0\n\n# 总花费\nsol$objval\n\n#&gt; [1] 8\n\n\n可以使总花费最少的指派计划是第 1 个人完成第 4 项任务，第 2 个人完成第 3 项任务，第 3 个人完成第 2 项任务，第 4 个人完成第 1 项任务，总花费为 8。\n\n20.5.3 混合整数线性优化\n目标函数是线性的，一部分决策变量是整数。\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{x}} \\quad & 3x_1 + 7x_2 - 12x_3 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    5x_1 + 7x_2 + 2x_3 \\leq 61\\\\\n    3x_1 + 2x_2 - 9x_3 \\leq 35\\\\\n    x_1 + 3x_2 + x_3 \\leq 31\\\\\n    x_1,x_2 \\geq 0, \\quad x_2, x_3 \\in \\mathbb{Z}, \\quad x_3 \\in [-10, 10]\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n矩阵形式如下\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{x}} \\quad &\n  \\begin{bmatrix}\n  3  \\\\\n  7  \\\\\n  -12\n  \\end{bmatrix}\n  ^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\left\\{\n\\begin{array}{l}\n  \\begin{bmatrix}\n  5 & 7 & 2 \\\\\n  3 & 2 & -9\\\\\n  1 & 3 & 1\n  \\end{bmatrix}\n  \\boldsymbol{x} \\leq\n  \\begin{bmatrix}\n   61 \\\\\n   35 \\\\\n   31\n  \\end{bmatrix}\n\\end{array} \\right.\n\\end{aligned}\n\\]\n第1个变量是连续值，第2、3个变量是整数，第3个变量的下、上界分别是 -10 和 10。\n\nop &lt;- OP(\n  objective = L_objective(c(3, 7, -12)),\n  types = c(\"C\", \"I\", \"I\"),\n  constraints = L_constraint(\n    L = matrix(c(\n      5, 7, 2,\n      3, 2, -9,\n      1, 3, 1\n    ), ncol = 3, byrow = TRUE),\n    dir = c(\"&lt;=\", \"&lt;=\", \"&lt;=\"),\n    rhs = c(61, 35, 31)\n  ),\n  # 添加约束\n  bounds = V_bound(\n    li = 3, ui = 3,\n    lb = -10, ub = 10, nobj = 3\n  ),\n  maximum = TRUE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 3 with\n#&gt; - 1 continuous objective variable,\n#&gt; - 2 integer objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 1 lower and 1 upper non-standard variable bound.\n\n# 求解\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1]  0.3333333  8.0000000 -2.0000000\n\nres$objval\n\n#&gt; [1] 81\n\n\n\n20.5.4 混合整数二次优化\n目标函数是二次的，一部分决策变量是整数。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & x_1^2 + x_2^2 - x_1  x_2 + 3  x_1 - 2 x_2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      -x_1 - x_2 &lt;= -2 \\\\\n      x_1 - x_2 &lt;= 2 \\\\\n      x_2 &lt;= 3. \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n在二次优化的基础上，对变量添加整型约束，即变成混合整数二次优化 （Mixed Integer Quadratic Programming，简称 MIQP）。\n\n# D\nDmat &lt;- matrix(c(2, -1, -1, 2), nrow = 2, byrow = TRUE)\n# d\ndvec &lt;- c(3, -2)\n# A\nAmat &lt;- matrix(c(\n  -1, -1,\n  1, -1,\n  0, 1\n), ncol = 2, byrow = TRUE)\n# b\nbvec &lt;- c(-2, 2, 3)\n# 目标优化\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(Amat, rep(\"&lt;=\", 3), bvec),\n  types = c(\"I\", \"C\"),\n  maximum = FALSE # 求最小\n)\n# 查看可用于该优化问题的求解器\nROI_applicable_solvers(op)\n\n#&gt; NULL\n\n\n目前，ROI 包支持的开源求解器都不能处理 MIQP 问题。ECOSolveR 包可以求解凸二阶锥优化，部分变量可以是整数。因此，先将凸二次优化转化为凸锥优化问题，再连接 ECOSolveR 包提供 ecos 求解器，最后，调 ecos 求解器求解。\n\\[\n\\begin{aligned}\n\\min_{(t,\\boldsymbol{x})} \\quad &  t\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\nx_1^2 + x_2^2 - x_1  x_2 + 3  x_1 - 2 x_2 \\leq t \\\\\n      -x_1 - x_2 &lt;= -2 \\\\\n      x_1 - x_2 &lt;= 2 \\\\\n      x_2 &lt;= 3. \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n引入新的变量 \\(t\\) ，原目标函数化为线性，约束条件增加一个二次型。\n\\[\n\\begin{aligned}\n\\min_{(t,\\boldsymbol{x})} \\quad &  t\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      \\boldsymbol{x}^{\\top}D\\boldsymbol{x} + 2\\boldsymbol{d}^{\\top}\\boldsymbol{x} \\leq t \\\\\n      A\\boldsymbol{x} \\leq \\boldsymbol{b} \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n其中，\n\\[\nD = \\begin{bmatrix}\n2 & -1\\\\\n-1 & 2\n\\end{bmatrix}, \\quad\n\\boldsymbol{d} =  \n\\begin{bmatrix}\n3 \\\\\n-2\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n-1 & -1  \\\\\n1 & -1 \\\\\n0  & 1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n-2 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n最后，凸二次优化转为二阶锥优化 SOCP，形式如下：\n\\[\n\\begin{aligned}\n\\min_{(t^{\\star},\\boldsymbol{x})} \\quad & t^{\\star}\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      \\|D^{1/2}\\boldsymbol{x} + D^{-1/2}\\boldsymbol{d} \\|_2 \\leq t^{\\star} \\\\\n      A\\boldsymbol{x} \\leq \\boldsymbol{b} \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n代码如下\n\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = c(\n    C_constraint(L, cones = K_soc(3)),\n    L_constraint(Amat, rep(\"&lt;=\", 3), bvec)\n  ),\n  types = c(\"I\", \"C\", \"C\"),\n  maximum = FALSE # 默认求最小\n)\n\n# 调用 ECOSolveR 包\nlibrary(ROI.plugin.ecos)\nnlp &lt;- ROI_solve(op, solver = \"ecos\", start = c(1, 2))\nnlp$objval\nnlp$solution\n\n因二次优化的目标函数是二次连续可微的，而且是凸函数，求解器 Bonmin 可以获得最优解。\nvar x1 integer;\nvar x2;\nminimize z: x1^2 + x2^2 - x1 * x2 + 3 * x1 - 2 * x2;\nsubject to A_limit: -x1 - x2 &lt;= -2;\nsubject to B_limit: x1 - x2 &lt;= 2;\nsubject to C_limit: x2 &lt;= 3;\n\nlibrary(rAMPL)\n# 配置 AMPL 安装路径\nenv &lt;- new(Environment, \"/opt/AMPL/ampl.macos64\")\nampl &lt;- new(AMPL, env)\n# 加载混合整数二次优化模型文件\nampl$read(\"code/MIQP.mod\")\n# 设置 MIQP 求解器 Bonmin\nampl$setOption(\"solver\", \"bonmin\")\n# 求解问题\nampl$solve()\n# 最优解\nampl$getData(\"x1\")\nampl$getData(\"x2\")\n# 目标函数值\nampl$getData(\"z\")\n\n最优解在 \\((0,2)\\) 处获得，最优值为 0。\n\n20.5.5 混合整数非线性优化\n在 R 语言社区的官方仓库中还没有开源的 R 包可以求解此类问题，开源社区中 Bonmin 项目专门求解混合整数非线性优化 MINLP（Mixed Integer Non-Linear Programming）问题。数学优化软件 AMPL 封装了 Bonmin 软件，并提供 R 语言接口 rAMPL。AMPL 社区版可以免费使用打包的开源求解器。\n\n线性优化求解器 HiGHS。\n混合整数线性优化求解器 cbc。\n混合整数非线性优化求解器 Bonmin 和 Couenne。\n非线性优化求解器 Ipopt。\n\n安装 AMPL 社区版软件后，再安装 rAMPL 包，它依赖 Rcpp 包，所以需要一并安装。\ninstall.packages(\"Rcpp\", type = \"source\")\n# 从 AMPL 官网安装 rAMPL 包\ninstall.packages(\"https://ampl.com/dl/API/rAMPL.tar.gz\", repos = NULL,\n  INSTALL_opts = c(\"--no-multiarch\", \"--no-staged-install\")\n)\n下面求解如下混合整数非线性优化问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & 1.5(x_1 - \\sin(x_1 -x_2))^2 + 0.5x_2^2 + x_3^2 -x_1 x_2 -2x_1 + x_2 x_3 \\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      x_1,x_2 \\in \\mathbb{R} ~~ x_3 \\in \\mathbb{Z} \\\\\n      x_1,x_2 \\in [-20,20] ~~ x_3 \\in [-10,10].\n    \\end{array} \\right.\n\\end{aligned}\n\\]\nAMPL 模型代码如下：\nvar X1;\nvar X2;\nvar X3 integer;\nminimize z: 1.5 * (X1 - sin(X1 - X2))^2 + 0.5 * X2^2 + X3^2 - X1 * X2 - 2 * X1 + X2 * X3;\nsubject to A_limit: -20 &lt;= X1 &lt;= 20;\nsubject to B_limit: -20 &lt;= X2 &lt;= 20;\nsubject to C_limit: -10 &lt;= X3 &lt;= 10;\n将代码保存到文件 code/MINLP.mod ，下面加载 rAMPL 包，调用求解器 Bonmin 求解该优化问题。\n\nlibrary(rAMPL)\n# 配置 AMPL 安装路径\nenv &lt;- new(Environment, \"/opt/AMPL/ampl.macos64\")\nampl &lt;- new(AMPL, env)\n# 加载混合整数非线性优化模型文件\nampl$read(\"code/MINLP.mod\")\n# 设置 MINLP 求解器 Bonmin\nampl$setOption(\"solver\", \"bonmin\")\n# 求解问题\nampl$solve()\n# 最优解\nampl$getData(\"X1\")\nampl$getData(\"X2\")\nampl$getData(\"X3\")\n# 目标函数值\nampl$getData(\"z\")\n\n如果使用 Bonmin 求解器，该优化问题的最优解在 \\((2.892556, 1.702552, -1)\\) 处获得，相应的目标函数值为 \\(-4.176012\\) 。如果使用求解器 Couenne ，它可以找到非凸混合整数非线性优化问题的全局最优解，Couenne 好于 Bonmin 求解器。\n\n# 调用 couenne 求解器\nampl$setOption(\"solver\", \"couenne\")\n# 求解问题\nampl$solve()\n\n最优解在 \\(x_1 = 4.999633, x_2 = 9.734148, x_3 = -5\\) 处取得，最优值为 \\(-10.96182\\) 。下面将两个最优解代入目标函数，验证一下最优值。\n\nfun &lt;- function(x) {\n  1.5 * (x[1] - sin(x[1] - x[2]))^2 + 0.5 * x[2]^2 +\n    x[3]^2 - x[1] * x[2] - 2 * x[1] + x[2] * x[3]\n}\n# 局部最优解\nfun(x = c(2.892556, 1.702552, -1))\n\n#&gt; [1] -4.176012\n\n# 全局最优解\nfun(x = c(4.999633, 9.734148, -5))\n\n#&gt; [1] -10.96182",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-numerical-optimization-summary",
    "href": "numerical-optimization.html#sec-numerical-optimization-summary",
    "title": "20  数值优化",
    "section": "\n20.6 总结",
    "text": "20.6 总结\n对大部分常规优化问题，都可以纳入 ROI 包的框架内。对少量复杂的优化问题，目前，必须借助开源社区的第三方求解器。\n\n对于含整型变量的凸锥优化问题，scs 包不能求解，ECOSolveR 包可以，它还可以求解可转化为凸二阶锥优化问题的混合整数二次优化问题。\n对于特定问题，比如 0-1 整数线性优化中的指派问题，相比于 ROI 包的大一统调用方式，lpSolve 包给出非常简明的使用语法。对凸二次优化问题，给出 quadprog 包的使用语法，补充说明 nloptr 包的结果，以及与 ROI 包调用语法的差异。\n对于凸的混合整数二次优化和非凸的混合整数非线性优化问题，借助 rAMPL 包分别调用开源的求解器 Bonmin 和 Couenne 求解。\n对于复杂的非线性优化问题，因其具有非凸、多模态等特点，求解非常困难。需要引入随机优化算法，比如采用 GA 包的遗传算法求解，效果可以达到商业软件的水平。\n对于凸优化问题，可以求解得又快又好，而对于非凸优化问题，要么只能获得局部最优解，要么可以搜索全局最优解，但不给保证，而且运行时间长。\n\n优化建模是一个具有基础性和支柱性的任务，几乎每个统计模型和机器学习算法背后都有一个优化问题。在 R 语言社区的优化任务视图 (Schwendinger 和 Borchers 2023) 中，可以看到数以百计的扩展包。非常广阔的应用场景催生了非常丰富的理论。根据目标函数和约束条件的情况，可以从不同的角度划分，如线性和非线性优化，连续和离散优化，确定性和随机优化，凸优化和非凸优化等。相关的理论著作非常多，感兴趣的读者可以根据自身情况找本教材系统性地学习。本章结构是按照优化问题分类组织的，主要涉及确定性的数值优化，因部分优化问题比较复杂，因此，也涉及少量的随机优化方法。\n优化建模是一个具有重要商业价值的领域，相关的开源和商业软件有很多，比较流行的有 Python 社区的 Pyomo (Hart, Watson, 和 Woodruff 2011)，Julia 社区的 JuMP (Dunning, Huchette, 和 Lubin 2017)。比较著名的商业软件有 Lingo、Mosek、Gurobi 等，而 AMPL 一个软件平台，对 20 个开源和商业求解器提供一套统一的建模语言，且提供 R、Python 等编程语言接口。\n相比于 Python 和 Julia 社区，R 语言社区在整合开源的优化建模软件方面，还有较长的路要走，ROI 包的出现意味着向整合的路迈出坚实的一步。优化建模的场景具有复杂性和多样性，算法实现更是五花八门，仅线性和整数线性优化方面，就至少有 lpSolve、 Rglpk 和 highs (Schwendinger 和 Schumacher 2023)等包，更别提非线性优化方面。这就又出现一个问题，对一个优化问题，采用何种算法及算法实现具有最好的效果，满足可用性、可靠性。尽管涉及数学和统计，但高质量的软件工具更是一个工程问题。\n从数据分析的角度来说，无论是 Python，还是 Julia，甚至于底层的 C++ 库，都不过是软件工具，首要问题是将实际问题转化为统计或数学模型，这需要抓住主要问题的关键因素，只有先做好建模的工作才能实现工具到商业价值的转化。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-numerical-optimization-exercises",
    "href": "numerical-optimization.html#sec-numerical-optimization-exercises",
    "title": "20  数值优化",
    "section": "\n20.7 习题",
    "text": "20.7 习题\n\n求解线性优化和整数线性优化的 R 包有很多，从使用语法、可求解的问题规模和问题类型比较 lpSolve、Rglpk 和 highs 等 R 包。\n求解非线性优化问题的 R 包有很多，其中有一些通过 Rcpp 包打包、调用 C++ 库，比如 RcppEnsmallen、RcppNumerical 等包，还有的 C++ 库提供头文件，可以在 C++ 环境中直接调用，比如 optim 库。通过 R 和 C++ 混合编程，一则引入更加庞大的开源社区，二则扩展求解非线性优化问题的规模和性能。请从求解问题类型、规模和性能等方面比较 5 个比较流行的 C++ 库。\n\n回顾凸二次优化一节，当矩阵 \\(D\\) 为半正定矩阵时，二次优化是非严格凸二次优化。调整示例里目标函数中的矩阵 \\(D\\) 使其行列式等于 0，其它条件不变。使用 ROI 包调用合适的优化求解器求解此类问题。\n\n代码# 非严格凸的二次优化问题\n# 凸二次优化一节的示例 矩阵 D 的行列式为 0\nDmat &lt;- matrix(c(2, 1, 4, 2), nrow = 2, byrow = TRUE)\ndvec &lt;- c(3, -2)\nAmat &lt;- matrix(c(-1, -1, 1, -1, 0, 1), ncol = 2, byrow = TRUE)\nbvec &lt;- c(-2, 2, 3)\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(L = Amat, dir = rep(\"&lt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nop\n# 调用 SQP 序列二次优化求解器\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 2))\n# 目标函数值 0 \nnlp$objval\n# 最优解 (0, 2)\nnlp$solution\n\n\n\n\n求解如下 2 维非线性无约束优化问题。\n\\[\n\\min_{\\boldsymbol{x}} \\quad 100 (x_2 -x_1^2)^2 + (1-x_1)^2\n\\]\n\n代码# Rosenbrock Banana function\n# 目标函数\nfr &lt;- function(x) {\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  100 * (x2 - x1 * x1)^2 + (1 - x1)^2\n}\n# 目标函数的梯度\ngrr &lt;- function(x) {\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  c(\n    -400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),\n    200 * (x2 - x1 * x1)\n  )\n}\n# 求解\nnlminb(start = c(-1.2, 1), objective = fr, gradient = grr)\n# 或者\noptim(par = c(-1.2, 1), fn = fr, gr = grr, method = \"L-BFGS-B\")\n\n\n\n\n求解如下 \\(n\\) 维非线性箱式约束优化问题。\n\\[\n\\min_{\\boldsymbol{x}} \\quad \\exp\\big( - \\sum_{i=1}^{n}(\\frac{x_i}{\\beta})^{2m}\\big)  - 2\\exp(- \\sum_{i=1}^{n}x_i^2)\\prod_{i=1}^{n} \\cos^2(x_i)\n\\]\n其中，\\(\\beta.=15, m = 3\\) ，\\(x_i \\in [-20,20], i = 1,2,\\ldots,n\\) 。请读者分别考虑 \\(n= 2\\) 和 \\(n = 4\\) 的情况。（全局最优解在 \\(x_i = 0, i = 1,2,\\ldots,n\\) 处取得，最优值为 \\(-1\\) 。）\n\n\n求解如下非线性约束优化问题。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & \\exp(\\sin(50 x_1)) + \\sin(60\\exp(x_2)) + \\sin(70\\sin(x_1)) \\\\\n         \\quad & + \\sin(\\sin(80x_2)) - \\sin(10(x_1 +x_2)) + \\frac{(x_1^2 + x_2^2)^{\\sin(x_2)}}{4} \\\\\n    \\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n     x_1 - \\big((\\cos(x_2))^{x_1} - x_1\\big)^{x_2} \\leq 0 \\\\\n    -50 \\leq x_1,x_2 \\leq 50\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n目标函数是不连续的，其函数图像如 图 20.10 所示。（提示：容错能力低的求解器一般无法求解。Lingo 给出一个局部最优解 \\((-46.14402, -0.8879601)\\) ，目标函数值为 \\(-2.645518\\) ，仅供参考。）\n\n代码fn &lt;- function(x) {\n  exp(sin(50 * x[1])) + sin(60 * exp(x[2])) +\n    sin(70 * sin(x[1])) + sin(sin(80 * x[2])) -\n    sin(10 * (x[1] + x[2])) + (x[1]^2 + x[2]^2)^(sin(x[2])) / 4\n}\n\ndf &lt;- expand.grid(\n  x1 = seq(from = 0.8, to = 1.4, length.out = 81),\n  x2 = seq(from = 0, to = 0.4, length.out = 41)\n)\n# 计算格点处的函数值\ndf$fn &lt;- apply(df, 1, FUN = fn)\n\n# 绘图\nwireframe(\n  data = df, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 20.10: 目标函数的曲面图\n\n\n\n\n\n代码fn &lt;- function(x) {\n  exp(sin(50 * x[1])) + sin(60 * exp(x[2])) +\n    sin(70 * sin(x[1])) + sin(sin(80 * x[2])) -\n    sin(10 * (x[1] + x[2])) + (x[1]^2 + x[2]^2)^(sin(x[2])) / 4\n}\ngr &lt;- function(x){\n  numDeriv::grad(fn, c(x[1], x[2]))\n}\nhin &lt;- function(x){\n  x[1] - ( (cos(x[2]))^x[1] - x[1] )^x[2]\n}\nhin.jac &lt;- function(x){\n  numDeriv::grad(hin, c(x[1], x[2]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, n = 2L, G = gr), # 2 个决策变量\n  constraints = F_constraint(\n    F = list(hin = hin),\n    dir = \"&lt;=\",\n    rhs = 0,\n    J = list(hin.jac = hin.jac)\n  ),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 2L),\n  maximum = FALSE # 求最小\n)\n# 全局优化求解器 nloptr.isres，不保证全局最优\n# 最优解 (20.68497, 37.20738) 处取得局部最优解，目标函数值 -3.053314\nnlp &lt;- ROI_solve(op, solver = \"nloptr.isres\", start = c(1, 0))\nnlp$solution\nnlp$objval\n# 局部优化求解器 nloptr.cobyla\n# 在处 (24.199046, 2.964661) 处取得局部最优解，目标函数值 0.6477342\nnlp &lt;- ROI_solve(op, solver = \"nloptr.cobyla\", start = c(1, 0))\nnlp$solution\nnlp$objval\n# nloptr.mma / nloptr.auglag / nloptr.slsqp 容错能力差，都不能求解\nnlp &lt;- ROI_solve(op, solver = \"nloptr.auglag\", start = c(1, 0))\n\n\n\n\n求解如下非线性约束优化问题。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & x_1^2\\sin(x_2) + x_2^2\\cos(x_1)\\\\\n  \\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      1 \\leq 3x_1 -x_2 \\leq 3 \\\\\n      x_1 + x_2 \\geq 2 \\\\\n      x_1 x_2 = 2 \\\\\n      \\sin(x_1) \\cos(x_2) \\leq 0.6 \\\\\n      x_1,x_2 \\in (-100,100).\n    \\end{array} \\right.\n  \\end{aligned}\n\\]\n\n代码# 一个 2 维的目标函数\nfn &lt;- function(x) {\n  x[1]^2 * sin(x[2]) + x[2]^2 * cos(x[1])\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    2 * x[1] * sin(x[2]) - x[2]^2 * sin(x[1]),\n    x[1]^2 * cos(x[2]) + 2 * x[2] * cos(x[1])\n  )\n}\n# 线性约束矩阵\nA &lt;- matrix(c(\n  1, 1,\n  3, -1,\n  3, -1\n), ncol = 2, byrow = TRUE)\n# 等式约束\nheq &lt;- function(x) {\n  prod(x)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  c(x[2], x[1])\n}\n# 不等式约束\nhin &lt;- function(x) {\n  sin(x[1]) * cos(x[2])\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x) {\n  c(cos(x[1]) * cos(x[2]), -sin(x[1]) * sin(x[2]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, G = gr, n = 2L),\n  # rbind 函数组合多种约束\n  constraints = rbind(\n    L_constraint(\n      L = A,\n      dir = c(\"&gt;=\", \"&lt;=\", \"&gt;=\"),\n      rhs = c(2, 3, 1)\n    ),\n    F_constraint(\n      F = list(heq = heq, hin = hin),\n      dir = c(\"==\", \"&lt;=\"),\n      rhs = c(2, 0.6),\n      # 等式和不等式约束的雅可比\n      J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n    )\n  ),\n  bounds = V_bound(ld = -100, ud = 100, nobj = 2L),\n  maximum = FALSE # 求最小\n)\n# 求解优化问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1/2, 4))\n# 最优解\nnlp$solution\n# 目标函数值\nnlp$objval\n\n\n\n\n\n\n\n\nBerkelaar, Michel 等. 2023. lpSolve: Interface to Lp_solve v. 5.5 to Solve Linear/Integer Programs. https://CRAN.R-project.org/package=lpSolve.\n\n\nBrandao, Filipe. 2023. rAMPL: AMPL API for R. https://github.com/ampl/rAMPL.\n\n\nDunning, Iain, Joey Huchette, 和 Miles Lubin. 2017. 《JuMP: A Modeling Language for Mathematical Optimization》. SIAM Review 59 (2): 295–320. https://doi.org/10.1137/15M1020575.\n\n\nFu, Anqi, 和 Balasubramanian Narasimhan. 2023. ECOSolveR: Embedded Conic Solver in R. https://CRAN.R-project.org/package=ECOSolveR.\n\n\nHart, William E, Jean-Paul Watson, 和 David L Woodruff. 2011. 《Pyomo: modeling and solving mathematical programs in Python》. Mathematical Programming Computation 3 (3): 219–60.\n\n\nJohnson, Steven G. 2023. The NLopt nonlinear optimization package. https://CRAN.R-project.org/package=nloptr.\n\n\nO’Donoghue, Brendan, Eric Chu, Parikh Neal, 和 Stephen Boyd. 2016. 《Operator Splitting for Conic Optimization via Homogeneous Self-Dual Embedding》. Journal of Optimization Theory and Applications 169 (3): 1042–68. https://doi.org/10.1007/s10957-016-0892-3.\n\n\nS original by Berwin A. Turlach, Fortran contributions from Cleve Moler dpodi/LINPACK), R port by Andreas Weingessel. 2019. quadprog: Functions to Solve Quadratic Programming Problems. https://CRAN.R-project.org/package=quadprog.\n\n\nSchwendinger, Florian, 和 Hans W. Borchers. 2023. CRAN Task View: Optimization and Mathematical Programming. https://CRAN.R-project.org/view=Optimization.\n\n\nSchwendinger, Florian, 和 Dirk Schumacher. 2023. highs: HiGHS Optimization Solver. https://CRAN.R-project.org/package=highs.\n\n\nScrucca, Luca. 2013. 《GA: A Package for Genetic Algorithms in R》. Journal of Statistical Software 53 (4): 1–37. https://doi.org/10.18637/jss.v053.i04.\n\n\nTheussl, Stefan, 和 Kurt Hornik. 2023. Rglpk: R/GNU Linear Programming Kit Interface. https://CRAN.R-project.org/package=Rglpk.\n\n\nTheußl, Stefan, Florian Schwendinger, 和 Kurt Hornik. 2020. 《ROI: An Extensible R Optimization Infrastructure》. Journal of Statistical Software 94 (15): 1–64. https://doi.org/10.18637/jss.v094.i15.\n\n\n刘浩洋, 户将, 李勇锋, 和 文再文. 2020. 最优化：建模、算法与理论. 北京: 高等教育出版社. http://faculty.bicmr.pku.edu.cn/~wenzw/optbook.html.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html",
    "href": "optimization-problems.html",
    "title": "21  优化问题",
    "section": "",
    "text": "21.1 旅行商问题\n旅行商问题 The Traveling Salesman Problem 是一个混合整数线性规划问题，TSP 包 (Hahsler 和 Hornik 2007) 是求解此问题的最佳工具包。一般地，旅行商问题作如下定义。已知 \\(n\\) 个城市之间的距离，以矩阵 \\(D\\) 表示各个城市之间的距离，其元素 \\(d_{ij}\\) 表示城市 \\(i\\) 到城市 \\(j\\) 之间的距离，其对角元素 \\(d_{ii} = 0\\)，其中 \\(i,j = 1,2,\\cdots, n\\) 。一个旅行路线可以用 \\(\\{1,2,\\ldots,n\\}\\) 的循环排列 \\(\\pi\\) 表示，\\(\\pi(i)\\) 表示在旅行线路中跟在城市 \\(i\\) 之后的城市。旅行商问题就是找一个排列 \\(\\pi\\) 使得如下旅行线路最短。\n\\[\n\\sum_{i=1}^{n} d_{i\\pi(i)}\n\\]\n每个城市必须走到，且只能走一次。等价于如下整数规划问题，也是一个指派问题。\n\\[\n\\begin{aligned}\n\\min ~ & \\sum_{i=1}^{n}\\sum_{j=1}^{n} d_{ij}x_{ij} \\\\\n\\text{s.t.} ~& \\sum_{i=1}^{n}x_{ij} = 1, ~j = 1,2,\\ldots,n, \\\\\n~& \\sum_{j=1}^{n}x_{ij} = 1, ~ i = 1,2,\\ldots,n, \\\\\n~& x_{ij} = 0 ~\\text{or} ~ 1\n\\end{aligned}\n\\]\n某人要去美国 10 个城市旅行，分别是亚特兰大 Atlanta、芝加哥 Chicago、丹佛 Denver 、休斯顿 Houston、洛杉矶 Los Angeles、迈阿密 Miami、纽约 New York、旧金山 San Francisco、 西雅图 Seattle、华盛顿特区 Washington DC。10 个城市的分布如 图 21.1 所示。从洛杉矶出发，最后回到洛杉矶，如何规划旅行线路使得总行程最短？行程最短的路径是什么？\n代码# 10 个城市的经纬度数据来自 maps 包的 us.cities 数据集\nus_city_latlong &lt;- read.table(file = textConnection(\"\nCity, Latitude, Longitude\nAtlanta, 33.76, -84.42\nChicago, 41.84, -87.68\nDenver, 39.77, -104.87\nHouston, 29.77, -95.39\nLos Angeles, 34.11, -118.41\nMiami, 25.78, -80.21\nNew York, 40.67, -73.94\nSan Francisco, 37.77, -122.45\nSeattle, 47.62, -122.35\nWashington DC, 38.91, -77.01\n\"), header = TRUE, sep = \",\")\n\nlibrary(sf)\nus_city_latlong &lt;- st_as_sf(us_city_latlong,\n  coords = c(\"Longitude\", \"Latitude\"), crs = 4326\n)\nlibrary(ggplot2)\nggplot() +\n  geom_sf_label(\n    data = us_city_latlong, aes(label = City),\n    fun.geometry = sf::st_centroid\n  ) +\n  geom_sf(data = us_city_latlong, color = \"red\") +\n  coord_sf(crs = \"ESRI:102003\") +\n  theme_bw() +\n  labs(x = \"经度\", y = \"纬度\")\n\n\n\n\n\n\n图 21.1: 10 个城市的分布图\n简单起见，这 10 个城市之间的距离以直线距离代替，R 内置的数据集 UScitiesD 已经记录了这 10 个城市之间的直线距离。 UScitiesD 是一个 dist 类型的数据，可以用函数 as.matrix() 将其转化为矩阵类型。\ndata(UScitiesD)\nD &lt;- as.matrix(UScitiesD)\nlibrary(TSP)\nD_tsp &lt;- as.TSP(D)\n# 出发城市洛杉矶\ntour_sol &lt;- solve_TSP(x = D_tsp, method = \"nearest_insertion\", start = 5)\ntour_sol\n\n#&gt; object of class 'TOUR' \n#&gt; result of method 'nearest_insertion' for 10 cities\n#&gt; tour length: 7373\n途经 10 个城市的最短路程为 7373 。因采用启发式的随机优化算法，每次求解的结果可能会有所不同，建议运行多次，比较结果，选择最优的方法。\n# 旅行最短路程\ntour_length(tour_sol)\n\n#&gt; [1] 7373\n\n# 旅行线路方案\nas.integer(tour_sol)\n\n#&gt;  [1]  5  8  9  3  2  7 10  1  6  4\n\nlabels(D_tsp)[as.integer(tour_sol)]\n\n#&gt;  [1] \"LosAngeles\"    \"SanFrancisco\"  \"Seattle\"       \"Denver\"       \n#&gt;  [5] \"Chicago\"       \"NewYork\"       \"Washington.DC\" \"Atlanta\"      \n#&gt;  [9] \"Miami\"         \"Houston\"\n求解结果对应的旅行方案，如 图 21.2 所示，依次走过的城市是：洛杉矶、旧金山、西雅图、丹佛、芝加哥、纽约、华盛顿特区、亚特兰大、迈阿密、休斯顿。\n代码us_city_tour &lt;- st_cast(st_combine(st_geometry(us_city_latlong[as.integer(tour_sol),])), \"POLYGON\")\nggplot() +\n  geom_sf_label(\n    data = us_city_latlong, aes(label = City),\n    fun.geometry = sf::st_centroid\n  ) +\n  geom_sf(data = us_city_latlong, color = \"red\") +\n  geom_sf(data = us_city_tour, fill = NA, color = \"black\") +\n  coord_sf(crs = \"ESRI:102003\") +\n  theme_bw() +\n  labs(x = \"经度\", y = \"纬度\")\n\n\n\n\n\n\n图 21.2: 10 个城市的路线图",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-markowitz-portfolio-optimization",
    "href": "optimization-problems.html#sec-markowitz-portfolio-optimization",
    "title": "21  优化问题",
    "section": "\n21.2 投资组合问题",
    "text": "21.2 投资组合问题\n作为一个理性的投资者，希望回报最大而风险最小，给定投资和回报的约束条件下，选择风险最小的组合。一个简单的马科维茨投资组合优化问题如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{w}} \\quad & \\boldsymbol{w}^{\\top}\\hat{\\Sigma}\\boldsymbol{w} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{w}^{\\top} \\leq \\boldsymbol{b}\n\\end{aligned}\n\\]\n其中，\\(\\boldsymbol{w}\\) 是权重向量，每个分量代表对投资对象的投资比例，\\(\\hat{\\Sigma}\\) 是关于投资对象的协方差矩阵，约束条件中包含两个部分，一个是权重之和为 1，一个是投资组合的收益率达到预期值。下面基于 12个科技公司公开的股价数据介绍此组合优化问题。\n首先利用 quantmod 包获取微软、谷歌、亚马逊、惠普、甲骨文、英特尔、威瑞森、eBay、AT&T、Apple、Adobe 和 IBM 等 12 支股票的历史股价数据。根据 2022-11-01 至 2022-12-01 期间的股票调整价，计算各支股票天粒度的收益率。收益率可以看作一个随机变量，收益率的波动变化，即随机变量的方差，可以看作风险。\n\n# 12 支股票的收益率\ntech_stock_return &lt;- readRDS(file = \"data/tech_stock_return.rds\")\nDD &lt;- 100 * tech_stock_return\n# 平均收益率\nr &lt;- mean(DD)\nr\n\n#&gt; [1] 0.3476413\n\n# 目标函数\nfoo &lt;- Q_objective(Q = cov(DD), L = rep(0, ncol(DD)))\n# 投资约束\nfull_invest &lt;- L_constraint(rep(1, ncol(DD)), \"==\", 1)\n# 回报约束\ntarget_return &lt;- L_constraint(apply(DD, 2, mean), \"==\", r)\n# 目标规划\nop &lt;- OP(objective = foo, constraints = rbind(full_invest, target_return))\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n求解器 nloptr.slsqp 需要给初值和等式约束的梯度，而求解器 quadprog 不需要给初值。下面使用 quadprog 来求解组合优化问题。\n\nlibrary(ROI.plugin.quadprog)\nsol &lt;- ROI_solve(op, solver = \"quadprog\")\n# 最优解：投资组合\nw &lt;- sol$solution\n# 保留 4 位小数\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 目标函数值：投资风险\nsqrt(t(w) %*% cov(DD) %*% w)\n\n#&gt;           [,1]\n#&gt; [1,] 0.9860861\n\n\n求解出来的投资组合是甲骨文、 AT&T 和 IBM，投资比例分别是 33.58% 、37.40% 和 29.02% 。以上 12 支股票都属于科技公司，收益率具有非常高的相关性，因此，最终选出来 3 支。\n与给定预期回报而风险最小的组合优化问题相对应的是另一个问题：给定风险的约束条件下，获得预期回报最大的组合。即求解如下组合优化问题：\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{w}} \\quad & \\boldsymbol{w}^{\\top}\\hat{\\boldsymbol{\\mu}} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{w} \\leq \\boldsymbol{b} \\\\\n\\quad & \\boldsymbol{w}^{\\top}\\hat{\\Sigma}\\boldsymbol{w} \\leq \\sigma\n\\end{aligned}\n\\]\n其中，目标函数中 \\(\\hat{\\boldsymbol{\\mu}}\\) 表示根据历史数据获得的投资对象的收益率，约束条件中 \\(\\sigma\\) 表示投资者可以接受的投资风险，其他符号的含义同前。在给定风险约束 \\(\\sigma\\) 下，求取回报最大的组合。线性约束也可以用函数 Q_constraint() 来表示，这样线性约束和二次约束可以整合在一起，代码如下：\n\n# 风险阈值\nsigma &lt;- sqrt(t(w) %*% cov(DD) %*% w)\nsigma\n\n#&gt;           [,1]\n#&gt; [1,] 0.9860861\n\n# 12 阶的全 0 矩阵\nzero_mat &lt;- diag(x = rep(0, ncol(DD)))\n# 目标函数\nfoo &lt;- Q_objective(Q = zero_mat, L = colMeans(DD))\n# 线性和二次约束\nmaxret_constr &lt;- Q_constraint(\n  Q = list(cov(DD), NULL),\n  L = rbind(\n    rep(0, ncol(DD)),\n    rep(1, ncol(DD))\n  ),\n dir = c(\"&lt;=\", \"==\"), rhs = c(1/2 * sigma^2, 1)\n)\n# 目标规划\nop &lt;- OP(objective = foo, constraints = maxret_constr, maximum = TRUE)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a quadratic objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type quadratic.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n函数 ROI_applicable_solvers() 识别规划问题类型，给出可求解此规划问题的求解器。\n\nROI_applicable_solvers(op)\n\n#&gt; [1] \"nloptr.cobyla\" \"nloptr.mma\"    \"nloptr.auglag\" \"nloptr.isres\" \n#&gt; [5] \"nloptr.slsqp\"\n\n\nquadprog 求解器不能求解该问题，尝试求解器 nloptr.slsqp ，12 支股票同等看待，所以，权重的初始值都设置为 \\(\\frac{1}{12}\\) 。\n\n# 求解规划问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = rep(1/12, 12))\n# 投资组合\nw &lt;- nlp$solution\n# 保留 4 位小数\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 投资组合的预期收益\nw %*% colMeans(DD)\n\n#&gt;           [,1]\n#&gt; [1,] 0.3476413\n\n\n结果显示，投资组合是甲骨文、 AT&T 和 IBM，投资比例分别是 33.58% 、37.40% 和 29.02% 。\n值得注意，当约束条件比较复杂，比如包含一些非线性的等式或不等式约束，可以用函数 F_constraint() 来表示，这更加的灵活，但需要传递（非）线性约束的雅可比向量或矩阵。用函数 F_constraint() 表示的代码如下，求解结果是一样的。\n\n# x 是一个表示权重的列向量 \n# 等式约束\n# 权重之和为 1 的约束\nheq &lt;- function(x) {\n  sum(x)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  rep(1, length(x))\n}\n# 不等式约束\n# 二次的风险约束\nhin &lt;- function(x){\n  1/2 * t(x) %*% cov(DD) %*% x\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x){\n  cov(DD) %*% x\n}\n# 目标规划\nop &lt;- OP(\n  objective = L_objective(L = colMeans(DD)), # 12 个目标变量\n  constraints = F_constraint(\n    # 等式和不等式约束\n    F = list(heq = heq, hin = hin),\n    dir = c(\"==\", \"&lt;=\"),\n    rhs = c(1, 1/2 * sigma^2),\n    # 等式和不等式约束的雅可比\n    J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n  ),\n  # 目标变量的取值范围\n  bounds = V_bound(ld = 0, ud = 1, nobj = 12L),\n  maximum = TRUE # 最大回报\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type nonlinear.\n#&gt; - 0 lower and 12 upper non-standard variable bounds.\n\n# 求解规划问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = rep(1/12, 12))\n# 投资组合\nw &lt;- nlp$solution\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 投资组合的预期收益\nw %*% colMeans(DD)\n\n#&gt;           [,1]\n#&gt; [1,] 0.3476413",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-gaussian-process-regression",
    "href": "optimization-problems.html#sec-gaussian-process-regression",
    "title": "21  优化问题",
    "section": "\n21.3 高斯过程回归",
    "text": "21.3 高斯过程回归\n高斯过程回归模型如下：\n\\[\n\\boldsymbol{y}(x) = D\\boldsymbol{\\beta} + S(x)\n\\]\n其中，\\(\\boldsymbol{\\beta}\\) 是一个 \\(p\\times 1\\) 维列向量，随机过程 \\(S(x)\\) 是均值为零，协方差为 \\(V_{\\boldsymbol{\\theta}}\\) 的平稳高斯过程，协方差矩阵 \\(V_{\\boldsymbol{\\theta}}\\) 的元素如下：\n\\[\n\\mathsf{Cov}\\{S(x_i), S(x_j)\\} = \\sigma^2 \\exp(-\\|x_i - x_j\\| / \\phi)\n\\]\n其中， \\(\\boldsymbol{\\theta} = (\\sigma^2,\\phi)\\) 表示与协方差矩阵相关的参数，随机过程 \\(S(x)\\) 的一个实现服从多元正态分布 \\(\\mathrm{MVN}(\\boldsymbol{0},V_{\\boldsymbol{\\theta}})\\) ，则 \\(\\boldsymbol{y}(x)\\) 也服从多元正态分布 \\(\\mathrm{MVN}(D\\boldsymbol{\\beta},V_{\\boldsymbol{\\theta}})\\) 。参数 \\(\\boldsymbol{\\beta}\\) 的广义最小二乘估计为 \\(\\hat{\\boldsymbol{\\beta}}(\\boldsymbol{\\theta}) = (D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}D)^{-1} D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\boldsymbol{y}\\) ，关于参数 \\(\\boldsymbol{\\theta}\\) 的剖面对数似然函数如下：\n\\[\n\\log \\mathcal{L}(\\boldsymbol{\\theta}) = -\\frac{n}{2}\\log (2\\pi) - \\frac{1}{2}\\log (\\det V_{\\boldsymbol{\\theta}}) -\\frac{1}{2}\\boldsymbol{y}^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\big(I - D(D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}D)^{-1}D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\big)\\boldsymbol{y}\n\\]\n下面考虑一个来自 MASS 包真实数据 topo。topo 数据集最初来自 John C. Davis （1973年）所著的书《Statistics and Data Analysis in Geology》。后来， J. J. Warnes 和 B. D. Ripley （1987年）以该数据集为例指出空间高斯过程的协方差函数的似然估计中存在的问题(Warnes 和 Ripley 1987)，并将其作为数据集 topo 放在 MASS 包里。Paulo J. Ribeiro Jr 和 Peter J. Diggle （2001年）将该数据集打包成自定义的 geodata 数据类型，放在 geoR 包里，并在他俩合著的书《Model-based Geostatistics》中多次出现。topo 是空间地形数据集，包含有 52 行 3 列，数据点是 310 平方英尺范围内的海拔高度数据，x 坐标每单位 50 英尺，y 坐标单位同 x 坐标，海拔高度 z 单位是英尺。\n\nlibrary(MASS)\ndata(topo)\nstr(topo)\n\n#&gt; 'data.frame':    52 obs. of  3 variables:\n#&gt;  $ x: num  0.3 1.4 2.4 3.6 5.7 1.6 2.9 3.4 3.4 4.8 ...\n#&gt;  $ y: num  6.1 6.2 6.1 6.2 6.2 5.2 5.1 5.3 5.7 5.6 ...\n#&gt;  $ z: int  870 793 755 690 800 800 730 728 710 780 ...\n\n\n根据 topo 数据集， \\(D = \\boldsymbol{1}\\) 是一个 \\(52 \\times 1\\) 的列向量，\\(\\boldsymbol{\\beta} = \\beta\\) 是一个截距项。设置参数初值 \\((\\sigma,\\phi) = (65,2)\\) 。为了与 Ripley 的论文中的图比较，下面扔掉了对数似然函数中常数项，用 R 语言编码的似然函数如下：\n\nlog_lik &lt;- function(x) {\n  n &lt;- nrow(topo)\n  D &lt;- t(t(rep(1, n)))\n  Sigma &lt;- x[1]^2 * exp(-as.matrix(dist(topo[, c(\"x\", \"y\")])) / x[2])\n  inv_Sigma &lt;- solve(Sigma)\n  P &lt;- diag(1, n) - D %*% solve(t(D) %*% solve(Sigma, D), t(D)) %*% inv_Sigma\n  as.vector(-1 / 2 * log(det(Sigma)) - 1 / 2 * t(topo[, \"z\"]) %*% inv_Sigma %*% P %*% topo[, \"z\"])\n}\nlog_lik(x = c(65, 2))\n\n#&gt; [1] -207.1364\n\n\n关于参数的偏导计算复杂，就不计算梯度了，下面调用 R 软件内置的 nlminb 优化器。发现，对不同的初始值，收敛到不同的位置，目标函数值非常接近。\n\nop &lt;- OP(\n  objective = F_objective(log_lik, n = 2L),\n  bounds = V_bound(lb = c(55, 5), ub = c(75, 8)),\n  maximum = TRUE\n)\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(65, 2))\nnlp$solution\n\n#&gt; [1] 65  5\n\nnlp$objval\n\n#&gt; [1] -197.4197\n\n\n如果初始值靠近局部极值点，则就近收敛到该极值点，比如初值 \\((65, 7)\\) ， \\((70, 7.5)\\) 。\n\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(65, 7))\nnlp$solution\n\n#&gt; [1] 65  7\n\nnlp$objval\n\n#&gt; [1] -196.9407\n\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(70, 7.5))\nnlp$solution\n\n#&gt; [1] 70.0  7.5\n\nnlp$objval\n\n#&gt; [1] -196.8441\n\n\n尝试调用来自 nloptr 包的全局优化求解器 nloptr.directL ，大大小小的坑都跳过去了，结果还是比较满意的。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\nnlp$solution\n\n#&gt; [1] 63.934432  6.121382\n\nnlp$objval\n\n#&gt; [1] -196.8158\n\n\n目标区域网格化，计算格点处的似然函数值，然后绘制似然函数图像。\n\ndat &lt;- expand.grid(\n  sigma = seq(from = 55, to = 75, length.out = 41),\n  phi = seq(from = 5, to = 8, length.out = 31)\n)\ndat$fn &lt;- apply(dat, 1, log_lik)\n\n似然函数关于参数 \\((\\sigma,\\phi)\\) 的三维曲面见 图 21.3 。\n\n代码wireframe(\n  data = dat, fn ~ sigma * phi,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(sigma), ylab = expression(phi),\n  zlab = list(expression(\n    italic(log-lik) ~ group(\"(\", list(sigma, phi), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 21.3: 对数似然函数的曲面图\n\n\n\n\n等高线图呈现一道非常长且平滑的山岭 long flat ridge，山岭上布满许多局部极大值，普通的数值优化求解器常常陷入其中，只有全局优化求解器才可能找到全局极大值点。高斯过程回归模型的对数似然函数是非凸的，多模态的。\n\n代码levelplot(fn ~ sigma * phi,\n  data = dat, aspect = 1,\n  xlim = c(54.5, 75.5), ylim = c(4.9, 8.1),\n  xlab = expression(sigma), ylab = expression(phi),\n  col.regions = cm.colors, contour = TRUE,\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = 0, units = \"inches\"),\n      right.padding = list(x = 0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.5, units = \"inches\"),\n      top.padding = list(x = -.5, units = \"inches\")\n    )\n  )\n)\n\n\n\n\n\n\n图 21.4: 对数似然函数的等高线图\n\n\n\n\n上图中没有看到许多局部极小值，与作者论文中的图 1 似乎不符。原因是什么？似然函数中涉及到的矩阵运算不精确，应该设计精度更高的运算方式？lattice 包绘图引擎无法展示更加细微的差异？还有一种解释，上图是对的，算法迭代时，对不同的初值，常常收敛到不同的结果，而这些不同的结果都位于岭上不同位置，对应的对数似然值却又几乎一样。\n作为验证，下面调用 nlme 包的 gls() 函数拟合数据，参数的极大似然估计结果与全局优化求解器的结果比较一致。参数估计结果 \\((\\sigma, \\phi)= (63.93429, 6.121352)\\) ，对数似然函数值为 -244.6006 ，自编的似然函数 log_lik() 在最优解处的值为 -196.8158，再加上之前扔掉的常数项 -52 / 2 * log(2 * pi) ，就是 -244.6006 ，丝毫不差。\n\nlibrary(nlme)\nfit_topo_ml &lt;- gls(z ~ 1,\n  data = topo, method = \"ML\",\n  correlation = corExp(value = 65, form = ~ x + y)\n)\nsummary(fit_topo_ml)\n\n#&gt; Generalized least squares fit by maximum likelihood\n#&gt;   Model: z ~ 1 \n#&gt;   Data: topo \n#&gt;        AIC     BIC    logLik\n#&gt;   495.2012 501.055 -244.6006\n#&gt; \n#&gt; Correlation Structure: Exponential spatial correlation\n#&gt;  Formula: ~x + y \n#&gt;  Parameter estimate(s):\n#&gt;    range \n#&gt; 6.121352 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Value Std.Error  t-value p-value\n#&gt; (Intercept) 863.708  45.49859 18.98318       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.7169766 -1.1919732 -0.5272282  0.1453374  1.5061096 \n#&gt; \n#&gt; Residual standard error: 63.93429 \n#&gt; Degrees of freedom: 52 total; 51 residual\n\n\n如果使用限制极大似然估计，会发现参数估计结果与之相距甚远，而对数似然函数值相差无几。参数估计结果 \\((\\sigma,\\phi) = (128.8275, 25.47324)\\) 。\n\nfit_topo_reml &lt;- gls(z ~ 1,\n  data = topo, method = \"REML\",\n  correlation = corExp(value = 65, form = ~ x + y)\n)\nsummary(fit_topo_reml)\n\n#&gt; Generalized least squares fit by REML\n#&gt;   Model: z ~ 1 \n#&gt;   Data: topo \n#&gt;        AIC      BIC    logLik\n#&gt;   485.1558 490.9513 -239.5779\n#&gt; \n#&gt; Correlation Structure: Exponential spatial correlation\n#&gt;  Formula: ~x + y \n#&gt;  Parameter estimate(s):\n#&gt;    range \n#&gt; 25.47324 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Value Std.Error  t-value p-value\n#&gt; (Intercept) 877.8956  116.7163 7.521619       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.45850506 -0.70167923 -0.37178079 -0.03800119  0.63732032 \n#&gt; \n#&gt; Residual standard error: 128.8275 \n#&gt; Degrees of freedom: 52 total; 51 residual",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-poisson-mixture-distributions",
    "href": "optimization-problems.html#sec-poisson-mixture-distributions",
    "title": "21  优化问题",
    "section": "\n21.4 泊松混合分布",
    "text": "21.4 泊松混合分布\n有限混合模型（Finite Mixtures of Distributions）的应用非常广泛，本节参考 BB 包 (Varadhan 和 Gilbert 2009) 的帮助手册，以泊松混合分布为例，介绍其参数的极大似然估计。更多详细的理论和算法介绍从略，感兴趣的读者可以查阅相关文献 (Hasselblad 1969)。BB 包比内置函数 optim() 功能更强，可以求解大规模非线性方程组，也可以求解带简单约束的非线性优化问题，还可以从多个初始值出发寻找全局最优解。\n两个泊松分布以一定比例 \\(p\\) 混合，以概率 \\(p\\) 服从泊松分布 \\(\\mathrm{Poisson}(\\lambda_1)\\) ，而以概率 \\(1-p\\) 服从泊松分布 \\(\\mathrm{Poisson}(\\lambda_1)\\) 。\n\\[\np\\times \\mathrm{Poisson}(\\lambda_1) + (1 - p)\\times \\mathrm{Poisson}(\\lambda_2)\n\\]\n泊松混合分布的概率密度函数 \\(f(x;p,\\lambda_1,\\lambda_2)\\) 如下：\n\\[\nf(x;p,\\lambda_1,\\lambda_2) = p \\times \\frac{\\lambda_1^x \\exp(-\\lambda_1)}{x!} + (1 - p) \\times \\frac{\\lambda_2^x \\exp(-\\lambda_2)}{x!}\n\\]\n随机变量 \\(X\\) 服从参数为 \\(p\\) 的伯努利分布 \\(X \\sim \\mathrm{Bernoulli}(1, p)\\) ，随机变量 \\(Y\\) 服从泊松混合分布，在伯努利分布的基础上，泊松混合分布也可作如下定义：\n\\[\n\\begin{array}{l}\nY \\sim \\left\\{\n\\begin{array}{l}\n\\mathrm{Poisson}(\\lambda_1), \\quad \\text{当} ~ X = 1 ~ \\text{时},\\\\\n\\mathrm{Poisson}(\\lambda_2), \\quad \\text{当} ~ X = 0 ~ \\text{时}.\n\\end{array} \\right.\n\\end{array}\n\\]\n对数似然函数如下：\n\\[\n\\ell(p,\\lambda_1,\\lambda_2) = \\sum_{i=0}^{n}y_i \\log\\big(p\\times \\exp(-\\lambda_1) \\times\\frac{\\lambda_1^{x_i}}{x_i!} + (1 - p)\\times \\exp(-\\lambda_2) \\times\\frac{\\lambda_2 ^{x_i}}{x_i!} \\big)\n\\]\n下 表格 21.1 数据来自 1947 年 Walter Schilling 发表在 JASA 的一篇文章 (Schilling 1947)。连续三年搜集伦敦《泰晤士报》刊登的死亡告示，每天的告示发布 80 岁及以上女性死亡人数。经过汇总统计，发现，在三年里，没有人死亡的告示出现 162 次，死亡 1 人的告示出现 267 次。\n\n\n表格 21.1: 死亡人数的统计\n\n\n\n死亡人数\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n发生频次\n162\n267\n271\n185\n111\n61\n27\n8\n3\n1\n\n\n\n\n\n考虑到夏季和冬季对老人死亡率的影响是不同的，因此，引入泊松混合分布来对数据建模。\n\n# 对数似然函数\n# p 是一个长度为 3 的向量\n# y 是观测数据向量\npoissmix_loglik &lt;- function(p, y) {\n  i &lt;- 0:(length(y) - 1)\n  loglik &lt;- y * log(p[1] * exp(-p[2]) * p[2]^i / exp(lgamma(i + 1)) +\n    (1 - p[1]) * exp(-p[3]) * p[3]^i / exp(lgamma(i + 1)))\n  sum(loglik)\n}\n# lgamma(i + 1) 表示整数 i 的阶乘的对数\n# 参数的下限\nlo &lt;- c(0, 0, 0)\n# 参数的上限\nhi &lt;- c(1, Inf, Inf)\n# 随机生成一组参数初始值\np0 &lt;- runif(3, c(0.2, 1, 1), c(0.8, 5, 8)) \n# 汇总统计出来的死亡人数的频次分布\ny &lt;- c(162, 267, 271, 185, 111, 61, 27, 8, 3, 1)\n\n调用 BB 包的函数 BBoptim() 求解多元非线性箱式约束优化问题。\n\nlibrary(BB)\n# 参数估计\nans &lt;- BBoptim(\n  par = p0, fn = poissmix_loglik, y = y,\n  lower = lo, upper = hi, \n  control = list(maximize = TRUE)\n)\n\n#&gt; iter:  0  f-value:  -2968.501  pgrad:  7.572203 \n#&gt; iter:  10  f-value:  -1992.18  pgrad:  3.503607 \n#&gt; iter:  20  f-value:  -1991.277  pgrad:  2.365923 \n#&gt; iter:  30  f-value:  -1990.325  pgrad:  1.405494 \n#&gt; iter:  40  f-value:  -1989.979  pgrad:  1.709452 \n#&gt; iter:  50  f-value:  -1989.946  pgrad:  0.02604793 \n#&gt;   Successful convergence.\n\nans\n\n#&gt; $par\n#&gt; [1] 0.3598808 1.2560870 2.6633987\n#&gt; \n#&gt; $value\n#&gt; [1] -1989.946\n#&gt; \n#&gt; $gradient\n#&gt; [1] 1.818989e-05\n#&gt; \n#&gt; $fn.reduction\n#&gt; [1] -978.5554\n#&gt; \n#&gt; $iter\n#&gt; [1] 59\n#&gt; \n#&gt; $feval\n#&gt; [1] 61\n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"Successful convergence\"\n#&gt; \n#&gt; $cpar\n#&gt; method      M \n#&gt;      2     50\n\n\nnumDeriv::hessian 计算极大似然点的黑塞矩阵，然后计算参数估计的标准差。\n\n# 黑塞矩阵\nhess &lt;- numDeriv::hessian(x = ans$par, func = poissmix_loglik, y = y)\nhess\n\n#&gt;           [,1]       [,2]       [,3]\n#&gt; [1,] -907.1131  270.22803  341.25563\n#&gt; [2,]  270.2280 -113.47865  -61.68173\n#&gt; [3,]  341.2556  -61.68173 -192.78329\n\n# 标准差\nse &lt;- sqrt(diag(solve(-hess)))\nse\n\n#&gt; [1] 0.1946826 0.3500306 0.2504754\n\n\nmultiStart 从不同初始值出发寻找全局最大值，先找一系列局部极大值，通过比较获得全局最大值。\n\n# 随机生成 10 组初始值\np0 &lt;- matrix(runif(30, c(0.2, 1, 1), c(0.8, 8, 8)), \n             nrow = 10, ncol = 3, byrow = TRUE)\nans &lt;- multiStart(\n  par = p0, fn = poissmix_loglik, action = \"optimize\",\n  y = y, lower = lo, upper = hi, quiet = TRUE,\n  control = list(maximize = TRUE, trace = FALSE)\n)\n# 筛选出迭代收敛的解\npmat &lt;- round(cbind(ans$fvalue[ans$conv], ans$par[ans$conv, ]), 4)\ndimnames(pmat) &lt;- list(NULL, c(\"fvalue\", \"parameter 1\", \n                               \"parameter 2\", \"parameter 3\"))\n# 去掉结果一样的重复解\npmat[!duplicated(pmat), ]\n\n#&gt;         fvalue parameter 1 parameter 2 parameter 3\n#&gt; [1,] -1989.946      0.6401      2.6634      1.2561\n#&gt; [2,] -1989.946      0.3599      1.2561      2.6634\n#&gt; [3,] -1999.873      0.3187      1.9075      2.2792",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-maximum-likelihood-estimation",
    "href": "optimization-problems.html#sec-maximum-likelihood-estimation",
    "title": "21  优化问题",
    "section": "\n21.5 极大似然估计",
    "text": "21.5 极大似然估计\n一元函数最优化问题和求根问题是相关的。在统计应用中，二项分布的比例参数的置信区间估计涉及求根，伽马分布的参数的极大似然估计涉及求根。下面介绍求根在估计伽马分布的参数中的应用。\n形状参数为 \\(\\alpha\\) 和尺度参数为 \\(\\sigma\\) 的伽马分布的概率密度函数 \\(f(x;\\alpha, \\sigma)\\) 如下：\n\\[\nf(x;\\alpha,\\sigma) = \\frac{1}{\\sigma^\\alpha \\Gamma(\\alpha)}x^{\\alpha - 1} \\exp(- \\frac{x}{\\sigma}), \\quad \\alpha \\geq 0, \\sigma &gt; 0\n\\]\n其中，\\(\\Gamma(\\cdot)\\) 表示伽马函数，伽马分布的均值为 \\(\\alpha \\sigma\\) ，方差为 \\(\\alpha\\sigma^2\\) 。下 图 21.5 展示两个伽马分布的概率密度函数，形状参数分别为 5 和 9，尺度参数均为 1，即伽马分布 \\(f(x; 5, 1)\\) 和 \\(f(x; 9, 1)\\) 。\n\n代码ggplot() +\n  geom_function(\n    fun = dgamma, args = list(shape = 9, scale = 1),\n    aes(colour = \"list(alpha == 9, sigma == 1)\"),\n    linewidth = 1.2, xlim = c(0, 20), \n  ) +\n  geom_function(\n    fun = dgamma, args = list(shape = 5, scale = 1),\n    aes(colour = \"list(alpha == 5, sigma == 1)\"),\n    linewidth = 1.2, xlim = c(0, 20)\n  ) +\n  scale_colour_viridis_d(\n    labels = scales::parse_format(),\n    begin = 0.3, end = 0.7,\n    option = \"C\"\n  ) +\n  theme_bw(base_family = \"sans\") +\n  theme(axis.title = element_text(family = \"Noto Serif CJK SC\"),\n        legend.title = element_text(family = \"Noto Serif CJK SC\"),\n        legend.position = \"top\", legend.justification = \"right\") +\n  labs(x = \"随机变量\", y = \"概率密度\", color = \"参数\")\n\n\n\n\n\n\n图 21.5: 伽马分布的概率密度函数\n\n\n\n\n给定一组来自伽马分布的样本 \\(x_1,x_2,\\ldots,x_n\\) ，关于参数 \\(\\alpha\\) 和 \\(\\sigma\\) 的似然函数如下：\n\\[\n\\mathcal{L}(\\alpha, \\sigma) = \\big(\\frac{1}{\\sigma^\\alpha \\Gamma(\\alpha)}\\big)^{n} (\\prod_{i=1}^{n} x_i)^{\\alpha - 1} \\exp(- \\frac{ \\sum_{i=1}^{n} x_i }{\\sigma})\n\\]\n则，其对数似然函数如下：\n\\[\n\\ell(\\alpha, \\sigma) = -n\\big(\\alpha \\log(\\sigma) + \\log \\Gamma(\\alpha) \\big) + (\\alpha - 1)\\sum_{i=1}^{n}\\log(x_i) - \\frac{ \\sum_{i=1}^{n} x_i }{\\sigma}\n\\]\n对数似然函数关于参数 \\(\\alpha\\) 和 \\(\\sigma\\) 的偏导数如下：\n\\[\n\\begin{aligned}\n\\frac{\\partial \\ell(\\alpha,\\sigma)}{\\partial \\alpha} &= -n\\Big( \\log(\\sigma) + \\big(\\log \\Gamma(\\alpha)\\big)' \\Big) + \\sum_{i=1}^{n}\\log (x_i) = 0 \\\\\n\\frac{\\partial \\ell(\\alpha,\\sigma)}{\\partial \\sigma} &= - \\frac{n\\alpha}{\\sigma} + \\frac{\\sum_{i=1}^{n}x_i}{\\sigma^2} = 0\n\\end{aligned}\n\\]\n根据第二个式子可得 \\(\\sigma = \\frac{1}{n\\alpha}\\sum_{i=1}^{n}x_i\\) ，将其代入第一个式子可得\n\\[\n\\log(\\alpha) - \\big(\\log \\Gamma(\\alpha)\\big)' = \\log\\big(\\frac{1}{n}\\sum_{i=1}^{n}x_i\\big) - \\frac{1}{n}\\sum_{i=1}^{n}\\log (x_i)\n\\]\n\nset.seed(20232023)\nx &lt;- rgamma(1000, shape = 1.5, scale = 2)\n# 形状参数和尺度参数的矩估计\nc(mean(x)^2 /var(x), var(x)/mean(x))\n\n#&gt; [1] 1.636030 1.902239\n\n# 极大似然估计\n# 常量\ncc &lt;- log(mean(x)) - mean(log(x))\n# 方程\nfun &lt;- function(alpha){\n  log(alpha) - digamma(alpha) - cc\n}\n# 找根\nuniroot(f = fun, interval = c(1, 3))\n\n#&gt; $root\n#&gt; [1] 1.610272\n#&gt; \n#&gt; $f.root\n#&gt; [1] 2.825244e-09\n#&gt; \n#&gt; $iter\n#&gt; [1] 6\n#&gt; \n#&gt; $init.it\n#&gt; [1] NA\n#&gt; \n#&gt; $estim.prec\n#&gt; [1] 6.103516e-05\n\n\n求得形状参数的估计 \\(\\alpha = 1.610272\\) ，进而，可得尺度参数的估计 \\(\\sigma = 1.932667\\) 。\n函数 uniroot() 只能找到方程的一个根，rootSolve 包采用牛顿-拉弗森（ Newton-Raphson ）算法找一元非线性方程（组）的根，特别适合有多个根的情况。\n\nlibrary(rootSolve)\n# 非线性方程（组）的根\nmultiroot(f = fun, start = 1.2)\n\n#&gt; $root\n#&gt; [1] 1.610272\n#&gt; \n#&gt; $f.root\n#&gt; [1] 3.121097e-10\n#&gt; \n#&gt; $iter\n#&gt; [1] 5\n#&gt; \n#&gt; $estim.precis\n#&gt; [1] 3.121097e-10\n\n# 搜索一个方程在区间内所有的根\nuniroot.all(f = fun, interval = c(1, 3))\n\n#&gt; [1] 1.610339",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-optimization-exercises",
    "href": "optimization-problems.html#sec-optimization-exercises",
    "title": "21  优化问题",
    "section": "\n21.6 习题",
    "text": "21.6 习题\n\n某人要周游美国各州，从纽约出发，走遍 50 个州的行政中心，最后回到纽约。规划旅行线路使得总行程最短。Base R 内置的 R 包 datasets 包含美国 50 个州的地理中心数据 state.center 。\n有限混合模型也常用 EM 算法来估计参数，美国黄石公园老忠实间歇泉的喷发规律近似为二维高斯混合分布，请读者以 R 软件内置的数据集 faithful 为基础，采用 EM 算法估计参数。\n\n获取百度、阿里、腾讯、京东、美团、滴滴、字节、360、网易、新浪等 10 支股票的历史股价数据。根据 2021-12-01 至 2022-12-01 股票的调整价计算 12 个月的股价收益率，根据月度股价收益率和波动率数据，设置投资组合，使得月度收益率不低于2%。股票代码以数字编码和 HK 结尾的为港股代码，有的公司在美股和港股上都有。可以用 quantmod 包下载各个公司的股价数据，下载拼多多股价数据的代码如下：\nquantmod::getSymbols(\"PDD\", auto.assign = FALSE, src = \"yahoo\")\n\n\n表格 21.2: 一些互联网公司及股票代码\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n公司\n美团\n阿里巴巴\n京东\n百度\n腾讯\n拼多多\n京东\n阿里巴巴\n\n\n股票代码\n3690.HK\n9988.HK\n9618.HK\n9888.HK\n0700.HK\nPDD\nJD\nBABA\n\n\n\n\n\n\n\n\n\n\n\nHahsler, Michael, 和 Kurt Hornik. 2007. 《TSP: Infrastructure for the traveling salesperson problem》. Journal of Statistical Software 23 (2): 1–21. https://doi.org/10.18637/jss.v023.i02.\n\n\nHasselblad, Victor. 1969. 《Estimation of Finite Mixtures of Distributions from the Exponential Family》. Journal of the American Statistical Association 64 (328): 1459–71. https://doi.org/10.1080/01621459.1969.10501071.\n\n\nSchilling, Walter. 1947. 《A Frequency Distribution Represented as the Sum of Two Poisson Distributions》. Journal of the American Statistical Association 42 (239): 407–24.\n\n\nVaradhan, Ravi, 和 Paul Gilbert. 2009. 《BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function》. Journal of Statistical Software 32 (4): 1–26. https://www.jstatsoft.org/v32/i04/.\n\n\nWarnes, J. J., 和 B. D. Ripley. 1987. 《Problems with likelihood estimation of covariance functions of spatial gaussian processes》. Biometrika 74 (3): 640–42.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "Agresti, Alan. 2007. An Introduction to Categorical Data\nAnalysis. 2nd ed. Hoboken, New Jersey: John Wiley & Sons, Inc.\n\n\nAnsari, A. R., and R. A. Bradley. 1960. “Rank-Sum Tests for\nDispersions.” The Annals of Mathematical Statistics 31\n(4): 1174–89. https://doi.org/10.1214/aoms/1177705688.\n\n\nAnscombe, F. J. 1973. “Graphs in Statistical Analysis.”\nThe American Statistician 27 (1): 17. https://doi.org/10.2307/2682899.\n\n\nBates, Douglas, and Dirk Eddelbuettel. 2013. “Fast and Elegant\nNumerical Linear Algebra Using the RcppEigen\nPackage.” Journal of Statistical Software 52 (5): 1–24.\nhttps://doi.org/10.18637/jss.v052.i05.\n\n\nBerkelaar, Michel et al. 2023. lpSolve:\nInterface to Lp_solve v. 5.5 to Solve\nLinear/Integer Programs. https://CRAN.R-project.org/package=lpSolve.\n\n\nBickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. “Sex Bias\nin Graduate Admissions: Data from Berkeley.” Science 187\n(4175): 398–404. https://doi.org/10.1126/science.187.4175.398.\n\n\nBiecek, Przemyslaw. 2023. DrWhy: Explain, Explore and\nDebug Predictive Machine Learning Models. https://github.com/ModelOriented/DrWhy.\n\n\nBrandao, Filipe. 2023. rAMPL:\nAMPL API for r. https://github.com/ampl/rAMPL.\n\n\nBrunson, Jason Cory. 2020. “ggalluvial: Layered Grammar for Alluvial\nPlots.” Journal of Open Source Software 5 (49): 2017. https://doi.org/10.21105/joss.02017.\n\n\nClopper, C. J., and E. S. Pearson. 1934. “The Use of Confidence or\nFiducial Limits Illustrated in the Case of the Binomial.”\nBiometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nCohen, Jacob. 1994. “The Earth Is Round (p &lt; .05).” American\nPsychologist 49 (12): 997–1003. https://doi.org/10.1037/0003-066x.49.12.997.\n\n\nDavies, Rhian, Steph Locke, and Lucy D’Agostino McGowan. 2022. datasauRus: Datasets from the Datasaurus\nDozen. https://CRAN.R-project.org/package=datasauRus.\n\n\nDobson, Annette J. 1983. An Introduction to Statistical\nModelling. 1st ed. London: Chapman; Hall/CRC. https://doi.org/10.1007/978-1-4899-3174-0.\n\n\nDunning, Iain, Joey Huchette, and Miles Lubin. 2017.\n“JuMP: A Modeling Language for Mathematical\nOptimization.” SIAM Review 59 (2): 295–320. https://doi.org/10.1137/15M1020575.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, and Robert Tibshirani.\n2004. “Least angle regression.”\nThe Annals of Statistics 32 (2): 407–99. https://doi.org/10.1214/009053604000000067.\n\n\nEpps, T. W., and Lawrence B. Pulley. 1983. “A Test for Normality\nBased on the Empirical Characteristic Function.”\nBiometrika 70 (3): 723–26. https://doi.org/10.2307/2336512.\n\n\nFeinerer, Ingo, Kurt Hornik, and David Meyer. 2008. “Text Mining\nInfrastructure in R.” Journal of Statistical\nSoftware 25 (5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nFligner, Michael A., and Timothy J. Killeen. 1976.\n“Distribution-Free Two-Sample Tests for Scale.” Journal\nof the American Statistical Association 71 (353): 210–13. https://doi.org/10.1080/01621459.1976.10481517.\n\n\nFriendly, Michael. 2021. HistData: Data Sets from the\nHistory of Statistics and Data Visualization. https://CRAN.R-project.org/package=HistData.\n\n\nFriendly, Michael, and David Meyer. 2016. Discrete Data Analysis\nwith r: Visualization and Modeling Techniques for Categorical and Count\nData. 1st ed. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nFu, Anqi, and Balasubramanian Narasimhan. 2023.\nECOSolveR: Embedded Conic Solver in r. https://CRAN.R-project.org/package=ECOSolveR.\n\n\nGalton, F. 1886. “Regression Towards Mediocrity in Hereditary\nStature.” Journal of the Anthropological Institute 15:\n246–63.\n\n\nGrün, Bettina, and Kurt Hornik. 2011. “topicmodels: An R Package for Fitting\nTopic Models.” Journal of Statistical Software 40 (13):\n1–30. https://doi.org/10.18637/jss.v040.i13.\n\n\nHahsler, Michael, and Kurt Hornik. 2007. “TSP:\nInfrastructure for the Traveling Salesperson\nProblem.” Journal of Statistical Software 23 (2): 1–21.\nhttps://doi.org/10.18637/jss.v023.i02.\n\n\nHanley, James A. 2004. “’Transmuting’ Women into Men: Galton’s\nFamily Data on Human Stature.” The American Statistician\n58 (3): 237–43.\n\n\nHart, William E, Jean-Paul Watson, and David L Woodruff. 2011.\n“Pyomo: Modeling and Solving Mathematical Programs in\nPython.” Mathematical Programming\nComputation 3 (3): 219–60.\n\n\nHasselblad, Victor. 1969. “Estimation of Finite Mixtures of\nDistributions from the Exponential Family.” Journal of the\nAmerican Statistical Association 64 (328): 1459–71. https://doi.org/10.1080/01621459.1969.10501071.\n\n\nHeyde, C. C., E. Seneta, P. Crépel, S. E. Fienberg, and J. Gani. 2001.\nStatisticians of the Centuries. New York, NY: Springer-Verlag.\nhttps://doi.org/10.1007/978-1-4613-0179-0.\n\n\nHolt, Charles C. 2004. “Forecasting Seasonals and Trends by\nExponentially Weighted Moving Averages.” International\nJournal of Forecasting 20 (1): 5–10. https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nHSU, P. L. 1938. “Contribution to the Theory of \"Student’s\" T-Test as Applied to the Problem of\nTwo Samples.” Statistical Research Memoirs 2: 1–24.\n\n\n———. 1983. Collected Papers. New York, NY: Springer-Verlag.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine Learning\nfor Text Analysis in R. New York: Chapman; Hall/CRC.\nhttps://smltar.com/.\n\n\nJohnson, Steven G. 2023. The NLopt Nonlinear\nOptimization Package. https://CRAN.R-project.org/package=nloptr.\n\n\nKabacoff, Robert I. 2022. R in Action: Data Analysis\nand Graphics with R and Tidyverse. 3rd\ned. Shelter Island, NY: Manning Publications Co.\n\n\nKim, Seock-Ho, and Allan S. Cohen. 1998. “On the Behrens-Fisher\nProblem: A Review.” Journal of Educational and Behavioral\nStatistics 23 (4): 356–77. https://doi.org/10.2307/1165281.\n\n\nKim, Yongdai, Hosik Choi, and Hee-Seok Oh. 2008. “Smoothly Clipped\nAbsolute Deviation on High Dimensions.” Journal of the\nAmerican Statistical Association 103 (484): 1665–73. https://doi.org/10.1198/016214508000001066.\n\n\nKolaczyk, Eric D., and Gábor Csárdi. 2020. Statistical Analysis of\nNetwork Data with R. 2nd ed. Springer, New York, NY.\nhttps://doi.org/10.1007/978-3-030-44129-6.\n\n\nKuhn, Max, and Hadley Wickham. 2020. Tidymodels: A Collection of\nPackages for Modeling and Machine Learning Using Tidyverse\nPrinciples. https://www.tidymodels.org.\n\n\nLang, Michel, and Patrick Schratz. 2023. mlr3verse: Easily Install and Load the mlr3 Package Family. https://CRAN.R-project.org/package=mlr3verse.\n\n\nLüdecke, Daniel. 2019. strengejacke:\nLoad Packages Associated with Strenge Jacke! https://github.com/strengejacke/strengejacke.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Brenton M.\nWiernik, Etienne Bacher, Rémi Thériault, and Dominique Makowski. 2022.\n“easystats: Framework for Easy\nStatistical Modeling, Visualization, and Reporting.”\nCRAN. https://easystats.github.io/easystats/.\n\n\nMeyer, David, Achim Zeileis, and Kurt Hornik. 2006. “The Strucplot\nFramework: Visualizing Multi-Way Contingency Tables with vcd.” Journal of Statistical\nSoftware 17 (3): 1–48. https://doi.org/10.18637/jss.v017.i03.\n\n\nMood, A. M. 1954. “On the Asymptotic Efficiency of Certain\nNonparametric Two-Sample Tests.” The Annals of Mathematical\nStatistics 25 (3): 514–22. https://doi.org/10.1214/aoms/1177728719.\n\n\nNewcombe, Robert G. 1998. “Interval Estimation for the Difference\nBetween Independent Proportions: Comparison of Eleven Methods.”\nStatistics in Medicine 17 (8): 873–90. https://doi.org/10.1002/(SICI)1097-0258(19980430)17:8&lt;873::AID-SIM779&gt;3.0.CO;2-I.\n\n\nO’Donoghue, Brendan, Eric Chu, Parikh Neal, and Stephen Boyd. 2016.\n“Operator Splitting for Conic Optimization via Homogeneous\nSelf-Dual Embedding.” Journal of Optimization Theory and\nApplications 169 (3): 1042–68. https://doi.org/10.1007/s10957-016-0892-3.\n\n\nRigby, R. A., and D. M. Stasinopoulos. 2005. “Generalized Additive\nModels for Location, Scale and Shape (with Discussion).”\nJournal of the Royal Statistical Society: Series C (Applied\nStatistics) 54 (3): 507–54. https://doi.org/10.1111/j.1467-9876.2005.00510.x.\n\n\nRyan, Jeffrey A., and Joshua M. Ulrich. 2022. quantmod: Quantitative Financial Modelling\nFramework. https://CRAN.R-project.org/package=quantmod.\n\n\nS original by Berwin A. Turlach, Fortran contributions from Cleve Moler\ndpodi/LINPACK), R port by Andreas Weingessel. 2019. quadprog: Functions to Solve Quadratic Programming\nProblems. https://CRAN.R-project.org/package=quadprog.\n\n\nSarkar, Deepayan. 2008. lattice:\nMultivariate Data Visualization with R. New York:\nSpringer. http://lmdvr.r-forge.r-project.org.\n\n\nSchilling, Walter. 1947. “A Frequency Distribution Represented as\nthe Sum of Two Poisson Distributions.” Journal of the\nAmerican Statistical Association 42 (239): 407–24.\n\n\nSchwendinger, Florian, and Hans W. Borchers. 2023. CRAN Task\nView: Optimization and Mathematical Programming. https://CRAN.R-project.org/view=Optimization.\n\n\nSchwendinger, Florian, and Dirk Schumacher. 2023. highs: HiGHS Optimization\nSolver. https://CRAN.R-project.org/package=highs.\n\n\nScrucca, Luca. 2013. “GA: A Package for Genetic\nAlgorithms in R.” Journal of Statistical\nSoftware 53 (4): 1–37. https://doi.org/10.18637/jss.v053.i04.\n\n\nShapiro, S. S., and M. B. Wilk. 1965. “An Analysis of Variance\nTest for Normality (Complete Samples).” Biometrika 52\n(3-4): 591–611. https://doi.org/10.1093/biomet/52.3-4.591.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR. New York: O’Reilly Media, Inc. https://www.tidytextmining.com/.\n\n\n\"Student\". 1908. “The Probable Error of a Mean.”\nBiometrika 6: 1–25.\n\n\nTang, Yuan, Masaaki Horikoshi, and Wenxuan Li. 2016. “ggfortify: Unified Interface to Visualize\nStatistical Result of Popular r Packages.” The R Journal\n8 (2): 474–85. https://doi.org/10.32614/RJ-2016-060.\n\n\nTheussl, Stefan, and Kurt Hornik. 2023. Rglpk: R/GNU\nLinear Programming Kit Interface. https://CRAN.R-project.org/package=Rglpk.\n\n\nTheußl, Stefan, Florian Schwendinger, and Kurt Hornik. 2020.\n“ROI: An Extensible R Optimization\nInfrastructure.” Journal of Statistical Software 94\n(15): 1–64. https://doi.org/10.18637/jss.v094.i15.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via\nthe Lasso.” Journal of the Royal Statistical\nSociety. Series B (Methodological) 58 (1): 267–88. http://www.jstor.org/stable/2346178.\n\n\nTyner, Sam, François Briatte, and Heike Hofmann. 2017. “Network\nVisualization with ggplot2.”\nThe R Journal 9 (1): 27–59. https://doi.org/10.32614/RJ-2017-023.\n\n\nVaradhan, Ravi, and Paul Gilbert. 2009. “BB: An\nR Package for Solving a Large System of Nonlinear Equations\nand for Optimizing a High-Dimensional Nonlinear Objective\nFunction.” Journal of Statistical Software 32 (4): 1–26.\nhttps://www.jstatsoft.org/v32/i04/.\n\n\nWarnes, J. J., and B. D. Ripley. 1987. “Problems with Likelihood\nEstimation of Covariance Functions of Spatial Gaussian\nProcesses.” Biometrika 74 (3): 640–42.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant\nGraphics for Data Analysis. 2nd ed. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science: Import, Tidy, Transform, Visualize,\nand Model Data. 2nd ed. Sebastopol, California: O’Reilly Media,\nInc. https://r4ds.hadley.nz/.\n\n\nWickham, Hadley, Danielle Navarro, and Thomas Lin Pedersen. 2024.\nggplot2: Elegant Graphics for Data\nAnalysis. 3rd ed. Springer-Verlag New York. https://ggplot2-book.org/.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession,\nand Statistical Inference.” Journal of the American\nStatistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nWinters, Peter R. 1960. “Forecasting Sales by Exponentially\nWeighted Moving Averages.” Management Science 6 (3):\n324–42. https://doi.org/10.1287/mnsc.6.3.324.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and\nKnitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.\n\n\nZeileis, Achim, David Meyer, and Kurt Hornik. 2007.\n“Residual-Based Shadings for Visualizing (Conditional)\nIndependence.” Journal of Computational and Graphical\nStatistics 16 (3): 507–25. https://doi.org/10.1198/106186007X237856.\n\n\nZhang, Cun-Hui. 2010. “Nearly Unbiased Variable Selection Under\nMinimax Concave Penalty.” The Annals of Statistics 38\n(2): 894–942. https://doi.org/10.1214/09-AOS729.\n\n\nZhang, Lijin, Xueyang Li, and Zhiyong Zhang. 2023. “Variety and\nMainstays of the r Developer Community.” The R Journal\n15: 5–25. https://doi.org/10.32614/RJ-2023-060.\n\n\n刘浩洋, 户将, 李勇锋, and 文再文. 2020.\n最优化：建模、算法与理论. 北京: 高等教育出版社. http://faculty.bicmr.pku.edu.cn/~wenzw/optbook.html.\n\n\n宋泽熙. 2011. “两个二项总体成功概率的比较.”\n中国校外教育（理论） z1: 81. https://doi.org/10.3969/j.issn.1004-8502-B.2011.z1.0919.\n\n\n赵鹏, 谢益辉, and 黄湘云. 2021. 现代统计图形. 北京:\n人民邮电出版社. https://bookdown.org/xiangyun/msg.\n\n\n韦博成. 2009.\n“《红楼梦》前80回与后40回某些文风差异的统计分析（两个独立二项总体等价性检验的一个应用）.”\n应用概率统计 25 (4): 441–48. https://doi.org/10.3969/j.issn.1001-4268.2009.04.012.",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "git-github.html",
    "href": "git-github.html",
    "title": "附录 A — Git 和 Github",
    "section": "",
    "text": "A.1 安装配置",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-setup",
    "href": "git-github.html#sec-setup",
    "title": "附录 A — Git 和 Github",
    "section": "",
    "text": "A.1.1 创建账户\n登陆 Github 官网 (https://github.com/)，点击左上角注册按钮，开始注册 Github 账户。\n\n\n\n\n\n\n图 A.1: 点击注册\n\n\n\n接着，输入注册用的邮箱地址，比如 Outlook 和 Gmail 等。\n\n\n\n\n\n\n图 A.2: 输入邮箱\n\n\n\n除了邮箱外，继续输入密码、用户名等，密码可以选用浏览器自动生成的复杂字符串，只要没有被别人占用，用户名可以按着自己的喜好填写。\n\n\n\n\n\n\n图 A.3: 输入用户名\n\n\n\n接着，系统要验证来注册 Github 账户的人是否是真人。\n\n\n\n\n\n\n图 A.4: 回答问题\n\n\n\n正确回答界面上出现的问题后，进入下一步，系统会给你之前提供的邮箱发送一个验证码。\n\n\n\n\n\n\n图 A.5: 输入验证码\n\n\n\n将收到的验证码输入进去，完成账户验证。\n\n\n\n\n\n\n图 A.6: 验证账户\n\n\n\n创建账户后，将自动进入如下界面，接下来，可以创建代码仓库了。\n\n\n\n\n\n\n图 A.7: 创建代码仓库\n\n\n\n\n\nA.1.2 安装 Git\n在 MacOS 系统上，系统自带 Git 工具，无需安装。在 Ubuntu 系统上，安装最新稳定版的命令如下：\nsudo add-apt-repository -y ppa:git-core/ppa\nsudo apt update && sudo apt install git\n在 Windows 系统上，安装最新稳定版的命令如下：\nwinget install --id Git.Git -e --source winget\n\n\nA.1.3 配置密钥\n在配置 GitHub 账户和安装完 Git 客户端后，接着配置密钥，以便将本地的代码推送到远程 Github 账户下的代码仓库。\ngit config --global user.name \"用户名\"\ngit config --global user.email \"邮箱地址\"\n\n\nA.1.4 (*) 账户共存\n在公司往往会有自己的一套代码管理系统，比如 Gitlab 或者某种类似 Gitlab 的工具。本节介绍如何使 Gitlab / Github 账户共存在一台机器上。\n如何生成 SSH 密钥见 Github 文档 — 使用 SSH 连接到 GitHub。有了密钥之后只需在目录 ~/.ssh 下创建一个配置文件 config。\nGithub 对应个人的私有邮箱，Gitlab 对应公司分配的个人邮箱。\n生成 SSH Key\nssh-keygen -t rsa -f ~/.ssh/id_rsa_github -C \"个人邮箱地址\"\nssh-keygen -t rsa -f ~/.ssh/id_rsa_gitlab -C \"公司邮箱地址\"\n将 GitHub/GitLab 公钥分别上传至服务器，然后创建配置文件\ntouch ~/.ssh/config\n配置文件内容如下\n#\n# Github\n#\nHost github.com // Github 代码仓库的服务器地址\nHostName github.com\nUser XiangyunHuang\nIdentityFile ~/.ssh/id_rsa_github\n\n#\n# company\n#\nHost xx.xx.xx.xx // 公司代码仓库的服务器地址\nIdentityFile ~/.ssh/id_rsa_gitlab\n配置成功，你会看到\nssh -T git@xx.xx.xx.xx\nWelcome to GitLab, xiangyunhuang!\n和\nssh -T git@github.com\nHi XiangyunHuang! You've successfully authenticated, but GitHub does not provide shell access.",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-basic-git-operations",
    "href": "git-github.html#sec-basic-git-operations",
    "title": "附录 A — Git 和 Github",
    "section": "A.2 基本操作",
    "text": "A.2 基本操作\n\nA.2.1 初始化仓库\ngit init\n\n\nA.2.2 添加文件\ngit add\n追踪当前目录下的内容\ngit add .\n追踪被修改(modified)文件，不包括新添加的文件和被删除(deleted)的文件，-u 是 --update 的缩写\ngit add -u\n添加所有文件，-A 是 --all 的缩写\ngit add -A\n\n\nA.2.3 记录修改\ngit commit\ngit commit -m \"添加提交说明\"\n\n\nA.2.4 推送修改\ngit push\ngit push -u origin master\n\n\nA.2.5 克隆项目\n克隆项目 git clone\ngit clone git@github.com:XiangyunHuang/data-analysis-in-action.git\n有的项目包含子模块，添加选项 --recursive 可以将子模块也克隆下来。\ngit clone --recursive git@github.com:cosname/cosx.org.git",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-pr-operations",
    "href": "git-github.html#sec-pr-operations",
    "title": "附录 A — Git 和 Github",
    "section": "A.3 分支操作",
    "text": "A.3 分支操作\n对每一个新的问题，创建新的分支，提交新的 PR。\n与人协作开发代码项目，往往涉及 Git 分支操作。通常有两个场景，其一是独立地在分支上进行开发，包含创建分支、修改分支、提交分支、合并分支和删除分支。其二是与人合作互相评审代码修改分支，除了之前的基础操作，还包含在分支上解决代码冲突，同步分支内容。\n\n\n\n\n\n\nflowchart LR\n  A[创建分支] --&gt; B[修改分支]\n  B --&gt; C[提交分支]\n  C --&gt; D[合并分支]\n  D --&gt; E[删除分支]\n\n\n\n\n图 A.8: Git 分支操作\n\n\n\n\n\n\nA.3.1 创建分支\ngit checkout -b 分支名称\n\n\nA.3.2 分支切换\ngit checkout 分支名称\n\n\nA.3.3 修改 PR\n# 拉取合作者的 PR\ngit fetch origin refs/pull/771/head:patch-2\n# 771 是 PR 对应的编号\ngit checkout patch-2\n\n# 你的修改\n\ngit add -u # 追踪修改的内容\ngit commit -m \"描述修改内容\"\n\ngit remote add LalZzy https://github.com/LalZzy/cosx.org.git\ngit push --set-upstream LalZzy patch-2\n\n\nA.3.4 (*) 创建 gh-pages 分支\n基于 GitHub Pages 创建站点用于存放图片和数据。\n\n在 Github 上创建一个空的仓库，命名为 uploads。\n在本地创建目录 uploads。\n切换到 uploads 目录下，执行如下命令。\n\ngit init \ngit checkout -b gh-pages\ngit remote add origin https://github.com/XiangyunHuang/uploads.git\n添加图片或者数据，并推送到 gh-pages 分支。\ngit add README.md\ngit commit \"消息\" \ngit push --set-upstream origin gh-pages\n这样仓库 uploads 只包含 gh-pages 分支，README.md 文件地址为\nhttps://xiangyunhuang.github.io/uploads/README.md",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-r-to-git",
    "href": "git-github.html#sec-r-to-git",
    "title": "附录 A — Git 和 Github",
    "section": "A.4 R 与 Git 交互",
    "text": "A.4 R 与 Git 交互\nusethis 包将 Git 操作封装了，特别是一些复杂的操作，比如修改他人的 PR\n\nA.4.1 从 R 操作 Git\n拉取编号为 1019 的 PR\nusethis::pr_fetch(1019)\n1019 是 PR 的编号，修改完，清理\nusethis::pr_finish()\n\n\nA.4.2 分析 Git 记录\n给我的仓库点赞的人有哪些，如果有很多，仅显示第一页。\nlibrary(gh)\nmy_repos &lt;- gh(\"GET /repos/:owner/:repo/stargazers\", \n               owner = \"XiangyunHuang\", page = 1, \n               repo = \"data-analysis-in-action\")\nvapply(my_repos, \"[[\", \"\", \"login\")\nJeroen Ooms 开发的 gert 包，提供了 git_rm()、 git_status()、 git_add() 和 git_commit() 等函数，其中包含 git_reset() 、git_branch_*() 等高级 Git 操作。查看最近的 5 条提交记录。\nlibrary(gert)\ngit_log(max = 5)\n更多内容，读者请看 Gert: A minimal git client for R。\ngit2r 包对 Git 仓库进行概要。\nsummary(git2r::repository())\ngitdown 包将 Git 提交日志转化为 GitBook\n截止 2023 年 6 月 1 日，统计之都的主站仓库，提交量最大的 10 个人。\ngit shortlog -sn | head -n 10\n 153    Dawei Lang\n 127    Yihui Xie\n 101    Ryan Feng Lin\n  93    Beilei Bian\n  65    Xiangyun Huang\n  46    王佳\n  42    雷博文\n  39    Miao YU\n  35    xiangyun\n  32    fanchao",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-git-extensions",
    "href": "git-github.html#sec-git-extensions",
    "title": "附录 A — Git 和 Github",
    "section": "A.5 (*) 辅助工具",
    "text": "A.5 (*) 辅助工具\nGit 扩展 git-delta 和 tig 是两款辅助工具。 tig 用于查看提交的历史日志。\n\nA.5.1 语法高亮\ngit-delta\nbrew install git-delta\n对 git diff 的输出提供语法高亮\n\n\nA.5.2 文本接口\n在 MacOS 上，推荐用 Homebrew 安装\nbrew install tig\n\n\nA.5.3 大文件存储\nGit Large File Storage (LFS) Git LFS\n# MacOS\nbrew install git-lfs\n# Ubuntu\nsudo apt install git-lfs\n配置 Git LFS\ngit lfs install\n项目中的大型数据文件\ngit lfs track \"*.csv\"\ngit add .gitattributes\ngit commit -m \"Git LFS 追踪数据文件\"\ngit push origin master",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  }
]