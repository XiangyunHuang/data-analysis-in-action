[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R 语言数据分析实战",
    "section": "",
    "text": "欢迎\n\n\n\n\n\n\n警告\n\n\n\nBook in early development. Planned release in 2024.\n\n\n本书初稿是在 RStudio IDE 内使用 Quarto 编辑的，Quarto 是继R Markdown之后，一个新的开源的科学和技术发布系统，它基于 Pandoc支持输出多种格式的书稿，比如 HTML 网页、EPUB 电子书、DOCX 文档和 PDF 便携式文档等。Quarto 吸收了过去 10 年 R Markdown 取得的经验和教训，在书籍写作、创建博客、制作简历和幻灯片等系列场景中支持更加统一的使用语法，一份源文档输出多种格式，使文档内容在不同场景中的迁移成本更低。了解更多 Quarto 特性，请访问 https://quarto.org/。\n书中的代码字体采用美观的 Source Code Pro 字体， 为方便跨操作系统编译书籍电子版，正文的中文字体采用开源的 fandol 字体。此外，考虑到美观性，本书图形使用了 Noto 系列中英文字体，它们来自 Google Fonts 字体库，分别是 Noto Sans 无衬线英文字体和 Noto Serif SC 宋体中文字体。\n书中 R 包名以粗体表示，如 knitr 包，函数名以等宽体表示，如 plot()，函数的参数名同理。代码块内注释用 # 表示，运行结果每一行开头以 #&gt; 标记。本书写作过程中，依赖 knitr (Xie 2015)、ggplot2 (Wickham 2016) 和 lattice (Sarkar 2008) 等众多 R 包。考虑到要同时支持 DOCX、EPUB、PDF 和 HTML 四种书籍格式，书中使用 knitr 包和 gt 包制作静态的表格。\n为方便测试贡献者提供的 PR，本书托管在 Github 上，同时启用 Github Action 服务，为书籍自定义了一个可复现全书内容的运行环境，包括 R 软件、扩展包和系统软件依赖，详见仓库中的 DESCRIPTION 文件。你现在看到的是在线编译版本，使用 Quarto 1.4.550，最新一次编译时间是 2024-03-04 12:30:31。\n\nxfun::session_info(packages = c(\n  \"ggplot2\", \"gganimate\", \"ggrepel\", \"ggdensity\",\n  \"ggridges\", \"ggsignif\", \"ggforce\", \"ggbeeswarm\",\n  \"ggeffects\", \"ggnewscale\", \"patchwork\", \"shiny\",\n  \"plotly\", \"lattice\", \"igraph\", \"tidygraph\", \"ggraph\",\n  \"dplyr\", \"purrr\", \"tidyr\", \"httr\", \"data.table\",\n  \"rsconnect\", \"knitr\", \"rmarkdown\", \"gt\", \"DT\",\n  \"showtext\", \"gifski\", \"tinytex\", \"magick\"\n), dependencies = FALSE)\n\n#&gt; R version 4.3.3 (2024-02-29)\n#&gt; Platform: x86_64-pc-linux-gnu (64-bit)\n#&gt; Running under: Ubuntu 22.04.4 LTS\n#&gt; \n#&gt; Locale:\n#&gt;   LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n#&gt;   LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n#&gt;   LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n#&gt;   LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n#&gt; \n#&gt; Package version:\n#&gt;   data.table_1.15.2 dplyr_1.1.4       DT_0.32           gganimate_1.0.9  \n#&gt;   ggbeeswarm_0.7.2  ggdensity_1.0.0   ggeffects_1.5.0   ggforce_0.4.2    \n#&gt;   ggnewscale_0.4.10 ggplot2_3.5.0     ggraph_2.2.0      ggrepel_0.9.5    \n#&gt;   ggridges_0.5.6    ggsignif_0.6.4    gifski_1.12.0.2   gt_0.10.1        \n#&gt;   httr_1.4.7        igraph_2.0.2      knitr_1.45        lattice_0.22.5   \n#&gt;   magick_2.8.3      patchwork_1.2.0   plotly_4.10.4     purrr_1.0.2      \n#&gt;   rmarkdown_2.25    rsconnect_1.2.1   shiny_1.8.0       showtext_0.9.6   \n#&gt;   tidygraph_1.3.1   tidyr_1.3.1       tinytex_0.49     \n#&gt; \n#&gt; Pandoc version: 3.1.11\n#&gt; \n#&gt; LaTeX version used: \n#&gt;   TeX Live 2023 (TinyTeX) with tlmgr 2024-02-03\n\n\n\n\n\n\nSarkar, Deepayan. 2008. lattice: Multivariate Data Visualization with R. New York: Springer. http://lmdvr.r-forge.r-project.org.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant Graphics for Data Analysis. 2nd 本. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and knitr. 2nd 本. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.",
    "crumbs": [
      "欢迎"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "前言",
    "section": "",
    "text": "为什么是 R 语言？\nR 语言在统计图形方面不仅走得早还走得远，当然，Python 语言也不错，近年来新起的 Julia 语言也很好。R 语言在统计图形方面的沉淀是非常深厚的，近年来，我发现越是简洁的越是优美，灵活的东西使用起来还非常简单，以 R 包 datasets内的数据集 PlantGrowth 为例，一般地，展示数据的分布会想到箱线图、直方图、密度图等，R 函数的泛型设计可以根据数据对象和变量的类型自动选择合适的图形， 图 19.7 是泛型函数 plot() 调用普通函数 boxplot() 和 spineplot() 绘制的。\n所以，直接调用相应的绘图函数也是可以的，如下：\nboxplot(weight ~ group, data = PlantGrowth, \n        ylab = \"植物干重\", xlab = \"组\")\nspineplot(cut(weight, 2) ~ group, data = PlantGrowth, \n          ylab = \"植物干重\", xlab = \"组\")\n脊柱图是马赛克图的一种特殊情况，也可以看做是堆积条形图的推广形式或者直方图的扩展。上面 cut() 函数的作用是将数值型变量 weight 分桶，对照组（control，简写 ctrl）和两个不同的实验组（treatment，简写 trt）都按同样的划分方式分作两桶。\ndat &lt;- transform(PlantGrowth, weight_bucket = cut(weight, 2))\naggregate(data = dat, weight ~ weight_bucket + group, FUN = length)\n\n#&gt;   weight_bucket group weight\n#&gt; 1   (3.59,4.95]  ctrl      4\n#&gt; 2   (4.95,6.31]  ctrl      6\n#&gt; 3   (3.59,4.95]  trt1      8\n#&gt; 4   (4.95,6.31]  trt1      2\n#&gt; 5   (3.59,4.95]  trt2      1\n#&gt; 6   (4.95,6.31]  trt2      9",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-why-r",
    "href": "preface.html#sec-why-r",
    "title": "前言",
    "section": "",
    "text": "(a) 箱线图\n\n\n\n\n\n\n\n\n\n(b) 脊柱图\n\n\n\n\n\n\n图 1: 影响植物生长的因素",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-why-book",
    "href": "preface.html#sec-why-book",
    "title": "前言",
    "section": "为什么写这本书？",
    "text": "为什么写这本书？\n近年来，数字经济成为热门词汇，企业数字化转型离不开数据，精细化运营更离不开数据分析，数据分析受到越来越多的关注。在数据分析领域，R 语言越来越流行，一本以 R 语言为依托，以实战为导向的数据分析书，市面上还不多。\n\n提供完整可复现的书籍源码，书中示例可以在 R 语言环境下复现。\n数据可视化部分，以一个真实数据串联绘图的基本要素，从图形的用途出发，将图形分类，结合真实数据介绍图形。\n展现数据分析的完整工作流，数据获取、操作、处理、可视化探索和分析、展示交流、建模分析、解释。\n将工作流应用于特定领域的数据分析，覆盖网络数据、文本数据、时序数据、空间数据等四大常见且重要的场景。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-how-book",
    "href": "preface.html#sec-how-book",
    "title": "前言",
    "section": "本书是怎么写的？",
    "text": "本书是怎么写的？\n\n本书在写作风格上借鉴了以下书籍\n\n《现代统计图形》 (赵鹏, 谢益辉, 和 黄湘云 2021) 讲清楚统计图形的来龙去脉，提供丰富的实战案例。\n《R in Action》(Kabacoff 2022) 根据入门、进阶和高阶将书籍内容分出层次。\n《R for Data Science》 (Wickham, Çetinkaya-Rundel, 和 Grolemund 2023) 根据数据分析的整个工作流拆分各个部分、章节。\n\n本书的写作素材来源非常广泛，比如\n\n大量的原始论文、书籍，回顾经典理论、数据案例，追根溯源\n大量的 R 包帮助文档，配合真实数据提供软件工具的使用说明\n一些国内外政府网站发布的权威数据，提供大量的实际案例数据\n从国内外论坛、书店搜集数据操作、展示和交流等方面的高频问题",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-intrinsical-motivation",
    "href": "preface.html#sec-intrinsical-motivation",
    "title": "前言",
    "section": "写作理念是什么？",
    "text": "写作理念是什么？\n\n\n以真实的数据为基础，介绍数据分析所用到的软件工具、统计方法和算法模型，对经典的数据分析案例，力求还原历史，讲清楚故事背景，数据处理的过程，不单单是分析方法和结果。\n尽可能选用来自社会、经济、文化、历史等方面的真实的、最新的或经典的数据，在讲数据分析技术的同时，也了解一点我们所处的社会，希望给读者一些启发，勾起读者的兴趣，主动探寻有趣的问题，收集整理所需的数据，做自己的研究，找到问题的答案，享受数据探索分析的过程，摸索出适合自己的分析方法和分析工具。\n结合多年使用 R 语言的经验以及最近几年在互联网行业工作的体会，形成数据分析师的技能栈，梳理知识体系，沉淀一套数据分析的方法。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-who-book",
    "href": "preface.html#sec-who-book",
    "title": "前言",
    "section": "目标读者是哪些？",
    "text": "目标读者是哪些？\n\n\n想通过编程实现数据分析的完整过程，使得整个过程可以复现，可以重复利用。\n对数据分析的实战有兴趣，想将数据分析技能应用于解决实际问题。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-what-book",
    "href": "preface.html#sec-what-book",
    "title": "前言",
    "section": "本书有哪些内容？",
    "text": "本书有哪些内容？\n\n入门部分：介绍软件 R、 RStudio 和 VS Code 的安装配置过程，常见的基本数据结构和类型，循环、判断、函数等基本的编程知识。\n数据部分：从本地文件、远程数据库、网页爬取等数据获取方式，筛选、变换、重塑、排序等基础的数据操作，离群值、异常值检测，缺失值处理等基础的数据处理\n展示部分：ggplot2 基础、统计图形、实战应用、经验总结\n交流部分：交互的图形、表格和应用，动态的 HTML 网页、PDF 文档和办公文档。\n建模部分：线性模型、广义线性模型、混合效应模型、数据挖掘算法和神经网络模型\n应用部分：网络数据、文本数据、时序数据、空间数据的分析\n其它部分：参数估计、假设检验和抽样分布等基础的统计推断，L-BFGS 算法、EM 算法等统计计算，自助法、重抽样等统计模拟。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-finding-public-datasets",
    "href": "preface.html#sec-finding-public-datasets",
    "title": "前言",
    "section": "公开数据从哪找？",
    "text": "公开数据从哪找？\n\n各国、各级政府的统计局，比如美国人口调查局、中国国家统计局等。\n国际、国内各类组织机构，比如世界银行、美国疾病预防控制中心等。\n各类网站提供的数据集，比如 GitHub 开放数据集列表 awesome-public-datasets，kaggle 网站提供大量数据分析竞赛及相应的数据集。\nR 包内置数据集，已整理得很好，比如 spData 包 收集整理了很多空间统计方面的数据集。Rdatasets 更是收集约 1900 个数据集，全部来自 CRAN 上发布的 R 包。\n一些 R 包封装数据下载的接口，比如tidyBdE包可以下载西班牙银行开放的数据，WDI 可以下载世界银行开放的数据。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "preface.html#sec-asking-the-right-questions",
    "href": "preface.html#sec-asking-the-right-questions",
    "title": "前言",
    "section": "学会有效地提问？",
    "text": "学会有效地提问？\n\n想清楚自己的问题是什么？尽力做好拆解和界定。\n去掉枝叶，保留主干，提供最小的可重复的示例。\n有耐心地等待社区的回应，积极地与社区沟通。\n为社区提供力所能及的帮助，提升自己的影响力。\n\n\n\n\n\nKabacoff, Robert I. 2022. R in Action: Data Analysis and graphics with R and Tidyverse. 3rd 本. Shelter Island, NY: Manning Publications Co.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, 和 Garrett Grolemund. 2023. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 2nd 本. Sebastopol, California: O’Reilly Media, Inc. https://r4ds.hadley.nz/.\n\n\n赵鹏, 谢益辉, 和 黄湘云. 2021. 现代统计图形. 北京: 人民邮电出版社. https://bookdown.org/xiangyun/msg.",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "介绍",
    "section": "",
    "text": "数据探索和分析\n数据可视化是数据探索和分析的一个手段，数据可视化的主要目的有两个：其一是探索 Explore，其二是解释 Explain。\n探索是面向数据分析师自己，而展示是面向数据分析的消费者。面对不同的角色，可视化的目的是不一样的，探索是了解数据，展示是传递信息。了解数据的分布、隐藏的模式、缺失情况、异常情况，步步深入地挖掘数据的潜在规律。展示是传递数据分析的结论和洞见，强调美观、效率、效果，除了数据分析师本人几乎没人想看探索数据过程中产生的数以十计的中间图形。\n数据可视化是通过计算机程序绘制图形来展示数据，有时是在图上展示原始数据，比如散点图，有时展示汇总数据，比如直方图，有时借助一些数据变换，比如对数变换，甚至更为复杂的统计变换。数据可视化主要是描述、提炼和汇总原始数据，从数据中获取信息。\n除了选择合适的工具（Base R / grid / lattice / ggplot2）绘制图形（提供 R 代码实现），选择图形（30+多种常见图形）和解释图形（真实数据背景）往往比想的更加困难，本书试图去回答这些问题。\n大多教科书侧重理论和方法，计算机强调编程，数值计算是精确的，图形是粗燥的。然而，只有模型和方法，缺乏数据探索的分析和建模，计算的结果和分析的结论可能是不正确的，数据可能在欺骗你(Anscombe 1973)。\ndatasauRus 包 (Davies, Locke, 和 D’Agostino McGowan 2022) 内置了一个数据集 datasaurus_dozen，它整合了 13 个子数据集，它们在均值、标准差等描述性统计量方面十分接近，见下 表格 1 。其中 \\(\\bar{x},\\sigma_x\\) 分别代表预测变量 \\(X\\) 的均值和标准差，\\(\\bar{y},\\sigma_y\\) 代表响应变量 \\(Y\\) 的均值和标准差，\\(\\beta_0,\\beta_1\\) 代表回归方程 方程式 1 的截距和斜率，\\(R^2\\) 代表模型拟合数据的程度。\n\\[\ny = \\beta_0 + \\beta_1 x + \\epsilon\n\\tag{1}\\]\n表格 1: datasaurus_dozen 数据集的一些描述性统计量和线性回归结果\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n子数据集\n\\(\\bar{x}\\)\n\\(\\sigma_x\\)\n\\(\\bar{y}\\)\n\\(\\sigma_y\\)\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(R^2\\)\n\n\n\ndino\n54.263\n16.765\n47.832\n26.935\n53.453\n-0.104\n0.004\n\n\naway\n54.266\n16.770\n47.835\n26.940\n53.425\n-0.103\n0.004\n\n\nh_lines\n54.261\n16.766\n47.830\n26.940\n53.211\n-0.099\n0.004\n\n\nv_lines\n54.270\n16.770\n47.837\n26.938\n53.891\n-0.112\n0.005\n\n\nx_shape\n54.260\n16.770\n47.840\n26.930\n53.554\n-0.105\n0.004\n\n\nstar\n54.267\n16.769\n47.840\n26.930\n53.327\n-0.101\n0.004\n\n\nhigh_lines\n54.269\n16.767\n47.835\n26.940\n53.809\n-0.110\n0.005\n\n\ndots\n54.260\n16.768\n47.840\n26.930\n53.098\n-0.097\n0.004\n\n\ncircle\n54.267\n16.760\n47.838\n26.930\n53.797\n-0.110\n0.005\n\n\nbullseye\n54.269\n16.769\n47.831\n26.936\n53.809\n-0.110\n0.005\n\n\nslant_up\n54.266\n16.769\n47.831\n26.939\n53.813\n-0.110\n0.005\n\n\nslant_down\n54.268\n16.767\n47.836\n26.936\n53.850\n-0.111\n0.005\n\n\nwide_lines\n54.267\n16.770\n47.832\n26.938\n53.635\n-0.107\n0.004\n诸多统计量都难以发现它们的差异，透过数据可视化这面照妖镜，却可以使数据的本来面目无所遁形，如 图 1 所示。可见，单个统计量就好比管窥蠡测，稍有不慎，我们就成了盲人摸象。\n图 1: 数据可视化为何如此重要\n数据可视化的重要性在于探索数据的真实分布，为数据建模提供假设和依据，也为验证、评估模型的效果。结合 图 1 也解释了为什么线性回归模型在解释数据方面的无能为力，即 \\(R^2\\) 介于 0.004 至 0.005 之间，数据根本不符合线性模型的条件。\n有时候是有的数据符合模型假设，而有的不符合，我们没有上帝之眼，看不到哪些符合哪些不符合。在数据集不多的情况下，可以全部展示出来，数据集很多的时候，可以抽样一部分，再展示。下面再举一个例子，anscombe 数据集来自 R 软件内置的 R 包 datasets，它包含四组数据 \\((x_i, y_i), i =1,2,3,4\\)，如 表格 2 所示。\n表格 2: anscombe 数据集\n\n\n\n\n\n\n\n\n第1组\n第2组\n第3组\n第4组\n\n\nx1\ny1\nx2\ny2\nx3\ny3\nx4\ny4\n\n\n\n\n10\n8.04\n10\n9.14\n10\n7.46\n8\n6.58\n\n\n8\n6.95\n8\n8.14\n8\n6.77\n8\n5.76\n\n\n13\n7.58\n13\n8.74\n13\n12.74\n8\n7.71\n\n\n9\n8.81\n9\n8.77\n9\n7.11\n8\n8.84\n\n\n11\n8.33\n11\n9.26\n11\n7.81\n8\n8.47\n\n\n14\n9.96\n14\n8.10\n14\n8.84\n8\n7.04\n\n\n6\n7.24\n6\n6.13\n6\n6.08\n8\n5.25\n\n\n4\n4.26\n4\n3.10\n4\n5.39\n19\n12.50\n\n\n12\n10.84\n12\n9.13\n12\n8.15\n8\n5.56\n\n\n7\n4.82\n7\n7.26\n7\n6.42\n8\n7.91\n\n\n5\n5.68\n5\n4.74\n5\n5.73\n8\n6.89\n用统计的方法发现四组数据的样本均值、方差、相关系数和回归系数几乎是相同的，实际上，借助散点 图 10.15 分别描述各组数据的关系时，却发现四组数据之间有极大的差异，且只有第一组数据看起来符合线性模型的条件 (Anscombe 1973)。\n图形还告诉我们第二组数据的更适合二次非线性回归，第三组数据受到离群点的重大影响，第四组数据自变量只有两个取值，像是两个分布按不同比例混合的结果。",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "intro.html#sec-exploration-explaination",
    "href": "intro.html#sec-exploration-explaination",
    "title": "介绍",
    "section": "",
    "text": "(a) 第一组数据\n\n\n\n\n\n\n\n\n\n(b) 第二组数据\n\n\n\n\n\n\n\n\n\n\n\n(c) 第三组数据\n\n\n\n\n\n\n\n\n\n(d) 第四组数据\n\n\n\n\n\n\n图 2: 数据可视化为何如此重要",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "intro.html#sec-data-communication",
    "href": "intro.html#sec-data-communication",
    "title": "介绍",
    "section": "数据展示和交流",
    "text": "数据展示和交流\n无论是数据表格还是交互图形，首先都承担着数据展示的基础作用，通过趋势、对比继而传递更加明确的信息和洞见，采用合适的表达方式可以高效准确地传递信息，促进交流，获取反馈，从而改善已有的分析方法和结论。\n数据展示和交流主要分两大部分：其一是用户可与之交互的图形、表格和应用，其二是文档内容可重复的 HTML 动态网页文档、PDF 便携式文档、 Office 办公文档。涵盖完整数据分析过程的网页文档， 用于毕业的学位论文、投稿的期刊论文、出版的书籍初稿、交流的演示文稿，无论是 LaTeX 编译的 PDF 格式文档还是 DOCX 文档，R 语言社区都有非常先进的工具满足需求。\n13  交互图形 首先介绍 plotly 包绘图的基础语法以及与 ggplot2 包绘图 的关系，其次介绍制作常用的交互图形，如条形图、直方图、箱线图、曲线图等，最后介绍一些常用的技巧，如导出静态图片、添加水印徽标等。\n14  交互表格 首先介绍 DT 包制作交互表格的基础语法，其次介绍常用的功能，如列分层分组、按列配色、列格式化、搜索排序、数据导出等，最后介绍一些基础的 CSS 和 JavaScript 知识，支持一些中高级的表格定制功能。\n15  交互应用 首先介绍 shiny 包制作交互应用的整体概览，如前端布局、后端计算、筛选器、模块交互等，其次从易到难介绍一个完整的数据应用，最后介绍生产级的 Shiny 应用开发的技术栈。\n16  HTML 文档 首先回顾 R 语言社区陆续出现的 R Sweave、R Markdown 和 Quarto 三套创作工具，其次介绍 Quarto 的基础用法，如 Markdown 基础和 Pandoc 的基础，接着根据使用场景分别介绍 HTML、PDF 和 Office 文档的特性。\n\n\n\n\nAnscombe, F. J. 1973. 《Graphs in Statistical Analysis》. The American Statistician 27 (1): 17. https://doi.org/10.2307/2682899.\n\n\nDavies, Rhian, Steph Locke, 和 Lucy D’Agostino McGowan. 2022. datasauRus: Datasets from the Datasaurus Dozen. https://CRAN.R-project.org/package=datasauRus.\n\n\nRigby, R. A., 和 D. M. Stasinopoulos. 2005. 《Generalized additive models for location, scale and shape (with discussion)》. Journal of the Royal Statistical Society: Series C (Applied Statistics) 54 (3): 507–54. https://doi.org/10.1111/j.1467-9876.2005.00510.x.",
    "crumbs": [
      "介绍"
    ]
  },
  {
    "objectID": "wrangling-objects.html",
    "href": "wrangling-objects.html",
    "title": "1  数据对象",
    "section": "",
    "text": "1.1 数据类型",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-objects.html#sec-data-type",
    "href": "wrangling-objects.html#sec-data-type",
    "title": "1  数据对象",
    "section": "",
    "text": "1.1.1 整型\n\nc(1L, 2L)\n\n[1] 1 2\n\n\n\n1.1.2 逻辑型\n\nc(TRUE, FALSE)\n\n[1]  TRUE FALSE\n\n\n\n1.1.3 字符型\n\nc(\"A\", \"B\")\n\n[1] \"A\" \"B\"\n\n\n\n1.1.4 日期型\n\nc(as.Date(\"2022-01-01\"), as.Date(\"2022-01-02\"))\n\n[1] \"2022-01-01\" \"2022-01-02\"\n\n\n\n1.1.5 数值型\n\nc(1,1.2)\n\n[1] 1.0 1.2",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-objects.html#sec-data-structure",
    "href": "wrangling-objects.html#sec-data-structure",
    "title": "1  数据对象",
    "section": "\n1.2 数据结构",
    "text": "1.2 数据结构\n\n1.2.1 向量\n所有元素都是同一类型\n\n1.2.2 矩阵\n所有元素都是同一类型\n\n1.2.3 数组\n所有元素都是同一类型\n\n1.2.4 列表\n元素可以属于不同类型\n\n1.2.5 因子\n\n1.2.6 数据框\n同列的元素类型必须一致，不同列的元素类型可以不同。\n\n1.2.7 ts\nts 类型用于表示时间序列数据，是继承自数组类型的。给定数据、采样初始时间、采样频率的情况下，利用内置的函数 ts() 构造一个 ts 类型的分钟级的时间序列对象。\n\nx &lt;- ts(\n  data = rnorm(100), \n  start = c(2017, 1), \n  frequency = 365.25 * 24 * 60, \n  class = \"ts\", names = \"Time_Series\"\n)\n\nts() 函数的 start 和 frequency 参数很关键，前者指定了时间单位是天，后者指定每个时间单位下的数据点的数量。其中 365.25 是因为每隔 4 年有 366 天，平均下来，每年算 365.25 天。每隔 1 / (24 * 60) 天（即 1 分钟）采样一个点。如果初始时间不是从一年的第1分钟开始，而是从此时此刻 2023-01-31 10:43:30 CST 开始，则可以换算成今年的第 30 * 24 * 60 + 9 * 60 + 43 = 43783 分钟，则 Start = c(2023, 43783)。\n以数据集 x 为例，它是一个 ts 类型的时间序列数据对象。时间序列对象有很多方法，如函数 class() 、 mode() 和 str() 分别可以查看其数据类型、存储类型和数据结构。\n\n# 数据类型\nclass(x)\n\n[1] \"ts\"\n\n# 存储类型\nmode(x)\n\n[1] \"numeric\"\n\n# 数据结构\nstr(x)\n\n Time-Series [1:100] from 2017 to 2017: 0.324 -0.46 -0.972 0.16 0.982 ...\n\n\n函数 start() 和 end() 查看开始和结束的时间点。\n\nc(start(x), end(x))\n\n[1] 2017    1 2017  100\n\n\n函数 time() 可以查看在以上时间区间的划分。\n\ntime(x)\n\nTime Series:\nStart = c(2017, 1) \nEnd = c(2017, 100) \nFrequency = 525960 \n  [1] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [16] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [31] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [46] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [61] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [76] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n [91] 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017\n\n\n函数 tsp() 可以查看其期初、期末和周期。\n\ntsp(x)\n\n[1]   2017   2017 525960",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据对象</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html",
    "href": "wrangling-collection.html",
    "title": "2  数据获取",
    "section": "",
    "text": "2.1 从本地文件读取\n利用 Base R 提供的基础函数从各类文件导入数据",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-file",
    "href": "wrangling-collection.html#sec-file",
    "title": "2  数据获取",
    "section": "",
    "text": "2.1.1 csv 文件\n小的 csv 文件，可用 Base R 提供的 read.csv() 函数读取。 大型 csv 文件，可用 data.table 的 fread() 函数读取。\n\n2.1.2 xlsx 文件\nreadxl 读 xls 和 xlsx 文件，writexl 写 xlsx。\nopenxlsx 读/写 xlsx 文件\n\n2.1.3 arrow 文件\nApache Arrow 的 R 语言接口 arrow 超出内存的大规模数据操作。比如在时空数据处理场景，数据文件往往比较大，需要在远程服务器上处理超出本地计算机内存的数据，geoarrow包和sfarrow包都是应对此类需求。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-database",
    "href": "wrangling-collection.html#sec-database",
    "title": "2  数据获取",
    "section": "\n2.2 从数据库中导入",
    "text": "2.2 从数据库中导入\n从各类数据库导入数据，比如 RSQLite 等\n\n2.2.1 RSQLite\n\n2.2.2 odbc\n\n2.2.3 RJDBC\n很多数据库都有 Java 接口驱动",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-web-scraping",
    "href": "wrangling-collection.html#sec-web-scraping",
    "title": "2  数据获取",
    "section": "\n2.3 从各类网页中抓取",
    "text": "2.3 从各类网页中抓取\nrvest 包从网页、网站抓取数据， 再用 xml2 和 httr2 解析处理网页数据。\n\n2.3.1 豆瓣排行榜\n\n2.3.2 链家二手房",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-collection.html#sec-rest-api",
    "href": "wrangling-collection.html#sec-rest-api",
    "title": "2  数据获取",
    "section": "\n2.4 从数据接口中获取",
    "text": "2.4 从数据接口中获取\n\n2.4.1 Github\n从 Github API 接口中获取托管在 Github 上的 R 包的信息，比如点赞、关注和转发的数量。首先从 CRAN 上获得 R 包元数据信息，接着筛选出托管在 Github 上的 R 包，清理出 R 包在 Github 上的网址。\n\npdb &lt;- readRDS(file = \"data/cran-package-db-20231231.rds\")\n# 过滤出 Github \npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package) & grepl(pattern = \"github\", x = BugReports),\n  select = c(\"Package\", \"Maintainer\", \"Title\", \"BugReports\")\n)\n# 掐头去尾\npdb$repo &lt;- sub(x =  pdb$BugReports, pattern = \"(http|https)://(www\\\\.){0,1}github\\\\.com/\", replacement = \"\")\npdb$repo &lt;- sub(x = pdb$repo, pattern = \"/{1,}(issues|blob).*\", replacement = \"\")\npdb$repo &lt;- sub(x = pdb$repo, pattern = \"/{1,}(discussions|wiki)\", replacement = \"\")\npdb$repo &lt;- sub(x = pdb$repo, pattern = \"/$\", replacement = \"\")\n\n获取某代码仓库信息的 Github API 是 https://api.github.com/repos ，为了批量地访问 API ，收集想要的数据，将数据请求、结果整理的过程打包成一个函数。\n\ngithub_stats &lt;- function(repo) {\n  url &lt;- paste(\"https://api.github.com/repos\", repo, sep = \"/\")\n  # 最多允许失败 5 次，每失败一次休息 5s\n  req &lt;- xfun::retry(curl::curl_fetch_memory, url = url, .times = 5, .pause = 5)\n  x &lt;- jsonlite::fromJSON(rawToChar(req$content))\n  # 爬失败的标记一下\n  if(is.null(x$stargazers_count)) x$stargazers_count &lt;- x$subscribers_count &lt;- x$forks_count &lt;- -1\n  # 爬一个休息 1s\n  Sys.sleep(1)\n  data.frame(\n    repo = repo,\n    # 点赞 仓库上 star 的人数\n    stargazers_count = x$stargazers_count,\n    # 关注 仓库上 watch 的人数\n    subscribers_count = x$subscribers_count,\n    # 转发 仓库上 fork 的人数\n    forks_count = x$forks_count\n  )\n}\n\n下面测试一下这段代码，获取代码仓库 yihui/knitr 的点赞、关注和转发的人数。\n\n# 测试代码\ngithub_stats(repo = \"yihui/knitr\")\n\n         repo stargazers_count subscribers_count forks_count\n1 yihui/knitr             2334               115         872\n\n\n理论上，使用函数 lapply() 遍历所有 R 包可得所需数据，将数据收集函数应用到每一个 R 包上再合并结果，即如下操作。\n\n# 合并数据\ngh_repo_db &lt;- data.table::rbindlist(lapply(pdb$repo, github_stats))\n\n实际上，在没有访问令牌的情况下，Github API 的访问次数是有限制的，只有 60 次（一段时间内）。首先在 Github 开发者设置中申请一个应用，获得应用名称（appname）、客户端 ID（key）和密钥（secret），下面借助 httr 包配置 OAuth 凭证。\n\nlibrary(httr)\n# Github API Oauth2\noauth_endpoints(\"github\")\n# 应用名称（appname）、客户端 ID（key）和密钥（secret）\nmyapp &lt;- oauth_app(\n  appname = \"Application Name\", key = \"Client ID\",\n  secret = \"Client Secrets\"\n)\n# 获取 OAuth 凭证\ngithub_token &lt;- oauth2.0_token(oauth_endpoints(\"github\"), myapp)\n# 使用 API\ngtoken &lt;- config(token = github_token)\n\n修改函数 github_stats() 中请求 Github API 的一行代码，发送带密钥的 GET 请求。\n\nreq &lt;- xfun::retry(GET, url = url, config = gtoken, .times = 5, .pause = 5)\n\n此外，请求难免出现意外，按照上面的方式，一旦报错，数据都将丢失。因此，要预先准备存储空间，每获取一条数据就存进去，如果报错了，就打个标记。\n\n# 准备存储数据\ngh_repo_db &lt;- data.frame(\n  repo = pdb$repo, stargazers_count = rep(-1, length(pdb$repo)),\n  subscribers_count = rep(-1, length(pdb$repo)),\n  forks_count = rep(-1, length(pdb$repo))\n)\n# 不断更新数据\nwhile (any(gh_repo_db$stargazers_count == -1)) {\n  tmp &lt;- gh_repo_db[gh_repo_db$stargazers_count == -1, ]\n  for (repo in tmp$repo) {\n    gh_repo_db[gh_repo_db$repo == repo, ] &lt;- github_stats(repo = repo)\n  }\n  if(repo == tmp$repo[length(tmp$repo)]) break\n}\n\n最后，将收集整理好的数据保存到磁盘上，下面按点赞数量给 R 包排序，篇幅所限，仅展示前 20。\n\ngh_repo_db &lt;- readRDS(file = \"data/gh-repo-db-2023.rds\")\ngh_repo_db &lt;- gh_repo_db[!duplicated(gh_repo_db$repo),]\ngh_repo_db &lt;- gh_repo_db[order(gh_repo_db$stargazers_count, decreasing = T),] \nhead(gh_repo_db, 20)\n\n                      repo stargazers_count subscribers_count forks_count\n8434          dmlc/xgboost            25266               909        8707\n5553      facebook/prophet            17415               425        4474\n4307         mlflow/mlflow            16365               292        3793\n3807    Microsoft/LightGBM            15821               437        3798\n265           apache/arrow            13080               356        3220\n3080           h2oai/h2o-3             6624               384        2016\n2790     tidyverse/ggplot2             6210               308        2028\n3430 interpretml/interpret             5894               141         706\n6921         rstudio/shiny             5180               339        1818\n4317         mlpack/mlpack             4668               185        1577\n1754       tidyverse/dplyr             4612               246        2131\n640       rstudio/bookdown             3565               122        1263\n1430 Rdatatable/data.table             3437               170         977\n6316     rstudio/rmarkdown             2758               146         977\n2269          wesm/feather             2708                97         174\n5324       plotly/plotly.R             2467               117         628\n5084   thomasp85/patchwork             2344                49         159\n1389        r-lib/devtools             2340               120         760\n3658           yihui/knitr             2326               115         877\n6868      satijalab/seurat             2034                75         867\n\n\n将发布在 Github 上的受欢迎的 R 包列出来了，方便读者选用，也看到一些有意思的结果。\n\n机器学习相关的 R 包靠在最前面，实际上，它们（占十之七八）多是对应软件的 R 语言接口，点赞的数目应当算上其它语言接口的贡献。\n在机器学习之后，依次是数据可视化（ggplot2、shiny、plotly.R、patchwork）、数据操作（dplyr、data.table、feather）和可重复性计算（bookdown、rmarkdown、knitr）、R 包开发（devtools）和生物信息（seurat）。\n\n最后，简要说明数据的情况：以上观察结果是基于 CRAN 在 2023-12-31 发布的 R 包元数据，8475 个 R 包在 Github 托管源代码，这些 R 包的点赞、关注和转发数据是在 2024-01-30 爬取的。其中，共有 29 个 R 包不按规矩填写、改名字、换地方、甚至删库了，这些 R 包是可忽略的。当然，也存在一些 R 包并未托管在 Github 上，但质量不错，比如 glmnet 包、colorspace 包、fGarch 包等，应当是少量的。\n\n2.4.2 中国地震台网\n中国地震台网 可以想象后台有一个数据库，在页面的小窗口中输入查询条件，转化为某种 SQL 语句，传递给数据库管理系统，执行查询语句，返回查询结果，即数据。\n\n2.4.3 美国地质调查局\n美国地质调查局提供一些选项窗口，可供选择数据范围，直接下载 CSV 或 XLS 文件。\n\n2.4.4 美国人口调查局\n美国人口调查局\ntidycensus 需要注册账号，获取使用 API 接口的访问令牌，可以想象后台不仅有一个数据库，在此之上，还有一层数据鉴权。\n\n2.4.5 世界银行\n世界银行和国际货币基金组织\nwbstats 包封装世界银行提供的数据接口 REST API",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>数据获取</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html",
    "href": "wrangling-cleaning.html",
    "title": "3  数据清洗",
    "section": "",
    "text": "3.1 正则表达式",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html#sec-regexp",
    "href": "wrangling-cleaning.html#sec-regexp",
    "title": "3  数据清洗",
    "section": "",
    "text": "3.1.1 量词\n\n\n3.1.2 级联\n\n\n3.1.3 断言\n正向查找 / 反向查找\n\n\n3.1.4 反向引用\n\n\n3.1.5 命名捕捉",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-cleaning.html#sec-string-operations",
    "href": "wrangling-cleaning.html#sec-string-operations",
    "title": "3  数据清洗",
    "section": "3.2 字符串操作",
    "text": "3.2 字符串操作\n\n3.2.1 查找\ngrep() / grepl() 返回是否匹配的结果\n\n\n3.2.2 替换\nsub() / gsub() 替换一次和多次\n\n\n3.2.3 提取\nregexpr() / gregexpr()\nregexec() / gregexec()",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据清洗</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html",
    "href": "wrangling-manipulation.html",
    "title": "4  数据操作",
    "section": "",
    "text": "4.1 操作工具\n本节所用数据来自世界银行，介绍 Base R、data.table、dplyr 的简介、特点、对比",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-tools",
    "href": "wrangling-manipulation.html#sec-tools",
    "title": "4  数据操作",
    "section": "",
    "text": "4.1.1 Base R\n在 data.frame 的基础上，提供一系列辅助函数实现各类数据操作。\n\naggregate(iris, Sepal.Length ~ Species, FUN = length)\n\n     Species Sepal.Length\n1     setosa           50\n2 versicolor           50\n3  virginica           50\n\n\n\n4.1.2 data.table\ndata.table 包在 Base R 的基础上，扩展和加强了原有函数的功能，提供一套完整的链式操作语法。\n\nlibrary(data.table)\niris_dt &lt;- as.data.table(iris)\niris_dt[ ,.(cnt = length(Sepal.Length)) , by = \"Species\"]\n\n      Species   cnt\n       &lt;fctr&gt; &lt;int&gt;\n1:     setosa    50\n2: versicolor    50\n3:  virginica    50\n\n\n\n4.1.3 dplyr\ndplyr 包提供一套全新的数据操作语法，与 purrr 包和 tidyr 包一起形成完备的数据操作功能。在 R 环境下，dplyr 包提供一套等价的表示，代码如下：\n\niris |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count()\n\n# A tibble: 3 × 2\n# Groups:   Species [3]\n  Species        n\n  &lt;fct&gt;      &lt;int&gt;\n1 setosa        50\n2 versicolor    50\n3 virginica     50\n\n\n\n4.1.4 SQL\n实际工作中，SQL （结构化查询语言）是必不可少的基础性工具，比如 SQLite、 Hive 和 Spark 等都提供基于 SQL 的数据查询引擎，没有重点介绍 SQL 操作是因为本书以 R 语言为数据分析的主要工具，而不是它不重要。以 dplyr 来说吧，它的诸多语义动词就是对标 SQL 的。\n\nlibrary(DBI)\nconn &lt;- DBI::dbConnect(RSQLite::SQLite(),\n  dbname = system.file(\"db\", \"datasets.sqlite\", package = \"RSQLite\")\n)\n\n按 Species 分组统计数据条数， SQL 查询语句如下：\n\nSELECT COUNT(1) AS cnt, Species\nFROM iris\nGROUP BY Species;\n\nSQL 代码执行的结果如下：\n\niris_preview\n\n  cnt    Species\n1  50     setosa\n2  50 versicolor\n3  50  virginica\n\n\ndplyr 包能连接数据库，以上 SQL 代码也可以翻译成等价的 dplyr 语句。\n\ndplyr::tbl(conn, \"iris\") |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count()\n\n# Source:   SQL [3 x 2]\n# Database: sqlite 3.45.0 [/home/runner/work/_temp/Library/RSQLite/db/datasets.sqlite]\n# Groups:   Species\n  Species        n\n  &lt;chr&gt;      &lt;int&gt;\n1 setosa        50\n2 versicolor    50\n3 virginica     50\n\n\ndplyr 包的函数 show_query() 可以将 dplyr 语句转化为查询语句，这有助于排错。\n\ndplyr::tbl(conn, \"iris\") |&gt; \n  dplyr::group_by(Species) |&gt; \n  dplyr::count() |&gt; \n  dplyr::show_query()\n\n&lt;SQL&gt;\nSELECT `Species`, COUNT(*) AS `n`\nFROM `iris`\nGROUP BY `Species`\n\n\nglue 包可以使用 R 环境中的变量，相比于 sprintf() 函数，可以组合更大型的 SQL 语句，这在生产环境中广泛使用。\n\n# R 环境中的变量\ngroup &lt;- \"Species\"\n# 组合 SQL\nquery &lt;- glue::glue(\"\n  SELECT COUNT(1) AS cnt, Species\n  FROM iris\n  GROUP BY ({group})\n\")\n# 将 SQL 语句传递给数据库，执行 SQL 语句\nDBI::dbGetQuery(conn, query)\n\n  cnt    Species\n1  50     setosa\n2  50 versicolor\n3  50  virginica\n\n\n用完后，关闭连接通道。\n\ndbDisconnect(conn = conn)\n\n更多关于 SQL 语句的使用介绍见书籍《Become a SELECT star》。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-basic-operator",
    "href": "wrangling-manipulation.html#sec-basic-operator",
    "title": "4  数据操作",
    "section": "\n4.2 Base R 操作",
    "text": "4.2 Base R 操作\n介绍最核心的 Base R 数据操作，如筛选、排序、变换、聚合、重塑等\n\n4.2.1 筛选\n筛选操作可以用函数 subset() 或 [ 实现\n\nsubset(iris, subset = Species == \"setosa\" & Sepal.Length &gt; 5.5, select = c(\"Sepal.Length\", \"Sepal.Width\"))\n\n   Sepal.Length Sepal.Width\n15          5.8         4.0\n16          5.7         4.4\n19          5.7         3.8\n\n\n\niris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5.5, c(\"Sepal.Length\", \"Sepal.Width\")]\n\n   Sepal.Length Sepal.Width\n15          5.8         4.0\n16          5.7         4.4\n19          5.7         3.8\n\n\n\n4.2.2 变换\n变换操作可以用函数 within()/transform() 实现。最常见的变换操作是类型转化，比如从字符串型转为因子型、整型或日期型等。\n\n# iris2 &lt;- transform(iris, Species_N = as.integer(Species))[1:3, ]\niris2 &lt;- within(iris, {\n  Species_N &lt;- as.integer(Species)\n})\nstr(iris2)\n\n'data.frame':   150 obs. of  6 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Species_N   : int  1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n4.2.3 排序\n排序操作可以用函数 order() 实现\n\niris[order(iris$Sepal.Length, decreasing = FALSE)[1:3], ]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n14          4.3         3.0          1.1         0.1  setosa\n9           4.4         2.9          1.4         0.2  setosa\n39          4.4         3.0          1.3         0.2  setosa\n\n\n\n4.2.4 聚合\n聚合操作可以用函数 aggregate() 实现\n\naggregate(iris, Sepal.Length ~ Species, mean)\n\n     Species Sepal.Length\n1     setosa        5.006\n2 versicolor        5.936\n3  virginica        6.588\n\n\n\n4.2.5 合并\n两个数据框的合并操作可以用函数 merge() 实现\n\ndf1 &lt;- data.frame(a1 = c(1, 2, 3), a2 = c(\"A\", \"B\", \"C\"))\ndf2 &lt;- data.frame(b1 = c(2, 3, 4), b2 = c(\"A\", \"B\", \"D\"))\n# LEFT JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all.x = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  C  3 NA\n\n# RIGHT JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all.y = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  D NA  4\n\n# INNER JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all = FALSE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n\n# FULL JOIN\nmerge(x = df1, y = df2, by.x = \"a2\", by.y = \"b2\", all = TRUE)\n\n  a2 a1 b1\n1  A  1  2\n2  B  2  3\n3  C  3 NA\n4  D NA  4\n\n\n\n4.2.6 重塑\n将数据集从宽格式转为长格式，可以用函数 reshape() 实现，反之，亦然。\n\n# 长格式\ndf3 &lt;- data.frame(\n  extra = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4),\n  group = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),\n  id = c(1, 2, 3, 1, 2, 3)\n)\n# 长转宽\nreshape(df3, direction = \"wide\", timevar = \"group\", idvar = \"id\")\n\n  id extra.A extra.B\n1  1     0.7    -1.2\n2  2    -1.6    -0.1\n3  3    -0.2     3.4\n\n# 也可以指定组合变量的列名\nreshape(df3, direction = \"wide\", timevar = \"group\", idvar = \"id\",\n        v.names = \"extra\", sep = \"_\")\n\n  id extra_A extra_B\n1  1     0.7    -1.2\n2  2    -1.6    -0.1\n3  3    -0.2     3.4\n\n\n提取并整理分组线性回归系数。函数 split() 将数据集 iris 按分类变量 Species 拆分成列表， 函数 lapply() 将线性回归操作 lm() 应用于列表的每一个元素上，再次用函数 lapply() 将函数 coef() 应用于线性回归后的列表上，提取回归系数，用函数 do.call() 将系数合并成矩阵，最后，用函数as.data.frame() 转化成数据框。\n\ns1 &lt;- split(iris, ~Species)\ns2 &lt;- lapply(s1, lm, formula = Sepal.Length ~ Sepal.Width)\ns3 &lt;- lapply(s2, coef)\ns4 &lt;- do.call(\"rbind\", s3)\ns5 &lt;- as.data.frame(s4)\ns5\n\n           (Intercept) Sepal.Width\nsetosa        2.639001   0.6904897\nversicolor    3.539735   0.8650777\nvirginica     3.906836   0.9015345\n\ndo.call(\n  \"rbind\",\n  lapply(\n    lapply(\n      split(iris, ~Species), lm,\n      formula = Sepal.Length ~ Sepal.Width\n    ),\n    coef\n  )\n)\n\n           (Intercept) Sepal.Width\nsetosa        2.639001   0.6904897\nversicolor    3.539735   0.8650777\nvirginica     3.906836   0.9015345",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-manipulation.html#sec-data-table",
    "href": "wrangling-manipulation.html#sec-data-table",
    "title": "4  数据操作",
    "section": "\n4.3 data.table 操作",
    "text": "4.3 data.table 操作\n掌握此等基础性的工具，再去了解新工具也不难，更重要的是，只要将一种工具掌握的足够好，也就足以应付绝大多数的情况。\n\n介绍 data.table 基础语法，对标 Base R，介绍基础操作，同时给出等价的 dplyr 实现，但不运行代码。\ndata.table 扩展 Base R 数据操作，介绍常用的操作 8 个，讲清楚出现的具体场景，同时给出等价的 dplyr 实现，但不运行代码。\ndata.table 特有的高级数据操作 on、.SD 、.I 、.J 等。\n\n\n4.3.1 筛选\ndata.table 扩展了函数 [ 功能，简化 iris$Species == \"setosa\" 代码 Species == \"setosa\"\n\niris_dt[Species == \"setosa\" & Sepal.Length &gt; 5.5, c(\"Sepal.Length\", \"Sepal.Width\")]\n\n   Sepal.Length Sepal.Width\n          &lt;num&gt;       &lt;num&gt;\n1:          5.8         4.0\n2:          5.7         4.4\n3:          5.7         3.8\n\n\n\n4.3.2 变换\n变换操作可以用函数 :=\n\niris_dt[, Species_N := as.integer(Species)]\nstr(iris_dt)\n\nClasses 'data.table' and 'data.frame':  150 obs. of  6 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Species_N   : int  1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\n\n\n4.3.3 排序\n排序操作可以用函数 order()\n\niris_dt[order(Sepal.Length, decreasing = FALSE)[1:3], ]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Species_N\n          &lt;num&gt;       &lt;num&gt;        &lt;num&gt;       &lt;num&gt;  &lt;fctr&gt;     &lt;int&gt;\n1:          4.3         3.0          1.1         0.1  setosa         1\n2:          4.4         2.9          1.4         0.2  setosa         1\n3:          4.4         3.0          1.3         0.2  setosa         1\n\n\n\n4.3.4 聚合\n聚合操作用函数 .() 和 by 组合\n\niris_dt[, .(mean = mean(Sepal.Length)), by = \"Species\"]\n\n      Species  mean\n       &lt;fctr&gt; &lt;num&gt;\n1:     setosa 5.006\n2: versicolor 5.936\n3:  virginica 6.588\n\n\n\n4.3.5 合并\n合并操作也是用函数 merge() 来实现。\n\ndt1 &lt;- data.table(a1 = c(1, 2, 3), a2 = c(\"A\", \"B\", \"C\"))\ndt2 &lt;- data.table(b1 = c(2, 3, 4), b2 = c(\"A\", \"B\", \"D\"))\n# LEFT JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all.x = TRUE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n3:      C     3    NA\n\n# RIGHT JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all.y = TRUE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n3:      D    NA     4\n\n# INNER JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all = FALSE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n\n# FULL JOIN\nmerge(x = dt1, y = dt2, by.x = \"a2\", by.y = \"b2\", all = TRUE)\n\nKey: &lt;a2&gt;\n       a2    a1    b1\n   &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:      A     1     2\n2:      B     2     3\n3:      C     3    NA\n4:      D    NA     4\n\n\n\n4.3.6 重塑\n将数据集从宽格式转为长格式，可以用函数 dcast() 实现，反之，可以用函数 melt() 实现。\n\n# 长格式\ndt3 &lt;- data.table(\n  extra = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4),\n  group = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),\n  id = c(1, 2, 3, 1, 2, 3)\n)\n# 长转宽\ndcast(dt3, id ~ group, value.var = \"extra\")\n\nKey: &lt;id&gt;\n      id     A     B\n   &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:     1   0.7  -1.2\n2:     2  -1.6  -0.1\n3:     3  -0.2   3.4\n\n\n类似 Base R，也用 data.table 来实现 iris 分组线性回归\n\niris_dt[, as.list(coef(lm(Sepal.Length ~ Sepal.Width))), by = \"Species\"]\n\n      Species (Intercept) Sepal.Width\n       &lt;fctr&gt;       &lt;num&gt;       &lt;num&gt;\n1:     setosa    2.639001   0.6904897\n2: versicolor    3.539735   0.8650777\n3:  virginica    3.906836   0.9015345",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>数据操作</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html",
    "href": "wrangling-processing.html",
    "title": "5  数据处理",
    "section": "",
    "text": "5.1 缺失值处理\n缺失是一种非常常见的数据问题。",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-missing-data",
    "href": "wrangling-processing.html#sec-missing-data",
    "title": "5  数据处理",
    "section": "",
    "text": "5.1.1 查找\n缺失值在数据框中的位置\n\n\n5.1.2 汇总\n缺失值的占比、分布情况，可视化获得缺失的结构 VIM\n\n\n5.1.3 替换\n替换数据框中的缺失值\n\n\n5.1.4 插补\nmice Multivariate Imputation by Chained Equations 缺失值插补",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-exception-data",
    "href": "wrangling-processing.html#sec-exception-data",
    "title": "5  数据处理",
    "section": "5.2 异常值处理",
    "text": "5.2 异常值处理\n提及异常，一般会联想到数据本身出问题了，比如数据错误。比较常见的情况是业务有异动，导致数据异常波动，需要及时捕捉到这种异常波动，找到异常的原因，进而采取措施。\n\n5.2.1 检测\n\n\n5.2.2 识别\n\n\n5.2.3 处理",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "wrangling-processing.html#sec-outlier-data",
    "href": "wrangling-processing.html#sec-outlier-data",
    "title": "5  数据处理",
    "section": "5.3 离群值处理",
    "text": "5.3 离群值处理\n离群，并不是数据本身出问题，而是数据隐藏着特殊信息，与平时不一样的情况，与大家伙不一样的情况。比如情人节鲜花和蛋糕的需求量激增，端午节粽子的需求激增，这和平时很不一样。需求数据本身没有问题，如实反应了现实情况。因此，需要根据现实情况，调整预测模型，做出更加准确的需求预测，提前安排供给。\n\n5.3.1 检测\n\n\n5.3.2 识别\n\n\n5.3.3 处理",
    "crumbs": [
      "数据准备",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据处理</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html",
    "href": "visualization-basic.html",
    "title": "6  ggplot2 入门",
    "section": "",
    "text": "6.1 图层\nggplot2 绘图必须包含以下三个要素，缺少任何一个，图形都是不完整的。\n下面逐一说明三个要素的作用，为简单起见，从数据集 gapminder 中选取 2007 年的数据。\n图 6.1 (a) 仅提供数据，只渲染出来一个绘图区域。 图 6.1 (b) 仅提供数据和映射，将变量 gdpPercap 映射给横轴，变量 lifeExp 映射给纵轴，继续渲染出来横、纵坐标轴及标签。 图 6.1 (c) 提供了数据、映射和图层三要素，观察值根据几何图层 geom_point() 将几何元素 「点」渲染在绘图区域上，形成散点图。函数 ggplot() 和函数 geom_point() 之间是以加号 + 连接的。无论最终产出的图形如何复杂，这个模式贯穿 ggplot2 绘图。\n10 多年来，ggplot2 包陆续添加了很多几何图层，目前支持的有 53 个，如下：\n也正因这些丰富多彩的图层，ggplot2 可以非常便捷地做各种数据探索和展示工作。从时间序列数据、网络社交数据到文本数据、空间数据，乃至时空数据都有它大显身手的地方。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-layer",
    "href": "visualization-basic.html#sec-layer",
    "title": "6  ggplot2 入门",
    "section": "",
    "text": "数据，前面已经重点介绍和准备了；\n映射，数据中的变量与几何元素的对应关系；\n图层，至少需要一个图层用来渲染观察值。\n\n\nlibrary(ggplot2)\ngapminder_2007 &lt;- gapminder[gapminder$year == 2007, ]\nggplot(data = gapminder_2007)\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp))\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(size = pop))\n\n\n\n\n\n\n\n\n\n(a) 只有数据\n\n\n\n\n\n\n\n\n\n(b) 只有数据和坐标映射\n\n\n\n\n\n\n\n\n\n\n\n(c) 数据、坐标映射和点图层\n\n\n\n\n\n\n\n\n\n(d) 数据、坐标映射、点图层和视觉映射（可选）\n\n\n\n\n\n\n图 6.1: ggplot2 绘图三要素\n\n\n\n\n\n\n表格 6.2: ggplot2 包可以绘制丰富的统计图形\n\n\n\ngeom_abline\ngeom_dotplot\ngeom_qq_line\n\n\ngeom_area\ngeom_errorbar\ngeom_quantile\n\n\ngeom_bar\ngeom_errorbarh\ngeom_raster\n\n\ngeom_bin_2d\ngeom_freqpoly\ngeom_rect\n\n\ngeom_bin2d\ngeom_function\ngeom_ribbon\n\n\ngeom_blank\ngeom_hex\ngeom_rug\n\n\ngeom_boxplot\ngeom_histogram\ngeom_segment\n\n\ngeom_col\ngeom_hline\ngeom_sf\n\n\ngeom_contour\ngeom_jitter\ngeom_sf_label\n\n\ngeom_contour_filled\ngeom_label\ngeom_sf_text\n\n\ngeom_count\ngeom_line\ngeom_smooth\n\n\ngeom_crossbar\ngeom_linerange\ngeom_spoke\n\n\ngeom_curve\ngeom_map\ngeom_step\n\n\ngeom_density\ngeom_path\ngeom_text\n\n\ngeom_density_2d\ngeom_point\ngeom_tile\n\n\ngeom_density_2d_filled\ngeom_pointrange\ngeom_violin\n\n\ngeom_density2d\ngeom_polygon\ngeom_vline\n\n\ngeom_density2d_filled\ngeom_qq",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-label",
    "href": "visualization-basic.html#sec-label",
    "title": "6  ggplot2 入门",
    "section": "\n6.2 标签",
    "text": "6.2 标签\n用函数 labs() 可以添加横轴、纵轴、图例的标题，整个图片的标题和副标题等。下图 图 6.2 (a) 是默认设置下显示的标签内容，而 图 6.2 (b) 是用户指定标签内容后的显示效果。\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region))\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", tag = \"标签\",\n       title = \"这里是标题\", caption = \"这是图形说明\", \n       subtitle = \"这里是副标题\", color = \"图例标题\")\n\n\n\n\n\n\n\n\n\n(a) 默认设置\n\n\n\n\n\n\n\n\n\n\n\n(b) 自定义标签\n\n\n\n\n\n\n图 6.2: 添加标签",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-scale",
    "href": "visualization-basic.html#sec-scale",
    "title": "6  ggplot2 入门",
    "section": "\n6.3 刻度",
    "text": "6.3 刻度\n\n有时候 图 6.1 (c) 看起来不太好，收入低的国家太多，聚集在一起，重叠覆盖比较严重。而高收入国家相对较少，分布稀疏，距离低收入比较远，数据整体的分布很不平衡。此时，可以考虑对横轴标度做一些变换，常用的有以 10 为底的对数变换，如 图 6.3 。\n\nlibrary(scales)\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.3: 人均 GDP 做对数变换\n\n\n\n\n为了更加醒目地展示横轴做了对数变换，需要添加对应的刻度标签。scales 包 (H. Wickham 和 Seidel 2022) 提供很多刻度标签支持，比如函数 label_log() 默认提供以 10 为底的刻度标签，如 图 6.4 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(labels = label_log()) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.4: 刻度标签随数据变换调整\n\n\n\n\n这其实还不够，有的刻度标签含义不够显然，且看 图 6.4 的横轴第一个刻度标签 \\(10^{2.48}\\) 是用来替换 图 6.3 的横轴第一个刻度标签 300。10 的 2.48 次方可不容易看出是 300 的意思，实际上它等于 302。因此，结合人均 GDP 的实际范围，有必要适当调整横轴显示范围，这可以在函数 scale_x_log10() 中设置参数 limits，横轴刻度标签会随之适当调整，调整后的效果如 图 6.5 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(labels = label_log(), limits = c(100, 110000)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.5: 设置数据展示范围\n\n\n\n\n根据横轴所代表的人均 GDP （单位：美元）的实际含义，其实，可以进一步，添加更多的信息，即刻度标签带上数量单位，此处是美元符号。scales 包提供的函数 label_dollar() 可以实现，效果如 图 6.6 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(labels = label_dollar(), limits = c(100, 110000)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.6: 设置数据展示范围\n\n\n\n\n最后，有必要添加次刻度线作为辅助参考线。图中点与点之间的横向距离代表人均 GDP 差距，以 10 为底的对数变换不是线性变化的，肉眼识别起来有点困难。从 100 美元到 100000 美元，在 100 美元、1000 美元、10000 美元和 100000 美元之间均添加 10 条次刻度线，每个区间内相邻的两条次刻度线之差保持恒定。下面构造刻度线的位置，了解原值和对数变换后的对应关系。\n\n# 刻度线位置\nmb &lt;- unique(as.numeric(1:10 %o% 10^(1:4)))\n# 对数变换后\nlog10(mb)\n\n#&gt;  [1] 1.000000 1.301030 1.477121 1.602060 1.698970 1.778151 1.845098 1.903090\n#&gt;  [9] 1.954243 2.000000 2.301030 2.477121 2.602060 2.698970 2.778151 2.845098\n#&gt; [17] 2.903090 2.954243 3.000000 3.301030 3.477121 3.602060 3.698970 3.778151\n#&gt; [25] 3.845098 3.903090 3.954243 4.000000 4.301030 4.477121 4.602060 4.698970\n#&gt; [33] 4.778151 4.845098 4.903090 4.954243 5.000000\n\n# 刻度线位置\nformat(mb, big.mark = \",\", scientific = 999)\n\n#&gt;  [1] \"     10\" \"     20\" \"     30\" \"     40\" \"     50\" \"     60\" \"     70\"\n#&gt;  [8] \"     80\" \"     90\" \"    100\" \"    200\" \"    300\" \"    400\" \"    500\"\n#&gt; [15] \"    600\" \"    700\" \"    800\" \"    900\" \"  1,000\" \"  2,000\" \"  3,000\"\n#&gt; [22] \"  4,000\" \"  5,000\" \"  6,000\" \"  7,000\" \"  8,000\" \"  9,000\" \" 10,000\"\n#&gt; [29] \" 20,000\" \" 30,000\" \" 40,000\" \" 50,000\" \" 60,000\" \" 70,000\" \" 80,000\"\n#&gt; [36] \" 90,000\" \"100,000\"\n\n\n函数 scale_x_log10() 提供参数 minor_breaks 设定刻度线的位置。最终效果如 图 6.7 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\")\n\n\n\n\n\n\n图 6.7: 添加次刻度线，提供更多参考",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-color",
    "href": "visualization-basic.html#sec-color",
    "title": "6  ggplot2 入门",
    "section": "\n6.4 配色",
    "text": "6.4 配色\n好的配色可以让图形产生眼前一亮的效果，R 语言社区在统计图形领域深耕 20 多年，陆续涌现很多专门调色的 R 包，常见的有：\n\n\nRColorBrewer (Neuwirth 2022) (https://github.com/axismaps/colorbrewer/)\n\nmunsell (C. Wickham 2018) (https://github.com/cwickham/munsell/)\n\ncolorspace (Zeileis 等 2020) (https://colorspace.r-forge.r-project.org/)\n\npaletteer (Hvitfeldt 2021) (https://github.com/EmilHvitfeldt/paletteer)\n\nscico (Pedersen 和 Crameri 2022) (https://github.com/thomasp85/scico)\n\nviridis (Garnier 等 2021) (https://github.com/sjmgarnier/viridis/)\n\nviridisLite (Garnier 等 2021) (https://github.com/sjmgarnier/viridisLite/)\n\ncolormap (Karambelkar 2016) (https://github.com/bhaskarvk/colormap)\n\nggplot2 提供多种方式给图形配色，最常见的要数函数 scale_color_brewer()，它调用 RColorBrewer 包制作离散型的调色板，根据离散型变量的具体情况，可分为发散型 qualitative、对撞型 Diverging、有序型 Sequential。在图 图 6.7 的基础上，将分类型的区域变量映射给散点的颜色，即得到 图 6.8 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region)) +\n  scale_color_brewer(palette = \"Set1\") +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", color = \"区域\")\n\n\n\n\n\n\n图 6.8: 使用 RColorBrewer 包提供的 Set1 调色板\n\n\n\n\n另一种方式是调用函数 scale_color_manual()，需要用户给分类变量值逐个指定颜色，即提供一个命名的向量，效果如 图 6.9 。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region)) +\n  scale_color_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", color = \"区域\")\n\n\n\n\n\n\n图 6.9: 手动挨个指定分类变量的颜色",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-legend",
    "href": "visualization-basic.html#sec-legend",
    "title": "6  ggplot2 入门",
    "section": "\n6.5 图例",
    "text": "6.5 图例\n在 图 6.8 的基础上，继续将每个国家的人口总数映射给点的大小，绘制气泡图。此时有两个视觉映射变量 — 离散型的变量 country （国家）和连续型的变量 pop （人口总数）。不仅仅是图层函数 geom_point()，所有的几何图层都提供参数 show.legend 来控制图例的显示或隐藏。传递命名逻辑向量还可以在多个图例中选择性保留。 图 6.10 在两个图例中保留一个，即人口总数。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region, size = pop),\n    show.legend = c(color = FALSE, size = TRUE)\n  ) +\n  scale_color_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", size = \"人口总数\")\n\n\n\n\n\n\n图 6.10: 在两个图例中保留一个\n\n\n\n\n全世界各个国家的人口总数从百万级横跨到十亿级，根据此实际情况，适当调整图例刻度标签是很有必要的，可以让图例内容更具可读性。 图 6.11 是修改图例刻度标签后的效果，其中 M 表示 Million（百万），B 表示 Billion （十 亿）。\n\nggplot(data = gapminder_2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(color = region, size = pop),\n    show.legend = c(color = FALSE, size = TRUE)\n  ) +\n  scale_color_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12), labels = label_number(scale_cut = cut_short_scale())) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", size = \"人口总数\")\n\n\n\n\n\n\n图 6.11: 修改图例刻度标签",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-theme",
    "href": "visualization-basic.html#sec-theme",
    "title": "6  ggplot2 入门",
    "section": "\n6.6 主题",
    "text": "6.6 主题\n主题就是一系列风格样式的集合，提前设定标题、文本、坐标轴、图例等元素的默认参数，供后续调用。10 年来，R 语言社区陆续出现很多主题包。\n\n\nggthemes (Arnold 2021) 收集了网站（如 Fivethirtyeight）、杂志（如《经济学家》）、软件（如 Stata）等的配色主题，打包成可供 ggplot2 绘图的主题，更多内容见 (https://github.com/jrnold/ggthemes)\n\nggsci (Xiao 2018) 包收集了多份期刊杂志的图形配色，将其融入 ggplot2 绘图主题中，更多内容见 (https://github.com/road2stat/ggsci)。\n\nggpubr (Kassambara 2022) 包在 ggplot2 之上封装一套更加易用的函数，可以快速绘制出版级的统计图形 (https://github.com/kassambara/ggpubr)。\n\nggcharts (Neitmann 2020) 包类似 ggpubr 包，也提供一套更加快捷的函数接口，缩短数据可视化的想法与实际图形的距离，更多内容见 (https://github.com/thomas-neitmann/ggcharts)。\n\nggthemr (Tobin 2020) 是比较早的 ggplot2 主题包，上游依赖少，更多内容见 (https://github.com/Mikata-Project/ggthemr)。\n\nggtech (Bion 2018) 包收集了许多科技公司的设计风格，将其制作成可供 ggplot2 绘图使用的主题，更多内容见 (https://github.com/ricardo-bion/ggtech)。\n\nbbplot (Stylianou 等 2022) 为 BBC 新闻定制的一套主题，更多内容见 (https://github.com/bbc/bbplot)。\n\npilot (Hawkins 2022) 包提供一套简洁的 ggplot2 主题，特别是适合展示分类、离散型数据，更多内容见 (https://github.com/olihawkins/pilot)。\n\nggthemeassist (Gross 和 Ottolinger 2016) 包提供 RStudio IDE 插件，帮助用户以鼠标点击的交互方式设置 ggplot2 图形的主题样式，更多内容见 (https://github.com/calligross/ggthemeassist)。\n\n在 图 6.11 的基础上，以 ggplot2 包内置的主题 theme_classic() 替换默认的主题，效果如下 图 6.12 ，这是一套非常经典的主题，它去掉所有的背景色和参考系，显得非常简洁。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop), shape = 21, col = \"white\",\n    show.legend = c(fill = TRUE, size = FALSE)\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_classic() +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.12: ggplot2 内置的经典主题风格\n\n\n\n\n在已有主题的基础上，还可以进一步细微调整，比如，将图例移动至绘图区域的下方，见 图 6.13 。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop), shape = 21, col = \"white\",\n    show.legend = c(fill = TRUE, size = FALSE)\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_classic() +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.13: 图例置于图形下方\n\n\n\n\n或者用户觉得合适的任意位置。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop), shape = 21, col = \"white\",\n    show.legend = c(fill = TRUE, size = FALSE)\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.875, 0.3)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.14: 微调图例位置\n\n\n\n\n或者更换其它主题，比如 ggthemes 包内置极简主题 theme_tufte()，它仅保留主刻度线，更加凸显数据。\n\nlibrary(ggthemes)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  theme_tufte(base_family = \"sans\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside =  c(0.875, 0.3), \n    legend.title = element_text(family = \"Noto Sans CJK SC\"),\n    legend.text = element_text(family = \"Noto Sans CJK SC\"),\n    axis.title = element_text(family = \"Noto Sans CJK SC\")) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.15: ggthemes 的极简主题 Tufte",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-annotation",
    "href": "visualization-basic.html#sec-annotation",
    "title": "6  ggplot2 入门",
    "section": "\n6.7 注释",
    "text": "6.7 注释\n注释可以是普通文本，数学公式，还可以是图形照片、表情包。注释功能非常强大，但也是非常灵活，往往使用起来颇费功夫，需要结合数据情况，从图形所要传递的信息出发，适当添加。R 语言社区陆续出现一些扩展包，让用户使用起来更方便些。\n\n\nggrepel (Slowikowski 2021) 包可以通过添加一定距离的扰动，可以缓解文本重叠的问题，更多内容见 (https://github.com/slowkow/ggrepel)。\n\nggtext (Wilke 2020) 包支持以 Markdown 语法添加丰富的文本内容，更多内容见 (https://github.com/wilkelab/ggtext)。\n\nstring2path (Yutani 2022) 包字体轮廓生成路径，注释文本随路径变化，更多内容见 (https://github.com/yutannihilation/string2path)。\n\nggimage (Yu 2022) 包提供图像图层，实现以图片代替散点的效果，图片还可以是表情包，更多内容见 (https://github.com/GuangchuangYu/ggimage)。\n\n在 图 6.15 的基础上，给人口总数大于 2 亿的国家添加文本注释。这可以用 ggplot2 包提供的文本图层函数 geom_text() 实现，效果如 图 6.16 。\n\nlibrary(ggrepel)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(\n    data = function(x) subset(x, year == 2007),\n    aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  geom_text(\n    data = function(x) subset(x, year == 2007 & pop &gt;= 20 * 10^7),\n    aes(label = country), show.legend = FALSE\n  ) +\n  scale_size(range = c(2, 12)) +\n  theme_tufte(base_family = \"sans\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside =  c(0.9, 0.3), \n    legend.title = element_text(family = \"Noto Sans CJK SC\"),\n    legend.text = element_text(family = \"Noto Sans CJK SC\"),\n    axis.title = element_text(family = \"Noto Sans CJK SC\")) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.16: 添加文本注释\n\n\n\n\n当需要给许多点添加文本注释时，就难以避免地遇到注释文本重叠的问题。比如给人口总数大于 5000 万的国家添加文本注释，此时，适合使用 ggrepel 包，调用函数 geom_text_repel() — 这是一个新的文本图层，通过添加适当的位移缓解文本重叠问题。\n\nlibrary(ggrepel)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(data = function(x) subset(x, year == 2007),\n             aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_x_log10(\n    labels = label_dollar(), minor_breaks = mb, limits = c(100, 110000)\n  ) +\n  geom_text_repel(\n    data = function(x) subset(x, year == 2007 & pop &gt;= 5 * 10^7),\n    aes(label = country), size = 3, max.overlaps = 50,\n    segment.colour = \"gray\", seed = 2022, show.legend = FALSE\n  ) +\n  scale_size(range = c(2, 12)) +\n  theme_tufte(base_family = \"sans\") +\n  theme(\n    legend.position = \"inside\", \n    legend.position.inside =  c(0.9, 0.3), \n    legend.title = element_text(family = \"Noto Sans CJK SC\"),\n    legend.text = element_text(family = \"Noto Sans CJK SC\"),\n    axis.title = element_text(family = \"Noto Sans CJK SC\")) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.17: 缓解文本注释相互覆盖的问题",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-facet",
    "href": "visualization-basic.html#sec-facet",
    "title": "6  ggplot2 入门",
    "section": "\n6.8 分面",
    "text": "6.8 分面\nggplot2 包有两个函数 facet_wrap() 和 facet_grid() 都可以用来实现分面操作，分面的目的是将数据切分，一块一块地展示。下面在 图 6.15 的基础上，按收入水平变量分面，即将各个国家或地区按收入水平分开，效果如 图 6.18 所示。facet_grid() 与 facet_wrap() 的效果是类似的，就不再赘述了。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(data = function(x) subset(x, year == 2007),\n             aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(labels = label_log(), limits = c(100, 110000)) +\n  facet_wrap(facets = ~income_level, ncol = 2) +\n  theme_classic() +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.18: 按收入水平变量分面\n\n\n\n\n在函数 facet_wrap() 内设置不同的参数值，会有不同的排列效果。设置 ncol = 3，意味着排成 3 列，而分类变量 continent 总共有 5 种不同的类别，因此将会是 3 列 2 行的布局，效果如下 图 6.19 。\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(data = function(x) subset(x, year == 2007),\n             aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE),\n    shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10(labels = label_log(), limits = c(100, 110000)) +\n  facet_wrap(facets = ~income_level, ncol = 3) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.2)) +\n  labs(x = \"人均 GDP\", y = \"预期寿命\", fill = \"区域\")\n\n\n\n\n\n\n图 6.19: 按区域变量分面",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-animate",
    "href": "visualization-basic.html#sec-animate",
    "title": "6  ggplot2 入门",
    "section": "\n6.9 动画",
    "text": "6.9 动画\n从 1991 年至 2020 年，gapminder 数据集一共是 30 年的数据。根据 2007 年的数据绘制了 图 6.20 ，每年的数据绘制一幅图像，30 年总共可获得 30 帧图像，再以每秒播放 6 帧图像的速度将 30 帧图像合成 GIF 动画。因此，设置这个动画总共 30 帧，每秒播放的图像数为 6。\n\noptions(gganimate.nframes = 30, gganimate.fps = 6)\n\ngganimate 包提供一套代码风格类似 ggplot2 包的动态图形语法，可以非常顺滑地与之连接。在了解了 ggplot2 绘制图形的过程后，用 gganimate 包制作动画是非常容易的。gganimate 包会调用 gifski (https://github.com/r-rust/gifski) 包来合成动画，因此，除了安装 gganimate 包，还需要安装 gifski 包。接着，在已有的 ggplot2 绘图代码基础上，再追加一个转场图层函数 transition_time()，这里是按年逐帧展示图像，因此，其转场的时间变量为 gapminder 数据集中的变量 year。\n\nlibrary(gganimate)\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(aes(fill = region, size = pop),\n    show.legend = c(fill = TRUE, size = FALSE), \n    alpha = 0.65, shape = 21, col = \"white\"\n  ) +\n  scale_fill_manual(values = c(\n    `拉丁美洲与加勒比海地区` = \"#E41A1C\", `撒哈拉以南非洲地区` = \"#377EB8\",\n    `欧洲与中亚地区` = \"#4DAF4A\", `中东与北非地区` = \"#984EA3\",\n    `东亚与太平洋地区` = \"#FF7F00\", `南亚` = \"#FFFF33\", `北美` = \"#A65628\"\n  )) +\n  scale_size(range = c(2, 12), labels = label_number(scale_cut = cut_short_scale())) +\n  scale_x_log10(labels = label_log(), limits = c(10, 130000)) +\n  facet_wrap(facets = ~income_level) +\n  theme_classic() +\n  labs(\n    title = \"{frame_time} 年\", x = \"人均 GDP\",\n    y = \"预期寿命\", size = \"人口总数\", fill = \"区域\"\n  ) +\n  transition_time(time = year)\n\n\n\n\n\n\n图 6.20: 制作动画",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-combine",
    "href": "visualization-basic.html#sec-combine",
    "title": "6  ggplot2 入门",
    "section": "\n6.10 组合",
    "text": "6.10 组合\n将多幅小图组合起来构成一幅大图也是常见的需求，常见于出版级、产品级的作品中。组合涉及到布局，布局涉及到层次。有的组合图是从不同角度呈现数据，有的组合图是从传递信息的主次出发，等等。patchwork 包是非常流行的一个基于 ggplot2 的用于图形组合的 R 包，下面基于 faithful 数据展示绘制组合图形的过程。\n首先根据喷发时间将 faithful 数据分成两组。\n\n# 根据喷发时间将数据分成两组\nfaithful &lt;- transform(faithful, group = ifelse(eruptions &gt; 3, \"A\", \"B\"))\n\n绘制分组散点图，叠加二维核密度曲线。\n\n# 绘制分组散点图\nscatterplot &lt;- ggplot(faithful, aes(eruptions, waiting, color = group)) +\n  geom_point() +\n  geom_density_2d() +\n  theme_classic() +\n  theme(axis.text = element_blank(), axis.title = element_blank())\n\n将上图中的图例单独抽取出来，作为一个子图。\n\n# https://stackoverflow.com/questions/46079033/\n# Extract legend from ggplot object\nextract_legend &lt;- function(gg) {\n  grobs &lt;- ggplot_gtable(ggplot_build(gg))\n  foo &lt;- which(sapply(grobs$grobs, function(x) x$name) == \"guide-box\")\n  grobs$grobs[[foo]]\n}\nlegend &lt;- extract_legend(scatterplot)\n\n获得图例后，原图中不需要图例了。\n\nscatterplot &lt;- scatterplot + theme(legend.position = \"none\")\n\n准备两个箱线图分别描述 faithful 数据集中的等待时间 waiting 和喷发时间 eruptions 。\n\nboxplot_left &lt;- ggplot(faithful, aes(group, waiting, fill = group)) +\n  geom_boxplot() +\n  theme_classic() +\n  theme(\n    legend.position = \"none\", axis.ticks.x = element_blank(),\n    axis.text.x = element_blank(), axis.title.x = element_blank()\n  )\n\nboxplot_bottom &lt;- ggplot(faithful, aes(group, eruptions, fill = group)) +\n  geom_boxplot() +\n  theme_classic() +\n  theme(\n    legend.position = \"none\", axis.ticks.y = element_blank(),\n    axis.text.y = element_blank(), axis.title.y = element_blank()\n  ) +\n  coord_flip()\n\n加载 patchwork 包，使用函数 wrap_plots() 组合 boxplot_left 、scatterplot 、legend 和 boxplot_bottom 四个子图，最终效果见下图。\n\nlibrary(patchwork)\ntop &lt;- wrap_plots(boxplot_left, scatterplot, ncol = 2, widths = c(0.2, 0.8))\nbottom &lt;- wrap_plots(legend, boxplot_bottom, ncol = 2, widths = c(0.22, 0.8))\nfinal &lt;- wrap_plots(top, bottom, nrow = 2, heights = c(0.8, 0.2))\nfinal\n\n\n\n\n\n\n图 6.21: patchwork 组合多幅子图\n\n\n\n\n主图是占据着最大篇幅的叠加二维密度曲线的散点图，展示数据的二维分布，两个箱线图辅助展示等待时间 waiting 和喷发时间 eruptions 的分布，而左下角的图例是次要的说明。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-basic.html#sec-arts",
    "href": "visualization-basic.html#sec-arts",
    "title": "6  ggplot2 入门",
    "section": "\n6.11 艺术",
    "text": "6.11 艺术\nGeorgios Karamanis 基于 R 语言和扩展包 ggforce 制作了一系列生成艺术（Generative Arts）作品。下图是 ggforce 包的 4 个图层函数 geom_regon()、 geom_spiro()、 geom_diagonal() 和 geom_spoke() 分别生成的四幅图片。\nlibrary(ggforce)\ns &lt;- 900\nggplot() +\n  geom_regon(aes(\n    x0 = cos((1:s) / 57), y0 = sin((1:s) / 57),\n    sides = 6, r = cos((1:s) / 24),\n    angle = cos((1:s) / 23), color = 1:s %% 15\n  ),\n  linewidth = 0.2, fill = NA, linetype = \"twodash\"\n  ) +\n  scale_color_viridis_c(option = 15, guide = \"none\") +\n  coord_fixed() +\n  theme_void()\n\nr &lt;- seq(1, 11, 0.1)\nggplot() +\n  geom_spiro(aes(r = r, R = r * 20, d = r^2, outer = T, color = r %% 10), linewidth = 3) +\n  scale_color_viridis_c(option = \"turbo\") +\n  coord_fixed() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\ns &lt;- 1200\nggplot() +\n  geom_diagonal(aes(\n    x = cos(seq(0, pi, length.out = s)),\n    y = sin(seq(0, pi, length.out = s)),\n    xend = cos(seq(0, 360 * pi, length.out = s)),\n    yend = sin(seq(0, 360 * pi, length.out = s))\n  ),\n  linewidth = 0.1, strength = 1\n  ) +\n  coord_fixed() +\n  theme_void()\n\ne &lt;- 1e-3\ns &lt;- 1e4\nt &lt;- pi / 2 * cumsum(seq(e, -e, length.out = s))^3\nggplot() +\n  geom_spoke(aes(\n    x = cumsum(cos(t)), y = cumsum(sin(t)),\n    angle = t, color = t, radius = 1:s %% 500\n  ), alpha = 0.5) +\n  scale_color_distiller(palette = 15, guide = \"none\") +\n  coord_fixed() +\n  theme_void()\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_regon()\n\n\n\n\n\n\n\n\n\n(b) 函数 geom_spiro()\n\n\n\n\n\n\n\n\n\n\n\n(c) 函数 geom_diagonal()\n\n\n\n\n\n\n\n\n\n(d) 函数 geom_spoke()\n\n\n\n\n\n\n图 6.22: R 语言与生成艺术\n\n\n需要充满想象，或借助数学、物理方程，或借助算法、数据生成。好看，但没什么用的生成艺术作品。\n\nhttps://art-from-code.netlify.app/\nhttps://clauswilke.com/art/project/before-after\nhttps://clauswilke.com/art/\nhttps://art.djnavarro.net/\nhttps://www.data-imaginist.com/art\n\n\n\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra Themes, Scales and Geoms for ggplot2. https://CRAN.R-project.org/package=ggthemes.\n\n\nBion, Ricardo. 2018. ggtech: ggplot2 tech themes and scales.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, 等. 2021. viridis: Colorblind-Friendly Color Maps for R. https://doi.org/10.5281/zenodo.4679424.\n\n\nGross, Calli, 和 Philipp Ottolinger. 2016. ggThemeAssist: Add-in to Customize ggplot2 Themes. https://CRAN.R-project.org/package=ggThemeAssist.\n\n\nHawkins, Oliver. 2022. pilot: A minimal ggplot2 theme with an accessible discrete color palette. https://github.com/olihawkins/pilot.\n\n\nHvitfeldt, Emil. 2021. paletteer: Comprehensive Collection of Color Palettes. https://github.com/EmilHvitfeldt/paletteer.\n\n\nKarambelkar, Bhaskar. 2016. colormap: Color Palettes using Colormaps Node Module. https://CRAN.R-project.org/package=colormap.\n\n\nKassambara, Alboukadel. 2022. ggpubr: ggplot2 Based Publication Ready Plots. https://CRAN.R-project.org/package=ggpubr.\n\n\nNeitmann, Thomas. 2020. ggcharts: Shorten the Distance from Data Visualization Idea to Actual Plot. https://CRAN.R-project.org/package=ggcharts.\n\n\nNeuwirth, Erich. 2022. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.\n\n\nPedersen, Thomas Lin, 和 Fabio Crameri. 2022. scico: Colour Palettes Based on the Scientific Colour-Maps. https://CRAN.R-project.org/package=scico.\n\n\nSlowikowski, Kamil. 2021. ggrepel: Automatically Position Non-Overlapping Text Labels with ggplot2. https://CRAN.R-project.org/package=ggrepel.\n\n\nStylianou, Nassos, Will Dahlgreen, Robert Cuffe, Tom Calver, 和 Ransome Mpini. 2022. bbplot: making ggplot2 graphics in BBC NEWS style.\n\n\nTobin, Ciaran. 2020. ggthemr: Themes for ggplot2.\n\n\nWickham, Charlotte. 2018. munsell: Utilities for Using Munsell Colours. https://CRAN.R-project.org/package=munsell.\n\n\nWickham, Hadley, 和 Dana Seidel. 2022. scales: Scale Functions for Visualization. https://CRAN.R-project.org/package=scales.\n\n\nWilke, Claus O. 2020. ggtext: Improved Text Rendering Support for ggplot2. https://CRAN.R-project.org/package=ggtext.\n\n\nXiao, Nan. 2018. ggsci: Scientific Journal and Sci-Fi Themed Color Palettes for ggplot2. https://CRAN.R-project.org/package=ggsci.\n\n\nYu, Guangchuang. 2022. ggimage: Use Image in ggplot2. https://CRAN.R-project.org/package=ggimage.\n\n\nYutani, Hiroaki. 2022. string2path: Rendering Font into data.frame. https://CRAN.R-project.org/package=string2path.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, 和 Claus O. Wilke. 2020. 《colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes》. Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ggplot2 入门</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html",
    "href": "visualization-intermediate.html",
    "title": "7  基础图形",
    "section": "",
    "text": "7.1 描述趋势\nGNU R 是一个自由的统计计算和统计绘图环境，最初由新西兰奥克兰大学统计系的 Ross Ihaka 和 Robert Gentleman 共同开发。1997 年之后，成立了一个 R Core Team（R 语言核心团队），他们在版本控制系统 Apache Subversion上一起协作开发至今。25 年—四分之一个世纪过去了，下面分析他们留下的一份开发日志，了解一段不轻易为人所知的故事。\n首先，下载 1997 年至今约 25 年的原始代码提交日志数据。下载数据的代码如下，它是一行 Shell 命令，可在 MacOS 或 Ubuntu 等 Linux 系统的终端里运行，借助 Apache Subversion 软件，将提交日志导出为 XML 格式 的数据文件，保存在目录 data-raw/ 下，文件名为 svn_trunk_log_2022.xml，本书网页版随附。\nsvn log --xml --verbose -r 6:83528 \\\n  https://svn.r-project.org/R/trunk &gt; data-raw/svn_trunk_log_2022.xml\n去掉没什么信息的前5次代码提交记录：初始化仓库，上传原始的 R 软件源码等。 从 Ross Ihaka 在 1997-09-18 提交第 1 次代码改动开始，下载所有的提交日志。截至 2022-12-31，代码最新版本号为 83528，意味着代码仓库已存在 8 万多次提交。\n下载数据后，借助 xml2 包预处理这份 XML 格式数据，提取最重要的信息，谁在什么时间做了什么改动。经过一番操作后，将清洗干净的数据保存到目录 data/ 下，以 R 软件特有的文件格式保存为 svn-trunk-log-2022.rds，同样与书随附。这样下来，原 XML 格式保存的 35 M 文件减少为 1 M 多，极大地减少存储空间，方便后续的数据探索和可视化。下面是这份日志数据最初的两行：\nsvn_trunk_log &lt;- readRDS(file = \"data/svn-trunk-log-2022.rds\")\nhead(svn_trunk_log, 2)\n\n#&gt;   revision author               stamp                                msg\n#&gt; 1        6  ihaka 1997-09-18 04:41:25 New predict.lm from Peter Dalgaard\n#&gt; 2        7  ihaka 1997-09-18 04:42:42             Updated release number\n一共是四个字段，分别是代码提交时记录的版本号 revision，提交代码的人 author，提交代码的时间 stamp 和提交代码时伴随的说明 msg。接下来，带着问题一起探索开源自由的统计软件 R 过去 25 年波澜壮阔的历史！",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualize-data-trend",
    "href": "visualization-intermediate.html#sec-visualize-data-trend",
    "title": "7  基础图形",
    "section": "",
    "text": "7.1.1 折线图\n\n\n\n\n\n\n\n提示\n\n\n\n不再介绍每个函数、每个参数和每行代码的作用，而是重点阐述折线图的作用，以及如何解读数据，阐述解读的思路和方向，建立起数据分析的思维。将重点放在这些方面，有助于书籍存在的长远意义，又结合了最真实的背景和原始数据，相信对实际工作的帮助会更大。而对于使用到统计方法的函数，则详加介绍，展示背后的实现细节，而不是调用函数做调包侠。\n\n\n折线图的意义是什么？在表达趋势变化，趋势的解读很重要。先来了解一下总体趋势，即过去 25 年里代码提交次数的变化情况。数据集 svn_trunk_log 没有年份字段，但时间字段 stamp 隐含了年份信息，因此，新生成一个字段 year 将年份信息从 stamp 提取出来。\n\nsvn_trunk_log &lt;- within(svn_trunk_log, {\n  # 提取日期、月份、年份、星期、第几周、第几天等时间成分\n  year &lt;- as.integer(format(stamp, \"%Y\"))\n  date &lt;- format(stamp, format = \"%Y-%m-%d\", tz = \"UTC\")\n  month &lt;- format(stamp, format = \"%m\", tz = \"UTC\")\n  hour &lt;- format(stamp, format = \"%H\", tz = \"UTC\")\n  week &lt;- format(stamp, format = \"%U\", tz = \"UTC\")\n  wday &lt;- format(stamp, format = \"%a\", tz = \"UTC\")\n  nday &lt;- format(stamp, format = \"%j\", tz = \"UTC\")\n})\n# 代码维护者 ID 和姓名对应\nctb_map &lt;- c(\n  \"bates\" = \"Douglas Bates\", \"deepayan\" = \"Deepayan Sarkar\",\n  \"duncan\" = \"Duncan Temple Lang\", \"falcon\" = \"Seth Falcon\",\n  \"guido\" = \"Guido Masarotto\", \"hornik\" = \"Kurt Hornik\",\n  \"iacus\" = \"Stefano M. Iacus\", \"ihaka\" = \"Ross Ihaka\",\n  \"jmc\" = \"John Chambers\", \"kalibera\" = \"Tomas Kalibera\",\n  \"lawrence\" = \"Michael Lawrence\", \"leisch\" = \"Friedrich Leisch\",\n  \"ligges\" = \"Uwe Ligges\", \"luke\" = \"Luke Tierney\",\n  \"lyndon\" = \"Others\", \"maechler\" = \"Martin Maechler\",\n  \"mike\" = \"Others\", \"morgan\" = \"Martin Morgan\",\n  \"murdoch\" = \"Duncan Murdoch\", \"murrell\" = \"Paul Murrell\",\n  \"pd\" = \"Peter Dalgaard\", \"plummer\" = \"Martyn Plummer\",\n  \"rgentlem\" = \"Robert Gentleman\", \"ripley\" = \"Brian Ripley\",\n  \"smeyer\" = \"Sebastian Meyer\", \"system\" = \"Others\",\n  \"tlumley\" = \"Thomas Lumley\", \"urbaneks\" = \"Simon Urbanek\"\n)\nsvn_trunk_log$author &lt;- ctb_map[svn_trunk_log$author]\n\n接着，调用分组聚合函数 aggregate() 统计各年的代码提交量。\n\ntrunk_year &lt;- aggregate(data = svn_trunk_log, revision ~ year, FUN = length)\n\n然后，将数据集 trunk_year 以折线图展示，如 图 7.1 所示。\n\nlibrary(ggplot2)\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_line() +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.1: 过去 25 年代码提交次数的变化情况\n\n\n\n\n为什么呈现这样的变化趋势？我最初想到的是先逐步增加，然后下降一会儿，再趋于平稳。这比较符合软件从快速迭代开发期，过渡到成熟稳定期的生命周期。接着，从小时趋势图观察代码提交量的变化，发现有高峰有低谷，上午高峰，晚上低峰，但也并不是所有年份都一致，这是因为开发者来自世界各地，位于不同的时区。\n\naggregate(data = svn_trunk_log, revision ~ year + hour, length) |&gt; \n  ggplot(aes(x = hour, y = revision, group = year)) +\n  geom_line() +\n  geom_line(data = function(x) subset(x, year &lt; 2006),\n            aes(color = as.character(year))) +\n  theme_classic() +\n  labs(x = \"时段\", y = \"提交量\", color = \"年份\")\n\n\n\n\n\n\n图 7.2: 提交代码的时段分布\n\n\n\n\n最后，观察代码提交量的月趋势图，12月和次年1月、7-8 月份提交量迎来小高峰，应该是教授们放寒暑假。\n\naggregate(data = svn_trunk_log, revision ~ year + month, length) |&gt;\n  transform(date = as.Date(paste(year, month, \"01\", sep = \"-\"))) |&gt;\n  ggplot(aes(x = date, y = revision)) +\n  geom_point(aes(color = factor(year)), show.legend = F, size = 0.75) +\n  geom_line(aes(color = factor(year)), show.legend = F) +\n  scale_x_date(date_minor_breaks = \"1 year\") +\n  theme_classic() +\n  theme(panel.grid.minor.x = element_line()) +\n  labs(x = \"时间（月粒度）\", y = \"提交量\")\n\n\n\n\n\n\n图 7.3: 提交代码的月份分布\n\n\n\n\n\n7.1.2 瀑布图\n相比于折线图，瀑布图将变化趋势和增减量都展示了，如 图 7.4 所示，每年的提交量就好像瀑布上的水，图中每一段水柱表示当期相对于上一期的增减量。瀑布图是用矩形图层 geom_rect() 构造的，数据点作为矩形对角点，对撞型的颜色表示增减。\n\ntrunk_year &lt;- trunk_year[order(trunk_year$year), ]\n\ntrunk_year_tmp &lt;- data.frame(\n  xmin = trunk_year$year[-length(trunk_year$year)],\n  ymin = trunk_year$revision[-length(trunk_year$revision)],\n  xmax = trunk_year$year[-1],\n  ymax = trunk_year$revision[-1],\n  fill = trunk_year$revision[-1] - trunk_year$revision[-length(trunk_year$revision)] &gt; 0\n)\n\nggplot() +\n  geom_rect(\n    data = trunk_year_tmp,\n    aes(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax, fill = fill\n), \n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = trunk_year, aes(x = year, y = revision), size = 0.75\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.4: 25 年代码逐年提交量的变化趋势\n\n\n\n\nggTimeSeries 包 (Kothari 2022) (https://github.com/thecomeonman/ggTimeSeries) 提供统计图层 stat_waterfall() 实现类似的瀑布图，如 图 7.5 所示。\n\nlibrary(ggTimeSeries)\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  stat_waterfall() +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.5: 矩形图层构造瀑布图\n\n\n\n\n\n7.1.3 曲线图\n\n将散点以线段逐个连接起来，形成折线图，刻画原始的变化，而曲线图的目标是刻画潜在趋势。有两种画法，其一从代数的角度出发，做插值平滑，在相邻两点之间以一条平滑的曲线连接起来；其二从统计的角度出发，做趋势拟合，通过线性或非线性回归，获得变化趋势，以图呈现，使得散点之中隐藏的趋势更加清晰。\nggplot2 (Wickham 2016) 包提供函数 geom_smooth() 拟合散点图中隐含的趋势，通过查看函数 geom_smooth() 的帮助文档，可以了解其内部调用的统计方法。默认情况下，采用局部多项式回归拟合方法，内部调用了函数 loess() 来拟合趋势，如 图 7.6 所示。\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(data = subset(trunk_year, year != 1997)) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n图 7.6: 过去 25 年代码提交次数的变化情况\n\n\n\n\n类似大家熟悉的线性回归拟合函数 lm()，函数 loess() 也是基于类似的使用语法。下面继续以此数据为例，了解该函数的使用，继而了解 ggplot2 绘制平滑曲线图背后的统计方法。1997 年是不完整的，不参与模型参数的估计。\n\ntrunk_year_loess &lt;- loess(revision ~ year,\n  data = subset(trunk_year, year != 1997),\n  span = 0.75, degree = 2, method = \"loess\",\n  family = \"symmetric\",\n  control = loess.control(surface = \"direct\", iterations = 4)\n)\n\n下面通过设定函数 geom_smooth() 的参数，可以达到一样的效果，见下 图 7.7\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\",\n    method.args = list(\n      span = 0.75, degree = 2, family = \"symmetric\",\n      control = loess.control(surface = \"direct\", iterations = 4)\n    ), data = subset(trunk_year, year != 1997)) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.7: 过去 25 年代码提交次数的变化情况\n\n\n\n\nmethod = \"loess\" 意味着调用了一种非参数的回归方法，即局部估计散点平滑 （locally estimated scatterplot smoothing），另一个与之类似的回归方法是局部加权散点平滑 （locally weighted scatterplot smoothing），简称 lowess 。1991 年 Jerome Friedman 提出多元适应性回归样条（Multivariate Adaptive Regression Splines），R 语言社区对应功能的扩展包是 earth 。\n除了 method = \"loess\"，函数 geom_smooth() 支持的统计方法还有很多，比如非线性回归拟合 nls()\n\ntrunk_year_nls &lt;- nls(revision ~ a * (year - 1996)^2 + b,\n  data = subset(trunk_year, year != 1997),\n  start = list(a = -0.1, b = 1000)\n)\n\n采用一元二次非线性回归拟合方法，效果如 图 7.8 所示。\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    method = \"nls\", \n    formula = \"y ~ a * (x - 1996)^2 + b\",\n    method.args = list(\n      start = list(a = -0.1, b = 1000)\n    ), se = FALSE, \n    data = subset(trunk_year, year != 1997),\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 7.8: 过去 25 年代码提交次数的变化情况\n\n\n\n\n\n\n\n\n\n\n注意\n\n\n\n在函数 geom_smooth() 内调用非线性回归拟合方法时，暂不支持提供置信区间。\n\n\n即便在不清楚统计原理的情况下，也不难看出 图 7.7 和 图 7.8 的差异，局部多项式回归捕捉到了更多的信息，特别是起步阶段的上升趋势，以及 2000-2005 年的高峰特点。\n\nsummary(trunk_year_loess)\n\n#&gt; Call:\n#&gt; loess(formula = revision ~ year, data = subset(trunk_year, year != \n#&gt;     1997), span = 0.75, degree = 2, family = \"symmetric\", method = \"loess\", \n#&gt;     control = loess.control(surface = \"direct\", iterations = 4))\n#&gt; \n#&gt; Number of Observations: 25 \n#&gt; Equivalent Number of Parameters: 4.53 \n#&gt; Residual Scale Estimate: 308.4 \n#&gt; Trace of smoother matrix: 4.97  (exact)\n#&gt; \n#&gt; Control settings:\n#&gt;   span     :  0.75 \n#&gt;   degree   :  2 \n#&gt;   family   :  symmetric      iterations = 4\n#&gt;   surface  :  direct\n#&gt;   normalize:  TRUE\n#&gt;  parametric:  FALSE\n#&gt; drop.square:  FALSE\n\n\n\nsummary(trunk_year_nls)\n\n#&gt; \n#&gt; Formula: revision ~ a * (year - 1996)^2 + b\n#&gt; \n#&gt; Parameters:\n#&gt;    Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; a   -2.9625     0.4555  -6.504 1.23e-06 ***\n#&gt; b 3070.0890   147.1920  20.858  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 471.8 on 23 degrees of freedom\n#&gt; \n#&gt; Number of iterations to convergence: 1 \n#&gt; Achieved convergence tolerance: 2.808e-08\n\n\n非线性回归模型带有 2 个参数，一共 26 个观察值，因此，自由度为 26 - 2 = 24。 RSE 残差平方和的标准差为\n\n# 非线性回归的残差平方和的标准差\nsqrt(sum(residuals(trunk_year_nls)^2)/24)\n\n#&gt; [1] 461.8963\n\n\n以平滑曲线连接相邻的散点，可以构造一个插值方法给函数 geom_smooth()，如下示例基于样条插值函数 spline()。样条源于德国宝马工程师，车辆外壳弧线，那些拥有非常漂亮的弧线，越光滑，与空气的摩擦阻力越小，车辆的气动外形更加符合流体力学的要求，加工打磨更加困难，往往价值不菲。美感是相通的，即使不懂车标，通过气动外形，也能识别出车辆的档次。\nggplot2 包支持的平滑方法有很多，如借助函数 splinefun() 构造样条插值获得平滑曲线，调用 mgcv 包的函数 gam() ，调用 ggalt 包的函数 geom_xspline() 。\nxxspline &lt;- function(formula, data, ...) {\n  dat &lt;- model.frame(formula, data)\n  res &lt;- splinefun(dat[[2]], dat[[1]])\n  class(res) &lt;- \"xxspline\"\n  res\n}\n\npredict.xxspline &lt;- function(object, newdata, ...) {\n  object(newdata[[1]])\n}\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    formula = \"y~x\",\n    method = xxspline, se = FALSE,\n    data = subset(trunk_year, year != 1997)\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    formula = y ~ s(x, k = 12),\n    method = \"gam\", se = FALSE,\n    data = subset(trunk_year, year != 1997)\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\nggplot(data = trunk_year, aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(\n    method = \"lm\", \n    formula = \"y ~ poly((x - 1996), 3)\",\n    se = FALSE, \n    data = subset(trunk_year, year != 1997),\n  ) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n\n\n\n(a) 自定义样条插值 spline\n\n\n\n\n\n\n\n\n\n(b) 广义可加模型样条拟合\n\n\n\n\n\n\n\n\n\n\n\n(c) 自由度为 3 的正交多项式拟合\n\n\n\n\n\n\n图 7.9: 过去 25 年代码提交次数的变化情况\n\n\n数学公式表达的统计模型与 R 语言表达的计算公式的对应关系见下 表格 7.1 ，更多详情见帮助文档 ?formula。\n\n\n表格 7.1: 数学公式与 R 语言表示的计算公式\n\n\n\n\n\n\n\n数学公式\nR 语言计算公式\n\n\n\n\\(y = \\beta_0\\)\ny ~ 1\n\n\n\\(y = \\beta_0 + \\beta_1 x_1\\)\n\ny ~ 1 + x1 或 y ~ x1 或 y ~ x1 + x1^2\n\n\n\n\\(y = \\beta_1 x_1\\)\n\ny ~ 0 + x1 或 y ~ -1 + x1\n\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\\)\ny ~ x1 + x2\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2\\)\ny ~ x1 * x2\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 x_2\\)\ny ~ x1:x2\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2\\)\ny ~ x1 + x2 + x1:x2\n\n\n\\(y = \\beta_0 + \\sum_{i=1}^{999}\\beta_i x_i\\)\ny ~ .\n\n\n\\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^5\\)\ny ~ x + I(x^5)\n\n\n\\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\)\ny ~ x + I(x^2)\n\n\n\\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\)\ny ~ poly(x, degree = 2, raw = TRUE)\n\n\n\n\n\n\n\n7.1.4 流线图\n流线图（Stream Graph）是堆积面积图（Stacked Area Graph）的一种变体，适合描述时间序列数据的趋势。ggplot2 扩展包 ggstream 可以制作流线图，如下图所示。\n\nlibrary(ggstream)\ntrunk_year_author &lt;- aggregate(data = svn_trunk_log, revision ~ year + author, FUN = length)\nggplot(trunk_year_author, aes(x = year, y = revision, fill = author)) +\n  geom_stream() +\n  theme_classic() +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"年份\", y = \"提交量\", fill = \"贡献者\")\n\n\n\n\n\n\n图 7.10: 各开发者的提交量趋势\n\n\n\n\n\n7.1.5 曲面图\nggplot2 包暂不支持绘制三维曲面图，而 lattice 包支持，但也是非常有限的支持。lattice 包和 ggplot2 包都是基于图形语法的，层层叠加就必然会出现覆盖，只有在绘制函数型数据的图像时是合适的，因为覆盖少，即使覆盖也不妨碍趋势的表达。根据不同的使用场景有两个更好的选择，基于 OpenGL 的真三维图形可以用 rayrender 和 rayshader 包绘制，而基于 JavaScripts 的交互式三维图形可以用 rgl 或 plotly 包绘制。\n下 图 7.11 是用 lattice 包的 wireframe() 函数绘制的，这是一个三维曲面透视图，三维图形有时候并不能很好地表达数据，或者数据并不适合用三维图形表示。数据本身并没有那么明显的趋势规律，同样也会体现不出三维图形的表达能力。大部分情况下，我们应当避免使用静态的三维图形，但函数型数据是适合用三维图形来表达的。\n\n代码trunk_year_week &lt;- aggregate(data = svn_trunk_log, revision ~ year + week, FUN = length)\nlibrary(lattice)\nwireframe(\n  data = trunk_year_week, revision ~ year * as.integer(week),\n  shade = TRUE, drape = FALSE,\n  xlab = \"年份\",\n  ylab = \"第几周\",\n  zlab = list(\"提交量\", rot = 90),\n  scales = list(\n    arrows = FALSE, col = \"black\"\n  ),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -.6, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.8, units = \"inches\"),\n      top.padding = list(x = -1.0, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = -60, x = -70, y = 0)\n)\n\n\n\n\n\n\n图 7.11: 25 年代码提交量变化趋势图\n\n\n\n\n每周的代码提交量受影响因素多，不确定性多，波动表现尖锐高频，上图反而对整体趋势的表达不够简洁清晰。按年、月统计提交量平均掉了每日的波动，反而可以体现更大的周期性和趋势性。下面绘制三维柱形图，三维图形天然给人有更加直观的感觉，毕竟立体。latticeExtra 包提供三维柱形图图层 panel.3dbars()，如 图 7.12 所示。\n\n代码# 按年、月分组统计代码提交量\ntrunk_year_month &lt;- aggregate(\n  data = svn_trunk_log,\n  revision ~ year + month, FUN = length\n)\n# 数据转化为矩阵类型\ntrunk_year_month_m &lt;- matrix(\n  data = trunk_year_month[trunk_year_month$year &gt; 1998, \"revision\"],\n  ncol = 12, nrow = 24, byrow = FALSE,\n  dimnames = list(\n    1999:2022, # 行\n    1:12 # 列\n  )\n)\n# 绘制三维柱形图\ncloud(trunk_year_month_m,\n  panel.3d.cloud = latticeExtra::panel.3dbars,\n  col.facet = \"red\", # 柱子的颜色\n  col = \"gray90\",\n  xbase = 0.5, ybase = 0.5, # 柱子的大小\n  scales = list(\n    arrows = FALSE, col = \"black\",\n    # tck 刻度线的长度\n    tck = c(0.7, 1.5, 1),\n    # distance 控制标签到轴的距离\n    distance = c(1.2, 0.6, 0.8)\n  ),\n  # rot 旋转轴标签\n  xlab = list(\"年份\", rot = -45), ylab = list(\"月份\", rot = 45),\n  zlab = list(\"提交量\", rot = 90),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -.6, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.8, units = \"inches\"),\n      top.padding = list(x = -1.0, units = \"inches\")\n    )\n  ),\n  # 去掉边框\n  par.settings = list(\n    axis.line = list(col = \"transparent\"),\n    layout.widths = list(ylab.axis.padding = 0)\n  ),\n  screen = list(z = -45, x = -30, y = 0)\n)\n\n\n\n\n\n\n图 7.12: 25 年代码提交量变化趋势图\n\n\n\n\n\n7.1.6 热力图\n图 7.13 提交量变化趋势\n\nggplot(data = trunk_year_week, aes(x = as.integer(week) , y = year, fill = revision)) +\n  geom_tile(linewidth = 0.4) +\n  scale_fill_viridis_c(option = \"C\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme_classic() +\n  labs(x = \"第几周\", y = \"年份\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.13: 25 年代码提交量变化热力图\n\n\n\n\n图层 scale_x_continuous() 中设置 expand = c(0, 0) 可以去掉数据与 x 轴之间的空隙。 或者添加坐标参考系图层 coord_cartesian()，设置参数 expand = FALSE 同时去掉横纵轴与数据之间的空隙。\n\naggregate(data = svn_trunk_log, revision ~ year + month, length) |&gt;\n  ggplot(aes(x = month, y = year, fill = revision)) +\n  geom_tile(linewidth = 0.4) +\n  scale_fill_viridis_c(option = \"C\") +\n  coord_cartesian(expand = FALSE) +\n  theme_classic() +\n  labs(x = \"月份\", y = \"年份\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.14: 25 年代码提交量变化热力图\n\n\n\n\n\n7.1.7 日历图\n更加直观地展示出节假日、休息工作日、寒暑假，比如描述学生学习规律、需求的季节性变化、周期性变化。\n\n# 星期、月份缩写\nweek.abb &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\nmonth.abb &lt;- c(\n  \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n)\n# 按年、星期、第几周聚合统计提交量数据\nsvn_trunk_year &lt;- aggregate(\n  revision ~ year + wday + week, FUN = length,\n  data = svn_trunk_log, subset = year %in% 2018:2022\n)\n# 第几周转为整型数据\n# 周几转为因子型数据\nsvn_trunk_year &lt;- within(svn_trunk_year, {\n   week = as.integer(week)\n   wday = factor(wday, labels = week.abb)\n})\n\n\nggplot(data = svn_trunk_year, aes(\n  x = week, y = wday, fill = cut(revision, breaks = 5 * 0:5)\n)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  scale_fill_brewer(palette = \"Greens\") +\n  scale_x_continuous(\n    expand = c(0, 0), breaks = seq(1, 52, length = 12), labels = month.abb\n  ) +\n  facet_wrap(~year, ncol = 1) +\n  theme_minimal() +\n  labs(x = \"月份\", y = \"星期\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.15: 最近 5 年休息和工作日打码活跃度\n\n\n\n\n经过了解 svn_trunk_year 2018 - 2022 年每天提交量的范围是 0 次到 21 次，0 次表示当天没有提交代码，SVN 上也不会有日志记录。因此，将提交量划分为 5 档\n\n7.1.8 棋盘图\n棋盘图一般可以放所有时间节点的聚合信息，格点处为落的子\n该数据集的存储结构很简单，是一个两列的数据框，它的一些属性如下：\n\nstr(rversion)\n\n#&gt; 'data.frame':    140 obs. of  2 variables:\n#&gt;  $ version: chr  \"0.49\" \"0.50-a1\" \"0.50-a4\" \"0.60.0\" ...\n#&gt;  $ date   : chr  \"1997-04-23\" \"1997-07-22\" \"1997-09-10\" \"1997-12-04\" ...\n\n\n做一点数据处理，将 date 字段转为日期类型，并从日期中提取年、月信息。\n\nrversion$date &lt;- as.Date(rversion$date, format = \"%Y-%m-%d\", tz = \"UTC\")\nrversion$year &lt;- format(rversion$date, \"%Y\")\nrversion$month &lt;- format(rversion$date, \"%m\")\n\n统计过去 25 年里每月的发版次数，如图 图 7.16\n\naggregate(data = rversion, version ~ year + month, length) |&gt;\n  ggplot(aes(x = month, y = year)) +\n  geom_label(aes(label = version, fill = version),\n    show.legend = F, color = \"white\") +\n  scale_fill_viridis_c(option = \"D\", begin = 0.2, end = 0.8) +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray95\")) +\n  labs(x = \"月份\", y = \"年份\")\n\n\n\n\n\n\n图 7.16: 25 年 R 软件发版情况\n\n\n\n\n\n7.1.9 时间线图\n时间线图非常适合回顾过去，展望未来，讲故事\n时间线图展示信息的层次和密度一般由时间跨度决定。时间跨度大时，展示重点节点信息，时间跨度小时，重点和次重点信息都可以放。从更加宏观的视角，厘清发展脉络，比如近两年的 R 软件发版情况。\n本节用到一个数据集 rversion，记录了历次 R 软件发版时间及版本号，见 表格 7.2\n\n\n\n表格 7.2: R 软件发版数据集（部分）\n\n\n\n\n版本号\n发版日期\n发版年份\n发版月份\n\n\n\n0.49\n1997-04-23\n1997\n04\n\n\n0.50-a1\n1997-07-22\n1997\n07\n\n\n0.50-a4\n1997-09-10\n1997\n09\n\n\n0.60.0\n1997-12-04\n1997\n12\n\n\n0.60.1\n1997-12-07\n1997\n12\n\n\n0.61.0\n1997-12-22\n1997\n12\n\n\n\n\n\n\n\n\n\nrversion_tl &lt;- within(rversion, {\n  # 版本号为 x.0.0 为重大版本 big\n  # 版本号为 x.1.0 x.12.0 x.20.0 为主要版本 major\n  # 版本号为 x.0.1 为次要版本 minor\n  status &lt;- ifelse(grepl(pattern = \"*\\\\.0\\\\.0\", x = version), \"big\", version)\n  status &lt;- ifelse(grepl(pattern = \"*\\\\.[1-9]{1,2}\\\\.0$\", x = status), \"major\", status)\n  status &lt;- ifelse(!status %in% c(\"big\", \"major\"), \"minor\", status)\n})\npositions &lt;- c(0.5, -0.5, 1.0, -1.0, 1.5, -1.5)\ndirections &lt;- c(1, -1)\n# 位置\nrversion_pos &lt;- data.frame(\n  # 只要不是同一天发布的版本，方向相对\n  date = unique(rversion_tl$date),\n  position = rep_len(positions, length.out = length(unique(rversion_tl$date))),\n  direction = rep_len(directions, length.out = length(unique(rversion_tl$date)))\n)\n# 原始数据上添加方向和位置信息\nrversion_df &lt;- merge(x = rversion_tl, y = rversion_pos, by = \"date\", all = TRUE)\n# 最重要的状态放在最后绘制到图上\nrversion_df &lt;- rversion_df[with(rversion_df, order(date, status)), ]\n\n选取一小段时间内的发版情况，比如最近的三年 — 2020 - 2022 年\n\n# 选取 2020 - 2022 年的数据\nsub_rversion_df&lt;- rversion_df[rversion_df$year %in% 2020:2022, ]\n# 月份注释\nmonth_dat &lt;- data.frame(\n  date = seq(from = as.Date('2020-01-01'), to = as.Date('2022-12-31'), by = \"3 month\")\n)\nmonth_dat &lt;- within(month_dat, {\n  month = format(date, \"%b\")\n})\n# 年份注释\nyear_dat &lt;- data.frame(\n  date = seq(from = as.Date('2020-01-01'), to = as.Date('2022-12-31'), by = \"1 year\")\n)\nyear_dat &lt;- within(year_dat, {\n  year = format(date, \"%Y\")\n})\n\n图 7.17 展示 2020-2022 年 R 软件发版情况\n\nggplot(data = sub_rversion_df) +\n  geom_segment(aes(x = date, y = 0, xend = date, yend = position)) +\n  geom_hline(yintercept = 0, color = \"black\", linewidth = 1) +\n  geom_label(\n    aes(x = date, y = position, label = version, color = status),\n    show.legend = FALSE\n  ) +\n  geom_point(aes(x = date, y = 0, color = status),\n    size = 3, show.legend = FALSE\n  ) +\n  geom_text(\n    data = month_dat, aes(x = date, y = 0, label = month), vjust = 1.5\n  ) +\n  geom_text(\n    data = year_dat, aes(x = date, y = 0, label = year), vjust = -0.5\n  ) +\n  theme_void()\n\n\n\n\n\n\n图 7.17: 2020-2022 年 R 软件发版情况\n\n\n\n\n图中红色标注的是里程碑式的重大版本，绿色标注的是主要版本，蓝色标注的次要版本，小修小补，小版本更新。\n当时间跨度非常大时，比如过去 25 年，那就只能放重大版本和主要版本信息了，时间上月份信息就不能用名称简写，而用数字更加合适。而且还得竖着放，同时添加那个版本最有影响力的改动。相比于，棋盘图，这是时间线图的优势。\n\nsub_rversion_df2 &lt;- rversion_df[rversion_df$status %in% c(\"big\", \"major\"), ]\nggplot(data = sub_rversion_df2) +\n  geom_segment(aes(x = 0, y = date, xend = position, yend = date, color = status),\n    show.legend = F\n  ) +\n  geom_vline(xintercept = 0, color = \"black\", linewidth = 1) +\n  geom_label(\n    aes(x = position, y = date, label = version, color = status),\n    show.legend = FALSE\n  ) +\n  geom_point(aes(x = 0, y = date, color = status), size = 3, show.legend = FALSE) +\n  geom_text(\n    aes(x = 0, y = as.Date(format(date, \"%Y-01-01\")), label = year),\n    hjust = -0.1\n  ) +\n  theme_void()\n\n\n\n\n\n\n图 7.18: 25 年里 R 软件重大及主要版本发布情况\n\n\n\n\n在 R 语言诞生的前 5 年里，每年发布 3 个主要版本，这 5 年是 R 软件活跃开发的时期。而 2003-2012 年的这 10 年，基本上每年发布 2 个主要版本。2013-2022 年的这 10 年，基本上每年发布 1 个主要版本。\ntimevis 包基于 JavaScript 库 Vis 的 vis-timeline 模块，可以 创建交互式的时间线图，支持与 Shiny 应用集成。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualize-data-comparisons",
    "href": "visualization-intermediate.html#sec-visualize-data-comparisons",
    "title": "7  基础图形",
    "section": "\n7.2 描述对比",
    "text": "7.2 描述对比\n数据来自中国国家统计局发布的2021年统计年鉴，\n\n\n\n表格 7.3: 中国各年龄段的性别比数据（部分）\n\n\n\n\n年龄\n人口数/男\n人口数/女\n性别比（女=100）\n区域\n\n\n\n0-4\n16078524\n14523013\n110.71\n城市\n\n\n5-9\n17172999\n15087731\n113.82\n城市\n\n\n10-14\n14619691\n12727731\n114.86\n城市\n\n\n15-19\n17249362\n15404683\n111.97\n城市\n\n\n20-24\n19776472\n18481665\n107.01\n城市\n\n\n25-29\n22937131\n21478748\n106.79\n城市\n\n\n\n\n\n\n\n\n对比的是什么？城市、镇和乡村的性别分布，是否失衡？在哪个年龄段表现很失衡？\n\n7.2.1 柱形图\n分年龄段比较城市、镇和乡村的性别比数据\n\nggplot(data = china_age_sex, aes(x = `年龄`, y = `性别比（女=100）`, fill = `区域`)) +\n  geom_hline(yintercept = 100, color = \"gray\", lty = 2, linewidth = 1) +\n  geom_col(position = \"dodge2\", width = 0.75) +\n  theme_bw()\n\n\n\n\n\n\n图 7.19: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n考虑到数据本身的含义，一般来说，性别比不可能从 0 开始，除非现实中出现了《西游记》里的女儿国。因此，将纵轴的范围，稍加限制，从 性别比为 70 开始，目的是突出城市、镇和乡村的差异。\n\nggplot(data = china_age_sex, aes(x = `年龄`, y = `性别比（女=100）`, fill = `区域`)) +\n  geom_hline(yintercept = 100, color = \"gray\", lty = 2, linewidth = 1) +\n  geom_col(position = \"dodge2\", width = 0.75) +\n  coord_cartesian(ylim = c(70, 130)) +\n  theme_bw()\n\n\n\n\n\n\n图 7.20: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n\n7.2.2 条形图\n将柱形图横过来即可得到条形图，横过来的好处主要体现在分类很多的时候，留足空间给年龄分组的分类标签，从左到右，从上往下也十分符合大众的阅读习惯\n\nggplot(data = china_age_sex, aes(x = `性别比（女=100）`, y = `年龄`, fill = `区域`)) +\n  geom_vline(xintercept = 100, color = \"gray\", lty = 2, linewidth = 1) +\n  geom_col(position = \"dodge2\", width = 0.75) +\n  coord_cartesian(xlim = c(70, 130)) +\n  theme_bw()\n\n\n\n\n\n\n图 7.21: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n\n7.2.3 点线图\n克利夫兰点图 dotchart() 在条形图的基础上，省略了条形图的宽度，可以容纳更多的数据点。\n\nggplot(data = china_age_sex, aes(x = `性别比（女=100）`, y = `年龄`, color = `区域`)) +\n  geom_vline(xintercept = 100, color = \"lightgray\", lty = 2, linewidth = 1) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n图 7.22: 分年龄段比较城市、镇和乡村的性别比数据\n\n\n\n\n\n7.2.4 词云图\nggwordcloud 包提供词云图层 geom_text_wordcloud() 根据代码提交的说明制作词云图。\n\nlibrary(ggwordcloud)\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  ggplot(aes(label = author, size = revision)) +\n  geom_text_wordcloud(seed = 2022, grid_size = 10, max_grid_size = 24) +\n  scale_size_area(max_size = 20)\n\n\n\n\n\n\n图 7.23: 词云图\n\n\n\n\n词云图也可以是条形图或柱形图的一种替代，词云图不用担心数目多少，而条形图不适合太多的分类情形。\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  subset(subset = revision &gt;= 100) |&gt; \n  ggplot(aes(x = revision, y = reorder(author, revision))) +\n  geom_col() +\n  theme_classic() +\n  coord_cartesian(expand = FALSE) +\n  labs(x = \"提交量\", y = \"维护者\")\n\n\n\n\n\n\n图 7.24: 开发者提交量排行榜",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualize-data-proportion",
    "href": "visualization-intermediate.html#sec-visualize-data-proportion",
    "title": "7  基础图形",
    "section": "\n7.3 描述占比",
    "text": "7.3 描述占比\n\n7.3.1 简单饼图\n提交量小于 2000 次的贡献者合并为一类 Others，按贡献者分组统计提交量及其占比，如 图 7.25 所示。\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  transform(author2 = ifelse(revision &lt; 2000, \"Others\", author)) |&gt;\n  aggregate(revision ~ author2, FUN = sum) |&gt;\n  transform(label = paste0(round(revision / sum(revision), digits = 4) * 100, \"%\")) |&gt;\n  ggplot(aes(x = 1, fill = reorder(author2, revision), y = revision)) +\n  geom_col(position = \"fill\", show.legend = FALSE, color = \"white\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  coord_polar(theta = \"y\") +\n  geom_text(aes(x = 1.2, label = author2),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  geom_text(aes(x = 1.65, label = label),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.25: 维护者提交量占比\n\n\n\n\n当把提交量小于 1000 次的贡献者合并为 Others，则分类较多，占比小的也有一席之地，饼图上显得十分拥挤。\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  transform(author2 = ifelse(revision &lt; 1000, \"Others\", author)) |&gt; \n  aggregate(revision ~ author2, FUN = sum) |&gt; \n  transform(label = paste0(round(revision / sum(revision), digits = 4) * 100, \"%\")) |&gt; \n  ggplot(aes(x = 1, fill = reorder(author2, revision)  , y = revision)) +\n  geom_col(position = \"fill\", show.legend = FALSE, color = \"white\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  coord_polar(theta = \"y\") +\n  geom_text(aes(x = 1.2, label = author2),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  geom_text(aes(x = 1.6, label = label),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.26: 维护者提交量占比\n\n\n\n\n一种缓解拥挤的办法是通过 ggrepel 包在扇形区域旁边添加注释\n\nlibrary(ggrepel)\ndat1 &lt;- aggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  transform(author2 = ifelse(revision &lt; 1000, \"Others\", author)) |&gt;\n  aggregate(revision ~ author2, FUN = sum)\n\ndat2 &lt;- within(dat1, {\n  value &lt;- 100 * revision / sum(revision)\n  csum &lt;- rev(cumsum(rev(value)))\n  pos &lt;- value / 1.5 + c(csum[-1], NA)\n  pos &lt;- ifelse(is.na(pos), value / 2, pos)\n  label &lt;- paste(author2, paste0(round(value, 2), \"%\"), sep = \"\\n\")\n})\n\nggplot(data = dat2, aes(x = 1, fill = author2, y = value)) +\n  geom_col(show.legend = FALSE, color = \"white\") +\n  coord_polar(theta = \"y\") +\n  geom_label_repel(aes(y = pos, label = label), \n    size = 4.5, nudge_x = 0.75, show.legend = FALSE\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.27: 维护者提交量占比\n\n\n\n\n但是数量很多的情况下，也是无能为力的，当然，是否需要显示那么多，是否可以合并占比小的部分，也是值得考虑的问题。\n\n\n\n表格 7.4: SVN 日志中的贡献者（部分）\n\n\n\n\nSVN 花名\n真实名字\n主要贡献\n\n\n\nrgentlem\nRobert Gentleman\nR 语言创始人\n\n\nihaka\nRoss Ihaka\nR 语言创始人\n\n\nripley\nBrian Ripley\nR Core Team 中的核心\n\n\nmurrell\nPaul Murrell\ngrid 包及栅格绘图系统\n\n\nmaechler\nMartin Maechler\ncluster / Matrix 包维护者\n\n\nhornik\nKurt Hornik\nR FAQ 和 CRAN 维护者\n\n\njmc\nJohn Chambers\nS 语言的创始人之一\n\n\nbates\nDouglas Bates\nnlme / lme4 包核心开发者\n\n\npd\nPeter Dalgaard\n《统计导论与 R 语言》作者\n\n\nligges\nUwe Ligges\n让 BUGS 与 R 同在\n\n\nplummer\nMartyn Plummer\n让 JAGS 与 R 携手\n\n\nluke\nLuke Tierney\ncompiler 包核心开发者\n\n\niacus\nStefano M. Iacus\n让 CRAN 拥抱 Fedora 系统\n\n\nkalibera\nTomas Kalibera\n编码问题终结者\n\n\ndeepayan\nDeepayan Sarkar\nlattice 包维护者\n\n\nmurdoch\nDuncan Murdoch\nR 软件的 Windows 版本维护者\n\n\nduncan\nDuncan Temple Lang\nXML / RCurl 包开发者\n\n\nurbaneks\nSimon Urbanek\nrJava / Rserve 包维护者\n\n\n\n\n\n\n\n\n\n7.3.2 环形饼图\n中间空了一块\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  transform(author2 = ifelse(revision &lt; 2000, \"Others\", author)) |&gt; \n  aggregate(revision ~ author2, FUN = sum) |&gt; \n  transform(label = paste0(round(revision / sum(revision), digits = 4) * 100, \"%\")) |&gt; \n  ggplot(aes(x = 1, fill = author2, y = revision)) +\n  geom_col(position = \"fill\", show.legend = FALSE, color = \"white\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  coord_polar(theta = \"y\") +\n  geom_text(aes(x = 1.2, label = author2),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  geom_text(aes(x = 1.7, label = label),\n    position = position_fill(vjust = 0.5), color = \"black\"\n  ) +\n  theme_void() +\n  labs(x = NULL, y = NULL) +\n  xlim(c(0.2, 1.7))\n\n\n\n\n\n\n图 7.28: 维护者提交量占比\n\n\n\n\n\n7.3.3 扇形饼图\n扇形饼图又叫风玫瑰图或南丁格尔图\n\naggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt; \n  transform(author2 = ifelse(revision &lt; 2000, \"Others\", author)) |&gt; \n  aggregate(revision ~ author2, FUN = sum) |&gt; \n  ggplot(aes(x = reorder(author2, revision), y = revision)) +\n  geom_col(aes(fill = author2), show.legend = FALSE) +\n  coord_polar() +\n  theme_minimal() +\n  theme(axis.text.y = element_blank()) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n图 7.29: 维护者提交量分布\n\n\n\n\n\n7.3.4 帕累托图\n\n除了饼图，还常用堆积柱形图描述各个部分的数量，柱形图的优势在于简洁，准确，兼顾对比和趋势。下 图 7.30 描述各年开发者们的贡献量及其变化趋势，饼图无法表达数量的变化趋势。\n\naggregate(data = svn_trunk_log, revision ~ year + author, FUN = length) |&gt; \n  ggplot(aes(x = year, y = revision, fill = author)) +\n  geom_col() +\n  theme_classic() +\n  coord_cartesian(expand = FALSE) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"年份\", y = \"提交量\", fill = \"开发者\")\n\n\n\n\n\n\n图 7.30: 代码提交量的比例趋势\n\n\n\n\n百分比堆积柱形图在数量堆积柱形图的基础上，将纵坐标的数量转化为百分比，下 图 7.31 展示各年开发者代码提交比例的变化趋势。\n\naggregate(data = svn_trunk_log, revision ~ year + author, FUN = length) |&gt; \n  ggplot(aes(x = year, y = revision, fill = author)) +\n  geom_col(position = \"fill\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  theme_classic() +\n  coord_cartesian(expand = FALSE) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"年份\", y = \"提交量\", fill = \"开发者\")\n\n\n\n\n\n\n图 7.31: 代码提交量的比例趋势\n\n\n\n\n帕累托图描述各个部分的占比，特别是突出关键要素的占比。收入常服从帕累托分布，这是一个幂率分布，比如 80% 的财富集中在 20% 的人的手中。下 图 7.32 展示过去 25 年各位开发者的代码累计提交量，提交量小于 1000 的已经合并为一类。不难看出，Ripley 的提交量远高于其他开发者。\n\ndat &lt;- aggregate(data = svn_trunk_log, revision ~ author, FUN = length) |&gt;\n  transform(author = ifelse(revision &lt; 1000, \"Others\", author)) |&gt;\n  aggregate(revision ~ author, FUN = sum)\ndat &lt;- dat[order(-dat$revision), ]\n\nggplot(data = dat, aes(x = reorder(author, revision, decreasing = T), y = revision)) +\n  geom_col(width = 0.75) +\n  geom_line(aes(y = cumsum(revision), group = 1)) +\n  geom_point(aes(y = cumsum(revision))) +\n  theme_classic() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  labs(x = \"维护者\", y = \"累计提交量\")\n\n\n\n\n\n\n图 7.32: 代码提交量的比例分布\n\n\n\n\n\n7.3.5 马赛克图\n马赛克图常用于展示多个分类数据，如 图 7.33 所示，展示加州伯克利分校院系录取情况。\n\nlibrary(ggmosaic)\nggplot(data = as.data.frame(UCBAdmissions)) +\n  geom_mosaic(aes(x = product(Dept, Gender), weight = Freq, fill = Admit)) +\n  theme_minimal()\n\n\n\n\n\n\n图 7.33: 加州伯克利分校院系录取情况\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\nBase R 提供函数 plot() 和 mosaicplot() 对 table 表格类型的数据可视化，提供一套公式绘图语法，可以绘制类似的马赛克图。\n\nmosaicplot(~ Gender + Dept + Admit,\n  data = UCBAdmissions, color = TRUE,\n  main = \"\", xlab = \"性别\", ylab = \"院系\"\n)\n\n对于多维列联表数据，Base R 提供函数 loglin() 拟合对数线性模型，以获取更加定量的结果。更进一步，MASS 包在函数 loglin() 的基础上，打包了另一个函数 loglm() ，它提供与函数 lm() 和 glm() 相一致的公式语法，使用起来更加方便。当然，函数 glm() 本身也是可以拟合对数线性模型的，毕竟它也是一种特殊的广义线性模型。\n\n\n\n7.3.6 矩阵树图\n矩阵树图展示有层次的占比，比如 G20 国家的 GDP 按半球、地域分组。treemapify 包专门绘制矩阵树图，下 图 7.34 展示南北半球，各地域内各个国家 GDP 的占比。\n\n\n\n表格 7.5: G20 国家经济水平：GDP 总量、人类发展指数等\n\n\n\n\n\n\n\n\n\n\n\n\n区域\n国家\nGDP\n人类发展指数\n经济水平\n所属半球\n\n\n\nAfrica\nSouth Africa\n384315\n0.629\nDeveloping\nSouthern\n\n\nNorth America\nUnited States\n15684750\n0.937\nAdvanced\nNorthern\n\n\nNorth America\nCanada\n1819081\n0.911\nAdvanced\nNorthern\n\n\nNorth America\nMexico\n1177116\n0.775\nDeveloping\nNorthern\n\n\nSouth America\nBrazil\n2395968\n0.730\nDeveloping\nSouthern\n\n\nSouth America\nArgentina\n474954\n0.811\nDeveloping\nSouthern\n\n\n\n\n\n\n\n\n每个瓦片的大小代表国家的 GDP 在所属半球里的比重。\n\nggplot(G20, aes(area = gdp_mil_usd, fill = region, label = country, subgroup = region)) +\n  geom_treemap() +\n  geom_treemap_text(grow = T, reflow = T, colour = \"black\") +\n  facet_wrap(~hemisphere) +\n  scale_fill_brewer(palette = \"Set1\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"G20 主要经济体\", fill = \"区域\")\n\n\n\n\n\n\n图 7.34: G20 主要经济体的 GDP 占比\n\n\n\n\n\n7.3.7 量表图\n展示调查研究中的用户态度。量表在市场调查，问卷调查，App 用户体验反馈等方面应用十分广泛，已经成为调查研究中的金标准。量表由心理学家 Rensis Likert 于 1932 年提出 (Likert 1932)，Likert Scale 就是以他的名字命名的。\n量表在互联网产品中应用非常广泛，比如美团App里消息页面中的反馈框，用以收集用户使用产品的体验情况，如 表格 7.6 所示，从极其困难到极其方便，将用户反馈分成7个等级，目的是收集用户的反馈，以期改善产品的体验。\n\n\n表格 7.6: 您觉得在本页面，找想看的消息方便吗？\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n极其困难\n非常困难\n比较困难\n一般\n比较方便\n非常方便\n极其方便\n\n\n\n\n\n量表中的问题、观点的描述极其简单明了，对回答、表明态度的任何人都不会造成歧义，以确保不受文化差异、学历差异等的影响，受调查的人只需在待选的几个选项中圈选即可。候选项一般为 5-7 个，下面是一组典型的选项：\n\nStrongly disagree （强烈反对），\nDisagree（反对），\nNeither agree nor disagree（中立），\nAgree（同意），\nStrongly agree（强烈同意）。\n\nJason M. Bryer 开发了一个 R 包 likert，特别适合调查研究数据可视化，将研究对象的态度以直观有效的方式展示出来，内置多个数据集，其中 表格 7.7 是一个数学焦虑量表调查的结果，调查数据来自统计课上的 20 个学生。\n调查对象是 78 个来自不同学科的本科生，样本含有 36 个男性和 42 个女性，64% 的样本的年龄在 18 至 24 岁，36% 的样本年龄 25 岁及以上。更多数据背景信息 (Bai 等 2009)。\n\n\n表格 7.7: 你对数学感到焦虑吗？\n\n\n\n\n\n\n\n\n\n\n\n观点\n强烈反对\n反对\n中立\n同意\n强烈同意\n\n\n\nI find math interesting.\n10\n15\n10\n35\n30\n\n\nI get uptight during math tests.\n10\n20\n20\n25\n25\n\n\nI think that I will use math in the future.\n0\n0\n20\n25\n55\n\n\nMind goes blank and I am unable to think clearly when doing my math test.\n30\n30\n15\n10\n15\n\n\nMath relates to my life.\n5\n20\n10\n40\n25\n\n\nI worry about my ability to solve math problems.\n20\n20\n20\n30\n10\n\n\nI get a sinking feeling when I try to do math problems.\n35\n10\n15\n35\n5\n\n\nI find math challenging.\n5\n10\n15\n45\n25\n\n\nMathematics makes me feel nervous.\n20\n25\n15\n25\n15\n\n\nI would like to take more math classes.\n20\n25\n30\n20\n5\n\n\nMathematics makes me feel uneasy.\n25\n15\n20\n25\n15\n\n\nMath is one of my favorite subjects.\n35\n15\n25\n20\n5\n\n\nI enjoy learning with mathematics.\n15\n25\n30\n20\n10\n\n\nMathematics makes me feel confused.\n15\n20\n15\n35\n15\n\n\n\n\n\n\n相比于 ggplot2 绘制的普通条形图， 图 7.35 有一些独特之处：对立型的渐变色表示两个不同方向的态度，左右两侧以中立态度为中间位置，非常形象，并且按照其中一个方向的态度数据排序，显得比较整齐有序，便于理解。\n\n# 数据来自 likert 包\nMathAnxiety &lt;- readRDS(file = \"data/MathAnxiety.rds\")\n# 宽转长格式\nMathAnxiety_df &lt;- reshape(data = MathAnxiety, \n  varying = c(\"Strongly Disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly Agree\"),\n  times = c(\"Strongly Disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly Agree\"),\n  timevar = \"Attitude\", v.names = \"Numbers\",  idvar = \"Item\", \n  new.row.names = 1:(5 * 14), direction = \"long\"\n )\n\nMathAnxiety_df$Attitude &lt;- factor(MathAnxiety_df$Attitude, levels = c(\n  \"Strongly Agree\", \"Agree\", \"Neutral\", \"Disagree\", \"Strongly Disagree\"\n), labels =  c(\n  \"强烈同意\", \"同意\", \"中立\", \"反对\", \"强烈反对\"\n), ordered = TRUE)\n\nggplot(data = MathAnxiety_df, aes(x = Numbers, y = Item)) +\n  geom_col(aes(fill = Attitude), position = \"fill\") +\n  scale_x_continuous(labels = scales::label_percent()) +\n  scale_y_discrete(labels = scales::label_wrap(25)) +\n  scale_fill_brewer(palette = \"BrBG\", direction = -1) +\n  theme_classic() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  coord_cartesian(expand = FALSE) +\n  labs(x = \"占比\", y = \"问题\", fill = \"态度\")\n\n\n\n\n\n\n图 7.35: 你喜欢数学吗\n\n\n\n\nlikert 包的函数 likert() 适合对聚合的调查数据绘图。\n\nlibrary(likert)\nlmath &lt;- likert(summary = MathAnxiety)\nplot(lmath)\n\n而 ggstats 包的函数 gglikert() 适合对明细的调查数据绘图。下面模拟一次调查收集到的数据，共计 150 人回答 6 个问题，每个问题都有 5 个候选项构成。\n\nlibrary(ggstats)\nlikert_levels &lt;- c(\"强烈反对\", \"反对\", \"中立\", \"同意\", \"强烈同意\")\nset.seed(2023)\nlibrary(data.table)\ndf &lt;- data.table(\n  q1 = sample(likert_levels, 150, replace = TRUE),\n  q2 = sample(likert_levels, 150, replace = TRUE, prob = 5:1),\n  q3 = sample(likert_levels, 150, replace = TRUE, prob = 1:5),\n  q4 = sample(likert_levels, 150, replace = TRUE, prob = 1:5),\n  q5 = sample(c(likert_levels, NA), 150, replace = TRUE),\n  q6 = sample(likert_levels, 150, replace = TRUE, prob = c(1, 0, 1, 1, 0))\n)\nfkt &lt;- paste0(\"q\", 1:6)\ndf[, (fkt) := lapply(.SD, factor, levels = likert_levels), .SDcols = fkt]\n\n一个调查问卷共有 6 个题目，150 个人对 6 个问题的回答构成一个数据框 df 。\n\ngglikert(df)\n\n\n\n\n\n\n图 7.36: Likert 图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-intermediate.html#sec-visualization-intermediate-exercise",
    "href": "visualization-intermediate.html#sec-visualization-intermediate-exercise",
    "title": "7  基础图形",
    "section": "\n7.4 习题",
    "text": "7.4 习题\n\n\n根据 Github 代码提交量数据制作日历图。\n\ngithub_ctb &lt;- jsonlite::read_json(path = \"data/contributions.json\")\ngithub_df &lt;- data.frame(\n  date = unlist(lapply(github_ctb$contributions, \"[[\", \"date\")),\n  count = unlist(lapply(github_ctb$contributions, \"[[\", \"count\")),\n  color = unlist(lapply(github_ctb$contributions, \"[[\", \"color\")),\n  intensity = unlist(lapply(github_ctb$contributions, \"[[\", \"intensity\"))\n)\nweek.abb &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\ngithub_df &lt;- within(github_df, {\n  date &lt;- as.Date(date)\n  year &lt;- format(date, format = \"%Y\", tz = \"UTC\")\n  month &lt;- format(date, format = \"%m\", tz = \"UTC\")\n  week &lt;- format(date, format = \"%U\", tz = \"UTC\")\n  wday &lt;- format(date, format = \"%a\", tz = \"UTC\")\n  nday &lt;- format(date, format = \"%j\", tz = \"UTC\")\n  week &lt;- as.integer(week)\n  wday &lt;- factor(wday, labels = week.abb)\n})\nggplot(\n  data = subset(github_df, subset = year %in% 2020:2022),\n  aes(x = week, y = wday, fill = count)\n) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  scale_fill_distiller(palette = \"Greens\", direction = 1) +\n  scale_x_continuous(\n    expand = c(0, 0), breaks = seq(1, 52, length = 12), labels = month.abb\n  ) +\n  facet_wrap(~year, ncol = 1) +\n  theme_minimal() +\n  labs(x = \"月份\", y = \"星期\", fill = \"提交量\")\n\n\n\n\n\n\n图 7.37: Github 打卡日历图\n\n\n\n\n\n\n\n\n\n\nBai, H., L. Wang, W. Pan, 和 M. Frey. 2009. 《Measuring mathematics anxiety: Psychometric analysis of a bidimensional affective scale》. Journal of Instructional Psychology 36 (3): 185–93.\n\n\nKothari, Aditya. 2022. ggTimeSeries: Time Series Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggTimeSeries.\n\n\nLikert, Rensis. 1932. 《A Technique for the Measurement of Attitudes》. Archives of Psychology 142 (1): 1–55.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant Graphics for Data Analysis. 2nd 本. Springer-Verlag New York. https://ggplot2.tidyverse.org.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>基础图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html",
    "href": "visualization-advanced.html",
    "title": "8  统计图形",
    "section": "",
    "text": "8.1 描述分布\n数据来自中国国家统计局发布的2021年统计年鉴，各省、直辖市和自治区分区域的性别比数据（部分）情况见 表格 8.1 。\n表格 8.1: 各省、直辖市和自治区分区域的性别比数据（部分）\n\n\n\n\n地区\n人口数/男\n人口数/女\n性别比（女=100）\n区域\n\n\n\n北京\n8937161\n8814520\n101.39\n城市\n\n\n天津\n5610161\n5322931\n105.40\n城市\n\n\n河北\n11010407\n11119188\n99.02\n城市\n\n\n山西\n6588788\n6608849\n99.70\n城市\n\n\n内蒙古\n4714495\n4731924\n99.63\n城市\n\n\n辽宁\n12626419\n12946058\n97.53\n城市",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html#sec-visualize-data-distribution",
    "href": "visualization-advanced.html#sec-visualize-data-distribution",
    "title": "8  统计图形",
    "section": "",
    "text": "8.1.1 箱线图\nlibrary(ggplot2)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_boxplot() +\n  theme_classic()\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_boxplot(outlier.colour = \"red\") +\n  theme_classic()\nlibrary(lvplot)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_lv() +\n  theme_classic()\nboxplot(`性别比（女=100）` ~ `区域` , data = province_sex_ratio)\n\n\n\n\n\n\n\n\n\n(a) ggplot2 包\n\n\n\n\n\n\n\n\n\n(b) ggplot2 包（高亮离群值）\n\n\n\n\n\n\n\n\n\n\n\n(c) lvplot 包\n\n\n\n\n\n\n\n\n\n(d) Base R 包\n\n\n\n\n\n\n图 8.1: 箱线图的几种绘制形式\n\n\n箱线图的历史有 50 多年了，它的变体也有很多，除了 ggplot2 包，lvplot 包也可以绘制箱线图的变体 (McGill 和 Larsen 1978)。更多详情见 Hadley Wickham 和 Lisa Stryjewski 的文章 40 years of boxplots。\n\n8.1.2 提琴图\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin(fill = \"lightgray\") +\n  theme_classic()\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin(fill = \"lightgray\", draw_quantiles = c(0.25, 0.5, 0.75)) +\n  theme_classic()\nvioplot::vioplot(`性别比（女=100）` ~ `区域`,\n  data = province_sex_ratio, col = \"lightgray\")\nbeanplot::beanplot(`性别比（女=100）` ~ `区域`,\n  data = province_sex_ratio, col = \"lightgray\", log = \"\",\n  xlab = \"区域\", ylab = \"性别比（女=100）\")\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_violin()\n\n\n\n\n\n\n\n\n\n(b) 函数 geom_violin() 标记分位点\n\n\n\n\n\n\n\n\n\n\n\n(c) vioplot 包\n\n\n\n\n\n\n\n\n\n(d) beanplot 包\n\n\n\n\n\n\n图 8.2: 提琴图\n\n\nbeanplot 包的名字是根据图形的外观取的，bean 即是豌豆，rug 用须线表示数据。\n\n8.1.3 直方图\nggplot2 包绘制直方图的函数是 geom_histogram() ，而与之相关的函数 geom_freqpoly() 是绘制折线图，将直方图中每个柱子的顶点连接起来。\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, fill = `区域`)) +\n  geom_histogram(binwidth = 5, color = \"white\", position = \"stack\") +\n  scale_fill_grey() +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8)) +\n  labs(y = \"频数\")\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, color = `区域`)) +\n  geom_freqpoly(binwidth = 5, stat = \"bin\", position = \"stack\") +\n  scale_color_grey() +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8))\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_histogram()\n\n\n\n\n\n\n\n\n\n(b) 函数 geom_freqpoly()\n\n\n\n\n\n\n图 8.3: 直方图\n\n\n\n8.1.4 密度图\nggplot2 包绘制密度图的函数是 geom_density()， 图 8.4 展示分组密度曲线图\n\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`)) +\n  geom_density(aes(fill = `区域`), alpha = 0.75) +\n  scale_fill_grey() +\n  theme_classic()\n\n\n\n\n\n\n图 8.4: 密度图\n\n\n\n\n\n8.1.4.1 堆积（条件）密度图\n\n\n\n\n\n\n注意\n\n\n\nStacked density plots: if you want to create a stacked density plot, you probably want to ‘count’ (density * n) variable instead of the default density\n\n\n堆积密度图正确的绘制方式是保护边际密度。\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, y = after_stat(density))) +\n  geom_density(aes(fill = `区域`), position = \"stack\", alpha = 0.5) +\n  scale_fill_grey() +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8))\nggplot(data = province_sex_ratio, aes(x = `性别比（女=100）`, y = after_stat(density * n))) +\n  geom_density(aes(fill = `区域`), position = \"stack\", alpha = 0.5) +\n  scale_fill_grey() +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8))\n\n\n\n\n\n\n\n\n\n(a) 堆积密度图 after_stat(density)\n\n\n\n\n\n\n\n\n\n(b) 堆积密度图 after_stat(density * n)\n\n\n\n\n\n\n图 8.5: 累积分布密度图\n\n\n什么原因导致 图 8.5 中两个子图看起来没什么差别呢？而换一组数据，就可以看出明显的差别。\nggplot(diamonds, aes(x = carat, y = after_stat(density), fill = cut)) +\n  geom_density(position = \"stack\") +\n  scale_fill_grey() +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.8, 0.7)) +\n  labs(x = \"克拉\", y = \"频数\", fill = \"切工\")\nggplot(diamonds, aes(x = carat, y = after_stat(density * n), fill = cut)) +\n  geom_density(position = \"stack\") +\n  scale_fill_grey() +\n  scale_y_continuous(\n    breaks = c(25000, 50000, 75000), \n    labels = c(\"25K\", \"50K\", \"75K\")) +\n  theme_classic() +\n  theme(legend.position = \"inside\", legend.position.inside = c(0.8, 0.7)) +\n  labs(x = \"克拉\", y = \"频数\", fill = \"切工\")\n\n\n\n\n\n\n\n\n\n(a) 函数 after_stat(density)\n\n\n\n\n\n\n\n\n\n(b) 函数 after_stat(density * n)\n\n\n\n\n\n\n图 8.6: 堆积密度图\n\n\n\n8.1.4.2 联合密度图\n\nstate_x77 &lt;- data.frame(state.x77, state_name = rownames(state.x77),\n  state_region = state.region, check.names = FALSE)\np1 &lt;- ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point() +\n  geom_density_2d(\n    aes(color = after_stat(level), alpha = after_stat(level)), show.legend = F\n  ) +\n  scale_color_distiller(palette = \"Greys\") +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  ) +\n  theme_classic()\np1\n\n\n\n\n\n\n图 8.7: 二维联合密度图\n\n\n\n\n\n8.1.4.3 边际密度图\nggExtra 包(Attali 和 Baker 2022) 添加边际密度曲线和边际直方图。\n\nlibrary(ggExtra)\nggMarginal(p1, type = \"density\")\nggMarginal(p1, type = \"histogram\")\n\n\n\n\n\n\n图 8.8: 描述边际分布\n\n\n\n\n\n8.1.4.4 填充密度图\nggplot2 包提供二维密度图层 geom_density_2d_filled() 绘制热力图， ggdist (Kay 2022) 进行了一些扩展。\n\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_density_2d_filled(contour_var = \"count\") +\n  theme_classic() +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  )\n\n\n\n\n\n\n图 8.9: ggplot2 包绘制二维填充密度图\n\n\n\n\n相比于 ggplot2 内置的二维核密度估计，ggdensity (Otto 和 Kahle 2023) 有一些优势，根据数据密度将目标区域划分，更加突出层次和边界。gghdr 包与 ggdensity 类似，展示 highest density regions (HDR)\n\nlibrary(ggdensity)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_hdr() +\n  geom_point() +\n  theme_classic() +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  )\n\n\n\n\n\n\n图 8.10: ggdensity 包绘制二维填充密度图\n\n\n\n\n\n8.1.5 岭线图\n叠嶂图，还有些其它名字，如峰峦图、岭线图等，详情参考统计之都主站《叠嶂图的前世今生》，主要用来描述数据的分布情况，在展示分布的对比上效果非常好。\n图 8.11 设置窗宽为 1.5 个百分点\n\n\n\n\n\n\n\n\n\n(a) 岭线图\n\n\n\n\n\n\n\n\n\n(b) 岭线图和抖动图组合\n\n\n\n\n\n\n\n\n\n\n\n(c) 岭线图和轴须图组合\n\n\n\n\n\n\n图 8.11: 描述数据分布\n\n\n\n\n\n\n\n\n提示\n\n\n\n除了中国国家统计年鉴，各省、自治区、直辖市及各级统计局每年都会发布一些统计年鉴、公告等数据，读者可以在此基础上继续收集更多数据，来分析诸多有意思的问题：\n\n城市、镇和乡村男女性别比呈现差异化分布的成因。\n城市、镇和乡村男女年龄构成。\n将上述问题从省级下钻到市、县级来分析。\n\n\n\n\n8.1.6 抖动图\n下面先用函数 geom_point() 绘制散点图展示原始数据，通过点的疏密程度暗示数据的分布。Base R 函数 stripchart() 可以实现类似的效果。当数据量比较大时，点相互覆盖比较严重，此时，抖动图比较适合用来展示原始数据。函数 geom_beeswarm() 提供了另一种散点的组织方式，按一定的规则，而不是近似随机的方式组织。\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_point() +\n  theme_classic()\nstripchart(\n  `性别比（女=100）` ~ `区域`, vertical = TRUE, pch = 1,\n  data = province_sex_ratio, xlab = \"区域\")\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_jitter(width = 0.25) +\n  theme_classic()\nlibrary(ggbeeswarm)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_beeswarm() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) 函数 geom_point()\n\n\n\n\n\n\n\n\n\n(b) 函数 stripchart()\n\n\n\n\n\n\n\n\n\n\n\n(c) 函数 geom_jitter()\n\n\n\n\n\n\n\n\n\n(d) 函数 geom_beeswarm()\n\n\n\n\n\n\n图 8.12: 散点图\n\n\nSidiropoulos 等 (2018) 提出一种新的方式描述数据的分布，集合抖动图和小提琴图的功能，在给定的分布界限内抖动。数据点受 violin 的曲线限制，蜂群图也是某种形式的抖动图，添加 violin 作为参考边界，与 sina 图是非常类似的。\nlibrary(ggforce)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_sina() +\n  theme_classic()\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin() +\n  geom_sina() +\n  theme_classic()\nlibrary(ggbeeswarm)\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_quasirandom() +\n  theme_classic()\nggplot(data = province_sex_ratio, aes(x = `区域`, y = `性别比（女=100）`)) +\n  geom_violin() +\n  geom_quasirandom() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) ggforce 包的函数 geom_sina()\n\n\n\n\n\n\n\n\n\n(b) 函数 geom_sina() 叠加函数 geom_violin()\n\n\n\n\n\n\n\n\n\n\n\n(c) ggbeeswarm 包的函数 geom_quasirandom()\n\n\n\n\n\n\n\n\n\n(d) 函数 geom_quasirandom() 叠加函数 geom_violin()\n\n\n\n\n\n\n图 8.13: 加强版的抖动图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html#sec-visualize-data-relation",
    "href": "visualization-advanced.html#sec-visualize-data-relation",
    "title": "8  统计图形",
    "section": "\n8.2 描述关系",
    "text": "8.2 描述关系\n\n8.2.1 散点图\n散点图用以描述变量之间的关系，展示原始的数据，点的形态、大小、颜色等都可以随更多变量变化。\n中国国家统计局 2021 年发布的统计年鉴，2020 年 31 个省、直辖市、自治区的抚养比、文盲率、人口数的关系。\n\n\n\n表格 8.2: 2020 年各省、直辖市、自治区，总抚养比和文盲率相关数据（部分）\n\n\n\n\n地区\n人口数\n15-64岁\n抚养比\n15岁及以上人口\n文盲人口\n文盲率\n\n\n\n广东\n126012510\n91449628\n37.79\n102262628\n1826344\n1.79\n\n\n山东\n101527453\n67100737\n51.31\n62464815\n3308280\n4.01\n\n\n河南\n99365519\n62974661\n57.79\n76376565\n2228594\n2.92\n\n\n江苏\n84748016\n58129537\n45.79\n71856068\n2211291\n3.08\n\n\n四川\n83674866\n56036154\n49.32\n70203754\n3330733\n4.74\n\n\n河北\n74610235\n49133330\n51.85\n59521267\n1128423\n1.90\n\n\n\n\n\n\n\n\n其中，文盲人口是指15岁及以上不识字及识字很少人口，文盲率 = 文盲人口 / 15岁及以上人口，抚养比 = (0-14岁 + 65岁及以上) / 15-64岁人口数。\n\nlibrary(ggplot2)\nggplot(data = china_raise_illiteracy) +\n  geom_point(aes(x = `总抚养比`, y = `文盲人口占15岁及以上人口的比重`)) +\n  theme_classic() +\n  labs(x = \"抚养比（%）\", y = \"文盲率（%）\")\n\n\n\n\n\n\n图 8.14: 文盲率与抚养比的关系\n\n\n\n\n\n8.2.2 气泡图\n气泡图在散点图的基础上，添加了散点大小的视觉维度，可以在图上多展示一列数据，下 图 8.15 新增了人口数变量。此外，在气泡旁边添加地区名称，将气泡填充的颜色也映射给了人口数变量。\n\nlibrary(ggrepel)\nlibrary(scales)\nggplot(\n  data = china_raise_illiteracy,\n  aes(x = `总抚养比`, y = `文盲人口占15岁及以上人口的比重`)\n) +\n  geom_point(aes(size = `人口数`, color = `人口数`),\n    alpha = 0.85, pch = 16,\n    show.legend = c(color = FALSE, size = TRUE)\n  ) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  scale_color_viridis_c(option = \"C\") +\n  geom_text_repel(\n    aes(label = `地区`), size = 3, max.overlaps = 50,\n    segment.colour = \"gray\", seed = 2022, show.legend = FALSE\n  ) +\n  coord_cartesian(xlim = c(30, 60), ylim = c(0, 10.5), expand = FALSE) +\n  theme_classic() +\n  labs(x = \"抚养比（%）\", y = \"文盲率（%）\")\n\n\n\n\n\n\n图 8.15: 文盲率和抚养比数据\n\n\n\n\n\n8.2.3 凹凸图\n凹凸图描述位置排序关系随时间的变化，比如前年、去年和今年各省的 GDP 排序变化，春节各旅游景点的人流量变化。ggbump 包专门用来绘制凹凸图，如 图 8.16 所示，展示\n\nlibrary(ggbump)\n# 位置排序变化\ndf &lt;- data.frame(\n  country = c(\n    \"印度\", \"印度\", \"印度\", \"瑞典\",\n    \"瑞典\", \"瑞典\", \"德国\", \"德国\",\n    \"德国\", \"芬兰\", \"芬兰\", \"芬兰\"\n  ),\n  year = c(\n    2018, 2019, 2020, 2018, 2019, 2020,\n    2018, 2019, 2020, 2018, 2019, 2020\n  ),\n  value = c(\n    492, 246, 246, 369, 123, 492,\n    246, 369, 123, 123, 492, 369\n  )\n)\n\nlibrary(data.table)\ndf &lt;- as.data.table(df)\ndf[, rank := rank(value, ties.method = \"random\"), by = \"year\"]\n\nggplot(df, aes(year, rank, color = country)) +\n  geom_point(size = 7) +\n  geom_text(data = df[df$year == min(df$year), ],\n            aes(x = year - .1, label = country), size = 5, hjust = 1) +\n  geom_text(data = df[df$year == max(df$year), ],\n            aes(x = year + .1, label = country), size = 5, hjust = 0) +\n  geom_bump(linewidth = 2, smooth = 8) +\n  scale_x_continuous(limits = c(2017.6, 2020.4), breaks = seq(2018, 2020, 1)) +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\", panel.grid.major = element_blank()) +\n  labs(x = NULL, y = \"排名\") +\n  scale_y_reverse() +\n  coord_fixed(ratio = 0.5)\n\n\n\n\n\n\n图 8.16: 凹凸图\n\n\n\n\n\n8.2.4 韦恩图\n韦恩图描述集合、群体的交叉关系，整体和部分的包含关系，ggVennDiagram 包展示 A、B、C 三个集合的交叉关系，如 图 8.17 所示\n\nx &lt;- list(A = 1:5, B = 2:7, C = 5:10)\nggVennDiagram::ggVennDiagram(x) +\n  scale_fill_gradient(low = \"#F4FAFE\", high = \"#4981BF\")\n\n\n\n\n\n\n图 8.17: A、B、C 三个集合的交叉关系\n\n\n\n\n\n8.2.5 网络图\ntidygraph 包基于 igraph 包操作图数据，计算网络图中节点重要性，ggraph包基于 ggplot2 包可视化网络关系。\n\nlibrary(ggraph)\ndata(\"highschool\")\nstr(highschool)\n\n#&gt; 'data.frame':    506 obs. of  3 variables:\n#&gt;  $ from: num  1 1 1 1 1 2 2 3 3 4 ...\n#&gt;  $ to  : num  14 15 21 54 55 21 22 9 15 5 ...\n#&gt;  $ year: num  1957 1957 1957 1957 1957 ...\n\n\nhighschool 是一个数据框类型的数据，记录了1957 年和 1958 年一些高中男生之间的关系，在数据集中，这些男生被编码成数字 1-71。\n\nhighschool[highschool$from == 1, ]\n\n#&gt;     from to year\n#&gt; 1      1 14 1957\n#&gt; 2      1 15 1957\n#&gt; 3      1 21 1957\n#&gt; 4      1 54 1957\n#&gt; 5      1 55 1957\n#&gt; 244    1 15 1958\n#&gt; 245    1 21 1958\n#&gt; 246    1 22 1958\n\n\n1 号男生在 1957 年与 14、15、21、54、55 男生关系密切，到了 1958 年，他与 15、21、22 关系比较密切。tidygraph 包在 igraph 的基础上，可以对图数据进行操作，下面先将数据框转化为图，然后计算中心度，作为高中生的受欢迎程度。\n\ngraph &lt;- tidygraph::as_tbl_graph(highschool, directed = TRUE) |&gt; \n  dplyr::mutate(Popularity = tidygraph::centrality_degree(mode = 'in'))\ngraph\n\n#&gt; # A tbl_graph: 70 nodes and 506 edges\n#&gt; #\n#&gt; # A directed multigraph with 1 component\n#&gt; #\n#&gt; # Node Data: 70 × 1 (active)\n#&gt;    Popularity\n#&gt;         &lt;dbl&gt;\n#&gt;  1          2\n#&gt;  2          0\n#&gt;  3          0\n#&gt;  4          4\n#&gt;  5          5\n#&gt;  6          2\n#&gt;  7          2\n#&gt;  8          3\n#&gt;  9          4\n#&gt; 10          4\n#&gt; # ℹ 60 more rows\n#&gt; #\n#&gt; # Edge Data: 506 × 3\n#&gt;    from    to  year\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     1    13  1957\n#&gt; 2     1    14  1957\n#&gt; 3     1    20  1957\n#&gt; # ℹ 503 more rows\n\n\n\nggraph(graph, layout = \"kk\") +\n  geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) +\n  geom_node_point(aes(size = Popularity)) +\n  facet_edges(~year) +\n  theme_graph(base_family = \"sans\", foreground = \"steelblue\", fg_text_colour = \"white\")\n\n\n\n\n\n\n图 8.18: 高中男生间关系的变化",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-advanced.html#sec-visualize-data-uncertainty",
    "href": "visualization-advanced.html#sec-visualize-data-uncertainty",
    "title": "8  统计图形",
    "section": "\n8.3 描述不确定性",
    "text": "8.3 描述不确定性\n统计是一门研究不确定性的学科，由不确定性引出许多的基本概念，比如用置信区间描述点估计的不确定性，用覆盖概率描述区间估计方法的优劣。下面以二项分布参数的点估计与区间估计为例，通过可视化图形介绍这一系列统计概念。就点估计来说，描述不确定性可以用标准差、置信区间。\nggdist 包可视化分布和不确定性 (Kay 2022)\n\nMichael Friendly 2021 年的课程 Psychology of Data Visualization\n\nClaus O. Wilke 2023 年的课程 SDS 375 Schedule Spring 2023\n\n\n\n8.3.1 置信区间\n\n\n表格 8.3: 二项分布的分布列\n\n\n\n0\n1\n2\n\\(\\cdots\\)\nn\n\n\n\\(p_0\\)\n\\(p_1\\)\n\\(p_2\\)\n\\(\\cdots\\)\n\\(p_n\\)\n\n\n\n\n\n二项分布 \\(\\mathrm{Binomial}(n,p)\\) 的参数 \\(p\\) 的精确区间估计如下：\n\\[\n\\big(\\mathrm{Beta}(\\frac{\\alpha}{2}; x, n-x+1), \\mathrm{Beta}(1-\\frac{\\alpha}{2}; x+1, n-x)\\big)\n\\tag{8.1}\\]\n其中， \\(x\\) 表示成功次数，\\(n\\) 表示实验次数，\\(\\mathrm{Beta}(p;v,w)\\) 表示形状参数为 \\(v\\) 和 \\(w\\) 的 Beta 贝塔分布的 \\(p\\) 分位数，参数 \\(p\\) 的置信区间的上下限 \\(P_L,P_U\\) 满足\n\\[\n\\begin{aligned}\n\\frac{\\Gamma(n+1)}{\\Gamma(x)\\Gamma(n-x+1)}\\int_{0}^{P_L}t^{x-1}(1-t)^{n-x}\\mathrm{dt} &= \\frac{\\alpha}{2} \\\\\n\\frac{\\Gamma(n+1)}{\\Gamma(x+1)\\Gamma(n-x)}\\int_{0}^{P_U}t^{x}(1-t)^{n-x-1}\\mathrm{dt} &= 1-\\frac{\\alpha}{2}\n\\end{aligned}\n\\]\n\\(p_x\\) 表示二项分布 \\(\\mathrm{Binomial}(n,p)\\) 第 \\(x\\) 项的概率，\\(x\\) 的取值为 \\(0,1,\\cdots,n\\)\n\\[p_x = \\binom{n}{x}p^x(1-p)^{n-x}, \\quad x = 0,1,\\cdots,n\\]\n二项分布的累积分布函数和 \\(S_k\\) 表示前 \\(k\\) 项概率之和\n\\[S_k = \\sum_{x=0}^{k} p_x\\]\n\\(S_k\\) 服从形状参数为 \\(n-k,k+1\\) 的贝塔分布 \\(I_x(a,b)\\)，对应于 R 函数 pbeta(x,a,b)。 \\(S_k\\) 看作贝塔分布的随机变量 \\(X\\)\n\\[\n\\begin{aligned}\nB_x(a,b) &=\\int_{0}^{x}t^{a-1}(1-t)^{b-1}\\mathrm{dt} \\\\\nI_x(a,b) &= \\frac{B_x(a,b)}{B(a,b)}, \\quad B(a,b) = B_1(a,b)\n\\end{aligned}\n\\]\n考虑二项总体的参数 \\(p=0.7\\)，重复模拟 50 次，每次模拟获得的比例 \\(\\hat{p}\\) 及其置信区间，区间估计方法来自 (Clopper 和 Pearson 1934) ，函数 binom.test() 也是采用此方法，二者计算结果相同。如 图 8.19 所示，置信区间覆盖真值的情况用不同颜色表示，覆盖用灰色表示，没有覆盖用黑色表示。\n\nclopper_pearson &lt;- function(p = 0.1, n = 10, nsim = 100) {\n  set.seed(2022)\n  nd &lt;- rbinom(nsim, prob = p, size = n)\n  ll &lt;- qbeta(p = 0.05 / 2, shape1 = nd, shape2 = n - nd + 1)\n  ul &lt;- qbeta(p = 1 - 0.05 / 2, shape1 = nd + 1, shape2 = n - nd)\n  data.frame(nd = nd, ll = ll, ul = ul, cover = ul &gt; p & ll &lt; p)\n}\n# 二项分布的参数 p = 0.7\ndat &lt;- clopper_pearson(p = 0.7, n = 10, nsim = 50)\n# 二项分布的参数的置信区间覆盖真值的情况\nggplot(data = dat, aes(x = 1:50, y = nd / 10, colour = cover)) +\n  geom_hline(yintercept = 0.7, lty = 2, linewidth = 1.2, color = \"gray\") +\n  geom_pointrange(aes(ymin = ll, ymax = ul)) +\n  scale_color_grey(labels = c(`TRUE` = \"是\", `FALSE` = \"否\")) +\n  theme_classic() +\n  labs(x = \"n\", y = \"p\", color = \"覆盖\")\n\n\n\n\n\n\n图 8.19: Clopper-Pearson 置信区间\n\n\n\n\n图中，横坐标表示模拟次数 \\(n\\) ，纵坐标表示对应的成功概率 \\(p\\) ，线段端点表示置信区间上下限。\n\n8.3.2 假设检验\n假设检验的目的是做决策，决策是有风险的，是可能发生错误的，为了控制犯第一类错误的可能性，我们用 P 值描述检验统计假设的不确定性，用功效描述检验方法的优劣。对同一个统计假设，同一组数据，不同的检验方法有不同的 P 值，本质是检验方法的功效不同。\nggpval 在图上添加检验的 P 值结果，ggsignif (Constantin 和 Patil 2021) 在图上添加显著性注释。ggstatsplot (Patil 2021) 可视化统计检验、模型的结果，描述功效变化。ggpubr 制作出版级统计图形，两样本均值的比较。\n\nwith(\n  aggregate(\n    data = PlantGrowth, weight ~ group,\n    FUN = function(x) c(dist_mean = mean(x), dist_sd = sd(x))\n  ),\n  cbind.data.frame(weight, group)\n) |&gt;\n  ggplot(aes(x = group, y = dist_mean)) +\n  geom_col(\n    position = position_dodge(0.4), width = 0.4, fill = \"gray\"\n  ) +\n  geom_errorbar(aes(ymin = dist_mean - dist_sd, ymax = dist_mean + dist_sd),\n    position = position_dodge(0.4), width = 0.2) +\n  theme_classic() +\n  labs(x = \"组别\", y = \"植物干重\")\n\n\n\n\n\n\n图 8.20: 植物生长\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\nR 3.5.0 以后，函数 aggregate() 的参数 drop 默认值为 TRUE， 表示扔掉未用来分组的变量，聚合返回的是一个矩阵类型的数据对象。\n\n\n单因素方差分析 oneway.test() 检验各组的方差是否相等。\n\noneway.test(data = PlantGrowth, weight ~ group)\n\n#&gt; \n#&gt;  One-way analysis of means (not assuming equal variances)\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 5.181, num df = 2.000, denom df = 17.128, p-value = 0.01739\n\n\n结果显示方差不全部相等，因此，采用函数 t.test(var.equal = FALSE) 来检验数据。图 8.21 展示假设检验的结果，分别标记了 ctrl 与 trt1、trt1 与 trt2 两组 t 检验的结果。\n\nlibrary(ggsignif)\nggplot(data = PlantGrowth, aes(x = group, y = weight)) +\n  geom_boxplot(width = 0.25) +\n  geom_jitter(width = 0.15) +\n  geom_signif(comparisons = list(c(\"ctrl\", \"trt1\"), c(\"trt1\", \"trt2\")), \n              map_signif_level = function(p) sprintf(\"p = %.2g\", p), \n              textsize = 6, test = \"t.test\") +\n  theme_classic() +\n  coord_cartesian(clip = \"off\")\n\n\n\n\n\n\n图 8.21: 展示假设检验的结果\n\n\n\n\n为了了解其中的原理，下面分别使用函数 t.test() 检验数据，结果给出的 P 值与上 图 8.21 完全一样。\n\nt.test(data = PlantGrowth, weight ~ group, subset = group %in% c(\"ctrl\", \"trt1\"))\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  weight by group\n#&gt; t = 1.1913, df = 16.524, p-value = 0.2504\n#&gt; alternative hypothesis: true difference in means between group ctrl and group trt1 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.2875162  1.0295162\n#&gt; sample estimates:\n#&gt; mean in group ctrl mean in group trt1 \n#&gt;              5.032              4.661\n\nt.test(data = PlantGrowth, weight ~ group, subset = group %in% c(\"trt1\", \"trt2\"))\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  weight by group\n#&gt; t = -3.0101, df = 14.104, p-value = 0.009298\n#&gt; alternative hypothesis: true difference in means between group trt1 and group trt2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -1.4809144 -0.2490856\n#&gt; sample estimates:\n#&gt; mean in group trt1 mean in group trt2 \n#&gt;              4.661              5.526\n\n\n\n8.3.3 模型预测\n描述模型预测的不确定性，预测的方差、预测区间。线性回归来说，回归线及置信带。代码提交量的趋势拟合\n\nsvn_trunk_log &lt;- readRDS(file = \"data/svn-trunk-log-2022.rds\")\nsvn_trunk_log$year &lt;- as.integer(format(svn_trunk_log$stamp, \"%Y\"))\ntrunk_year &lt;- aggregate(data = svn_trunk_log, revision ~ year, FUN = length)\nggplot(data = trunk_year[trunk_year$year != 1997,], aes(x = year, y = revision)) +\n  geom_point() +\n  geom_smooth(aes(color = \"LOESS\", fill = \"LOESS\"),\n    method = \"loess\", formula = \"y~x\",\n    method.args = list(\n      span = 0.75, degree = 2, family = \"symmetric\",\n      control = loess.control(surface = \"direct\", iterations = 4)\n    )) +\n  geom_smooth(aes(color = \"GAM\", fill = \"GAM\"),\n    formula = y ~ s(x, k = 12), method = \"gam\", se = TRUE) +\n  geom_smooth(aes(color = \"Cubic Spline\", fill = \"Cubic Spline\"),\n                method = \"lm\", formula = y ~ splines::bs(x, 3), se = T) +\n  scale_color_brewer(name = \"模型\", palette = \"Set1\") +\n  scale_fill_brewer(name = \"模型\", palette = \"Set1\") +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"gray90\")) +\n  labs(x = \"年份\", y = \"提交量\")\n\n\n\n\n\n\n图 8.22: 趋势拟合、预测和推断\n\n\n\n\n\n8.3.4 模型诊断\n\n所有模型都是错误的，但有些是有用的。\n— 乔治·博克斯\n\n描述模型的敏感性，数据中存在的离群值，变量之间的多重共线性等。引入 Cook 距离、杠杆值、VIF 等来诊断模型。\n\n# 准备数据\nstate_x77 &lt;- data.frame(state.x77,\n  state_name = rownames(state.x77), state_region = state.region,\n  state_abb = state.abb, check.names = FALSE\n)\n# 线性模型拟合\nfit &lt;- lm(`Life Exp` ~ Income + Murder, data = state_x77)\n# 模型诊断图\nlibrary(ggfortify)\nautoplot(fit, which = 1:6, label.size = 3)\n\n\n\n\n\n\n图 8.23: 线性模型的诊断图\n\n\n\n\n对于复杂的统计模型，比如混合效应模型的诊断，ggPMX 包。\n\n8.3.5 边际效应\n继续 state_x77 数据集，以预期寿命（1969-1971 年统计）为因变量，Income 人均收入（1974 年）和 Murder 谋杀和非过失杀人率（单位：十万分之一，1976 年统计）为自变量，建立线性模型如下：\n\\[\n\\text{Life Exp} = \\alpha + \\beta_1  \\text{Income} + \\beta_2 \\text{Murder} + \\epsilon\n\\tag{8.2}\\]\n在 R 语言中，可以用函数 lm() 拟合上述模型，\n\nfit &lt;- lm(`Life Exp` ~ Income + Murder, data = state_x77)\n\n模型拟合结果输出如下：\n\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = `Life Exp` ~ Income + Murder, data = state_x77)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.48301 -0.62099 -0.01714  0.47768  2.20831 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 71.2255815  0.9673952  73.626  &lt; 2e-16 ***\n#&gt; Income       0.0003705  0.0001973   1.878   0.0666 .  \n#&gt; Murder      -0.2697594  0.0328408  -8.214 1.22e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.8259 on 47 degrees of freedom\n#&gt; Multiple R-squared:  0.637,  Adjusted R-squared:  0.6215 \n#&gt; F-statistic: 41.23 on 2 and 47 DF,  p-value: 4.561e-11\n\n\nggeffects 描述单个自变量的作用，人均收入对预期寿命的边际效应\n\nlibrary(ggeffects)\nincome_pred &lt;- ggpredict(fit, terms = \"Income\")\nggplot(income_pred, aes(x, predicted)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.1) +\n  theme_classic() +\n  labs(x = \"人均收入\", y = \"预期寿命\")\n\n\n\n\n\n\n图 8.24: 边际效应\n\n\n\n\n\n\n\n\nAttali, Dean, 和 Christopher Baker. 2022. ggExtra: Add Marginal Histograms to ggplot2, and More ggplot2 Enhancements. https://CRAN.R-project.org/package=ggExtra.\n\n\nClopper, C. J., 和 E. S. Pearson. 1934. 《The Use of Confidence or Fiducial Limits Illustrated In The Case of The Binomial》. Biometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nConstantin, Ahlmann-Eltze, 和 Indrajeet Patil. 2021. 《ggsignif: R Package for Displaying Significance Brackets for ggplot2》. PsyArxiv. https://doi.org/10.31234/osf.io/7awm6.\n\n\nKay, Matthew. 2022. ggdist: Visualizations of Distributions and Uncertainty. https://doi.org/10.5281/zenodo.3879620.\n\n\nMcGill, Tukey, R., 和 W. A. Larsen. 1978. 《Variations of box plots》. The American Statistician 32 (1): 12–16. https://www.jstor.org/stable/2683468.\n\n\nOtto, James, 和 David Kahle. 2023. 《ggdensity: Improved Bivariate Density Visualization in R》. The R Journal 15: 220–36. https://doi.org/10.32614/RJ-2023-048.\n\n\nPatil, Indrajeet. 2021. 《Visualizations with statistical details: The ggstatsplot approach》. Journal of Open Source Software 6 (61): 3167. https://doi.org/10.21105/joss.03167.\n\n\nSidiropoulos, Nikos, Sina Hadi Sohi, Thomas Lin Pedersen, Bo Torben Porse, Ole Winther, Nicolas Rapin, 和 Frederik Otzen Bagger. 2018. 《SinaPlot: An Enhanced Chart for Simple and Truthful Representation of Single Observations Over Multiple Classes》. Journal of Computational and Graphical Statistics 27 (3): 673–76. https://doi.org/10.1080/10618600.2017.1366914.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>统计图形</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html",
    "href": "visualization-lattice.html",
    "title": "9  lattice 入门",
    "section": "",
    "text": "9.1 分组散点图\n函数 xyplot() 在 lattice 包中非常具有代表性，掌握此函数的作图规律，其它函数学起来也就不难了。分组散点图是一个非常常见的、用来描述变量之间关系的图形，下面就以绘制一个分组散点图来介绍函数 xyplot() 的用法。\nlibrary(lattice)\nxyplot(\n  x = Sepal.Length ~ Petal.Length, groups = Species, scales = \"free\",\n  data = iris, grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\",\n  auto.key = list(space = \"top\", columns = 3)\n)\n\n\n\n\n\n\n图 9.1: 分组散点图\n除了通过 space 参数设置图例的位置，还可以通过坐标设置图例的位置，比如下 图 9.2 (b) 中设置图例的位置坐标为 x = 1, y = 0 使得图例位于图的右下角。图例坐标的参考点是原点 x = 0, y = 0 就是左下角的位置，而右上角的位置为 x = 1, y = 1 。\n除了上面介绍的几个参数，还有许多其它参数，其中一部分会在后续介绍其它种类的图形时顺带介绍，剩余的部分请感兴趣的读者查看函数 xyplot() 的帮助文档。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-lattice-xyplot",
    "href": "visualization-lattice.html#sec-lattice-xyplot",
    "title": "9  lattice 入门",
    "section": "",
    "text": "参数 x 需要传递 R 语言中的表达式，这是一种被广泛使用的公式语法，示例中为 Sepal.Length ~ Petal.Length ，表示横坐标为 Petal.Length， 纵坐标为 Sepal.Length 。\n参数 groups 指定分组变量，此处为 Species 变量，表示鸢尾花种类。\n参数 scales 设置坐标轴刻度， scales = \"free\" 表示去掉边框上面和右面的刻度线。\n参数 data 指定绘图数据，此处为 iris 数据集。\n参数 grid 控制是否添加背景网格线，此处为 TRUE 表示添加背景网格线。\n参数 xlab 和参数 ylab 分别指定横、纵坐标轴标签。\n参数 auto.key 设置图例，示例中设置 space = \"top\" 将图例置于图形上方，设置 columns = 3 使条目排成 3 列，此外，设置 reverse.rows = TRUE 还可以使图例中的条目顺序反向。\n\n\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(space = \"right\", columns = 1)\n)\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(corner = c(1, 0))\n)\n\n\n\n\n\n\n\n\n\n(a) 图例位于图右侧\n\n\n\n\n\n\n\n\n\n\n\n(b) 图例位于内内部\n\n\n\n\n\n\n图 9.2: 调整图例位置",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-lattice-par",
    "href": "visualization-lattice.html#sec-lattice-par",
    "title": "9  lattice 入门",
    "section": "\n9.2 图形参数",
    "text": "9.2 图形参数\n类似 Base R 绘图系统中的图形参数设置函数 par()和 ggplot2 包中的主题设置函数 theme()， lattice 包也有图形参数设置函数 trellis.par.set() ，而图形参数查询函数为 trellis.par.get() 。可设置的图形参数非常多，仅常用的也不少。首先来看看有哪些图形参数可以设置。\n\ntp &lt;- trellis.par.get()\nnames(tp)\n\n#&gt;  [1] \"grid.pars\"         \"fontsize\"          \"background\"       \n#&gt;  [4] \"panel.background\"  \"clip\"              \"add.line\"         \n#&gt;  [7] \"add.text\"          \"plot.polygon\"      \"box.dot\"          \n#&gt; [10] \"box.rectangle\"     \"box.umbrella\"      \"dot.line\"         \n#&gt; [13] \"dot.symbol\"        \"plot.line\"         \"plot.symbol\"      \n#&gt; [16] \"reference.line\"    \"strip.background\"  \"strip.shingle\"    \n#&gt; [19] \"strip.border\"      \"superpose.line\"    \"superpose.symbol\" \n#&gt; [22] \"superpose.polygon\" \"regions\"           \"shade.colors\"     \n#&gt; [25] \"axis.line\"         \"axis.text\"         \"axis.components\"  \n#&gt; [28] \"layout.heights\"    \"layout.widths\"     \"box.3d\"           \n#&gt; [31] \"par.title.text\"    \"par.xlab.text\"     \"par.ylab.text\"    \n#&gt; [34] \"par.zlab.text\"     \"par.main.text\"     \"par.sub.text\"\n\n\n可以看到，图形参数着实非常多，知道了这么多图形参数，而每个参数又有哪些选项可取呢？不忙，再看看图形参数的结构，比如 superpose.symbol 。\n\ntp$superpose.symbol\n\n#&gt; $alpha\n#&gt; [1] 1 1 1 1 1 1 1\n#&gt; \n#&gt; $cex\n#&gt; [1] 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n#&gt; \n#&gt; $col\n#&gt;          blue        orange   bluishgreen    vermillion       skyblue \n#&gt;     \"#0072B2\"     \"#E69F00\"     \"#009E73\"     \"#D55E00\"     \"#56B4E9\" \n#&gt;        yellow reddishpurple \n#&gt;     \"#F0E442\"     \"#CC79A7\" \n#&gt; \n#&gt; $fill\n#&gt; [1] \"#CCFFFF\" \"#FFCCFF\" \"#CCFFCC\" \"#FFE5CC\" \"#CCE6FF\" \"#FFFFCC\" \"#FFCCCC\"\n#&gt; \n#&gt; $font\n#&gt; [1] 1 1 1 1 1 1 1\n#&gt; \n#&gt; $pch\n#&gt; [1] 1 1 1 1 1 1 1\n\n\n这是一个列表，有 6 个元素，每个元素设置符号的不同属性，依次是透明度 alpha、大小 cex、颜色 col、填充色 fill、字型 font 和类型 pch ，这些属性的含义与函数 par() 是一致的。下 图 9.3 展示所有的常用图形参数及其可设置的选项。\n\n\n\n\n\n\n\n图 9.3: 常用图形参数\n\n\n\n\n现在，知道了图形设置参数及其结构，还需要知道它们究竟在绘图时起什么作用，也就是说它们控制图形中的哪部分元素及效果。下 图 9.4 展示 lattice 包图形参数效果。由图可知，图形参数 superpose.symbol 是控制散点图中的点，点可以是普通的点，也可以是任意的字母符号。\n\n\n\n\n\n\n\n图 9.4: 图形参数效果预览\n\n\n\n\n在之前的 图 9.1 的基础上，设置 type = c(\"p\", \"r\") 添加回归线。通过图形参数 par.settings 设置各类绘图元素的符号类型和大小，该参数接受一个列表类型的数据，列表的元素还是列表，列表的层层嵌套实现图中元素的精细控制。列表元素 superpose.symbol 控制点的符号，pch = 16 设置为 16，相比于默认的点要大一号。列表元素 superpose.line 控制线，lwd = 2 设置宽度为 2，比默认的宽度大一倍，lty = 3 设置线的类型为 3，表示虚线。通过参数 auto.key 设置图例位置，图例位于图形上方，图例中的条目排成3列。\n\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, type = c(\"p\", \"r\"),\n  xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(columns = 3, space = \"top\"), \n  par.settings = list(\n    superpose.symbol = list(pch = 16),\n    superpose.line = list(lwd = 2, lty = 3)\n  )\n)\n\n\n\n\n\n\n图 9.5: 调整点、线、图例元素\n\n\n\n\nlatticeExtra 包有两个函数专门用来设置图形风格，分别是 theEconomist.theme() 和 ggplot2like() ，这两个主题函数提供一系列预设的图形参数，前者来自《经济学人》杂志的图形主题，后者来自 ggplot2 包的默认绘图主题。\nlibrary(latticeExtra)\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(space = \"top\", columns = 3), \n  par.settings = ggplot2like()\n)\nxyplot(\n  Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", grid = TRUE, xlab = \"萼片长度\", ylab = \"花瓣长度\", \n  auto.key = list(space = \"top\", columns = 3), \n  par.settings = theEconomist.theme(with.bg = TRUE, box = \"transparent\")\n)\n\n\n\n\n\n\n\n\n\n(a) ggplot2 包默认的绘图主题\n\n\n\n\n\n\n\n\n\n\n\n(b) 《经济学人》杂志的绘图主题\n\n\n\n\n\n\n图 9.6: latticeExtra 内置的两个主题",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-common-lattice",
    "href": "visualization-lattice.html#sec-common-lattice",
    "title": "9  lattice 入门",
    "section": "\n9.3 常见图形",
    "text": "9.3 常见图形\n\n9.3.1 分组柱形图\n本节所用数据集 Insurance 来自 MASS 包，记录一家保险公司面临风险的投保人数量，以及在 1973 年第 3 季度他们提出汽车理赔的数量。数据类型、各个变量的类型及部分预览数据如下：\n\ndata(Insurance, package = \"MASS\")\nstr(Insurance)\n\n#&gt; 'data.frame':    64 obs. of  5 variables:\n#&gt;  $ District: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ Group   : Ord.factor w/ 4 levels \"&lt;1l\"&lt;\"1-1.5l\"&lt;..: 1 1 1 1 2 2 2 2 3 3 ...\n#&gt;  $ Age     : Ord.factor w/ 4 levels \"&lt;25\"&lt;\"25-29\"&lt;..: 1 2 3 4 1 2 3 4 1 2 ...\n#&gt;  $ Holders : int  197 264 246 1680 284 536 696 3582 133 286 ...\n#&gt;  $ Claims  : int  38 35 20 156 63 84 89 400 19 52 ...\n\n\n其中，District 表示投保人居住的地区，因子型变量。Group 汽车按油箱大小分组的变量，有序的因子型变量。Age 投保人的年龄段标签，有序的因子型变量。Holders 投保人数量，整型变量。Claims 理赔数量，整型变量。下 图 9.7 先按投保人的汽车类型分面，再按投保人所在地区分组，展示理赔频度与投保人年龄的关系。\n\nbarchart(\n  Claims / Holders ~ Age | Group, groups = District,\n  data = Insurance, xlab = \"年龄段\", ylab = \"理赔频度\",\n  auto.key = list(space = \"top\", columns = 4, title = \"地区\", cex.title = 1)\n)\n\n\n\n\n\n\n图 9.7: 分组柱形图\n\n\n\n\n函数 barchart() 中的公式 Claims / Holders ~ Age | Group ，斜杠 / 表示除法，波浪线 ~ 表示响应变量与自变量的分界，竖线 | 表示分面。\n\n9.3.2 分组箱线图\n\nbwplot(Petal.Length ~ Species, data = iris, scales = \"free\",\n  xlab = \"鸢尾花种类\", ylab = \"花瓣长度\")\n\n\n\n\n\n\n图 9.8: 分组箱线图\n\n\n\n\n\n9.3.3 经验分布图\n用阶梯图表示累积经验分布图，纵轴表示累积概率，不同种类的鸢尾花，花瓣长度的分布明显不同。根据 Glivenko–Cantelli 定理，经验分布函数以概率 1 收敛至累积分布函数。\n\nlibrary(latticeExtra)\necdfplot(~ Petal.Length | Species, data = iris, scales = \"free\", \n         xlab = \"花瓣长度\", ylab = \"累积概率\")\n\n\n\n\n\n\n图 9.9: 经验分布图\n\n\n\n\n\n9.3.4 回归曲线图\n\n\nsplines 自然立方样条 ns()\n\n\nmgcv 广义可加模型 s()\n\n\n\n\n\n\n\n\n\n图 9.10: 调色板\n\n\n\n\n图 9.11 中用不同的回归模型拟合数据中的趋势。1920s 汽车行驶距离和速度的关系图。函数 panel.smoother() 来自 latticeExtra 包\nlibrary(splines)\nlibrary(nlme)\nlibrary(mgcv)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ x,\n      col.line = \"#EA4335\", method = \"lm\", ...\n    )\n  }\n)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ x,\n      col.line = \"#4285f4\", method = \"loess\", span = 0.9, ...\n    )\n  }\n)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ ns(x, 5),\n      col.line = \"#34A853\", method = \"lm\", ...\n    )\n  }\n)\nxyplot(dist ~ speed,\n  data = cars, scales = \"free\", xlab = \"速度\", ylab = \"距离\",\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.smoother(y ~ s(x),\n      col.line = \"#FBBC05\", method = \"gam\", ...\n    )\n  }\n)\n\n\n\n\n\n\n\n\n\n(a) 线性回归\n\n\n\n\n\n\n\n\n\n(b) 局部多项式回归\n\n\n\n\n\n\n\n\n\n\n\n(c) 自然样条回归\n\n\n\n\n\n\n\n\n\n(d) 广义可加回归\n\n\n\n\n\n\n图 9.11: 回归曲线图\n\n\n\n9.3.5 置信区间图\n各个郡县每 10 万人当中因癌症死亡的人数。USCancerRates 数据集来自 latticeExtra 包，记录各个郡县的癌症死亡率及其置信区间，下图展示新泽西州各个郡县的癌症死亡率及其置信区间。\n\nsegplot(reorder(county, rate.male) ~ LCL95.male + UCL95.male,\n  data = subset(USCancerRates, state == \"New Jersey\"),\n  draw.bands = FALSE, centers = rate.male,\n  scales = list(x = list(alternating = 1, tck = c(1, 0))),\n  xlab = \"癌症死亡率\", ylab = \"郡县\"\n)\n\n\n\n\n\n\n图 9.12: 置信区间图\n\n\n\n\n\n9.3.6 置信椭圆图\nlatticeExtra 包的函数 panel.ellipse() 可以绘制置信椭圆。二维数据，置信水平为 0.95 时，置信椭圆。\n\nxyplot(Sepal.Length ~ Petal.Length,\n  groups = Species, data = iris, scales = \"free\",\n  xlab = \"萼片长度\", ylab = \"花瓣长度\",\n  par.settings = list(\n    superpose.symbol = list(pch = 16),\n    superpose.line = list(lwd = 2, lty = 3)\n  ),\n  panel = function(x, y, ...) {\n    panel.xyplot(x, y, ...)\n    panel.ellipse(x, y, level = 0.85, ...)\n  },\n  auto.key = list(space = \"top\", columns = 3)\n)\n\n\n\n\n\n\n图 9.13: 分组置信椭圆图\n\n\n\n\n\n9.3.7 切片水平图\n按照深度降序排列，根据震级 mag 划分 4 个区间，每个区间内数据点的数量比较平衡，相邻区间之间有重叠部分。对数据进行切片，观察连续的切片数据，增加一个维度。\n对震深排序的目的是让数据点按照一定的顺序绘制在图上，数据点相距较近容易互相覆盖。使得在二维平面上，通过对数据点的染色，也能体现地震深度在空间中的层次变化。\n不同的震级下，地震深度在空间中的变化是一致的。\n\n# 震级区间\nquakes$Magnitude &lt;- equal.count(quakes$mag, number = 4)\n# 震深\ndepth.ord &lt;- rev(order(quakes$depth))\nquakes.ordered &lt;- quakes[depth.ord, ]\n\nIntervals:\n   min  max count\n1 3.95 4.55   484\n2 4.25 4.75   492\n3 4.45 4.95   425\n4 4.65 6.45   415\n\nOverlap between adjacent intervals:\n[1] 293 306 217\n函数 equal.count() 内部调用函数 co.intervals() ，还有两个参数 number 和 overlap。如果要没有重叠的话，得设置 overlap = 0 。\n\nquakes$Magnitude &lt;- equal.count(quakes$mag, number = 4, overlap = 0)\n\n\nlevelplot(depth ~ long + lat | Magnitude,\n  data = quakes.ordered, scales = \"free\",\n  panel = panel.levelplot.points, \n  prepanel = prepanel.default.xyplot, \n  type = c(\"p\", \"g\"), layout = c(2, 2)\n)\n\n\n\n\n\n\n图 9.14: 分面水平图\n\n\n\n\n\n9.3.8 三维散点图\nlattice 包的函数 cloud() 三维散点图\n\ncloud(Sepal.Length ~ Sepal.Width + Petal.Length,\n  groups = Species, data = iris,\n  # 去掉方向箭头\n  scales = list(arrows = FALSE, col = \"black\"),\n  xlab = list(\"萼片宽度\", rot = 30),\n  ylab = list(\"花瓣长度\", rot = -35),\n  zlab = list(\"萼片长度\", rot = 90),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(\n    # 点的类型\n    superpose.symbol = list(pch = 16),\n    # 去掉外框线\n    axis.line = list(col = \"transparent\")\n  )\n)\n\n\n\n\n\n\n图 9.15: 三维散点图\n\n\n\n\n下面是一个示例，自定义面板函数 panel.3d.cloud 。\n\n\n\n\n\n\n注释\n\n\n\n图底部的网格待改进，生成网格线的代码太死板。\n\n\n\n# 加载数据\nrongelap &lt;- readRDS(file = \"data/rongelap.rds\")\nrongelap_coastline &lt;- readRDS(file = \"data/rongelap_coastline.rds\")\n\nlibrary(lattice)\n# 参考 lattice 书籍的图 6.5 的绘图代码\npanel.3dcoastline &lt;- function(..., rot.mat, distance, xlim, ylim, zlim,\n                              xlim.scaled, ylim.scaled, zlim.scaled) {\n  scale.vals &lt;- function(x, original, scaled) {\n    scaled[1] + (x - original[1]) * diff(scaled) / diff(original)\n  }\n  scaled.map &lt;- rbind(\n    scale.vals(rongelap_coastline$cX, xlim, xlim.scaled),\n    scale.vals(rongelap_coastline$cY, ylim, ylim.scaled),\n    zlim.scaled[1]\n  )\n  m &lt;- ltransform3dto3d(scaled.map, rot.mat, distance)\n  panel.lines(m[1, ], m[2, ], col = \"black\")\n}\n\nrongelap_grid_line &lt;- rbind.data.frame(\n  data.frame(x = 1000 * -6:0, y = -3500),\n  data.frame(x = 1000 * 0:-6, y = -3000),\n  data.frame(x = 1000 * -6:0, y = -2500),\n  data.frame(x = 1000 * 0:-6, y = -2000),\n  data.frame(x = 1000 * -6:0, y = -1500),\n  data.frame(x = 1000 * 0:-6, y = -1000),\n  data.frame(x = 1000 * -6:0, y = -500),\n  data.frame(x = 1000 * 0:-6, y = 0),\n  data.frame(x = -6000, y = -500 * 7:0),\n  data.frame(x = -5000, y = -500 * 0:7),\n  data.frame(x = -4000, y = -500 * 7:0),\n  data.frame(x = -3000, y = -500 * 0:7),\n  data.frame(x = -2000, y = -500 * 7:0),\n  data.frame(x = -1000, y = -500 * 0:7),\n  data.frame(x = 0, y = -500 * 7:0)\n)\n\npanel.3dgridline &lt;- function(..., rot.mat, distance, xlim, ylim, zlim,\n                              xlim.scaled, ylim.scaled, zlim.scaled) {\n  scale.vals &lt;- function(x, original, scaled) {\n    scaled[1] + (x - original[1]) * diff(scaled) / diff(original)\n  }\n  scaled.map &lt;- rbind(\n    scale.vals(rongelap_grid_line$x, xlim, xlim.scaled),\n    scale.vals(rongelap_grid_line$y, ylim, ylim.scaled),\n    zlim.scaled[1]\n  )\n  m &lt;- ltransform3dto3d(scaled.map, rot.mat, distance)\n  panel.lines(x = m[1,], y = m[2,], col = \"gray\", lty = 2)\n}\n\ncloud(counts / time ~ cX * cY,\n  data = rongelap, col = \"black\",\n  xlim = c(-6500, 100), ylim = c(-3800, 150),\n  scales = list(arrows = FALSE, col = \"black\"),\n  aspect = c(0.75, 0.5),\n  xlab = list(\"横坐标（米）\", rot = 20),\n  ylab = list(\"纵坐标（米）\", rot = -50),\n  zlab = list(\"辐射强度\", rot = 90),\n  type = c(\"p\", \"h\"), pch = 16, lwd = 0.5,\n  panel.3d.cloud = function(...) {\n    panel.3dgridline(...)\n    panel.3dcoastline(...) # 海岸线\n    panel.3dscatter(...)\n  },\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(\n    # 移除几条内框线\n    # box.3d = list(col = c(1, 1, NA, NA, 1, NA, 1, 1, 1)),\n    # 刻度标签字体大小\n    axis.text = list(cex = 0.8),\n    # 去掉外框线\n    axis.line = list(col = \"transparent\")\n  ),\n  # 设置三维图的观察方位\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 9.16: 添加三维网格参考线和透视曲线\n\n\n\n\n\n9.3.9 三维透视图\n有如下参数方程\n\\[\n\\begin{aligned}\n\\left\\{\n\\begin{array}{l}\nx(u,v) = \\cos(u)\\big(r + \\cos(u / 2)\\big) \\\\\ny(u,v) = \\sin(u)\\big(r + \\cos(u / 2)\\sin(tv) - \\sin(u / 2)\\sin(2tv)\\big)\\sin(tv) -\n    \\sin(u / 2)\\sin(2tv) \\\\\nz(u,v) = \\sin(u / 2) \\sin(tv) + \\cos(u / 2) \\sin(tv)\n\\end{array} \\right.\n\\end{aligned}\n\\]\n其中，\\(u\\) 和 \\(v\\) 是参数，\\(\\frac{u}{2\\pi} \\in [0.3,1.25], \\frac{v}{2\\pi} \\in [0,1]\\)，\\(r\\) 和 \\(t\\) 是常量，不妨设 \\(r = 2\\) 和 \\(t=1\\) 。\n\n# lattice 书 6.3.1 节 参数\nkx &lt;- function(u, v) cos(u) * (r + cos(u / 2))\nky &lt;- function(u, v) {\n  sin(u) * (r + cos(u / 2) * sin(t * v) -\n    sin(u / 2) * sin(2 * t * v)) * sin(t * v) -\n    sin(u / 2) * sin(2 * t * v)\n}\nkz &lt;- function(u, v) sin(u / 2) * sin(t * v) + cos(u / 2) * sin(t * v)\nn &lt;- 50\nu &lt;- seq(0.3, 1.25, length = n) * 2 * pi\nv &lt;- seq(0, 1, length = n) * 2 * pi\num &lt;- matrix(u, length(u), length(u))\nvm &lt;- matrix(v, length(v), length(v), byrow = TRUE)\nr &lt;- 2\nt &lt;- 1\n\nwireframe(kz(um, vm) ~ kx(um, vm) + ky(um, vm),\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90), alpha = 0.75,\n  scales = list(arrows = FALSE, col = \"black\"),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 9.17: 三维透视图\n\n\n\n\n绘图函数 wireframe() 支持使用公式语法，也支持矩阵类型的数据绘制透视图。\n\nwireframe(volcano,\n  drape = TRUE, colorkey = FALSE, shade = TRUE,\n  xlab = list(\"南北方向\", rot = -40),\n  ylab = list(\"东西方向\", rot = 45),\n  zlab = list(\"高度\", rot = 90),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -.6, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.8, units = \"inches\"),\n      top.padding = list(x = -1.0, units = \"inches\")\n    )\n  ),\n  # 设置坐标轴字体大小\n  par.settings = list(\n    axis.line = list(col = \"transparent\"),\n    fontsize = list(text = 12, points = 10)\n  ),\n  scales = list(arrows = FALSE, col = \"black\"), \n  screen = list(z = -45, x = -50, y = 0)\n)\n\n\n\n\n\n\n图 9.18: 奥克兰火山地形图\n\n\n\n\n\n9.3.10 地形轮廓图\n绘图函数 levelplot() 支持使用公式语法，也支持矩阵类型的数据绘制轮廓图。基于奥克兰火山地形数据 volcano 绘制轮廓图，volcano 是矩阵类型的数据。\n\nlevelplot(volcano, useRaster = TRUE,\n  # 去掉图形上、右边多余的刻度线\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ),\n  par.settings = list(\n    # x/y 轴标签字体，刻度标签字体\n    par.xlab.text = list(fontfamily = \"Noto Serif CJK SC\"),\n    par.ylab.text = list(fontfamily = \"Noto Serif CJK SC\"),\n    axis.text = list(fontfamily = \"sans\")\n  ),\n  xlab = \"南北方向\", ylab = \"东西方向\"\n)\n\n\n\n\n\n\n图 9.19: 奥克兰火山的地形轮廓图\n\n\n\n\n函数 levelplot() 的参数 col.regions 需要传递一个函数，示例中使用的默认设置。常见的函数有 hcl.colors() 、 gray.colors() 、terrain.colors() 、cm.colors() 和 topo.colors() 等，函数 hcl.colors() 默认使用 viridis 调色板，还可以用函数 colorRampPalette() 构造调色板函数。\n\ndata(topo, package = \"MASS\")\nlevelplot(z ~ x * y, data = topo, scales = \"free\",\n  panel = panel.2dsmoother, contour = TRUE,\n  form = z ~ s(x, y, bs = \"gp\", k = 50), method = \"gam\",\n  xlab = \"水平方向\", ylab = \"垂直方向\"\n)\n\n\n\n\n\n\n图 9.20: 奥克兰火山的地形轮廓图\n\n\n\n\n函数 panel.2dsmoother() 来自 latticeExtra 包，数据的二维分布，默认采用 tp\n\n\ntp thin plate regression spline 回归样条方法平滑。\n\ncr Cubic regression spline 立方回归样条。\n\ngp Gaussian process smooths 高斯过程平滑，默认为全秩 Full Rank，指定 k 低秩近似 Low Rank。\n\n9.3.11 地区分布图\n最后一个想要介绍的是地区分布图，也叫面量图、围栏图，描述空间栅格数据的分布，常见的一种情况是展示各个地区的人口、社会、经济指标。下面通过 tigris 包可以下载美国人口调查局发布的数据，本想下载与观测数据年份最近的地图数据，但是 2009 年及以前的地图数据缺失，因此，笔者下载了 2010 年的地图数据，它与得票率数据最近。\n\nlibrary(tigris)\nus_state_map &lt;- states(cb = TRUE, year = 2010, resolution = \"20m\", class = \"sf\")\nus_state_map &lt;- shift_geometry(us_state_map, geoid_column = \"STATE\", position = \"below\")\n\n第一行代码用 tigris 包的函数 states() 下载 2010 年比例尺为 1:20000000 的多边形州边界矢量地图数据，返回一个 simple feature 类型的空间数据类型。第二行代码用该包的另一个函数 shift_geometry() 移动离岸的州和领地，将它们移动到主体部分的下方。\n\nlibrary(sf)\nus_state_sf &lt;- readRDS(\"data/us-state-map-2010.rds\")\n# sf 转 sp\nus_state_sp &lt;- as(us_state_sf, \"Spatial\")\nlibrary(maps)\n# sp 转 map\nus_state_map &lt;- SpatialPolygons2map(us_state_sp, namefield = \"NAME\")\n# 准备观测数据\ndata(votes.repub)\n# 转为 data.frame 类型\nvotes_repub &lt;- as.data.frame(votes.repub)\n\n数据集 votes.repub 记录 1856-1976 年美国历届大选中共和党在各州的得票率。图中以由红到蓝的颜色变化表示由低到高的得票率，1964 年共和党在东南一隅得票率较高，在其它地方得票率普遍较低，形成一边倒的情况，最终由民主党的林登·约翰逊当选美国第36任总统。1968 年共和党在东南部得票率最低，与 1964 年相比，整个反过来了，最终由共和党的理查德·尼克松当选美国第37任总统。\n\nlibrary(RColorBrewer)\nrdbu_pal &lt;- colorRampPalette(colors = brewer.pal(n = 11, name = \"RdBu\"))\nmapplot(rownames(votes_repub) ~ `1964` + `1968`, data = votes_repub,\n  border = NA, map = us_state_map, colramp = rdbu_pal, layout = c(1, 2),\n  scales = list(draw = FALSE), xlab = \"\", ylab = \"\"\n)\n\n\n\n\n\n\n图 9.21: 共和党在各州的得票率\n\n\n\n\n参数 border 设置州边界线的颜色，NA 表示去掉边界线。参数 map 设置州边界地图数据。参数 colramp 设置一个调色板，用于将得票率与调色板上的颜色映射起来。美国历届大选，共和党和民主党竞争总统职位，最终由得票率决定，用红蓝对抗型调色板表现竞争关系。基于 RColorBrewer 包的 RdBu 调色板，用函数 colorRampPalette() 构造一个新的红蓝调色板。参数 layout 将多个子图按照一定顺序排列，图中设置 2 行 1 列的多图布局。参数 scales 用来调整刻度，设置 list(draw = FALSE) 将图中的刻度去掉了。参数 xlab 设置一个空字符，即 xlab = \"\" 可去掉横坐标轴标签，参数 ylab 应用于设置纵坐标，用法与参数 xlab 一样。图中，主要表现得票率在各州的分布，因此，坐标轴刻度和标签都不太重要，可以去掉。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#sec-basic-lattice-summary",
    "href": "visualization-lattice.html#sec-basic-lattice-summary",
    "title": "9  lattice 入门",
    "section": "\n9.4 总结",
    "text": "9.4 总结\n现在回过头来看，无论是图形样式还是绘图语法， lattice 可以看作是介于 Base R 和 ggplot2 之间的一种绘图风格。举例来说，下面比较 Base R 和 lattice 的图形样式。\nplot(Sepal.Length ~ Petal.Length, col = Species, data = iris,\n  xlab = \"萼片长度\", ylab = \"花瓣长度\")\nxyplot(Sepal.Length ~ Petal.Length, groups = Species, data = iris,\n  scales = \"free\", xlab = \"萼片长度\", ylab = \"花瓣长度\")\n\n\n\n\n\n\n\n\n\n(a) Base R 图形\n\n\n\n\n\n\n\n\n\n(b) lattice 图形\n\n\n\n\n\n\n图 9.22: 对比 Base R 和 lattice 制作的分组散点图\n\n\n与函数 plot() 对应的是函数 xyplot() ，它们共用一套公式语法，参数 data 的含义也是一样的。与参数 col 对应的是参数 groups ，作用是添加数据分组标识。在两个函数中，添加横纵坐标轴标签都是用参数 xlab 和 ylab 。函数 xyplot() 中参数 scales 的作用是对坐标轴刻度的调整，参数值 \"free\" 表示去掉图形上边和右边的刻度线，默认情况下是有刻度线的。\n在高级的绘图函数方面，Base R 和 lattice 基本都有功能对应的函数，在低水平的绘图函数方面，二者截然不同，主要是因为后者基于另一套绘图系统 — grid 绘图系统。Base R 作图常常需要一个函数一个函数地不断叠加，在图中画上点、线、轴、标签等元素，而 lattice 主要通过面板函数，层层叠加的方式，每一个面板函数实现一个功能，整合一系列绘图操作。本章主要介绍 lattice 包和 latticeExtra 包，用到的高级绘图函数如下表。\n\n\n表格 9.1: lattice 和 latticeExtra 包的部分函数\n\n\n\n\n\n\n\n\n\nR 包\n函数\n图形\n作用\n\n\n\nlattice\nxyplot()\n（分组）散点图\n描述关系\n\n\nlattice\nbwplot()\n（分组）箱线图\n描述分布\n\n\nlattice\nbarchart()\n（分组）柱形图\n描述对比\n\n\nlattice\nlevelplot()\n切片水平图\n描述趋势\n\n\nlattice\nwireframe()\n三维透视图\n描述趋势\n\n\nlattice\ncloud()\n三维散点图\n描述分布\n\n\nlatticeExtra\npanel.smoother()\n回归曲线图\n描述趋势\n\n\nlatticeExtra\npanel.2dsmoother()\n地形轮廓图\n描述趋势\n\n\nlatticeExtra\necdfplot()\n经验分布图\n描述分布\n\n\nlatticeExtra\nsegplot()\n置信区间图\n描述不确定性\n\n\nlatticeExtra\npanel.ellipse()\n置信椭圆图\n描述不确定性\n\n\nlatticeExtra\nmapplot()\n地区分布图\n描述分布\n\n\n\n\n\n\n\n\n\n\nSarkar, Deepayan. 2008. lattice: Multivariate Data Visualization with R. New York: Springer. http://lmdvr.r-forge.r-project.org.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-lattice.html#footnotes",
    "href": "visualization-lattice.html#footnotes",
    "title": "9  lattice 入门",
    "section": "",
    "text": "Paul 在 DSC 2001 大会上的幻灯片。↩︎",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>lattice 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html",
    "href": "visualization-graphics.html",
    "title": "10  graphics 入门",
    "section": "",
    "text": "10.1 绘图基础\n利用点、线等基础元素从零开始绘图。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-elements",
    "href": "visualization-graphics.html#sec-graphics-elements",
    "title": "10  graphics 入门",
    "section": "",
    "text": "10.1.1 plot()\n\n本节将主要基于鸢尾花数据集介绍 R 语言基础绘图系统，该数据集最早来自埃德加·安德森，后来，被罗纳德·费希尔在介绍判别分析的论文中用到，从而，流行于机器学习社区。鸢尾花是非常漂亮的一种花，在统计和机器学习社区家喻户晓，更别提在植物界的名声。其实，远不止于此，在绘画艺术界也是如雷贯耳，印象派大师文森特·梵高画了一系列鸢尾花作品。万紫千红，但能入画的不多，故而，鸢尾花更显高雅。在生命最后的一段日子里，梵高受精神病折磨，在法国普罗旺斯的圣·雷米医院里，唯有盛开的鸢尾花陪着他，最著名的《星月夜》就是在这时候创作出来的。下面先让我们一睹鸢尾花芳容，图片来自维基百科鸢尾花词条。\n\n\n\n\n\n\n\n\n\n(a) versicolor 杂色鸢尾\n\n\n\n\n\n\n\n\n\n(b) setosa 山鸢尾\n\n\n\n\n\n\n\n\n\n(c) virginica 弗吉尼亚鸢尾\n\n\n\n\n\n\n图 10.1: 三种鸢尾花\n\n\n鸢尾花数据集已经打包在 R 软件中，而且默认已经加载到命名空间，下面用函数 summary() 查看其概况。\n\nsummary(iris)\n\n#&gt;   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n#&gt;  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n#&gt;  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n#&gt;  Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n#&gt;  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n#&gt;  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n#&gt;  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n#&gt;        Species  \n#&gt;  setosa    :50  \n#&gt;  versicolor:50  \n#&gt;  virginica :50  \n#&gt;                 \n#&gt;                 \n#&gt; \n\n\n函数 plot() 采用公式语法可以快速作图。\nplot(Sepal.Length ~ Sepal.Width, data = iris)\nplot(iris$Sepal.Width, iris$Sepal.Length, panel.first = grid())\n\n\n\n\n\n\n\n\n\n(a) 公式语法绘制散点图\n\n\n\n\n\n\n\n\n\n(b) 带背景参考线的散点图\n\n\n\n\n\n\n图 10.2: 快速作图函数 plot()\n\n\n函数 plot() 是一个泛型函数，传递不同类型的参数值会调用不同的绘图方法，而不同的绘图方法的参数是不同的。当采用公式语法绘图时，会自动调用函数 plot.formula() ，此时，参数 panel.first 就不起作用。当不使用公式语法时，会调用函数 plot.default() ，此时，参数 panel.first 就起作用，利用该参数可以添加背景参考线。\n\n10.1.2 标签\n函数 plot() 的参数 xlab 、ylab 和 main 可以分别设置坐标轴横、纵标签和图主标题。\n\nplot(\n  Sepal.Length ~ Sepal.Width, data = iris, \n  xlab = \"Sepal Width\", ylab = \"Sepal Length\",\n  main = \"Edgar Anderson's Iris Data\"\n)\n\n\n\n\n\n\n图 10.3: 标签\n\n\n\n\n\n10.1.3 字体\n作图函数 plot() 和 title() 都有参数 family ，设置该参数可以调整图形中的字体。下 图 10.4 的横纵坐标轴标签和图标题设为宋体，坐标轴刻度标签设为无衬线字体。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, ann = FALSE, family = \"sans\")\ntitle(\n  xlab = \"萼片宽度\", ylab = \"萼片长度\",\n  main = \"埃德加·安德森的鸢尾花数据\", family = \"Noto Serif CJK SC\"\n)\n\n\n\n\n\n\n图 10.4: 字体\n\n\n\n\n\n10.1.4 分组\n分组有两种方式，其一按照数据中的分类变量分组，其二按照一定的规则分组。而图形表达的方式可以借助颜色或图形元素的样式。\n函数 plot() 的参数 col 和 pch 都可以用来分组，前者通过颜色，后者通过点的类型。简单起见，将数据集 iris 中的 Species 列传递给参数 col ，实现不同种类的鸢尾花配以不同的颜色。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, col = Species, pch = 16)\n\n\n\n\n\n\n图 10.5: 分组\n\n\n\n\n下面采用一个简单规则将数据分成两组，将鸢尾花中 setosa 山毛榉类型且 Sepal.Length 萼片长度大于 5 厘米的分成一组，以红色填充散点代表这部分数据，与余下的散点形成对比，达到区分的目的。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris)\npoints(Sepal.Length ~ Sepal.Width, data = iris, \n  col = \"#EA4335\", pch = 16,\n  subset = Species == \"setosa\" & Sepal.Length &gt; 5\n)\n\n\n\n\n\n\n图 10.6: 分组\n\n\n\n\n\n10.1.5 配色\n经过探查，知道数据集 iris 中的 Species 列有三种取值。调用函数 palette() 设置一个超过 3 种颜色的调色板可以实现自定义配色。首先来看看当前调色板的颜色。\n\npalette()\n\n#&gt; [1] \"black\"   \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\"\n#&gt; [8] \"gray62\"\n\n\n一共是 8 种颜色，效果预览见 图 10.7 。\n\n\n\n\n\n\n\n图 10.7: 默认调色板\n\n\n\n\n设置新的调色板也是用函数 palette() ，参数 value 设置新的颜色值向量，下面依次是红、蓝、绿、黄四种颜色。\n\npalette(value = c(\"#EA4335\", \"#4285f4\", \"#34A853\", \"#FBBC05\"))\n\n函数 plot() 的调色板默认来自函数 palette() ，经过上面的调整，同一行绘图代码出来不同的效果，即 图 10.5 变成 图 10.8 。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, col = Species, pch = 16)\n\n\n\n\n\n\n图 10.8: 配色\n\n\n\n\n\n10.1.6 注释\n函数 text() 可以在图上任意位置添加文本或公式。下图在位置 (4,6.5) 处添加红色的文字 flower。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris)\ntext(x = 4, y = 6.5, labels = \"flower\", col = \"#EA4335\")\n\n\n\n\n\n\n图 10.9: 注释\n\n\n\n\n\n10.1.7 图例\n函数 plot() 不会自动添加图例，需要使用函数 legend() 添加图例。\n\nplot(Sepal.Length ~ Sepal.Width, data = iris, col = Species, pch = 16)\nlegend(x = \"topright\", title = \"Species\",\n  legend = unique(iris$Species), box.col = NA, bg = NA,\n  pch = 16, col = c(\"#EA4335\", \"#4285f4\", \"#34A853\")\n)\n\n\n\n\n\n\n图 10.10: 图例\n\n\n\n\n图例放置在绘图区域以外，比如右边空区域。此时，通过点和文本构造图例。\n\nop &lt;- par(mar = c(4, 4, 3, 6))\nplot(\n  Sepal.Length ~ Sepal.Width, data = iris, \n  col = Species, pch = 16, main = \"Edgar Anderson's Iris Data\"\n)\ntext(x = 4.7, y = 6.75, labels = \"Species\", pos = 4, offset = .5, xpd = T)\npoints(x = 4.7, y = 6.5, pch = 16, cex = 1, col = \"#EA4335\", xpd = T)\ntext(x = 4.7, y = 6.5, labels = \"setosa\", pos = 4, col = \"#EA4335\", xpd = T)\npoints(x = 4.7, y = 6.3, pch = 16, cex = 1, col = \"#4285f4\", xpd = T)\ntext(x = 4.7, y = 6.3, labels = \"versicolor\", pos = 4, col = \"#4285f4\", xpd = T)\npoints(x = 4.7, y = 6.1, pch = 16, cex = 1, col = \"#34A853\", xpd = T)\ntext(x = 4.7, y = 6.1, labels = \"virginica\", pos = 4, col = \"#34A853\", xpd = T)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.11: 图例\n\n\n\n\n在函数 plot() 内设置较宽的坐标轴范围，获得一个较宽的绘图区域，再用函数 points() 添加数据点，最后，使用函数 legend() 添加图例。\n\nplot(\n  x = c(2, 6), y = range(iris$Sepal.Length), type = \"n\",\n  xlab = \"Sepal Width\", ylab = \"Sepal Length\",\n  main = \"Edgar Anderson's Iris Data\"\n)\npoints(Sepal.Length ~ Sepal.Width,\n  col = Species, pch = 16, data = iris\n)\nlegend(x = \"right\", title = \"Species\",\n  legend = unique(iris$Species), box.col = NA, bg = NA,\n  pch = 16, col = c(\"#EA4335\", \"#4285f4\", \"#34A853\")\n)\n\n\n\n\n\n\n图 10.12: 图例\n\n\n\n\n\n10.1.8 统计\n添加分组线性回归线。按鸢尾花种类分组，线性回归模型拟合数据，抽取回归系数。首先，使用函数 split() 将数据集 iris 按变量 Species 分组拆分，得到一个列表，每个元素都是数据框。接着，调用函数 lapply() 将函数 lm() 作用到列表的每个元素上，得到一个列表，每个元素都是线性拟合对象。最后，再调函数 lapply() 将函数 coef() 应用到列表的每个元素上，得到回归模型的系数向量。\n\nlapply(\n  lapply(\n    split(iris, ~Species), lm,\n    formula = Sepal.Length ~ Sepal.Width\n  ),\n  coef\n)\n\n#&gt; $setosa\n#&gt; (Intercept) Sepal.Width \n#&gt;   2.6390012   0.6904897 \n#&gt; \n#&gt; $versicolor\n#&gt; (Intercept) Sepal.Width \n#&gt;   3.5397347   0.8650777 \n#&gt; \n#&gt; $virginica\n#&gt; (Intercept) Sepal.Width \n#&gt;   3.9068365   0.9015345\n\n\n走到绘图这一步，往往是画什么内容比较清楚，分类数量、调色板都确定下来了。大致来说分 6 步：第一步，实现分组线性回归拟合；第二步，绘制分组散点图；第三步，添加分组回归线；第四步，添加图例并调整图例的位置；第五步，设置图形边界等绘图参数；第六步，添加背景网格线。输入线性拟合对象给函数 abline() 可以直接绘制回归线，不需要从拟合对象中提取回归系数。调用函数 par() 设置图形边界，特别是增加图形右侧边界以容纳图例，再调用函数 legend() 要设置 xpd = TRUE 以允许图例超出绘图区域。\n\n# 分组线性拟合\niris_lm &lt;- lapply(\n  split(iris, ~Species), lm, formula = Sepal.Length ~ Sepal.Width\n)\n# 将分组变量和颜色映射\ncols &lt;- c(\"setosa\" = \"#EA4335\",  \"versicolor\" = \"#4285f4\", \"virginica\" = \"#34A853\")\n# 设置图形边界以容纳标签和图例\nop &lt;- par(mar = c(4, 4, 3, 8))\n# 绘制分组散点图\nplot(\n  Sepal.Length ~ Sepal.Width,\n  data = iris, col = Species, pch = 16,\n  xlab = \"Sepal Width\", ylab = \"Sepal Length\",\n  main = \"Edgar Anderson's Iris Data\"\n)\n# 添加背景参考线\ngrid()\n# 添加回归线\nfor (species in c(\"setosa\", \"versicolor\", \"virginica\")) {\n  abline(iris_lm[[species]], col = cols[species], lwd = 2)\n}\n# 添加图例\nlegend(\n  x = \"right\", title = \"Species\", inset = -0.4, xpd = TRUE,\n  legend = unique(iris$Species), box.col = NA, bg = NA, lty = 1, lwd = 2,\n  pch = 16, col = c(\"#EA4335\", \"#4285f4\", \"#34A853\")\n)\n# 恢复图形参数设置\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.13: 分组线性回归",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-advanced",
    "href": "visualization-graphics.html#sec-graphics-advanced",
    "title": "10  graphics 入门",
    "section": "\n10.2 绘图进阶",
    "text": "10.2 绘图进阶\n\n10.2.1 组合图形\n点、线、多边形组合\n\nx &lt;- seq(-10, 10, length = 400)\ny1 &lt;- dnorm(x)\ny2 &lt;- dnorm(x, m = 3)\nop &lt;- par(mar = c(5, 4, 2, 1))\nplot(x, y2,\n  xlim = c(-3, 8), type = \"n\",\n  xlab = quote(Z == frac(mu[1] - mu[2], sigma / sqrt(n))),\n  ylab = \"Density\"\n)\npolygon(c(1.96, 1.96, x[240:400], 10),\n  c(0, dnorm(1.96, m = 3), y2[240:400], 0),\n  col = \"grey80\", lty = 0\n)\nlines(x, y2)\nlines(x, y1)\npolygon(c(-1.96, -1.96, x[161:1], -10),\n  c(0, dnorm(-1.96, m = 0), y1[161:1], 0),\n  col = \"grey30\", lty = 0\n)\npolygon(c(1.96, 1.96, x[240:400], 10),\n  c(0, dnorm(1.96, m = 0), y1[240:400], 0),\n  col = \"grey30\"\n)\nlegend(x = 4.2, y = .4,\n  fill = c(\"grey80\", \"grey30\"),\n  legend = expression(\n    P(abs(Z) &gt; 1.96, H[1]) == 0.85,\n    P(abs(Z) &gt; 1.96, H[0]) == 0.05\n  ), bty = \"n\"\n)\ntext(0, .2, quote(H[0]:~ ~ mu[1] == mu[2]))\ntext(3, .2, quote(H[1]:~ ~ mu[1] == mu[2] + delta))\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.14: 正态总体下两样本均值之差的检验\n\n\n\n\n\n10.2.2 多图布局\n布局函数 layout() 和图形参数设置函数 par()\n\ndata(anscombe)\nform &lt;- sprintf(\"y%d ~ x%d\", 1:4, 1:4)\nfit &lt;- lapply(form, lm, data = anscombe)\nop &lt;- par(mfrow = c(2, 2), mgp = c(2, 0.7, 0), \n          mar = c(3, 3, 1, 1) + 0.1, oma = c(0, 0, 2, 0))\nfor (i in 1:4) {\n  plot(as.formula(form[i]),\n    data = anscombe, col = \"black\",\n    pch = 20, xlim = c(3, 19), ylim = c(3, 13),\n    xlab = as.expression(substitute(x[i], list(i = i))),\n    ylab = as.expression(substitute(y[i], list(i = i))),\n    family = \"sans\"\n  )\n  abline(fit[[i]], col = \"black\")\n  text(\n    x = 7, y = 12, family = \"sans\",\n    labels = bquote(R^2 == .(round(summary(fit[[i]])$r.squared, 3)))\n  )\n}\nmtext(\"数据集的四重奏\", outer = TRUE)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.15: 数据可视化很重要",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-choose",
    "href": "visualization-graphics.html#sec-graphics-choose",
    "title": "10  graphics 入门",
    "section": "\n10.3 图形选择",
    "text": "10.3 图形选择\n以不同的二维或三维图形可视化同一份多元数据。颜色图、透视图、等值线图和填充等值线图存在某种相似性，又有区别。\n\n10.3.1 颜色图\n\\[\nf(x,y) =\n\\begin{cases}\n\\frac{\\sin(\\sqrt{x^2 + y^2})}{\\sqrt{x^2 + y^2}}, & (x,y) \\neq (0,0)\\\\\n1, & (x,y) = (0,0)\n\\end{cases}\n\\]\n\ny &lt;- x &lt;- seq(from = -8, to = 8, length.out = 51)\nz &lt;- outer(x, y, FUN = function(x, y) sin(sqrt(x^2 + y^2)) / sqrt(x^2 + y^2))\nz[26, 26] &lt;- 1\n\n将绘图区域划分成网格，每个小网格对应一个颜色值。函数 image() 绘制颜色图\n\nimage(x = x, y = y, z = z, xlab = \"$x$\", ylab = \"$y$\")\n\n\n\n\n\n\n图 10.16: 颜色图\n\n\n\n\n\n10.3.2 透视图\n函数 persp() 绘制透视图\n\nop &lt;- par(mar = c(0, 1, 2, 1))\npersp(\n  x = x, y = y, z = z, main = \"二维函数的透视图\",\n  theta = 30, phi = 30, expand = 0.5, col = \"lightblue\",\n  xlab = \"$x$\", ylab = \"$y$\", zlab = \"$f(x,y)$\"\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.17: 透视图\n\n\n\n\n\n10.3.3 等值线图\n地理上，常用等高线图描述地形，等高线图和等值线图其实是一个意思。函数 contour() 绘制等值线图。\n\ncontour(x = x, y = y, z = z, xlab = \"$x$\", ylab = \"$y$\")\n\n\n\n\n\n\n图 10.18: 等值线图\n\n\n\n\n\n10.3.4 填充等值线图\n函数 filled.contour() 绘制填充等值线图。\n\nfilled.contour(\n  x = x, y = y, z = z, asp = 1,\n  color.palette = hcl.colors,\n  plot.title = {\n    title(\n      main = \"二维函数的填充等值线图\",\n      xlab = \"$x$\", ylab = \"$y$\"\n    )\n  },\n  plot.axes = {\n    grid(col = \"gray\")\n    axis(1, at = 2 * -4:4, labels = 2 * -4:4)\n    axis(2, at = 2 * -4:4, labels = 2 * -4:4)\n    points(0, 0, col = \"blue\", pch = 16)\n  },\n  key.axes = {\n    axis(4, seq(-0.2, 1, length.out = 9))\n  }\n)\n\n\n\n\n\n\n图 10.19: 填充等值线图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-graphics.html#sec-graphics-summary",
    "href": "visualization-graphics.html#sec-graphics-summary",
    "title": "10  graphics 入门",
    "section": "\n10.4 总结",
    "text": "10.4 总结\n\n10.4.1 tinyplot 包\ntinyplot 包扩展 Base R 函数 plot() 的功能，在公式语法方面和 lattice 包很接近。另一个值得一提的 R 包是 basetheme ，用来设置 Base R 绘图主题。\n\nlibrary(tinyplot)\ntinyplot(Sepal.Length ~ Sepal.Width | Species, data = iris, \n      palette = \"Tableau 10\", pch = 16)\n\n\n\n\n\n\n图 10.20: tinyplot 包绘制分组散点图\n\n\n\n\n或者使用参数 by 指定分组变量，效果和上图一样。\n\nwith(iris, {\n  tinyplot(y = Sepal.Length, x = Sepal.Width, by = Species,\n      palette = \"Tableau 10\", pch = 16)\n})\n\n还可以使用参数 legend 调整图例的位置，比如放置在绘图区域下方。\n\nop &lt;- par(mar = c(5, 4, .5, .5))\ntinyplot(Sepal.Length ~ Sepal.Width | Species,\n  data = iris, palette = \"Tableau 10\", pch = 16,\n  legend = legend(\"bottom!\", title = \"Species of iris\", bty = \"o\")\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 10.21: tinyplot 包调整图例位置\n\n\n\n\n还可以绘制其它类型的图形，如分组密度曲线图等。\n\nwith(iris, tinyplot(\n  density(Sepal.Length), by = Species,\n  bg = \"by\",   # 分组填充\n  grid = TRUE, # 背景网格\n  palette = \"Tableau 10\",\n  legend = list(\"topright\", bty = \"o\") # 右上角图例\n))\n\n\n\n\n\n\n图 10.22: tinyplot 包绘制密度曲线图\n\n\n\n\n\n10.4.2 plot3D 包\n虽然不提倡大量使用三维图形，但如何绘制三维图形却是生生不息的命题，以下仅是 R 语言社区的冰山一角。\n\n\nplotrix (Lemon 2006) 一个坐落于 R 的红灯区的 R 包。基于 Base R 各类绘图函数。\n\nscatterplot3d (Ligges 和 Mächler 2003) 基于 Base R 绘制三维散点图。\n\nmisc3d (Feng 和 Tierney 2008) 绘制三维图形的杂项，支持通过 Base R、 tcltk 包和 rgl 包渲染图形。\n\nplot3D (Soetaert 2021) 依赖 misc3d 包，加强 Base R 在制作三维图形方面的能力。\n\n举个比较新颖的一个例子，plot3D 包的函数 image2D() 绘制二维颜色图，细看又和 image() 函数不同，渲染出来的图形有三维的立体感。归根结底，很多时候束缚住自己的不是工具，而是视野和思维。以奥克兰 Maunga Whau 火山地形数据 volcano 为例。\nlibrary(plot3D)\nimage2D(volcano,\n  shade = 0.2, rasterImage = TRUE, asp = 0.7,\n  xlab = \"南北方向\", ylab = \"东西方向\",\n  main = \"奥克兰 Maunga Whau 地形图\", clab = \"高度\",\n  contour = FALSE, col = hcl.colors(100),\n  colkey = list(\n    at = 90 + 20 * 0:5, labels = 90 + 20 * 0:5,\n    length = 1, width = 1\n  )\n)\nop &lt;- par(mar = c(1, 1.5, 0, 0))\npersp3D(\n  x = 1:87, y = 1:61, z = volcano, col = hcl.colors(100),\n  ticktype = \"detailed\", colkey = FALSE, expand = 1, \n  phi = 35, theta = 125, bty = \"b2\", shade = TRUE,\n  ltheta = 100, lphi = 45,\n  xlab = \"\\n南北方向\", ylab = \"\\n东西方向\", zlab = \"\\n高度\"\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n\n\n\n(a) 函数 image2D() 二维颜色图\n\n\n\n\n\n\n\n\n\n\n\n(b) 函数 persp3D() 三维透视图\n\n\n\n\n\n\n图 10.23: 奥克兰火山地形图\n\n\n值得一提，Python 社区的绘图模块 matplotlib 同样具有强大的绘图能力，三维图形也不在话下。不过，不同的绘图系统所采用的透视法不同，如下图所示。\n\n代码from matplotlib import cm\nfrom matplotlib.colors import LightSource\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# 设置 PGF 后端渲染图形\nimport matplotlib as mpl\nmpl.use(\"pgf\")\n# XeLaTeX 编译图形\nplt.rcParams.update({\n    \"text.usetex\": True,\n    \"pgf.texsystem\": \"xelatex\",\n    \"pgf.rcfonts\": False,    # don't setup fonts from rc parameters\n    \"pgf.preamble\": \"\\n\".join([\n            r\"\\usepackage[fontset=fandol,UTF8]{ctex}\",\n        ]),\n})\n# 读取数据\nvolcano = pd.read_csv(\"data/volcano.csv\", header=None)\n# DataFrame 转 Array\nz = volcano.to_numpy()\n# 数据行、列数\nnrows, ncols = z.shape\n# 线性序列\nx = np.linspace(1, 87, ncols)\ny = np.linspace(1, 61, nrows)\n# 类似 R 语言函数 expand.grid()\nxv, yv = np.meshgrid(x, y)\n# 设置主题\nfig, ax = plt.subplots(subplot_kw=dict(projection=\"3d\"))\n# 观察视角\nax.view_init(azim=30, elev=30)\n# 设置坐标轴标签\nax.set_xlabel(r\"南北方向\", rotation=45)\nax.set_ylabel(r\"东西方向\", rotation=-15)\nax.set_zlabel(r\"高度\", rotation=90)\n# 去掉多余的边空\nfig.set_tight_layout(True)\n# 光源照射的角度\nls = LightSource(270, 45)\n# 自定义调色板\nrgb = ls.shade(z, cmap=cm.viridis, vert_exag=0.1, blend_mode=\"soft\")\n# 三维透视图\nsurf = ax.plot_surface(\n    xv, yv, z, rstride=1, cstride=1, facecolors=rgb,\n    linewidth=0, antialiased=False, shade=False\n)\n# 渲染\nplt.show()\n\n\n\n\n\n\n图 10.24: matplotlib 绘制三维透视图\n\n\n\n\n\n\n\n\nFeng, Dai, 和 Luke Tierney. 2008. 《Computing and Displaying Isosurfaces in R》. Journal of Statistical Software 28 (1). https://doi.org/10.18637/jss.v028.i01.\n\n\nLemon, Jim. 2006. 《plotrix: a package in the red light district of R》. R-News 6 (4): 8–12.\n\n\nLigges, Uwe, 和 Martin Mächler. 2003. 《scatterplot3d: An R Package for Visualizing Multivariate Data》. Journal of Statistical Software 8 (11): 1–20. https://doi.org/10.18637/jss.v008.i11.\n\n\nSoetaert, Karline. 2021. plot3D: Plotting Multi-Dimensional Data. https://CRAN.R-project.org/package=plot3D.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>graphics 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html",
    "href": "visualization-tikz.html",
    "title": "11  TikZ 入门",
    "section": "",
    "text": "11.1 standalone 宏包\n最常见的 LaTeX 文档类有 article、report、beamer、book，分别对应文章、报告、演示和书籍。有的宏包在此基础上扩展功能，比如 ctex 宏包提供中文支持，有四个文档类 ctexart、 ctexrep 、ctexbeamer 和 ctexbook 与之对应起来。standalone 宏包提供 standalone 文类主要用于绘制独立的图片，默认情况下，文档四周多余的空白部分会被裁剪掉。在 LaTeX 环境中，推荐使用 TikZ 来绘图。standalone 文类可与 tikz 宏包一起使用，生成一张张由 TikZ 代码绘制的独立图片。下面举个简单的例子，用 TikZ 绘制两个坐标轴。\nstandalone 文类启用 tikz 选项来绘图，选项 border=1mm 表示图片四周的边空保留 1 毫米，文档内容放在 document 环境里，TikZ 绘图代码放在 tikzpicture 环境中，命令 \\draw 负责绘制具体的图形，用 XeLaTeX 编译，效果如 图 11.1 所示。\n图 11.1: TikZ 绘图\nstandalone 文类有很多选项，下面介绍 4 个选项的常用内容。\nstandalone 文类是支持 PSTricks 绘图的，下面在直角坐标系中绘制一个带阴影效果的圆，示例代码如下：\nstandalone 文类的选项 pstricks 表示启用 PSTricks 绘图环境，加载 pst-plot 宏包提供额外的命令，PSTricks 是基于 PostScript 语言的，每一个绘图命令都是 \\ps 开头的，比如 \\psset 、\\psaxes、\\pscircle 等。\\begin{pspicture} 和 \\end{pspicture} 之间是 PSTricks 绘图代码，\\begin{pspicture} 之后的 (0,0)(11,11) 是左下和右上角两个坐标，定义了一个绘图区域。和 TikZ 绘图代码一样，也用 XeLaTeX 编译，效果如 图 11.2 所示。\n图 11.2: PSTricks 绘图\n可以在 Quarto 和 R Markdown 文档中插入 PSTricks 绘图代码，使用 knitr 包的 tikz 引擎绘图。只要修改模版文件 tikz2pdf.tex ，移除一行 \\usetikzlibrary{matrix} ，不再加载 tikz 宏包及其 matrix 库。TIKZ_CLASSOPTION 不再仅限于 TikZ ，而是 standalone 文类的选项，相应地，EXTRA_TIKZ_PREAMBLE_CODE 变成一般的 LaTeX 文档的导言区，TIKZ_CODE 可以是 PSTricks 代码。新的模版文件 tikz2pdf.tex 如下：\n上 图 11.2 即是由 knitr 包的 tikz 引擎渲染出来的。在代码块选项 engine-opts 中，传递一个列表，分别包含 classoption（standalone 文类选项）、 extra.preamble（导言区）、 template （TikZ 模版文件）三块内容。生成 图 11.2 的 engine-opts 设置如下：\n其它选项和更多详细介绍见 standalone 宏包帮助文档。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-standalone",
    "href": "visualization-tikz.html#sec-tikz-standalone",
    "title": "11  TikZ 入门",
    "section": "",
    "text": "\\documentclass[tikz,border=1mm]{standalone}\n\\begin{document}\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) -- (0,0) node[left]{O} -- (0,6);\n\\end{tikzpicture}\n\\end{document}\n\n\n\n\nclass 选项指定文类环境，默认值为 article，表示在 article 文类中绘图。其它选项还有 beamer ，表示在演示环境中绘图。在不同的文类中，图片渲染出来的效果不同。\ntikz=true|false 选项是否启用 TikZ 绘图，默认值是 false 。当显式地在 standalone 文类中启用 tikz 选项，就表示用 TikZ 绘图，将自动加载 tikz 宏包。与之类似的选项 pstricks=true|false ，表示是否启用 PSTricks 绘图，PSTricks 是LaTeX 社区中一套语法不同于 TikZ 的绘图工具。\ncrop=true|false 选项是否裁剪变空，默认值是 true ，表示绘图区域以外的部分都裁剪掉。与之相关的另一个选项是 border ，可以更加精细地控制图片四周的各个边空。\nborder 选项指定边空大小，默认值是 0，表示无边空。当 crop=true 时，再指定 border 选项，比如 border=1mm 表示图片四周的边空保留 1 毫米。图片四周的边空大小可以按照左、下、右、上的顺序指定，比如 border={5mm 6mm 0mm -2mm} 表示图片左边空 5 毫米、下边空 6 毫米、右边空 0 毫米、上边空负 2 毫米。\n\n\n\\documentclass[pstricks,border={5mm 6mm 0mm -2mm}]{standalone}\n\\usepackage{pst-plot}\n\\begin{document}\n\\psset{xunit=0.15in, yunit=0.15in}\n\\begin{pspicture}(0,0)(11,11)\n\\psaxes[Dx=4,Dy=4, subticks=4]{-&gt;}(0,0)(0,0)(10,10)[$x$,0][$y$,0]\n\\pscircle[runit=0.15in, fillcolor=orange!50, fillstyle=solid,shadow=true](5,5){3}\n\\end{pspicture}\n\\end{document}\n\n\n\n\\documentclass[\n%% TIKZ_CLASSOPTION %%\n]{standalone}\n%% EXTRA_TIKZ_PREAMBLE_CODE %%\n\\begin{document}\n%% TIKZ_CODE %%\n\\end{document}\n\nlist(\n  classoption = \"pstricks,border={5mm 6mm 0mm -2mm}\",\n  extra.preamble = \"\\\\usepackage{pst-plot}\",\n  template = \"code/tikz2pdf.tex\"\n)",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-pgf",
    "href": "visualization-tikz.html#sec-tikz-pgf",
    "title": "11  TikZ 入门",
    "section": "\n11.2 PGF 宏包",
    "text": "11.2 PGF 宏包\nPGF 宏包提供一套易于学习和使用的绘图语法 TikZ，TikZ 是 TikZ ist kein Zeichenprogramm 的简写，命名有 Linux 哲学意味。下面比较详细的介绍 LaTeX 宏包 PGF 绘制曲线图的过程。\n\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) -- (0,0) node[left]{O} -- (0,6);\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.3: PGF 绘制曲线图\n\n\n\n\n首先，\\draw 命令绘制带箭头的坐标轴，坐标轴的范围 \\([0,6]\\times[0,6]\\) 。坐标轴是由线构成的，线有虚线、实线，也有宽度和颜色，虚线还有不同类型，这些都是可以设置的参数，比如将 \\draw[&lt;-&gt;] 改为 \\draw[color=red,&lt;-&gt;] ，坐标轴颜色设置为红色。\n\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) node[below]{$q$} -- (0,0) node[left]{O} -- (0,6) node[left]{$V(q)$};\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.4: PGF 绘制曲线图\n\n\n\n\n然后，在位置 (6,0) 和 (0,6) 分别添加节点 node[below]{$q$} 和 node[left]{$V(q)$} 。node 表示节点，节点的标签内容在大括号内，标签的位置在中括号内，这里，below 表示在位置 (6,0) 的下方。\n\n\\begin{tikzpicture}\n\\draw[&lt;-&gt;] (6,0) node[below]{$q$} -- (0,0) node[left]{O} -- (0,6) node[left]{$V(q)$};\n\\draw[very thick] (0,0) to [out=90,in=145] (5,4.5);\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.5: PGF 绘制曲线图\n\n\n\n\n最后，从点 (0,0) 至点 (5,4.5) 绘制一条非常粗的曲线。曲线从点 (0,0) 出去的时候，是以 90 度垂直水平轴的方向出去的，到点 (5,4.5) 是以 145 度方向进入的。角度是按照逆时针方向计算的。线的粗细、方向都是由参数决定的。\n在这里，TikZ 是用来绘制示意图的，不需要知道每个命令的每个参数的取值有哪些。关键是知道自己想要画什么，其实，可以用铅笔在纸上以最快的方式绘制草图，了解每个绘图元素，然后查找 PGF 帮助手册，找到对应的命令和参数，将草图工整地誊抄一遍。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-pgfplots",
    "href": "visualization-tikz.html#sec-tikz-pgfplots",
    "title": "11  TikZ 入门",
    "section": "\n11.3 三维图",
    "text": "11.3 三维图\n顾名思义，pgfplots 宏包基于 PGF 的，用它来绘制三维图形是非常方便的。\n\\documentclass[tikz]{standalone}\n\\usepackage{pgfplots}\n\\pgfplotsset{width=7cm,compat=1.17}\n\\begin{document}\n%% TikZ 代码%%\n\\end{document}\n首先加载 pgfplots 宏包，设置全局的绘图参数，width=7cm 表示绘图页面宽度，compat=1.17 表示使用 pgfplots 的版本。\n\n\\begin{tikzpicture}\n\\begin{axis}[\n    hide axis,\n    colormap/viridis\n]\n\\addplot3[\n    mesh,\n    samples=50,\n    domain=-8:8\n]\n{ sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2) };\n\\addlegendentry{$\\frac{\\sin(r)}{r}$}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.6: TikZ 绘制三维图 viridis 调色板\n\n\n\n\n\n\\begin{tikzpicture}\n\\begin{axis}[\n    hide axis,\n    colormap/jet\n]\n\\addplot3[\n    mesh,\n    samples=50,\n    domain=-8:8\n]\n{ sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2) };\n\\addlegendentry{$\\frac{\\sin(r)}{r}$}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.7: TikZ 绘制三维图 jet 调色板\n\n\n\n\n\n\\begin{tikzpicture}\n\\begin{axis}[\n    hide axis,\n    colormap/cool,\n    colorbar sampled,\n    domain=-8:8\n]\n\\addplot3[\n    contour filled={\n      number=20,\n    },\n    ]{sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2)};\n\\addlegendentry{$\\frac{\\sin(r)}{r}$}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.8: TikZ 绘制三维图 cool 调色板\n\n\n\n\n\n\n\\begin{axis} 和 \\end{axis} 环境有很多配置选项，参数值 [hide axis, colormap/viridis] 中 hide axis 表示隐藏坐标轴，colormap/viridis 表示三维图形的调色板采用 viridis 。colormap 支持很多不同的调色板，上面列举了两个。其实还可以增加不同的选项，比如添加选项 colorbar sampled 会生成一个颜色条，还可以添加选项 colorbar horizontal 来水平放置颜色条。\n可以在导言区加载 \\usetikzlibrary{pgfplots.colorbrewer} 导入 ColorBrewer 系列调色板，方便后续绘图时调用。作用与 R 语言中的 RColorBrewer 包类似，调色板名称略有不同，前者 PuBu-9 对应后者 PuBu 。\n\n\\addplot3 命令绘制函数 sin(deg(sqrt(x^2+y^2)))/sqrt(x^2+y^2) 的三维图像，即函数 \\(f(x,y)=\\frac{\\sin(\\sqrt{x^2 + y^2})}{\\sqrt{x^2 + y^2}}\\) 的三维图像。参数值 [mesh, samples=50, domain=-8:8] 中 mesh 表示三维图形是网格状，其它可选值还有曲面图 surf 、填充等值线图 contour filled 等，samples=50 表示网格密度是 50，domain=-8:8 表示横纵坐标的范围都是 \\([-8,8]\\) 。\n\n\\addlegendentry 添加图例，图例标签是 \\(\\frac{\\sin(r)}{r}\\) ，颜色会随着调色板变化。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-network",
    "href": "visualization-tikz.html#sec-tikz-network",
    "title": "11  TikZ 入门",
    "section": "\n11.4 网络图",
    "text": "11.4 网络图\n绘制网络图用 tikz-network 宏包，也是 PGF 的一个扩展包。图结构是根据顶点和边来定义的，图的复杂程度也可以用顶点和边的规模来衡量。图描述一种非线性的关系，有自己的一套语言，定义顶点 \\Vertex 和边 \\Edge 的两个命令是最基础的。下面绘制柯尼斯堡七桥问题对应的图。\n\\documentclass[tikz]{standalone}\n\\usepackage{tikz-network}\n\\begin{document}\n%% TikZ 代码%%\n\\end{document}\n\n\\begin{tikzpicture}\n\\Vertex[IdAsLabel, x=5, color=gray, size=1, fontsize=\\large]{A}\n\\Vertex[IdAsLabel, x=10, color=gray, size=1, fontsize=\\large]{B}\n\\Vertex[IdAsLabel, x=15, color=gray, size=1, fontsize=\\large]{C}\n\\Vertex[IdAsLabel, x=10, y=6, color=gray, size=1, fontsize=\\large]{D}\n\n\\Edge[label=2, bend=45, fontscale=2](A)(B)\n\\Edge[label=6, bend=30, fontscale=2](A)(D)\n\\Edge[label=3, bend=45, fontscale=2](B)(A)\n\\Edge[label=5, bend=45, fontscale=2](B)(C)\n\\Edge[label=4, bend=45, fontscale=2](C)(B)\n\\Edge[label=7, bend=30, fontscale=2](D)(C)\n\\Edge[label=1, fontscale=2](D)(B)\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.9: 柯尼斯堡七桥\n\n\n\n\n\n\\Vertex 命令定义顶点（含标签），参数 IdAsLabel 表示顶点 ID 作为标签，参数 x 和 y 表示坐标位置，参数 color 表示顶点的填充色，参数 size 表示顶点的大小，参数 fontsize 表示标签文本的大小。\n\\Edge 命令在已有顶点的基础上定义边，(A)(B) 表示从顶点 A 到顶点 B 有一条边，参数label 表示边上的标签文本，参数 bend 表示边的弧度，参数 fontscale 表示标签文本的大小。\n\n不难看出，无论是顶点还是边，都有颜色、大小、标签等参数，尽管参数名称有所不同。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-mindmap",
    "href": "visualization-tikz.html#sec-tikz-mindmap",
    "title": "11  TikZ 入门",
    "section": "\n11.5 思维导图",
    "text": "11.5 思维导图\n思维导图是非常常见的一种树状图，用于梳理层次关系。TikZ 绘制思维导图是通过 mindmap 库实现的，它是 PGF 的一个库。如 图 11.10 所示，看着和脑神经网络有某种相似性，所以，有时候，思维导图也叫脑图。\n\\documentclass[tikz,svgnames]{standalone}\n\\usepackage[fontset=fandol]{ctex}\n\\usetikzlibrary{mindmap}\n\\begin{document}\n%% TikZ 代码%%\n\\end{document}\n\n\\begin{tikzpicture}[\n    mindmap, every node/.style=concept, concept color=orange, text=white,\n    level 1/.append style={level distance=5cm, sibling angle=60, font=\\LARGE},\n    level 2/.append style={level distance=3.5cm, sibling angle=45, font=\\large}\n  ]\n\n  \\node{\\huge{\\textsf{数据分析}}} [clockwise from=60]\n  child [concept color=DarkMagenta] {\n      node {\\textit{数据准备}} [clockwise from=120]\n      child { node {数据对象}}\n      child { node {数据获取}}\n      child { node {数据清洗}}\n      child { node {数据操作}}\n    }\n  child [concept color=DarkBlue] {\n      node {\\textit{数据探索}} [clockwise from=30]\n      child { node {ggplot2 入门}}\n      child { node {基础图形}}\n      child { node {统计图形}}\n    }\n  child [concept color=Brown] {\n      node {\\textit{数据交流}} [clockwise from=-30]\n      child { node {交互图形}}\n      child { node {交互表格}}\n      child { node {交互应用}}\n    }\n  child [concept color=teal] {\n      node {\\textit{统计分析}} [clockwise from=-75]\n      child { node {统计检验}}\n      child { node {回归分析}}\n      child { node {功效分析}}\n    }\n  child [concept color=purple] {\n      node {\\textit{数据建模}} [clockwise from=-120]\n      child { node {网络分析}}\n      child { node {文本分析}}\n      child { node {时序分析}}\n    }\n  child [concept color=DarkGreen] {\n      node {\\textit{优化建模}} [clockwise from=180]\n      child { node {统计计算}}\n      child { node {数值优化}}\n      child { node {优化问题}}\n    };\n\\end{tikzpicture}\n\n\n\n\n\n\n图 11.10: TikZ 绘制思维导图\n\n\n\n\n根节点视为一层，则该思维导图有三层。不同的颜色和字体来区分不同的层次或分类，数据分析划分为不同的部分，每个部分有若干章。根节点字体为黑体、第二、三级节点分别为楷体、宋体。\n\\node{\\huge{\\textsf{数据科学}}} [clockwise from=60]\n定义根节点，节点的文本设置为黑体，大小设置为 \\huge 。由根节点向外辐射生成 6 个子节点，每隔 60 度设置一个子节点。\n  child [concept color=DarkMagenta] {\n      node {\\textit{数据准备}} [clockwise from=120]\n      child { node {数据对象}}\n      child { node {数据获取}}\n      child { node {数据清洗}}\n      child { node {数据操作}}\n    }\n第一个子节点，颜色为饱和的紫色 DarkMagenta，二级子节点为「数据准备」，三级子节点有 4 个，逆时针 120 度的位置设置第一个三级子节点「数据对象」，然后顺时针往下，依次是「数据获取」、「数据清洗」和「数据操作」。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-smart-diagram",
    "href": "visualization-tikz.html#sec-smart-diagram",
    "title": "11  TikZ 入门",
    "section": "\n11.6 SmartArt 图",
    "text": "11.6 SmartArt 图\nOffice 办公软件中有一个 SmartArt 绘图模块，专门用来绘制各类示意图。LaTeX 宏包 smartdiagram 基于 TikZ 定制了一套风格类似的绘图库。 smartdiagram 宏包的主要绘图命令是 \\smartdiagram[参数值] ，设置不同的参数值可以绘制不同的图形，如气泡图 bubble diagram 和描述图 descriptive diagram 等。\n\n\\smartdiagram[bubble diagram]{\n  Pandoc,\n  编程语言~\\\\ (Python\\\\R/Julia\\\\JavaScript), \n  编译引擎~\\\\ (Jupyter\\\\Knitr\\\\Observable), \n  扩展Pandoc~\\\\ (交叉引用\\\\悬浮引用\\\\布局面板), \n  文档项目~\\\\ (批量渲染\\\\共享配置),\n  扩展接口~\\\\ (RStudio\\\\VS Code\\\\JupyterLab) \n}\n\n\n\n\n\n\n图 11.11: 气泡图\n\n\n\n\n\n\\smartdiagram[descriptive diagram]{\n  {编程语言, {Python、R、Julia、JavaScript}}, \n  {编译引擎, {Jupyter、Knitr、Observable}}, \n  {扩展Pandoc, {交叉引用、悬浮引用、布局面板}}, \n  {文档项目, {批量渲染、共享配置}},\n  {扩展接口, {RStudio、VS Code、JupyterLab}},\n}\n\n\n\n\n\n\n图 11.12: 描述图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-tikz.html#sec-tikz-with-r",
    "href": "visualization-tikz.html#sec-tikz-with-r",
    "title": "11  TikZ 入门",
    "section": "\n11.7 TikZ 与 R",
    "text": "11.7 TikZ 与 R\nTikZ 绘图的优势有很多，语法简单、易于上手、功能强大、资源丰富、成熟稳定等，可以说几乎是集所有优点于一身。正因如此，knitr 包和 tikzDevice 包将其引入 R 语言社区中。knitr 包的 tikz 引擎是用来编译 TikZ 代码的，默认使用的是 standalone 文类。\nR 语言绘图遇到公式时，略显不足，而排版公式是 LaTeX 的优势。正因为有所不足，所以我也不会纠结于工具层面的东西，什么好用用什么！三维 图 11.6 是用 LaTeX 里的优秀绘图工具 TikZ 制作的，细心的读者会发现本书多次用到这个工具。\n众所周知，Donald Knuth 十年磨一剑，开发了 TeX 排版系统，就是解决排版数学公式的痛点。如 图 11.13 所示，因图形中包含数学公式和符号，为了获得原汁原味的渲染效果，在使用 Base R 绘图的过程中通过 tikzDevice 包引入了 LaTeX 中的 TikZ 绘图引擎。\n\nopar &lt;- par(mgp = c(2, 0.7, 0), mar = c(4, 3, 4, 1) + 0.1, no.readonly = TRUE)\nset.seed(2021)\nx &lt;- rnorm(10)\ny &lt;- x + rnorm(5, sd = 0.25)\nlab &lt;- sample(\n  x = paste0(\"$\\\\mathcal{\", LETTERS, \"}$\"),\n  size = 10, replace = FALSE\n)\nmodel &lt;- lm(y ~ x)\nrsq &lt;- summary(model)$r.squared\nrsq &lt;- signif(rsq, 4)\nplot(x, y,\n  main = \"你好 \\\\LaTeX!\", # 引入 7 号文本字体\n  sub = \"$\\\\mathcal{N}(x;\\\\mu,\\\\Sigma)$\",\n  xlab = \"$x$\", ylab = \"$y$\", type = \"n\"\n)\ntext(x = x, y = y, labels = lab)\nabline(model, col = \"black\")\n# 引入 7 号数学字体\nmtext(paste(\"线性模型: $\\\\mathsf{R}^{2}=\", rsq, \"$\"), line = 0.5)\nlegend(\"bottomright\",\n  legend = paste0(\n    \"$y = \", round(coef(model)[2], 3), \"x +\",\n    round(coef(model)[1], 3), \"$\"\n  ),\n  bty = \"n\"\n)\non.exit(par(opar), add = TRUE)\n\n\n\n\n\n\n图 11.13: 简单线性模型\n\n\n\n\n图 11.14 是贝塞尔函数 \\(\\mathcal{K}_{\\kappa}(u)\\) 在区间 \\((10^{-8}, 10^2)\\) 和 \\((0, 4)\\) 上的图像。其中，图 11.14 (a) 是区间 \\((10^{-8}, 10^2)\\) 上的贝塞尔函数 \\(\\mathcal{K}_{\\kappa}(u)\\)， 图 11.14 (b) 是区间 \\((0, 4)\\) 上的贝塞尔函数 \\(\\mathcal{K}_{\\kappa}(u)\\) 。\nx0 &lt;- 2^(-20:10)\nnus &lt;- c(2:5, 10, 20)\nx &lt;- seq(0, 4, length.out = 501)\n\nplot(x0, x0^-8,\n  frame.plot = TRUE, # 添加绘图框\n  log = \"xy\",    # x 和 y 轴都取对数尺度\n  axes = FALSE,  # 去掉坐标轴\n  xlab = \"$u$\", ylab = \"$\\\\mathcal{K}_{\\\\kappa}(u)$\", # 设置坐标轴标签\n  type = \"n\", # 清除绘图区域的内容\n  ann = TRUE, # 添加标题 x和y轴标签\n  panel.first = grid() # 添加背景参考线\n)\n\naxis(1,\n  at = 10^(-8 + 2 * 0:5),\n  labels = paste0(\"$\\\\mathsf{10^{\", -8 + 2 * 0:5, \"}}$\")\n)\naxis(2,\n  at = 10^(-8 + 16 * 0:4),\n  labels = paste0(\"$\\\\mathsf{10^{\", -8 + 16 * 0:4, \"}}$\"), las = 1\n)\n\nfor (i in seq(length(nus))) {\n  lines(x0, besselK(x0, nu = nus[i]), col = hcl.colors(9)[i], lwd = 2)\n}\nlegend(\"topright\",\n  legend = paste0(\"$\\\\kappa=\", rev(nus), \"$\"),\n  col = hcl.colors(9, rev = TRUE), lwd = 2, cex = 1\n)\n\nx &lt;- seq(0, 4, length.out = 501)\nx &lt;- x[x &gt; 0]\nplot(x, x,\n  frame.plot = TRUE, ylim = c(1e+0, 1e+20), log = \"y\",\n  xlab = \"$u$\", ylab = \"$\\\\mathcal{K}_{\\\\kappa}(u)$\",\n  type = \"n\", yaxt = \"n\", ann = TRUE, panel.first = grid()\n)\naxis(2,\n  at = c(1e+0, 1e+05, 1e+10, 1e+15, 1e+20),\n  labels = paste0(\"$\\\\mathsf{10^{\", 5 * 0:4, \"}}$\"), las = 1\n)\n\nfor (i in seq(length(nus))) {\n  lines(x, besselK(x, nu = nus[i]), col = hcl.colors(9)[i], lwd = 2)\n}\nlegend(\"topright\",\n  legend = paste0(\"$\\\\kappa=\", rev(nus), \"$\"),\n  col = hcl.colors(9, rev = TRUE), lwd = 2, cex = 1\n)\n\n\n\n\n\n\n\n\n\n(a) 区间 \\((10^{-8}, 10^2)\\) 上的贝塞尔函数\n\n\n\n\n\n\n\n\n\n(b) 区间 \\((0, 4)\\) 上的贝塞尔函数\n\n\n\n\n\n\n图 11.14: 贝塞尔函数图像",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>TikZ 入门</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html",
    "href": "visualization-practice.html",
    "title": "12  探索实践",
    "section": "",
    "text": "12.1 分析老忠实间歇泉喷发规律\n图 12.1 展示美国怀俄明州黄石国家公园老忠实间歇泉喷发规律，横轴表示喷发持续时间（以分钟计），纵轴表示等待时间（以分钟计），点的亮暗程度（白到黑）代表附近点密度的高低，亮度值通过二维核密度估计方法得到，具体实现借助了 KernSmooth (Wand 和 Jones 1995) 包提供的 bkde2D() 函数，设置了喷发时间的窗宽为 0.7 分钟，等待时间的窗宽为 7分钟。不难看出，每等待 55 分钟左右间歇泉喷发约 2 分钟，或者每等待 80 分钟左右间歇泉喷发 4.5 约分钟，非常守时，表现得很老实，故而得名。说实话，二维核密度估计在这里有点大材小用了，因为数据点比较少，肉眼也能分辨出来哪里聚集的点多，哪里聚集的点少。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-faithful",
    "href": "visualization-practice.html#sec-faithful",
    "title": "12  探索实践",
    "section": "",
    "text": "代码# faithful 添加二维核密度估计 density 列\nlibrary(KernSmooth)\nden &lt;- bkde2D(x = faithful, bandwidth = c(0.7, 7), gridsize = c(51L, 51L))\nfaithful2d &lt;- expand.grid(eruptions = den$x1, waiting = den$x2) |&gt;\n  transform(density = as.vector(den$fhat))\n\nplot(faithful,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(0.5, 6.5),\n  ylim = c(35, 100)\n)\ntitle(xlab = \"喷发时间\", ylab = \"等待时间\", family = \"Noto Serif CJK SC\")\n\nplot(faithful,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(0.5, 6.5),\n  ylim = c(35, 100),\n  col = densCols(faithful,\n    bandwidth = c(0.7, 7),\n    nbin = c(51L, 51L), colramp = hcl.colors\n  )\n)\ntitle(xlab = \"喷发时间\", ylab = \"等待时间\", family = \"Noto Serif CJK SC\")\n\nplot(faithful,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(0.5, 6.5),\n  ylim = c(35, 100),\n  col = densCols(faithful,\n    bandwidth = c(0.7, 7),\n    nbin = c(51L, 51L), colramp = hcl.colors\n  )\n)\ncontour(den$x1, den$x2, den$fhat, nlevels = 10, add = TRUE, family = \"sans\")\ntitle(xlab = \"喷发时间\", ylab = \"等待时间\", family = \"Noto Serif CJK SC\")\n\n# 散点添加颜色\nmkBreaks &lt;- function(u) u - diff(range(u)) / (length(u) - 1) / 2\n# faithful 划入网格内\nxbin &lt;- cut(faithful[, 1], mkBreaks(den$x1), labels = FALSE)\nybin &lt;- cut(faithful[, 2], mkBreaks(den$x2), labels = FALSE)\n# 网格对应的核密度估计值即为 faithful 对应的核密度估计值\nfaithful$dens &lt;- den$fhat[cbind(xbin, ybin)]\n# 若是 faithful 数据点没有划分，则置为 0 \nfaithful$dens[is.na(faithful$dens)] &lt;- 0\n\nlibrary(ggplot2)\nlibrary(ggnewscale)\nggplot() +\n  geom_point(\n    data = faithful, aes(x = eruptions, y = waiting, color = dens),\n    shape = 20, size = 2, show.legend = FALSE\n  ) +\n  scale_colour_viridis_c(option = \"D\") +\n  new_scale_color() +\n  geom_contour(data = faithful2d, aes(\n    x = eruptions, y = waiting,\n    z = density, colour = after_stat(level)\n  ), bins = 14, linewidth = 0.45, show.legend = FALSE) +\n  scale_colour_viridis_c(option = \"C\", direction = -1, begin = 0.2, end = 0.8) +\n  # colorspace::scale_color_continuous_sequential(palette = \"Grays\") +\n  scale_x_continuous(breaks = 1:6) +\n  scale_y_continuous(breaks = 10 * 4:10) +\n  coord_cartesian(xlim = c(0.5, 6.5), ylim = c(35, 100)) +\n  labs(x = \"喷发时间\", y = \"等待时间\", colour = \"密度\") +\n  theme_bw(base_size = 13) +\n  theme(\n    legend.title = element_text(family = \"Noto Serif CJK SC\"),\n    axis.title = element_text(family = \"Noto Serif CJK SC\"),\n    axis.title.x = element_text(\n      margin = margin(b = 0, l = 0, t = 20, r = 0)\n    ),\n    axis.title.y = element_text(\n      margin = margin(b = 0, l = 0, t = 0, r = 20)\n    ),\n    panel.border = element_rect(color = \"black\"),\n    panel.grid = element_blank(),\n    panel.grid.major = element_line(\n      color = \"lightgray\",\n      linetype = 3, linewidth = 0.5\n    ),\n    axis.ticks.length = unit(0.25, \"cm\"),\n    axis.text.x = element_text(\n      family = \"sans\", color = \"black\",\n      vjust = -1.5, size = rel(1.25)\n    ),\n    axis.text.y = element_text(\n      family = \"sans\", color = \"black\",\n      angle = 90, vjust = 1.5, hjust = 0.5,\n      size = rel(1.25)\n    )\n  )\n\n\n\n\n\n\n\n\n\n(a) faithful 数据集的散点图\n\n\n\n\n\n\n\n\n\n(b) 点的亮暗表示核密度估计值的大小\n\n\n\n\n\n\n\n\n\n\n\n(c) 等高线表示核密度估计值\n\n\n\n\n\n\n\n\n\n(d) 等高线表示核密度估计值\n\n\n\n\n\n\n图 12.1: 二维核密度估计\n\n\n\n\n\n\n\n\n提示\n\n\n\n函数 bkde2D() 实现二维带窗宽的核密度估计（2D Binned Kernel Density Estimate），R 语言存在多个版本，grDevices 包的函数 densCols() 直接调用 KernSmooth 包的函数 bkde2D()，graphics 包的函数 smoothScatter() 与函数 densCols() 一样，内部也是调用 bkde2D() 函数，ggplot2 包的图层 geom_density_2d() 采用 MASS 包的函数 kde2d()，在算法实现上，MASS::kde2d() 与 KernSmooth::bkde2D() 不同，前者是二维核密度估计（Two-Dimensional Kernel Density Estimation）。Tarn Duong 的著作 《Multivariate Kernel Smoothing and Its Applications 》 (José. Chacón 2018) 对多元核平滑方法及其应用作了专门的论述，相关实现见书籍配套的 ks 包。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-china-household-sex",
    "href": "visualization-practice.html#sec-china-household-sex",
    "title": "12  探索实践",
    "section": "\n12.2 中国地区级男女性别比分布",
    "text": "12.2 中国地区级男女性别比分布\n图 12.2 (a) 展示 2020 年中国各省、自治区和直辖市分城市、镇和乡村的性别比数据。数据来自中国国家统计局发布的 2021 年统计年鉴，在数据量不太大的情况下，尽可能展示原始数据，可以捕捉到更加细致的差异。社会经济相关的数据常常显示有马太效应，对原始数据适当做一些变换有利于比较和展示数据，图 12.2 (b) 展示对数变换后的性别比数据的分布。大部分地区的性别比数据都在 100:100 左右，流动人口的性别比波动大很多。\n\n代码china_household_sex &lt;- readRDS(file = \"data/china-household-sex-2020.rds\")\nggplot(data = china_household_sex, aes(x = `户口登记状况`, y = `男性` / `女性`)) +\n  geom_jitter(aes(color = `区域`), width = 0.3) +\n  theme_classic()\n\nggplot(data = china_household_sex, aes(x = `户口登记状况`, y = `男性` / `女性`)) +\n  geom_jitter(aes(color = `区域`), width = 0.3) +\n  scale_y_continuous(trans = \"log10\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n(a) 原始性别比数据\n\n\n\n\n\n\n\n\n\n(b) 对数变换后的性别比数据\n\n\n\n\n\n图 12.2: 2020 年中国地区级男女性别比分布\n\n\n\n\n「住本乡、镇、街道，户口在本乡、镇、街道」土著和已获得当地户口的。性别比分布有明显的层次差异，性别比均值从大到小依次是城市、乡村、镇。城市里，男性略多于女性，镇里，男性明显少于女性，乡村里，男性略低于女性。\n「住本乡、镇、街道，户口待定」黑户或其它。性别比分布有明显的层次差异。同上。\n「住本乡、镇、街道，户口在外乡、镇、街道，离开户口登记地半年以上」流出人口，流出乡、镇、街道。城市、镇、乡村的性别比数据充分混合了，性别比分布没有明显的层次差异。\n「居住在港澳台或国外，户口在本乡、镇、街道」流出人口，流出国。同上。",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-usa-mortality",
    "href": "visualization-practice.html#sec-usa-mortality",
    "title": "12  探索实践",
    "section": "\n12.3 美国历年各年龄死亡率变化",
    "text": "12.3 美国历年各年龄死亡率变化\n\n图 12.3 展示美国 1933-2020 年男性分年龄的死亡率数据1。图分上下两部分，上半部分展示死亡率原值随年龄的变化情况，以 ggplot2 默认的调色板给各个年份配色，下半部分展示死亡率对数变换后随年龄的变化情况，并以红、橙、黄、绿、青、蓝、紫构造彩虹式的调色板给各个年份配色。作图过程中，使用对数变换和调用彩虹式的调色板，帮助我们观察到更多的细节、层次。对数变换后，更加清晰地展示死亡率的变化，尤其是 0-20 岁之间的死亡率起伏变化。调用彩虹式的调色板后，约 20 年为一个阶段，每个阶段内呈现梯度变化，多个阶段体现层次性，更加清晰地展示死亡率曲线的变动趋势。透过层次看到 80 多年来，美国在医疗和公共卫生方面取得的显著改善。\n\n代码usa_mortality &lt;- readRDS(file = \"data/usa-mortality-2020.rds\")\nlibrary(patchwork)\np1 &lt;- ggplot(data = usa_mortality, aes(x = Age, y = Male, group = Year)) +\n  geom_vline(xintercept = \"100\", colour = \"gray\", lty = 2) +\n  geom_line(aes(color = Year), linewidth = 0.25) +\n  scale_x_discrete(\n    breaks = as.character(20 * 0:5),\n    labels = as.character(20 * 0:5)\n  ) +\n  theme_classic() \np2 &lt;- p1 +\n  labs(x = \"年龄\", y = \"死亡率\", color = \"年份\")\np3 &lt;- p1 +\n  scale_y_log10(labels = scales::label_log()) +\n  scale_colour_gradientn(colors = RColorBrewer::brewer.pal(name = \"Spectral\", n = 11)) +\n  labs(x = \"年龄\", y = \"死亡率（对数尺度）\", color = \"年份\")\np2 / p3\n\n\n\n\n\n\n图 12.3: 1933-2020 年美国男性死亡率曲线\n\n\n\n\n图 12.3 也展示了很多基础信息，出生时有很高的死亡率，出生后死亡率迅速下降，一直到10岁，死亡率才又开始回升，直到 20 岁，死亡率才回到出生时的水平。之后，在青年阶段死亡率缓慢增加，直至老年阶段达到很高的死亡率水平。相比于老年阶段，医疗水平的改善作用主要体现在婴儿、儿童、青少年阶段。\n图 12.3 还展示了一个潜在的数据质量问题，在 100 岁之后，死亡率波动程度明显在变大，这是因为高龄人数变得很少，即死亡率的分母变得很小，分子的细小波动会被放大，也因为同样的原因，100 岁以上的死亡率主要依赖模型估计，甚至出现死亡率大于 1 的罕见情况。因此，就对比医疗和公共卫生水平的变化而言，从数据的实际情况出发，100 岁以上的情况可以不参与比较。\n图 12.4 以年份为横轴，以年龄为纵轴绘制网格，网格内部根据男性死亡率数据填充颜色制作热力图，死亡率数据是对数尺度，颜色的变化和死亡率的变化关系同前，采用了相同的调色板。更加深入的分析和建模，详见 Marron 和 Dryden (2022) 的第一章。\n\n代码ggplot(data = usa_mortality, aes(x = Year, y = Age, fill = Male)) +\n  scale_fill_gradientn(\n    colors = RColorBrewer::brewer.pal(name = \"Spectral\", n = 11),\n    trans = \"log10\", labels = scales::percent_format()\n  ) +\n  geom_tile(linewidth = 0.4) +\n  scale_y_discrete(\n    breaks = as.character(10 * 0:10),\n    labels = as.character(10 * 0:10),\n    expand = c(0, 0)\n  ) +\n  scale_x_continuous(\n    breaks = 1940 + 10 * 0:8,\n    labels = 1940 + 10 * 0:8,\n    expand = c(0, 0)\n  ) + \n  theme_classic() +\n  labs(x = \"年份\", y = \"年龄\", fill = \"死亡率\")\n\n\n\n\n\n\n图 12.4: 1933-2020 年美国男性死亡率热力图",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-virginia-deaths",
    "href": "visualization-practice.html#sec-virginia-deaths",
    "title": "12  探索实践",
    "section": "\n12.4 美国弗吉尼亚州城乡死亡率",
    "text": "12.4 美国弗吉尼亚州城乡死亡率\nVADeaths 数据来自 Base R 内置的 datasets 包，记录 1940 年美国弗吉尼亚州死亡率，如下表。\n\n\n\n表格 12.1: 1940 年美国弗吉尼亚州死亡率\n\n\n\n\n\n农村男\n农村女\n城市男\n城市女\n\n\n\n50-54\n11.7\n8.7\n15.4\n8.4\n\n\n55-59\n18.1\n11.7\n24.3\n13.6\n\n\n60-64\n26.9\n20.3\n37.0\n19.3\n\n\n65-69\n41.0\n30.9\n54.6\n35.1\n\n\n70-74\n66.0\n54.3\n71.1\n50.0\n\n\n\n\n\n\n\n\n死亡率数据是按年龄段、城乡、性别分组统计的，这是一个三因素交叉统计表，表格中第1行第1列的数据表示 50-54 岁乡村男性的死亡率为 11.7 ‰ ，即在 50-54 岁乡村男性群体中，1000 个人中死亡 11.7 个，这是抽样调查出来的数字。下图分年龄段、城乡、性别展示弗吉尼亚州死亡率数据，从图例来看，突出的是各年龄段的对比，图主要传递的信息是各年龄段的死亡率差异。无论城市还是乡村，也无论男性还是女性，年龄越大死亡率越高，这完全是一个符合生物规律的客观事实，这是众人皆知的，算不上洞见。\n\n代码dat &lt;- transform(expand.grid(\n  site = c(\"乡村\", \"城镇\"), sex = c(\"男\", \"女\"), \n  age = ordered(c(\"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\"))\n), deaths = as.vector(t(VADeaths)) / 1000)\n\nlibrary(ggplot2)\n# (\\u2030) 表示千分号\nggplot(data = dat, aes(x = sex, y = deaths, fill = age)) +\n  geom_col(position = \"dodge2\") +\n  scale_y_continuous(labels = scales::label_percent(scale = 1000, suffix = \"\\u2030\")) +\n  scale_fill_brewer(palette = \"Spectral\") +\n  facet_wrap(~site, ncol = 1) +\n  theme_bw(base_size = 13) +\n  labs(x = \"性别\", y = \"死亡率\", fill = \"年龄\")\n\n\n\n\n\n\n图 12.5: 弗吉尼亚州各年龄段死亡率的对比\n\n\n\n\n将对比对象从年龄段转变为城乡，描述城乡差距在死亡率上的体现，是不是一下子更深刻了呢？城市降低各个年龄段的死亡率，暗示着城市的居住条件、医疗水平比乡村好，提高城市化率增加全民的寿命。严格来说，就这个粗糙的数据集不能如此快地下这个结论，但是，它暗示这个信息，同样也符合人们的常识。\n\n代码ggplot(data = dat, aes(x = age, y = deaths, fill = site)) +\n  geom_col(position = \"dodge2\") +\n  scale_y_continuous(labels = scales::label_percent(scale = 1000, suffix = \"\\u2030\")) +\n  scale_fill_brewer(palette = \"Spectral\") +\n  facet_wrap(~sex, ncol = 1) +\n  theme_bw(base_size = 13) +\n  labs(x = \"年龄\", y = \"死亡率\", fill = \"城乡\")\n\n\n\n\n\n\n图 12.6: 弗吉尼亚州城乡死亡率的对比",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-diamonds-distr",
    "href": "visualization-practice.html#sec-diamonds-distr",
    "title": "12  探索实践",
    "section": "\n12.5 如何用图表示累积概率分布",
    "text": "12.5 如何用图表示累积概率分布\n不失一般性，考虑连续随机变量的条件分布和累积分布。不妨设随机变量 \\(x\\) 的概率分布函数和概率密度函数分别是 \\(F(x)\\) 和 \\(f(x)\\) 。已知概率分布函数和概率密度函数之间有如下关系。\n\\[\nF(x) = \\int_{-\\infty}^{x} f(t) \\mathrm{dt}\n\\]\ndiamonds 数据来自 ggplot2 包，记录了约 54000 颗钻石的价格、重量、切工、颜色、纯净度、尺寸等属性信息。图 12.7 展示这批不同切工的钻石随价格的分布，在这个示例中，如何表达累积分布？概率分布的密度曲线是根据直方图估计得来的，根据不同价格区间内钻石的数量占总钻石的比例估计概率。固定窗宽，即在同一价格区间内累积不同切工的钻石数量，得到累积概率，最后获得累积概率密度曲线，更多理论细节见数据可视化陷阱 (Pu 和 Kay 2020) 。\n\n代码library(ggplot2)\nlibrary(patchwork)\np1 &lt;- ggplot(diamonds, aes(x = price, y = after_stat(density), fill = cut)) +\n  geom_density(position = \"stack\", colour = \"white\") +\n  scale_fill_brewer(palette = \"Spectral\") +\n  scale_y_continuous(\n    labels = expression(0, 5~\"·\"~10^-4, 10 ~ \"·\" ~ 10^-4, 15 ~ \"·\" ~ 10^-4),\n    breaks = c(0, 5, 10, 15) * 10^(-4)\n  ) +\n  theme_bw(base_family = \"Noto Serif CJK SC\") +\n  labs(x = \"价格\", y = \"概率密度\", fill = \"切工\", tag = \"坏\") +\n  theme(\n    axis.text.x = element_text(family = \"sans\", color = \"black\"),\n    axis.text.y = element_text(\n      family = \"sans\", color = \"black\",\n      angle = 90, vjust = 1.5, hjust = 0.5\n    ),\n    legend.text = element_text(family = \"sans\"),\n    plot.tag = element_text(family = \"Noto Serif CJK SC\", color = \"red\"),\n    plot.tag.position = \"topright\"\n  )\n\np2 &lt;- ggplot(diamonds, aes(x = price, y = after_stat(density * n), fill = cut)) +\n  geom_density(position = \"stack\", colour = \"white\") +\n  scale_fill_brewer(palette = \"Spectral\") +\n  theme_bw(base_family = \"Noto Serif CJK SC\") +\n  labs(x = \"价格\", y = \"概率质量\", fill = \"切工\", tag = \"好\") +\n  theme(\n    axis.text.x = element_text(family = \"sans\", color = \"black\"),\n    axis.text.y = element_text(\n      family = \"sans\", color = \"black\",\n      angle = 90, vjust = 1.5, hjust = 0.5\n    ),\n    legend.text = element_text(family = \"sans\"),\n    plot.tag = element_text(family = \"Noto Serif CJK SC\", color = \"black\"),\n    plot.tag.position = \"topright\"\n  )\n\np1 / p2\n\n\n\n\n\n\n图 12.7: 不同切工的钻石随价格的分布",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-confidence-belt",
    "href": "visualization-practice.html#sec-confidence-belt",
    "title": "12  探索实践",
    "section": "\n12.6 解释二项总体参数的置信带",
    "text": "12.6 解释二项总体参数的置信带\n0 和 1 是世界的原点，蕴含大道真意，从 0-1 分布也叫伯努利分布，独立同 0-1分布之和可以衍生出二项分布。在一定条件下，可以用泊松分布近似二项分布。根据中心极限定理，独立同二项分布的极限和与正态分布可以发生关系。在二项分布、正态分布的基础上，可以衍生出超几何分布、贝塔分布等等。本书多个地方以二项分布为例介绍基本统计概念和模型。\n在给定置信水平为 0.95，即 \\(\\alpha = 0.05\\)，固定样本量 \\(n = 10\\)，观测到的成功次数 \\(x\\) 可能为 \\(0,1,\\cdots,10\\)。对于给定的 \\(p\\)，不同 \\(x\\) 值出现的机率 \\(P(X = x)\\) 由 \\((p + q)^{10}\\) 二项展开式的项给出，这里 \\(q = 1-p\\)，即：\n\\[\nP(X = x) = \\binom{n}{x}p^x(1-p)^{n-x}\n\\tag{12.1}\\]\n在给定 \\(p = 0.1\\) 的情况下，求二项分布的上 \\(\\alpha/2 = 0.025\\) 分位点，尾项之和不应超过 \\(\\alpha/2\\)，最大的 \\(x\\) 值可有如下方程给出：\n\\[\n\\sum_{r = x}^{n}\\binom{n}{x}p^x(1-p)^{n-x} = \\frac{\\alpha}{2}\n\\tag{12.2}\\]\n在 R 语言中，函数 qbinom() 可以计算上述二项分布的上分位点 \\(x = 3\\)，即\n\nqbinom(0.025, size = 10, prob = 0.1, lower.tail = F)\n\n#&gt; [1] 3\n\n\n反过来，若已知上分位点为 \\(x = 3\\)，则概率为\n\\[\nP(X &gt; 3) = \\sum_{x &gt; 3}^{10}\\binom{10}{x}0.1^x*(1-0.1)^{10-x}\n\\tag{12.3}\\]\n在 R 语言中，函数 pbinom() 可以计算上述二项分布的上分位点对应的概率为 \\(0.0127952\\)。\n\npbinom(q = 3, size = 10, prob = 0.1, lower.tail = F)\n\n#&gt; [1] 0.0127952\n\n\n首先简单回顾一下置信区间，在学校和教科书里，有两种说法如下：\n\n\n\\(1-\\alpha\\) 的把握确定区间包含真值。\n区间包含真值的概率是 \\(1-\\alpha\\)。\n\n为什么要采纳第一种说法而不是第二种呢？这其实涉及到置信区间的定义问题，历史上 E. S. Pearson 和 R. A. Fisher 曾有过争论。和大多数以正态分布为例介绍参数的置信估计不同，下面以二项分布为例展开介绍。我们知道二项分布是 N 个伯努利分布的卷积，而伯努利分布又称为 0-1 分布，最形象的例子要数抛硬币了，反复投掷硬币，将正面朝上记为 1，反面朝上记为 0，记录正反面出现的次数，正面朝上的总次数又叫成功次数。\n1934 年 C. J. Clopper 和 E. S. Pearson 在给定置信水平 \\(1- \\alpha = 0.95\\) 和样本量 \\(n = 10\\) 的情况下，给出二项分布 \\(B(n, p)\\) 参数 \\(p\\) 的区间估计（即所谓的 Clopper-Pearson 精确区间估计）和置信带 (Clopper 和 Pearson 1934)，如 图 12.8 所示，横坐标为观测到的成功次数，纵坐标为参数 \\(p\\) 的置信限。具体来说，固定样本量为 10，假定观测到的成功次数为 2，在置信水平为 0.95 的情况下，Base R 内置的二项精确检验函数 binom.test()，可以获得参数 \\(p\\) 的精确区间估计为 \\((p_1, p_2) = (0.025, 0.556)\\)，即：\n\n# 精确二项检验 p = 0.2\nbinom.test(x = 2, n = 10, p = 0.2)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  2 and 10\n#&gt; number of successes = 2, number of trials = 10, p-value = 1\n#&gt; alternative hypothesis: true probability of success is not equal to 0.2\n#&gt; 95 percent confidence interval:\n#&gt;  0.02521073 0.55609546\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                    0.2\n\n\n值得注意，这个估计的区间与函数 binom.test() 中参数 p 的取值无关，也就是说，当 \\(p = 0.4\\)，区间估计结果是一样的，如下：\n\n# 精确二项检验 p = 0.4\nbinom.test(x = 2, n = 10, p = 0.4)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  2 and 10\n#&gt; number of successes = 2, number of trials = 10, p-value = 0.3335\n#&gt; alternative hypothesis: true probability of success is not equal to 0.4\n#&gt; 95 percent confidence interval:\n#&gt;  0.02521073 0.55609546\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                    0.2\n\n\n由此，也可以看出区间估计与假设检验的一些关系。\n\n\n代码library(rootSolve) # uniroot.all\noptions(digits = 4)\n# r 为上分位点\np_fun &lt;- function(p, r = 9) qbinom(0.025, size = 10, prob = p, lower.tail = F) - r # 上分位点\nl_fun &lt;- function(p, r = 9) qbinom(0.025, size = 10, prob = p, lower.tail = T) - r # 下分位点\n\n# 计算每个分位点对应的最小的概率 p\np &lt;- sapply(0:10, function(x) min(uniroot.all(p_fun, lower = 0, upper = 1, r = x)))\n\n# 计算每个分位点对应的最大的概率 l\nl &lt;- sapply(0:10, function(x) max(uniroot.all(l_fun, lower = 0, upper = 1, r = x)))\n\nplot(\n  x = seq(from = 0, to = 10, length.out = 11),\n  y = seq(from = 0, to = 1, length.out = 11),\n  type = \"n\", ann = FALSE, family = \"sans\", panel.first = grid()\n)\ntitle(xlab = \"成功次数\", ylab = \"置信限\", family = \"Noto Serif CJK SC\")\nlines(x = 0:10, y = p, type = \"s\") # 朝下的阶梯线\nlines(x = 0:10, y = p, type = \"l\") # 折线\n# points(x = 0:10, y = p, pch = 16, cex = .8) # 散点\n\n# abline(a = 0, b = 0.1, col = \"gray\", lwd = 2, lty = 2) # 添加对称线\ntext(x = 5, y = 0.5, label = \"置信带\", cex = 1.5, srt = 45, family = \"Noto Serif CJK SC\")\n# points(x = 5, y = 0.5, col = \"black\", pch = 16) # 中心对称点\n# points(x = 5, y = 0.5, col = \"black\", pch = 3) # 中心对称点\n\nlines(x = 0:10, y = l, type = \"S\") # 朝上的阶梯线\nlines(x = 0:10, y = l, type = \"l\") # 折线\n# points(x = 0:10, y = l, pch = 16, cex = .8) # 散点\n\npoints(x = c(2, 2), y = c(0.03, 0.55), pch = 8, col = \"black\")\ntext(x = 2, y = 0.55, labels = expression(p[2]), pos = 1)\ntext(x = 2, y = 0.03, labels = expression(p[1]), pos = 3)\n\n\n\n\n\n\n图 12.8: 二项分布参数的置信带",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-coverage-probability",
    "href": "visualization-practice.html#sec-coverage-probability",
    "title": "12  探索实践",
    "section": "\n12.7 解释置信区间及其覆盖概率",
    "text": "12.7 解释置信区间及其覆盖概率\n\n统计图形很重要的一个作用是解释统计概念，这就要求不拘泥于抽象的严格数学表达，借助数值模拟，可视化等手段帮助读者发散思维，加深理解复杂的逻辑概念，建立统计直觉，正如顾恺之所言「以形写神，形神兼备」。下面仅以二项分布为例讲讲区间估计及其覆盖概率。众所周知，在置信水平为 \\(1 - \\alpha\\) 的情况下，二项分布 \\(\\mathrm{Bin}(n,p)\\) 的参数 \\(p\\) （也叫成功概率）的 Wald 区间估计为\n\\[\n(\\hat{p} - Z_{1-\\alpha/2} \\sqrt{\\hat{p}*(1-\\hat{p})/n}, \\hat{p} + Z_{1-\\alpha/2} \\sqrt{\\hat{p}*(1-\\hat{p})/n})\n\\tag{12.4}\\]\n其中，\\(n\\) 为样本量，\\(Z_{1-\\alpha/2}\\) 为标准正态分布 \\(\\mathcal{N}(0,1)\\) 在 \\(1-\\alpha/2\\) 处的分位点。 \\(\\alpha\\) 一般取 0.05，进而 \\(Z_{1-\\alpha/2} \\approx 1.96\\)。用通俗的话说，有 \\(1 - \\alpha\\) 的把握确定参数真值 \\(p\\) 在该估计区间内。可见区间估计的意义是解决点估计可靠性问题，但是可靠性和精度往往不能兼得。统计上，通常的做法是先给定可靠性，去尽可能提升精度，即给定置信水平，使估计区间的长度尽可能短，这就涉及到区间估计的方法问题。\n下面通过数值模拟的方式辅助说明 Wald 和 Agresti-Coull 两种区间估计方法，现固定样本量 \\(n = 10\\) 或 \\(n = 100\\)，重复抽样 1000 次，将参数 \\(p\\) 以 0.01 的间隔离散化，从 0.01 取值到 0.99。已知给定参数 \\(p\\)，每次抽样都可以得到参数 \\(p\\) 的估计值 \\(\\hat{p}\\) 及其置信区间，1000 次的重复抽样可以计算出来 1000 个置信区间，每个区间要么覆盖真值，要么没有覆盖真值，覆盖的比例可以近似为覆盖概率。\n如 图 12.9 所示，从上往下分别代表 Wald、 Agresti-Coull、 Wilson 和 Clopper-Pearson 区间估计，纵坐标是覆盖概率，横坐标是参数 \\(p\\) 的真值，图中黑虚线表示置信水平 \\(1-\\alpha=0.95\\)，红、蓝点线分别表示样本量 \\(n=10\\) 和 \\(n=100\\) 的模拟情况。不难看出，Wald 区间估计方法在小样本情况下表现很差，覆盖概率很少能达到置信水平的，而 Agresti-Coull 区间估计在 Wald 基础上添加了修正后，情况得到显著改善。更多区间估计方法的详细比较见文献 Blyth 和 Hutchinson (1960);Brown, Cai, 和 DasGupta (2001);Geyer 和 Meeden (2005) 。\n\n代码# 计算覆盖概率\n# Wald 覆盖\ncoverage_wald &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  phats &lt;- rbinom(nsim, prob = p, size = n) / n\n  ll &lt;- phats - qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  ul &lt;- phats + qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  mean(ll &lt; p & ul &gt; p)\n}\n# Agresti-Coull 覆盖\ncoverage_agresti &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  phats &lt;- (rbinom(nsim, prob = p, size = n) + 2) / (n + 4)\n  ll &lt;- phats - qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  ul &lt;- phats + qnorm(1 - 0.05 / 2) * sqrt(phats * (1 - phats) / n)\n  mean(ll &lt; p & ul &gt; p)\n}\n# Clopper and Pearson (1934)\n# 与 binom.test() 计算结果一致\ncoverage_clopper &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  nd &lt;- rbinom(nsim, prob = p, size = n)\n  ll &lt;- qbeta(p = 0.05 / 2, shape1 = nd, shape2 = n - nd + 1)\n  ul &lt;- qbeta(p = 1 - 0.05 / 2, shape1 = nd + 1, shape2 = n - nd)\n  mean(ll &lt; p & ul &gt; p)\n}\n# Wilson (1927)\n# 与 prop.test(correct = FALSE) 计算结果一致\ncoverage_wilson &lt;- function(p = 0.1, n = 10, nsim = 1000) {\n  phats &lt;- rbinom(nsim, prob = p, size = n) / n\n  lambda &lt;- qnorm(1 - 0.05 / 2)\n  ll &lt;- phats + lambda^2 / (2 * n) - lambda * sqrt(phats * (1 - phats) / n + lambda^2 / (4 * n^2))\n  ul &lt;- phats + lambda^2 / (2 * n) + lambda * sqrt(phats * (1 - phats) / n + lambda^2 / (4 * n^2))\n  mean(ll / (1 + lambda^2 / n) &lt; p & ul / (1 + lambda^2 / n) &gt; p)\n}\n\nsim_dat &lt;- transform(expand.grid(\n  p = seq(0.01, 0.99, by = 0.01),\n  n = c(10, 100),\n  nsim = 1000,\n  methods = c(\"Wald\", \"Agresti-Coull\", \"Wilson\", \"Clopper-Pearson\")\n), prob = ifelse(methods == \"Wald\",\n  Vectorize(coverage_wald)(p = p, n = n, nsim = nsim),\n  ifelse(methods == \"Agresti-Coull\",\n    Vectorize(coverage_agresti)(p = p, n = n, nsim = nsim),\n    ifelse(methods == \"Wilson\",\n      Vectorize(coverage_wilson)(p = p, n = n, nsim = nsim),\n      Vectorize(coverage_clopper)(p = p, n = n, nsim = nsim)\n    )\n  )\n), nsample = ifelse(n == 10, \"n=10\", \"n=100\"))\n\nggplot(data = sim_dat, aes(x = p, y = prob, color = nsample)) +\n  geom_hline(yintercept = 0.95, linetype = 2, \n             linewidth = 1, color = \"gray60\") +\n  geom_point() +\n  geom_path() +\n  # annotate(geom = \"text\", x = 0, y = 0.95, label = \"0.950\",\n  #          fontface = \"bold\", hjust = 2, size = 3.5) +\n  # scale_color_grey() +\n  scale_color_brewer(palette = \"Set1\") +\n  facet_wrap(facets = ~methods, ncol = 1, scales = \"free_y\") +\n  labs(x = \"成功概率\", y = \"覆盖概率\", color = \"样本量\") +\n  theme_bw(base_size = 13, base_family = \"sans\") +\n  theme(title = element_text(family = \"Noto Serif CJK SC\")) + \n  coord_cartesian(clip = 'off')\n\n\n\n\n\n\n图 12.9: 二项分布参数的几种区间估计：覆盖概率随成功概率的变化\n\n\n\n\n通过 图 12.9 一看就明白了几种区间估计方法的优劣，以及为什么软件普遍默认采用 Wilson 估计方法？因为它又稳定又准确。 Wilson 区间估计用的更加广泛的，Base R 内置的比例检验函数 prop.test() 在不启用 Yates 修正时，就是用该方法获得比例 \\(p\\) 的区间估计 (Wilson 1927)。Clopper-Pearson 区间估计特别适合小样本情形，它是精确区间估计方法，Base R 内置的二项比例检验函数 binom.test() 就是用该方法获得比例 \\(p\\) 的区间估计(Clopper 和 Pearson 1934)。\n\n\n\n\n\n\n提示\n\n\n\n请读者再思考两个问题： 图 12.9 为什么呈现对称的形式，泊松分布会和二项分布有类似的现象吗？如果有的话，连续分布，如正态分布和指数分布也会有吗？",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#sec-exercise-practice",
    "href": "visualization-practice.html#sec-exercise-practice",
    "title": "12  探索实践",
    "section": "\n12.8 习题",
    "text": "12.8 习题\n\n1888 年，瑞士开始进入一个人口转变的阶段，从发展中国家的高出生率开始下滑。分析生育率和经济指标的关系。数据集 swiss 记录了 1888 年瑞士 47 个说法语的省份的生育率和社会经济指标数据。Fertility（生育率，采用常见的标准生育率统计口径）、Agriculture（男性从事农业生产的比例）、Examination（应征者在军队考试中获得最高等级的比例）、Education（应征者有小学以上教育水平的比例）、Catholic（信仰天主教的比例）、Infant.Mortality（婴儿死亡率，仅考虑出生一年内死亡），各个指标都统一标准化为百分比的形式。其中，Examination 和 Education 是 1887 年、1888 年和 1889 年的平均值。瑞士 182 个地区 1888 年及其它年份的数据可从网站获得。\n\n\n\n\n\nBlyth, Colin R., 和 David W. Hutchinson. 1960. 《Table of Neyman-Shortest Unbiased Confidence Intervals for the Binomial Parameter》. Biometrika 47 (3/4): 381–91. https://www.jstor.org/stable/2333308.\n\n\nBrown, Lawrence D., T. Tony Cai, 和 Anirban DasGupta. 2001. 《Interval Estimation for a Binomial Proportion》. Statistical Science, 期 2: 101–33. https://projecteuclid.org/euclid.ss/1009213286.\n\n\nClopper, C. J., 和 E. S. Pearson. 1934. 《The Use of Confidence or Fiducial Limits Illustrated In The Case of The Binomial》. Biometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nGeyer, Charles J., 和 Glen D. Meeden. 2005. 《Fuzzy and Randomized Confidence Intervals and P-Values》. Statistical Science 20 (4): 358–66. https://www.jstor.org/stable/20061193.\n\n\nJosé. Chacón, Tarn Duong. 2018. Multivariate Kernel Smoothing and Its Applications. Boca Raton, Florida: Chapman; Hall/CRC. https://www.mvstat.net/mvksa/.\n\n\nMarron, J. S., 和 Ian L. Dryden. 2022. Object Oriented Data Analysis. 1st 本. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nPu, Xiaoying, 和 Matthew Kay. 2020. 《A Probabilistic Grammar of Graphics》. 收入 Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1–13. ACM. https://doi.org/10.1145/3313831.3376466.\n\n\nWand, M. P., 和 M. C. Jones. 1995. Kernel Smoothing. 1st 本. Boca Raton, Florida: Chapman; Hall/CRC. http://matt-wand.utsacademics.info/webWJbook/.\n\n\nWilson, Edwin B. 1927. 《Probable inference, the law of succession, and statistical inference》. Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "visualization-practice.html#footnotes",
    "href": "visualization-practice.html#footnotes",
    "title": "12  探索实践",
    "section": "",
    "text": "数据来自德国马克斯普朗克人口研究所、美国加州大学伯克利分校、法国人口研究所共同建立的人类死亡率数据库 (https://www.mortality.org/)。↩︎",
    "crumbs": [
      "数据探索",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>探索实践</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html",
    "href": "interactive-graphics.html",
    "title": "13  交互图形",
    "section": "",
    "text": "13.1 基础元素",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-interactive-elements",
    "href": "interactive-graphics.html#sec-interactive-elements",
    "title": "13  交互图形",
    "section": "",
    "text": "13.1.1 图层\nplotly 包封装了许多图层函数，可以绘制各种各样的统计图形，见下 表格 13.1 。\n\n\n表格 13.1: plotly 包可以绘制丰富的统计图形\n\n\n\nadd_annotations\nadd_histogram\nadd_polygons\n\n\nadd_area\nadd_histogram2d\nadd_ribbons\n\n\nadd_bars\nadd_histogram2dcontour\nadd_scattergeo\n\n\nadd_boxplot\nadd_image\nadd_segments\n\n\nadd_choropleth\nadd_lines\nadd_sf\n\n\nadd_contour\nadd_markers\nadd_surface\n\n\nadd_data\nadd_mesh\nadd_table\n\n\nadd_fun\nadd_paths\nadd_text\n\n\nadd_heatmap\nadd_pie\nadd_trace\n\n\n\n\n\n下面以散点图为例，使用方式非常类似 ggplot2 包，函数 plot_ly() 类似 ggplot()，而函数 add_markers() 类似 geom_point()，效果如 图 13.1 所示。\n\n# https://plotly.com/r/reference/scatter/\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers()\n\n\n\n\n\n\n\n\n图 13.1: 默认风格的简单散点图\n\n\n\n\n或者使用函数 add_trace()，层层添加图形元素，效果和上 图 13.1 是一样的。\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_trace(type = \"scatter\", mode = \"markers\")\n\n\n\n\n\n\n\n提示\n\n\n\nplotly 包的函数 plot_ly() 又与 ggplot2 包中函数 qplot() 类似，可以将大部分设置塞进去。\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  type = \"scatter\", mode = \"markers\"\n)\n\n所以，总的来说， add_markers() 、add_trace(type = \"scatter\", mode = \"markers\") 和 plot_ly(type = \"scatter\", mode = \"markers\") 是等价的。\n\n\n\n13.1.2 配色\n在 图 13.1 的基础上，将颜色映射到震级变量上。\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers(color = ~mag)\n\n\n\n\n\n\n图 13.2: 给散点图配色\n\n\n\n\n13.1.3 刻度\n东经和南纬\n\nplotly::plot_ly(data = quakes, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers(color = ~mag) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\", ticksuffix = 'E'),\n    yaxis = list(title = \"纬度\", ticksuffix = 'S')\n  )\n\n\n\n\n\n\n图 13.3: 设置刻度及标签\n\n\n\n\n13.1.4 标签\n添加横轴、纵轴以及主副标题\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  marker = list(\n    color = ~mag,\n    colorscale = \"Viridis\",\n    colorbar = list(title = list(text = \"震级\"))\n  )\n) |&gt;\n  plotly::add_markers() |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\"),\n    title = \"斐济及其周边地区的地震活动\"\n  )\n\n\n\n\n\n\n图 13.4: 添加各处标题\n\n\n\n\n13.1.5 主题\nplotly 内置了一些主题风格\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  marker = list(\n    color = ~mag,\n    colorscale = \"Viridis\",\n    colorbar = list(title = list(text = \"震级\"))\n  )\n) |&gt;\n  plotly::add_markers() |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\"),\n    title = \"斐济及其周边地区的地震活动\"\n  )\n\n\n\n\n\n\n图 13.5: 设置主题风格\n\n\n\n\n13.1.6 字体\n\n13.1.7 图例",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-plotly-common-graphics",
    "href": "interactive-graphics.html#sec-plotly-common-graphics",
    "title": "13  交互图形",
    "section": "\n13.2 常用图形",
    "text": "13.2 常用图形\n\n13.2.1 散点图\nplotly 包支持绘制许多常见的散点图，从直角坐标系 scatter 到极坐标系 scatterpolar 和地理坐标系 scattergeo，从二维平面 scatter 到三维空间 scatter3d，借助 WebGL 可以渲染大规模的数据点 scattergl。\n\n\n表格 13.2: plotly 包支持绘制的散点图类型\n\n\n\n类型\n名称\n\n\n\nscatter\n二维平面散点图\n\n\nscatter3d\n三维立体散点图\n\n\nscattergl\n散点图（WebGL 版）\n\n\nscatterpolar\n极坐标下散点图\n\n\nscatterpolargl\n极坐标下散点图（WebGL 版）\n\n\nscattergeo\n地理坐标下散点图\n\n\nscattermapbox\n地理坐标下散点图（MapBox 版）\n\n\nscattercarpet\n地毯图\n\n\nscatterternary\n三元图\n\n\n\n\n\n\n图 13.6 展示斐济及其周边的地震分布\n\nplotly::plot_ly(\n  data = quakes, x = ~long, y = ~lat,\n  type = \"scatter\", mode = \"markers\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"经度\"),\n    yaxis = list(title = \"纬度\")\n  )\n\n\n\n\n\n\n\n\n图 13.6: 普通散点图\n\n\n\n\n\n13.2.2 柱形图\n\n# https://plotly.com/r/reference/bar/\nplotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"bar\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\n\n\n\n\n\n图 13.7: 柱形图\n\n\n\n\n13.2.3 曲线图\n\nplotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"scatter\",\n  mode = \"markers+lines\", line = list(shape = \"spline\")\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\n\n\n\n\n\n图 13.8: 曲线图\n\n\n\n\n13.2.4 直方图\n地震次数随震级的分布变化，下 图 13.9 为频数分布图\n\n# https://plotly.com/r/reference/histogram/\nplotly::plot_ly(quakes, x = ~mag, type = \"histogram\") |&gt; \n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"次数\")\n  )\n\n\n\n\n\n\n\n\n图 13.9: 地震震级的频数分布图\n\n\n\n\n地震震级的概率分布，下 图 13.10 为频率分布图\n\nplotly::plot_ly(\n  data = quakes, x = ~mag, type = \"histogram\",\n  histnorm = \"probability\",\n  marker = list(\n    color = \"lightblue\",\n    line = list(color = \"white\", width = 2)\n  )\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"频率\")\n  )\n\n\n\n\n\n\n\n\n图 13.10: 地震震级的频率分布图\n\n\n\n\nhistnorm = \"probability\" 意味着纵轴表示频率，即每个窗宽下地震次数占总地震次数的比例。地震常常发生在地下，不同的深度对应着不同的地质构造、不同的地震成因，下 图 13.11 展示海平面下不同深度的地震震级分布。\n\nquakes$depth_bin &lt;- cut(quakes$depth, breaks = 150 * 0:5)\n\n\nplotly::plot_ly(quakes,\n  x = ~mag, colors = \"viridis\",\n  color = ~depth_bin, type = \"histogram\"\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"震级\"),\n    yaxis = list(title = \"次数\")\n  )\n\n\n\n\n\n\n\n\n图 13.11: 地震震级的频率分布图\n\n\n\n\n\n13.2.5 箱线图\n\nplotly::plot_ly(quakes,\n  x = ~depth_bin, y = ~mag, colors = \"viridis\",\n  color = ~depth_bin, type = \"box\"\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"深度\"),\n    yaxis = list(title = \"震级\")\n  )\n\n\n\n\n\n\n图 13.12: 不同深度下地震震级的分布\n\n\n\n\nplotly::plot_ly(quakes,\n  x = ~depth_bin, y = ~mag, split = ~depth_bin,\n  type = \"violin\", color = ~depth_bin, colors = \"viridis\",\n  box = list(visible = TRUE),\n  meanline = list(visible = TRUE)\n) |&gt; \n  plotly::layout(\n    xaxis = list(title = \"深度\"),\n    yaxis = list(title = \"震级\")\n  )\n\n\n\n\n\n\n图 13.13: 不同深度下地震震级的分布\n\n\n\n\n13.2.6 热力图\nplotly 整合了开源的 Mapbox GL JS，可以使用 Mapbox 提供的瓦片地图服务（Mapbox Tile Maps），对空间点数据做核密度估计，展示热力分布，如 图 13.14 所示。图左上角为所罗门群岛（Solomon Islands）、瓦努阿图（Vanuatu）和新喀里多尼亚（New Caledonia），图下方为新西兰北部的威灵顿（Wellington）和奥克兰（Auckland），图中部为斐济（Fiji）。\n\nplotly::plot_ly(\n  data = quakes, lat = ~lat, lon = ~long, radius = 10,\n  type = \"densitymapbox\", coloraxis = \"coloraxis\"\n) |&gt;\n  plotly::layout(\n    mapbox = list(\n      style = \"stamen-terrain\", zoom = 3,\n      center = list(lon = 180, lat = -25)\n    ),\n    coloraxis = list(colorscale = \"Viridis\")\n  )\n\n\n\n\n\n\n\n\n图 13.14: 空间点数据的核密度估计\n\n\n\n\n图中设置瓦片地图的风格 style 为 \"stamen-terrain\"，还可以使用其他开放的栅格瓦片地图服务，比如 \"open-street-map\" 和 \"carto-positron\"。如果使用 MapBox 提供的矢量瓦片地图服务，则需要访问令牌 Mapbox Access Token。图中设置中心坐标 center 以及缩放倍数 zoom，目的是突出图片中的数据区域。设置调色板 Viridis 展示热力分布，黄色团块的地方表示地震频次高。\n\n13.2.7 面量图\n在之前我们介绍过用 ggplot2 绘制地区分布图，实际上，地区分布图还有别名，如围栏图、面量图等。本节使用 plotly 绘制交互式的地区分布图，如 图 13.15 所示。\n\n# https://plotly.com/r/reference/choropleth/\ndat &lt;- data.frame(state.x77,\n  stats = rownames(state.x77),\n  stats_abbr = state.abb\n)\n# 绘制图形\nplotly::plot_ly(\n  data = dat,\n  type = \"choropleth\",\n  locations = ~stats_abbr,\n  locationmode = \"USA-states\",\n  colorscale = \"Viridis\",\n  colorbar = list(title = list(text = \"人均收入\")),\n  z = ~Income\n) |&gt;\n  plotly::layout(\n    geo = list(scope = \"usa\"),\n    title = \"1974年美国各州的人均收入\"\n  )\n\n\n\n\n\n\n\n\n图 13.15: 1974 年美国各州的人均收入\n\n\n\n\n\n13.2.8 动态图\n本节参考 plotly 包的官方示例渐变动画，数据来自 SVN 代码提交日志，统计 Martin Maechler 和 Brian Ripley 的年度代码提交量，他们是 R Core Team 非常重要的两位成员，长期参与维护 R 软件及社区。下图展示 1999-2022 年 Martin Maechler 和 Brian Ripley 的代码提交量变化。\n\n# https://plotly.com/r/animations/\ntrunk_year_author &lt;- aggregate(data = svn_trunk_log, revision ~ year + author, FUN = length)\n# https://plotly.com/r/cumulative-animations/\naccumulate_by &lt;- function(dat, var) {\n  var &lt;- lazyeval::f_eval(f = var, data = dat)\n  lvls &lt;- plotly:::getLevels(var) \n  dats &lt;- lapply(seq_along(lvls), function(x) {\n    cbind(dat[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])\n  })\n  dplyr::bind_rows(dats)\n}\n\nsubset(trunk_year_author, year &gt;= 1999 & author %in% c(\"ripley\", \"maechler\")) |&gt;\n  accumulate_by(~year) |&gt;\n  plotly::plot_ly(\n    x = ~year, y = ~revision, split = ~author,\n    frame = ~frame, type = \"scatter\", mode = \"lines\",\n    line = list(simplyfy = F)\n  ) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  ) |&gt;\n  plotly::animation_opts(\n    frame = 100, transition = 0, redraw = FALSE\n  ) |&gt;\n  plotly::animation_button(\n    visible = TRUE, # 显示播放按钮\n    label = \"播放\", # 按钮文本\n    font = list(color = \"gray\")# 文本颜色\n  ) |&gt;\n  plotly::animation_slider(\n    currentvalue = list(\n      prefix = \"年份 \",\n      xanchor = \"right\",\n      font = list(color = \"gray\", size = 30)\n    )\n  )\n\n\n\n\n\n\n图 13.16: 1999-2022 年 Martin Maechler 和 Brian Ripley 的代码提交量变化\n\n\n\nlazyeval 的非标准计算采用 Base R 实现，目前，已经可以被 rlang 替代。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-graphics.html#sec-plotly-common-tricks",
    "href": "interactive-graphics.html#sec-plotly-common-tricks",
    "title": "13  交互图形",
    "section": "\n13.3 常用技巧",
    "text": "13.3 常用技巧\n\n13.3.1 数学公式\n正态分布的概率密度函数形式如下：\n\\[\n\\begin{aligned}\n& f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\{-\\frac{(x -\\mu)^2}{2\\sigma^2}\\}\n\\end{aligned}\n\\]\n下图展示两个正态分布，分别是 \\(\\mathcal{N}(3, 1^2)\\) 和 \\(\\mathcal{N}(2, 1.5^2)\\) 。函数 plotly::TeX() 包裹 LaTeX 书写的数学公式，plotly 包调用 MathJax 库渲染图中的公式符号。\n\n代码x &lt;- seq(from = -4, to = 8, length.out = 193)\ny1 &lt;- dnorm(x, mean = 3, sd = 1)\ny2 &lt;- dnorm(x, mean = 2, sd = 1.5)\n\nplotly::plot_ly(\n  x = x, y = y1, type = \"scatter\", mode = \"lines\",\n  fill = \"tozeroy\", fillcolor = \"rgba(0, 204, 102, 0.2)\",\n  text = ~ paste0(\n    \"x：\", x, \"&lt;br&gt;\",\n    \"y：\", round(y1, 3), \"&lt;br&gt;\"\n  ),\n  hoverinfo = \"text\",\n  name = plotly::TeX(\"\\\\mathcal{N}(3,1^2)\"),\n  line = list(shape = \"spline\", color = \"#009B95\")\n) |&gt; \n  plotly::add_trace(\n    x = x, y = y2, type = \"scatter\", mode = \"lines\",\n    fill = \"tozeroy\", fillcolor = \"rgba(51, 102, 204, 0.2)\",\n    text = ~ paste0(\n      \"x：\", x, \"&lt;br&gt;\",\n      \"y：\", round(y2, 3), \"&lt;br&gt;\"\n    ),\n    hoverinfo = \"text\",\n    name = plotly::TeX(\"\\\\mathcal{N}(2, 1.5^2)\"),\n    line = list(shape = \"spline\", color = \"#403173\")\n  ) |&gt; \n  plotly::layout(\n    xaxis = list(showgrid = F, title = plotly::TeX(\"x\")),\n    yaxis = list(showgrid = F, title = plotly::TeX(\"f(x)\")),\n    legend = list(x = 0.8, y = 1, orientation = \"v\")\n  ) |&gt; \n  plotly::config(mathjax = \"cdn\", displayModeBar = FALSE)\n\n\n\n\n\n\n\n\n\n图 13.17: 设置数学公式\n\n\n\n\n\n13.3.2 动静转化\n在出版书籍，发表期刊文章，打印纸质文稿等场景中，需要将交互图形导出为静态图形，再插入到正文之中。\n\nlibrary(ggplot2)\np &lt;- ggplot(data = quakes, aes(x = long, y = lat)) +\n  geom_point()\np\n\n\n\n\n\n\n图 13.18: ggplot2 绘制的静态图形\n\n\n\n\n将 ggplot2 包绘制的散点图转化为交互式的散点图，只需调用 plotly 包的函数 ggplotly()。\n\nplotly::ggplotly(p)\n\n\n\n\n\n当使用配置函数 config() 设置参数选项 staticPlot = TRUE，可将原本交互式的动态图形转为非交互式的静态图形。\n\nplotly::ggplotly(p) |&gt; \n  plotly::config(staticPlot = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n函数 style() 设置动态点的注释，比如点横纵坐标、坐标文本，以及整个注释标签的样式，如背景色。\n\nplotly::ggplotly(p, dynamicTicks = \"y\") |&gt; \n  plotly::style(hoveron = \"points\", hoverinfo = \"x+y+text\", \n        hoverlabel = list(bgcolor = \"white\"))\n\n\n\n\n\n\n\norca (Open-source Report Creator App) 软件针对 plotly.js 库渲染的图形具有很强的导出功能，安装 orca 后，plotly::orca() 函数可以将基于 htmlwidgets 的 plotly 图形对象导出为 PNG、PDF 和 SVG 等格式的高质量静态图片。\n\n# orca\nplotly::orca(p, \"plotly-quakes.svg\")\n# kaleido\nplotly::save_image(p, \"plotly-quakes.svg\")\n\n\n13.3.3 坐标系统\nquakes 是一个包含空间位置的数据集，plotly 的 scattergeo 图层 针对空间数据提供多边形矢量边界地图数据，支持设定坐标参考系。下 图 13.19 增加了地震震级维度，在空间坐标参考系下绘制散点。\n\nplotly::plot_ly(\n  data = quakes,\n  lon = ~long, lat = ~lat,\n  type = \"scattergeo\", mode = \"markers\",\n  text = ~ paste0(\n    \"站点：\", stations, \"&lt;br&gt;\",\n    \"震级：\", mag\n  ),\n  marker = list(\n    color = ~mag, colorscale = \"Viridis\",\n    size = 10, opacity = 0.8,\n    line = list(color = \"white\", width = 1)\n  )\n) |&gt;\n  plotly::layout(geo = list(\n    showland = TRUE,\n    landcolor = plotly::toRGB(\"gray95\"),\n    countrycolor = plotly::toRGB(\"gray85\"),\n    subunitcolor = plotly::toRGB(\"gray85\"),\n    countrywidth = 0.5,\n    subunitwidth = 0.5,\n    lonaxis = list(\n      showgrid = TRUE,\n      gridwidth = 0.5,\n      range = c(160, 190),\n      dtick = 5\n    ),\n    lataxis = list(\n      showgrid = TRUE,\n      gridwidth = 0.5,\n      range = c(-40, -10),\n      dtick = 5\n    )\n  ))\n\n\n\n\n\n\n\n\n图 13.19: 空间点数据图\n\n\n\n\n\n13.3.4 添加水印\n在图片右下角添加水印图片\n\nplotly::plot_ly(quakes,\n  x = ~long, y = ~lat, color = ~mag, \n  type = \"scatter\", mode = \"markers\"\n) |&gt; \n  plotly::config(staticPlot = TRUE) |&gt; \n  plotly::layout(\n    images = list( # 水印图片\n      source = \"https://images.plot.ly/language-icons/api-home/r-logo.png\",\n      xref = \"paper\", # 页面参考\n      yref = \"paper\",\n      x = 0.90, # 横坐标\n      y = 0.20, # 纵坐标\n      sizex = 0.2, # 长度\n      sizey = 0.2, # 宽度\n      opacity = 0.5 # 透明度\n    )\n  )\n\n\n\n\n\n\n图 13.20: 添加水印图片\n\n\n\n\n13.3.5 多图布局\n将两个图形做上下排列\n\np1 &lt;- plotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"bar\"\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\np2 &lt;- plotly::plot_ly(\n  data = trunk_year, x = ~year, y = ~revision, type = \"scatter\",\n  mode = \"markers+lines\", line = list(shape = \"spline\")\n) |&gt;\n  plotly::layout(\n    xaxis = list(title = \"年份\"),\n    yaxis = list(title = \"代码提交量\")\n  )\n\nhtmltools::tagList(p1, p2)\n\n\n\n\n\n\n\n图 13.21: 上下布局\n\n\n\nplotly 包提供的函数 subplot() 专门用于布局排列，下图的上下子图共享 x 轴。\n\nplotly::subplot(plotly::style(p1, showlegend = FALSE), \n                plotly::style(p2, showlegend = FALSE), \n                nrows = 2, margin = 0.05, shareX = TRUE, titleY = TRUE)\n\n\n\n\n\n\n图 13.22: 上下布局\n\n\n\n下图展示更加灵活的布局形式，嵌套使用布局函数 subplot() 实现。\n\np11 &lt;- plotly::subplot(plotly::style(p1, showlegend = FALSE),\n  plotly::style(p2, showlegend = FALSE),\n  nrows = 1, margin = 0.05, shareY = TRUE, titleX = TRUE\n)\n\nplotly::subplot(p11,\n  plotly::style(p2, showlegend = FALSE),\n  nrows = 2, margin = 0.05, shareY = FALSE, titleX = FALSE\n)\n\n\n\n\n\n\n图 13.23: 灵活布局\n\n\n\n\n13.3.6 图表联动\ncrosstalk 包可将 plotly 包绘制的图形和 DT 包制作的表格联动起来。plotly 绘制交互图形，在图形上用套索工具筛选出来的数据显示在表格中。\n\nlibrary(crosstalk)\n# quakes 数据变成可共享的\nquakes_sd &lt;- SharedData$new(quakes)\n# 绘制交互图形\np &lt;- plotly::plot_ly(quakes_sd, x = ~long, y = ~lat) |&gt; \n  plotly::add_markers() |&gt; \n  plotly::highlight(on = \"plotly_selected\", off = \"plotly_deselect\")\n# 制作表格\nd &lt;- DT::datatable(quakes_sd, options = list(dom = \"tp\"))\n# 将图表组合一起展示\nbscols(list(p, d))\n\n\n\n\n\n\n\n\n\n\n\n\n\n图 13.24: 图表联动",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>交互图形</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html",
    "href": "interactive-tables.html",
    "title": "14  交互表格",
    "section": "",
    "text": "14.1 基础功能",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-basic",
    "href": "interactive-tables.html#sec-table-basic",
    "title": "14  交互表格",
    "section": "",
    "text": "14.1.1 创建表格\n\n14.1.2 添加标题\n\n14.1.3 添加注释\n\n14.1.4 水平滚动\n\n14.1.5 垂直滚动\n\n14.1.6 数据分页\n\n14.1.7 适应宽度\n\n14.1.8 行列分组\n\n14.1.9 列格式化\n\n14.1.10 数据配色\n\nlibrary(tibble)\n\ndat &lt;- tribble(\n  ~name1, ~name2,\n  as.character(htmltools::tags$b(\"加粗\")), as.character(htmltools::a(href = \"https://rstudio.com\", \"超链\")), # 支持超链接\n  as.character(htmltools::em(\"强调\")), '&lt;a href=\"#\" onclick=\"alert(\\'Hello World\\');\"&gt;Hello&lt;/a&gt;',\n  as.character(htmltools::span(style = \"color:red\", \"正常\")), \"正常\"\n)\n\n根据数据的大小配上颜色\n\ncolorize_num &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", x),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", x)\n  )\n}\ncolorize_pct &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", scales::percent(x, accuracy = 0.01)),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", scales::percent(x, accuracy = 0.01))\n  )\n}\n\ncolorize_pp &lt;- function(x) {\n  ifelse(x &gt; 0,\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"green\", paste0(round(100*x, digits = 2), \"PP\")),\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", \"red\", paste0(round(100*x, digits = 2), \"PP\"))\n  )\n}\n\ncolorize_text &lt;- function(x, color = \"red\") {\n    sprintf(\"&lt;span style='color:%s'&gt;%s&lt;/span&gt;\", color, x )\n}\n\n\nlibrary(DT)\ndatatable(\n  data = dat, escape = FALSE, \n  colnames = c(colorize_text(\"第1列\", \"red\"), \n               as.character(htmltools::em(\"第2列\"))),\n  options = list(\n    pageLength = 5, # 每页显示5行\n    dom = \"t\"\n  )\n)\n\n\n表格 14.1: 数据配色\n\n\n\n\n\n\n\n\n\nBase R 内置的 R 包含有丰富的数据集，非常适合演示图形和阐述统计理论，后面技术和理论部分的介绍大多围绕内置的数据集展开，数据集及其描述如下表所示：\n\n# 抽取 R 包信息\nPkgs &lt;- sapply(list.files(R.home(\"library\")), function(x) {\n  packageDescription(pkg = x, fields = \"Priority\")\n})\n# 抽取内置 R 包列表\nCorePkgs &lt;- names(Pkgs[Pkgs %in% c(\"base\", \"recommended\") & !is.na(Pkgs)])\n# 抽取 R 包的数据集\nBaseDataSets &lt;- data(package = CorePkgs)$results[, c(\"Package\", \"Item\", \"Title\")]\n\nlibrary(DT)\ndatatable(BaseDataSets,\n  rownames = FALSE, # 不显示行名\n  extensions = c(\"Buttons\", \"RowGroup\"),\n  options = list(\n    pageLength = 10, # 每页显示的行数\n    language = list(url = \"//cdn.datatables.net/plug-ins/1.10.11/i18n/Chinese.json\"), # 汉化\n    dom = \"Bfrtp\", # 去掉显示行数 i、过滤 f 的能力，翻页用 p 表示\n    ordering = F, # 去掉列排序\n    buttons = c(\"copy\", \"csv\", \"excel\", \"print\"), # 提供打印按钮\n    rowGroup = list(dataSrc = 0), # 按 Package 列分组\n    columnDefs = list(\n      list(className = \"dt-center\", targets = 0), # 不显示行名，则 targets 从 0 开始，否则从 1 开始\n      list(visible = FALSE, targets = 0) # 不显示 Package 列\n    )\n  )\n)\n\n\n表格 14.2: Base R 包内置的数据集",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-extend",
    "href": "interactive-tables.html#sec-table-extend",
    "title": "14  交互表格",
    "section": "\n14.2 扩展功能",
    "text": "14.2 扩展功能\n\n14.2.1 汉化表格\n\n14.2.2 下载数据",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-tables.html#sec-table-reactable",
    "href": "interactive-tables.html#sec-table-reactable",
    "title": "14  交互表格",
    "section": "\n14.3 其它工具",
    "text": "14.3 其它工具",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>交互表格</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html",
    "href": "interactive-applications.html",
    "title": "15  交互应用",
    "section": "",
    "text": "15.1 简单示例\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  sliderInput(inputId = \"n\", label = \"观测记录的数目\", \n              min = 1, max = nrow(faithful), value = 100),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    hist(faithful$eruptions[seq_len(input$n)],\n      breaks = 40,\n      main = \"美国黄石公园喷泉\",\n      xlab = \"喷发持续时间\"\n    )\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-demo",
    "href": "interactive-applications.html#sec-shiny-demo",
    "title": "15  交互应用",
    "section": "",
    "text": "15.1.1 UI 前端\n\n15.1.2 Server 后端",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-widget",
    "href": "interactive-applications.html#sec-shiny-widget",
    "title": "15  交互应用",
    "section": "\n15.2 Shiny 组件",
    "text": "15.2 Shiny 组件\n组件又很多，下面想重点介绍 4 个，它们使用频次很高，很有代表性。\n\n15.2.1 筛选器\n单个筛选器、独立筛选器、筛选器联动\n\n15.2.2 输入框\n数值型、文本型\n\n15.2.3 动作按钮\n提交按钮、响应按钮\n\n15.2.4 书签\n书签记录输入状态，链接可以指向页面状态\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  sliderInput(inputId = \"n\", label = \"观测记录的数目\", \n              min = 1, max = nrow(faithful), value = 100),\n  plotOutput(\"plot\"),\n  bookmarkButton(id = \"bookmark1\", label = \"书签\", title = \"记录、分享此时应用的状态\")\n)\n\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    hist(faithful$eruptions[seq_len(input$n)],\n      breaks = 40,\n      main = \"美国黄石公园喷泉\",\n      xlab = \"喷发持续时间\"\n    )\n  })\n}\n\nenableBookmarking(store = \"url\")\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-extensions",
    "href": "interactive-applications.html#sec-shiny-extensions",
    "title": "15  交互应用",
    "section": "\n15.3 Shiny 扩展",
    "text": "15.3 Shiny 扩展\n页面布局\n\n\nshinydashboard / shinydashboardPlus Shiny 应用\n\nflexdashboard R Markdown 文档中制作 Shiny 应用\nbs4Dash\n\n交互表格\n\nDT\nreactable\n\n交互图形\n\nplotly\nggiraph\n\n\n15.3.1 页面布局\n\n15.3.2 交互表格\n下面在 Shiny 应用中插入 DT 包制作的交互表格\n\n# 前端\nlibrary(shiny)\nui &lt;- fluidPage(\n  # 应用的标题名称\n  titlePanel(\"鸢尾花数据集\"),\n  # 边栏\n  fluidRow(\n    column(12, DT::dataTableOutput(\"table\"))\n  )\n)\n\n# 服务端\nserver &lt;- function(input, output, session) {\n  output$table &lt;- DT::renderDataTable(iris,\n    options = list(\n      pageLength = 5, # 每页显示5行\n      initComplete = I(\"function(settings, json) {alert('Done.');}\")\n    ), server = F\n  )\n}\n\nshinyApp(ui, server)\n\n\n\n\n\n\n\n重要\n\n\n\n加载 shiny 包后再加载 DT 包，函数 dataTableOutput() 和renderDataTable() 显示冲突，因为两个 R 包都有这两个函数。在创建 shiny 应用的过程中，如果我们需要呈现动态表格，就需要使用 DT 包的 DT::dataTableOutput() 和 DT::renderDataTable() ，否则会报错，详见 https://github.com/rstudio/shiny/issues/2653。\n\n\nreactable 基于 JS 库 React Table 提供交互式表格渲染，和 shiny 无缝集成，是替代 DT 的不二选择，在 app.R 用 reactable 包的 reactableOutput() 和 renderReactable() 函数替代 shiny 里面的 dataTableOutput() 和 renderDataTable()。 再也不用忍受 DT 和 shiny 的函数冲突了，且其覆盖测试达到 99%。\n\nlibrary(shiny)\n\n下面在 Shiny 应用中插入 reactable 包制作的交互表格\n\nlibrary(shiny)\nlibrary(reactable)\n\nui &lt;- fluidPage(\n  reactableOutput(\"table\")\n)\n\nserver &lt;- function(input, output) {\n  output$table &lt;- renderReactable({\n    reactable(iris,\n      filterable = TRUE, # 过滤\n      searchable = TRUE, # 搜索\n      showPageSizeOptions = TRUE, # 页面大小\n      pageSizeOptions = c(5, 10, 15), # 页面大小可选项\n      defaultPageSize = 10, # 默认显示10行\n      highlight = TRUE, # 高亮选择\n      striped = TRUE, # 隔行高亮\n      fullWidth = FALSE, # 默认不要全宽填充，适应数据框的宽度\n      defaultSorted = list(\n        Sepal.Length = \"asc\", # 由小到大排序\n        Petal.Length = \"desc\" # 由大到小\n      ),\n      columns = list(\n        Sepal.Width = colDef(style = function(value) { \n          # Sepal.Width 添加颜色标记\n          if (value &gt; 3.5) {\n            color &lt;- \"#008000\"\n          } else if (value &gt; 2) {\n            color &lt;- \"#e00000\"\n          } else {\n            color &lt;- \"#777\"\n          }\n          list(color = color, fontWeight = \"bold\") # 字体加粗\n        })\n\n      )\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n除了 DT 和 reactable 包，其它支持 Shiny 集成的 R 包还有 gt 、formattable 和 kableExtra 等。\n\n15.3.3 交互图形\nggiraph 包",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-dashboard",
    "href": "interactive-applications.html#sec-shiny-dashboard",
    "title": "15  交互应用",
    "section": "\n15.4 Shiny 仪表盘",
    "text": "15.4 Shiny 仪表盘\ndashboard 翻译过来叫仪表盘，就是驾驶仓的那个玩意，形象地表达作为掌舵者应该关注的对象。R 包 shiny 出现后，仪表盘的制作显得非常容易，也很快形成了一个生态，比如 shinydashboard、 flexdashboard 等，此外 bs4Dash 基于 Bootstrap 4 的仪表盘，目前 shiny 和 rmarkdown 都在向 Bootstrap 4 升级，这是未来的方向。 shinydashboardPlus 主要目的在于扩展 shinydashboard 包\n\n15.4.1 shinydashboard 包\n将如下内容保存为 app.R 文件。\n\nlibrary(shiny)\nlibrary(shinydashboard)\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Basic dashboard\"),\n  ## 边栏\n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Dashboard\", tabName = \"dashboard\", icon = icon(\"dashboard\")),\n      menuItem(\"Widgets\", tabName = \"widgets\", icon = icon(\"th\"))\n    )\n  ),\n  ## 主体内容\n  dashboardBody(\n    tabItems(\n      # 第一个 Tab 页内容\n      tabItem(\n        tabName = \"dashboard\",\n        fluidRow(\n          box(plotOutput(\"plot1\", height = 250)),\n          box(\n            title = \"Controls\",\n            sliderInput(\"slider\", \"Number of observations:\", 1, 100, 50)\n          )\n        )\n      ),\n\n      # 第二个 Tab 页内容\n      tabItem(\n        tabName = \"widgets\",\n        h2(\"Widgets tab content\")\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  set.seed(122)\n  histdata &lt;- rnorm(500)\n\n  output$plot1 &lt;- renderPlot({\n    data &lt;- histdata[seq_len(input$slider)]\n    hist(data)\n  })\n}\n\nshinyApp(ui, server)\n\n\n15.4.2 shinydashboardPlus 包\nshinydashboardPlus 包的函数 descriptionBlock()\n\nlibrary(shiny)\nlibrary(shinydashboard)\nlibrary(shinydashboardPlus)\n\nshinyApp(\n  ui = dashboardPage(\n    dashboardHeader(),\n    dashboardSidebar(),\n    dashboardBody(\n      box(\n        solidHeader = FALSE,\n        title = \"状态概览\",\n        background = NULL,\n        width = 4,\n        status = \"danger\",\n        footer = fluidRow(\n          column(\n            width = 6,\n            descriptionBlock(\n              number = \"17%\",\n              numberColor = \"green\",\n              numberIcon = \"fa fa-caret-up\",\n              header = \"$35,210.43\",\n              text = \"总收入\",\n              rightBorder = TRUE,\n              marginBottom = FALSE\n            )\n          ),\n          column(\n            width = 6,\n            descriptionBlock(\n              number = \"18%\",\n              numberColor = \"red\",\n              numberIcon = \"fa fa-caret-down\",\n              header = \"1200\",\n              text = \"目标完成\",\n              rightBorder = FALSE,\n              marginBottom = FALSE\n            )\n          )\n        )\n      )\n    ),\n    title = \"Description Blocks\"\n  ),\n  server = function(input, output) { }\n)\n\n\n15.4.3 bs4Dash 包\n\nlibrary(bs4Dash)\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Basic dashboard\"),\n  dashboardSidebar(),\n  dashboardBody(\n    # Boxes need to be put in a row (or column)\n    fluidRow(\n      box(plotOutput(\"plot1\", height = 250)),\n      \n      box(\n        title = \"Controls\",\n        sliderInput(\"slider\", \"Number of observations:\", 1, 100, 50)\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  set.seed(122)\n  histdata &lt;- rnorm(500)\n  \n  output$plot1 &lt;- renderPlot({\n    data &lt;- histdata[seq_len(input$slider)]\n    hist(data)\n  })\n}\n\nshinyApp(ui, server)\n\n\n15.4.4 miniUI 包\nminiUI 包制作迷你版 Shiny 应用，适用于小屏幕显示。\n\nlibrary(shiny)\nlibrary(miniUI)\nlibrary(leaflet)\nlibrary(ggplot2)\n\nui &lt;- miniPage(\n  gadgetTitleBar(\"Shiny gadget example\"),\n  miniTabstripPanel(\n    miniTabPanel(title = \"参数\",\n      icon = icon(\"sliders\"),\n      miniContentPanel(\n        sliderInput(\"year\", \"年份\", 1978, 2010, c(2000, 2010), sep = \"\")\n      )\n    ),\n    miniTabPanel(title = \"可视化\",\n      icon = icon(\"area-chart\"),\n      miniContentPanel(\n        plotOutput(\"quakes\", height = \"100%\")\n      )\n    ),\n    miniTabPanel(title = \"地图\",\n      icon = icon(\"map-o\"),\n      miniContentPanel(\n        padding = 0,\n        leafletOutput(\"map\", height = \"100%\")\n      ),\n      miniButtonBlock(\n        actionButton(\"resetMap\", \"Reset\")\n      )\n    ),\n    miniTabPanel(title = \"数据\",\n      icon = icon(\"table\"),\n      miniContentPanel(\n        DT::dataTableOutput(\"table\")\n      )\n    ),\n    selected = \"Map\"\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  output$quakes &lt;- renderPlot({\n    ggplot(quakes, aes(long, lat)) +\n      geom_point()\n  })\n\n  output$map &lt;- renderLeaflet({\n    force(input$resetMap)\n\n    leaflet(quakes, height = \"100%\") |&gt;\n      addTiles() |&gt;\n      addMarkers(lng = ~long, lat = ~lat)\n  })\n\n  output$table &lt;- DT::renderDataTable({\n    quakes\n  })\n\n  observeEvent(input$done, {\n    stopApp(TRUE)\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-themes",
    "href": "interactive-applications.html#sec-shiny-themes",
    "title": "15  交互应用",
    "section": "\n15.5 Shiny 主题",
    "text": "15.5 Shiny 主题\n\n15.5.1 bslib 包\n\nbslib\n\n15.5.2 shinymaterial 包\nshinymaterial 包实现 Material Design\n\nlibrary(shiny)\nlibrary(shinymaterial)\n\nui &lt;- material_page(\n  title = \"用户画像\",\n  nav_bar_fixed = TRUE,\n  # 每个 sidebar 内容\n  material_side_nav(\n    fixed = TRUE,\n    # Place side-nav tabs within side-nav\n    material_side_nav_tabs(\n      side_nav_tabs = c(\n        \"数据汇总\" = \"tab_1\",\n        \"趋势信息\" = \"tab_2\"\n      ),\n      icons = c(\"cast\", \"insert_chart\")\n    )\n  ),\n  # 每个 tab 页面的内容\n  material_side_nav_tab_content(\n    side_nav_tab_id = \"tab_1\",\n    tags$h2(\"第一个tab页\")\n  ),\n  material_side_nav_tab_content(\n    side_nav_tab_id = \"tab_2\",\n    tags$h2(\"第二个tab页\")\n  )\n)\n\nserver &lt;- function(input, output) {\n\n}\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-faster",
    "href": "interactive-applications.html#sec-shiny-faster",
    "title": "15  交互应用",
    "section": "\n15.6 Shiny 优化",
    "text": "15.6 Shiny 优化\n提升 shiny 仪表盘访问性能的4个建议",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-deployment",
    "href": "interactive-applications.html#sec-shiny-deployment",
    "title": "15  交互应用",
    "section": "\n15.7 Shiny 部署",
    "text": "15.7 Shiny 部署\n\n15.7.1 promises 并发\nshiny 异步编程实现并发访问，多人同时访问 Shiny 应用的情况下，解决必须等另一个人完成访问的情况下才能继续访问的问题。\n\nlibrary(shiny)\nlibrary(future)\nlibrary(promises)\n\nplan(multiprocess)\n\nui &lt;- fluidPage(\n  h2(\"测试异步下载\"),\n  tags$ol(\n    tags$li(\"Verify that plot appears below\"),\n    tags$li(\"Verify that pressing Download results in 5 second delay, then rock.csv being downloaded\"),\n    tags$li(\"Check 'Throw on download?' checkbox and verify that pressing Download results in 5 second delay, then error, as well as stack traces in console\")\n  ),\n  hr(),\n  checkboxInput(\"throw\", \"Throw on download?\"),\n  downloadButton(\"download\", \"下载 (等待5秒)\"),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output, session) {\n  output$download &lt;- downloadHandler(\"rock.csv\", function(file) {\n    future({Sys.sleep(5)}) %...&gt;%\n      {\n        if (input$throw) {\n          stop(\"boom\")\n        } else {\n          write.csv(rock, file)\n        }\n      }\n  })\n\n  output$plot &lt;- renderPlot({\n    plot(cars)\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-alternative",
    "href": "interactive-applications.html#sec-shiny-alternative",
    "title": "15  交互应用",
    "section": "\n15.8 Shiny 替代品",
    "text": "15.8 Shiny 替代品\nR Markdown + Shiny 文档\n\ncrosstalk 交互\nflexdashboard 布局\nDT 交互表格\nleaflet 交互地图\nggiraph 交互图形\n\nQuarto Dashboard 文档",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-showcases",
    "href": "interactive-applications.html#sec-shiny-showcases",
    "title": "15  交互应用",
    "section": "\n15.9 Shiny 案例",
    "text": "15.9 Shiny 案例\n\n\nradiant 探索性数据分析解决方案",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "interactive-applications.html#sec-shiny-summary",
    "href": "interactive-applications.html#sec-shiny-summary",
    "title": "15  交互应用",
    "section": "\n15.10 总结",
    "text": "15.10 总结\n事实上，作为 BI 工程师，相当一部分工作是与数据开发结合的。从 Kafka 接入埋点上报的原始日志（ODS 层）、清洗抽取特定业务/领域内的数据（Fact 事实层）、面向某一类任务的主题数据（ topic 主题层）、面向特定数据产品的应用数据 （app 应用层）。\n\n数据仓库 Hive 数据开发：事实、主题和应用层\n数据计算 Spark 数据开发工具 Spark SQL / Hive SQL 任务调度\n数据报表 MySQL / Doris 数据同步工具 Hive2MySQL 同步应用层数据\n数据展示 Dashboard 应用开发工具 Shiny RStudio Shiny Server\n\n报表开发从数据仓库的 DWD 层开始，可能一些业务原因，我们需要从 ODS 层甚至从点击流的日志数据开始，经过数据清洗、提取、聚合成为支撑BI报表最底层的基础表，存储在 Hive 中，然后对这一系列的基础表根据BI展示的需要进行第二层聚合形成中间表，这两层数据根据业务情况做增量更新或者全量更新，并将中间表同步到 MySQL 仓库中，全量更新的情况，往往更新数据比较大，建议用 sqoop 做数据的同步。创建第二层的中间表稍有些灵活性，原则是在中间表之上对应的数据操作和可视化是容易实现且效率较高的，否则应该构造第三层的中间表，绝不能将大规模的数据集直接导入 R 中进行分析和可视化，拖慢前端展示的速度，占用过多的服务器资源。\n\n\n\n\n\n\n\n图 15.1: Shiny 生态系统\n\n\n\n\n连接数据库。根据数据库的情况选择相应的 R 接口包，比如连接 MySQL 数据库可以用 RMySQL 包，值得一提， odbc 包支持连接相当多的数据库。\n数据操作。根据需要处理的数据规模，可以选择 Base R、 data.table 或者 dplyr 做数据操作，推荐和管道操作一起使用，增加代码可读性。\n交互表格。推荐 reactable 和 DT 包做数据呈现。\n交互图形。推荐功能强大的 plotly 包，可以先用 ggplot2 绘制，然后调用 plotly 包的 ggplotly() 函数将静态图转化为交互图。\n针对特定应用场景的其它交互可视化工具包，比如 leaflet 可以将地图嵌入 Shiny 应用， dygraphs 可以将时间序列塞进去。\nShiny 组件。shinyFeedback 提供用户输入的反馈。shinyWidgets 提供自定义 widget 的功能。miniUI 专为小屏设计，shinyMobile 在 IOS 和安卓手机上访问 shiny 应用。\nShiny 主题。比如 shinythemes 包可以统一配色，dashboardthemes 提供更加深度的主题，shinytableau 提供仿 Tableau 的 dashboard 框架。sass 在 CSS 样式层面重定义风格。bslib 通过 Bootstrap 3/4/5 定制 Shiny 和 R Markdown 主题。\nShiny 权限。shinymanager / shinyauthr 支持单个 shiny 应用的权限管理，firebase 提供访问权限设置 https://firebase.john-coene.com/。\nShiny 框架。ShinyStudio 打造基于容器架构的协作开发环境的开源解决方案，golem 构建企业级 shiny 应用的框架，RinteRface 开发的系列 R 包也试图打造一套完整的解决方案，并配有速查小抄 cheatsheets。\nShiny 部署。shiny-server 以网络服务的方式支持 shiny 应用，shinyproxy 提供企业级部署 shiny 应用的开源解决方案。\n\n自 RStudio 推出 Shiny 系列产品以来，一些公司进一步根据所需扩展和定制，比如 Appsilon、RinteRface、ThinkR-open、dreamRs 和datastorm-open 等。经过商业公司和个人开发者的努力，Shiny 生态非常庞大，资源非常丰富。\n\nShiny 入门 https://shiny.posit.co/r/getstarted/。\nShiny 扩展包 https://github.com/nanxstats/awesome-shiny-extensions。\nShiny 常用技巧和提示 https://github.com/daattali/advanced-shiny。\nShiny 各类资源列表 https://github.com/grabear/awesome-rshiny。\n\n特别值得一提，Shiny 方面的三本专著。\n\nHadley Wickham 的书 Mastering Shiny。\nColin Fay, Sébastien Rochette, Vincent Guyader, Cervan Girard 的书 Engineering Production-Grade Shiny Apps。\nDavid Granjon 的书 Outstanding User Interfaces with Shiny。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>交互应用</span>"
    ]
  },
  {
    "objectID": "documents-html.html",
    "href": "documents-html.html",
    "title": "16  HTML 文档",
    "section": "",
    "text": "16.1 文档元素\n无论是 R Markdown 还是 Quarto，都是站在巨人 Pandoc 的肩膀上，Pandoc 在普通 Markdown 的基础上提供了许多扩展支持，通过一些简单的标记，大大丰富了文档内容，下面介绍的内容适用于 R Markdown 和 Quarto，无论文档最终的输出格式如何。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-doc-elements",
    "href": "documents-html.html#sec-doc-elements",
    "title": "16  HTML 文档",
    "section": "",
    "text": "16.1.1 样式\n文字样式，如加粗、倾斜、上下标等。\n\n\n\n\n\n\nMarkdown 语法\n输出\n\n\n\n*斜体*, **加粗**, ***粗斜体***\n\n斜体, 加粗, 粗斜体\n\n\n\n上角标^2^ / 下角标~2~\n上角标2 / 下角标2\n\n\n\n~~删除线~~\n删除线\n\n\n`代码`\n代码\n\n\n\n16.1.2 图片\n其一插入现成的图片，其二插入代码生成的图片\n\n\n\n\n\n\n\n\n\n(a) versicolor 杂色鸢尾\n\n\n\n\n\n\n\n\n\n(b) setosa 山鸢尾\n\n\n\n\n\n\n\n\n\n(c) virginica 弗吉尼亚鸢尾\n\n\n\n\n\n\n图 16.1: 三种鸢尾花\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n图 16.2: 流程图\n\n\n\n\nggplot2 绘制的图形\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(aes(color = Species)) +\n  theme_classic()\n\n\n\n\n\n\n图 16.3: 一幅简单的 ggplot2 图形\n\n\n\n\n\n16.1.3 表格\nMarkdown 原生支持的表格和 knitr 包制作的表格。\n\n\n表格 16.1: 鸢尾花数据集\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n\n\n\n\n\nknitr::kable(head(iris, 3))\n\n\n表格 16.2: 鸢尾花数据集\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n\n\n\n\n\n\n\n\n16.1.4 列表\n常见的列表有无序列表、有序列表及其嵌套。\n\n\n表格 16.3: 几种列表\n\n\n\n\n\n\n\nMarkdown 语法\n输出\n\n\n\n* 无序列表\n    + 子条目 1\n    + 子条目 2\n        - 子子条目 1\n\n无序列表\n\n子条目 1\n子条目 2\n\n子子条目 1\n\n\n\n\n\n\n\n*   条目 2\n\n    继续 (缩进 4 格)\n\n\n条目 2\n继续 (缩进 4 格)\n\n\n\n\n1. 有序列表\n2. 条目 2\n    i) 子条目 1\n         A.  子子条目 1\n\n有序列表\n条目 2\n\n子条目 1\n\n子子条目 1\n\n\n\n\n\n\n\n(@)  第一个人是好的\n\n第二个人是坏的\n\n(@)  第三个人是丑陋的\n\n\n第一个人是好的\n\n第二个人是坏的\n\n第三个人是丑陋的\n\n\n\n\n::: {}\n1. 一个列表\n:::\n\n::: {}\n1. 又一个列表\n:::\n\n\n\n一个列表\n\n\n\n\n又一个列表\n\n\n\n\n\n术语\n: 定义\n\n术语\n\n定义\n\n\n\n\n\n\n\n\n在 (@) 中添加标识符，如 (@good) 就可以引用列表中的条目 (1)。\n\n16.1.5 引用\n除了引用外部书籍、文章、刊物等的内容，还有长文档内部的交叉引用，这项功能是非常需要的，涉及图、表、公式、定理，参考文献，列表条目等。\n\n16.1.6 脚注\n\nIf you imagine that this pen is Trellis, then Lattice is not this pen.1\n— Paul Murrell\n\n\n16.1.7 公式\n公式分两种情况，其一是行内公式，其二是行间公式。前者一对美元符号夹住数学公式，美元符号与字母之间不能有空格，比如 $\\beta$ 渲染出来的效果是 \\(\\beta\\) 。后者是两对美元符号夹住公式，比如 $$\\beta$$ 渲染出来的效果如下：\n\\[\\beta\\]\n行内公式一般用来写数学符号，行间公式一般用来排版数学公式，特别是多行公式。行间公式可以编号，也可以不编号，编号通常是了交叉引用。\n\\[\\mathbf{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\]\n排版行间公式有很多不同的 LaTeX 环境，最常见的有两种，一种是多个公式逐行排，一种是长公式折行，常常都要求对齐。举例来说，线性模型的两种表示方式，一种是矩阵向量式，一种是数据结构式，见 方程式 16.1 。\n\\[\n\\begin{aligned}\n\\mathbf{y} &= X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\\\\ny_i &= \\mathbf{x}_i\\boldsymbol{\\beta} + \\epsilon_i\n\\end{aligned}\n\\tag{16.1}\\]\n在行间公式中，使用 split 公式环境排版一个长公式，这个公式是折成多行的，表达一个计算过程。举例来说，线性模型回归系数的最小二乘估计 \\(\\hat{\\boldsymbol{\\beta}}\\) 的方差的计算过程，见 方程式 16.2 。\n\\[\n\\begin{split}\n\\mathsf{Var}\\{\\hat{\\boldsymbol{\\beta}}\\} & =\\mathsf{Var}\\{(X{^\\top}X)^{-1}X{^\\top}\\mathbf{y}\\}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\mathsf{Var}\\{\\mathbf{y}\\}\\big((X{^\\top}X)^{-1}X{^\\top}\\big){^\\top}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\mathsf{Var}\\{\\mathbf{y}\\}X(X{^\\top}X)^{-1}\\\\\n& =(X{^\\top}X)^{-1}X{^\\top}\\sigma^{2}IX(X{^\\top}X)^{-1}\\\\\n& =(X{^\\top}X)^{-1}\\sigma^{2}\n\\end{split}\n\\tag{16.2}\\]\n值得注意，\n\nLaTeX 命令 \\mathbf 只对英文字母 \\(a,b,c,A,B,C\\) 加粗，对希腊字母 \\(\\theta,\\alpha,\\beta,\\ldots,\\gamma\\) 加粗应该使用命令 \\boldsymbol。\nQuarto 文档中将行间公式中成对 $$ 转化为 LaTeX 中的 equation 环境。Quarto 不支持在多行公式逐行编号，也不支持在多行公式中对某一（些）行编号。而在 LaTeX 文档中，这些全都支持，可以说公式排版是 LaTeX 最突出的优势。\n\nMathJax 支持公式宏定义，如定义命令 \\bm 对希腊字母加粗。在 Quarto 文档中插入如下代码，用命令 \\boldsymbol 定义一个新的命令 \\bm，这种做法很常见，用来简少公式排版的工作量。\n$$\n\\def\\bm#1{{\\boldsymbol #1}}\n$$",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-report",
    "href": "documents-html.html#sec-quarto-report",
    "title": "16  HTML 文档",
    "section": "\n16.2 制作报告",
    "text": "16.2 制作报告\nQuarto Report 文档\n\n16.2.1 SQL 查询\n\nlibrary(DBI)\nconn &lt;- DBI::dbConnect(RSQLite::SQLite(),\n  dbname = system.file(\"db\", \"datasets.sqlite\", package = \"RSQLite\")\n)\n\nBase R 内置的数据集都整合进 RSQLite 的样例数据库里了，\n\ndbListTables(conn)\n\n [1] \"BOD\"              \"CO2\"              \"ChickWeight\"      \"DNase\"           \n [5] \"Formaldehyde\"     \"Indometh\"         \"InsectSprays\"     \"LifeCycleSavings\"\n [9] \"Loblolly\"         \"Orange\"           \"OrchardSprays\"    \"PlantGrowth\"     \n[13] \"Puromycin\"        \"Theoph\"           \"ToothGrowth\"      \"USArrests\"       \n[17] \"USJudgeRatings\"   \"airquality\"       \"anscombe\"         \"attenu\"          \n[21] \"attitude\"         \"cars\"             \"chickwts\"         \"esoph\"           \n[25] \"faithful\"         \"freeny\"           \"infert\"           \"iris\"            \n[29] \"longley\"          \"morley\"           \"mtcars\"           \"npk\"             \n[33] \"pressure\"         \"quakes\"           \"randu\"            \"rock\"            \n[37] \"sleep\"            \"stackloss\"        \"swiss\"            \"trees\"           \n[41] \"warpbreaks\"       \"women\"           \n\n\n随意选择 5 行数据记录，将结果保存到变量 iris_preview\n\nSELECT * FROM iris LIMIT 5;\n\n查看变量 iris_preview 的内容\n\niris_preview\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n\n\n结束后关闭连接\n\ndbDisconnect(conn = conn)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-presentation",
    "href": "documents-html.html#sec-quarto-presentation",
    "title": "16  HTML 文档",
    "section": "\n16.3 制作演示",
    "text": "16.3 制作演示\nQuarto Presentation",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#sec-quarto-book",
    "href": "documents-html.html#sec-quarto-book",
    "title": "16  HTML 文档",
    "section": "\n16.4 编写书籍",
    "text": "16.4 编写书籍\nQuarto Book 网页格式",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-html.html#footnotes",
    "href": "documents-html.html#footnotes",
    "title": "16  HTML 文档",
    "section": "",
    "text": "(on the difference of Lattice (which eventually was called grid) and Trellis) DSC 2001, Wien (March 2001)↩︎",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>HTML 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html",
    "href": "documents-latex.html",
    "title": "17  PDF 文档",
    "section": "",
    "text": "17.1 LaTeX 基础\nLaTeX 是一个非常方便用户使用的排版工具，提供一套精确的编程语言，下面是一个简单示例。短短 14 行代码展示了大量的常用功能，生成文章标题、作者、目录，设置文档布局、排版公式、交叉引用等。\n接下来，逐行解释上面的 LaTeX 代码。\n所有的 LaTeX 命令都是以反斜杠 \\ 开头的。文类和红包的选项说明可查看其帮助文档。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-tex-elements",
    "href": "documents-latex.html#sec-tex-elements",
    "title": "17  PDF 文档",
    "section": "",
    "text": "\\documentclass[b5paper]{article}\n\\usepackage[heading=true, UTF8]{ctex} % 设置中文环境\n\\usepackage{amsmath,bm} % 处理数学公式\n\\title{LaTeX 入门}\n\\author{张三}\n\\begin{document}\n\\maketitle\n\\tableofcontents\n\\section{线性模型} \\label{sec:lm}\n第 \\ref{sec:lm} 节介绍线性模型，线性模型的矩阵表示见公式 \\ref{eq:lm} 。\n\\begin{align} \\label{eq:lm}\n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n\\end{align}\n\\end{document}\n\n\n\n\\documentclass 命令用来加载文类，常用的有 article、 report、 book 等，文类的选项 b5paper 表示布局为 B5 纸。\n\n\\usepackage 命令用来加载 LaTeX 宏包，上面的第2行设置中文环境，加载了 ctex 宏包，并设置了两个选项 heading=true 和 UTF8 。\n\n\\title 和 \\author 命令分别用来设置文档标题和作者。\\documentclass 和 \\begin{document} 之间的部分叫导言区，常常用来加载宏包和自定义 LaTeX 命令。\\begin{document} 和 \\end{document} 之间的部分叫正文。\n\n\\maketitle 和 \\tableofcontents 命令分别用来生成标题和文档目录。\\section 命令设置小节的标题。\\label 命令设置小节标签，用于交叉引用。\n\n\\begin{align} 和 \\end{align} 是一个公式环境，其间的命令 \\bm 来自 bm 宏包，用于加粗数学符号，命令 \\mathsf 、 \\beta 和 \\epsilon 都来自 amsmath 宏包。\n\n\\begin{align} 之后的命令 \\label{eq:lm} 设置公式标签，eq:lm 是用户指定的唯一标识符，不同公式不能重复使用同一标签，\\ref{eq:lm} 在正文中交叉引用公式。\n\n\n\n17.1.1 中英字体\n大部分情况下，加载 ctex 宏包就够了，但也有的场景需要使用特定的中文字体，比如学位论文排版、项目申请书等，这些对文档格式有极其严格的要求。此时，可以在导言区使用 xecjk 宏包配置字体，或者加载 ctex 宏包时添加选项 fontset=none ，加载 ctex 宏包会自动加载 xecjk 宏包。\n\\usepackage[heading=true, fontset=none, UTF8]{ctex} % 设置中文环境\n下面的代码表示在 LaTeX 文档里使用黑体、宋体、仿宋、楷体四款中文字体。正文字体是宋体，中文没有斜体，倾斜中文使用楷体，加粗中文使用黑体，等宽字体使用仿宋。\n\\setCJKmainfont[ItalicFont={KaiTi_GB2312}, BoldFont={SimHei}]{SimSun}\n\\setCJKsansfont{SimHei}\n\\setCJKmonofont{FangSong_GB2312}\n% 黑体\n\\setCJKfamilyfont{heiti}{SimHei}             \n\\newcommand{\\heiti}{\\CJKfamily{heiti}}\n% 楷体 GB2312\n\\setCJKfamilyfont{kaishu}{KaiTi_GB2312}             \n\\newcommand{\\kaishu}{\\CJKfamily{kaishu}}\n% 宋体\n\\setCJKfamilyfont{songti}{SimSun}             \n\\newcommand{\\songti}{\\CJKfamily{songti}}\n% 仿宋 GB2312\n\\setCJKfamilyfont{fangsong}{FangSong_GB2312}             \n\\newcommand{\\fangsong}{\\CJKfamily{fangsong}}\nLaTeX 提供很多字体宏包，支持英文字体、数学字体单独设定。在加载 amsmath 宏包后，加载 mathpazo 设置数学字体，加载 palatino 设置正文中的英文字体，加载 courier 设置代码中的等宽字体，加载 fontenc 设置字体编码方式。确保已安装 dvips 宏包，它用来处理字体文件。\n\\usepackage{mathpazo} % 数学符号\n\\usepackage{palatino} % 英文衬线字体\n\\usepackage{courier}  % 英文无衬线字体\n\\usepackage[T1]{fontenc} % 字体编码 T1\n\n17.1.2 数学公式\n排版数学公式分三部分，其一是排版的环境，其二是使用的符号、其三是使用的字体。公式环境都是由成对的命令组成，前面已经提及 align 环境，这是一个可对公式编号的适用于对齐多行公式的排版环境。\n\nLaTeX 公式排版环境\n\n可编号\n无编号\n作用\n\n\n\nalign\nalign*\n多行公式对齐\n\n\nequation\nequation*\n可与 split / cases 等环境嵌套使用\n\n\nmultline\nmultline*\n长公式折行\n\n\ngather\ngather*\n多行公式居中\n\n\n\n不可编号的排版环境，行内公式排版，用一对美元符号 $ $或一对小括号 \\( \\)。行间公式排版，用一对双美元符号 $$ $$ 或一对中括号 \\[ \\] 。\nLaTeX 支持丰富的数学符号大、小写英文字母，大、小写希腊字母，字母可以加粗、倾斜，字母也可以设置为等宽字体或衬线字体，还可以设置花体、空心体等。一些常用的数学符号样式见下表。\n\n\n\n\n\n\n\n\n\n大写\n小写\n加粗\n无衬线\n\n\n\\(X\\)\n\\(x\\)\n\\(\\boldsymbol{X}\\)\n\\(\\mathsf{X}\\)\n\n\n衬线\n花体\n空心体\n花体\n\n\n\\(\\mathrm{X}\\)\n\\(\\mathcal{X}\\)\n\\(\\mathbb{X}\\)\n\\(\\mathscr{X}\\)\n\n\n大写\n小写\n加粗\n无衬线\n\n\n\\(\\Gamma\\)\n\\(\\gamma\\)\n\\(\\boldsymbol{\\gamma}\\)\n\\(\\mathsf{\\Gamma}\\)\n\n\n\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2}\n\\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } \n+ \\sqrt{XY} \\Bigg)^3\n\\]\namsmath 宏包渲染效果如下：\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2} \\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } + \\sqrt{XY} \\Bigg)^3\n\\]\nnewtxtext 和 newtxmath 宏包常组合在一起，提供一套 New Times 字体风格的文本和数学公式，一种介于。\n\\documentclass[b5paper]{article}\n\\usepackage{amsmath}\n\\usepackage{newtxtext,newtxmath}\n\\begin{document}\n\\[\n\\Bigg(\\sqrt{\\frac{M}{1 - \\big(\\frac{r}{\\widetilde{x_1 + \\cdots + u_N}} \\big)^2}\n\\big(\\sum_{\\beta =1}^{N} \\sum_{i=1}^{n}\\frac{\\partial u_{\\beta}}{\\partial x_i} + 1 \\big) } \n+ \\sqrt{XY} \\Bigg)^3\n\\]\n\\end{document}\nnewtxmath 宏包渲染效果如下：\n\n\n\n\n\n图 17.1: newtxmath 包渲染的公式效果\n\n\n\n17.1.3 代码抄录\nverbatim 环境是用来抄录代码的。\n\\begin{verbatim}\nlibrary(stats) % 提供 lowess, rpois, rnorm 等函数\nlibrary(graphics) % 提供 plot 方法\nplot(cars)\nlines(lowess(cars))\n\\end{verbatim}\n渲染出来的效果如下：\n\n\n\n\n\n图 17.2: verbatim 抄录环境\n\n\nlistings 宏包提供丰富的配置，下面在导言区设置代码字体样式和大小，代码块的背景、代码块的行号。\n\\usepackage{xcolor}\n\\definecolor{shadecolor}{rgb}{.97, .97, .97}\n\\usepackage{listings}\n\\lstset{\n  basicstyle=\\ttfamily, % 代码是等宽字体\n  backgroundcolor=\\color{shadecolor},  % 代码块的背景颜色\n  breaklines=true, % 可以段行\n  numbers=left,    % 行序号\n  numberstyle=\\footnotesize, % 行序号字体大小\n  commentstyle=\\ttfamily     % 注释是等宽字体\n}\n启用 lstlisting 环境抄录代码，设置参数 language=R 指定抄录环境中的编程语言类型，以便提供语法高亮。\n\\begin{lstlisting}[language=R]\nlibrary(stats)    % 提供 lowess, rpois, rnorm 等函数\nlibrary(graphics) % 提供 plot 方法\nplot(cars)\nlines(lowess(cars))\n\\end{lstlisting}\n渲染出来的效果如下：\n\n\n\n\n\n图 17.3: lstlisting 抄录环境\n\n\n\n17.1.4 插入图表\n首先在导言区加载 graphicx 宏包，然后可以使用 \\includegraphics 命令插入图片，该命令有一些选项，[width=.65\\textwidth] 表示插入的图片占页面宽度的 65%。\n\\usepackage{graphicx}\n在正文中 figure 环境是专门用来处理的图片，选项 [h] 表示将图片就插入此处，不要浮动。 center 环境将图片居中，\\caption 和 \\label 命令分别用来指定图片的标题和标签。\n\\begin{figure}[h]\n  \\begin{center}\n    \\includegraphics[width=.65\\textwidth]{images/peaks.png}\n    \\caption{图片的标题}\n    \\label{fig:figure}\n  \\end{center}\n\\end{figure}\n渲染效果如下\n\n\n\n\n\n图 17.4: 图片的标题\n\n\ntable 环境用于制作控制表格位置，tabular 用于制作表格，控制表头、每个列和每个格子。\n\\begin{table}[h!]\n  \\begin{center}\n    \\begin{tabular}{|c c c|} \n     \\hline\n      列1 & 列2 & 列3 \\\\ \n      \\hline\n      1 & 6 & 77 \\\\ \n      2 & 7 & 15 \\\\\n      3 & 8 & 44 \\\\\n      \\hline\n    \\end{tabular}\n  \\caption{表格的标题}\n  \\label{tbl:table}\n  \\end{center}\n\\end{table}\n\\begin{table}[h!] 表格环境中 [h!] 让表格不要浮动， center 环境使表格居中，\\begin{tabular}{|c c c|} 表格各个列的元素居中，表格整体封闭， \\hline 制作水平线，\\\\ 用于换行， & 用于表格格子对齐，\\caption 添加表格的标题，\\label 添加表格标识符，以便后续引用。\n渲染出来的效果如下：\n\n\n表格 17.1: 表格的标题\n\n\n\n列 1\n列 2\n列 3\n\n\n\n1\n6\n77\n\n\n2\n7\n15\n\n\n3\n8\n44\n\n\n\n\n\n\n\n17.1.5 交叉引用\n\\ref 命令用于图、表、公式、章节的交叉引用，引用图片 \\ref{fig:figure} 、引用表格 \\ref{tbl:table} 、引用公式 \\ref{eq:lm} 等。\n\\cite 命令用于参考文献的引用。\n\n17.1.6 PDF-A/X\n启用 PDF/X 或 PDF/A 标准，导言区加载 pdfx 宏包\n% PDF/A-1b 标准\n\\usepackage[a-1b]{pdfx}\n示例文档内容如下：\n\\documentclass[b5paper]{article}\n\\usepackage{amsmath} % boldsymbol\n\\usepackage[a-1b]{pdfx}\n\\title{Math in LaTeX}\n\\author{Zhang San}\n\\begin{document}\n\\maketitle\n\\tableofcontents\n\\section{Math}\n\\begin{align}\n\\boldsymbol{x},\\mathbf{x},\\mathsf{x},x\n\\end{align}\n\\begin{verbatim}\nrequire(stats) # for lowess, rpois, rnorm\nrequire(graphics) # for plot methods\nplot(cars)\nlines(lowess(cars))\n\\end{verbatim}\n\\end{document}\n编译 LaTeX 文档的命令如下：\nxelatex --shell-escape -output-driver=\"xdvipdfmx -z 0\" &lt;filename&gt;.tex",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-rmarkdown-elements",
    "href": "documents-latex.html#sec-rmarkdown-elements",
    "title": "17  PDF 文档",
    "section": "\n17.2 R Markdown 基础",
    "text": "17.2 R Markdown 基础\n\n\n---\ntitle: \"R Markdown 入门\"\nauthor: \"张三\"\ndocumentclass: article\noutput: \n  bookdown::pdf_book: \n    extra_dependencies:\n      ctex: \n        - UTF8\n        - heading=true\n      bm: null\n    toc: yes\n    template: null\n    base_format: rmarkdown::pdf_document\n    latex_engine: xelatex\n    number_sections: yes\nmathspec: true\ncolorlinks: yes\nclassoptions: \"b5paper\"    \n---\n\n# 线性模型 {#sec:lm}\n\n第 \\@ref(sec:lm) 节介绍线性模型，线性模型的矩阵表示见公式 \\@ref(eq:lm) 。\n\n```{=tex}\n\\begin{align} \n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n(\\#eq:lm)\n\\end{align}\n```\n\n\n\n17.2.1 中英字体\n\n17.2.2 数学公式\n\n17.2.3 代码抄录\n\n17.2.4 插入图表\n\n17.2.5 交叉引用\n\n17.2.6 布局排版\n\n\n---\ntitle: \"R Markdown 双栏排版\"\nsubtitle: \"副标题\"\nauthor: \"张三\"\ndate: \"`r Sys.Date()`\"\nmathspec: yes\nfontsize: 10pt\ngraphics: yes\nlof: yes\ngeometry: margin=1.18in\noutput: \n  bookdown::pdf_book: \n    number_sections: yes\n    toc: yes\n    fig_crop: no\n    latex_engine: xelatex\n    base_format: rmarkdown::pdf_document\n    citation_package: natbib\n    template: null\n    extra_dependencies:\n      sourcecodepro:\n       - scale=0.85\n      ctex:\n       - heading=true\n       - fontset=fandol\n      caption:\n       - labelfont=bf\n       - singlelinecheck=off\n       - textfont=it\n       - justification=centering\n      Alegreya: null\nkeywords: \n  - 动态文档\n  - 双栏排版\nsubject: \"可重复研究与动态文档\"\nabstract: |\n  这里是摘要内容\nbibliography: \n - packages.bib\nbiblio-style: plainnat\nnatbiboptions: \"authoryear,round\"\nlink-citations: true\ncolorlinks: true\nclassoption: \"UTF8,a4paper,twocolumn\"\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n# R Markdown\n\nR Markdown 文档混合了代码、图形和文字内容[@rmarkdown]。\n\n## 代码 {#sec:code}\n\n```{r cars}\nsummary(cars)\n```\n\n## 插图 {#sec:plot}\n\n```{r}\n#| fig-iris, \n#| fig.cap=\"鸢尾花数据集\", \n#| fig.width=5, \n#| fig.height=4,\n#| fig.showtext=TRUE, \n#| out.width=\"95%\", \n#| echo=FALSE\n\nlibrary(ggplot2)\nggplot(iris, aes(Sepal.Length, Sepal.Width)) +\n  geom_point(aes(colour = Species)) +\n  scale_colour_brewer(palette = \"Set1\") +\n  labs(\n    title = \"鸢尾花数据的散点图\",\n    x = \"萼片长度\", y = \"萼片宽度\", colour = \"鸢尾花类别\",\n    caption = \"鸢尾花数据集最早见于 Edgar Anderson (1935) \"\n  )\n```\n\n# 参考文献 {#chap:refer}",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-quarto-elements",
    "href": "documents-latex.html#sec-quarto-elements",
    "title": "17  PDF 文档",
    "section": "\n17.3 Quarto 基础",
    "text": "17.3 Quarto 基础\n\n\n---\ntitle: \"Quarto 入门\"\nauthor: \"张三\"\nlang: zh\nformat:\n  pdf:\n    include-in-header:\n      - text: |\n          \\usepackage[heading=true,UTF8]{ctex} \n          \\usepackage{amsmath,bm}\n    toc: true\n    mathspec: true\n    number-sections: true\n    colorlinks: true\n    documentclass: article\n    papersize: b5paper\n---\n\n# 线性模型 {#sec-lm}\n\n@sec-lm 介绍线性模型，线性模型的矩阵表示见 @eq-lm 。\n\n$$\n\\bm{\\mathsf{y}} = \\bm{\\mathsf{X}}\\bm{\\beta} + \\bm{\\epsilon}\n$$ {#eq-lm}\n\n\n\n17.3.1 中英字体\n\n17.3.2 数学公式\n\n17.3.3 代码抄录\n\n17.3.4 插入图表\n插入图片的语法是 ![](){}，中括号内是插图标题，小括号内是插图存放路径，大括号内是插图的标识符和属性，比如 width=\"65%\" 设置图片的宽度为页面宽度的 65%。\n![An Elephant](images/peaks.png){#fig-quarto-figure width=\"65%\"}\n渲染效果如下：\n\n\n\n\n\n图 17.5: Peaks 函数图像\n\n\n表格默认左对齐，冒号加虚线、虚线加冒号、虚线两侧加冒号分别对应左对齐、右对齐和居中对齐。\n| Default | Left | Right | Center |\n|---------|:-----|------:|:------:|\n| 12      | 12   |    12 |   12   |\n| 123     | 123  |   123 |  123   |\n| 1       | 1    |     1 |   1    |\n\n: 制作表格的管道语法 {#tbl-quarto-table}\n渲染效果如下：\n\n\n表格 17.2: 制作表格的管道语法\n\n\n\nDefault\nLeft\nRight\nCenter\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n17.3.5 交叉引用\n@tbl-quarto-table 插入 表格 17.2 ，@fig-quarto-figure 插入 图 17.5 。引用表格的标识符前缀必须是 tbl，引用插图的标识符前缀必须是 fig，后以连字符连接其它内容。对比 LaTeX 文档中的图、表引用 \\ref{fig:figure} ，Quarto 中的 @ 符号对应于命令 \\ref 。值得注意，在 LaTeX 文档中，对标识符的命名没有这般要求，但为了区分引用内容，通常会加上不同的前缀。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-latex.html#sec-quarto-beamer",
    "href": "documents-latex.html#sec-quarto-beamer",
    "title": "17  PDF 文档",
    "section": "\n17.4 Quarto beamer",
    "text": "17.4 Quarto beamer\nQuarto 制作 beamer 幻灯片\n\n\n---\ntitle: \"Quarto 幻灯片模版\"\nauthor:\n  - 张三\n  - 李四\ninstitute: \n  - XX 大学\n  - XX 学院\ndate: today\ndate-format: long\ndocumentclass: beamer\nclassoption: \n  - 11pt\n  - compress\n  - xcolor=x11names\n  - UTF8\nlang: zh\nformat:\n  beamer:\n    theme: Singapore\n    fonttheme: structurebold\n    pdf-engine: lualatex\n    include-in-header: \n      text: |\n        \\usecolortheme[named=SpringGreen4]{structure}\n        \\usepackage[fontset=fandol]{ctex}\n    keep-tex: false\n    mathspec: true\n    toc: true\n    navigation: horizontal\n    latex-min-runs: 2\n    latex-auto-install: false\nlink-citations: true\n---\n\n# In the morning\n\n## Getting up\n\n-   Turn off alarm\n-   Get out of bed\n\n## Breakfast\n\n-   Eat eggs\n-   Drink coffee\n\n# In the evening\n\n## Dinner\n\n-   Eat spaghetti\n-   Drink wine\n\n## Going to sleep\n\n-   Get in bed\n-   Count sheep\n\n\nPandoc’s Markdown 制作 beamer 幻灯片\n\n\n---\ntitle: \"Quarto 幻灯片模版\"\nauthor:\n  - 张三\n  - 李四\ninstitute: \n  - XX 大学\n  - XX 学院\nmathspec: true\ntoc: true\ntoc-title: \"目录\"\n---\n\n# In the morning\n\n## Getting up\n\n-   Turn off alarm\n-   Get out of bed\n\n## Breakfast\n\n-   Eat eggs\n-   Drink coffee\n\n# In the evening\n\n## Dinner\n\n-   Eat spaghetti\n-   Drink wine\n\n## Going to sleep\n\n-   Get in bed\n-   Count sheep\n\n\n将 Markdown 文档转化为 beamer 幻灯片的命令\n\npandoc --pdf-engine lualatex -t beamer \\\n  --variable theme=\"Singapore\" --variable fonttheme=\"structurebold\" \\\n  --variable classoption=\"xcolor=x11names\" \\\n  --variable header-includes=\"\\usecolortheme[named=SpringGreen4]{structure}\" \\\n  --variable header-includes=\"\\usepackage[fontset=fandol]{ctex}\" \\\n  -f markdown pandoc-beamer.md -o pandoc-beamer.pdf",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>PDF 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html",
    "href": "documents-office.html",
    "title": "18  Office 文档",
    "section": "",
    "text": "18.1 Word 文档",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-words",
    "href": "documents-office.html#sec-office-words",
    "title": "18  Office 文档",
    "section": "",
    "text": "18.1.1 Markdown 制作 Word 文档\n本节探索 (R) Markdown + Pandoc 以 Word 格式作为最终交付的可能性。\n\n\n18.1.2 R Markdown 制作 Word 文档\ndocxtools、officer 和 officedown 大大扩展了 rmarkdown 包在制作 Word/PPT 方面的功能。\n\n\n18.1.3 自定义 Word 模版\nR Markdown 借助 Pandoc 将 Markdown 转化为 Word 文档，继承自 Pandoc 的扩展性， R Markdown 也支持自定义 Word 模版，那如何自定义呢？首先，我们需要知道 Pandoc 内建的 Word 模版长什么样子，然后我们依样画葫芦，制作适合实际需要的模版。获取 Pandoc 自带的 Word 和 PPT 模版，只需在命令行中执行\n# DOCX 模版\npandoc -o custom-reference.docx --print-default-data-file reference.docx\n# PPTX 模版\npandoc -o custom-reference.pptx --print-default-data-file reference.pptx\n这里其实是将 Pandoc 自带的 docx 文档 reference.docx 拷贝一份到 custom-reference.docx，而后将 custom-reference.docx 文档自定义一番，但仅限于借助 MS Word 去自定义样式。\n\nWord 文档的 YAML 元数据定义\n如何深度自定义文档模版\n\nbookdown 提供的函数 word_document2() 相比于 rmarkdown 提供的 word_document() 支持图表的交叉引用，更多细节详见帮助 ?bookdown::word_document2。",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-powerpoints",
    "href": "documents-office.html#sec-office-powerpoints",
    "title": "18  Office 文档",
    "section": "18.2 PowerPoint 演示",
    "text": "18.2 PowerPoint 演示",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "documents-office.html#sec-office-emails",
    "href": "documents-office.html#sec-office-emails",
    "title": "18  Office 文档",
    "section": "18.3 电子邮件",
    "text": "18.3 电子邮件\nRahul Premraj 基于 rJava 包开发的 mailR 虽然还未在 CRAN 上正式发布，但是已得到很多人的关注，也被广泛的使用，目前作者已经不维护了，继续使用有一定风险。 RStudio 公司 Richard Iannone 新开发的 blastula 扔掉了 Java 的重依赖，更加轻量化、现代化，支持发送群组邮件。\n\n18.3.1 curl 包\ncurl 包提供的函数 send_mail() 本质上是在利用 curl 软件发送邮件，举个例子，邮件内容如下：\nFrom: \"张三\" &lt;邮箱地址&gt;\nTo: \"李四\" &lt;邮箱地址&gt;\nSubject: 测试邮件\n\n你好：\n\n这是一封测试邮件！\n将邮件内容保存为 mail.txt 文件，然后使用 curl 命令行工具将邮件内容发出去。\ncurl --url 'smtp://公司邮件服务器地址:开放的端口号' \\\n  --ssl-reqd --mail-from '发件人邮箱地址' \\\n  --mail-rcpt '收件人邮箱地址' \\\n  --upload-file data/mail.txt \\\n  --user '发件人邮箱地址:邮箱登陆密码'\n\n\n\n\n\n\n注释\n\n\n\nGmail 出于安全性考虑，不支持这种发送邮件的方式，会将邮件内容阻挡，进而接收不到邮件。\n\n\n\n\n18.3.2 blastula 包\n下面以 blastula 包为例怎么支持 Gmail、Outlook、QQ 等邮件发送，先安装系统软件依赖，CentOS 8 上安装依赖\nsudo dnf install -y libsecret-devel libsodium-devel\n然后安装 keyring 和 blastula\ninstall.packages(c(\"keyring\", \"blastula\"))\n接着配置邮件帐户，这一步需要邮件账户名和登陆密码，配置一次就够了，不需要每次发送邮件的时候都配置一次\nlibrary(blastula)\ncreate_smtp_creds_key(\n  id = \"outlook\", \n  user = \"zhangsan@outlook.com\",\n  provider = \"outlook\"\n)\n第二步，准备邮件内容，包括邮件主题、发件人、收件人、抄送人、密送人、邮件主体和附件等。\nattachment &lt;- \"data/mail.txt\" # 如果没有附件，引号内留空即可。\n# 这个Rmd文件渲染后就是邮件的正文，交互图形和交互表格不适用\nbody &lt;- \"examples/html-document.Rmd\" \n# 渲染邮件内容，生成预览\nemail &lt;- render_email(body) |&gt; \n  add_attachment(file = attachment)\nemail\n最后，发送邮件\nsmtp_send(\n  from = c(\"张三\" = \"xxx@outlook.com\"), # 发件人\n  to = c(\"李四\" = \"xxx@foxmail.com\",\n         \"王五\" = \"xxx@gmail.com\"), # 收件人\n  cc = c(\"赵六\" = \"xxx@outlook.com\"), # 抄送人\n  subject = \"这是一封测试邮件\",\n  email = email,\n  credentials = creds_key(id = \"outlook\")\n)\n密送人实现群发单显，即一封邮件同时发送给多个人，每个收件人只能看到发件人地址而看不到其它收件人地址。\nemail &lt;- compose_email(\n  body = md(\"\nMarkdown 格式的邮件内容\n\")\n)\n\nsmtp_send(\n  from = c(\"发件人\" = \"xx@outlook.com\"),\n  to = c(\"收件人\" = \"xx@outlook.com\"),\n  bcc = c(\n    \"抄送人\" = \"xx@outlook.com\"\n    ),\n  subject = \"邮件主题\",\n  email = email,\n  credentials = creds_key(id = \"outlook\")\n)",
    "crumbs": [
      "数据交流",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Office 文档</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html",
    "href": "common-statistical-tests.html",
    "title": "19  常见的统计检验",
    "section": "",
    "text": "19.1 单样本检验\nflowchart LR\n  A(单样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D1(方差已知) --&gt; E1(Z 检验)\n  C1 --&gt; D2(方差未知) --&gt; E2(t 检验)\n  B1 --&gt; C2(方差检验) --&gt; E3(卡方检验)\n  B2 --&gt; C3(均值检验) --&gt; E4(Wilcoxon 秩和检验)\n  B2 --&gt; C4(方差检验) --&gt; E5[无检验方法]\n\n\n\n\n图 19.1: 单样本检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-one-sample",
    "href": "common-statistical-tests.html#sec-one-sample",
    "title": "19  常见的统计检验",
    "section": "",
    "text": "19.1.1 正态总体均值检验\n\n19.1.1.1 方差已知\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu - \\mu_0 \\leq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu - \\mu_0 \\geq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu - \\mu_0 = 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 \\neq 0\n\\end{aligned}\n\\]\n设 \\(x_1,\\cdots,x_n\\) 是来自总体 \\(\\mathcal{N}(\\mu,\\sigma^2)\\) 的样本，样本均值和方差分别\n\\(\\bar{x} = \\frac{\\sum_{i=1}^{n}x_i}{n}\\) ，\\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\)\n考虑到 \\(\\bar{x} \\sim \\mathcal{N}(\\mu,\\sigma^2 / n)\\) ，则检验统计量服从正态分布\n\\[\nu = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n\\]\n假定 \\(\\mu_0 = 1\\) 对于检验问题 I 拒绝域 \\(\\{u \\geq u_{1-\\alpha}\\}\\)\n\nset.seed(20232023)\nn &lt;- 20\n# 样本\nx &lt;- rnorm(n, mean = 1.8, sd = 2)\n# 检验统计量\nu &lt;- (mean(x) - 1) / (2 / sqrt(n))\n# 临界值\nqnorm(p = 1 - 0.05, mean = 0, sd = 1)\n\n#&gt; [1] 1.644854\n\n# P 值\n1 - pnorm(q = u)\n\n#&gt; [1] 0.005082465\n\n\n\n\n\n\n\n\n重要\n\n\n\n随机变量 \\(X\\) 服从标准正态分布，它的概率分布函数如下：\n\\[\nP(X \\leq u)= \\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{u}\\mathrm{e}^{-t^2/2}\\mathrm{dt}\n\\]\n若已知概率 \\(p = 0.95\\) ，则对应的下分位点可用函数 qnorm() 计算。\n\nqnorm(p = 0.95, mean = 0, sd = 1)\n\n#&gt; [1] 1.644854\n\n\n\n\n\n19.1.1.2 方差未知\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu - \\mu_0 \\leq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu - \\mu_0 \\geq 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu - \\mu_0 = 0 \\quad vs. \\quad H_1: \\mu - \\mu_0 \\neq 0\n\\end{aligned}\n\\]\n考虑到\n\\[\n\\begin{aligned}\n& \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0,1) \\\\\n& \\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi^2(n-1) \\\\\n& \\mathsf{E}\\{s^2\\} = \\sigma^2 \\quad \\mathsf{Var}\\{s^2\\} = \\frac{2\\sigma^4}{n-1}\n\\end{aligned}\n\\]\n根据 t 分布的定义，检验统计量服从 t 分布，即 \\(t \\sim t(n-1)\\)\n\\[\nt = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\n\\]\n假定 \\(\\mu_0 = 1\\) 对于检验问题 I ，拒绝域 \\(\\{t \\geq t_{1-\\alpha}(n-1)\\}\\)\n\n# 检验统计量\nt0 &lt;- (mean(x) - 1) / sqrt(var(x) / n)\n# 临界值\nqt(p = 1 - 0.05, df = n - 1)\n\n#&gt; [1] 1.729133\n\n# P 值\n1 - pt(q = t0, df = n - 1)\n\n#&gt; [1] 0.01569596\n\n\n\n\n\n\n\n\n注释\n\n\n\n英国统计学家 William Sealy Gosset (1876-1937) 于 1908 年在杂志 《Biometrics》 上以笔名 Student 发表论文《The Probable Error of a Mean》(\"Student\" 1908)，论文中展示了独立同正态分布的样本 \\(x_1, \\ldots, x_n \\stackrel{i.i.d}{\\sim} \\mathcal{N}(\\mu,\\sigma^2)\\) 的样本方差 \\(s^2\\) 和样本标准差 \\(s\\) 的抽样分布，根据均值和标准差不相关的性质导出 t 分布，宣告 t 分布的诞生，因其在小样本领域的突出贡献，W. S. Gosset 进入世纪名人录 (Heyde 等 2001)。\n\n\n\n\n\n表格 19.1: \\(t\\) 分布的分位数表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.75\n0.8\n0.9\n0.95\n0.975\n0.99\n0.995\n0.999\n\n\n\n1\n1.0000\n1.3764\n3.0777\n6.3138\n12.7062\n31.8205\n63.6567\n318.3088\n\n\n2\n0.8165\n1.0607\n1.8856\n2.9200\n4.3027\n6.9646\n9.9248\n22.3271\n\n\n3\n0.7649\n0.9785\n1.6377\n2.3534\n3.1824\n4.5407\n5.8409\n10.2145\n\n\n4\n0.7407\n0.9410\n1.5332\n2.1318\n2.7764\n3.7469\n4.6041\n7.1732\n\n\n5\n0.7267\n0.9195\n1.4759\n2.0150\n2.5706\n3.3649\n4.0321\n5.8934\n\n\n6\n0.7176\n0.9057\n1.4398\n1.9432\n2.4469\n3.1427\n3.7074\n5.2076\n\n\n7\n0.7111\n0.8960\n1.4149\n1.8946\n2.3646\n2.9980\n3.4995\n4.7853\n\n\n8\n0.7064\n0.8889\n1.3968\n1.8595\n2.3060\n2.8965\n3.3554\n4.5008\n\n\n9\n0.7027\n0.8834\n1.3830\n1.8331\n2.2622\n2.8214\n3.2498\n4.2968\n\n\n10\n0.6998\n0.8791\n1.3722\n1.8125\n2.2281\n2.7638\n3.1693\n4.1437\n\n\n\n\n\n\n\n\n\n19.1.2 正态总体方差检验\n卡方检验 \\(\\chi^2\\) 检验统计量服从卡方分布。\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\sigma^2 - \\sigma^2_0 \\leq 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\sigma^2 - \\sigma^2_0 \\geq 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\sigma^2 - \\sigma^2_0 = 0 \\quad vs. \\quad H_1: \\sigma^2 - \\sigma^2_0 \\neq 0\n\\end{aligned}\n\\]\n一般假定均值 \\(\\mu\\) 是未知的。检验统计量服从卡方分布 \\(\\chi^2(n-1)\\)\n\\[\n\\chi^2 = \\frac{(n-1)s^2}{\\sigma^2_0}\n\\]\n设 \\(\\sigma^2_0 = 1.5^2\\) ，考虑检验问题 I\n\n# 检验统计量\nchi &lt;- (n - 1) * var(x) / 1.5^2\n# 临界值\nqchisq(p = 1 - 0.05, df = n -1)\n\n#&gt; [1] 30.14353\n\n# P 值\n1 - pchisq(q = chi, df = n -1)\n\n#&gt; [1] 0.002183653\n\n\nR 软件提供很多统计分布的计算，因此，不再需要查分位数表，现算即可。计算自由度为 \\(n\\) 概率为 \\(p\\) 的 \\(\\chi^2\\) 分布的分位数 \\(\\chi^2_p(n)\\) ，即\n\\[\nP(\\chi^2(n) \\leq \\chi^2_p(n)) = p\n\\]\n若已知自由度为 1 ，概率为 0.05，则可借助分位数函数 qchisq() 计算对应的（下）分位点。\n\nqchisq(p = 0.05, df = 1)\n\n#&gt; [1] 0.00393214\n\n\n同理，也可以获得 \\(\\chi^2\\) 分布的分位数 表格 19.2 ，计算出来的分位数保留 4 位小数。\n\n\n\n表格 19.2: \\(\\chi^2\\) 分布的分位数表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n0.01\n0.025\n0.05\n0.1\n0.9\n0.95\n0.975\n0.99\n0.995\n\n\n\n1\n0.0000\n0.0002\n0.0010\n0.0039\n0.0158\n2.7055\n3.8415\n5.0239\n6.6349\n7.8794\n\n\n2\n0.0100\n0.0201\n0.0506\n0.1026\n0.2107\n4.6052\n5.9915\n7.3778\n9.2103\n10.5966\n\n\n3\n0.0717\n0.1148\n0.2158\n0.3518\n0.5844\n6.2514\n7.8147\n9.3484\n11.3449\n12.8382\n\n\n4\n0.2070\n0.2971\n0.4844\n0.7107\n1.0636\n7.7794\n9.4877\n11.1433\n13.2767\n14.8603\n\n\n5\n0.4117\n0.5543\n0.8312\n1.1455\n1.6103\n9.2364\n11.0705\n12.8325\n15.0863\n16.7496\n\n\n6\n0.6757\n0.8721\n1.2373\n1.6354\n2.2041\n10.6446\n12.5916\n14.4494\n16.8119\n18.5476\n\n\n7\n0.9893\n1.2390\n1.6899\n2.1673\n2.8331\n12.0170\n14.0671\n16.0128\n18.4753\n20.2777\n\n\n8\n1.3444\n1.6465\n2.1797\n2.7326\n3.4895\n13.3616\n15.5073\n17.5345\n20.0902\n21.9550\n\n\n9\n1.7349\n2.0879\n2.7004\n3.3251\n4.1682\n14.6837\n16.9190\n19.0228\n21.6660\n23.5894\n\n\n10\n2.1559\n2.5582\n3.2470\n3.9403\n4.8652\n15.9872\n18.3070\n20.4832\n23.2093\n25.1882\n\n\n\n\n\n\n\n\n\n19.1.3 总体未知均值检验\n有了均值和方差，为什么还要位置参数和尺度参数？为了更一般地描述问题，扩展范围。特别是在总体分布未知或知之甚少的情况下做检验，不再仅限于均值和方差这样的特征量。\n考虑前面正态总体均值检验中的假设 I 的形式，若总体的分布形式未知，则需要 Wilcoxon （威尔科克森）秩和检验 wilcox.test() 来做均值的比较。\n\nwilcox.test(x = x, mu = 1, alternative = \"greater\")\n\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  x\n#&gt; V = 163, p-value = 0.01479\n#&gt; alternative hypothesis: true location is greater than 1\n\n\n相比于 t 检验，P 值更小。\n\n19.1.4 总体未知方差检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-two-samples",
    "href": "common-statistical-tests.html#sec-two-samples",
    "title": "19  常见的统计检验",
    "section": "\n19.2 两样本检验",
    "text": "19.2 两样本检验\n\n\n\n\n\nflowchart LR\n  A(两样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D1(方差已知) --&gt; E1(Z 检验)\n  C1 --&gt; D2(方差未知但相等) --&gt; E2(t 检验)\n  C1 --&gt; D3(方差未知且不等) --&gt; E3(Welch t 检验)\n  B1 --&gt; C2(方差检验) --&gt; E4(F 检验)\n  C2 --&gt; E7(Bartlett 检验)\n  B2 --&gt; C3(均值检验) --&gt; E5(Wilcoxon 符号秩检验\\nKruskal-Wallis 秩和检验)\n  B2 --&gt; C4(方差检验) --&gt; E8(Ansari-Bradley 检验\\nMood 检验\\nFligner-Killeen 检验)\n\n\n\n\n图 19.2: 两样本检验\n\n\n\n\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的样本。\n\n19.2.1 正态总体均值检验\n两样本均值之差的检验\n\n代码library(ggplot2)\n# 绘制虚线所需的数据\nconst &lt;- 1 / sqrt(2 * pi)\ndat &lt;- data.frame(\n  x = c(-1, -1, 3, 3),\n  y = c(const, 0, const / 1.5, 0),\n  group = c(\"dnorm1\", \"dnorm1\", \"dnorm2\", \"dnorm2\"),\n  upper = c(const, 0, const / 1.5, 0),\n  lower = c(0, 0, 0, 0)\n)\nggplot() +\n  geom_function(\n    fun = dnorm, args = list(mean = -1, sd = 1),\n    aes(colour = \"dnorm1\"), linewidth = 1.5, xlim = c(-5, 10)\n  ) +\n  geom_function(\n    fun = dnorm, args = list(mean = 3, sd = 1.5),\n    aes(colour = \"dnorm2\"), linewidth = 1.5, xlim = c(-5, 10)\n  ) +\n  scale_color_brewer(palette = \"Set1\", labels = c(\n    dnorm1 = \"$\\\\mathcal{N}(\\\\mu_1, \\\\sigma_1^2)$\",\n    dnorm2 = \"$\\\\mathcal{N}(\\\\mu_2, \\\\sigma_2^2)$\"\n  )) +\n  geom_linerange(\n    aes(x = x, y = y, ymin = lower, ymax = upper, colour = group),\n    linewidth = 2, lty = 2, show.legend = FALSE, data = dat\n  ) +\n  annotate(\"text\", x = -1, y = 0, label = \"$\\\\mu_1$\", vjust = 2.5) +\n  annotate(\"text\", x = 3, y = 0, label = \"$\\\\mu_2$\", vjust = 2.5) +\n  theme_classic(base_size = 13) +\n  theme(legend.position.inside = c(0.9, 0.9)) +\n  labs(x = \"$x$\", y = \"$f(x)$\", color = \"正态分布\") +\n  coord_cartesian(clip = \"off\")\n\n\n\n\n\n\n图 19.3: 两样本均值之差的检验\n\n\n\n\n常见检验问题\n\\[\n\\begin{aligned}\n\\mathrm{I}   \\quad H_0: \\mu_1 - \\mu_2 \\leq 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 &gt; 0 \\\\\n\\mathrm{II}  \\quad H_0: \\mu_1 - \\mu_2 \\geq 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 &lt; 0 \\\\\n\\mathrm{III} \\quad H_0: \\mu_1 - \\mu_2 = 0 \\quad vs. \\quad H_1: \\mu_1 - \\mu_2 \\neq 0\n\\end{aligned}\n\\]\n\n19.2.1.1 方差已知\n\\[\nu = \\frac{(\\bar{x} - \\bar{y}) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}} }\n\\]\n检验统计量服从标准正态分布 \\(u \\sim \\mathcal{N}(0,1)\\)，检验统计量 \\(u\\) 对应的样本值 \\(u_0\\)，检验的拒绝域和 \\(P\\) 值如下\n\\[\nW_1 = \\{u \\geq u_{1 - \\alpha} \\}, \\quad p_1 = 1 - \\varPhi(u_0)\n\\]\n\nn_1 &lt;- 100\nn_2 &lt;- 80\nmu_1 &lt;- 10\nsigma_1 &lt;- 2.5\nmu_2 &lt;- 6\nsigma_2 &lt;- 4.5\n\nset.seed(20232023)\nx1 &lt;- rnorm(n_1, mean = mu_1, sd = sigma_1)\ny1 &lt;- rnorm(n_2, mean = mu_2, sd = sigma_2)\nu0 &lt;- (mean(x1) - mean(y1)) / sqrt(sigma_1^2 / n_1 + sigma_2^2 / n_2)\nu0\n\n#&gt; [1] 6.779039\n\n\n对检验问题 I，给定显著性水平 \\(\\alpha = 0.05\\)，得出拒绝域 \\(\\{ u \\geq 1.645\\}\\)，计算样本观察值得到的检验统计量的值 \\(u_0 = 6.779\\)，而该值落在拒绝域，所以拒绝原假设，即拒绝 \\(\\mu_1 - \\mu_2 \\leq 0\\)，则接受 \\(\\mu_1 - \\mu_2 &gt; 0\\)。\n\n# 计算拒绝域\nqnorm(1 - 0.05)\n\n#&gt; [1] 1.644854\n\n# 计算 P 值\n1 - pnorm(u0)\n\n#&gt; [1] 6.048939e-12\n\n\n\n19.2.1.2 方差未知但相等\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma^2)\\) 的样本。\nt 检验，检验统计量服从自由度为 \\(n_1 + n_2 - 2\\) 的 t 分布\n\\[\nt = \\frac{(\\bar{x} -\\bar{y})-(\\mu_1 - \\mu_2)}{s_0\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\]\n其中，\n\\[\n\\begin{aligned}\n& \\bar{x} = \\sum_{i=1}^{n_1}x_i \\quad \\bar{y} = \\sum_{i=1}^{n_2}y_i \\\\\n& s_0^2 = \\frac{1}{n_1 + n_2 - 2}\\big(\\sum_{i=1}^{n_1}(x_i - \\bar{x})^2 + \\sum_{i=1}^{n_2}(y_i - \\bar{y})^2\\big)\n\\end{aligned}\n\\]\n\ns_w &lt;- sqrt(1 / (n_1 + n_2 - 2) * ((n_1 - 1) * var(x1) + (n_2 - 1) * var(y1)))\nt0 &lt;- (mean(x1) - mean(y1)) / (s_w * sqrt(1 / n_1 + 1 / n_2))\nt0\n\n#&gt; [1] 8.155781\n\n\n样本观察值 \\(t_0 = 8.155 &gt; t_{0.95}(n_1 + n_2 -2) = 1.653\\) 落在拒绝域内，对于检验问题 I 我们要拒绝原假设\n\n# 临界值：0.95 分位点对应的分位数\nqt(1 - 0.05, df = n_1 + n_2 - 2)\n\n#&gt; [1] 1.653459\n\n# p 值\n1 - pt(t0, df = n_1 + n_2 - 2, lower.tail = TRUE)\n\n#&gt; [1] 3.019807e-14\n\n\n利用 R 内置的 t.test() 函数计算\n\nt.test(x = x1, y = y1, alternative = \"greater\", var.equal = TRUE)\n\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  x1 and y1\n#&gt; t = 8.1558, df = 178, p-value = 3.016e-14\n#&gt; alternative hypothesis: true difference in means is greater than 0\n#&gt; 95 percent confidence interval:\n#&gt;  3.036384      Inf\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 10.338905  6.530406\n\n\n检验统计量的值及对应的 P 值都是一样的。睡眠数据 sleep 记录了两种药物对病人睡眠时间的影响，此数据集由 “Student”（哥塞特的笔名） 收集。\n\n# 方差未知但相等\nt.test(extra ~ group, data = sleep, var.equal = TRUE)\n\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -1.8608, df = 18, p-value = 0.07919\n#&gt; alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.363874  0.203874\n#&gt; sample estimates:\n#&gt; mean in group 1 mean in group 2 \n#&gt;            0.75            2.33\n\n\n\n19.2.1.3 方差未知且不等\n两个样本的样本量不是很大，总体方差也未知，两样本均值之差的显著性检验，即著名的 Behrens-Fisher 问题，Welch 在 1938 年提出近似服从自由度为 \\(l\\) 的 t 分布。\n两样本的样本量很大，尽管总体方差未知，两样本均值之差的显著性检验，极限分布是正态分布，可以用 Z 检验。在样本量很大的情况下，Welch t 检验也可以用。\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的 IID 样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的 IID 样本。\nWelch（韦尔奇） t 检验\n\\[\nT = \\frac{(\\bar{x} - \\bar{y}) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{s_x^2}{n_1} + \\frac{s_y^2}{n_2}} }\n\\]\n其中，\\(s_x^2\\) 表示样本 x 的方差 \\(s_x^2 = \\frac{1}{n_1-1}\\sum_{i=1}^{n_1}(x_i -\\bar{x})^2\\) ，\\(s_y^2\\) 表示样本 y 的方差 \\(s_y^2 = \\frac{1}{n_2-1}\\sum_{i=1}^{n_2}(y_i -\\bar{y})^2\\) 。检验统计量 \\(T\\) 服从自由度为 \\(l\\) 的 t 分布。\n\\[\nl = \\frac{s_0^4}{ \\frac{s_x^4}{n_1^2(n_1 - 1)} + \\frac{s_y^4}{n_2^2(n_2-1)} }\n\\]\n其中， \\(s_0^2 = s_x^2 / n_1 + s_y^2/n_2\\)，\\(l\\) 通常不是整数，实际使用时，\\(l\\) 可取最近的整数。\n\ns0 &lt;- var(x1) / n_1 + var(y1) / n_2\nl &lt;- s0^2 / (var(x1)^2 / (n_1^2 * (n_1 - 1)) + var(y1)^2 / (n_2^2 * (n_2 - 1)))\nl\n\n#&gt; [1] 126.7708\n\n\n所以， \\(l\\) 可取 127。检验统计量的值如下\n\nt0 &lt;- (mean(x1) - mean(y1)) / sqrt(s0)\nt0\n\n#&gt; [1] 7.77002\n\n\n\n# 临界值：0.95 分位点对应的分位数\nqt(1 - 0.05, df = 127)\n\n#&gt; [1] 1.65694\n\n# p 值\n1 - pt(t0, df = 126.7708, lower.tail = TRUE) \n\n#&gt; [1] 1.162404e-12\n\n# 就近取整\n1 - pt(t0, df = 127, lower.tail = TRUE)\n\n#&gt; [1] 1.153078e-12\n\n\n与函数 t.test() 比较，值得注意，t 分布的自由度可以为非整数。\n\nt.test(x = x1, y = y1, alternative = \"greater\", var.equal = FALSE)\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  x1 and y1\n#&gt; t = 7.77, df = 126.77, p-value = 1.162e-12\n#&gt; alternative hypothesis: true difference in means is greater than 0\n#&gt; 95 percent confidence interval:\n#&gt;  2.996334      Inf\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 10.338905  6.530406\n\n\n举例：sleep 数据集\n\n\n\n\n\n\n\n图 19.4: 学生睡眠数据的分布\n\n\n\n\n\n# 方差未知且不等\nt.test(extra ~ group, data = sleep, var.equal = FALSE)\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -1.8608, df = 17.776, p-value = 0.07939\n#&gt; alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.3654832  0.2054832\n#&gt; sample estimates:\n#&gt; mean in group 1 mean in group 2 \n#&gt;            0.75            2.33\n\n\n\n\n\n\n\n\n注释\n\n\n\nEgon Pearson 接过他父亲 Karl Pearson 的职位，担任伦敦大学学院的高尔顿统计教授。许宝騄（Pao-Lu Hsu）在 Jerzy Neyman 和 Egon Pearson 主编的杂志《Statistical Research Memoirs》发表第一篇关于 Behrens-Fisher 问题的论文 (HSU 1938)，1998 年关于 Behrens-Fisher 问题的综述 (Kim 和 Cohen 1998)。陈家鼎和郑忠国一起整理了许宝騄的生平事迹和学术成就，见《许宝騄先生的生平和学术成就》。钟开涞（Kai-Lai Chung）将许宝騄的论文集整理出版 (HSU 1983)。\n\n\nt 检验的影响是如此巨大，以至于广泛存在于具有统计功能的软件中，比如办公软件里的 t 检验。以 MacOS 上的 Numbers 表格软件为例，如 图 19.5 所示，首先打开 Numbers 软件，新建工作表，输入两组数值，然后点击空白处，再从顶部导航栏找到「插入」菜单，「公式」选项，点击扩展选项「新建公式」，在弹出的会话条里输入 TTEST，依次选择第一组，第二组值，检验类型和样本类型，最后点击确认，即可得到两样本 t 检验的 P 值结果。\n\n\n\n\n\n\n\n图 19.5: 办公软件 Numbers 的两样本 t 检验\n\n\n\n\n微软 Excel 办公软件也提供 t 检验计算器，和 MacOS 系统上的 Numbers 办公软件类似，它提供 T.TEST 函数，计算结果也一样，此处从略。R 软件自带 t.test() 函数，也是用于做 t 检验，如下：\n\nt.test(x = c(3, 4, 5, 8, 9, 1, 2, 4, 5), y = c(6, 19, 3, 2, 14, 4, 5, 17, 1))\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  c(3, 4, 5, 8, 9, 1, 2, 4, 5) and c(6, 19, 3, 2, 14, 4, 5, 17, 1)\n#&gt; t = -1.3622, df = 10.255, p-value = 0.2023\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -8.767183  2.100516\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  4.555556  7.888889\n\n\n\n19.2.2 正态总体方差检验\n比较两个正态总体的方差是否相等，F 检验。\n\n# 两样本\nvar.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; F = 0.79834, num df = 9, denom df = 9, p-value = 0.7427\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.198297 3.214123\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;          0.7983426\n\n# 或者\nbartlett.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; Bartlett's K-squared = 0.10789, df = 1, p-value = 0.7426\n\n\n注意：函数 bartlett.test() 支持多样本情况。\n\n19.2.3 总体未知均值检验\n在总体分布未知的情况下，比较均值是否相等的检验。\n\n\nwilcox.test() 适用于单样本和两样本的均值检验，单样本 Wilcoxon 秩和检验，两样本 Wilcoxon 符号秩和检验，后者也叫 Mann-Whitney 检验。\n\nkruskal.test() 适用于两样本和多样本，比较多个均值是否相等的检验，Kruskal-Wallis 秩和检验。\n\n单样本和两样本 wilcox.test()。\n\nwilcox.test(extra ~ group, data = sleep)\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; \n#&gt;  Wilcoxon rank sum test with continuity correction\n#&gt; \n#&gt; data:  extra by group\n#&gt; W = 25.5, p-value = 0.06933\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\ncoin 包提供渐进 Wilcoxon-Mann-Whitney 检验\n\n# Asymptotic Wilcoxon-Mann-Whitney Test\nwilcox_test(extra ~ group, data = sleep, conf.int = TRUE)\n\n#&gt; \n#&gt;  Asymptotic Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  extra by group (1, 2)\n#&gt; Z = -1.8541, p-value = 0.06372\n#&gt; alternative hypothesis: true mu is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.500000e+00  1.270214e-10\n#&gt; sample estimates:\n#&gt; difference in location \n#&gt;              -1.347344\n\n# Exact Wilcoxon-Mann-Whitney Test\nwilcox_test(\n  extra ~ group, data = sleep,\n  distribution = \"exact\", conf.int = TRUE\n)\n\n#&gt; \n#&gt;  Exact Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  extra by group (1, 2)\n#&gt; Z = -1.8541, p-value = 0.06582\n#&gt; alternative hypothesis: true mu is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -3.5  0.0\n#&gt; sample estimates:\n#&gt; difference in location \n#&gt;                  -1.35\n\n\n两样本和多样本 kruskal.test() 。\n\nkruskal.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  extra by group\n#&gt; Kruskal-Wallis chi-squared = 3.4378, df = 1, p-value = 0.06372\n\n\n能用参数检验的一定也可以用非参数检验，一般来说，非参数检验的功效不小于参数检验，非参数检验不要求分布是正态，比如此时 P 值从 0.07939 降至 0.06372。\n\n19.2.4 总体未知方差检验\n对总体没有分布要求的方差齐性检验方法有三个，按适用范围分类，见下 表格 19.3 。\n\n\n表格 19.3: 检验方法分类\n\n\n\n\n\n\n\n两个样本\n多个样本\n\n\n\nAnsari-Bradley 检验 ansari.test()\n\nMood 检验 mood.test()\n\n\n\nFligner-Killeen 检验 fligner.test()\n\n\n\n\n\n\n\n以 A. R. Ansari 和 R. A. Bradley 命名的 Ansari-Bradley 检验 (Ansari 和 Bradley 1960)，对应的 R 函数是 ansari.test() ，以 A. M. Mood 命名的 Mood 检验 (Mood 1954)，对应的 R 函数是 mood.test() ，这两者都属于两样本的非参数检验，检验尺度参数是否相同（齐性）。以 M. A. Fligner 和 T. J. Killeen 命名的 Fligner-Killeen 检验 (Fligner 和 Killeen 1976)，对应的 R 函数是 fligner.test() ，也属于非参数检验，适用于两样本和多样本的情况。非参数检验常涉及位置参数和尺度参数这一对概念，就正态分布而言，位置参数可以理解为均值 \\(\\mu\\) ，尺度参数可以理解为方差 \\(\\sigma^2\\) 。\n\nansari.test(extra ~ group, data = sleep)\n\n#&gt; Warning in ansari.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; \n#&gt;  Ansari-Bradley test\n#&gt; \n#&gt; data:  extra by group\n#&gt; AB = 50.5, p-value = 0.4927\n#&gt; alternative hypothesis: true ratio of scales is not equal to 1\n\nmood.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Mood two-sample test of scale\n#&gt; \n#&gt; data:  extra by group\n#&gt; Z = 0.44761, p-value = 0.6544\n#&gt; alternative hypothesis: two.sided\n\nfligner.test(extra ~ group, data = sleep)\n\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  extra by group\n#&gt; Fligner-Killeen:med chi-squared = 0.21252, df = 1, p-value = 0.6448",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multi-samples",
    "href": "common-statistical-tests.html#sec-multi-samples",
    "title": "19  常见的统计检验",
    "section": "\n19.3 多样本检验",
    "text": "19.3 多样本检验\n\n\n\n\n\nflowchart LR\n  A(多样本) --&gt; B1(正态总体)\n  A  --&gt; B2(总体未知)\n  B1 --&gt; C1(均值检验)\n  C1 --&gt; D2(方差相等) --&gt; E2(F 检验)\n  C1 --&gt; D3(方差不等) --&gt; E3(F 检验)\n  B1 --&gt; C2(方差检验) --&gt; E4(Hartley 检验\\n Bartlett 检验\\n 修正的 Bartlett 检验\\n Levene 检验)\n  B2 --&gt; C3(均值检验) --&gt; E5(Kruskal-Wallis 秩和检验\\n Friedman 秩和检验\\n Quade 检验)\n  B2 --&gt; C4(方差检验) --&gt; E7(Fligner-Killeen 检验)\n\n\n\n\n图 19.6: 多样本检验\n\n\n\n\n本节考虑 Base R 内置的 PlantGrowth 数据集，它收集自 Annette J. Dobson 所著书籍《An Introduction to Statistical Modelling》(Dobson 1983) 第 2 章第 2 节的案例 — 研究植物在两种不同试验条件下的生长情况，植物通过光合作用吸收土壤的养分和空气中的二氧化碳，完成积累，故以植物的干重来刻画植物的生长情况，首先将几乎相同的种子随机地分配到实验组和对照组，基于完全随机实验设计（completely randomized experimental design），经过预定的时间后，将植物收割，干燥并称重。\n\nstr(PlantGrowth)\n\n#&gt; 'data.frame':    30 obs. of  2 variables:\n#&gt;  $ weight: num  4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ...\n#&gt;  $ group : Factor w/ 3 levels \"ctrl\",\"trt1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n设立对照组（控制组）ctrl 和实验组 trt1 和 trt2，比较不同的处理方式对植物干重的影响\n\nsummary(PlantGrowth)\n\n#&gt;      weight       group   \n#&gt;  Min.   :3.590   ctrl:10  \n#&gt;  1st Qu.:4.550   trt1:10  \n#&gt;  Median :5.155   trt2:10  \n#&gt;  Mean   :5.073            \n#&gt;  3rd Qu.:5.530            \n#&gt;  Max.   :6.310\n\n\n每个组都有 10 颗植物，生长情况如 图 19.7 所示\n\n## Annette J. Dobson 扩展的 Plant Weight Data 数据，见 59 页\nlibrary(ggplot2)\nggplot(data = PlantGrowth, aes(x = group, y = weight, color = group)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n图 19.7: 植物干重\n\n\n\n\n\n19.3.1 正态总体均值检验\n\n19.3.1.1 假定同方差\n讲清楚原假设和备择假设。讲清楚假设检验、方差分析、一般线性模型（包含广义线性模型和线性混合效应模型）的关系。\n\\(\\sigma_i^2 = \\mathsf{Var}\\{\\epsilon_{ij}\\}, i = 1,2,3\\) 表示第 \\(i\\) 组的方差，\n\\[\ny_{ij} = \\mu + \\epsilon_{ij}, i = 1,2,3\n\\]\n其中 \\(\\mu\\) 是固定的未知参数。单因素方差分析 oneway.test()\n\n# 假设各组方差相同\noneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)\n\n#&gt; \n#&gt;  One-way analysis of means\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 4.8461, num df = 2, denom df = 27, p-value = 0.01591\n\n\n线性模型也假定各个组的方差是相同的，模型显著性检验的结果和上面是一致的。\n\nfit_lm &lt;- lm(weight ~ group, data = PlantGrowth)\nanova(fit_lm) # 或者 summary(fit)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: weight\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  3.7663  1.8832  4.8461 0.01591 *\n#&gt; Residuals 27 10.4921  0.3886                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n模型输出整理成 表格 19.4\n\n\n\n表格 19.4: 线性回归的输出\n\n\n\n\n\n估计值\n标准差\nt 统计量\nP 值\n\n\n\n\\(\\alpha\\)\n5.032\n0.1971\n25.5265\n0.0000\n\n\n\\(\\beta_1\\)\n-0.371\n0.2788\n-1.3308\n0.1944\n\n\n\\(\\beta_2\\)\n0.494\n0.2788\n1.7720\n0.0877\n\n\n\n\n\n\n\n\n\n19.3.1.2 假定异方差\n\n# 计算各个组的方差\naggregate(data = PlantGrowth, weight ~ group, FUN = var)\n\n#&gt;   group    weight\n#&gt; 1  ctrl 0.3399956\n#&gt; 2  trt1 0.6299211\n#&gt; 3  trt2 0.1958711\n\n# 或者\nwith(PlantGrowth, tapply(weight, group, var))\n\n#&gt;      ctrl      trt1      trt2 \n#&gt; 0.3399956 0.6299211 0.1958711\n\n\n各个组的方差确实不太相同。\n\n# 假设各组方差不同\noneway.test(weight ~ group, data = PlantGrowth, var.equal = FALSE)\n\n#&gt; \n#&gt;  One-way analysis of means (not assuming equal variances)\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 5.181, num df = 2.000, denom df = 17.128, p-value = 0.01739\n\n\n线性混合效应模型，假定每一组（层）有不同的方差。\n\nfit_gls &lt;- nlme::gls(weight ~ 1,\n  data = PlantGrowth, method = \"ML\",\n  weights = nlme::varIdent(form = ~ 1 | group)\n)\nsummary(fit_gls)\n\n#&gt; Generalized least squares fit by maximum likelihood\n#&gt;   Model: weight ~ 1 \n#&gt;   Data: PlantGrowth \n#&gt;        AIC      BIC    logLik\n#&gt;   67.99884 73.60363 -29.99942\n#&gt; \n#&gt; Variance function:\n#&gt;  Structure: Different standard deviations per stratum\n#&gt;  Formula: ~1 | group \n#&gt;  Parameter estimates:\n#&gt;      ctrl      trt1      trt2 \n#&gt; 1.0000000 1.6028758 0.9103568 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Value Std.Error  t-value p-value\n#&gt; (Intercept) 5.205999  0.115762 44.97158       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.78654574 -0.92900218 -0.08794552  0.61374803  2.09128348 \n#&gt; \n#&gt; Residual standard error: 0.5798892 \n#&gt; Degrees of freedom: 30 total; 29 residual\n\n\n考虑每个组有不同的方差，放开同方差的假设，发现，从对数似然的角度来看，有一定提升。\n\nlogLik(fit_lm)\n\n#&gt; 'log Lik.' -26.80952 (df=4)\n\nlogLik(fit_gls)\n\n#&gt; 'log Lik.' -29.99942 (df=4)\n\n\n\n19.3.2 正态总体方差检验\n总体服从正态分布，有四种常见的参数检验方法：\n\nHartley 检验：各组样本量必须相等。\nBartlett 检验：各组样本量可以相等或不等，但每个组的样本量必须不低于 5。\n修正的 Bartlett 检验：在样本量较大或较小、相等或不等场合都可使用。\nLevene 检验：相当于单因素组间方差分析，相比于 Bartlett 检验，Levene 检验更加稳健。\n\n\n\n\n\n\n\n提示\n\n\n\n在总体分布未知的情况下，检验方差齐性的非参数方法也都可以用在这里。\n\n\n设 \\(x_1,\\cdots,x_{n_1}\\) 是来自总体 \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) 的样本，设 \\(y_1,\\cdots,y_{n_2}\\) 是来自总体 \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) 的样本，设 \\(z_1,\\cdots,z_{n_3}\\) 是来自总体 \\(\\mathcal{N}(\\mu_3,\\sigma_3^2)\\) 的样本。\n\\[\n\\sigma_1^2 = \\sigma_2^2 = \\sigma_3^2 \\quad vs. \\quad \\sigma_1^2,\\sigma_2^2,\\sigma_3^2 \\quad  \\text{不全相等}\n\\]\nBartlett （巴特利特）检验 bartlett.test() 要求总体的分布为正态分布，检验各个组的方差是否有显著性差异，即方差齐性检验，属于参数检验，适用于多个样本的情况。\n\n# 三样本\nbartlett.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Bartlett's K-squared = 2.8786, df = 2, p-value = 0.2371\n\n# 或者\ncar::leveneTest(weight ~ group, data = PlantGrowth)\n\n#&gt; Levene's Test for Homogeneity of Variance (center = median)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  2  1.1192 0.3412\n#&gt;       27\n\n\n\n19.3.3 总体未知均值检验\nKruskal-Wallis 秩和检验 kruskal.test() 检验均值是否齐性。\n\nkruskal.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  weight by group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\n等价的线性模型表示\n\nfit_lm &lt;- lm(rank(weight) ~ group, data = PlantGrowth)\nanova(fit_lm) # summary(fit_lm)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: rank(weight)\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  618.95 309.475  5.1324 0.01291 *\n#&gt; Residuals 27 1628.05  60.298                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFriedman 秩和检验是非参数检验。适用于单因素重复测量数据的方差分析，检验是否存在一组值显著高于或低于其他组。针对 unreplicated blocked data\n典型场景：n 个品酒师对 k 瓶葡萄酒打分，是否存在一组打分显著高于其他组。检验睡眠质量一组人显著好于另一组人。\n\nfriedman.test(extra ~ group | ID, data = sleep)\n\n#&gt; \n#&gt;  Friedman rank sum test\n#&gt; \n#&gt; data:  extra and group and ID\n#&gt; Friedman chi-squared = 9, df = 1, p-value = 0.0027\n\n\nformula 参数取值为 a ~ b | c ，a 表示数据值，b 分组变量 groups，c 表示 blocks。\nQuade 检验 quade.test() 与 Friedman 检验类似，Quade 检验应用于 unreplicated complete block designs。\n\n# 睡眠实验\nquade.test(extra ~ group | ID, data = sleep)\n\n#&gt; \n#&gt;  Quade test\n#&gt; \n#&gt; data:  extra and group and ID\n#&gt; Quade F = 28.557, num df = 1, denom df = 9, p-value = 0.0004661\n\n\n术语涉及实验设计，比如完全区组设计 complete block designs 。1879 年迈克尔逊光速测量数据记录了五次实验，每次试验测量 20 次光速。数据集 morley 中光速 Speed 已经编码过了，为了展示方便，原始观测速度减去了 299000 (km/sec)。\n\n# 光速实验\nquade.test(Speed ~ Expt | Run, data = morley)\n\n#&gt; \n#&gt;  Quade test\n#&gt; \n#&gt; data:  Speed and Expt and Run\n#&gt; Quade F = 3.6494, num df = 4, denom df = 76, p-value = 0.008976\n\n\n\n\nggplot(data = morley, aes(x = Expt, y = Speed, group = Expt)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal() +\n  labs(x = \"Expt\", y = \"Speed (km/sec)\")\n\n\n\n\n\n\n图 19.8: 1879 年迈克尔逊光速实验数据\n\n\n\n\n\n19.3.4 总体未知方差检验\n三个及以上样本的方差齐性检验。进一步地，我们在线性模型的基础上考虑每个实验组有不同的方差，先做方差齐性检验。\n\n# 非参数检验\nfligner.test(weight ~ group, data = PlantGrowth)\n\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Fligner-Killeen:med chi-squared = 2.3499, df = 2, p-value = 0.3088\n\n\n检验的结果显示，可以认为三个组的方差没有显著差异。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-pairwise-data",
    "href": "common-statistical-tests.html#sec-pairwise-data",
    "title": "19  常见的统计检验",
    "section": "\n19.4 配对样本检验",
    "text": "19.4 配对样本检验\n配对样本检验算是两样本检验的一种特殊情况。若待检验的样本不止两个，则两两配对检验。\n\n\n表格 19.5: 配对样本检验\n\n\n\n\n\n\n\n样本\nR 函数\n\n\n两样本\n\n\nt.test(paired = TRUE) 正态总体均值检验\n\nwilcox.test(paired = TRUE) 总体未知均值检验\n\n\n\n\n\n\n\n19.4.1 配对 t 检验\n做两个组的配对 t 检验，函数 t.test() 的参数 paired 设置为 TRUE ，两个组的样本当作配对样本处理。\n\nt.test(extra ~ group, data = sleep, paired = TRUE)\n\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  extra by group\n#&gt; t = -4.0621, df = 9, p-value = 0.002833\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -2.4598858 -0.7001142\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;           -1.58\n\n\n做多个组的两两配对 t 检验，函数 pairwise.t.test() 的参数 paired 设置为 TRUE ，当仅做两个组的配对 t 检验时，检验结果与前面的等价。\n\nwith(sleep, pairwise.t.test(x = extra, g = group, paired = TRUE))\n\n#&gt; \n#&gt;  Pairwise comparisons using paired t tests \n#&gt; \n#&gt; data:  extra and group \n#&gt; \n#&gt;   1     \n#&gt; 2 0.0028\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n输出结果中，组 1 和组 2 配对 t 检验的 P 值为 0.0028。\n\n\n\n\n\n\n提示\n\n\n\n两个组的配对 t 检验还与变截距的线性混合效应模型等价。\n\nlibrary(nlme)\nm &lt;- lme(fixed = extra ~ group, random = ~ 1 | ID, data = sleep)\nsummary(m)\n\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: sleep \n#&gt;        AIC      BIC    logLik\n#&gt;   77.95588 81.51737 -34.97794\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | ID\n#&gt;         (Intercept)  Residual\n#&gt; StdDev:      1.6877 0.8697384\n#&gt; \n#&gt; Fixed effects:  extra ~ group \n#&gt;             Value Std.Error DF  t-value p-value\n#&gt; (Intercept)  0.75 0.6003979  9 1.249172  0.2431\n#&gt; group2       1.58 0.3889588  9 4.062127  0.0028\n#&gt;  Correlation: \n#&gt;        (Intr)\n#&gt; group2 -0.324\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.63372282 -0.34157076  0.03346151  0.31510644  1.83858572 \n#&gt; \n#&gt; Number of Observations: 20\n#&gt; Number of Groups: 10\n\n\n输出结果中，固定效应部分 group2 意味着相对于第 1 组，第 2 组的增加值，其为 1.58，对应的 t 统计量的值为 4.062127， P 值为 0.0028。调用 nlme 包的函数 intervals() 计算固定效应部分 95% 的置信区间。\n\nintervals(m, which = \"fixed\")\n\n#&gt; Approximate 95% confidence intervals\n#&gt; \n#&gt;  Fixed effects:\n#&gt;                  lower est.    upper\n#&gt; (Intercept) -0.6081944 0.75 2.108194\n#&gt; group2       0.7001140 1.58 2.459886\n\n\ngroup2 对应的 95% 的置信区间是 \\((0.7001140, 2.459886)\\) 。\n\n\n\n19.4.2 配对 Wilcoxon 检验\nWilcoxon 检验函数 wilcox.test() 设置 paired = TRUE 可以做配对检验，但是仅限于两个组。\n\n# 不支持\n# wilcox.test(weight ~ group, data = PlantGrowth, paired = TRUE)\n# 支持\nwilcox.test(extra ~ group, data = sleep, paired = TRUE)\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with ties\n\n\n#&gt; Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\n#&gt; compute exact p-value with zeroes\n\n\n#&gt; \n#&gt;  Wilcoxon signed rank test with continuity correction\n#&gt; \n#&gt; data:  extra by group\n#&gt; V = 0, p-value = 0.009091\n#&gt; alternative hypothesis: true location shift is not equal to 0",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multiple-comparisons",
    "href": "common-statistical-tests.html#sec-multiple-comparisons",
    "title": "19  常见的统计检验",
    "section": "\n19.5 多重假设检验",
    "text": "19.5 多重假设检验\n同时检验多个统计假设。\n\n\n表格 19.6: 多重假设检验\n\n\n\n\n\n\n\n样本\nR 函数\n\n\n多样本\n\n\npairwise.t.test() 正态总体均值检验\n\npairwise.prop.test() 二项总体比例检验\n\npairwise.wilcox.test() 总体未知均值检验\n\n\n\n\n\n\n\n19.5.1 多重 t 检验\n数据集 sleep 仅有两个组，数据集 PlantGrowth 包含三个组，下面以数据集 PlantGrowth 为例，介绍做多个组同时进行两两比较的 t 检验。\n\n# 样本成对的情况\nwith(PlantGrowth, pairwise.t.test(x = weight, g = group, paired = TRUE))\n\n#&gt; \n#&gt;  Pairwise comparisons using paired t tests \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.346 -    \n#&gt; trt2 0.220 0.058\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n函数 pairwise.t.test() 以 P 值给出两两配对比较的结果，trt1 和 ctrl 配对比较，P 值为 0.346，trt2 和 ctrl 配对比较，P 值为 0.220，以此类推。\n\n# 样本非成对的情况\nwith(PlantGrowth, pairwise.t.test(x = weight, g = group))\n\n#&gt; \n#&gt;  Pairwise comparisons using t tests with pooled SD \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.194 -    \n#&gt; trt2 0.175 0.013\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n19.5.2 多重比例检验\n对于离散数据，做两两比例检验，采用函数 pairwise.prop.test() ，如下示例含有 4 个组。\n\nsmokers &lt;- c(83, 90, 129, 70)\npatients &lt;- c(86, 93, 136, 82)\npairwise.prop.test(smokers, patients)\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n#&gt; Warning in prop.test(x[c(i, j)], n[c(i, j)], ...): Chi-squared approximation\n#&gt; may be incorrect\n\n\n#&gt; \n#&gt;  Pairwise comparisons using Pairwise comparison of proportions \n#&gt; \n#&gt; data:  smokers out of patients \n#&gt; \n#&gt;   1     2     3    \n#&gt; 2 1.000 -     -    \n#&gt; 3 1.000 1.000 -    \n#&gt; 4 0.119 0.093 0.124\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n19.5.3 Wilcoxon 检验\nWilcoxon 检验的是两个总体的均值是否相等。\n函数 pairwise.wilcox.test() 做两个及以上组的两两比较检验。\n\nwith(PlantGrowth, pairwise.wilcox.test(x = weight, g = group))\n\n#&gt; Warning in wilcox.test.default(xi, xj, paired = paired, ...): cannot compute\n#&gt; exact p-value with ties\n\n\n#&gt; \n#&gt;  Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n#&gt; \n#&gt; data:  weight and group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.199 -    \n#&gt; trt2 0.126 0.027\n#&gt; \n#&gt; P value adjustment method: holm\n\n\n\n19.5.4 Dunn 检验\ndunn.test 包提供函数 dunn.test() 实现 Dunn 检验，将 Kruskal-Wallis 秩和检验用于两两比较。\n\nlibrary(dunn.test)\nwith(PlantGrowth, dunn.test(x = weight, g = group, method = \"holm\", altp = TRUE))\n\n#&gt;   Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data: weight and group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.02\n#&gt; \n#&gt; \n#&gt;                          Comparison of weight by group                         \n#&gt;                                     (Holm)                                     \n#&gt; Col Mean-|\n#&gt; Row Mean |       ctrl       trt1\n#&gt; ---------+----------------------\n#&gt;     trt1 |   1.117725\n#&gt;          |     0.2637\n#&gt;          |\n#&gt;     trt2 |  -1.689289  -2.807015\n#&gt;          |     0.1823    0.0150*\n#&gt; \n#&gt; alpha = 0.05\n#&gt; Reject Ho if p &lt;= alpha",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-distribution-test",
    "href": "common-statistical-tests.html#sec-distribution-test",
    "title": "19  常见的统计检验",
    "section": "\n19.6 总体分布的检验",
    "text": "19.6 总体分布的检验\n前面介绍的检验方法都是对总体的某个特征数（均值、方差）进行检验，下面介绍的检验方法是针对分布的性质。比如样本是否来自正态分布，两个样本是否来自同一分布，样本点之间是否相互独立，样本点列是否平稳等。通过检验方法探索样本的分布性质。\n\n19.6.1 正态性检验\n什么样的数据是正态的，理论上是清楚的，对统计建模来说，更实际的问题是什么样的数据是够正态的！探索性数据分析是不断提出假设和验证假设的过程。\n\nUsually (but not always) doing tests of normality reflect a lack of understanding of the power of rank tests, and an assumption of high power for the tests (qq plots don’t always help with that because of their subjectivity). When possible it’s good to choose a robust method. Also, doing pre-testing for normality can affect the type I error of the overall analysis.\n— Frank Harrell 1\n\n检验：拒绝原假设和接受原假设的风险，数据本身和理论的正态分布的距离，抛开 P 值\nShapiro 和 Wilk 提出的 W 检验 (Shapiro 和 Wilk 1965) ，对应的 R 函数为 shapiro.test()\n\nset.seed(20232023)\nx &lt;- rnorm(100, mean = 5, sd = 3)\nshapiro.test(x)\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.98635, p-value = 0.3954\n\n\n\nThe issue really comes down to the fact that the questions: “exactly normal?”, and “normal enough?” are 2 very different questions (with the difference becoming greater with increased sample size) and while the first is the easier to answer, the second is generally the more useful one.\n— Greg Snow 2\n\nEP 检验对多种备择假设有较高的效率，利用样本的特征函数和正态分布的特征函数的差的模的平方产生的一个加权积分得到 EP 检验统计量 (Epps 和 Pulley 1983)\n\n\n\n\n\n\n提示\n\n\n\n样本量 \\(n \\geq 200\\) EP 检验统计量 \\(T_{EP}\\) 非常接近 \\(n = \\infty\\) 时 \\(T_{EP}\\) 的分位数。\n\n\n设 \\(x_1, \\ldots, x_n\\) 是来自正态总体 \\(\\mathcal{N}(\\mu,\\sigma^2)\\) 的样本， EP 检验统计量定义为\n\\[\nT_{EP} = 1 + \\frac{n}{\\sqrt{3}} + \\frac{2}{n}\\sum_{i=2}^{n}\\sum_{j=1}^{i-1}\\exp\\big\\{ - \\frac{(x_j - x_i)^2}{2s^2_{\\star}}  \\big\\} - \\sqrt{2} \\sum_{i=1}^{n}\\exp\\big\\{- \\frac{(x_i - \\bar{x})^2}{4s^2_{\\star}}  \\big\\}\n\\]\n其中 \\(\\bar{x},s^2_{\\star}\\) 分别是样本均值和（除以 \\(n\\) 的）样本方差。\n\n19.6.2 同分布检验\nLilliefors 检验 3 和单样本的 ks 检验的关系\n\nAs to whether you can do a Lilliefors test for several groups, that depends entirely on your ability to understand what the underlying question would be (see Adams D 1979).\n— Knut M. Wittkowski 4\n\nKolmogorov-Smirnov 检验：单样本或两样本的同分布检验 ks.test()\n\n# 数据 x 与正态分布比较\nks.test(x, y = \"pnorm\")\n\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x\n#&gt; D = 0.85897, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: two-sided\n\n\n\n19.6.3 相关性检验\n样本的相关性检验 cor.test()：Pearson’s 相关系数检验，Kendall’s \\(\\tau\\) 检验或者 Spearman’s \\(\\rho\\) 检验。基于美国高等法院律师对州法官的评级数据集 USJudgeRatings 介绍各项评分之间的相关性。\n\n# cor.test(method = \"pearson\")  # lm(y ~ 1 + x)\ncor.test(~ CONT + INTG, data = USJudgeRatings)\n\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  CONT and INTG\n#&gt; t = -0.8605, df = 41, p-value = 0.3945\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.4168591  0.1741182\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.1331909\n\n\n其中，变量 CONT 表示律师与法官的联系次数，INTG 表示司法公正。\n\n# cor.test(method = \"kendall\")\n# cor.test(method = \"spearman\") # lm(rank(y) ~ 1 + rank(x))\n\n\n19.6.4 独立性检验\n时间序列独立性检验 Box.test() 计算 Box-Pierce 或 Ljung-Box 检验统计量来检查给定时间序列的独立性假设。\n\n19.6.5 平稳性检验\n时间序列单位根检验，检验时间序列平稳性 Phillips-Perron 的单位根检验 PP.test()\n\nPP.test(x, lshort = TRUE)",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-multivariate-hypothesis-testing",
    "href": "common-statistical-tests.html#sec-multivariate-hypothesis-testing",
    "title": "19  常见的统计检验",
    "section": "\n19.7 多元分布情形",
    "text": "19.7 多元分布情形\n\nHotelling T2 检验：总体服从多元正态分布，两样本均值之差的检验。\nMauchly 球形检验：总体服从多元正态分布，单样本协方差矩阵的检验。\n\n\n19.7.1 Hotelling T2 检验\nHotelling T2 检验是一维情形下两样本 \\(t\\) 检验的多维推广。\n\n19.7.2 Mauchly 球形检验\nMauchly 球形检验 mauchly.test() 检验：Wishart 分布的协方差矩阵是否正比于给定的矩阵。一组样本来自多元正态分布，样本的协方差矩阵是关于样本的随机矩阵，随机矩阵的分布服从 Wishart 分布。\n如果 \\(\\bm{x_1}, \\bm{x_2}, \\cdots, \\bm{x_m}\\)，\\(\\bm{x_i} \\in \\mathbb{R}^p\\)，\\(\\bm{x_i} \\overset{i.i.d}{\\sim} \\mathrm{MVN}(0,\\Sigma)\\)，即 \\(m\\) 个样本点都服从均值为 \\(0\\)，协方差矩阵为 \\(\\Sigma\\) 的 \\(p\\) 维多元正态分布 \\(\\mathrm{MVN}(0,\\Sigma)\\)，且样本点之间相互独立。则 \\(X = \\bm{x}^{\\top}\\bm{x}\\) 服从参数为 \\(\\Sigma\\) ，自由度为 \\(m\\) 的 Wishart 分布 \\(W_p(\\Sigma, m)\\)。概率密度函数如下\n\\[\nf(X) = \\frac{1}{2^{\\frac{mp}{2}}|\\Sigma|^{\\frac{m}{2}}\\Gamma_{p}(\\frac{m}{2})}|X|^{(m-p-1)/2}\\exp\\{-\\frac{1}{2}\\mathrm{tr}(\\Sigma^{-1}X)\\}\n\\]\n其中， \\(\\Gamma_p\\) 是多元伽马函数，定义如下\n\\[\n\\Gamma_p(\\frac{m}{2}) = \\pi^{p(p-1)/4}\\prod_{j=1}^{p}\\Gamma(\\frac{m}{2} - \\frac{j-1}{2})\n\\]\nR 语言内置了一个模拟数生成器，可以直接模拟出服从 Wishart 分布 \\(W_p(\\Sigma, m)\\) 的样本，\\(m = \\mathrm{df}, \\Sigma = \\mathrm{Sigma}\\)。 R 语言命令如下：\n\nrWishart(n, df, Sigma)\n\n其中，整型参数 n 指定样本量，数值参数 df 指定自由度，正定的 \\(p \\times p\\) 矩阵 Sigma 指定 Wishart 分布的矩阵参数。rWishart() 返回一个 \\(p\\times p \\times n\\) 数组 \\(R\\)，其中 \\(R[,,i]\\) 是正定矩阵，是服从 Wishart 分布 \\(W_p(\\Sigma, m)\\) 的一个样本点，其中 \\(m = \\mathrm{df}, \\Sigma = \\mathrm{Sigma}\\)。\n\nset.seed(2022)\n# 构造 n 个随机矩阵\nS &lt;- matrix(c(1.2, 0.9, 0.9, 1.2), nrow = 2, ncol = 2)\nrWishart(n = 3, df = 2, Sigma = S)\n\n#&gt; , , 1\n#&gt; \n#&gt;          [,1]      [,2]\n#&gt; [1,] 3.213745 1.2445391\n#&gt; [2,] 1.244539 0.5032642\n#&gt; \n#&gt; , , 2\n#&gt; \n#&gt;          [,1]     [,2]\n#&gt; [1,] 4.443057 3.387850\n#&gt; [2,] 3.387850 2.605341\n#&gt; \n#&gt; , , 3\n#&gt; \n#&gt;          [,1]     [,2]\n#&gt; [1,] 3.614911 4.797919\n#&gt; [2,] 4.797919 6.846811\n\n\n随机矩阵 \\(M\\) 的期望 \\(\\mathsf{E}(M) = m \\times \\Sigma\\)，随机矩阵 \\(M\\) 中每个元素的方差\n\\[\n\\mathsf{Var}(M_{ij}) = m (\\Sigma_{ij}^2 + \\Sigma_{ii}\\Sigma_{jj}), \\quad S = \\Sigma\n\\]\n若 \\(p = 1\\)，即 \\(\\Sigma\\) 是一个标量 \\(\\sigma^2\\)，Wishart 分布退化为自由度为 \\(\\mathrm{df}\\) 的卡方分布 \\(\\chi^2\\)，即 \\(W_1(\\sigma^2, m) = \\sigma^2\\chi_{m}^2\\)。下面计算随机矩阵 \\(M\\) 的期望。\n\nset.seed(2022)\nWish &lt;- rWishart(n = 3000, df = 2, Sigma = S)\n# 计算随机矩阵 M 的期望\napply(Wish, MARGIN = 1:2, FUN = mean)\n\n#&gt;          [,1]     [,2]\n#&gt; [1,] 2.375915 1.792558\n#&gt; [2,] 1.792558 2.430074\n\n# 随机矩阵 M 的期望理论值\n2 * S\n\n#&gt;      [,1] [,2]\n#&gt; [1,]  2.4  1.8\n#&gt; [2,]  1.8  2.4\n\n\n接着计算随机矩阵 \\(M\\) 的方差。\n\n# 样本方差\napply(Wish, MARGIN = 1:2, var)\n\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.668746 4.472606\n#&gt; [2,] 4.472606 5.729270\n\n# 理论方差\n2*(S^2 + tcrossprod(diag(S)))\n\n#&gt;      [,1] [,2]\n#&gt; [1,] 5.76 4.50\n#&gt; [2,] 4.50 5.76",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-common-statistical-tests-notes",
    "href": "common-statistical-tests.html#sec-common-statistical-tests-notes",
    "title": "19  常见的统计检验",
    "section": "\n19.8 假设检验的一些注记",
    "text": "19.8 假设检验的一些注记\n真实数据的情况是复杂多样的，本章按照数据情况对检验方法分类，方便读者根据手头的数据情况，快速从众多的方法中定位最合适的检验方法。依次是单样本检验、两样本检验、多样本检验、计数数据检验、配对样本检验。如果已知符合参数检验的条件，优先考虑参数检验。如果不确定是否符合参数检验的条件，对参数检验和非参数检验方法都适用，非参数检验方法的功效更大，方法更优。在总体分布未知的情况下，无论是对均值检验还是对方差检验，大部分情况下都需要非参数检验方法。\n在假设检验理论方面作出贡献的人非常多，自 Karl Pearson 提出卡方统计量、卡方分布和卡方检验以来，陆续涌现出来一批人及载入史册的工作，见下表。不难看出，19 世纪后半叶至20世纪前半叶，假设检验理论经过一个世纪的发展趋于成熟。从假设检验这个细分领域也印证了世界的统计中心从英国逐渐转移到美国，相比而言，中国在这方面的贡献微乎其微。笔者同时也注意到很多检验方法都是以人名命名的，且已经被编写到各类统计软件中。R 语言中有十分丰富的统计检验函数，根据这些函数及其帮助文档可以追溯到检验方法的发明者，再从维基百科中找到学者及其提出的检验方法的详情页，最后，根据学者的出生日期排序整理成表格。\n\n\n表格 19.7: 对假设检验理论有重要贡献的学者\n\n\n\n\n\n\n\n\n\n\n\n姓名\n国籍\n出生\n死亡\n寿命\n贡献\n\n\n\nK. Pearson\n英国\n1857-03-27\n1936-04-27\n79\n卡方分布、卡方检验\n\n\nC. Spearman\n英国\n1863-09-10\n1945-09-17\n82\nSpearman’s \\(\\rho\\)\n\n\n\nW. S. Gosset\n英国\n1876-06-13\n1937-10-16\n61\nt 分布、t 检验\n\n\nR. A. Fisher\n英国\n1890-02-17\n1962-07-29\n72\nF 检验、Fisher 精确检验\n\n\nF. Wilcoxon\n美国\n1892-09-02\n1965-11-18\n73\nWilcoxon 秩检验\n\n\nH. Cramér\n瑞士\n1893-09-25\n1985-10-05\n92\nCramér’s V\n\n\nJ. Neyman\n波兰、美国\n1894-04-16\n1981-08-05\n87\nNeyman-Pearson 引理\n\n\nE. S. Pearson\n英国\n1895-08-11\n1980-06-12\n84\nNeyman-Pearson 引理\n\n\nH. Hotelling\n美国\n1895-09-29\n1973-12-26\n78\nHotelling T2 检验\n\n\nE. J. G. Pitman\n澳大利亚\n1897-10-29\n1993-07-21\n95\nPitman 估计\n\n\nJ. Wishart\n英国\n1898-11-28\n1956-07-14\n57\nWishart 分布\n\n\nQ. M. McNemar\n美国\n1900-02-20\n1986-07-03\n86\nMcNemar 检验\n\n\nF. Yates\n英国\n1902-05-12\n1994-06-17\n92\nYates 矫正\n\n\nA. Wald\n匈牙利\n1902-10-31\n1950-12-13\n48\nWald 检验\n\n\nA. Kolmogorov\n苏联\n1903-04-25\n1987-10-20\n84\nKolmogorov-Smirnov 检验\n\n\nS. S. Wilks\n美国\n1906-06-17\n1964-03-07\n57\nWilks 检验/似然比检验\n\n\nJ. W. Mauchly\n美国\n1907-08-30\n1980-01-08\n72\nMauchly 球形检验\n\n\nM. Kendall\n英国\n1907-09-06\n1983-03-29\n76\nKendall’s \\(\\tau\\)\n\n\n\nW. G. Cochran\n英国、美国\n1909-07-15\n1980-03-29\n70\nCochran–Mantel–Haenszel 检验\n\n\nM. S. Bartlett\n英国\n1910-06-18\n2002-01-08\n91\nBartlett 检验\n\n\nW. M. Haenszel\n美国\n1910-06-19\n1998-03-13\n87\nCochran–Mantel–Haenszel 检验\n\n\nB. L. Welch\n英国\n1911\n1989-12-29\n78\nWelch t 检验\n\n\nH. O. Hartley\n德国\n1912-04-13\n1980-12-30\n68\nHartley 检验\n\n\nM. Friedman\n美国\n1912-07-31\n2006-11-16\n94\nFriedman 秩和检验\n\n\nW. A. Wallis\n美国\n1912-11-05\n1998-10-12\n85\nKruskal-Wallis 检验\n\n\nH. Levene\n美国\n1914-01-17\n2003-07-02\n89\nLevene 检验\n\n\nJ. W. Tukey\n美国\n1915-06-16\n2000-07-26\n85\nTukey’s HSD 检验\n\n\nO. J. Dunn\n美国\n1915-09-01\n2008-01-12\n92\nDunn 检验\n\n\nE. L. Lehmann\n法国、美国\n1917-11-20\n2009-09-12\n91\nLehmann-Scheffé 定理\n\n\nT. W. Anderson\n美国\n1918-06-05\n2016-09-17\n98\nAnderson–Darling 检验\n\n\nN. Mantel\n美国\n1919-02-16\n2002-05-25\n83\nCochran–Mantel–Haenszel 检验\n\n\nW. Kruskal\n美国\n1919-10-10\n2005-04-21\n85\nKruskal-Wallis 检验\n\n\nGeorge E. P. Box\n英国、美国\n1919-10-18\n2013-03-28\n93\nBox-Pierce 检验\n\n\nC. R. Rao\n印度、美国\n1920-09-10\n2023-08-22\n102\nScore 检验\n\n\nM. Wilk\n加拿大\n1922-12-18\n2013-02-19\n90\nShapiro-Wilk 检验\n\n\nJ. Durbin\n英国\n1923-06-30\n2012-06-23\n88\nDurbin 检验\n\n\nL. Le Cam\n法国\n1924-11-18\n2000-04-25\n75\n渐近理论\n\n\nH. Lilliefors\n美国\n1928-06-14\n2008-02-23\n80\nLilliefors 检验\n\n\nS. S. Shapiro\n美国\n1930-07-13\n-\n93\nShapiro-Wilk 检验\n\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n笔者仅根据自己搜集了解的材料制作此表，受一定的局限，或有缺漏和主观。20 世纪 60 年代后，假设检验理论开始成熟起来了，所以仅考虑 1930 年以前出生的。此外，学者需具有一定的名气，至少收录在维基百科词条里。\n\n\n其中，最重要的统计学家及其学术传承关系见下 图 19.9 。\n\n\n\n\n\nflowchart LR\n  F_Galton(F. Galton\\n 1822-1911) --&gt; K_Pearson(K. Pearson\\n 1857-1936)\n  K_Pearson --&gt; R_A_Fisher(R. A. Fisher \\n 1890-1962)\n  R_A_Fisher --&gt; J_Neyman(J. Neyman\\n1894-1981)\n  R_A_Fisher --&gt; E_S_Pearson(E. S. Pearson \\n1895-1980)\n  J_Neyman --&gt; E_L_Lehmann(E. L. Lehmann\\n1917-2009)\n  E_S_Pearson --&gt; A_Wald(A. Wald\\n1902-1950)\n\n\n\n\n图 19.9: 最重要的统计学家及其学术传承关系\n\n\n\n\nF. Galton 是 K. Pearson 的老师，E. S. Pearson 是 K. Pearson 的儿子。E. L. Lehmann 是 J. Neyman 的学生，J. Neyman 和 E. S. Pearson 一起提出 N-P 引理，是置信区间和假设检验理论的奠基人。假设检验和区间估计、决策理论是紧密相关的，A. Wald 是继 J. Neyman 和 E. S. Pearson 之后，继续开疆拓土的一位统计学家，不幸的是，在一场飞机事故中英年早逝。\n\n19.8.1 假设检验和多重比较的关系\nFDR 是 False Discovery Rate 的简称\n\n19.8.2 假设检验和方差分析的关系\n\n19.8.2.1 单因素一元方差分析\n函数 aov() 可以做单、双因素一元方差分析\n\nfit_aov &lt;- aov(weight ~ group, data = PlantGrowth)\n\n两两比较，多重比较\n\nTukeyHSD(fit_aov)\n\n#&gt;   Tukey multiple comparisons of means\n#&gt;     95% family-wise confidence level\n#&gt; \n#&gt; Fit: aov(formula = weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt; $group\n#&gt;             diff        lwr       upr     p adj\n#&gt; trt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711\n#&gt; trt2-ctrl  0.494 -0.1972161 1.1852161 0.1979960\n#&gt; trt2-trt1  0.865  0.1737839 1.5562161 0.0120064\n\n\n自己实现方差分析\n\n# 自由度\ndf1 &lt;- 2\ndf2 &lt;- 27\n# 每组样本量\ngroup.size &lt;- 10\n# 组间方差\nsq.between &lt;- sum(tapply(\n  PlantGrowth$weight, PlantGrowth$group,\n  function(x) (mean(x) - mean(PlantGrowth$weight))^2\n)) * group.size\n\nmean.sq.between &lt;- sq.between / df1\n\n# 组内方差\nsq.within &lt;- sum(tapply(\n  PlantGrowth$weight, PlantGrowth$group,\n  function(x) sum((x - mean(x))^2)\n))\n\nmean.sq.within &lt;- sq.within / df2\n# F 统计量\nf.value &lt;- mean.sq.between / mean.sq.within\nf.value\n\n#&gt; [1] 4.846088\n\n# P 值\np.value &lt;- 1 - pf(f.value, df1, df2)\np.value\n\n#&gt; [1] 0.01590996\n\n\n从假设检验角度看单因素方差分析，方差分析其实是在比较多个组的均值是否有显著差异。\n\noneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)\n\n#&gt; \n#&gt;  One-way analysis of means\n#&gt; \n#&gt; data:  weight and group\n#&gt; F = 4.8461, num df = 2, denom df = 27, p-value = 0.01591\n\n\n方差分析还可以纳入线性模型的框架内\n\nfit &lt;- lm(weight ~ group, data = PlantGrowth)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.0710 -0.4180 -0.0060  0.2627  1.3690 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   5.0320     0.1971  25.527   &lt;2e-16 ***\n#&gt; grouptrt1    -0.3710     0.2788  -1.331   0.1944    \n#&gt; grouptrt2     0.4940     0.2788   1.772   0.0877 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.6234 on 27 degrees of freedom\n#&gt; Multiple R-squared:  0.2641, Adjusted R-squared:  0.2096 \n#&gt; F-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\n\nanova(fit)\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: weight\n#&gt;           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \n#&gt; group      2  3.7663  1.8832  4.8461 0.01591 *\n#&gt; Residuals 27 10.4921  0.3886                  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n假定各个组来自正态总体，且它们的方差相同，从 F 统计量的值和检验的 P 值看，方差分析 aov() 、假设检验 oneway.test() 和线性模型 lm() 在这里等价了。\n\n19.8.2.2 双因素一元方差分析\n\nwith(ToothGrowth, interaction.plot(supp, dose, len))\n\n\n\n\n\n\n图 19.10: OJ 和 VC 的交互作用\n\n\n\n\n如果 dose = 2， 则 len 与提供的方式 supp 没有关系。\n\nfit_aov &lt;- aov(len ~ supp * dose, data = ToothGrowth)\nfit_aov\n\n#&gt; Call:\n#&gt;    aov(formula = len ~ supp * dose, data = ToothGrowth)\n#&gt; \n#&gt; Terms:\n#&gt;                      supp      dose supp:dose Residuals\n#&gt; Sum of Squares   205.3500 2224.3043   88.9201  933.6349\n#&gt; Deg. of Freedom         1         1         1        56\n#&gt; \n#&gt; Residual standard error: 4.083142\n#&gt; Estimated effects may be unbalanced\n\n\n\n19.8.2.3 单因素多元方差分析\nPlantGrowth 属于一元方差分析，观测变量只有植物干重一个变量。如果推广到多个变量，就是多元方差分析 multivariate analysis of variance 。不同种类的鸢尾花的萼片长度的分布有所不同。\n\nlibrary(ggplot2)\nlibrary(ggridges)\nggplot(data = iris, aes(x = Sepal.Length, y = Species, fill = Species)) +\n  scale_fill_brewer(palette = \"Greys\") +\n  geom_density_ridges(bandwidth = 0.2) +\n  theme_ridges(font_size = 12, font_family = \"sans\")\n\n\n\n\n\n\n图 19.11: 鸢尾花萼片长度的分布\n\n\n\n\n\nfit &lt;- manova(cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, data = iris)\nsummary(fit, test = \"Wilks\")\n\n#&gt;            Df    Wilks approx F num Df den Df    Pr(&gt;F)    \n#&gt; Species     2 0.023439   199.15      8    288 &lt; 2.2e-16 ***\n#&gt; Residuals 147                                              \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nP 值小于 0.0.5，说明 iris 数据集三个组的均值向量有显著差异。关于均值向量的检验方法，请看 ?summary.manova 。\n按 Species 分组统计各个变量的样本均值、样本方差\n\naggregate(data = iris, cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, mean)\n\n#&gt;      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; 1     setosa        5.006       3.428        1.462       0.246\n#&gt; 2 versicolor        5.936       2.770        4.260       1.326\n#&gt; 3  virginica        6.588       2.974        5.552       2.026\n\naggregate(data = iris, cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, var)\n\n#&gt;      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt; 1     setosa    0.1242490  0.14368980   0.03015918  0.01110612\n#&gt; 2 versicolor    0.2664327  0.09846939   0.22081633  0.03910612\n#&gt; 3  virginica    0.4043429  0.10400408   0.30458776  0.07543265\n\n\n\n19.8.3 假设检验与区间估计的关系\n区间估计的意义是解决点估计可靠性问题，它用置信系数解决了对估计结果的信心问题，弥补了点估计的不足。置信系数是最大的置信水平。\nBase R 提供的 binom.test() 函数可以精确计算置信区间，即所谓的 Clopper-Pearson 区间，而 prop.test() 函数可近似计算置信区间，即所谓的 Wilson 区间。以单样本的比例检验为例。\n\n# 近似区间估计\nprop.test(x = 2, n = 10, p = 0.95, conf.level = 0.95, correct = TRUE)\n\n#&gt; Warning in prop.test(x = 2, n = 10, p = 0.95, conf.level = 0.95, correct =\n#&gt; TRUE): Chi-squared approximation may be incorrect\n\n\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  2 out of 10, null probability 0.95\n#&gt; X-squared = 103.16, df = 1, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true p is not equal to 0.95\n#&gt; 95 percent confidence interval:\n#&gt;  0.03542694 0.55781858\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.2\n\n# 精确区间估计\nbinom.test(x = 2, n = 10, p = 0.95, conf.level = 0.95)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  2 and 10\n#&gt; number of successes = 2, number of trials = 10, p-value = 1.605e-09\n#&gt; alternative hypothesis: true probability of success is not equal to 0.95\n#&gt; 95 percent confidence interval:\n#&gt;  0.02521073 0.55609546\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                    0.2\n\n\n实际达到的置信度水平随真实的未知参数值和样本量的变化而剧烈波动，这意味着这种参数估计方法在实际应用中不可靠、真实场景中参数真值是永远未知的，样本量是可控的，并且是可以变化的。根本原因在于这类分布是离散的，比如这里的二项分布。当样本数据服从离散的分布，置信区间的端点也是离散的。这种缺陷是无法避免的，清晰的置信区间和离散的数据之间存在无法调和的冲突。\n\n19.8.4 常见的统计检验是线性模型\n两样本的均值检验：非参数检验方法\n\n19.8.4.1 Wilcoxon 符号秩检验\n与 wilcox.test() 等价的线性模型\n\nsigned_rank &lt;- function(x) sign(x) * rank(abs(x))\nfit &lt;- lm(signed_rank(extra) ~ group, data = sleep)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = signed_rank(extra) ~ group, data = sleep)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -14.55  -6.55   0.90   6.90  13.95 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)  \n#&gt; (Intercept)    3.050      2.872   1.062   0.3022  \n#&gt; group2         8.300      4.061   2.044   0.0559 .\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 9.081 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.1884, Adjusted R-squared:  0.1433 \n#&gt; F-statistic: 4.177 on 1 and 18 DF,  p-value: 0.05589\n\n\n\n19.8.4.2 Kruskal-Wallis 秩和检验\n与 kruskal.test() 等价的线性模型表示。\n\nfit &lt;- lm(rank(extra) ~ group, data = sleep)\nsummary(fit)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = rank(extra) ~ group, data = sleep)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -8.450 -3.925 -0.500  5.275  8.950 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)    8.050      1.738   4.633 0.000207 ***\n#&gt; group2         4.900      2.457   1.994 0.061520 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.495 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.1809, Adjusted R-squared:  0.1354 \n#&gt; F-statistic: 3.976 on 1 and 18 DF,  p-value: 0.06152\n\n\n\n19.8.5 假设检验的工业应用\n传统的试验设计为什么不适用于互联网？因为Fisher的实验设计和方差分析，主要针对的是受控对象，比如测试武器、肥料配比、飞机制造等实体的东西。互联网是虚拟经济，实验的对象是人，对平台来说，人的行为是半知半解，更不受控，所以需要成千上万、乃至几十万的样本才能抵消样本内部的随机性。互联网数据的噪声太多、太大了，微小的变化就好像一粒小石子扔进大海里，要获得样本间显著的差异性，需要累积相当的样本量。另一方面，大型的互联网公司，搜索、推荐、广告等业务相对成熟，提升关键指标，拿到好的结果，往往比较困难。成熟的业务几乎不太可能一次实验拿到很好的结果，所以，方向比努力重要，更快地迭代，跑在同行前面，更快地试错（想法），试更多的错（想法），更好地试错（想法），累积更多的经验，做更多地创新，这是 A/B 实验平台的核心价值。\n曾经，在学校里，我总想获得一个全局最优解，并且还有这样的情结，到了厂里，发现没人研究全局最优解，大家都在做 A/B 实验优化自己的子业务和方向。有时候这个细分业务方向甚至也就小几万的用户了。 全局最优解和局部最优解，我们不太可能获得全局最优解，一则全局最优解受影响的因素很多，而这些因素变化很快，所以，即使可以获得全局最优解，代价会非常大，那么，怎么办呢？还不如获取局部最优解，研究一个个局部显然比研究全局要简单的多，此外，研究局部的好处是可以快速地随业务迭代。\n一个完整的实验周期包含提出问题、设计实验、收集数据、组织数据、统计检验、分析结论、数据解读、数据交流、决策行动、业务价值。这是一个闭环，根据业务中发现的问题，提出解决方法，并设计实验验证。问题有时候就是机会，奋斗的方向，解决问题自然就会带来业务价值。实验又可以按业务问题、数据问题和统计问题划分三个阶段。\n\n业务问题：根据目标确定方向，找到有价值的、可以解决的业务问题，再提出合理的统计假设。\n数据问题：数据收集、数据组织、数据管理、数据治理，验证数据流的完整性、一致性等。\n统计问题：设计实验方案，包括分流、实验周期等，利用假设检验、区间估计和功效分析等统计工具完成显著性分析、可靠性分析，撰写数据分析和评估报告。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#sec-common-statistical-tests-exercise",
    "href": "common-statistical-tests.html#sec-common-statistical-tests-exercise",
    "title": "19  常见的统计检验",
    "section": "\n19.9 习题",
    "text": "19.9 习题\n\n分析《红楼梦》的情景描写。参考 2009 年东南大学韦博成教授将两个独立二项总体的等价性检验应用于《红楼梦》前80回与后40回某些文风差异的统计分析 (韦博成 2009)。\n\n根据数据集 chickwts 分析不同喂食方式对小鸡体重的影响。（单因素方差分析）\n\nggplot(data = chickwts, aes(x = feed, y = weight)) +\n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n图 19.12: 不同喂食方式对小鸡的影响\n\n\n\n\n\n\n根据数据集 ChickWeight 分析 4 种喂食方式对小鸡体重有影响，每个小鸡本身对喂食方式的接受、吸收程度不一样、它们本身的素质不一样（个体差异），要考察喂食的方式的影响，应该剔除掉个体差异，才是喂食方式的真正影响。\n\nggplot(data = ChickWeight, aes(x = Time, y = weight, group = Chick, color = Diet)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~Diet) +\n  theme_minimal()\n\n\n\n\n\n\n图 19.13: 不同喂食方式对小鸡的影响（续）\n\n\n\n\n\n\n\n\n\n\nAnsari, A. R., 和 R. A. Bradley. 1960. 《Rank-Sum Tests for Dispersions》. The Annals of Mathematical Statistics 31 (4): 1174–89. https://doi.org/10.1214/aoms/1177705688.\n\n\nCohen, Jacob. 1994. 《The Earth Is Round (\\(p &lt; .05\\))》. American Psychologist 49 (12): 997–1003. https://doi.org/10.1037/0003-066x.49.12.997.\n\n\nDobson, Annette J. 1983. An Introduction to Statistical Modelling. 1st 本. London: Chapman; Hall/CRC. https://doi.org/10.1007/978-1-4899-3174-0.\n\n\nEpps, T. W., 和 Lawrence B. Pulley. 1983. 《A Test for Normality Based on the Empirical Characteristic Function》. Biometrika 70 (3): 723–26. https://doi.org/10.2307/2336512.\n\n\nFligner, Michael A., 和 Timothy J. Killeen. 1976. 《Distribution-Free Two-Sample Tests for Scale》. Journal of the American Statistical Association 71 (353): 210–13. https://doi.org/10.1080/01621459.1976.10481517.\n\n\nHeyde, C. C., E. Seneta, P. Crépel, S. E. Fienberg, 和 J. Gani. 2001. Statisticians of the Centuries. New York, NY: Springer-Verlag. https://doi.org/10.1007/978-1-4613-0179-0.\n\n\nHSU, P. L. 1938. 《Contribution to the theory of \"Student’s\" \\(T\\)-test as applied to the problem of two samples》. Statistical Research Memoirs 2: 1–24.\n\n\n———. 1983. Collected Papers. New York, NY: Springer-Verlag.\n\n\nKim, Seock-Ho, 和 Allan S. Cohen. 1998. 《On the Behrens-Fisher Problem: A Review》. Journal of Educational and Behavioral Statistics 23 (4): 356–77. https://doi.org/10.2307/1165281.\n\n\nMood, A. M. 1954. 《On the Asymptotic Efficiency of Certain Nonparametric Two-Sample Tests》. The Annals of Mathematical Statistics 25 (3): 514–22. https://doi.org/10.1214/aoms/1177728719.\n\n\nShapiro, S. S., 和 M. B. Wilk. 1965. 《An analysis of variance test for normality (complete samples)》. Biometrika 52 (3-4): 591–611. https://doi.org/10.1093/biomet/52.3-4.591.\n\n\n\"Student\". 1908. 《The probable error of a mean》. Biometrika 6: 1–25.\n\n\n韦博成. 2009. 《《红楼梦》前80回与后40回某些文风差异的统计分析（两个独立二项总体等价性检验的一个应用）》. 应用概率统计 25 (4): 441–48. https://doi.org/10.3969/j.issn.1001-4268.2009.04.012.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "common-statistical-tests.html#footnotes",
    "href": "common-statistical-tests.html#footnotes",
    "title": "19  常见的统计检验",
    "section": "",
    "text": "https://stat.ethz.ch/pipermail/r-help/2005-April/070508.html↩︎\nhttps://stat.ethz.ch/pipermail/r-help/2009-May/390164.html↩︎\nhttps://personal.utdallas.edu/~herve/Abdi-Lillie2007-pretty.pdf↩︎\nhttps://stat.ethz.ch/pipermail/r-help/2004-February/045597.html↩︎",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>常见的统计检验</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html",
    "href": "regression-and-correlation.html",
    "title": "20  回归与相关分析",
    "section": "",
    "text": "20.1 子代身高与亲代身高的关系\n弗朗西斯·高尔顿（Francis Galton, 1822-1911）是历史上著名的优生学家、心理学家、遗传学家和统计学家，是统计学中相关和回归等一批概念的提出者，是遗传学中回归现象的发现者。1885年，高尔顿以保密和给予金钱报酬的方式，向社会征集了 205 对夫妇及其 928 个成年子女的身高数据(Galton 1886)。\n目前，Michael Friendly 从原始文献中整理后，将该数据集命名为 GaltonFamilies，放在 R 包 HistData (Friendly 2021) 内，方便大家使用。篇幅所限，下 表格 20.1 展示该数据集的部分内容。\n表格 20.1: 高尔顿收集的 205 对夫妇及其子女的身高数据（部分）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n家庭编号\n父亲身高\n母亲身高\n中亲身高\n子女数量\n子女编号\n子女性别\n子女身高\n\n\n\n001\n78.5\n67.0\n75.43\n4\n1\nmale\n73.2\n\n\n001\n78.5\n67.0\n75.43\n4\n2\nfemale\n69.2\n\n\n001\n78.5\n67.0\n75.43\n4\n3\nfemale\n69.0\n\n\n001\n78.5\n67.0\n75.43\n4\n4\nfemale\n69.0\n\n\n002\n75.5\n66.5\n73.66\n4\n1\nmale\n73.5\n\n\n002\n75.5\n66.5\n73.66\n4\n2\nmale\n72.5\n表中子女性别一栏，Male 表示男性，Female 表示女性。表中 1 号家庭父亲身高 78.5 英寸，母亲身高 67.0 英寸，育有 4 个成年子女，1 男 3 女，子女身高依次是 73.2 英寸、 69.2 英寸、 69.0 英寸 和 69.0 英寸。1 英寸相当于 2.54 厘米，78.5 英寸相当于 199.39 厘米，约等于 2 米的身高。\n高尔顿提出「中亲」概念，即父母的平均身高，认为子代身高只与父母平均身高相关，而与父母身高差无关，为了消除性别给身高带来的差异，女性身高均乘以 1.08。\n根据数据统计的均值和协方差，椭圆 level = 0.95\n代码library(ggplot2)\nggplot(data = GaltonFamilies, aes(x = midparentHeight, y = childHeight, color = gender)) +\n  geom_point(aes(fill = gender), pch = 21, color = \"white\", \n             size = 2, alpha = 0.75) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", se = FALSE) +\n  stat_ellipse(type = \"norm\", level = 0.95, linetype = 2) +\n  scale_color_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  scale_fill_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  guides(fill = guide_legend(reverse = TRUE), \n         color = guide_legend(reverse = TRUE)) +\n  labs(x = \"父母平均身高\", y = \"子女身高\", fill = \"性别\", color = \"性别\") +\n  theme_classic()\n\n\n\n\n\n\n图 20.1: 子代身高与亲代身高的关系\n女儿的身高乘以 1.08 后，两条回归线将几乎重合。(Hanley 2004)\n代码GaltonFamilies[, height_children := childHeight * c(\"female\" = 1.08, \"male\" = 1)[gender]] |&gt;\n  ggplot(aes(x = midparentHeight, y = height_children, color = gender)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", se = FALSE) +\n  geom_point(size = 1.5, alpha = 0.75) +\n  stat_ellipse( type = \"norm\", linetype = 2) +\n  scale_color_brewer(palette = \"Set1\", labels = c(male = \"男\", female = \"女\")) +\n  guides(color = guide_legend(reverse = TRUE)) +\n  labs(x = \"父母平均身高\", y = \"子女身高\", color = \"性别\") +\n  theme_classic()\n\n\n\n\n\n\n图 20.2: 子代身高与亲代身高的关系\n\\[\n\\mathrm{height}_{children} = \\alpha + \\beta * \\mathrm{height}_{midparent} + \\epsilon\n\\]\n表格 20.2: 子女身高向中亲平均身高回归\n\n\n\n\n性别\n截距\n中亲身高\n\n\n\nmale\n19.91346\n0.7132745\n\n\nfemale\n19.80016\n0.7136104\n代码data(Galton, package = \"HistData\")\nplot(Galton,\n  pch = 20, panel.first = grid(), cex = 1, ann = FALSE,\n  xlim = c(63.5, 73.5),\n  ylim = c(61, 74.5),\n  col = densCols(Galton,\n    bandwidth = c(1, 1),\n    nbin = c(11L, 11L), colramp = hcl.colors\n  )\n)\nreg &lt;- lm(child ~ parent, data = Galton)\nabline(reg, lwd = 2)\nlines(lowess(x = Galton$parent, y = Galton$child), col = \"blue\", lwd = 2)\nlibrary(KernSmooth)\nden &lt;- bkde2D(x = Galton, bandwidth = c(1, 1), gridsize = c(11L, 11L))\ncontour(den$x1, den$x2, den$fhat, nlevels = 10, add = TRUE, family = \"sans\")\ntitle(xlab = \"父母平均身高\", ylab = \"子女身高\", family = \"Noto Serif CJK SC\")\n\n\n\n\n\n\n图 20.3: 二维核密度估计与二元正态分布\n向均值回归现象最早是高尔顿在甜豌豆实验中发现的，实际上，均值回归现象在社会经济和自然界中广泛存在，比如一个人的智力水平受家族平均水平的影响。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#sec-state-x77",
    "href": "regression-and-correlation.html#sec-state-x77",
    "title": "20  回归与相关分析",
    "section": "\n20.2 预期寿命与人均收入的关系",
    "text": "20.2 预期寿命与人均收入的关系\n\n生物遗传的回归现象，更确切地说是因果而不是相关，是一种近似的函数关系。与回归紧密相连的是另一个统计概念是相关，主要刻画数量指标之间的关系深浅程度，相关系数是其中一个度量。在经济、社会领域中，很多数据指标存在相关性，接下来的这个例子基于 1977 年美国人口调查局发布的统计数据，篇幅所限，下 表格 20.3 展示美国各州的部分统计数据。\n\n\n\n表格 20.3: 1977 年美国人口调查局发布的各州统计数据（部分）\n\n\n\n\n州名\n区域划分\n人口数量\n人均收入\n预期寿命\n\n\n\nAlabama\nSouth\n3615\n3624\n69.05\n\n\nAlaska\nWest\n365\n6315\n69.31\n\n\nArizona\nWest\n2212\n4530\n70.55\n\n\nArkansas\nSouth\n2110\n3378\n70.66\n\n\nCalifornia\nWest\n21198\n5114\n71.71\n\n\nColorado\nWest\n2541\n4884\n72.06\n\n\n\n\n\n\n\n\n该数据集在 R 环境中的结构如下：\n\nstr(state_x77)\n\n#&gt; 'data.frame':    50 obs. of  10 variables:\n#&gt;  $ Population  : num  3615 365 2212 2110 21198 ...\n#&gt;  $ Income      : num  3624 6315 4530 3378 5114 ...\n#&gt;  $ Illiteracy  : num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...\n#&gt;  $ Life Exp    : num  69 69.3 70.5 70.7 71.7 ...\n#&gt;  $ Murder      : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...\n#&gt;  $ HS Grad     : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...\n#&gt;  $ Frost       : num  20 152 15 65 20 166 139 103 11 60 ...\n#&gt;  $ Area        : num  50708 566432 113417 51945 156361 ...\n#&gt;  $ state_name  : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n#&gt;  $ state_region: Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n\n\n它是一个 50 行 10 列的数据框，其中，state_name（州名）是字符型变量， state_region（区域划分）是因子型变量。除了这两个变量外，Population（人口数量，单位：1000），Income（人均收入，单位：美元），Life Exp（预期寿命，单位：岁）等都是数值型的变量。下 图 20.4 展示了1977 年美国各州的预期寿命和人均收入的关系，通过此图，可以初步观察出两个指标存在一些明显的正向相关性，也符合常识。\n\n代码library(ggplot2)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point() +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 20.4: 预期寿命与人均收入的关系图\n\n\n\n\n为了更加清楚地观察到哪些州预期寿命长，哪些州人均收入高，在 图 20.4 基础上，在散点旁边添加州名。此外，为了观察各州的地域差异，根据各州所属区域，给散点分类，最后，将各州人口数量映射给散点的大小，形成如下 图 20.5 所示的分类气泡图。\n\n代码library(ggplot2)\nlibrary(ggrepel)\nlibrary(scales)\nggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系（分地域）\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 20.5: 分地域预期寿命与人均收入的气泡图\n\n\n\n\n整体来说，预期寿命与人均收入息息相关。\n\n代码ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\") +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\n\n\n\n图 20.6: 1977 年美国各州预期寿命与人均收入的关系：回归分析\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n从 图 20.5 到 图 20.6 ，尝试初步量化两个变量之间的相关性之前，有没有想过，回归线应该更加陡峭一些，即回归线的斜率应该更大一些，是什么原因导致平缓了这么多？是阿拉斯加州和内华达州的数据偏离集体太远。那又是什么原因导致阿拉斯加州人均收入全美第一，而预期寿命倒数呢？同样的，内华达州的人均收入也不低，但预期寿命为什么上不去呢？\n\n\n\n代码ggplot(data = state_x77, aes(x = Income, y = `Life Exp`)) +\n  geom_point(aes(size = 1000 * Population, color = state_region)) +\n  geom_smooth(method = \"lm\", formula = \"y~x\", color = \"red\") +\n  geom_smooth(data = function(x) subset(x, !state_name %in% c(\"Nevada\", \"Alaska\") ), method = \"lm\", formula = \"y~x\", color = \"green\") +\n  geom_text_repel(aes(label = state_name), size = 3, seed = 2022) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    x = \"人均收入（美元）\", y = \"预期寿命（年）\",\n    title = \"1977 年各州预期寿命与人均收入的关系\",\n    caption = \"数据源：美国人口调查局\",\n    size = \"人口数量\", color = \"区域划分\"\n  ) +\n  theme_classic() +\n  theme(\n    panel.grid = element_line(colour = \"gray92\"),\n    panel.grid.major = element_line(linewidth = rel(1.0)),\n    panel.grid.minor = element_line(linewidth = rel(0.5))\n  )\n\n\n\nm &lt;- lm(data = state_x77, `Life Exp` ~ Income)\nsummary(m)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = `Life Exp` ~ Income, data = state_x77)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -2.96547 -0.76381 -0.03428  0.92876  2.32951 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 6.758e+01  1.328e+00  50.906   &lt;2e-16 ***\n#&gt; Income      7.433e-04  2.965e-04   2.507   0.0156 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.275 on 48 degrees of freedom\n#&gt; Multiple R-squared:  0.1158, Adjusted R-squared:  0.09735 \n#&gt; F-statistic: 6.285 on 1 and 48 DF,  p-value: 0.01562\n\n\n输出结果中各个量的计算公式及 R 语言实现，比如方差 Variance、偏差 Deviance/Bias、残差 Residual Error",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#分析影响入院等待时间的因素",
    "href": "regression-and-correlation.html#分析影响入院等待时间的因素",
    "title": "20  回归与相关分析",
    "section": "\n20.3 分析影响入院等待时间的因素",
    "text": "20.3 分析影响入院等待时间的因素\n医院的床位是非常重要的资源。\n\nhospital_waiting_time &lt;- readRDS(file = \"data/hospital_waiting_time.rds\")\n\n\nstr(hospital_waiting_time)\n\n#&gt; 'data.frame':    2625 obs. of  11 variables:\n#&gt;  $ 等待时间    : num  1 1.2 20 6 8.9 2.9 7.9 2.8 2.7 5 ...\n#&gt;  $ 门诊次      : int  2 7 43 1 3 1 10 3 6 2 ...\n#&gt;  $ 住院次      : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 开住院条日期: int  3 3 3 3 3 3 3 3 3 3 ...\n#&gt;  $ 性别        : int  0 0 1 1 1 1 0 1 1 1 ...\n#&gt;  $ 年龄        : int  42 32 59 9 45 73 50 25 14 20 ...\n#&gt;  $ 入院疾病分类: int  3 1 1 3 3 3 4 1 2 3 ...\n#&gt;  $ 入院目的    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 住院类别    : int  2 2 2 2 2 2 2 2 2 2 ...\n#&gt;  $ 入院病情    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ 医生        : int  2 2 2 2 2 4 2 2 4 4 ...",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "regression-and-correlation.html#sec-exercise-regression-and-correlation",
    "href": "regression-and-correlation.html#sec-exercise-regression-and-correlation",
    "title": "20  回归与相关分析",
    "section": "\n20.4 习题",
    "text": "20.4 习题\n\nR 软件内置的数据集 esoph 是一份关于法国伊勒-维莱讷地区食道癌的数据，请读者根据这份数据研究年龄组、烟草消费量、酒精消费量（每日喝酒量）和患食道癌的关系。\n\n\n\n\n\nFriendly, Michael. 2021. HistData: Data Sets from the History of Statistics and Data Visualization. https://CRAN.R-project.org/package=HistData.\n\n\nGalton, F. 1886. 《Regression Towards Mediocrity in Hereditary Stature》. Journal of the Anthropological Institute 15: 246–63.\n\n\nHanley, James A. 2004. 《’Transmuting’ women into men: Galton’s family data on human stature》. The American Statistician 58 (3): 237–43.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>回归与相关分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html",
    "href": "categorical-data-analysis.html",
    "title": "21  分类数据的分析",
    "section": "",
    "text": "21.1 比例检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-prop-test",
    "href": "categorical-data-analysis.html#sec-prop-test",
    "title": "21  分类数据的分析",
    "section": "",
    "text": "21.1.1 单样本检验\n比例检验函数 prop.test() 检验比例是否等于给定的值。单样本的比例检验结果中比例的区间估计与 Wilson 区间估计 (Wilson 1927) 是相关的。区间估计与假设检验是有紧密关系的，对于二项分布比例的 11 种区间估计方法的比较 (Newcombe 1998)。\n\n21.1.1.1 近似检验\n\n21.1.1.2 精确检验\n函数 binom.test() 来做二项检验，函数 binom.test() 用来检验伯努利试验中成功概率 \\(p\\) 和给定概率 \\(p_0\\) 的关系，属于精确检验 (Clopper 和 Pearson 1934)。\n比例 \\(p\\) 的检验，做 \\(n\\) 次独立试验，样本 \\(X_1,\\ldots,X_n \\sim b(1, p)\\)，事件发生的总次数 \\(\\sum_{i=1}^{n}X_i\\)。\n\n# 模拟一组样本\nset.seed(20232023)\nx &lt;- sample(x = c(0, 1), size = 100, replace = TRUE, prob = c(0.8, 0.2))\n\n二项分布中成功概率的检验\n\nbinom.test(sum(x), n = 100, p = 0.5)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  sum(x) and 100\n#&gt; number of successes = 23, number of trials = 100, p-value = 5.514e-08\n#&gt; alternative hypothesis: true probability of success is not equal to 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.1517316 0.3248587\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                   0.23\n\n\n检验成功概率 p 是否等于 0.5， P 值 \\(5.514 \\times 10^{-8}\\) 结论是拒绝原假设\n\nbinom.test(sum(x), n = 100, p = 0.2)\n\n#&gt; \n#&gt;  Exact binomial test\n#&gt; \n#&gt; data:  sum(x) and 100\n#&gt; number of successes = 23, number of trials = 100, p-value = 0.4534\n#&gt; alternative hypothesis: true probability of success is not equal to 0.2\n#&gt; 95 percent confidence interval:\n#&gt;  0.1517316 0.3248587\n#&gt; sample estimates:\n#&gt; probability of success \n#&gt;                   0.23\n\n\n检验成功概率 p 是否等于 0.2， P 值 0.4534 结论是不能拒绝原假设\n切比雪夫不等式（Chebyshev, 1821-1894）。设随机变量 \\(X\\) 的数学期望和方差都存在，则对任意常数 \\(\\epsilon &gt; 0\\)，有\n\\[\n\\begin{aligned}\nP(|X - EX| \\geq \\epsilon) & \\leq \\frac{Var(X)}{\\epsilon^2} \\\\\nP(|X - EX| \\leq \\epsilon) & \\geq 1 - \\frac{Var(X)}{\\epsilon^2}\n\\end{aligned}\n\\]\n\n21.1.2 两样本检验\n关于两样本的比例检验问题\n\\[\n\\begin{aligned}\nH_0: P_A = P_B \\quad vs. \\quad H_1: P_A &gt; P_B \\\\\nH_0: P_A = P_B \\quad vs. \\quad H_1: P_A &lt; P_B\n\\end{aligned}\n\\]\n\\(H_0\\) 成立的情况下，暗示着两个样本来自同一总体。\n比例检验函数 prop.test() 用来检验两组或多组二项分布的成功概率（比例）是否相等。\n设随机变量 X 服从参数为 \\(p\\) 的二项分布 \\(b(n, p)\\)， \\(Y\\) 服从参数为 \\(\\theta\\) 的二项分布 \\(b(m,\\theta)\\)， \\(m,n\\) 都假定为较大的正整数，检验如下问题\n\\[\nH_0: P_A \\geq P_B \\quad vs. \\quad H_1: P_A &lt; P_B\n\\]\n根据中心极限定理\n\\[\n\\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{p(1-p)}{n} + \\frac{\\theta(1-\\theta)}{m}}}\n\\]\n近似服从标准正态分布 \\(N(0,1)\\)。如果用矩估计 \\(\\bar{X}\\) 和 \\(\\bar{Y}\\) 分别替代总体参数 \\(p\\) 和 \\(\\theta\\)，构造检验统计量\n\\[\nT = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n} + \\frac{\\bar{Y}(1-\\bar{Y})}{m}}}\n\\]\n根据 Slutsky 定理，检验统计量 \\(T\\) 近似服从标准正态分布，当 \\(T\\) 偏大时，拒绝 \\(H_0\\)。该方法的优势在于当 \\(n,m\\) 比较大时，二项分布比较复杂，无法建立统计表，利用标准正态分布表来给出检验所需要的临界值，简便易行！\n当 \\(p\\) 和 \\(\\theta\\) 都比较小，上述方法检验效果不好，原因在于由中心极限定理对 \\(\\bar{X}\\) 和 \\(\\bar{Y}\\) 的正态分布近似效果不好，或者间接地导致 \\(\\bar{X}-\\bar{Y}\\) 的方差偏小，进而 \\(T\\) 的分辨都不好，而且当 \\(p,\\theta\\) 很接近 1 时，上述现象也会产生！\n下面介绍新的解决办法，办法来自两个二项总体成功概率的比较 (宋泽熙 2011)。\n上面的检验问题等价于\n\\[\nH_0: \\frac{P_A}{P_B} \\geq 1 \\quad vs. \\quad H_1: \\frac{P_A}{P_B} &lt; 1\n\\]\n引入检验统计量\n\\[\nT^{\\star} = \\frac{\\bar{X}}{\\bar{Y}}\n\\]\n同样由 Slutsky 定理和中心极限定理可知， \\(\\bar{X}/\\bar{Y}\\) 近似服从 正态分布 \\(\\mathcal{N}(1,\\frac{1-\\theta}{m\\theta})\\)\n当 \\((T^\\star - 1)/\\hat\\sigma\\) 偏大时接受 \\(H_0\\)，临界值可通过 \\(\\mathcal{N}(0, \\hat\\sigma^2)\\) 分布表计算得到， \\(\\hat\\sigma^2\\) 是对 \\(\\frac{1-\\theta}{m\\theta}\\) 的估计，比如取 \\(\\hat\\sigma^2 = \\frac{1-\\bar{Y}}{m}\\cdot \\frac{1}{\\bar{Y}}\\) 或取 \\(\\hat\\sigma^2 = \\frac{1-\\bar{Y}}{m}\\cdot \\frac{1}{\\bar{X}}\\)\n由于渐近方差形如 \\(\\frac{1-\\theta}{m\\theta}\\)，因而在 \\(\\theta\\) 较小，渐近方差较大，克服了之前 \\(\\bar{X} - \\bar{Y}\\)的方差较小的问题\n\\(p,\\theta\\) 很接近 1 时，我们取检验统计量\n\\[\nT^{\\star\\star} = \\frac{1-\\bar{Y}}{1-\\bar{X}}\n\\]\n结论和 \\(T^\\star\\) 类似，当 \\(T^{\\star\\star}\\) 偏大时，拒绝 \\(H_0\\)。\n\n21.1.3 多样本检验\n\n21.1.3.1 比例齐性检验\n对多组数据的比例检验，可以理解为比例齐性检验。\n\n21.1.3.2 比例趋势检验\n比例趋势检验函数 prop.trend.test() 的原假设：四个组里面病人中吸烟的比例是相同的。备择假设：四个组的吸烟比例是有趋势的。\n\\[\n\\begin{aligned}\n& H_0: P_1 = P_2 = P_3 = P_4 \\\\\n& H_1: P_1 &lt; P_2 &lt; P_3 &lt; P_4 ~\\text{或者}~ P_1 &gt; P_2 &gt; P_3 &gt; P_4\n\\end{aligned}\n\\]\n\nsmokers &lt;- c(83, 90, 129, 70)\npatients &lt;- c(86, 93, 136, 82)\nprop.test(smokers, patients)\n\n#&gt; \n#&gt;  4-sample test for equality of proportions without continuity correction\n#&gt; \n#&gt; data:  smokers out of patients\n#&gt; X-squared = 12.6, df = 3, p-value = 0.005585\n#&gt; alternative hypothesis: two.sided\n#&gt; sample estimates:\n#&gt;    prop 1    prop 2    prop 3    prop 4 \n#&gt; 0.9651163 0.9677419 0.9485294 0.8536585\n\nprop.trend.test(smokers, patients)\n\n#&gt; \n#&gt;  Chi-squared Test for Trend in Proportions\n#&gt; \n#&gt; data:  smokers out of patients ,\n#&gt;  using scores: 1 2 3 4\n#&gt; X-squared = 8.2249, df = 1, p-value = 0.004132",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-poisson-test",
    "href": "categorical-data-analysis.html#sec-poisson-test",
    "title": "21  分类数据的分析",
    "section": "\n21.2 泊松检验",
    "text": "21.2 泊松检验\n泊松分布是 1837年由法国数学家泊松 （Poisson, 1781-1840） 首次提出。\n\\[\np(x) = \\frac{\\lambda^x\\exp(-\\lambda)}{x!}, x = 0, 1, \\cdots .\n\\]\n泊松分布的期望和方差都是 \\(\\lambda\\) ，一般要求 \\(\\lambda &gt; 0\\)。\n\n21.2.1 单样本\npoisson.test() 泊松分布的参数 \\(\\lambda\\) 的精确检验，适用于单样本和两样本。\n\npoisson.test(x,\n  T = 1, r = 1,\n  alternative = c(\"two.sided\", \"less\", \"greater\"),\n  conf.level = 0.95\n)\n\n参数 T 数据的时间单位\n\n21.2.2 两样本",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#列联表描述",
    "href": "categorical-data-analysis.html#列联表描述",
    "title": "21  分类数据的分析",
    "section": "\n21.3 列联表描述",
    "text": "21.3 列联表描述\n泰坦尼克号乘客生存死亡统计数据，Titanic 数据集\n\nTitanic\n\n#&gt; , , Age = Child, Survived = No\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st     0      0\n#&gt;   2nd     0      0\n#&gt;   3rd    35     17\n#&gt;   Crew    0      0\n#&gt; \n#&gt; , , Age = Adult, Survived = No\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st   118      4\n#&gt;   2nd   154     13\n#&gt;   3rd   387     89\n#&gt;   Crew  670      3\n#&gt; \n#&gt; , , Age = Child, Survived = Yes\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st     5      1\n#&gt;   2nd    11     13\n#&gt;   3rd    13     14\n#&gt;   Crew    0      0\n#&gt; \n#&gt; , , Age = Adult, Survived = Yes\n#&gt; \n#&gt;       Sex\n#&gt; Class  Male Female\n#&gt;   1st    57    140\n#&gt;   2nd    14     80\n#&gt;   3rd    75     76\n#&gt;   Crew  192     20\n\n\n\n21.3.1 行列分组表格\n\n代码# 长格式转宽格式\ntitanic_data &lt;- reshape(\n  data = as.data.frame(Titanic), direction = \"wide\",\n  idvar = c(\"Class\", \"Sex\", \"Age\"),\n  timevar = \"Survived\", v.names = \"Freq\", sep = \"_\"\n)\n\n# 制作表格\ngt::gt(titanic_data) |&gt; \n  gt::cols_label(\n    Freq_Yes = \"存活\",\n    Freq_No = \"死亡\",\n    Class = \"船舱\",\n    Sex = \"性别\",\n    Age = \"年龄\"\n  )\n\n\n表格 21.1: 泰坦尼克号乘客生存死亡统计数据\n\n\n\n\n\n\n\n船舱\n性别\n年龄\n死亡\n存活\n\n\n\n1st\nMale\nChild\n0\n5\n\n\n2nd\nMale\nChild\n0\n11\n\n\n3rd\nMale\nChild\n35\n13\n\n\nCrew\nMale\nChild\n0\n0\n\n\n1st\nFemale\nChild\n0\n1\n\n\n2nd\nFemale\nChild\n0\n13\n\n\n3rd\nFemale\nChild\n17\n14\n\n\nCrew\nFemale\nChild\n0\n0\n\n\n1st\nMale\nAdult\n118\n57\n\n\n2nd\nMale\nAdult\n154\n14\n\n\n3rd\nMale\nAdult\n387\n75\n\n\nCrew\nMale\nAdult\n670\n192\n\n\n1st\nFemale\nAdult\n4\n140\n\n\n2nd\nFemale\nAdult\n13\n80\n\n\n3rd\nFemale\nAdult\n89\n76\n\n\nCrew\nFemale\nAdult\n3\n20\n\n\n\n\n\n\n\n\n\n\n\n21.3.2 百分比堆积图\n泰坦尼克号处女航乘客数量按船舱、性别、年龄和存活情况分层， ggstats 包绘制百分比堆积柱形图展示多维分类数据。\n\n代码library(ggplot2)\nlibrary(ggstats)\nggplot(as.data.frame(Titanic)) +\n  aes(x = Class, fill = Survived, weight = Freq, by = Class) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  geom_text(stat = \"prop\", position = position_fill(.5)) +\n  facet_grid(~Sex) +\n  labs(x = \"船舱\", y = \"比例\", fill = \"存活\")\n\n\n\n\n\n\n图 21.1: 百分比堆积柱形图展示多维分类数据\n\n\n\n\nggstats 包提供的图层 stat_prop() 是 stat_count() 的变种， as.data.frame(Titanic) 中 Age 一列会自动聚合吗？ by = Class 按 Class 分组聚合，统计 Survived 的比例，提供 prop 计算的变量，传递给 geom_text() 以添加注释，position 设置将注释放在柱子的中间\n\n21.3.3 桑基图\n用 ggalluvial 包(Brunson 2020)绘制桑基图展示多维分类数据。\n\n代码library(ggplot2)\nlibrary(ggalluvial)\nggplot(\n  data = as.data.frame(Titanic),\n  aes(axis1 = Class, axis2 = Sex, axis3 = Age, y = Freq)\n) +\n  scale_x_discrete(limits = c(\"Class\", \"Sex\", \"Age\")) +\n  geom_alluvium(aes(fill = Survived)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_classic() +\n  labs(\n    x = \"分层维度\", y = \"人数\", fill = \"存活\",\n    title = \"泰坦尼克号处女航乘客分层情况\"\n  )\n\n\n\n\n\n\n图 21.2: 桑基图展示多维分类数据\n\n\n\n\n\n21.3.4 马赛克图\n\n代码op &lt;- par(mar = c(2.5, 2.5, 1.5, 0.5))\nmosaicplot(~ Class + Sex + Age + Survived,\n  data = Titanic, # shade = TRUE, \n  color = TRUE, border = \"white\",\n  xlab = \"船舱\", ylab = \"性别\", main = \"泰坦尼克号\")\npar(op)\n\n\n\n\n\n\n图 21.3: 马赛克图展示多维分类数据\n\n\n\n\nvcd 包针对分类数据做了很多专门的可视化工作，内置了很多数据集和绘图函数，在 Base R 绘图基础上，整合了许多统计分析功能，提供了一个统一的可视化框架(Meyer, Zeileis, 和 Hornik 2006; Zeileis, Meyer, 和 Hornik 2007)，更多细节见著作《Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data》及其附带的 R 包 vcdExtra(Friendly 和 Meyer 2016)。\n\n代码library(grid)\nlibrary(vcd)\nmosaic(~ Class + Sex + Age + Survived,\n  data = Titanic, shade = TRUE, legend = TRUE\n)\n\n\n\n\n\n\n图 21.4: 马赛克图展示多维分类数据",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-chisq-test",
    "href": "categorical-data-analysis.html#sec-chisq-test",
    "title": "21  分类数据的分析",
    "section": "\n21.4 列联表分析",
    "text": "21.4 列联表分析\n是否应该按照列联表的维度分类？还是应该从分析的目的和作用出发？比如我的目的是检验独立性。二者似乎也并不冲突。\n列联表中的数据服从多项分布，关于独立性检验，有如下几种常见类型：\n\n相互独立 Mutual independence 所有变量之间相互独立，\\(X \\perp Y \\perp Z\\) 。\n联合独立 Joint independence 两个变量的联合与第三个变量独立，\\(XY \\perp Z\\) 。\n边际独立 Marginal independence 当忽略第三个变量时，两个变量是独立的。列联表压缩\n条件独立 Conditional independence 当固定第三个变量时，两个变量是独立的，\\(X \\perp Y | Z\\)。\n\n本节数据来自著作《An Introduction to Categorical Data Analysis》(Agresti 2007) 的第2章习题 2.33，探索 1976-1977 年美国佛罗里达州的凶杀案件中被告肤色和死刑判决的关系。\n\n代码tbl &lt;- expand.grid(\n  Death = c(\"Yes\", \"No\"), # 判决结果 是否死刑\n  Defend = c(\"白人\", \"黑人\"),  # 被告 肤色\n  Victim = c(\"白人\", \"黑人\")   # 原告 （被害人）肤色\n)\nethnicity &lt;- data.frame(tbl, Freq = c(19, 132, 11, 52, 0, 9,  6, 97))\n\n# 长格式转宽格式\ndat1 &lt;- reshape(\n  data = ethnicity, direction = \"wide\",\n  idvar = c(\"Defend\", \"Victim\"),\n  timevar = \"Death\", v.names = \"Freq\", sep = \"_\"\n)\n# 制作表格\ngt::gt(dat1) |&gt; \n  gt::cols_label(\n    Freq_Yes = \"是\",\n    Freq_No = \"否\",\n    Victim = \"被害人\",\n    Defend = \"被告\"\n  ) |&gt; \n  gt::tab_spanner(\n    label = \"死刑\",\n    columns = c(Freq_Yes, Freq_No)\n  ) |&gt; \n  gt::opt_row_striping()\n\n\n表格 21.2: 佛罗里达州的凶杀案件统计数据\n\n\n\n\n\n\n\n\n被告\n被害人\n死刑\n\n\n是\n否\n\n\n\n\n白人\n白人\n19\n132\n\n\n黑人\n白人\n11\n52\n\n\n白人\n黑人\n0\n9\n\n\n黑人\n黑人\n6\n97\n\n\n\n\n\n\n\n\n\n\n\n21.4.1 相互独立性\n皮尔逊卡方检验（ Pearson’s \\(\\chi^2\\) 检验） chisq.test() 常用于列联表独立性检验和方差分析模型的拟合优度检验。下面是一个 \\(2 \\times 2\\) 的列联表。\n\n卡方独立性检验\n\n\n第一列\n第二列\n合计\n\n\n\n第一行\n\\(a\\)\n\\(b\\)\n\\(a+b\\)\n\n\n第二行\n\\(c\\)\n\\(d\\)\n\\(c+d\\)\n\n\n合计\n\\(a+c\\)\n\\(b+d\\)\n\\(a+b+c+d\\)\n\n\n\n\n# Death 死刑与 Defend （被告）独立性检验\nm &lt;- xtabs(Freq ~ Death + Defend, data = ethnicity)\nm\n\n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes   19   17\n#&gt;   No   141  149\n\nchisq.test(m, correct = TRUE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 0.086343, df = 1, p-value = 0.7689\n\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 0.22145, df = 1, p-value = 0.6379\n\n\n当被告是白人时，死刑判决 19 个，占总的死刑判决数量的 19/36 = 52.78%，当被告是黑人时，死刑判决 17 个，占总的死刑判决数量的 17/36 = 47.22%。判决结果与被告种族没有显著关系，但与原告（受害人）种族是有关系的，请继续往下看。\n\n# Death 死刑与 Victim （原告）独立性检验\nm &lt;- xtabs(Freq ~ Death + Victim, data = ethnicity)\nchisq.test(m, correct = TRUE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 4.7678, df = 1, p-value = 0.029\n\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 5.6149, df = 1, p-value = 0.01781\n\n\n当受害人是白人时，死刑判决 30 个，占总的死刑判决数量的 30/36 = 83.33%，当受害人是黑人时，死刑判决 6 个，占总的死刑判决数量的 6/36 = 16.67%。受害人是白人时，死刑判决明显多于黑人。\n多维列联表\n\nm &lt;- xtabs(Freq ~ Death + Defend + Victim, data = ethnicity)\nm\n\n#&gt; , , Victim = 白人\n#&gt; \n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes   19   11\n#&gt;   No   132   52\n#&gt; \n#&gt; , , Victim = 黑人\n#&gt; \n#&gt;      Defend\n#&gt; Death 白人 黑人\n#&gt;   Yes    0    6\n#&gt;   No     9   97\n\n\n判决结果、被告种族、原告种族三者是否存在联合独立性，即考虑 (Victim, Death) 是否与 Defend 独立，(Victim, Defend) 是否与 Death 独立，(Death, Defend) 与 Victim 是否相互独立。\n\nfm &lt;- loglin(table = m, margin = list(c(1, 2), c(1, 3), c(2, 3)), print = FALSE)\nfm \n\n#&gt; $lrt\n#&gt; [1] 0.7007504\n#&gt; \n#&gt; $pearson\n#&gt; [1] 0.3751739\n#&gt; \n#&gt; $df\n#&gt; [1] 1\n#&gt; \n#&gt; $margin\n#&gt; $margin[[1]]\n#&gt; [1] \"Death\"  \"Defend\"\n#&gt; \n#&gt; $margin[[2]]\n#&gt; [1] \"Death\"  \"Victim\"\n#&gt; \n#&gt; $margin[[3]]\n#&gt; [1] \"Defend\" \"Victim\"\n\n# 拟合对数线性模型\n# fm &lt;- loglin(m, list(c(1), c(2), c(3)))\n# fm\n\n似然比检验统计量（Likelihood Ratio Test statistic），皮尔逊 \\(\\chi^2\\) 统计量（Pearson X-square Test statistic）\n\n1 - pchisq(fm$lrt, fm$df)\n\n#&gt; [1] 0.4025317\n\n\n拟合对数线性模型\n\nfit_dvp &lt;- glm(Freq ~ ., data = ethnicity, family = poisson(link = \"log\"))\n\n模型输出\n\nsummary(fit_dvp)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ ., family = poisson(link = \"log\"), data = ethnicity)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  2.45087    0.18046  13.582  &lt; 2e-16 ***\n#&gt; DeathNo      2.08636    0.17671  11.807  &lt; 2e-16 ***\n#&gt; Defend黑人   0.03681    0.11079   0.332     0.74    \n#&gt; Victim黑人  -0.64748    0.11662  -5.552 2.83e-08 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 395.92  on 7  degrees of freedom\n#&gt; Residual deviance: 137.93  on 4  degrees of freedom\n#&gt; AIC: 181.61\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\nPearson \\(\\chi^2\\) 统计量\n\nsum(residuals(fit_dvp, type = \"pearson\")^2)\n\n#&gt; [1] 122.3975\n\n\nMASS 包计算模型参数的置信区间\n\nconfint(fit_dvp, trace = FALSE)\n\n#&gt;                  2.5 %     97.5 %\n#&gt; (Intercept)  2.0802598  2.7893934\n#&gt; DeathNo      1.7546021  2.4493677\n#&gt; Defend黑人  -0.1803969  0.2543149\n#&gt; Victim黑人  -0.8790491 -0.4213701\n\n\n对于单元格总样本量小于 40 或 T 小于 1 时，需采用费希尔精确检验（ Fisher ’s Exact 检验）。\n\n21.4.2 边际独立性\n费希尔精确检验：固定边际的情况下，检验列联表行和列之间的独立性 fisher.test() 。\nfisher.test() 函数用法，统计原理和公式，适用范围和条件，概念背景和历史。\n费舍尔 (Sir Ronald Fisher, 1890.2 – 1962.7)1 和一位女士打赌，女士说能品出奶茶中奶和茶的添加顺序。\nfisher.test() 针对计数数据，检验列联表中行和列的独立性。\n\nTeaTasting &lt;- matrix(c(3, 1, 1, 3),\n  nrow = 2,\n  dimnames = list(\n    Guess = c(\"Milk\", \"Tea\"),\n    Truth = c(\"Milk\", \"Tea\")\n  )\n)\nTeaTasting\n\n#&gt;       Truth\n#&gt; Guess  Milk Tea\n#&gt;   Milk    3   1\n#&gt;   Tea     1   3\n\n\n\n# 单边 P 值\nfisher.test(TeaTasting, alternative = \"greater\")\n\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  TeaTasting\n#&gt; p-value = 0.2429\n#&gt; alternative hypothesis: true odds ratio is greater than 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3135693       Inf\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   6.408309\n\n# 双边 P 值\nfisher.test(TeaTasting, alternative = \"two.sided\")\n\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  TeaTasting\n#&gt; p-value = 0.4857\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;    0.2117329 621.9337505\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   6.408309\n\n# 单边 P 值\nsum(dhyper(x = c(3, 4), m = 4, n = 4, k = 4))\n\n#&gt; [1] 0.2428571\n\n\n\n21.4.3 对称性\n用于计数数据的 McNemar 卡方检验（ McNemar \\(\\chi^2\\) 检验）：检验二维列联表行和列的对称性 mcnemar.test()。怎么理解对称性？其实是配对检验。看帮助实例。\n\nPerformance &lt;- matrix(c(794, 86, 150, 570),\n  nrow = 2,\n  dimnames = list(\n    \"1st Survey\" = c(\"Approve\", \"Disapprove\"),\n    \"2nd Survey\" = c(\"Approve\", \"Disapprove\")\n  )\n)\nPerformance\n\n#&gt;             2nd Survey\n#&gt; 1st Survey   Approve Disapprove\n#&gt;   Approve        794        150\n#&gt;   Disapprove      86        570\n\nmcnemar.test(Performance)\n\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  Performance\n#&gt; McNemar's chi-squared = 16.818, df = 1, p-value = 4.115e-05\n\n\n\n21.4.4 条件独立性\n用于分层分类数据的 Cochran-Mantel-Haenszel 卡方检验：两个枚举（分类）变量的条件独立性，假定不存在三个因素的交互作用。Cochran-Mantel-Haenszel 检验 mantelhaen.test()\n\nstr(UCBAdmissions)\n\n#&gt;  'table' num [1:2, 1:2, 1:6] 512 313 89 19 353 207 17 8 120 205 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ Admit : chr [1:2] \"Admitted\" \"Rejected\"\n#&gt;   ..$ Gender: chr [1:2] \"Male\" \"Female\"\n#&gt;   ..$ Dept  : chr [1:6] \"A\" \"B\" \"C\" \"D\" ...\n\n\nUCBAdmissions 数据集是一个 \\(2\\times 2 \\times 6\\) 的三维列联表，R 语言中常用 table 类型表示。实际上，table 类型衍生自 array 数组类型，当把 UCBAdmissions 当作一个数组操作时，1、2、3 分别表示 Admit、Gender、Dept 三个维度。\n\nmantelhaen.test(UCBAdmissions)\n\n#&gt; \n#&gt;  Mantel-Haenszel chi-squared test with continuity correction\n#&gt; \n#&gt; data:  UCBAdmissions\n#&gt; Mantel-Haenszel X-squared = 1.4269, df = 1, p-value = 0.2323\n#&gt; alternative hypothesis: true common odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.7719074 1.0603298\n#&gt; sample estimates:\n#&gt; common odds ratio \n#&gt;         0.9046968\n\n\n没有证据表明院系与性别之间存在关联。在给定院系的情况下，是否录取和性别没有显著关系。\n\n# 按系统计\napply(UCBAdmissions, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))\n\n#&gt;         A         B         C         D         E         F \n#&gt; 0.3492120 0.8025007 1.1330596 0.9212838 1.2216312 0.8278727\n\nwoolf &lt;- function(x) {\n  x &lt;- x + 1 / 2\n  k &lt;- dim(x)[3]\n  or &lt;- apply(x, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))\n  w &lt;- apply(x, 3, function(x) 1 / sum(1 / x))\n  1 - pchisq(sum(w * (log(or) - weighted.mean(log(or), w))^2), k - 1)\n}\nwoolf(UCBAdmissions)\n\n#&gt; [1] 0.0034272",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-ucb-admissions",
    "href": "categorical-data-analysis.html#sec-ucb-admissions",
    "title": "21  分类数据的分析",
    "section": "\n21.5 加州伯克利分校的录取情况",
    "text": "21.5 加州伯克利分校的录取情况\n1973 年加州伯克利分校 6 个最大的院系的录取情况见下 表格 21.3 ，研究目标是加州伯克利分校在招生录取工作中是否有性别歧视？\n\n\n\n表格 21.3: 加州伯克利分校的录取情况\n\n\n\n\n\n\n\n\n院系\n录取\n拒绝\n\n\n男性\n女性\n男性\n女性\n\n\n\n\nA\n512\n89\n313\n19\n\n\nB\n353\n17\n207\n8\n\n\nC\n120\n202\n205\n391\n\n\nD\n138\n131\n279\n244\n\n\nE\n53\n94\n138\n299\n\n\nF\n22\n24\n351\n317\n\n\n\n\n\n\n\n\n\n\n借助马赛克图 图 21.5 可以更加直观的看出数据中的比例关系。\n\n\n\n\n\n\n\n图 21.5: 加州伯克利分校院系录取情况\n\n\n\n\n接下来进行定量的分析，首先，按性别和录取情况统计人数，如下：\n\nm &lt;- xtabs(Freq ~ Gender + Admit, data = as.data.frame(UCBAdmissions))\nm\n\n#&gt;         Admit\n#&gt; Gender   Admitted Rejected\n#&gt;   Male       1198     1493\n#&gt;   Female      557     1278\n\n\n可以看到，申请加州伯克利分校的女生当中，只有 \\(557 / (557 + 1278) = 30.35\\%\\) 录取了，而男生则有 \\(1198 / (1198 + 1493) = 44.52\\%\\) 的录取率。根据皮尔逊 \\(\\chi^2\\) 检验：\n\n# 不带耶茨矫正\nchisq.test(m, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  m\n#&gt; X-squared = 92.205, df = 1, p-value &lt; 2.2e-16\n\n\n可知 \\(\\chi^2\\) 统计量的值为 \\(92.205\\) 且 P 值远远小于 0.05， 差异达到统计显著性，不是随机因素导致的。因此，加州伯克利分校被指控在招生录取工作中存在性别歧视。然而，当我们细分到各个院系去看录取率（录取人数 / 申请人数），结果显示院系 A 的录取率为 64.41%，院系 B 的录取率为 63.24%，依次类推，各院系情况如下：\n\nproportions(xtabs(Freq ~ Dept + Admit,\n  data = as.data.frame(UCBAdmissions)\n), margin = 1)\n\n#&gt;     Admit\n#&gt; Dept   Admitted   Rejected\n#&gt;    A 0.64415863 0.35584137\n#&gt;    B 0.63247863 0.36752137\n#&gt;    C 0.35076253 0.64923747\n#&gt;    D 0.33964646 0.66035354\n#&gt;    E 0.25171233 0.74828767\n#&gt;    F 0.06442577 0.93557423\n\n\n\n\n\n\n\n\n\n图 21.6: 加州伯克利分校各院系录取情况\n\n\n\n\n对每个院系，单独使用皮尔逊 \\(\\chi^2\\) 检验，发现只有 A 系的男、女生录取率的差异达到统计显著性，其它系的差异都不显著。辛普森悖论在这里出现了，在分类数据的分析中，常常遇到。\n\n# 以 A 系为例\nma &lt;- xtabs(Freq ~ Gender + Admit,\n  subset = Dept == \"A\",\n  data = as.data.frame(UCBAdmissions)\n)\nchisq.test(ma, correct = FALSE)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  ma\n#&gt; X-squared = 17.248, df = 1, p-value = 3.28e-05\n\n\n为了经一步说明此现象的原因，建立对数线性模型来拟合数据，值得一提的是皮尔逊卡方检验可以从对数线性模型的角度来看，而对数线性模型是一种特殊的广义线性模型，针对计数数据建模。\n\nfit_ucb0 &lt;- glm(Freq ~ Dept + Admit + Gender,\n  family = poisson(link = \"log\"),\n  data = as.data.frame(UCBAdmissions)\n)\nsummary(fit_ucb0)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ Dept + Admit + Gender, family = poisson(link = \"log\"), \n#&gt;     data = as.data.frame(UCBAdmissions))\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)    5.37111    0.03964 135.498  &lt; 2e-16 ***\n#&gt; DeptB         -0.46679    0.05274  -8.852  &lt; 2e-16 ***\n#&gt; DeptC         -0.01621    0.04649  -0.349 0.727355    \n#&gt; DeptD         -0.16384    0.04832  -3.391 0.000696 ***\n#&gt; DeptE         -0.46850    0.05276  -8.879  &lt; 2e-16 ***\n#&gt; DeptF         -0.26752    0.04972  -5.380 7.44e-08 ***\n#&gt; AdmitRejected  0.45674    0.03051  14.972  &lt; 2e-16 ***\n#&gt; GenderFemale  -0.38287    0.03027 -12.647  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2650.1  on 23  degrees of freedom\n#&gt; Residual deviance: 2097.7  on 16  degrees of freedom\n#&gt; AIC: 2272.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n添加性别和院系的交互效应后，对数线性模型的 AIC 下降一半多，说明模型的交互效应是显著的，也就是说性别和院系之间存在非常强的关联。\n\nfit_ucb1 &lt;- glm(Freq ~ Dept + Admit + Gender + Dept * Gender,\n  family = poisson(link = \"log\"),\n  data = as.data.frame(UCBAdmissions)\n)\nsummary(fit_ucb1)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Freq ~ Dept + Admit + Gender + Dept * Gender, family = poisson(link = \"log\"), \n#&gt;     data = as.data.frame(UCBAdmissions))\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)         5.76801    0.03951 145.992  &lt; 2e-16 ***\n#&gt; DeptB              -0.38745    0.05475  -7.076 1.48e-12 ***\n#&gt; DeptC              -0.93156    0.06549 -14.224  &lt; 2e-16 ***\n#&gt; DeptD              -0.68230    0.06008 -11.356  &lt; 2e-16 ***\n#&gt; DeptE              -1.46311    0.08030 -18.221  &lt; 2e-16 ***\n#&gt; DeptF              -0.79380    0.06239 -12.722  &lt; 2e-16 ***\n#&gt; AdmitRejected       0.45674    0.03051  14.972  &lt; 2e-16 ***\n#&gt; GenderFemale       -2.03325    0.10233 -19.870  &lt; 2e-16 ***\n#&gt; DeptB:GenderFemale -1.07581    0.22860  -4.706 2.52e-06 ***\n#&gt; DeptC:GenderFemale  2.63462    0.12343  21.345  &lt; 2e-16 ***\n#&gt; DeptD:GenderFemale  1.92709    0.12464  15.461  &lt; 2e-16 ***\n#&gt; DeptE:GenderFemale  2.75479    0.13510  20.391  &lt; 2e-16 ***\n#&gt; DeptF:GenderFemale  1.94356    0.12683  15.325  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for poisson family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2650.10  on 23  degrees of freedom\n#&gt; Residual deviance:  877.06  on 11  degrees of freedom\n#&gt; AIC: 1062.1\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n此辛普森悖论现象的解释是女生倾向于申请录取率低的院系，而男生倾向于申请录取率高的院系，最终导致整体上，男生的录取率显著高于女生。至于为什么女生会倾向于申请录取率低的院系？这可能要看具体的院系是哪些，招生政策如何？这已经不是仅仅依靠招生办的统计数字就可以完全解释得了的，更多详情见文献 Bickel, Hammel, 和 O’Connell (1975) 。\n\n\n\n\n\n\n提示\n\n\n\n对数线性模型的皮尔逊 \\(\\chi^2\\) 检验的统计量\n\nsum(residuals(fit_ucb1, type = \"pearson\")^2)\n\n#&gt; [1] 797.7045\n\n\n比较多个广义线性模型的拟合效果，除了看 AIC，还可以看对数似然，它越大越好。可以看到添加性别和院系的交互效应后，对数似然增加了一倍多。\n\n# 基础模型\nlogLik(fit_ucb0)\n\n#&gt; 'log Lik.' -1128.365 (df=8)\n\n# 添加交互效应\nlogLik(fit_ucb1)\n\n#&gt; 'log Lik.' -518.0581 (df=13)",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#sec-titanic",
    "href": "categorical-data-analysis.html#sec-titanic",
    "title": "21  分类数据的分析",
    "section": "\n21.6 分析泰坦尼克号乘客生存率",
    "text": "21.6 分析泰坦尼克号乘客生存率\n分析存活率的影响因素。\n除了从条件独立性检验的角度，下面从逻辑回归模型的角度分析这个高维列联表数据，由此，我们可以知道假设检验和广义线性模型之间的联系，针对复杂高维列联表数据进行关联分析和解释。\n响应变量是乘客的状态，存活还是死亡，titanic_data 是按船舱 Class、性别 Sex 和年龄 Age 分类汇总统计的数据，因此，下面的逻辑回归模型是对乘客群体的建模。\n\n# 建立模型\nfit_titanic &lt;- glm(cbind(Freq_Yes, Freq_No) ~ Class + Sex + Age,\n  data = titanic_data, family = binomial(link = \"logit\")\n)\n\n接着，我们查看模型输出的情况\n\n# 模型输出\nsummary(fit_titanic)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = cbind(Freq_Yes, Freq_No) ~ Class + Sex + Age, family = binomial(link = \"logit\"), \n#&gt;     data = titanic_data)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   0.6853     0.2730   2.510   0.0121 *  \n#&gt; Class2nd     -1.0181     0.1960  -5.194 2.05e-07 ***\n#&gt; Class3rd     -1.7778     0.1716 -10.362  &lt; 2e-16 ***\n#&gt; ClassCrew    -0.8577     0.1573  -5.451 5.00e-08 ***\n#&gt; SexFemale     2.4201     0.1404  17.236  &lt; 2e-16 ***\n#&gt; AgeAdult     -1.0615     0.2440  -4.350 1.36e-05 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 671.96  on 13  degrees of freedom\n#&gt; Residual deviance: 112.57  on  8  degrees of freedom\n#&gt; AIC: 171.19\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\n\n\n\n\n\nAgresti, Alan. 2007. An Introduction to Categorical Data Analysis. 2nd 本. Hoboken, New Jersey: John Wiley & Sons, Inc.\n\n\nBickel, P. J., E. A. Hammel, 和 J. W. O’Connell. 1975. 《Sex Bias in Graduate Admissions: Data from Berkeley》. Science 187 (4175): 398–404. https://doi.org/10.1126/science.187.4175.398.\n\n\nBrunson, Jason Cory. 2020. 《ggalluvial: Layered Grammar for Alluvial Plots》. Journal of Open Source Software 5 (49): 2017. https://doi.org/10.21105/joss.02017.\n\n\nClopper, C. J., 和 E. S. Pearson. 1934. 《The Use of Confidence or Fiducial Limits Illustrated In The Case of The Binomial》. Biometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nFriendly, Michael, 和 David Meyer. 2016. Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data. 1st 本. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nMeyer, David, Achim Zeileis, 和 Kurt Hornik. 2006. 《The Strucplot Framework: Visualizing Multi-Way Contingency Tables with vcd》. Journal of Statistical Software 17 (3): 1–48. https://doi.org/10.18637/jss.v017.i03.\n\n\nNewcombe, Robert G. 1998. 《Interval estimation for the difference between independent proportions: comparison of eleven methods》. Statistics in Medicine 17 (8): 873–90. https://doi.org/10.1002/(SICI)1097-0258(19980430)17:8&lt;873::AID-SIM779&gt;3.0.CO;2-I.\n\n\nWilson, Edwin B. 1927. 《Probable inference, the law of succession, and statistical inference》. Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZeileis, Achim, David Meyer, 和 Kurt Hornik. 2007. 《Residual-based Shadings for Visualizing (Conditional) Independence》. Journal of Computational and Graphical Statistics 16 (3): 507–25. https://doi.org/10.1198/106186007X237856.\n\n\n宋泽熙. 2011. 《两个二项总体成功概率的比较》. 中国校外教育（理论） z1: 81. https://doi.org/10.3969/j.issn.1004-8502-B.2011.z1.0919.",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "categorical-data-analysis.html#footnotes",
    "href": "categorical-data-analysis.html#footnotes",
    "title": "21  分类数据的分析",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Ronald_Fisher↩︎",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>分类数据的分析</span>"
    ]
  },
  {
    "objectID": "power-analysis.html",
    "href": "power-analysis.html",
    "title": "22  统计检验的功效",
    "section": "",
    "text": "22.1 三大检验方法\n统计检验的一般方法。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#三大检验方法",
    "href": "power-analysis.html#三大检验方法",
    "title": "22  统计检验的功效",
    "section": "",
    "text": "22.1.1 Wald 检验\n\n22.1.2 Wilks 检验\n也叫似然比检验\n\n22.1.3 Rao 检验\n也叫得分检验",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#t-检验的功效",
    "href": "power-analysis.html#t-检验的功效",
    "title": "22  统计检验的功效",
    "section": "\n22.2 t 检验的功效",
    "text": "22.2 t 检验的功效\n检验的功效常用于样本量的计算\npower.t.test() 计算单样本或两样本的 t 检验的功效，或者根据功效计算参数，如样本量\n\n代码library(ggplot2)\nn &lt;- 30 # 样本量（只是一个例子）\nx &lt;- seq(from = 0, to = 12, by = 0.01)\ndat &lt;- data.frame(xx = x / sqrt(n), yy = 2 * (1 - pt(x, n - 1)))\nggplot(data = dat, aes(x = xx, y = yy)) +\n  geom_line(linewidth = 1) +\n  geom_vline(xintercept = c(0.01, 0.2, 0.5, 0.8, 1.2, 2), linetype = 2) +\n  theme_classic(base_size = 13) +\n  labs(x = \"$d = \\\\frac{t}{\\\\sqrt{n}}$\", \n       y = \"$2(1 - \\\\mathrm{pt}(x, n - 1))$\")\n\n\n\n\n\n\n图 22.1: t 检验的功效\n\n\n\n\n\npower.t.test(\n  n = 100, delta = 2.2,\n  sd = 1, sig.level = 0.05,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 100\n#&gt;           delta = 2.2\n#&gt;              sd = 1\n#&gt;       sig.level = 0.05\n#&gt;           power = 1\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\n\n\n表格 22.1: 函数 power.t.test() 的参数及其含义\n\n\n\n\n\n\n\n参数\n含义\n\n\n\nn\n每个组的样本量\n\n\ndelta\n两个组的均值之差\n\n\nsd\n标准差，默认值 1\n\n\nsig.level\n显著性水平，默认是 0.05 （犯第 I 类错误的概率）\n\n\npower\n检验的功效（1 - 犯第 II 类错误的概率）\n\n\ntype\nt 检验的类型 \"two.sample\" 两样本、\"one.sample\" 单样本或 \"paired\" 配对样本\n\n\nalternative\n单边或双边检验，取值为 \"two.sided\" 或 \"one.sided\"\n\n\n\n\n\n\n\n参数 n，delta，power，sd 和 sig.level 必须有一个值为 NULL，为 NULL 的参数是由其它参数决定的。\n\n# 前面 t 检验的等价功效计算\nlibrary(pwr)\npwr.t.test(\n  d = 2.2 / 6.4,\n  n = 100,\n  sig.level = 0.05,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 100\n#&gt;               d = 0.34375\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.6768572\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\nsleep 数据集为例，计算功效\n\n# 分组计算均值\naggregate(data = sleep, extra ~ group, FUN = mean)\n\n#&gt;   group extra\n#&gt; 1     1  0.75\n#&gt; 2     2  2.33\n\n# 分组计算标准差\naggregate(data = sleep, extra ~ group, FUN = sd)\n\n#&gt;   group    extra\n#&gt; 1     1 1.789010\n#&gt; 2     2 2.002249\n\n# 代入计算功效\npower.t.test(\n  delta = 2.33 - 0.75,            # 两组均值之差\n  sd = (2.002249 + 1.789010) / 2, # 标准差\n  sig.level = 0.05,         # 显著性水平\n  type = \"two.sample\",      # 两样本\n  power = 0.95,             # 功效水平\n  alternative = \"two.sided\" # 双边检验\n)\n\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 38.39795\n#&gt;           delta = 1.58\n#&gt;              sd = 1.89563\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\n经检验，上面取两组的平均方差代替共同方差和下面精确计算的结果差不多。各组至少需要 39 个样本。MKpower 包精确计算 Welch t 检验的功效\n\nlibrary(MKpower)\npower.welch.t.test(\n  delta = 2.33 - 0.75,\n  sd1 = 2.002249,\n  sd2 = 1.789010,\n  sig.level = 0.05,\n  power = 0.95,\n  alternative = \"two.sided\"\n)\n\n我国著名统计学家许宝騄先生对此功效计算方法做出过巨大贡献。",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#比例检验的功效",
    "href": "power-analysis.html#比例检验的功效",
    "title": "22  统计检验的功效",
    "section": "\n22.3 比例检验的功效",
    "text": "22.3 比例检验的功效\n\n# power.prop.test()\n\npower.prop.test() 计算两样本比例检验的功效\n功效可以用来计算实验所需要的样本量，检验统计量的功效越大/高，检验方法越好，实验所需要的样本量越少\n\n# p1 &gt;= p2 的检验 单边和双边检验\npower.prop.test(\n  p1 = .65, p2 = 0.6, sig.level = .05,\n  power = 0.90, alternative = \"one.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample comparison of proportions power calculation \n#&gt; \n#&gt;               n = 1603.846\n#&gt;              p1 = 0.65\n#&gt;              p2 = 0.6\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = one.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\npower.prop.test(\n  p1 = .65, p2 = 0.6, sig.level = .05,\n  power = 0.90, alternative = \"two.sided\"\n)\n\n#&gt; \n#&gt;      Two-sample comparison of proportions power calculation \n#&gt; \n#&gt;               n = 1968.064\n#&gt;              p1 = 0.65\n#&gt;              p2 = 0.6\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\n\npwr 包 pwr.2p.test() 函数提供了类似 power.prop.test() 函数的功能\n\nlibrary(pwr)\n# 明确 p1 &gt; p2 的检验\n# 单边检验拆分更加明细，分为大于和小于\npwr.2p.test(\n  h = ES.h(p1 = 0.65, p2 = 0.6),\n  sig.level = 0.05, power = 0.9, alternative = \"greater\"\n)\n\n#&gt; \n#&gt;      Difference of proportion power calculation for binomial distribution (arcsine transformation) \n#&gt; \n#&gt;               h = 0.1033347\n#&gt;               n = 1604.007\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.9\n#&gt;     alternative = greater\n#&gt; \n#&gt; NOTE: same sample sizes\n\n\n已知两样本的样本量不等，检验 H_0: \\(p_1 = p_2\\) H_1: \\(p_1 \\neq p_2\\) 的功效\n\npwr.2p2n.test(\n  h = 0.30, n1 = 80, n2 = 245,\n  sig.level = 0.05, alternative = \"greater\"\n)\n\n#&gt; \n#&gt;      difference of proportion power calculation for binomial distribution (arcsine transformation) \n#&gt; \n#&gt;               h = 0.3\n#&gt;              n1 = 80\n#&gt;              n2 = 245\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.7532924\n#&gt;     alternative = greater\n#&gt; \n#&gt; NOTE: different sample sizes\n\n\nh 表示两个样本的差异，计算得到的功效是 0.75",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "power-analysis.html#方差分析的功效",
    "href": "power-analysis.html#方差分析的功效",
    "title": "22  统计检验的功效",
    "section": "\n22.4 方差分析的功效",
    "text": "22.4 方差分析的功效\npower.anova.test() 计算平衡的单因素方差分析检验的功效\n\npower.anova.test(\n  groups = 4,       #  4 个组  \n  between.var = 1,  # 组间方差为 1\n  within.var = 3,   # 组内方差为 3\n  power = 0.95      # 1 - 犯第二类错误的概率\n)\n\n#&gt; \n#&gt;      Balanced one-way analysis of variance power calculation \n#&gt; \n#&gt;          groups = 4\n#&gt;               n = 18.18245\n#&gt;     between.var = 1\n#&gt;      within.var = 3\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt; \n#&gt; NOTE: n is number in each group\n\n\n\nlibrary(pwr)\n# f 是如何和上面的组间/组内方差等价指定的\npwr.anova.test(\n  k = 4,            # 组数\n  f = 0.5,          # 效应大小\n  sig.level = 0.05, # 显著性水平\n  power = 0.95      # 检验的效\n)\n\n#&gt; \n#&gt;      Balanced one-way analysis of variance power calculation \n#&gt; \n#&gt;               k = 4\n#&gt;               n = 18.18244\n#&gt;               f = 0.5\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.95\n#&gt; \n#&gt; NOTE: n is number in each group",
    "crumbs": [
      "统计分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>统计检验的功效</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html",
    "href": "analyze-network-data.html",
    "title": "23  网络数据分析",
    "section": "",
    "text": "23.1 R 语言社区的规模\n从 CRAN 上的 R 包及其开发者数量来看目前 R 语言社区规模。\n# 设置就近的 CRAN 镜像站点\nSys.setenv(R_CRAN_WEB = \"https://mirrors.tuna.tsinghua.edu.cn/CRAN\")\n# 获取 R 包元数据\npdb &lt;- tools::CRAN_package_db()\n截止 2022 年 12 月 31 日， CRAN 上发布的 R 包有 18976 个，CRAN 进入年末维护期 2022-12-22 至 2023-01-05。\npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package),\n  select = c(\"Package\", \"Maintainer\", \"Title\", \"Authors@R\", \"Date\", \"Published\")\n)\n距离上次更新的时间分布，有的包是一周内更新的，也有的是 10 多年未更新的。\npdb$date_diff &lt;- as.integer(as.Date(\"2022-12-31\") - as.Date(pdb$Published))\n根据发布日期 Published 构造新的一列 — 发布年份。\npdb$published_year &lt;- as.integer(format(as.Date(pdb$Published), \"%Y\"))\n然后按年统计更新的 R 包数量，如 图 23.1 所示，以 2020 年为例，总数 18976 个 R 包当中有 2470 个 R 包的更新日期停留在 2020 年，占比 2470 / 18976 = 13.02%。过去 1 年内更新的 R 包有 8112 个（包含新出现的 R 包），占总数 8112 / 18976 = 42.75%，过去 2 年内更新的 R 包有 11553 个，占总数 11553 / 18976 = 60.88%，这个占比越高说明社区开发者越活跃。\nlibrary(ggplot2)\naggregate(data = pdb, Package ~ published_year, FUN = length) |&gt;\n  ggplot(aes(x = published_year, y = Package)) +\n  geom_col(fill = NA, color = \"gray20\") +\n  theme_classic() +\n  coord_cartesian(expand = F) +\n  labs(x = \"年份\", y = \"R 包数量\")\n\n\n\n\n\n\n图 23.1: CRAN 上 R 包的更新情况\n截止 2022-12-31，CRAN 上 R 包的维护者有 10067 人，其中有多少人在 2022 年更新了自己的 R 包呢？有 4820 个维护者，占比 47.96%，也就是说 2022 年，有 4820 个开发者更新了 8112 个 R 包，人均更新 1.68 个 R 包，下 图 23.2 按 R 包发布年份统计开发者数量。\n# 清理维护者字段，同一个开发者可能有多个邮箱\nextract_maintainer &lt;- function(x) {\n  x &lt;- gsub(pattern = \"&lt;.*?&gt;\", replacement = \"\", x = x)\n  trimws(x, which = \"both\", whitespace = \"[ \\t\\r\\n]\")\n}\n# 只有 18 个维护者名字有大小写差别\npdb$Maintainer2 &lt;- extract_maintainer(pdb$Maintainer)\n# 维护者总数\nlength(unique(pdb$Maintainer2))\n\n#&gt; [1] 10067\n代码aggregate(\n  data = pdb, Maintainer2 ~ published_year,\n  FUN = function(x) { length(unique(x)) }\n) |&gt;\n  ggplot(aes(x = published_year, y = Maintainer2)) +\n  geom_col(fill = NA, color = \"gray20\") +\n  theme_classic() +\n  coord_cartesian(expand = F) +\n  labs(x = \"年份\", y = \"开发者数量\")\n\n\n\n\n\n\n图 23.2: CRAN 上的维护者活跃情况",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-community-org",
    "href": "analyze-network-data.html#sec-community-org",
    "title": "23  网络数据分析",
    "section": "\n23.2 R 语言社区的组织",
    "text": "23.2 R 语言社区的组织\n除了 RStudio 公司出品的 tidyverse (Wickham 等 2019) 和 tidymodels (Kuhn 和 Wickham 2020)，还有一些数据分析、建模的工具箱，如 mlr3verse (Lang 和 Schratz 2023)、easystats (Lüdecke 等 2022)、strengejacke (Lüdecke 2019) 和 DrWhy (Biecek 2023)。也有的组织基本停止了开发，如 Omegahat。还有的被商业公司收购后，不再活跃了，如 Revolution Analytics。它们作为解决方案大都属于一些组织，还有深藏功与名，有待笔者挖掘的。因不存在明显的规律，下面从开发者的邮箱出发，隶属企业、组织往往有统一的邮箱后缀。\n\nstr_extract &lt;- function(text, pattern, ...) regmatches(text, regexpr(pattern, text, ...))\n# 移除 ORPHANED\npdb &lt;- subset(pdb, subset = Maintainer != \"ORPHANED\")\n# 抽取邮件后缀\nextract_email_suffix &lt;- function(x) {\n  x &lt;- str_extract(text = x, pattern = \"&lt;.*?&gt;\")\n  sub(x = x, pattern = \".*?@(.*?)&gt;\", replacement = \"\\\\1\")\n}\npdb$Email_suffix &lt;- extract_email_suffix(pdb$Maintainer)\n\n按组织统计扩展包的数量（总的 R 包数量约 2 万），即各个组织开发的 R 包。\n\npdb_pkg &lt;- aggregate(\n  data = pdb, Package ~ Email_suffix, FUN = function(x) { length(unique(x)) }\n)\nhead(pdb_pkg[order(pdb_pkg$Package, decreasing = TRUE), ], 20)\n\n#&gt;        Email_suffix Package\n#&gt; 876       gmail.com    6968\n#&gt; 2044    rstudio.com     208\n#&gt; 979     hotmail.com     185\n#&gt; 1825    outlook.com     152\n#&gt; 1971  R-project.org     106\n#&gt; 2           163.com      94\n#&gt; 210    berkeley.edu      91\n#&gt; 2559      umich.edu      91\n#&gt; 2819         uw.edu      74\n#&gt; 1927 protonmail.com      73\n#&gt; 2564        umn.edu      69\n#&gt; 581      debian.org      68\n#&gt; 2951      yahoo.com      68\n#&gt; 1828     outlook.fr      63\n#&gt; 2212   stanford.edu      58\n#&gt; 155  auckland.ac.nz      57\n#&gt; 887          gmx.de      55\n#&gt; 2911       wisc.edu      55\n#&gt; 895  googlemail.com      50\n#&gt; 1970  r-project.org      50\n\n\n不难看出，至少有如下几类：\n\n邮件服务提供商。6968 个 R 包使用 gmail 邮箱作为联系维护者的方式，googlemail.com 也是谷歌提供的服务。hotmail.com 和 outlook.com 都是微软提供的邮箱服务，outlook.fr （法国）也是，除此之外，比较大的邮件服务提供商就是 163.com（网易）、 protonmail.com 和 yahoo.com （雅虎）等。\n商业组织。208 个 R 包来自 RStudio 公司的员工，这些维护者使用 RStudio 公司提供的邮箱。\n开源组织。R-project.org 和 r-project.org 都是 R 语言组织的联系方式，自不必多说，R 语言核心团队成员不仅维护 R 软件源码，还维护了很多 R 包。debian.org 是 Debian 组织的联系方式，都是开源组织（Open Source Org）。\n教育机构。berkeley.edu 、umich.edu 等以 edu 结尾的北美（国）的大学，gmx.de、 posteo.de 等以 de 结尾的德国大学，ucl.ac.uk 等以 uk 结尾的英国的大学，auckland.ac.nz 等以 nz 结尾的新西兰的大学，uwaterloo.ca 等以 ca 结尾的加拿大的大学。\n\n按组织统计开发者的数量（总的开发者数量约 1 万），即各个组织的 R 包开发者。\n\npdb_org &lt;- aggregate(\n  data = pdb, Maintainer2 ~ Email_suffix, FUN = function(x) { length(unique(x)) }\n)\nhead(pdb_org[order(pdb_org$Maintainer2, decreasing = TRUE), ], 20)\n\n#&gt;        Email_suffix Maintainer2\n#&gt; 876       gmail.com        3800\n#&gt; 979     hotmail.com         110\n#&gt; 1825    outlook.com          87\n#&gt; 2           163.com          57\n#&gt; 2559      umich.edu          54\n#&gt; 2951      yahoo.com          51\n#&gt; 2564        umn.edu          47\n#&gt; 1927 protonmail.com          46\n#&gt; 2819         uw.edu          46\n#&gt; 887          gmx.de          34\n#&gt; 210    berkeley.edu          33\n#&gt; 2044    rstudio.com          30\n#&gt; 895  googlemail.com          28\n#&gt; 2212   stanford.edu          27\n#&gt; 468    columbia.edu          26\n#&gt; 1114       inrae.fr          26\n#&gt; 2451      ucl.ac.uk          25\n#&gt; 2964       yale.edu          25\n#&gt; 635        duke.edu          23\n#&gt; 1906      posteo.de          23\n\n\n可见，大部分开发者采用邮件服务提供商的邮件地址。3800 个开发者使用来自谷歌的 gmail.com、197 个开发者使用来自微软的 hotmail.com 或 outlook.com，57 个开发者使用来自网易的 163.com，51 个开发者使用来自雅虎的 yahoo.com，46 个开发者使用来自 Proton 的 protonmail.com。\n无论从开发者数量还是 R 包数量的角度看，都有两个显著特点。其一马太效应，往头部集中，其二，长尾分布，尾部占比接近甚至超过 50%。\n\n23.2.1 美国、英国和加拿大\n1666 个开发者来自以 edu 为后缀的邮箱。各个组织（主要是大学）及其 R 包开发者数据如下：\n\nsum(pdb_org[grepl(pattern = \"edu$\", x = pdb_org$Email_suffix), \"Maintainer2\"])\n\n#&gt; [1] 1666\n\npdb_org_edu &lt;- pdb_org[grepl(pattern = \"edu$\", x = pdb_org$Email_suffix), ]\npdb_org_edu[order(pdb_org_edu$Maintainer2, decreasing = TRUE), ] |&gt; head(20)\n\n#&gt;        Email_suffix Maintainer2\n#&gt; 2559      umich.edu          54\n#&gt; 2564        umn.edu          47\n#&gt; 2819         uw.edu          46\n#&gt; 210    berkeley.edu          33\n#&gt; 2212   stanford.edu          27\n#&gt; 468    columbia.edu          26\n#&gt; 2964       yale.edu          25\n#&gt; 635        duke.edu          23\n#&gt; 2911       wisc.edu          23\n#&gt; 482     cornell.edu          22\n#&gt; 2444    ucdavis.edu          21\n#&gt; 1929        psu.edu          19\n#&gt; 2449   uchicago.edu          19\n#&gt; 2830 vanderbilt.edu          19\n#&gt; 1660       ncsu.edu          18\n#&gt; 1663         nd.edu          18\n#&gt; 1008    iastate.edu          17\n#&gt; 1919  princeton.edu          17\n#&gt; 1815        osu.edu          16\n#&gt; 2523      uiowa.edu          16\n\n\n好吧，几乎全是美国各个 NB 大学的，比如华盛顿大学（ uw.edu）、密歇根大学（umich.edu）、加州伯克利大学（berkeley.edu）等等。顺便一说，美国各个大学的网站，特别是统计院系很厉害的，已经帮大家收集得差不多了，有留学打算的读者自取，邮箱后缀就是学校/院官网。\n有些邮箱后缀带有院系，但是并没有向上合并到学校这一级，比如 stanford.edu 、stat.stanford.edu 和 alumni.stanford.edu 等没有合并统计。实际上，使用 edu 邮箱的教育机构大部份位于美国。有的邮箱来自教育机构，但是不以 edu 结尾，比如新西兰奥克兰大学 auckland.ac.nz 、瑞士苏黎世联邦理工学院 stat.math.ethz.ch 等美国以外的教育机构。下面分别查看英国和加拿大的情况。\n350 个开发者来自以 uk 为后缀的邮箱。各个组织（主要是大学）及其 R 包开发者数据如下：\n\nsum(pdb_org[grepl(pattern = \"uk$\", x = pdb_org$Email_suffix), \"Maintainer2\"])\n\n#&gt; [1] 350\n\npdb_org_uk &lt;- pdb_org[grepl(pattern = \"uk$\", x = pdb_org$Email_suffix), ]\npdb_org_uk[order(pdb_org_uk$Maintainer2, decreasing = TRUE), ] |&gt; head(20)\n\n#&gt;            Email_suffix Maintainer2\n#&gt; 2451          ucl.ac.uk          25\n#&gt; 329           cam.ac.uk          17\n#&gt; 295       bristol.ac.uk          15\n#&gt; 1088     imperial.ac.uk          14\n#&gt; 658            ed.ac.uk          13\n#&gt; 1286    lancaster.ac.uk          11\n#&gt; 1363          lse.ac.uk           9\n#&gt; 1605  mrc-bsu.cam.ac.uk           9\n#&gt; 2878      warwick.ac.uk           9\n#&gt; 870       glasgow.ac.uk           8\n#&gt; 1364        lshtm.ac.uk           8\n#&gt; 1424   manchester.ac.uk           8\n#&gt; 636        durham.ac.uk           7\n#&gt; 744        exeter.ac.uk           7\n#&gt; 2260 statslab.cam.ac.uk           7\n#&gt; 2188        soton.ac.uk           6\n#&gt; 2972         york.ac.uk           6\n#&gt; 978       hotmail.co.uk           5\n#&gt; 1948         qmul.ac.uk           5\n#&gt; 248         bioss.ac.uk           4\n\n\n258 个开发者来自以 ca 为后缀的邮箱。各个组织（主要是大学）及其 R 包开发者数据如下：\n\nsum(pdb_org[grepl(pattern = \"ca$\", x = pdb_org$Email_suffix), \"Maintainer2\"])\n\n#&gt; [1] 258\n\npdb_org_ca &lt;- pdb_org[grepl(pattern = \"ca$\", x = pdb_org$Email_suffix), ]\npdb_org_ca[order(pdb_org_ca$Maintainer2, decreasing = TRUE), ] |&gt; head(10)\n\n#&gt;          Email_suffix Maintainer2\n#&gt; 2822     uwaterloo.ca          19\n#&gt; 1397   mail.mcgill.ca          14\n#&gt; 2123           sfu.ca          12\n#&gt; 2801      utoronto.ca          12\n#&gt; 2426      ualberta.ca          11\n#&gt; 2239      stat.ubc.ca           9\n#&gt; 2434           ubc.ca           9\n#&gt; 2813          uvic.ca           8\n#&gt; 952            hec.ca           7\n#&gt; 1416 mail.utoronto.ca           7\n\n\n\n23.2.2 CRAN 和 RStudio\n下面根据邮箱后缀匹配抽取 CRAN 团队及开发的 R 包，规则也许不能覆盖所有的情况，比如署名 CRAN Team 的维护者代表的是 CRAN 团队，XML 和 RCurl 包就由他们维护。再比如，Brian Ripley 的邮箱 ripley@stats.ox.ac.uk 就不是 CRAN 官网域名。读者若有补充，欢迎 PR 给我。\n代码cran_dev &lt;- subset(pdb,\n  subset = grepl(\n    x = Maintainer,\n    pattern = paste0(c(\n      \"(@[Rr]-project\\\\.org)\", # 官方邮箱\n      \"(ripley@stats.ox.ac.uk)\", # Brian Ripley\n      \"(p.murrell@auckland.ac.nz)\", # Paul Murrell\n      \"(paul@stat.auckland.ac.nz)\", # Paul Murrell\n      \"(maechler@stat.math.ethz.ch)\", # Martin Maechler\n      \"(mmaechler+Matrix@gmail.com)\", # Martin Maechler\n      \"(bates@stat.wisc.edu)\", # Douglas Bates\n      \"(pd.mes@cbs.dk)\", # Peter Dalgaard\n      \"(ligges@statistik.tu-dortmund.de)\", # Uwe Ligges\n      \"(tlumley@u.washington.edu)\", # Thomas Lumley\n      \"(t.lumley@auckland.ac.nz)\", # Thomas Lumley\n      \"(martyn.plummer@gmail.com)\", # Martyn Plummer\n      \"(luke-tierney@uiowa.edu)\", # Luke Tierney\n      \"(stefano.iacus@unimi.it)\", # Stefano M. Iacus\n      \"(murdoch.duncan@gmail.com)\", # Duncan Murdoch\n      \"(michafla@gene.com)\" # Michael Lawrence\n    ), collapse = \"|\")\n  ),\n  select = c(\"Package\", \"Maintainer\")\n) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = '(&lt;([^&lt;&gt;]*)&gt;)|(\")', replacement = \"\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = \"(R-core)|(R Core Team)\", replacement = \"CRAN Team\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer,\n    pattern = \"(S. M. Iacus)|(Stefano M.Iacus)|(Stefano Maria Iacus)\",\n    replacement = \"Stefano M. Iacus\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = \"(Toby Hocking)\",\n    replacement = \"Toby Dylan Hocking\"\n  )) |&gt;\n  transform(Maintainer = gsub(\n    x = Maintainer, pattern = \"(John M Chambers)\", replacement = \"John Chambers\"\n  ))\ncran_dev &lt;- aggregate(data = cran_dev, Package ~ Maintainer, FUN = function(x) length(unique(x)))\ncran_dev &lt;- cran_dev[order(cran_dev$Package, decreasing = TRUE), ]\nknitr::kable(head(cran_dev, ceiling(nrow(cran_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\nknitr::kable(tail(cran_dev, floor(nrow(cran_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n\n\n表格 23.1: CRAN 团队开发维护 R 包数量情况\n\n\n\n\n\n(a) 表\n\n\n\n团队成员\nR 包数量\n\n\n\nKurt Hornik\n28\n\n\nSimon Urbanek\n26\n\n\nAchim Zeileis\n25\n\n\nMartin Maechler\n25\n\n\nTorsten Hothorn\n25\n\n\nPaul Murrell\n19\n\n\nToby Dylan Hocking\n17\n\n\nBrian Ripley\n12\n\n\nThomas Lumley\n12\n\n\nUwe Ligges\n9\n\n\nDuncan Murdoch\n7\n\n\nDavid Meyer\n6\n\n\nCRAN Team\n5\n\n\n\n\n\n\n\n\n\n\n(b) 续表\n\n\n\n团队成员\nR 包数量\n\n\n\nFriedrich Leisch\n5\n\n\nLuke Tierney\n5\n\n\nMichael Lawrence\n5\n\n\nStefan Theussl\n5\n\n\nBettina Grün\n3\n\n\nJohn Chambers\n3\n\n\nSimon Wood\n3\n\n\nBettina Gruen\n2\n\n\nDeepayan Sarkar\n2\n\n\nDouglas Bates\n2\n\n\nMartyn Plummer\n2\n\n\nPeter Dalgaard\n1\n\n\n\n\n\n\n\n\n\n\n\nKurt Hornik、Simon Urbanek、Achim Zeileis 等真是高产呐！除了维护 R 语言核心代码，还开发维护了那么多 R 包。以 Brian Ripley 为例，看看他都具体维护了哪些 R 包。\n\n代码subset(pdb,\n  subset = grepl(x = Maintainer, pattern = \"Brian Ripley\"),\n  select = c(\"Package\", \"Title\"), drop = TRUE\n) |&gt;\n  unique(by = \"Package\") |&gt;\n  transform(Title = gsub(pattern = \"(\\\\\\n)\", replacement = \" \", x = Title)) |&gt;\n  knitr::kable(row.names = FALSE)\n\n\n表格 23.2: Brian Ripley 维护的 R 包\n\n\n\n\n\n\n\n\nPackage\nTitle\n\n\n\nboot\nBootstrap Functions (Originally by Angelo Canty for S)\n\n\nclass\nFunctions for Classification\n\n\nfastICA\nFastICA Algorithms to Perform ICA and Projection Pursuit\n\n\ngee\nGeneralized Estimation Equation Solver\n\n\nKernSmooth\nFunctions for Kernel Smoothing Supporting Wand & Jones (1995)\n\n\nMASS\nSupport Functions and Datasets for Venables and Ripley’s MASS\n\n\nmix\nEstimation/Multiple Imputation for Mixed Categorical and Continuous Data\n\n\nnnet\nFeed-Forward Neural Networks and Multinomial Log-Linear Models\n\n\npspline\nPenalized Smoothing Splines\n\n\nRODBC\nODBC Database Access\n\n\nspatial\nFunctions for Kriging and Point Pattern Analysis\n\n\ntree\nClassification and Regression Trees\n\n\n\n\n\n\n\n\n震惊！有一半收录在 R 软件中，所以已经持续维护 20 多年了。下面继续根据邮箱后缀将 RStudio 团队的情况统计出来，结果见下表。\n代码rstudio_dev &lt;- subset(pdb,\n  subset = grepl(x = Maintainer, pattern = \"(posit.co)|(rstudio.com)|(yihui.name)\"),\n  select = c(\"Package\", \"Maintainer\")\n) |&gt;\n  transform(Maintainer = extract_maintainer(Maintainer))\nrstudio_dev &lt;- aggregate(data = rstudio_dev, Package ~ Maintainer, FUN = function(x) length(unique(x)))\nrstudio_dev &lt;- rstudio_dev[order(rstudio_dev$Package, decreasing = TRUE), ]\nknitr::kable(head(rstudio_dev, ceiling(nrow(rstudio_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\nknitr::kable(tail(rstudio_dev, floor(nrow(rstudio_dev) / 2)),\n  col.names = c(\"团队成员\", \"R 包数量\"), row.names = FALSE\n)\n\n\n表格 23.3: RStudio 团队开发维护 R 包数量情况（部分）\n\n\n\n\n\n(a) 表\n\n\n\n团队成员\nR 包数量\n\n\n\nHadley Wickham\n48\n\n\nYihui Xie\n22\n\n\nMax Kuhn\n18\n\n\nLionel Henry\n15\n\n\nWinston Chang\n15\n\n\nDaniel Falbel\n13\n\n\nJennifer Bryan\n13\n\n\nDavis Vaughan\n11\n\n\nCarson Sievert\n10\n\n\nTomasz Kalinowski\n8\n\n\nBarret Schloerke\n6\n\n\nThomas Lin Pedersen\n6\n\n\nHannah Frick\n5\n\n\nChristophe Dervieux\n4\n\n\nJoe Cheng\n4\n\n\nJulia Silge\n4\n\n\n\n\n\n\n\n\n\n\n(b) 续表\n\n\n\n团队成员\nR 包数量\n\n\n\nCole Arendt\n3\n\n\nEdgar Ruiz\n3\n\n\nJJ Allaire\n3\n\n\nKevin Kuo\n3\n\n\nKevin Ushey\n3\n\n\nRichard Iannone\n3\n\n\nAron Atkins\n2\n\n\nRomain François\n2\n\n\nYitao Li\n2\n\n\nBrian Smith\n1\n\n\nEmil Hvitfeldt\n1\n\n\nGarrick Aden-Buie\n1\n\n\nJames Blair\n1\n\n\nNathan Stephens\n1\n\n\nNick Strayer\n1\n\n\n\n\n\n\n\n\n\n\n\nCRAN 和 RStudio 团队是 R 语言社区最为熟悉的，其它团队需借助一些网络分析算法挖掘了。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-community-developer",
    "href": "analyze-network-data.html#sec-community-developer",
    "title": "23  网络数据分析",
    "section": "\n23.3 R 语言社区的开发者",
    "text": "23.3 R 语言社区的开发者\n\n23.3.1 最高产的开发者\n继续基于数据集 pdb ，将维护 R 包数量比较多的开发者统计出来。\n\n代码pdb_ctb &lt;- aggregate(data = pdb, Package ~ Maintainer2, FUN = length)\nggplot(data = pdb_ctb[pdb_ctb$Package &gt;= 20, ]) +\n  geom_col(aes(x = Package, y = reorder(Maintainer2, Package)), width = .1) +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\n\n\n\n\n\n\n图 23.3: 高产的 R 包开发者\n\n\n\n\n这些开发者的主页和主要的 R 社区贡献如下：\n\n\nDirk Eddelbuettel 维护了 Rcpp、RcppEigen 等流行的 R 包，通过 Rcpp 包将很多优秀的 C++ 库引入 R 语言社区。\n\nStéphane Laurent 维护了很多与 shiny、htmlwidgets 相关的 R 包，比如 rAmCharts4 包。\n\nGábor Csárdi 维护了 igraph 包以及大量帮助 R 包开发的基础设施，RStudio 雇员。\n\nHadley Wickham 维护了 ggplot2、dplyr、devtools 等流行的 R 包，RStudio 雇员。\n\nJeroen Ooms 维护了 magick、curl 以及大量帮助 R 包开发的基础设施。\n\nScott Chamberlain 维护了很多与 HTTP/Web 相关的 R 包，rOpenSci 联合创始人。\n\nRobin K. S. Hankin 维护了很多与贝叶斯、多元统计相关的 R 包。\n\nHenrik Bengtsson 维护了 future 和 parallelly 等流行的 R 包，在并行计算方面有很多贡献。\n\nJan Wijffels 维护了很多与自然语言处理、图像识别相关的 R 包，比如 udpipe 、BTM 和 word2vec 等包，Bnosac 团队成员。\n\nKurt Hornik 参与维护 R 软件代码并许多与自然语言处理相关的 R 包，R 核心团队成员。\n\nMartin Maechler 维护了 Matrix 包，R 核心团队成员。\n\nMax Kuhn 维护了 tidymodels 等包，RStudio 雇员。\n\nBob Rudis 维护了一些与 ggplot2 相关的 R 包，如 ggalt、hrbrthemes 和 statebins 等。\n\nKartikeya Bolar 维护了很多统计与 shiny 结合的 R 包，比如方差分析、逻辑回归、列联表、聚类分析等。\n\nKirill Müller 维护了 DBI 等大量与数据库连接的 R 包。\n\nShannon T. Holloway 维护了许多与生存分析相关的 R 包。\n\nSimon Urbanek 维护了 rJava、Rserve 等流行的 R 包，R 核心团队成员，负责维护 R 软件中与 MacOS 平台相关的部分。\n\nAchim Zeileis 维护了 colorspace 等流行的 R 包，R 核心团队成员。\n\nMuhammad Yaseen 维护了多个与 Multiple Indicator Cluster Survey 相关的 R 包。\n\nPablo Sanchez 维护了多个与市场营销平台连接的 R 语言接口，Windsor.ai 组织成员。\n\nThomas Lin Pedersen 维护了 patchwork、 gganimate 和 ggraph 等流行的 R 包，RStudio 雇员。\n\nTorsten Hothorn 在统计检验方面贡献了不少内容，比如 coin 和 multcomp 等包，R 核心团队成员。\n\nRichard Cotton 维护了 assertive 和 rebus 系列 R 包，代码可读性检查。\n\nFlorian Schwendinger 维护了大量运筹优化方面的 R 包，扩展了 ROI 包的能力。\n\nGuangchuang Yu 维护了 ggtree 和 ggimage 等 R 包，在生物信息和可视化领域有不少贡献。\n\nWinston Chang 维护了 shiny 等流行的 R 包，RStudio 雇员。\n\nJohn Muschelli 维护了多个关于神经图像的 R 包。\n\nKevin R. Coombes 维护了多个关于生物信息的 R 包，如 oompaBase 和 oompaData 等。\n\nYihui Xie 维护了 knitr 、rmarkdown 等流行的 R 包，RStudio 雇员。\n\nCarl Boettiger 维护了多个接口包，比如 rfishbase 等，rOpenSci 团队成员。\n\nMichael D. Sumner 维护了多个空间统计相关的 R 包。\n\nEmil Hvitfeldt 维护了多个统计学习相关的 R 包，如 fastTextR 包等，RStudio 雇员。\n\nGeorgi N. Boshnakov 维护了多个金融时间序列相关的 R 包，如 fGarch、timeDate 和 timeSeries 等包。\n\nHana Sevcikova 维护了多个与贝叶斯人口统计相关的 R 包。\n\nJoe Thorley 维护了多个与贝叶斯 MCMC 相关的 R 包，Poisson Consulting 雇员。\n\n统计开发者数量随维护 R 包数量的分布，发现，开发 1 个 R 包的开发者有 6732 人，开发 2 个 R 包的开发者有 1685 人，第二名是第一名的五分之一，递减规律非常符合指数分布。\n\ntable(pdb_ctb$Package)\n\n#&gt; \n#&gt;    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n#&gt; 6732 1685  725  328  177   82   80   52   37   37   29   15   18    8   11    7 \n#&gt;   17   18   19   20   21   22   23   24   25   26   27   28   31   32   33   52 \n#&gt;    1    3    4    4    2    3    3    1    5    5    2    1    1    1    1    3 \n#&gt;   58   63   69 \n#&gt;    1    1    1\n\n\n过滤掉非常高产的开发者，可以发现变化规律服从幂律分布。\nggplot(data = pdb_ctb, aes(x = Package)) +\n  geom_histogram(binwidth = 1) +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\nggplot(data = pdb_ctb[pdb_ctb$Package &lt;= 20, ], aes(x = Package)) +\n  geom_histogram(binwidth = 1, fill = NA, color = \"gray20\") +\n  scale_y_log10() +\n  theme_classic() +\n  labs(x = \"R 包数量\", y = \"开发者\")\n\n\n\n\n\n\n\n\n\n(a) 直方图\n\n\n\n\n\n\n\n\n\n(b) 直方图（对数尺度）\n\n\n\n\n\n\n图 23.4: 开发者数量的分布\n\n\n最高产 Top 1% 的开发者 131 人（开发 R 包超过 10 个的开发者）贡献了 2329 / 18976 = 12.3% 的扩展包 ，高产的是商业公司、开源组织、大学机构。\n\ndim(pdb_ctb[pdb_ctb$Package &gt; 10, ])\n\n#&gt; [1] 131   2\n\nsum(pdb_ctb[pdb_ctb$Package &gt; 10, \"Package\"])\n\n#&gt; [1] 2329\n\n\n最低产 Bottom 的开发者 6732 人（仅开发一个 R 包的开发者）占总开发者的比例 6732 / 10067 = 66.87%， 贡献了 6732 / 18976 = 35.5 % 的扩展包 ，低产的人是主体。\n\n23.3.2 开发者协作关系\n如果一个开发者维护了一个 R 包，就成为维护者。一个 R 包有唯一的一个维护者，可能有一个至多个贡献者，这样，维护者和贡献者之间就形成了有向关系，贡献者可能又是另一个 R 包的维护者，也可能不是。不仅有向而且可能存在环。在一个 R 包中，A 是 B 的贡献者，而在另一个 R 包中，B 是 A 的贡献者，A 和 B 之间可能通过多个 R 包存在多次互相协作关系，这也表明 A 和 B 之间的关系密切。有向环的节点可能有 2 个以上，一个人可能同时属于多个环。\n维护者 A 接受来自多个开发者的贡献，接受次数（所有贡献者人数的累和，A 的每个 R 包的贡献者人数相加）视为 A 的入度。维护者 A 作为开发者给多个维护者贡献，贡献次数（作为开发者给其它 R 包做贡献的次数，向外参与贡献的 R 包数目）视为 A 的出度。注意，A 作为维护者，必然包含 A 作为开发者，忽略 A 到 A 的贡献，只考虑贡献/协作关系。\n\n# 过滤重复和缺失的记录\npdb &lt;- subset(\n  x = pdb, subset = !duplicated(Package) & !is.na(`Authors@R`),\n  select = c(\"Package\", \"Maintainer\", \"Authors@R\")\n)\n# 提取维护者的名字\npdb$Maintainer &lt;- extract_maintainer(pdb$Maintainer)\n\n有些包的元数据中没有 Authors@R 字段，有可能是没有贡献者，比如 mgcv 包、gam 包等，但也有可能是有贡献者，只是维护者没有填写这个字段，比如 Rcpp 包、RcppEigen 包等，因此将这些先过滤出来。总之，本文是以 Authors@R 字段作为贡献者的来源，共计 12503 个 R 包含有 Authors@R ，有 6000+ 个 R 包没有该字段，缺失约占 R 包总数的 1/3，在不那么考虑准确性的情况下，也可以使用。Author 字段是一段没有结构的文本，相比于 Author 字段，Authors@R 字段是以 R 语言中的 person 类型为存储结构的，比较规范，因此，提取贡献者的操作比较方便。作为示例，下面提取 Matrix 包的贡献者。\n\ntmp &lt;- eval(parse(text = pdb[pdb$Package == \"Matrix\", \"Authors@R\"]))\ntmp &lt;- unlist(lapply(tmp, function(x) format(x, include = c(\"given\", \"family\"))))\n# 返回一个整洁的数据框\ntmp &lt;- data.frame(Package = \"Matrix\", Maintainer = pdb[pdb$Package == \"Matrix\", \"Maintainer\"], Authors = tmp)\n# 去掉 Authors 是 Maintainer 的记录\nsubset(tmp, subset = Maintainer != Authors)\n\n#&gt;   Package      Maintainer           Authors\n#&gt; 1  Matrix Martin Maechler     Douglas Bates\n#&gt; 3  Matrix Martin Maechler      Mikael Jagan\n#&gt; 4  Matrix Martin Maechler  Timothy A. Davis\n#&gt; 5  Matrix Martin Maechler Jens Oehlschlägel\n#&gt; 6  Matrix Martin Maechler       Jason Riedy\n#&gt; 7  Matrix Martin Maechler       R Core Team\n\n\n数据框包含 R 包（Package 字段）、及其维护者（Maintainer 字段）和贡献者（Authors 字段）。将上述过程写成一个函数，接着，将所有 R 包的贡献者提取出来，形成一个大的数据框。\n\nextract_authors &lt;- function(pkg) {\n  sub_pdb &lt;- pdb[pdb$Package == pkg, ]\n  tmp &lt;- eval(parse(text = sub_pdb[, \"Authors@R\"]))\n  tmp &lt;- unlist(lapply(tmp, function(x) format(x, include = c(\"given\", \"family\"))))\n  tmp &lt;- data.frame(Package = pkg, Maintainer = sub_pdb[, \"Maintainer\"], Authors = tmp)\n  subset(tmp, subset = Maintainer != Authors)\n}\nextract_authors(\"Matrix\")\n\n#&gt;   Package      Maintainer           Authors\n#&gt; 1  Matrix Martin Maechler     Douglas Bates\n#&gt; 3  Matrix Martin Maechler      Mikael Jagan\n#&gt; 4  Matrix Martin Maechler  Timothy A. Davis\n#&gt; 5  Matrix Martin Maechler Jens Oehlschlägel\n#&gt; 6  Matrix Martin Maechler       Jason Riedy\n#&gt; 7  Matrix Martin Maechler       R Core Team\n\n# lapply(c(\"Matrix\", \"gt\"), extract_authors)\n# 抽取所有 R 包的贡献者，运行需要1-2分钟时间\npdb_authors_list &lt;- lapply(pdb[, \"Package\"], extract_authors)\n# 合并列表\npdb_authors_dt &lt;- data.table::rbindlist(pdb_authors_list)\n\n最后整理出来的大数据框 pdb_authors_dt 含有近 26000 条记录，即边的规模大小。考虑到有些维护者和贡献者之间可能存在多次合作的情况，下面统计一下合作次数。\n\npdb_authors_dt[ ,.(cnt = length(Package)) , by = c(\"Maintainer\", \"Authors\")\n                ][cnt &gt;= 10, ][order(cnt, decreasing = T), ]\n\n#&gt;                 Maintainer               Authors   cnt\n#&gt;                     &lt;char&gt;                &lt;char&gt; &lt;int&gt;\n#&gt;  1:         Hadley Wickham               RStudio    36\n#&gt;  2:          Pablo Sanchez            Windsor.ai    25\n#&gt;  3:           Jan Wijffels                BNOSAC    24\n#&gt;  4:           Gábor Csárdi               RStudio    19\n#&gt;  5:               Hong Ooi             Microsoft    16\n#&gt;  6:               Max Kuhn               RStudio    14\n#&gt;  7:           Lionel Henry               RStudio    14\n#&gt;  8:      Robrecht Cannoodt        Wouter Saelens    13\n#&gt;  9:      Scott Chamberlain              rOpenSci    13\n#&gt; 10:            Joe Thorley    Poisson Consulting    13\n#&gt; 11:      Frederic Bertrand Myriam Maumy-Bertrand    12\n#&gt; 12:          Winston Chang               RStudio    12\n#&gt; 13:          Daniel Falbel               RStudio    12\n#&gt; 14:           David Kretch           Adam Banker    12\n#&gt; 15:           David Kretch      Amazon.com, Inc.    12\n#&gt; 16:         Victor Perrier           Fanny Meyer    11\n#&gt; 17:         Jennifer Bryan               RStudio    11\n#&gt; 18: William Michael Landau Eli Lilly and Company    11\n#&gt; 19:        Adrian Baddeley             Ege Rubak    11\n#&gt; 20:           Gábor Csárdi            Jim Hester    10\n#&gt; 21:          Kirill Müller               RStudio    10\n#&gt; 22:         Carson Sievert               RStudio    10\n#&gt; 23:    Thomas Lin Pedersen               RStudio    10\n#&gt; 24:           Lionel Henry        Hadley Wickham    10\n#&gt; 25:        Adrian Baddeley           Rolf Turner    10\n#&gt;                 Maintainer               Authors   cnt\n\n\nAuthors 字段出现了不少组织的名字，这是因为有许多 R 包的维护者受雇于该组织，版权归属于该组织，组织不仅提供持续的资金，而且还提供其它帮助。以 dplyr 包为例，Hadley Wickham 受雇于 RStudio 公司，在 dplyr 包的元数据中，字段 Authors@R 中 RStudio 的角色是 cph 和 fnd ，即版权所有和资金支持。角色 cre 就是维护者，负责与 CRAN 团队的沟通。角色 aut 就是对 R 包有实质贡献的人。\n\nformat(eval(parse(text = pdb[pdb$Package == \"dplyr\", \"Authors@R\"])),\n       include = c(\"given\", \"family\", \"role\"))\n\n#&gt; [1] \"Hadley Wickham [aut, cre]\" \"Romain François [aut]\"    \n#&gt; [3] \"Lionel Henry [aut]\"        \"Kirill Müller [aut]\"      \n#&gt; [5] \"RStudio [cph, fnd]\"\n\n\n此外，同属于一个组织的维护者之间常常合作紧密，从上面的结果可以看到，Gábor Csárdi 和 Jim Hester ，Lionel Henry 和 Hadley Wickham，Carson Sievert 和 Joe Cheng ，Jennifer Bryan 和 Hadley Wickham 等同属于 RStudio 公司，常常协作开发项目。对 RStudio、CRAN Team 和 rOpenSci 不再赘述，下面对排名靠前的其它组织略作说明。\n\n\nWindsor.ai 提供一系列可以连接各大营销平台，获取营销效果数据 R 包。\n\nBNOSAC 提供一系列计算机视觉、图像识别、自然语言处理方面的 R 包，比如 udpipe、word2vec、doc2vec 等包。\nMicrosoft 提供一系列连接和操作 Azure 云套件的 R 包，比如 AzureR 包。\n\nWouter Saelens 提供一系列单细胞轨迹推理（single-cell trajectory inference）相关的 R 包，形成一个 dynverse 家族。\n\n\nPoisson Consulting 提供一系列用于计算生物学和统计生态学的 R 包和相关研究论文。\n\nAmazon.com, Inc. 提供一系列用于存储、管理、操作等 Amazon 云服务的 R 包，形成一个 paws 套件。\n\nEli Lilly and Company 可能是 rOpenSci 的一员，赞助了旗下的 targets 和 jagstargets 等 R 包。\n\n最后，统计协作次数的分布，网络中边的权重的分布。\n\npdb_authors_net &lt;- pdb_authors_dt[, .(cnt = .N), by = c(\"Maintainer\", \"Authors\")]\ntable(pdb_authors_net$cnt)\n\n#&gt; \n#&gt;     1     2     3     4     5     6     7     8     9    10    11    12    13 \n#&gt; 20432  1511   365   121    44    28    14     8     3     6     4     5     3 \n#&gt;    14    16    19    24    25    36 \n#&gt;     2     1     1     1     1     1\n\n\n可以发现，绝大多数人之间协作只有一次。\n\n23.3.3 节点出入度分布\n下面简化这个网络，仅考虑贡献者也是维护者的情况，就是说网络中所有节点既是维护者也是贡献者，这会过滤掉组织机构、大量没有在 CRAN 发过 R 包的贡献者、从没给其它维护者做贡献的维护者。简化后，网络节点的出度、入度的分布图如下。\n# Maintainer 的入度\npdb_authors_net_indegree &lt;- pdb_authors_dt[Authors %in% Maintainer, \n  ][, .(in_degree = length(Authors)), by = \"Maintainer\"]\n# Authors 的出度\npdb_authors_net_outdegree &lt;- pdb_authors_dt[Authors %in% Maintainer, \n  ][, .(out_degree = length(Maintainer)), by = \"Authors\"]\n\nggplot(pdb_authors_net_indegree, aes(x = in_degree)) +\n  geom_histogram(binwidth = 1) +\n  geom_freqpoly(binwidth = 1) +\n  theme_classic()\nggplot(pdb_authors_net_outdegree, aes(x = out_degree)) +\n  geom_histogram(binwidth = 1) +\n  geom_freqpoly(binwidth = 1) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n(a) 入度的分布\n\n\n\n\n\n\n\n\n\n(b) 出度的分布\n\n\n\n\n\n\n图 23.5: 节点的入度和出度的分布\n\n\n\n23.3.4 可视化协作网络\n节点的大小以维护者维护的 R 包数量来表示，边的大小以维护者之间协作次数来表示。为了美观起见，更为了突出重点，仅保留协作次数大于 1 的边。\n\n# 边\npdb_authors_net_edge &lt;- pdb_authors_dt[Authors %in% Maintainer, \n  ][, .(edge_cnt = .N), by = c(\"Authors\", \"Maintainer\")][edge_cnt &gt; 1, ]\npdb_authors_net_edge[order(edge_cnt, decreasing = TRUE),]\n\n#&gt;                      Authors            Maintainer edge_cnt\n#&gt;                       &lt;char&gt;                &lt;char&gt;    &lt;int&gt;\n#&gt;   1:              Jim Hester          Gábor Csárdi       10\n#&gt;   2:          Hadley Wickham          Lionel Henry       10\n#&gt;   3:               Joe Cheng        Carson Sievert        9\n#&gt;   4:          Hadley Wickham        Jennifer Bryan        8\n#&gt;   5: Steven Andrew Culpepper James Joseph Balamuta        8\n#&gt;  ---                                                       \n#&gt; 526:             Aaron Wolen     Scott Chamberlain        2\n#&gt; 527:               Bob Rudis         Simon Garnier        2\n#&gt; 528:           Marco Sciaini         Simon Garnier        2\n#&gt; 529:          Carlos Morales           Martin Chan        2\n#&gt; 530:               Md Yeasin     Ranjit Kumar Paul        2\n\n# 顶点\npdb_authors_net_vertex &lt;- pdb_authors_dt[, .(vertex_cnt = length(unique(Package))), by = \"Maintainer\"\n  ][Maintainer %in% c(pdb_authors_net_edge$Maintainer, pdb_authors_net_edge$Authors),]\npdb_authors_net_vertex[order(vertex_cnt, decreasing = TRUE),]\n\n#&gt;                Maintainer vertex_cnt\n#&gt;                    &lt;char&gt;      &lt;int&gt;\n#&gt;   1:       Hadley Wickham         43\n#&gt;   2:         Gábor Csárdi         33\n#&gt;   3:          Jeroen Ooms         28\n#&gt;   4:    Scott Chamberlain         28\n#&gt;   5:            Yihui Xie         21\n#&gt;  ---                                \n#&gt; 579:    Katriona Goldmann          1\n#&gt; 580:        Carlo Pacioni          1\n#&gt; 581:       Michael Scholz          1\n#&gt; 582: Javier Roca-Pardinas          1\n#&gt; 583:         Xianying Tan          1\n\n\n这是一个有向图，其各个字段含义如下。\n\nMaintainer 维护者（代表流 to）\nAuthors 贡献者（代表源 from）\n\nedge_cnt 边的大小表示维护者 Maintainer 和贡献者 Authors 的协作次数\n\nvertex_cnt 顶点大小表示维护者 Maintainer 维护的 R 包数量\n\n下面先考虑用 igraph 包可视化这个复杂的有向带权网络。pdb_authors_net_edge 和 pdb_authors_net_vertex 都是数据框，首先调用 igraph 包的函数 graph_from_data_frame() 将其转化为网络类型 igraph ，然后使用函数 plot() 绘制网络图。\n\n代码# 构造图\nlibrary(igraph)\npdb_authors_graph &lt;- graph_from_data_frame(d = pdb_authors_net_edge, vertices = pdb_authors_net_vertex, directed = TRUE)\n# 可视化\nop &lt;- par(mar = rep(0, 4))\nplot(pdb_authors_graph,\n  edge.width = (E(pdb_authors_graph)$edge_cnt) / 2,\n  edge.arrow.size = .01,\n  edge.curved = .1,\n  layout = layout.kamada.kawai,\n  vertex.size = (V(pdb_authors_graph)$vertex_cnt) / 8,\n  vertex.label.cex = sqrt(V(pdb_authors_graph)$vertex_cnt) / 8\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 23.6: 开发者的协作关系网络\n\n\n\n\n协作关系弱的开发者占大部分，构成一个「月亮」的造型，其中，不乏维护多个 R 包的开发者，这些人要么单干，要么在专业小领域、小组织内协作。与之相对应的是协作关系较强的开发者，人数虽少，影响力却大，构成一个「太阳」的造型。协作得多往往意味着维护的 R 包也不少，甚至同属于一个组织，因此，高产的开发者、影响力大的组织聚集在一起，如 R Core Team、RStudio、rOpenSci 等。\n\neb &lt;- cluster_edge_betweenness(pdb_authors_graph)\neb\n\n#&gt; IGRAPH clustering edge betweenness, groups: 181, mod: 0.88\n#&gt; + groups:\n#&gt;   $`1`\n#&gt;   [1] \"Matt Nunes\"           \"Daniel Grose\"         \"Guy Nason\"           \n#&gt;   [4] \"Rebecca Killick\"      \"Idris Eckley\"         \"Alessandro Cardinali\"\n#&gt;   \n#&gt;   $`2`\n#&gt;   [1] \"Jin Zhu\"    \"Shiyun Lin\"\n#&gt;   \n#&gt;   $`3`\n#&gt;    [1] \"Julio Trecenti\"       \"Henrik Bengtsson\"     \"Morgane Pierre-Jean\" \n#&gt;    [4] \"Zhian N. Kamvar\"      \"Pierre Neuvial\"       \"Michal Bojanowski\"   \n#&gt;   + ... omitted several groups/vertices\n\n\nigraph 包提供多种社区探测的算法，上面简单使用函数 cluster_edge_betweenness() 来探测，结果显示有 181 个社区。社区 1 包含的成员如下：\n\neb$names[eb$membership == 1]\n\n#&gt; [1] \"Matt Nunes\"           \"Daniel Grose\"         \"Guy Nason\"           \n#&gt; [4] \"Rebecca Killick\"      \"Idris Eckley\"         \"Alessandro Cardinali\"\n\n\n社区 3、14、21、34、46、52、75 的成员是比较多的。其中，社区 3 是以 RStudio 为核心的大社区，社区 14 是以 CRAN 为核心的大社区。\n\n# RStudio 为核心的大社区\neb$names[eb$membership == 3]\n\n#&gt;  [1] \"Julio Trecenti\"       \"Henrik Bengtsson\"     \"Morgane Pierre-Jean\" \n#&gt;  [4] \"Zhian N. Kamvar\"      \"Pierre Neuvial\"       \"Michal Bojanowski\"   \n#&gt;  [7] \"Ian Lyttle\"           \"Thomas Lin Pedersen\"  \"Yihui Xie\"           \n#&gt; [10] \"Dirk Schumacher\"      \"Jeroen Ooms\"          \"Gábor Csárdi\"        \n#&gt; [13] \"Sean Kross\"           \"Carl Boettiger\"       \"Neal Richardson\"     \n#&gt; [16] \"Ryan Hafen\"           \"Matthew Fidler\"       \"Hadley Wickham\"      \n#&gt; [19] \"Mark Edmondson\"       \"Kirill Müller\"        \"Richard Iannone\"     \n#&gt; [22] \"Carson Sievert\"       \"Winston Chang\"        \"Lionel Henry\"        \n#&gt; [25] \"Jennifer Bryan\"       \"Michael Sumner\"       \"Scott Chamberlain\"   \n#&gt; [28] \"Garrick Aden-Buie\"    \"Daniel Falbel\"        \"Matthew B. Jones\"    \n#&gt; [31] \"Hiroaki Yutani\"       \"Taiyun Wei\"           \"Jim Hester\"          \n#&gt; [34] \"Romain François\"      \"Greg Freedman Ellis\"  \"Rhian Davies\"        \n#&gt; [37] \"Bryce Mecum\"          \"Steph Locke\"          \"Christophe Dervieux\" \n#&gt; [40] \"Jonathan Keane\"       \"Thibaut Jombart\"      \"Dewey Dunnington\"    \n#&gt; [43] \"Anne Cori\"            \"Bill Denney\"          \"Jared Huling\"        \n#&gt; [46] \"Wush Wu\"              \"Atsushi Yasumoto\"     \"Barret Schloerke\"    \n#&gt; [49] \"Yuan Tang\"            \"Duncan Garmonsway\"    \"Edzer Pebesma\"       \n#&gt; [52] \"Sebastian Meyer\"      \"Derek Burk\"           \"Tim Taylor\"          \n#&gt; [55] \"Alicia Schep\"         \"Tomasz Kalinowski\"    \"Michael Rustler\"     \n#&gt; [58] \"Joe Cheng\"            \"Bhaskar Karambelkar\"  \"Sebastian Kreutzer\"  \n#&gt; [61] \"JJ Allaire\"           \"JooYoung Seo\"         \"Zachary Foster\"      \n#&gt; [64] \"Malcolm Barrett\"      \"Aaron Wolen\"          \"Bruno Tremblay\"      \n#&gt; [67] \"Justin Wilkins\"       \"Yixuan Qiu\"           \"Johannes Friedrich\"  \n#&gt; [70] \"Kevin Ushey\"          \"Steven M. Mortimer\"   \"Karthik Ram\"         \n#&gt; [73] \"Jorrit Poelen\"        \"Maëlle Salmon\"        \"Aron Atkins\"         \n#&gt; [76] \"Ramnath Vaidyanathan\" \"Thomas Leeper\"        \"Dirk Eddelbuettel\"   \n#&gt; [79] \"Xianying Tan\"\n\n# CRAN 为核心的大社区\neb$names[eb$membership == 14]\n\n#&gt;  [1] \"Achim Zeileis\"        \"Michael Hahsler\"      \"Michel Lang\"         \n#&gt;  [4] \"Nikolaus Umlauf\"      \"Vincent Dorie\"        \"Bettina Gruen\"       \n#&gt;  [7] \"Bernd Bischl\"         \"Ben Bolker\"           \"Marc Becker\"         \n#&gt; [10] \"Friedrich Leisch\"     \"Brian Ripley\"         \"Michael Friendly\"    \n#&gt; [13] \"John Fox\"             \"Kurt Hornik\"          \"Patrick Schratz\"     \n#&gt; [16] \"Volodymyr Melnykov\"   \"Martin Maechler\"      \"George Ostrouchov\"   \n#&gt; [19] \"Drew Schmidt\"         \"Georgi N. Boshnakov\"  \"Wei-Chen Chen\"       \n#&gt; [22] \"Stefan Theussl\"       \"David Meyer\"          \"Jakob Bossek\"        \n#&gt; [25] \"Francois Michonneau\"  \"Marius Hofert\"        \"Florian Schwendinger\"\n#&gt; [28] \"Felix Zimmer\"         \"Martin Binder\"        \"Phil Chalmers\"       \n#&gt; [31] \"Lukas Sablica\"        \"Sebastian Fischer\"    \"Lennart Schneider\"   \n#&gt; [34] \"Jakob Richter\"        \"Florian Wickelmaier\"  \"Rudolf Debelak\"      \n#&gt; [37] \"Duncan Murdoch\"       \"Alexander Brenning\"   \"Ingo Feinerer\"\n\n\n同时，在 RStudio 这个大社区下，有一些与之紧密相关的小社区，比如 Rob Hyndman 等人的时间序列社区、Roger Bivand 等人的空间统计社区。\n\n# 时间序列 Rob Hyndman\neb$names[eb$membership == 52]\n\n#&gt;  [1] \"Asael Alonzo Matamoros\"   \"Nicholas Tierney\"        \n#&gt;  [3] \"Sevvandi Kandanaarachchi\" \"Rob Hyndman\"             \n#&gt;  [5] \"Di Cook\"                  \"Mitchell O'Hara-Wild\"    \n#&gt;  [7] \"Han Lin Shang\"            \"Sayani Gupta\"            \n#&gt;  [9] \"Earo Wang\"                \"Christoph Bergmeir\"\n\n# 空间统计 Roger Bivand\neb$names[eb$membership == 75]\n\n#&gt; [1] \"Sebastian Jeworutzki\" \"Roger Bivand\"         \"Colin Rundel\"        \n#&gt; [4] \"Angela Li\"            \"Gianfranco Piras\"     \"Patrick Giraudoux\"   \n#&gt; [7] \"Giovanni Millo\"\n\n\n结合前面的 图 23.6 ，知道有很多小圈圈，这些放一边，重点关注那些大的圈圈，见下图。\n\n代码op &lt;- par(mar = rep(0, 4))\nplot(eb, pdb_authors_graph,\n  edge.width = (E(pdb_authors_graph)$edge_cnt) / 4,\n  edge.arrow.size = .01,\n  edge.curved = .1,\n  layout = layout.kamada.kawai,\n  vertex.size = (V(pdb_authors_graph)$vertex_cnt) / 8,\n  vertex.label.cex = sqrt(V(pdb_authors_graph)$vertex_cnt) / 8\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 23.7: 探测协作关系网络中的社区\n\n\n\n\n下面使用 tidygraph 包构造图数据、计算节点中心度，dplyr 包操作数据。中心度代表节点（开发者）的影响力（或者重要性）。最后，借助 ggraph 包绘制维护者之间的贡献网络，节点的大小代表维护者影响力的强弱。\n\n代码pdb_authors_g &lt;- tidygraph::as_tbl_graph(pdb_authors_net_edge, directed = T) |&gt; \n dplyr::mutate(Popularity = tidygraph::centrality_degree(mode = 'in'))\nlibrary(ggraph)\nggraph(pdb_authors_g, layout = \"kk\") +\n  geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) +\n  geom_node_point(aes(size = Popularity), alpha = 0.5) +\n  theme_graph(base_family = \"sans\")\n\n\n\n\n\n\n图 23.8: 开发者的影响力网络\n\n\n\n\n前面两个网络图基于同一份数据、同样的网络布局算法，得到非常类似的结果。静态图上的标签相互重叠，影响细节的观察和探索，比如连接 CRAN 和 RStudio 两大阵营的通道。下面使用 visNetwork 包制作交互式网络图形，它是 JS 库 vis-network 的 R 语言接口， 使用 visNetwork 包绘制交互式网络图后，可以在图上使用鼠标放大、拖拽。可以发现在 CRAN 社区的 Achim Zeileis 和 RStudio 社区的 Max Kuhn 之间是由 Andri Signorell 牵线搭桥。此外，读者若有兴趣，可以使用 Richard Iannone 开发的 DiagrammeR 包制作静态的矢量网页图形。\n\n代码library(visNetwork)\n# 将 igraph 对象转为 visNetwork 包可用的数据\ndat &lt;- toVisNetworkData(pdb_authors_graph)\nnodes_df &lt;- dat$nodes\nnodes_df$value &lt;- nodes_df$vertex_cnt\nedges_df &lt;- dat$edges\nedges_df$value &lt;- edges_df$edge_cnt\n# 输入节点和边的数据\nvisNetwork(nodes = nodes_df, edges = edges_df, height = \"600px\") |&gt; \n  visIgraphLayout(randomSeed = 20232023, layout = \"layout.kamada.kawai\")\n\n\n\n\n\n\n图 23.9: 开发者的影响力网络（visNetwork）",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#扩展阅读",
    "href": "analyze-network-data.html#扩展阅读",
    "title": "23  网络数据分析",
    "section": "\n23.4 扩展阅读",
    "text": "23.4 扩展阅读\nR 语言网络分析方面的著作有 Erick Kolaczyk 的书籍《Statistical Analysis of Network Data with R》(Kolaczyk 和 Csárdi 2020)，网络可视化方面，推荐 Hadley Wickham 的著作《ggplot2: Elegant Graphics for Data Analysis》(Wickham, Navarro, 和 Pedersen 2024) 的第七章，Sam Tyner 等人的文章《Network Visualization with ggplot2》(Tyner, Briatte, 和 Hofmann 2017) 也值得一看。\n在网络数据分析方面， igraph 是非常流行的分析框架 ，它是由 C 语言写成的，非常高效。同时，它提供多种语言的接口，其 R 语言接口 igraph 包在 R 语言社区也是网络数据分析的事实标准，被很多其它做网络分析的 R 包所引用。开源的 Gephi 软件适合处理中等规模的网络分析和可视化。大规模图计算可以用 Apache Spark 的 GraphX。R 语言这层，主要还是对应数据分析和数据产品，用在内部咨询和商业分析上。\n企业级的图存储和计算框架，比较有名的是 Neo4j ，它有开源版本和商业版本。Nebula Graph 开源分布式图数据库，具有高扩展性和高可用性，支持千亿节点、万亿条边、毫秒级查询，有中文文档，有企业应用案例（美团图数据库平台建设及业务实践）。阿里研发的 GraphScope 提供一站式大规模图计算系统，支持图神经网络计算。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-network-data.html#sec-analysis-network-data-exercise",
    "href": "analyze-network-data.html#sec-analysis-network-data-exercise",
    "title": "23  网络数据分析",
    "section": "\n23.5 习题",
    "text": "23.5 习题\n\n类似开发者协作关系的分析，可以统计 R 包被多少 R 包依赖，依赖数量的分布。统计 R 包被依赖的深度（若 R 包 A 被 R 包 B 依赖，R 包 B 被 R 包 C 依赖，以此类推）。进而，构建、分析、可视化依赖关系网络，分析 R 包的影响力。\n本文基于 2022 年 12 月 31 日的 R 包元数据进行分析，请与 2023 年 12 月 31 日的数据比较。\n\n\n\n\n\nBates, Douglas, 和 Dirk Eddelbuettel. 2013. 《Fast and Elegant Numerical Linear Algebra Using the RcppEigen Package》. Journal of Statistical Software 52 (5): 1–24. https://doi.org/10.18637/jss.v052.i05.\n\n\nBiecek, Przemyslaw. 2023. DrWhy: Explain, Explore and Debug Predictive Machine Learning Models. https://github.com/ModelOriented/DrWhy.\n\n\nKolaczyk, Eric D., 和 Gábor Csárdi. 2020. Statistical Analysis of Network Data with R. 2nd 本. Springer, New York, NY. https://doi.org/10.1007/978-3-030-44129-6.\n\n\nKuhn, Max, 和 Hadley Wickham. 2020. Tidymodels: a collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org.\n\n\nLang, Michel, 和 Patrick Schratz. 2023. mlr3verse: Easily Install and Load the mlr3 Package Family. https://CRAN.R-project.org/package=mlr3verse.\n\n\nLüdecke, Daniel. 2019. strengejacke: Load Packages Associated with Strenge Jacke! https://github.com/strengejacke/strengejacke.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Brenton M. Wiernik, Etienne Bacher, Rémi Thériault, 和 Dominique Makowski. 2022. 《easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting》. CRAN. https://easystats.github.io/easystats/.\n\n\nTyner, Sam, François Briatte, 和 Heike Hofmann. 2017. 《Network Visualization with ggplot2》. The R Journal 9 (1): 27–59. https://doi.org/10.32614/RJ-2017-023.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, 等. 2019. 《Welcome to the tidyverse》. Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Danielle Navarro, 和 Thomas Lin Pedersen. 2024. ggplot2: Elegant Graphics for Data Analysis. 3rd 本. Springer-Verlag New York. https://ggplot2-book.org/.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>网络数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html",
    "href": "analyze-text-data.html",
    "title": "24  文本数据分析",
    "section": "",
    "text": "24.1 数据获取\n下载益辉的日志数据\n经过整理后，打包成 Rdata 数据供 R 软件使用。\n# 加载益辉的日志数据\nload(file = \"data/text/yihui.Rdata\")",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#数据获取",
    "href": "analyze-text-data.html#数据获取",
    "title": "24  文本数据分析",
    "section": "",
    "text": "总体规模：益辉每年的日志数量、日志平均字数，益辉发布书籍的年份\n过程细节：发布时间、日志字数的日历图、日志年度主题\n\n\ngit clone git@github.com:yihui/yihui.org.git",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-cn-blog",
    "href": "analyze-text-data.html#sec-cn-blog",
    "title": "24  文本数据分析",
    "section": "\n24.2 日志概况",
    "text": "24.2 日志概况\n\n代码library(ggplot2)\nlibrary(ggrepel)\nggplot() +\n  geom_label_repel(\n    data = df2, aes(x = year, y = file_name, label = event_wrap),\n    max.overlaps = 150, segment.colour = \"gray\", seed = 2023\n  ) +\n  geom_point(data = df1, aes(x = file_year, y = file_name)) +\n  geom_line(data = df1, aes(x = file_year, y = file_name)) +\n  scale_x_continuous(n.breaks = 15) +\n  theme_bw() +\n  labs(x = \"年份\", y = \"篇数\")\n\n\n\n\n\n\n图 24.1: 益辉每年发布的日志数量\n\n\n\n\n2006 年获得中国人民大学学士学位，2009 和 2013 年分别获得中国人民大学硕士和爱荷华州立大学博士学位，在校期间，日志数量持续增加，又陆续创立统计之都，举办中国 R 语言大会。在毕业那年需要完成毕业论文，因此，日志数量明显减少。2013 -2016 年，每年都有书籍出版，期间，有博士毕业、找工作、安家等重要事情，因此，日志数量持续处于低位。稳定后，2017-2018 年除了正常出两本书以外，写了大量的日志，迎来第二个高峰，2018 年，中英文日志数量超过 300 篇。2019-2020 年集中精力在写一本食谱。2021 年第一本中文书《现代统计图形》在10年后出版，这主要是 2007-2011 年的工作。2021-2023 年日志数量（2023年中文日志未发布）处于较低水平。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-text-clean",
    "href": "analyze-text-data.html#sec-text-clean",
    "title": "24  文本数据分析",
    "section": "\n24.3 数据清洗",
    "text": "24.3 数据清洗\n以 2001 年的一篇日志为例，展开数据清洗的过程。移除文章的 YAML 元数据，对于文本分析来说，主要是没啥信息含量。\n\nremove_yaml &lt;- function(x) {\n  x[(max(which(x == \"---\")) + 1):length(x)]\n}\nx &lt;- remove_yaml(x)\n\n移除「我」 「是」 「你」 「的」 「了」 「也」 等高频的人称、助词、虚词。这些词出现的规律对表现个人风格很重要，且看红楼梦关于后40回作者归属的研究，通过比较一些助词、虚词的出现规律，从而看出作者的习惯、文风。这种东西是在长期的潜移默化中形成的，对作者自己来说，都可能是无意识的。\n\nlibrary(jiebaR)\n# jieba_seg &lt;- worker(stop_word = \"data/text/stop_word.txt\")\njieba_seg &lt;- worker(stop_word = \"data/text/cn_stopwords.txt\")\n\n添加新词，比如「歪贼」、「谢益辉」等，主要是人名、外号等实体。\n\nnew_words &lt;- readLines(file(\"data/text/new_word.txt\"))\nnew_user_word(worker = jieba_seg, words = new_words)\n\n#&gt; [1] TRUE\n\n# 分词\nx_seg &lt;- segment(x, jieba_seg)\n\n分词后，再移除数字和英文\n\nremove_number_english &lt;- function(x) {\n  x &lt;- x[!grepl(\"\\\\d{1,}\", x)]\n  x[!grepl(\"[a-zA-Z]\", x)]\n}\nxx &lt;- remove_number_english(x = x_seg)\n\n词频统计\n\ntmp &lt;- freq(x = xx)\ntmp &lt;- tmp[order(tmp$freq, decreasing = T), ]\nhead(tmp)\n\n#&gt;       char freq\n#&gt; 166   一个    7\n#&gt; 238   同学    5\n#&gt; 187   没有    4\n#&gt; 195   一篇    4\n#&gt; 20    鼻音    3\n#&gt; 69  田春雨    3\n\n\nggwordcloud 包绘制词云图可视化词频统计的结果。\n\nlibrary(ggwordcloud)\nhead(tmp, 150) |&gt;\n  ggplot(aes(label = char, size = freq)) +\n  geom_text_wordcloud(seed = 2022, grid_size = 8, max_grid_size = 24) +\n  scale_size_area(max_size = 10)\n\n\n\n\n\n\n图 24.2: 词云可视化词频结果\n\n\n\n\n计算 TF-IDF 值\n\n# tmp = get_idf(x = list(xx))\nget_idf(x = list(xx)) |&gt; head()\n\n#&gt;     name count\n#&gt; 1   杨迪     0\n#&gt; 2   邹瑜     0\n#&gt; 3 蒋前程     0\n#&gt; 4 朱菁菁     0\n#&gt; 5   杨刚     0\n#&gt; 6   邓璋     0",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-topic-models",
    "href": "analyze-text-data.html#sec-topic-models",
    "title": "24  文本数据分析",
    "section": "\n24.4 主题的探索",
    "text": "24.4 主题的探索\n益辉的日志是没有分类和标签的，所以，先聚类，接着逐个分析每个类代表的实际含义。然后，将聚类的结果作为结果标签，再应用多分类回归模型，最后联合聚类、分类模型，从无监督转化到有监督模型。\ntopicmodels (Grün 和 Hornik 2011) 基于 tm (Feinerer, Hornik, 和 Meyer 2008) 支持潜在狄利克雷分配（Latent Dirichlet Allocation，简称 LDA） 和 Correlated Topics Models (CTM) 文本主题建模，这一套工具比较适合英文文本分词、向量化和建模。text2vec 包支持多个统计模型，如LDA 、LSA 、GloVe 等，文本向量化后，结合统计学习模型，可用于分类、回归、聚类等任务，更多详情见 https://text2vec.org。\n接下来使用 David M. Blei 等提出 LDA 算法做主题建模，详情见 LDA 算法原始论文。\n\nlibrary(text2vec)\n\n首先将所有日志分词、向量化，构建文档-词矩阵 document-term matrix (DTM)\n\n# 移除链接\nremove_links &lt;- function(x) {\n  gsub(pattern = \"(&lt;http.*?&gt;)|(\\\\(http.*?\\\\))|(&lt;www.*?&gt;)|(\\\\(www.*?&gt;\\\\))\", replacement = \"\", x)\n}\n# 清理、分词、清理\nfile_list1 &lt;- lapply(file_list, remove_yaml)\nfile_list1 &lt;- lapply(file_list1, remove_links)\nfile_list1 &lt;- lapply(file_list1, segment, jiebar = jieba_seg)\nfile_list1 &lt;- lapply(file_list1, remove_number_english)\n\n去掉没啥实际意义的词（比如单个字），极高频词和极低频词。\n\n# Token 化\nit &lt;- itoken(file_list1, ids = 1:length(file_list1), progressbar = FALSE)\nv &lt;- create_vocabulary(it)\n# 去掉单个字 减少 3K\nv &lt;- v[nchar(v$term) &gt; 1,]\n# 去掉极高频词和极低频词 减少 1.4W\nv &lt;- prune_vocabulary(v, term_count_min = 10, doc_proportion_max = 0.2)\n\n采用 LDA（Latent Dirichlet Allocation）算法建模\n\n# 词向量化\nvectorizer &lt;- vocab_vectorizer(v)\n# 文档-词矩阵 DTM\ndtm &lt;- create_dtm(it, vectorizer, type = \"dgTMatrix\")\n#  10 个主题\nlda_model &lt;- LDA$new(n_topics = 9, doc_topic_prior = 0.1, topic_word_prior = 0.01)\n# 训练模型\ndoc_topic_distr &lt;- lda_model$fit_transform(\n    x = dtm, n_iter = 1000, convergence_tol = 0.001, \n    n_check_convergence = 25, progressbar = FALSE\n  )\n\n#&gt; INFO  [04:36:59.970] early stopping at 175 iteration\n#&gt; INFO  [04:37:00.448] early stopping at 50 iteration\n\n\n下图展示主题的分布，各个主题及其所占比例。\n\nbarplot(\n  doc_topic_distr[1, ], xlab = \"主题\", ylab = \"比例\", \n  ylim = c(0, 1), names.arg = 1:ncol(doc_topic_distr)\n)\n\n\n\n\n\n\n图 24.3: 主题分布\n\n\n\n\n将 9 个主题的 Top 12 词分别打印出来。\n\nlda_model$get_top_words(n = 12, topic_number = 1L:9L, lambda = 0.3)\n\n#&gt;       [,1]   [,2]   [,3]   [,4]     [,5]   [,6]   [,7]   [,8]   [,9]    \n#&gt;  [1,] \"例子\" \"一首\" \"社会\" \"统计\"   \"代码\" \"记得\" \"吱吱\" \"时代\" \"网站\"  \n#&gt;  [2,] \"翻译\" \"歌词\" \"观点\" \"会议\"   \"函数\" \"不知\" \"照片\" \"意义\" \"数据\"  \n#&gt;  [3,] \"字符\" \"手机\" \"痛苦\" \"模型\"   \"文档\" \"同学\" \"好吃\" \"媒体\" \"图形\"  \n#&gt;  [4,] \"特征\" \"这首\" \"教育\" \"论文\"   \"文件\" \"阿姨\" \"我家\" \"文化\" \"域名\"  \n#&gt;  [5,] \"作品\" \"首歌\" \"人类\" \"老师\"   \"变量\" \"居然\" \"家里\" \"现实\" \"软件\"  \n#&gt;  [6,] \"中文\" \"遗憾\" \"追求\" \"分布\"   \"字体\" \"看见\" \"味道\" \"社交\" \"服务器\"\n#&gt;  [7,] \"排版\" \"艺术\" \"思考\" \"小子\"   \"元素\" \"学校\" \"厨房\" \"社区\" \"邮件\"  \n#&gt;  [8,] \"意思\" \"小说\" \"强烈\" \"统计学\" \"语法\" \"路上\" \"在家\" \"眼中\" \"提供\"  \n#&gt;  [9,] \"风格\" \"生活\" \"成功\" \"参加\"   \"编译\" \"听说\" \"黄瓜\" \"避免\" \"编辑\"  \n#&gt; [10,] \"主题\" \"诗词\" \"接受\" \"报告\"   \"图片\" \"印象\" \"包子\" \"造成\" \"系统\"  \n#&gt; [11,] \"伟大\" \"鸡蛋\" \"工作\" \"检验\"   \"参数\" \"当时\" \"叶子\" \"事实\" \"浏览器\"\n#&gt; [12,] \"表示\" \"人间\" \"努力\" \"学生\"   \"生成\" \"名字\" \"辣椒\" \"政治\" \"注册\"\n\n\n结果有点意思，说明益辉喜欢读书写作（主题 1、3、8）、诗词歌赋（主题 2）、统计图形（主题 4）、代码编程（主题 5）、回忆青春（主题 6）、做菜吃饭（7）、倒腾网站（主题 9）。\n\n\n\n\n\n\n注释\n\n\n\n提示：参考论文 (Zhang, Li, 和 Zhang 2023) 根据 perplexities 做交叉验证选择最合适的主题数量。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-similarity",
    "href": "analyze-text-data.html#sec-similarity",
    "title": "24  文本数据分析",
    "section": "\n24.5 相似性度量",
    "text": "24.5 相似性度量\n我与益辉日志的相似性度量",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-text-data.html#sec-analysis-text-data-exercises",
    "href": "analyze-text-data.html#sec-analysis-text-data-exercises",
    "title": "24  文本数据分析",
    "section": "\n24.6 习题",
    "text": "24.6 习题\n\ntext2vec 包内置的电影评论数据集 movie_review 中 sentiment（表示正面或负面评价）列作为响应变量，构建二分类模型，对用户的一段评论分类。（提示：词向量化后，采用 glmnet 包做交叉验证调整参数、模型）\n根据 CRAN 上发布的 R 包元数据分析 R 包的描述字段，实现 R 包主题分类。\n接习题 2，根据任务视图对 R 包的标记，建立有监督的多分类模型，评估模型的分类效果，并对尚未标记的 R 包分类。（提示：一个 R 包可能同时属于多个任务视图，考虑使用 xgboost 包）\n\n\n\n\n\nFeinerer, Ingo, Kurt Hornik, 和 David Meyer. 2008. 《Text Mining Infrastructure in R》. Journal of Statistical Software 25 (5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nGrün, Bettina, 和 Kurt Hornik. 2011. 《topicmodels: An R Package for Fitting Topic Models》. Journal of Statistical Software 40 (13): 1–30. https://doi.org/10.18637/jss.v040.i13.\n\n\nHvitfeldt, Emil, 和 Julia Silge. 2021. Supervised Machine Learning for Text Analysis in R. New York: Chapman; Hall/CRC. https://smltar.com/.\n\n\nSilge, Julia, 和 David Robinson. 2017. Text Mining with R. New York: O’Reilly Media, Inc. https://www.tidytextmining.com/.\n\n\nZhang, Lijin, Xueyang Li, 和 Zhiyong Zhang. 2023. 《Variety and Mainstays of the R Developer Community》. The R Journal 15: 5–25. https://doi.org/10.32614/RJ-2023-060.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>文本数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html",
    "href": "analyze-time-series-data.html",
    "title": "25  时序数据分析",
    "section": "",
    "text": "25.1 数据获取\nJoshua M. Ulrich 开发维护的 quantmod 包可以下载国内外股票市场的数据。本节主要以美团股价数据为例，美团自 2018-09-20 在香港挂牌上市，股票代码 3690.HK。首先用 quantmod 包 (Ryan 和 Ulrich 2022) 获取美团上市至 2023-11-24 每天的股价数据，包含 Open 开盘价、High 最高价、Low 最低价、Close 闭市价、Adjusted 调整价和 Volume 成交量数据。\nlibrary(quantmod)\n# 美团股票代码 3690\nmeituan &lt;- getSymbols(\"3690.HK\", auto.assign = FALSE, src = \"yahoo\")\n先来看数据的类型，数据类型颇为复杂，是由 xts 和 zoo 两种类型复合而成，xts 类型是继承自 zoo 类型的。\nclass(meituan)\n\n[1] \"xts\" \"zoo\"\n\nstr(meituan)\n\nAn xts object on 2018-09-20 / 2023-11-24 containing: \n  Data:    double [1275, 6]\n  Columns: 3690.HK.Open, 3690.HK.High, 3690.HK.Low, 3690.HK.Close, 3690.HK.Volume ... with 1 more column\n  Index:   Date [1275] (TZ: \"UTC\")\n  xts Attributes:\n    $ src    : chr \"yahoo\"\n    $ updated: POSIXct[1:1], format: \"2023-11-27 06:31:12\"\n数据集 meituan 是一个 xts 类型的时间序列数据对象，时间范围是 2018-09-20 至 2023-11-24，包含 4 个成分，分别如下\n与时间序列数据相关的数据类型有很多，比如 Base R 提供的 Date 和 POSIX 等，扩展包 timeDate 和 chron 也都有自己的一套数据类型及处理方法。xts 包是处理时间序列数据的主要工具之一，xts 是 eXtensible Time Series 的缩写。为了进一步了解用法，下面举个例子，使用该 R 包的函数 xts() 构造时间序列对象。\nlibrary(zoo)\nlibrary(xts)\n# 数据矩阵\nx &lt;- matrix(1:4, ncol = 2, nrow = 2)\n# 日期索引\nidx &lt;- as.Date(c(\"2018-01-01\", \"2019-12-12\"))\n# xts = matrix + index\nxts(x, order.by = idx)\n\n           [,1] [,2]\n2018-01-01    1    3\n2019-12-12    2    4",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#数据获取",
    "href": "analyze-time-series-data.html#数据获取",
    "title": "25  时序数据分析",
    "section": "",
    "text": "Data 部分显示为 906 行 6 列的双精度浮点存储的数值。\nColumns 部分显示列名，依次是 3690.HK.Open、3690.HK.High、 3690.HK.Low 和 3690.HK.Close 等，当列数很多时，显示时会省略。\nIndex 部分表示索引列，有序是时间序列数据的本质特点。示例中索引存储数据点产生的先后顺序，索引是用日期来表示的，日期所在的时区是 “UTC”。\nxts 部分是数据类型的一些属性（元数据），说明数据集的来源，什么时候制作的数据。示例中数据是从雅虎财经下载的，下载时间是 2023-11-27 14:31:12。\n\n\nxts(x = NULL,\n    order.by = index(x),\n    frequency = NULL,\n    unique = TRUE,\n    tzone = Sys.getenv(\"TZ\"),\n    ...)\n\n参数 x 表示数据。\n参数 order.by 表示索引数据。\n参数 frequency 表示频率。\n参数 unique 表示唯一。\n参数 tzone 表示时区。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#数据探索",
    "href": "analyze-time-series-data.html#数据探索",
    "title": "25  时序数据分析",
    "section": "\n25.2 数据探索",
    "text": "25.2 数据探索\n\n25.2.1 zoo\nzoo 包提供 S3 范型函数 autoplot.zoo() 专门可视化 zoo 类型的数据，它接受一个 zoo 类型的数据对象，返回一个 ggplot2 数据对象，然后用户可以添加自定义的绘图设置，更多详情见帮助文档 ?autoplot.zoo() 。\n\n# xts 包需要先加载，否则 Index 不是日期类型而是数值类型\nlibrary(ggplot2)\nautoplot(meituan[, \"3690.HK.Adjusted\"]) +\n  theme_classic() +\n  labs(x = \"日期\", y = \"股价\")\n\n\n\n\n\n\n图 25.1: 美团在香港上市以来的股价走势\n\n\n\n\nzoo 包还提供另一个范型函数 fortify() 将 zoo 数据对象转化为 data.frame ，这可以方便使用 ggplot2 包来展示数据。参数 melt = TRUE 意味着重塑原数据集，将数据从宽格式转长格式。参数 names = c(Index = \"Date\") 表示将 Index 列重命名为 date 列。\n\nmeituan_df &lt;- fortify(\n  meituan[, c(\"3690.HK.Adjusted\", \"3690.HK.High\")],\n  melt = TRUE, names = c(Index = \"Date\")\n)\n\n数据集 meituan_df 中的 Series 列是因子型的，将其标签 3690.HK.Adjusted 、3690.HK.High 调整为调整价、最高价。根据日期字段 Date 提取年份字段 year 和一年中的第几天的字段 day_of_year。\n\nmeituan_df &lt;- within(meituan_df, {\n  # 调整 Series 的标签\n  Series &lt;- factor(Series, labels = c(\"调整价\", \"最高价\"))\n  # 日期字段 Date 获取年份\n  year &lt;- format(Date, \"%Y\")\n  # 日期字段 Date 一年中的第几天\n  day_of_year &lt;- as.integer(format(Date, \"%j\"))\n})\n\n调用 ggplot2 包绘制分面、分组时间序列图，以 day_of_year 为横轴，股价 Value 为纵轴，按 year 分组，按 Series 分面。\n\nggplot(data = meituan_df, aes(x = day_of_year, y = Value)) +\n  geom_line(aes(color = year)) +\n  facet_wrap(~Series, ncol = 1) + \n  theme_classic() +\n  labs(x = \"一年中的第几天\", y = \"调整的股价\", color = \"年份\")\n\n\n\n\n\n\n图 25.2: 美团调整的股价逐年走势\n\n\n\n\n2019 年底开始出现疫情，2020 年整年陆续有疫情，美团股价一路狂飙突进，因疫情，利好外卖业务，市场看好外卖业务。2021 年政府去杠杆，互联网监管趋严，又监又管，受外部大环境，逆全球化趋势影响，整年股价一路走低。进入 2022 年，股价在 200 附近徘徊。\n\n25.2.2 xts\n\nlibrary(xts)\n\nxts 包提供 S3 泛型函数 plot.xts() 专门用来可视化 xts 类型的时间序列数据\n\nplot(meituan[, \"3690.HK.Adjusted\"], main = \"调整的股价\")\n\n\n\n\n\n\n图 25.3: 美团在香港上市以来的股价走势\n\n\n\n\n还可以任意选择一个时间窗口，展示相关数据\n\nplot(meituan[, \"3690.HK.Adjusted\"],\n  subset = \"2022-01-01/2022-12-31\", main = \"调整的股价\"\n)\n\n\n\n\n\n\n图 25.4: 美团 2021 年的股价走势\n\n\n\n\n元旦节三天不开市，所以假期没有数据。\n\n25.2.3 ggfortify\nggfortify (Tang, Horikoshi, 和 Li 2016) 支持快速地可视化 ts、timeSeries 、stl 等多种类型的时序数据， ggplot2 做数据探索会有一些帮助。\n\nlibrary(ggfortify)\nautoplot(meituan[, \"3690.HK.Adjusted\"], ts.geom = \"line\") +\n  scale_x_date(\n    date_breaks = \"1 year\",\n    date_minor_breaks = \"6 months\",\n    date_labels = \"%b\\n%Y\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n图 25.5: 美团股价走势\n\n\n\n\n\n25.2.4 dygraphs\ndygraphs 包专门绘制交互式时间序列图形，它封装了时序数据可视化库 dygraphs ，更多情况见 https://dygraphs.com/。下面以美团股价为例，展示时间窗口筛选、坐标轴名称、刻度标签、注释、事件标注、缩放等功能。\n\nlibrary(dygraphs)\n# 缩放\ndyUnzoom &lt;- function(dygraph) {\n  dyPlugin(\n    dygraph = dygraph,\n    name = \"Unzoom\",\n    path = system.file(\"plugins/unzoom.js\", package = \"dygraphs\")\n  )\n}\n\n# 年月\ngetYearMonth &lt;- '\n  function(d) {\n    var monthNames = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\",\"07\", \"08\", \"09\", \"10\", \"11\", \"12\"];\n    date = new Date(d);\n    return date.getFullYear() + \"-\" + monthNames[date.getMonth()]; \n  }'\n\n# 绘图\ndygraph(meituan[, \"3690.HK.Adjusted\"], main = \"美团股价走势\") |&gt;\n  dyRangeSelector(dateWindow = c(\"2023-01-01\", \"2023-11-24\")) |&gt;\n  dyAxis(name = \"x\", axisLabelFormatter = getYearMonth) |&gt;\n  dyAxis(\"y\", valueRange = c(0, 500), label = \"美团股价\") |&gt;\n  dyEvent(\"2020-01-23\", \"武汉封城\", labelLoc = \"bottom\") |&gt;\n  dyShading(from = \"2020-01-23\", to = \"2020-04-08\", color = \"#FFE6E6\") |&gt;\n  dyAnnotation(\"2020-01-23\", text = \"武汉封城\", tooltip = \"武汉封城\", width = 60) |&gt;\n  dyAnnotation(\"2020-04-08\", text = \"武汉解封\", tooltip = \"武汉解封\", width = 60) |&gt;\n  dyHighlight(highlightSeriesOpts = list(strokeWidth = 2)) |&gt;\n  dySeries(label = \"调整股价\") |&gt;\n  dyLegend(show = \"follow\", hideOnMouseOut = FALSE) |&gt;\n  dyOptions(fillGraph = TRUE, drawGrid = FALSE, gridLineColor = \"lightblue\") |&gt;\n  dyUnzoom()\n\n\n\n\n\n\n图 25.6: 美团股价变化趋势\n\n\n\n上图默认展示 YTD 数据，在一个动态的时间窗口内显示数据，假如今天是 2023-07-15，则展示 2023-01-01 至 2023-07-15 的股价数据。在函数 dyRangeSelector() 中设定时间窗口参数 dateWindow，实现数据范围的筛选。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#平稳性诊断",
    "href": "analyze-time-series-data.html#平稳性诊断",
    "title": "25  时序数据分析",
    "section": "\n25.3 平稳性诊断",
    "text": "25.3 平稳性诊断\n\n25.3.1 自相关图\n\nautoplot(acf(AirPassengers, plot = FALSE)) +\n  theme_classic()\n\n\n\n\n\n\n图 25.7: 乘客数量自相关图\n\n\n\n\n\n25.3.2 偏自相关图\n\nautoplot(pacf(AirPassengers, plot = FALSE)) +\n  theme_classic()\n\n\n\n\n\n\n图 25.8: 乘客数量偏自相关图\n\n\n\n\n\n25.3.3 延迟算子\n\n# 原始序列\nAirPassengers\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\n# 延迟 1 期\nlag(AirPassengers, k = 1)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1948                                             112\n1949 118 132 129 121 135 148 148 136 119 104 118 115\n1950 126 141 135 125 149 170 170 158 133 114 140 145\n1951 150 178 163 172 178 199 199 184 162 146 166 171\n1952 180 193 181 183 218 230 242 209 191 172 194 196\n1953 196 236 235 229 243 264 272 237 211 180 201 204\n1954 188 235 227 234 264 302 293 259 229 203 229 242\n1955 233 267 269 270 315 364 347 312 274 237 278 284\n1956 277 317 313 318 374 413 405 355 306 271 306 315\n1957 301 356 348 355 422 465 467 404 347 305 336 340\n1958 318 362 348 363 435 491 505 404 359 310 337 360\n1959 342 406 396 420 472 548 559 463 407 362 405 417\n1960 391 419 461 472 535 622 606 508 461 390 432    \n\n\n\n25.3.4 差分算子\n函数 diff() 实现差分算子，默认参数 lag = 1 ，differences = 1 表示延迟期数为 1 的一阶差分。\n\n# 延迟 1 期 1 阶差分\ndiff(AirPassengers, lag = 1, differences = 1)\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n1949         6   14   -3   -8   14   13    0  -12  -17  -15   14\n1950   -3   11   15   -6  -10   24   21    0  -12  -25  -19   26\n1951    5    5   28  -15    9    6   21    0  -15  -22  -16   20\n1952    5    9   13  -12    2   35   12   12  -33  -18  -19   22\n1953    2    0   40   -1   -6   14   21    8  -35  -26  -31   21\n1954    3  -16   47   -8    7   30   38   -9  -34  -30  -26   26\n1955   13   -9   34    2    1   45   49  -17  -35  -38  -37   41\n1956    6   -7   40   -4    5   56   39   -8  -50  -49  -35   35\n1957    9  -14   55   -8    7   67   43    2  -63  -57  -42   31\n1958    4  -22   44  -14   15   72   56   14 -101  -45  -49   27\n1959   23  -18   64  -10   24   52   76   11  -96  -56  -45   43\n1960   12  -26   28   42   11   63   87  -16  -98  -47  -71   42\n\n\n\n25.3.5 单位根检验\n\n25.3.6 格兰杰因果检验\n1969 年 Clive Granger 提出格兰杰因果检验，R 语言中 lmtest 包的函数 grangertest() 可以检验序列中变量之间的时间落差的相关性。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-exponential-smoothing",
    "href": "analyze-time-series-data.html#sec-exponential-smoothing",
    "title": "25  时序数据分析",
    "section": "\n25.4 指数平滑模型",
    "text": "25.4 指数平滑模型\n\n25.4.1 指数平滑\n首先来回答何为指数平滑？用历史数据的线性组合预测下一个时期的值，线性组合的权重随距离变远而按指数衰减。不妨设观测序列数据为 \\(\\{x_i\\}\\) ，预测序列数据为 \\(\\{y_i\\}\\)，用数学公式表达，如下：\n\\[\ny_h(1) = wx_h + w^2x_{h-1} + \\cdots = \\sum_{j=1}^{\\infty} w^j x_{h+1-j}\n\\]\n其中，权重 \\(0 &lt; w &lt; 1\\) ，权重越小表示距离远的历史数据对当前预测的贡献越小。线性组合的权重之和等于 1，所以\n\\[\n\\sum_{j=1}^{\\infty} w^j = \\frac{w}{1-w}\n\\]\n则第 \\(j\\) 个权重应为\n\\[\n\\frac{w^j}{\\frac{w}{1-w}} = (1-w)w^{j-1},j=1,2,\\ldots\n\\]\n则根据历史的 \\(h\\) 期数据预测未来的 1 期数据 \\(y_h(1)\\) 如下：\n\\[\ny_h(1) = (1-w)(x_h + wx_{h-1} + w^2x_{h-2} + \\cdots) = (1-w)\\sum_{j=0}^{\\infty}w^j x_{h-j}\n\\]\n以上就是指数平滑（exponential smoothing），在早期应用中，权重 \\(w\\) 的选取主要依靠经验。适用于没有明显趋势性、季节性、周期性的时间序列数据。\n\n25.4.2 函数 filter()\n\n函数 filter() 实现一元时间序列的线性过滤，或者对多元时间序列的单个序列分别做线性变换，它只是根据既定的平滑模型变换数据，没有拟合数据。函数 filter() 实现递归过滤和卷积过滤两种数据变换方式，分别对应自回归和移动平均两种时间序列平滑模型。\n\n递归过滤（自回归）\n\n\\[\ny_{i} = x_{i} + f_1 y_{i-1} +\\cdots+ f_p y_{i-p}\n\\tag{25.1}\\]\n\n卷积过滤（移动平均）\n\n\\[\ny_{i} = f_1 x_{i+o} + \\cdots + f_p x_{i+o-(p-1)}\n\\tag{25.2}\\]\n其中，\\(p\\) 代表模型的阶数， \\(o\\) 代表漂移项，O 表示英文单词 offset 的首字母。下面举个具体的例子来说明函数 filter() 的作用，设输入序列 \\(\\{x_i\\}\\) 是从 1 至 10 的整数。首先考虑自回归的情况，代码如下：\n\nx &lt;- 1:10\n# 自回归\nfilter(x, filter = c(2 / 3, 1 / 6, 1 / 6), method = \"recursive\")\n\nTime Series:\nStart = 1 \nEnd = 10 \nFrequency = 1 \n [1]  1.000000  2.666667  4.944444  7.907407 11.540123 15.835391 20.798182\n [8] 26.428041 32.724289 39.687230\n\n\n参数 x 指定输入的时间序列 \\(\\{x_i\\}\\)，参数 method 指定平滑的方法，method = \"recursive\" 表示使用自回归方法，参数 filter 表示自回归的系数，系数向量的长度代表模型 方程式 25.1 中的 \\(p\\) ，filter = c(2 / 3, 1 / 6, 1 / 6) 对应的模型如下：\n\\[\n\\begin{aligned}\ny_1 &= x_1 \\\\\ny_2 &= x_2 + \\frac{2}{3} y_1 \\\\\ny_3 &= x_3 + \\frac{2}{3} y_2 + \\frac{1}{6} y_1 \\\\\ny_i &= x_i + \\frac{2}{3} y_{i-1} + \\frac{1}{6} y_{i - 2} + \\frac{1}{6} y_{i - 3}, \\quad i \\geq 4 \\\\\n\\end{aligned}\n\\]\n其中，序列 \\(\\{y_i\\}\\) 表示函数 filter() 的输出结果，由上述方程不难看出自回归模型的递归的特点。为了理解自回归和递归的过程，下面依次计算 \\(y_1\\) 至 \\(y_4\\) 。\n\n# y1\n1\n\n[1] 1\n\n# y2\n2 + 2/3 * 1\n\n[1] 2.666667\n\n# y3\n3 + 2/3 * (2 + 2/3 * 1) + 1/6 * 1\n\n[1] 4.944444\n\n# y4\n4 + 2/3 * (3 + 2/3 * (2 + 2/3 * 1) + 1/6 * 1) + 1/6 *(2 + 2/3 * 1) + 1/6 * 1\n\n[1] 7.907407\n\n\n接下来，考虑移动平均的情况，代码如下：\n\n# 移动平均\nfilter(x, filter = c(2 / 3, 1 / 6, 1 / 6), method = \"convolution\", sides = 1)\n\nTime Series:\nStart = 1 \nEnd = 10 \nFrequency = 1 \n [1]  NA  NA 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5\n\n\n参数 method = \"convolution\" 表示使用移动平均。参数 sides 仅适用于卷积过滤，sides = 1 表示系数都是作用于过去的值。为了对比自回归和移动平均，不妨设移动平均的系数同自回归的系数，则移动平均模型如下：\n\\[\n\\begin{aligned}\ny_1 &~~ \\text{不存在}\\\\\ny_2 &~~ \\text{不存在}\\\\\ny_3 &= \\frac{2}{3} x_{3} + \\frac{1}{6} x_2 + \\frac{1}{6} x_1\\\\\ny_i &= \\frac{2}{3} x_{i} + \\frac{1}{6} x_{i - 1} + \\frac{1}{6} x_{i - 2}, \\quad i \\geq 3\n\\end{aligned}\n\\]\n比照模型 方程式 25.2 ，漂移项参数 \\(o\\) 为 0，也就是没有漂移，移动平均作用于过去的 3 期数据，也就是 \\(p = 3\\) 。因输出序列 \\(\\{y_i\\}\\) 中 \\(y_1,y_2\\) 不存在，下面仅计算 \\(y_3,y_4\\) 。\n\n# y3\n2/3 * 3 + 1/6 * 2 + 1/6 * 1\n\n[1] 2.5\n\n# y4\n2/3 * 4 + 1/6 * 3 + 1/6 * 2\n\n[1] 3.5\n\n\nTTR 包提供许多移动平均的计算函数，比如 SMA() ，下面计算过去 3 个观察值的算术平均。\n\nlibrary(TTR)\nSMA(x, n = 3)\n\n [1] NA NA  2  3  4  5  6  7  8  9\n\n\n\n25.4.3 简单指数平滑\n当时间序列不含趋势和季节性成分的时候，可以用简单指数平滑模型来拟合和预测。简单指数平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= b_{t-1} \\\\\ns_{t} &= s_{t-p}\n\\end{aligned}\n\\]\n其中，周期 \\(p\\)\n\nair_passengers_exp &lt;- HoltWinters(AirPassengers, gamma = FALSE, beta = FALSE)\nair_passengers_exp\n\nHolt-Winters exponential smoothing without trend and without seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, beta = FALSE, gamma = FALSE)\n\nSmoothing parameters:\n alpha: 0.9999339\n beta : FALSE\n gamma: FALSE\n\nCoefficients:\n      [,1]\na 431.9972\n\n\n预测的残差平方和 SSE sum-of-squared-errors\n\nair_passengers_exp$SSE\n\n[1] 162510.6\n\n\n\n# plot(air_passengers_exp)\nautoplot(air_passengers_exp) +\n  theme_classic()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 25.9: 简单指数平滑模型\n\n\n\n\n向前预测 5 期\n\nair_passengers_pred &lt;- predict(air_passengers_exp, n.ahead = 10, prediction.interval = TRUE)\n\n预测值及其预测区间\n\nplot(air_passengers_exp, air_passengers_pred)\n\n\n\n\n\n\n图 25.10: 简单指数平滑模型预测\n\n\n\n\n\n25.4.4 Holt 指数平滑\n当时间序列不含季节性成分，可以用 Holt 指数平滑模型拟合和预测 (Holt 2004) 。\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= s_{t-p}\n\\end{aligned}\n\\]\n\nair_passengers_holt &lt;- HoltWinters(AirPassengers, gamma = FALSE)\nair_passengers_holt\n\nHolt-Winters exponential smoothing with trend and without seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, gamma = FALSE)\n\nSmoothing parameters:\n alpha: 1\n beta : 0.003218516\n gamma: FALSE\n\nCoefficients:\n        [,1]\na 432.000000\nb   4.597605\n\n\n可知，\\(\\alpha = 1,\\beta = 0.0032\\)\n\nplot(air_passengers_holt)\n\n\n\n\n\n\n图 25.11: holt 指数平滑模型\n\n\n\n\n\n25.4.5 Holt-Winters 指数平滑\n时间序列同时含有趋势成分、季节性成分、随机成分，可以用 Holt-Winters 平滑模型来拟合和预测。根据趋势和季节性的关系，Holt-Winters 平滑模型分为可加 Holt-Winters 平滑和可乘 Holt-Winters 平滑。R 提供函数 HoltWinters() 拟合 Holt-Winters 平滑模型(Holt 2004; Winters 1960)。\n可加 Holt-Winters 平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= a_{t} + h \\times b_{t} + s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} - s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= \\gamma (y_{t} - a_{t}) + (1-\\gamma) s_{t-p}\n\\end{aligned}\n\\]\n可乘 Holt-Winters 平滑模型如下：\n\\[\n\\begin{aligned}\n\\hat{y}_{t+h} &= (a_{t} + h \\times b_{t}) \\times s_{t - p + 1 + (h - 1) \\mod p} \\\\\na_{t} &= \\alpha (y_{t} / s_{t-p}) + (1-\\alpha) (a_{t-1} + b_{t-1}) \\\\\nb_{t} &= \\beta (a_{t} - a_{t-1}) + (1-\\beta) b_{t-1} \\\\\ns_{t} &= \\gamma (y_{t} / a_{t}) + (1-\\gamma) s_{t-p}\n\\end{aligned}\n\\]\n其中 \\(\\alpha, \\beta, \\gamma\\) 是参数，\\(p\\) 为周期长度，\\(a_{t}, b_{t}, s_{t}\\) 分别代表水平、趋势和季节性成分。\n\nair_passengers_add &lt;- HoltWinters(AirPassengers, seasonal = \"additive\")\nair_passengers_add\n\nHolt-Winters exponential smoothing with trend and additive seasonal component.\n\nCall:\nHoltWinters(x = AirPassengers, seasonal = \"additive\")\n\nSmoothing parameters:\n alpha: 0.2479595\n beta : 0.03453373\n gamma: 1\n\nCoefficients:\n          [,1]\na   477.827781\nb     3.127627\ns1  -27.457685\ns2  -54.692464\ns3  -20.174608\ns4   12.919120\ns5   18.873607\ns6   75.294426\ns7  152.888368\ns8  134.613464\ns9   33.778349\ns10 -18.379060\ns11 -87.772408\ns12 -45.827781\n\n\n可知，\\(\\alpha = 0.248,\\beta = 0.0345,\\gamma = 1\\)\n\nautoplot(air_passengers_add) +\n  theme_classic()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 25.12: 可加 Holt-Winters 平滑模型拟合\n\n\n\n\n\nair_passengers_mult &lt;- HoltWinters(AirPassengers, seasonal = \"mult\")\n\n\nautoplot(air_passengers_mult) +\n  theme_classic()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 25.13: 可乘 Holt-Winters 平滑模型拟合\n\n\n\n\n做一个 Shiny 应用展示参数 \\(\\alpha, \\beta, \\gamma\\) 对 Holt-Winters 平滑预测的影响。",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-time-series-decomposition",
    "href": "analyze-time-series-data.html#sec-time-series-decomposition",
    "title": "25  时序数据分析",
    "section": "\n25.5 时间序列分解",
    "text": "25.5 时间序列分解\n\n可加模型\n\n\\[\ny_t = T_t + S_t + e_t\n\\]\n\n可乘模型\n\n\\[\ny_t = T_t \\times S_t \\times e_t\n\\]\n对时间序列 \\(\\{y_t\\}\\) 分解，趋势性成分 \\(T_t\\)、季节性成分 \\(S_t\\)、剩余成分 \\(e_t\\)\n\n25.5.1 函数 decompose()\n\n函数 decompose() 分解\n\nair_decomp_add &lt;- decompose(x = AirPassengers, type = \"additive\")\n\n函数返回一个列表，包含 6 个元素，分别是 x 原始序列，seasonal 季节性成分，figure 估计的季节图，trend 趋势成分，random 剩余成分，type 分解方法。\n\n# plot(air_decomp_add)\nautoplot(air_decomp_add) +\n  theme_classic()\n\nWarning: Removed 24 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n图 25.14: 变化趋势的分解\n\n\n\n\n去掉季节性部分\n\nAirPassengers_adjusted &lt;- AirPassengers - air_decomp_add$seasonal\nplot(AirPassengers_adjusted)\n\n\n\n\n\n\n图 25.15: 季节性调整\n\n\n\n\n\n25.5.2 函数 stl()\n\n函数 stl() 将时间序列分解为趋势性成分、季节性成分（周期性）、剩余成分。\n\nair_stl &lt;- stl(x = AirPassengers, s.window = 12)\n\n\nautoplot(air_stl) +\n  theme_classic()\n\n\n\n\n\n\n图 25.16: 变化趋势的分解\n\n\n\n\n剩余成分不是平稳序列，是异方差的。\nxts 包的 periodicity() 函数可以检测时间序列数据的周期，但时序数据对象最好是在 xts 框架内。\n\nxts::periodicity(AirPassengers)\n\nMonthly periodicity from Jan 1949 to Dec 1960",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-classic-time-series-models",
    "href": "analyze-time-series-data.html#sec-classic-time-series-models",
    "title": "25  时序数据分析",
    "section": "\n25.6 经典时间序列模型",
    "text": "25.6 经典时间序列模型\n\n25.6.1 自回归模型\n函数 ar() 拟合 AR 模型\n\nar(AirPassengers, order.max = 3)\n\n\nCall:\nar(x = AirPassengers, order.max = 3)\n\nCoefficients:\n      1        2  \n 1.1656  -0.2294  \n\nOrder selected 2  sigma^2 estimated as  1399\n\n\n\n25.6.2 移动平均模型\n将自回归的阶设为 0，函数 arima() 也可以用来拟合 MA 模型。\n\narima(AirPassengers, order = c(0, 1, 3))\n\n\nCall:\narima(x = AirPassengers, order = c(0, 1, 3))\n\nCoefficients:\n         ma1     ma2      ma3\n      0.1309  -0.359  -0.3599\ns.e.  0.0741   0.090   0.0907\n\nsigma^2 estimated as 949.5:  log likelihood = -693.45,  aic = 1394.91\n\n\n\n25.6.3 自回归移动平均模型\n函数 arima() 拟合 ARIMA 模型\n\narima(AirPassengers, order = c(1, 1, 3))\n\n\nCall:\narima(x = AirPassengers, order = c(1, 1, 3))\n\nCoefficients:\n         ar1      ma1      ma2      ma3\n      0.5227  -0.2906  -0.3884  -0.1219\ns.e.  0.1291   0.1284   0.1445   0.1322\n\nsigma^2 estimated as 886:  log likelihood = -688.45,  aic = 1386.89\n\n\nforecast 包提供函数 auto.arima() 自动选择合适的自回归、差分和移动平均的阶来拟合数据。\nforecast::auto.arima(AirPassengers)\nSeries: AirPassengers \nARIMA(2,1,1)(0,1,0)[12] \n\nCoefficients:\n         ar1     ar2      ma1\n      0.5960  0.2143  -0.9819\ns.e.  0.0888  0.0880   0.0292\n\nsigma^2 = 132.3:  log likelihood = -504.92\nAIC=1017.85   AICc=1018.17   BIC=1029.35",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "analyze-time-series-data.html#sec-time-series-summary",
    "href": "analyze-time-series-data.html#sec-time-series-summary",
    "title": "25  时序数据分析",
    "section": "\n25.7 总结",
    "text": "25.7 总结\n方法没有好坏，只有适合与否。Holt-Winter 适合预警任务，算法简单，可以及时出预测结果，仅需要一步预测，不需要给出多步预测，要求快，以便迅速作出反应。Prophet 实现的贝叶斯结构可加模型适合短期预测任务，只要在可容许的时间范围内出结果即可，可以迅速出结果当然更好，需要给出多步预测结果，且结果需要强解释性，以便提前做一些商家供给、平台资源的分配。商分模型常常需要比较强的可解释性，算法策略模型重在预测精准度，对可解释性要求不高。\n在时间序列数据的可视化方面，除了 Base R 提供的绘图方法外，静态的时序图 lattice 和 ggplot2 都不错，而交互式图形推荐使用 plotly 和 dygraphs。\nPortfolioAnalytics 包做投资组合优化，均值-方差，收益和风险权衡。 Rmetrics 提供系列时间序列数据分析和建模的 R 包，包括投资组合优化 fPortfolio、多元分析 fMultivar、自回归条件异方差模型 fGarch、二元相依结构的 Copulae 分析 fCopulae 、市场和基础统计 fBasics 。\nfable 一元到多元时间序列预测问题，提供 ETS、ARIMA、TSLM 等模型，并有书籍时间序列预测原则。值得一提， forecast 包开发者 Rob J Hyndman 称已不再开发新的功能，推荐大家使用 fable 包。feasts 包辅助特征抽取、序列分解、汇总统计和绘制图形等， 插件包 fable.prophet 接入 Prophet 的预测能力。timetk 时间序列数据处理、分析、预测和可视化工具箱，提供一致的操作方式，试图形成完成的解决方案。The Rmetrics Association 开发了一系列 R 包专门处理金融时间序列数据，比如 fGarch 包提供条件自回归异方差模型。\n从时间序列中寻找规律，这样才是真的数据建模，从数据到模型，而不是相反 Finding Patterns in Time Series，识别金融时间序列的模式和统计规律。\n\n\n\n\nHolt, Charles C. 2004. 《Forecasting seasonals and trends by exponentially weighted moving averages》. International Journal of Forecasting 20 (1): 5–10. https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nRyan, Jeffrey A., 和 Joshua M. Ulrich. 2022. quantmod: Quantitative Financial Modelling Framework. https://CRAN.R-project.org/package=quantmod.\n\n\nTang, Yuan, Masaaki Horikoshi, 和 Wenxuan Li. 2016. 《ggfortify: Unified Interface to Visualize Statistical Result of Popular R Packages》. The R Journal 8 (2): 474–85. https://doi.org/10.32614/RJ-2016-060.\n\n\nWinters, Peter R. 1960. 《Forecasting sales by exponentially weighted moving averages》. Management Science 6 (3): 324–42. https://doi.org/10.1287/mnsc.6.3.324.",
    "crumbs": [
      "数据建模",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>时序数据分析</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html",
    "href": "statistical-computation.html",
    "title": "26  统计计算",
    "section": "",
    "text": "26.1 回归问题与优化问题\n1996 年出现 Lasso （Least Absolute Selection and Shrinkage Operator，简称 Lasso）(Tibshirani 1996)，由于缺少高效的求解算法，Lasso 在高维小样本特征选择研究中没有广泛流行，最小角回归（Least Angle Regression，简称 LAR）算法 (Efron 等 2004) 的出现有力促进了 Lasso 在高维小样本数据中的应用。为了解决 Lasso 的有偏估计问题，自适应 Lasso、松弛 Lasso， SCAD （Smoothly Clipped Absolute Deviation，简称 SCAD）(Kim, Choi, 和 Oh 2008)，MCP (Minimax Concave Penalty，简称 MCP)(Zhang 2010) 陆续出现。经典的普通最小二乘、广义最小二乘、岭回归、逐步回归、Lasso 回归、最优子集回归都可转化为优化问题。具体地，一个带 L1 正则项的线性回归模型，其对应的优化问题如下：\n\\[\n\\arg \\min_{\\boldsymbol{\\beta},\\lambda} ~~ \\frac{1}{2} || \\bm{y} - X \\boldsymbol{\\beta} ||_2^2 +  \\lambda ||\\boldsymbol{\\beta}||_1\n\\]\n其中，\\(X \\in \\mathbb{R}^{n\\times k}\\)， \\(\\bm{y} \\in \\mathbb{R}^n\\)，\\(\\boldsymbol{\\beta} \\in \\mathbb{R}^k\\)， \\(0 &lt; \\lambda \\in \\mathbb{R}\\) 。下面以逻辑回归模型为例，介绍 R 语言中求解此类优化问题的方法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-log-likelihood",
    "href": "statistical-computation.html#sec-log-likelihood",
    "title": "26  统计计算",
    "section": "\n26.2 对数似然与损失函数",
    "text": "26.2 对数似然与损失函数\n\n26.2.1 Logistic 分布\n在介绍逻辑回归之前，先了解一下 Logistic 分布。一个均值为 \\(m\\) ，方差为 \\(\\frac{\\pi^2}{3}s^2\\) 的 Logistic 分布函数的形式为\n\\[\nF(x) = \\frac{1}{1 + \\exp(-\\frac{x - m}{s})}\n\\]\n密度函数的形式为\n\\[\nf(x) = \\frac{\\exp(-\\frac{x - m}{s})}{s(1 + \\exp(-\\frac{x-m}{s}))^2} = \\frac{\\exp(\\frac{x - m}{s})}{s(1 + \\exp(\\frac{x-m}{s}))^2}\n\\]\n密度函数与分布函数的关系如下：\n\\[\n\\frac{dF(x)}{dx} = f(x) = sF(x)(1 - F(x))\n\\]\n也就是说 Logistic 分布是上述微分方程的解。\n\n\n\n\n\n\n\n\n\n(a) 概率密度函数\n\n\n\n\n\n\n\n\n\n(b) 概率分布函数\n\n\n\n\n\n\n图 26.1: 逻辑斯谛分布\n\n\nR 语言中分别表示逻辑斯谛分布的密度函数、分布函数、分位函数和随机数生成函数如下：\ndlogis(x, location = 0, scale = 1, log = FALSE)\nplogis(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)\nqlogis(p, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)\nrlogis(n, location = 0, scale = 1)\n如果函数参数 location 或 scale 没有指定，则分别取默认值 0 和 1，就是标准的逻辑斯谛分布。位置参数（类似正态分布中的均值 \\(\\mu\\)）为 location = m ，尺度参数（类似正态分布中的标准差 \\(\\sigma\\)）为 scale = s，逻辑斯谛分布是一个长尾分布。\n\n26.2.2 逻辑回归\n响应变量 \\(Y\\) 服从伯努利分布 \\(\\mathrm{Bernoulli}(p)\\)，取值是 0 或 1，对线性预测 \\(X\\boldsymbol{\\beta}\\) 做 Logistic 变换\n\\[\n\\bm{p} = \\mathsf{E}Y = \\mathrm{Logistic}(X\\boldsymbol{\\beta}) = \\frac{1}{1 + e^{-(\\alpha + X\\boldsymbol{\\beta})}} = \\frac{e^{\\alpha + X\\boldsymbol{\\beta}}}{1 + e^{\\alpha + X\\boldsymbol{\\beta}}}\n\\]\nLogistic 的逆变换\n\\[\n\\mathrm{Logistic}^{-1}(\\bm{p})= \\ln\\big(\\frac{\\bm{p}}{1 - \\bm{p}}\\big) = \\alpha + X\\boldsymbol{\\beta}\n\\]\n记数据矩阵 \\(X\\) 为\n\\[\nX = \\begin{bmatrix}\n    x_{11} & x_{12} & x_{13} & \\dots  & x_{1k} \\\\\n    x_{21} & x_{22} & x_{23} & \\dots  & x_{2k} \\\\\n    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    x_{n1} & x_{n2} & x_{n3} & \\dots  & x_{nk}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\bm{x}_1^{\\top} \\\\\n\\bm{x}_2^{\\top} \\\\\n\\vdots \\\\\n\\bm{x}_n^{\\top}\n\\end{bmatrix}\n\\]\n每一行表示一次观测，每一列表示一个变量的 \\(n\\) 次观测，记 \\(X = (X_1, X_2, \\cdots, X_k)\\) 是一个 \\(n \\times k\\) 数据矩阵，其中 \\(\\bm{x}_i^{\\top}\\) 表示矩阵 \\(X\\) 的第 \\(i\\) 行，一共有 \\(n\\) 行，可以看作是 \\(1 \\times k\\) 的矩阵，\\(X_j, j = 1,2, \\cdots, k\\) 表示矩阵 \\(X\\) 的第 \\(j\\) 列，一共有 \\(k\\) 列。类似地， \\(\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\cdots, \\beta_k)^{\\top}\\) 是一个列向量，可以看作是 \\(k \\times 1\\) 的矩阵，\\(\\beta_j\\) 表示第 \\(j\\) 个变量 \\(X_j\\) 的系数。对第 \\(i\\) 次观测\n\\[\n\\mathrm{Logistic}^{-1}(p_i)= \\ln\\big(\\frac{p_i}{1-p_i}\\big) = \\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}\n\\]\n关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的似然函数如下：\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\alpha,\\boldsymbol{\\beta}) &= \\prod_{i=1}^{n} p_i^{y_i}(1 - p_i)^{1 - y_i} \\\\\n     &= \\prod_{i=1}^{n} \\Big(\\frac{e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}\\Big)^{y_i}\\Big(\\frac{1}{e^{\\alpha + \\bm{x}_i^{\\top}\\boldsymbol{\\beta}}}\\Big)^{1-y_i} \\\\\n\\end{aligned}\n\\tag{26.1}\\]\n关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的对数似然函数如下：\n\\[\n\\begin{aligned}\n\\ell(\\alpha,\\boldsymbol{\\beta}) &= \\log \\mathcal{L}(\\alpha,\\boldsymbol{\\beta}) \\\\\n& = \\sum_{i=1}^{n} \\Big[y_i \\log (p_i) + (1 - y_i) \\log(1-p_i)\\Big] \\\\\n&= \\sum_{i=1}^{n} \\Big[y_i \\log \\Big(\\frac{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\Big) + (1 - y_i) \\log\\Big(\\frac{1}{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\Big)\\Big]\n\\end{aligned}\n\\tag{26.2}\\]\n对数似然函数 \\(\\ell(\\alpha,\\boldsymbol{\\beta})\\) 关于参数 \\(\\alpha,\\boldsymbol{\\beta}\\) 的偏导数如下：\n\\[\n\\begin{aligned}\n\\frac{\\partial \\ell(\\alpha,\\boldsymbol{\\beta})}{\\partial \\alpha}  &= \\sum_{i=1}^{n}\\Big[ \\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) \\frac{\\partial p_i}{\\partial \\alpha} \\Big] \\\\\n\\frac{\\partial \\ell(\\alpha,\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} &= \\sum_{i=1}^{n}\\Big[\\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) \\frac{\\partial p_i}{\\partial \\beta} \\Big] \\\\\n& = \\sum_{i=1}^{n}\\Big[\\big(\\frac{y_i}{p_i} -  \\frac{1- y_i}{1 - p_i}\\big) p_i(1- p_i) \\bm{x}_i^{\\top} \\Big]\n\\end{aligned}\n\\tag{26.3}\\]\n其中， \\(p_i = \\frac{e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}{1 + e^{\\alpha + \\bm{x}_i\\boldsymbol{\\beta}}}\\) ，要使 \\(\\ell(\\alpha,\\boldsymbol{\\beta})\\) 取极大值，一般通过迭代加权最小二乘算法（Iteratively (Re-)Weighted Least Squares，简称 IWLS）求解此优化问题，它可以看作拟牛顿法的一种特殊情况，在 R 语言中，函数 glm() 是求解此类问题的办法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-solvers",
    "href": "statistical-computation.html#sec-solvers",
    "title": "26  统计计算",
    "section": "\n26.3 数值优化问题求解器",
    "text": "26.3 数值优化问题求解器\n\n26.3.1 optim()\n\n从一个逻辑回归模型模拟一组样本，共 2500 条记录，即 \\(n = 2500\\)，10 个观测变量，即 \\(k=10\\)，其中，只有变量 \\(X_1\\) 和 \\(X_2\\) 的系数非零，参数设定为 \\(\\alpha = 1, \\beta_1 = 3,\\beta_2 = -2\\)，而 \\(\\beta_i = 0, i=3, \\cdots, 10\\) 模拟数据的代码如下：\n\nset.seed(2023)\nn &lt;- 2500\nk &lt;- 10\nX &lt;- matrix(rnorm(n * k), ncol = k)\ny &lt;- rbinom(n, size = 1, prob = plogis(1 + 3 * X[, 1] - 2 * X[, 2]))\n\n模拟数据矩阵 X 与上述记号 \\(X\\) 是对应的，记号 \\(\\bm{x_i}^{\\top}\\) 表示数据矩阵的第 \\(i\\) 行。\\(\\alpha\\) 是逻辑回归方程的截距，\\(\\bm{\\beta}\\) 是 \\(k\\) 维列向量，\\(X\\) 是 \\(n \\times k\\) 维的矩阵且 \\(n &gt; k\\)，\\(y\\) 是 \\(n\\) 维向量。极大化对数似然函数 方程式 26.2 ，就是求解一个多维非线性无约束优化问题。方便起见，将 \\(\\alpha\\) 合并进 \\(\\bm{\\beta}\\) 向量，另，函数 optim() 默认求极小，因此在对数似然函数前添加负号。\n\n# 目标函数\nlog_logit_lik &lt;- function(beta) {\n  p &lt;- plogis(cbind(1, X) %*% beta)\n  -sum(y * log(p) + (1 - y) * log(1 - p))\n}\n\n高维情形下，没法绘制似然函数图形，退化到二维，如 图 26.2 所示，二维情形下的逻辑回归模型的负对数似然函数曲面。\n\n\n\n\n\n\n\n图 26.2: 二维情形下的逻辑回归模型的负对数似然函数曲面\n\n\n\n\n当用 Base R 函数 optim() 来求解时，发现 Nelder-Mead 算法收敛慢，易陷入局部最优解，即使迭代 10000 次，与真值仍然相去甚远。当用 SANN （模拟退火算法）求解此 11 维非线性无约束优化问题时，迭代 10000 次后，比较接近真值。\n\noptim(\n  par = rep(1, 11), # 初始值\n  fn = log_logit_lik, # 目标函数\n  method = \"SANN\",\n  control = list(maxit = 10000)\n)\n\n#&gt; $par\n#&gt;  [1]  1.0755086156  3.2857327374 -2.1172404451 -0.0268567120  0.0184306330\n#&gt;  [6]  0.0304496968  0.0045154725  0.1283816433 -0.0746276329 -0.0624193044\n#&gt; [11] -0.0001349772\n#&gt; \n#&gt; $value\n#&gt; [1] 754.1838\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    10000       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n\n\n根据目标函数计算其梯度，有了梯度信息，可以使用迭代效率更高的 L-BFGS-B 算法。\n\n# 梯度函数\nlog_logit_lik_grad &lt;- function(beta) {\n  p &lt;- plogis(cbind(1, X) %*% beta)\n  -t((y / p - (1 - y) / (1 - p)) * p * (1 - p)) %*% cbind(1, X)\n}\n\noptim(\n  par = rep(1, 11), # 初始值\n  fn = log_logit_lik, # 目标函数\n  gr = log_logit_lik_grad, # 目标函数的梯度\n  method = \"L-BFGS-B\"\n)\n\n#&gt; $par\n#&gt;  [1]  1.00802641  3.11296713 -2.00955313  0.05855394 -0.02650585  0.01330428\n#&gt;  [7]  0.02171815  0.10213455 -0.02949774 -0.08633384  0.08098888\n#&gt; \n#&gt; $value\n#&gt; [1] 750.9724\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;       13       13 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH\"\n\n\n相比于函数 optim()，R 包 nloptr 不但可以提供类似的数值优化功能，而且可以处理各类非线性约束，能力更强。仍然基于上面的优化问题， 调用 nloptr 包求解的代码如下：\n\nlibrary(nloptr)\nnlp &lt;- nloptr(\n  x0 = rep(1, 11),\n  eval_f = log_logit_lik,\n  eval_grad_f = log_logit_lik_grad,\n  opts = list(\n    \"algorithm\" = \"NLOPT_LD_LBFGS\",\n    \"xtol_rel\" = 1.0e-8\n  )\n)\nnlp\n\n#&gt; \n#&gt; Call:\n#&gt; \n#&gt; nloptr(x0 = rep(1, 11), eval_f = log_logit_lik, eval_grad_f = log_logit_lik_grad, \n#&gt;     opts = list(algorithm = \"NLOPT_LD_LBFGS\", xtol_rel = 1e-08))\n#&gt; \n#&gt; \n#&gt; Minimization using NLopt version 2.7.1 \n#&gt; \n#&gt; NLopt solver status: 3 ( NLOPT_FTOL_REACHED: Optimization stopped because \n#&gt; ftol_rel or ftol_abs (above) was reached. )\n#&gt; \n#&gt; Number of Iterations....: 23 \n#&gt; Termination conditions:  xtol_rel: 1e-08 \n#&gt; Number of inequality constraints:  0 \n#&gt; Number of equality constraints:    0 \n#&gt; Optimal value of objective function:  750.97235708148 \n#&gt; Optimal value of controls: 1.008028 3.112977 -2.009557 0.05854534 -0.02650855 0.01330416 0.02171839 \n#&gt; 0.1021212 -0.02949994 -0.08632463 0.08098663\n\n\n如果对数似然函数是多模态的，一般的求解器容易陷入局部最优解，推荐用 nloptr 包的全局优化求解器。\n\n26.3.2 glm()\n\nBase R 提供的函数 glm() 拟合模型，指定联系函数为 logit 变换。\n\nfit_r &lt;- glm(y ~ X, family = binomial(link = \"logit\"))\nsummary(fit_r)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = y ~ X, family = binomial(link = \"logit\"))\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  1.00803    0.07395  13.631   &lt;2e-16 ***\n#&gt; X1           3.11298    0.13406  23.222   &lt;2e-16 ***\n#&gt; X2          -2.00956    0.09952 -20.192   &lt;2e-16 ***\n#&gt; X3           0.05855    0.06419   0.912    0.362    \n#&gt; X4          -0.02651    0.06588  -0.402    0.687    \n#&gt; X5           0.01330    0.06461   0.206    0.837    \n#&gt; X6           0.02172    0.06496   0.334    0.738    \n#&gt; X7           0.10212    0.06279   1.626    0.104    \n#&gt; X8          -0.02950    0.06474  -0.456    0.649    \n#&gt; X9          -0.08632    0.06482  -1.332    0.183    \n#&gt; X10          0.08099    0.06385   1.268    0.205    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 3381.4  on 2499  degrees of freedom\n#&gt; Residual deviance: 1501.9  on 2489  degrees of freedom\n#&gt; AIC: 1523.9\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 6\n\n\n或者也可以用函数 glm.fit()，效果类似，使用方式不同罢了。\n\nfit_r2 &lt;- glm.fit(x = cbind(1, X), y = y, family = binomial(link = \"logit\"))\ncoef(fit_r2)\n\n#&gt;  [1]  1.00802820  3.11297679 -2.00955727  0.05854534 -0.02650855  0.01330416\n#&gt;  [7]  0.02171839  0.10212118 -0.02949994 -0.08632463  0.08098663\n\n\n函数 glm() 的参数是一个公式，函数 glm.fit() 的参数是矩阵、向量，用函数 glm() 拟合模型，其内部调用的就是函数 glm.fit()。\n\n26.3.3 glmnet 包\n调用 glmnet 包的函数 glmnet() 拟合模型，指定指数族的具体形式为二项分布，伯努利分布是二项分布的特殊形式，也叫两点分布或0-1分布。\n\nlibrary(Matrix)\nlibrary(glmnet)\nfit_glm &lt;- glmnet(x = X, y = y, family = \"binomial\")\n\n逻辑回归模型系数在 L1 正则下的迭代路径图\n\nplot(fit_glm, ylab = \"回归系数\")\n\n\n\n\n\n\n图 26.3: 回归系数的迭代路径\n\n\n\n\n从图可见，剩余两个系数是非零的，一个是 3， 一个是 -2，其余都被压缩，而接近为 0 了。\n\nplot(fit_glm$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\",\n  main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\n图 26.4: 惩罚系数的迭代路径\n\n\n\n\n随着迭代的进行，惩罚系数 \\(\\lambda\\) 越来越小，接近于 0，这也是符合预期的，因为模型本来就是简单的逻辑回归，不带惩罚项。选择一个迭代趋于稳定时的 \\(\\lambda\\) 比如 0.0005247159，此时各个参数的取值如下：\n\ncoef(fit_glm, s = 0.0005247159)\n\n#&gt; 11 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       s1\n#&gt; (Intercept)  0.997741857\n#&gt; V1           3.076358149\n#&gt; V2          -1.984018387\n#&gt; V3           0.052633923\n#&gt; V4          -0.020195037\n#&gt; V5           0.008065018\n#&gt; V6           0.015936357\n#&gt; V7           0.095722046\n#&gt; V8          -0.023589159\n#&gt; V9          -0.080864640\n#&gt; V10          0.075234011\n\n\n截距 (Intercept) 对应 \\(\\alpha = 0.997741857\\)，而 \\(\\beta_1 = 3.076358149\\) 对应 V1，\\(\\beta_2 = -1.984018387\\) 对应 V2，以此类推。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "statistical-computation.html#sec-evaluation-model-performance",
    "href": "statistical-computation.html#sec-evaluation-model-performance",
    "title": "26  统计计算",
    "section": "\n26.4 评估模型的分类效果",
    "text": "26.4 评估模型的分类效果\n逻辑回归模型是二分类模型，评估模型的分类效果，两个办法。\n\n可以用 AUC 指标或者 ROC 曲线，pROC 包和 ROCR 包都可以绘制 ROC 曲线。\n可以用 Wilcoxon 检验，越显著表示分类效果越好。\n\n\n26.4.1 ROC 曲线和 AUC 值\nROC 是 Receiver Operating Characteristic 简写。随机抽取 2000 个样本作为训练集，余下的数据作为测试集。\n\ndat &lt;- cbind.data.frame(X, y)\nset.seed(20232023)\nidx &lt;- sample(x = 1:nrow(dat), size = 2000, replace = F)\n# 训练集\ndat_train &lt;- dat[idx, ]\n# 测试集\ndat_test &lt;- dat[-idx, ]\n\n函数 glm() 拟合训练集数据\n\nfit_binom &lt;- glm(y ~ ., data = dat_train, family = binomial(link = \"logit\"))\n\n将训练好的模型用于测试集，调用函数 predict() 进行预测，type = \"response\" 获得预测概率值，它是对数几率，比值比的对数。\n\ndat_test$pred &lt;- predict(fit_binom, newdata = dat_test, type = \"response\")\n\n返回值介于 0 - 1 之间，表示预测概率。在测试集上绘制 ROC 曲线。\n\npROC::plot.roc(\n  y ~ pred, data = dat_test,\n  col = \"dodgerblue\", print.auc = TRUE,\n  auc.polygon = TRUE, auc.polygon.col = \"#f6f6f6\",\n  xlab = \"FPR\", ylab = \"TPR\", main = \"预测 ROC 曲线\"\n)\n\n#&gt; Setting levels: control = 0, case = 1\n\n\n#&gt; Setting direction: controls &lt; cases\n\n\n\n\n\n\n\n图 26.5: ROC 曲线\n\n\n\n\nROC 曲线越往左上角拱，表示预测效果越好。FPR 是 False Positive Rate 的缩写，TPR 是 True Positive Rate 的缩写。\n\n# 计算 AUC 值\npROC::auc(y ~ pred, data = dat_test)\n\n#&gt; Setting levels: control = 0, case = 1\n\n\n#&gt; Setting direction: controls &lt; cases\n\n\n#&gt; Area under the curve: 0.9487\n\n\nAUC 是 area under curve 的缩写，表示 ROC 曲线下的面积，所以 AUC 指标越接近 1 越好。\n\n26.4.2 Wilcoxon 检验\n对每个标签的预测概率指定服从均匀分布，相当于随机猜测，所以最后 ROC 会接近对角线，而且样本量越大越接近，AUC 会越来越接近 0.5。如果预测结果比随机猜测要好，Wilcoxon 检验会显著，预测效果越好检验会越显著，表示预测 pred 和观测 y 越接近。\n\nwilcox.test(pred ~ y, data = dat_test)\n\n#&gt; \n#&gt;  Wilcoxon rank sum test with continuity correction\n#&gt; \n#&gt; data:  pred by y\n#&gt; W = 3140, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, 和 Robert Tibshirani. 2004. 《Least angle regression》. The Annals of Statistics 32 (2): 407–99. https://doi.org/10.1214/009053604000000067.\n\n\nKim, Yongdai, Hosik Choi, 和 Hee-Seok Oh. 2008. 《Smoothly Clipped Absolute Deviation on High Dimensions》. Journal of the American Statistical Association 103 (484): 1665–73. https://doi.org/10.1198/016214508000001066.\n\n\nTibshirani, Robert. 1996. 《Regression Shrinkage and Selection via the Lasso》. Journal of the Royal Statistical Society. Series B (Methodological) 58 (1): 267–88. http://www.jstor.org/stable/2346178.\n\n\nZhang, Cun-Hui. 2010. 《Nearly unbiased variable selection under minimax concave penalty》. The Annals of Statistics 38 (2): 894–942. https://doi.org/10.1214/09-AOS729.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>统计计算</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html",
    "href": "numerical-optimization.html",
    "title": "27  数值优化",
    "section": "",
    "text": "27.1 线性优化\n线性优化是指目标函数和约束条件都是线性的优化问题。考虑如下线性优化问题：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & -6x_1 -5x_2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    x_1  + 4x_2 \\leq 16\\\\\n    6x_1 + 4x_2 \\leq 28\\\\\n    2x_1 - 5x_2 \\leq 6\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n其中，目标函数是 \\(-6x_1 -5x_2\\)，\\(\\min\\) 表示求目标函数的最小值，\\(\\boldsymbol{x} = (x_1,x_2)^{\\top}\\) 表示决策变量，无特殊说明，决策变量都取实数。\\(\\text{s.t.}\\) 是 subject to 的缩写，专指约束条件。上述线性优化问题写成矩阵形式，如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\n  \\begin{bmatrix}\n  -6  \\\\\n  -5\n  \\end{bmatrix}\n  ^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\left\\{\n\\begin{array}{l}\n  \\begin{bmatrix}\n  1 & 4  \\\\\n  6 & 4  \\\\\n  2 & -5\n  \\end{bmatrix}\n  \\boldsymbol{x} \\leq\n  \\begin{bmatrix}\n   16 \\\\\n   28 \\\\\n   6\n  \\end{bmatrix}\n\\end{array} \\right.\n\\end{aligned}\n\\]\n用 \\(\\boldsymbol{d}\\) 表示目标函数的系数向量，\\(A\\) 表示约束矩阵，\\(\\boldsymbol{b}\\) 表示右手边的向量。上述优化问题用矩阵表示，如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\n  \\boldsymbol{d}^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad &\n  A\\boldsymbol{x} \\leq\n  \\boldsymbol{b}\n\\end{aligned}\n\\]\n用 ROI 包提供的一套使用语法表示该线性优化问题，代码如下：\n# 定义优化问题\nop &lt;- OP(\n  objective = L_objective(L = c(-6, -5)),\n  constraints = L_constraint(\n    L = matrix(c(\n      1, 4,\n      6, 4, \n      2, -5\n    ), ncol = 2, byrow = TRUE),\n    dir = c(\"&lt;=\", \"&lt;=\", \"&lt;=\"),\n    rhs = c(16, 28, 6)\n  ),\n  types = c(\"C\", \"C\"),\n  maximum = FALSE\n)\n# 优化问题描述\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n# 求解优化问题\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1] 2.4 3.4\n\n# 目标函数值\nres$objval\n\n#&gt; [1] -31.4\n函数 OP() 定义一个优化问题，参数如下：\n不同类型的目标函数和约束条件组合在一起可以构成非常丰富的优化问题。ROI 包支持的目标函数、约束条件及相应的代码见下表。后续将根据优化问题，逐个介绍用法。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-linear-optimization",
    "href": "numerical-optimization.html#sec-linear-optimization",
    "title": "27  数值优化",
    "section": "",
    "text": "objective ：指定目标函数，用函数 L_objective() 表示线性优化中的目标函数，函数名中 L 表示 Linear（线性），包含数值型向量。\n\nconstraints ：指定约束条件，用函数 L_constraint() 表示线性优化中的约束条件，函数名中 L 表示 Linear（线性），包含约束矩阵 \\(A\\) ，约束分量的方向可为 &gt;= 、&lt;= 或 = ，本例中为 &lt;=，右手边的向量 \\(b\\) 。\n\ntypes ：指定决策变量的类型，分三种情况， B 表示 0-1 变量，字母 B 是 binary 的意思，I 表示整型变量，字母 I 是 integer 的意思，C 表示数值型变量，字母 C 是 continuous 的意思。本例中，两个变量都是连续型的，types = c(\"C\", \"C\") 。\n\nmaximum ：指定目标函数需要求极大还是极小，默认求极小，取值为逻辑值 TRUE 或 FALSE。\n\n\n\n\nROI 包可以表示的目标函数和约束条件\n\n目标函数\n代码\n约束条件\n代码\n\n\n\n线性函数\nL_objective()\n无约束\n留空\n\n\n二次函数\nQ_objective()\n箱式约束\nV_bound()\n\n\n非线性函数\nF_objective()\n线性约束\nL_constraint()\n\n\n\n\n二次约束\nQ_constraint()\n\n\n\n\n锥约束\nC_constraint()\n\n\n\n\n非线性约束\nF_constraint()",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-quadratic-optimization",
    "href": "numerical-optimization.html#sec-quadratic-optimization",
    "title": "27  数值优化",
    "section": "\n27.2 凸二次优化",
    "text": "27.2 凸二次优化\n二次优化分严格凸二次和非严格凸二次优化问题，严格凸要求矩阵对称正定，非严格凸要求矩阵对称半正定。对于矩阵负定的情况，不是凸优化问题，暂不考虑。二次优化的一般形式如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2}\\boldsymbol{x}^{\\top}D\\boldsymbol{x} + \\boldsymbol{d}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{x} \\leq \\boldsymbol{b}\n\\end{aligned}\n\\]\n二次优化不都是凸优化，当且仅当矩阵 \\(D\\) 半正定时，上述二次优化是凸二次优化，当矩阵 \\(D\\) 正定时，上述二次优化是严格凸二次优化。下面举个严格凸二次优化的具体例子，令\n\\[\nD = \\begin{bmatrix}\n2 & -1\\\\\n-1 & 2\n\\end{bmatrix}, \\quad\n\\boldsymbol{d} =  \n\\begin{bmatrix}\n3 \\\\\n-2\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n-1 & -1  \\\\\n1 & -1 \\\\\n0  & 1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n-2 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n即目标函数\n\\[\nQ(x_1,x_2) = x_1^2 + x_2^2 - x_1 x_2 + 3x_1- 2x_2\n\\]\n二次优化中的数据矩阵和向量 \\(D,\\boldsymbol{d},A,\\boldsymbol{b}\\) 依次用 Dmat、dvec、Amat、bvec 表示出来。\n\nDmat &lt;- matrix(c(2, -1, -1, 2), nrow = 2, byrow = TRUE)\ndvec &lt;- c(3, -2)\nAmat &lt;- matrix(c(-1, -1, 1, -1, 0, 1), ncol = 2, byrow = TRUE)\nbvec &lt;- c(-2, 2, 3)\n\n同样，也是在函数 OP()中传递目标函数，约束条件。在函数 Q_objective() 中定义二次优化的目标函数，字母 Q 是 Quadratic 的意思，表示二次部分，字母 L 是 Linear 的意思，表示线性部分。函数 L_constraint() 的使用同线性优化，不再赘述。根据 ROI 包的使用接口定义的参数，定义目标优化。\n\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(L = Amat, dir = rep(\"&lt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\nnloptr 包有许多优化求解器，可用于求解二次优化的也有好几个。对于一个目标优化，函数 ROI_applicable_solvers() 可以找到能够求解此优化问题的求解器。\n\nROI_applicable_solvers(op)\n\n#&gt; [1] \"nloptr.cobyla\" \"nloptr.mma\"    \"nloptr.auglag\" \"nloptr.isres\" \n#&gt; [5] \"nloptr.slsqp\"  \"quadprog\"\n\n\n下面使用其中的 nloptr.slsqp 来求解。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 2))\nnlp$objval\n\n#&gt; [1] -0.08333333\n\nnlp$solution\n\n#&gt; [1] 0.1666667 1.8333333\n\n\n作为对比，移除线性不等式约束，求解无约束优化问题。目标函数仍然是二次型，但是已经没有线性约束条件，所以不是二次优化问题，再用求解器 nloptr.slsqp 求解的结果已不是无约束优化的解。\n\nop2 &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  maximum = FALSE\n)\nop2\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 0 constraints\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\nnlp2 &lt;- ROI_solve(op2, solver = \"nloptr.slsqp\", start = c(1, 2))\nnlp2$objval\n\n#&gt; [1] -1\n\nnlp2$solution\n\n#&gt; [1] 0 1\n\n\n在可行域上画出等高线，标记目标解的位置， 图 27.2 展示无约束和有约束条件下的解。图中橘黄色线围成的三角形区域是可行域，红点表示无约束下求解器 nloptr.slsqp 获得的解 \\((0,1)\\) ，真正的无约束解是蓝点所在位置为 \\((-4/3,1/3)\\) ，黄点表示线性约束下求解器 nloptr.slsqp 获得的解 \\((1/6,11/6)\\) 。所以，不能用二次优化的求解器去求解无约束的二次优化问题。\n\n代码# 约束解\nqp_sol &lt;- nlp$solution\n# 无约束解\nuc_sol &lt;- nlp2$solution\ndat &lt;- expand.grid(x1 = seq(-2, 5.5, length.out = 50), \n                   x2 = seq(-1, 3.5, length.out = 50))\n# 二次优化的目标函数\ndat$fn &lt;- with(dat, x1^2 + x2^2 - x1 * x2 + 3 * x1 - 2 * x2)\nlevelplot(fn ~ x1 * x2, data = dat, aspect = .7,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  xlim = c(-2.2, 5.7), ylim = c(-1.1, 3.6),\n  panel = function(...) {\n    panel.levelplot(...)\n    panel.polygon(x = c(2, 5, -1), y = c(0, 3, 3),\n      border = \"orange\", lwd = 2, col = \"transparent\"\n    )\n    panel.points(\n      x = c(uc_sol[1], qp_sol[1], -4/3),\n      y = c(uc_sol[2], qp_sol[2], 1/3),\n      lwd = 5, col = c(\"red\", \"yellow\", \"blue\"), pch = 19\n    )\n  },\n  # 减少图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = 0, units = \"inches\"),\n      right.padding = list(x = 0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ), contour = TRUE, colorkey = TRUE,\n  col.regions = hcl.colors\n)\n\n\n\n\n\n\n图 27.2: 对比无约束和有约束条件下的解\n\n\n\n\nquadprog 包在求解约束条件下的严格凸二次优化问题时，同时给出无约束条件下的解。这个包自定义了一套二次优化问题的符号，查看求解函数 solve.QP() 的说明，略作对应后，求解上述优化问题的代码如下。\n\nlibrary(quadprog)\nsol &lt;- solve.QP(\n  Dmat = Dmat, dvec = -dvec, Amat = t(-Amat), bvec = -bvec\n)\nsol\n\n#&gt; $solution\n#&gt; [1] 0.1666667 1.8333333\n#&gt; \n#&gt; $value\n#&gt; [1] -0.08333333\n#&gt; \n#&gt; $unconstrained.solution\n#&gt; [1] -1.3333333  0.3333333\n#&gt; \n#&gt; $iterations\n#&gt; [1] 2 0\n#&gt; \n#&gt; $Lagrangian\n#&gt; [1] 1.5 0.0 0.0\n#&gt; \n#&gt; $iact\n#&gt; [1] 1\n\n\n其中，返回值的 unconstrained.solution 表示无约束下的解，与预期的解一致，这就没有疑惑了。可见，约束二次优化问题和无约束二次优化问题的求解器不同。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-cone-optimization",
    "href": "numerical-optimization.html#sec-cone-optimization",
    "title": "27  数值优化",
    "section": "\n27.3 凸锥优化",
    "text": "27.3 凸锥优化\n\n27.3.1 锥与凸锥\n二维平面上，圆盘和扇面是凸锥。三维空间中，球，圆锥、椭球、椭圆锥都是凸锥，如 图 27.3 所示。\n\n\n\n\n\n\n\n图 27.3: 常见的三维凸锥\n\n\n\n\n锥定义在对称的矩阵上，凸锥要求矩阵正定。一个 2 阶对称矩阵 \\(A\\) 是正定的\n\\[\nA = \\begin{bmatrix}\n  a_{11} & a_{12}  \\\\\n  a_{21} & a_{22}  \n  \\end{bmatrix}\n\\]\n意味着 \\(a_{11} &gt; 0, a_{22} &gt; 0, a_{12} = a_{21}, a_{11}a_{22} - a_{12}a_{21} &gt; 0\\) 。一般地，将 \\(n\\) 阶半正定的对称矩阵 \\(A\\) 构成的集合记为 \\(\\mathcal{K}_{+}^n\\) 。\n\\[\n\\mathcal{K}_{+}^n = \\{A \\in \\mathbb{R}^{n \\times n}|\\boldsymbol{x}^{\\top}A\\boldsymbol{x} \\geq 0, ~ \\forall \\boldsymbol{x} \\in \\mathbb{R}^n\\}\n\\]\n目标函数为线性的凸锥优化的一般形式如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &\\boldsymbol{d}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{x} + \\boldsymbol{k} = \\boldsymbol{b} \\\\\n& \\boldsymbol{k} \\in \\mathcal{K}.\n\\end{aligned}\n\\]\n其中，集合 \\(\\mathcal{K}\\) 是一个非空的封闭凸锥。在一个凸锥里，寻求一个线性目标函数的最小值。专门求解此类问题的 scs 包也在 ROI 包的支持范围内，可以求解的锥优化包括零锥、线性锥、二阶锥、指数锥、幂锥和半正定锥。\n下面举个例子说明凸锥，含参对称矩阵 \\(A(m_1,m_2,m_3)\\) 如下：\n\\[\nA(m_1,m_2,m_3) = \\begin{bmatrix}\n  1 & m_1 & m_2  \\\\\n  m_1 & 1 & m_3  \\\\\n  m_2 & m_3 & 1\n  \\end{bmatrix}.\n\\]\n而 \\(\\boldsymbol{k} = \\boldsymbol{b} - A\\boldsymbol{x}\\) 是非空封闭凸锥集合 \\(\\mathcal{K}\\) 中的元素。半正定矩阵 \\(A\\) 生成的集合（凸锥） \\(K\\) 如下：\n\\[\nK = \\{ (m_1,m_2,m_3) \\in \\mathbb{R}^3 \\mid A(m_1,m_2,m_3) \\in \\mathcal{K}_{+}^3 \\},\n\\]\n集合 \\(K\\) 是有界半正定的，要求含参矩阵 \\(A\\) 的行列式大于等于 0。 矩阵 \\(A\\) 的行列式如下：\n\\[\n\\det(A(m_1,m_2,m_3)) = - (m_1^2 + m_2^2 + m_3^2 -2m_1 m_2 m_3 -1)\n\\]\n集合 \\(K\\) 的边界可表示为如下方程的解：\n\\[\nm_1^2 + m_2^2 + m_3^2 -2m_1 m_2 m_3 = 1\n\\]\n或等价地表示为如下矩阵形式：\n\\[\n\\begin{split}\\left[\n\\begin{array}{c}\nm_1\\\\m_2\n\\end{array}\\right]^{\\top}\n\\left[\\begin{array}{rr}\n1 & -m_3\\\\-m_3 &1\n\\end{array}\\right]\n\\left[\\begin{array}{c}\nm_1\\\\m_2\n\\end{array}\\right] = 1 - m_3^2.\n\\end{split}\n\\]\n当 \\(m_3 = 0\\) 时，集合 \\(K\\) 的边界表示平面上的一个单位圆，当 \\(m_3 \\in [-1, 1]\\) ，集合 \\(K\\) 的边界表示一个椭圆。为了获得一个直观的印象，将集合 \\(K\\) 的边界绘制出来，如 图 27.3 所示，边界是一个三维曲面，曲面及其内部构成一个凸锥。\n\n代码# 分两部分绘图\nfn1 &lt;- function(x) {\n  x[1] * x[2] + sqrt(x[1]^2 * x[2]^2 - x[1]^2 - x[2]^2 + 1)\n}\n\nfn2 &lt;- function(x) {\n  x[1] * x[2] - sqrt(x[1]^2 * x[2]^2 - x[1]^2 - x[2]^2 + 1)\n}\n\ndf2 &lt;- df1 &lt;- expand.grid(\n  x = seq(-1, 1, length.out = 51),\n  y = seq(-1, 1, length.out = 51)\n)\n\n# 计算函数值\ndf1$fnxy &lt;- apply(df1, 1, fn1)\ndf2$fnxy &lt;- apply(df2, 1, fn2)\n# 添加分组变量\ndf1$group &lt;- \"1\"\ndf2$group &lt;- \"2\"\n# 合并数据\ndf &lt;- rbind(df1, df2)\n\n# 绘图\nwireframe(\n  data = df, fnxy ~ x * y, groups = group,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(m[1]),\n  ylab = expression(m[2]),\n  zlab = expression(m[3]),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 27.4: 锥\n\n\n\n\n\n27.3.2 零锥\n零锥的定义如下：\n\\[\n\\mathcal{K}_{zero} = \\{0\\}\n\\]\n常用于表示线性等式约束。\n\n27.3.3 线性锥\n线性锥（Linear Cone）的定义如下：\n\\[\n\\mathcal{K}_{lin} = \\{x \\in \\mathbb{R}|x \\geq 0\\}\n\\]\n常用于表示线性不等式约束。\n\n27.3.4 二阶锥\n二阶锥（Second-order Cone）的定义如下：\n\\[\n\\mathcal{K}_{soc}^{n} = \\{(t,x) \\in \\mathbb{R}^n|x \\in \\mathbb{R}^{n-1}, t\\in\\mathbb{R},\\| x \\|_2 \\leq t\\}\n\\]\n常用于凸二次优化问题。考虑如下二阶锥优化 SOCP 问题：\n\\[\n\\begin{aligned}\n\\max_{(\\boldsymbol{y},t)} \\quad & y_1 + y_2 \\\\\n\\text{s.t.} \\quad & \\sqrt{(2 + 3y_1)^2 + (4+5y_2)^2} \\leq 6 + 7t \\\\\n& y_1,y_2 \\in \\mathbb{R}, ~~ t \\in (-\\infty,9].\n\\end{aligned}\n\\]\n令 \\(\\boldsymbol{x} = (y_1, y_2, t)^{\\top}\\) ，\\(\\boldsymbol{b} = (b_1,b_2,b_3)^\\top\\)\n\\[\nA = \\begin{bmatrix}\n\\boldsymbol{a_1}^{\\top}\\\\\n\\boldsymbol{a_2}^{\\top}\\\\\n\\boldsymbol{a_3}^{\\top}\n\\end{bmatrix}\n\\]\n上述 SOCP 问题的非线性不等式约束等价于\n\\[\n\\sqrt{(b_2 - \\boldsymbol{a_2}^{\\top}\\boldsymbol{x})^2 + (b_3 -\\boldsymbol{a_3}^{\\top}\\boldsymbol{x})^2} \\leq b_1 - \\boldsymbol{a_1}^{\\top}\\boldsymbol{x}\n\\]\n其中，\n\\[\nA = \\begin{bmatrix}\n0 & 0 & -7  \\\\\n-3 & 0 & 0  \\\\\n0 & -5 & 0\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n6 \\\\\n2 \\\\\n4\n\\end{bmatrix}\n\\]\nscs 包不能求解此类优化问题，下面调用 ECOSolveR 包求解。\n\nlibrary(ROI.plugin.ecos)\nop &lt;- OP(\n  objective = c(1, 1, 0),\n  constraints = C_constraint(\n    L = rbind(\n      c(0, 0, -7),\n      c(-3, 0, 0),\n      c(0, -5, 0)\n    ),\n    cones = K_soc(3), rhs = c(6, 2, 4)\n  ), maximum = TRUE,\n  bounds = V_bound(ld = -Inf, ui = 3, ub = 9, nobj = 3)\n)\nsol &lt;- ROI_solve(op, solver = \"ecos\")\n# 最优解\nsol$solution\n\n#&gt; [1] 19.055671  6.300041  9.000000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 25.35571\n\n\n对决策变量 \\(y_1\\) 添加整数约束，则只有 ECOSolveR 包可以求解。\n\nop &lt;- OP(\n  objective = c(1, 1, 0),\n  constraints = C_constraint(\n    L = rbind(\n      c(0, 0, -7),\n      c(-3, 0, 0),\n      c(0, -5, 0)\n    ),\n    cones = K_soc(3), rhs = c(6, 2, 4)\n  ), maximum = TRUE, \n  # 决策变量约束\n  types = c(\"I\", \"C\", \"C\"), \n  bounds = V_bound(ld = -Inf, ui = 3, ub = 9, nobj = 3)\n)\nsol &lt;- ROI_solve(op, solver = \"ecos\")\n# 最优解\nsol$solution\n\n#&gt; [1] 19.000000  6.355418  9.000000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 25.35542\n\n\n\n27.3.5 指数锥\n指数锥（Exponential Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{expp}} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_2 &gt; 0,x_2\\exp\\big(\\frac{x_1}{x_2}\\big) \\leq x_3\\} \\cup \\{(x_1, 0, x_3) \\in \\mathbb{R}^3 | x_1 \\leq 0, x_3 \\geq 0 \\}\n\\]\n它的对偶如下：\n\\[\n\\mathcal{K}_{\\text{expd}} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1 &lt; 0, - x_1\\exp\\big(\\frac{x_2}{x_1}\\big) \\leq \\exp(1)x_3\\} \\cup \\{(0, x_2, x_3) \\in \\mathbb{R}^3 | x_2 , x_3 \\geq 0 \\}\n\\]\n考虑一个锥优化问题\n\\[\n\\begin{aligned}\n\\max_{(\\boldsymbol{x}, \\boldsymbol{t})} \\quad & x_1 + 2 x_2 \\\\\n\\text{s.t.} \\quad & \\exp(7 + 3x_1 + 5 x_2) \\leq 9 + 11 t_1 + 12t_2 \\\\\n\\quad & x_1,x_2 \\in (-\\infty,20], ~ t_1,t_2 \\in (-\\infty, 50]\n\\end{aligned}\n\\]\n约束条件 \\(\\exp(7 + 3x_1 + 5 x_2) \\leq 9 + 11 t_1 + 12t_2\\) 可以用指数锥来表示\n\\[\n\\begin{aligned}\nu &= 7 + 3y_1 + 5y_2 \\\\\nv &= 1 \\\\\nw &= 9 + 11t_1 + 12t_2\n\\end{aligned}\n\\]\n记 \\(\\boldsymbol{x} = (y_1,y_2,t_1,t_2)^{\\top}\\) ，则线性约束矩阵 \\(A\\) 和约束向量 \\(\\boldsymbol{b}\\) 如下：\n\\[\nA = \\begin{bmatrix}\n-3 & -5 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & -11 & -12\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n7 \\\\\n1 \\\\\n9\n\\end{bmatrix}\n\\]\n指数锥用函数 K_expp() 表示，锥优化问题的代码如下：\n\n# 目标优化\nop &lt;- OP(\n  objective = c(1, 2, 0, 0),\n  # 锥约束\n  constraints = C_constraint(L = rbind(\n    c(-3, -5, 0, 0),\n    c(0, 0, 0, 0),\n    c(0, 0, -11, -12)\n  ), cone = K_expp(1), rhs = c(7, 1, 9)),\n  bounds = V_bound(ld = -Inf, ub = c(20, 20, 50, 50)),\n  maximum = TRUE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 4 with\n#&gt; - 4 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'expp'\n#&gt; - 4 lower and 4 upper non-standard variable bounds.\n\n\n对于锥优化，可以调用 scs 包来求解。\n\n# 调用 scs 包\nlibrary(ROI.plugin.scs)\nsol &lt;- ROI_solve(op, solver = \"scs\")\n# 最优解\nsol$solution\n\n#&gt; [1] -33.3148  20.0000  50.0000  50.0000\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 6.685201\n\n\n\n27.3.6 幂锥\n一个三维幂锥（Power Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{powp}}^{\\alpha} = \\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1,x_2 \\geq 0,x_1^{\\alpha}x_2^{1-\\alpha} \\geq |x_3| \\}, \\alpha \\in [0,1]\n\\]\n它的对偶形式如下：\n\\[\n\\mathcal{K}_{\\text{powp}}^{\\alpha} = \\Big\\{(x_1, x_2,x_3) \\in \\mathbb{R}^3 | x_1,x_2 \\geq 0,\\big(\\frac{x_1}{\\alpha}\\big)^{\\alpha}\\big(\\frac{x_2}{1 - \\alpha}\\big)^{1-\\alpha} \\geq |x_3| \\Big\\}, \\alpha \\in [0,1]\n\\]\n考虑如下锥优化问题\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & 3x_1 + 5 x_2 \\\\\n\\text{s.t.} \\quad & 5 + x_1 \\leq (2 + x_2)^4 \\\\\n\\quad & x_1 \\geq 0, ~ x_2 \\geq 2\n\\end{aligned}\n\\]\n约束条件 \\(5 + x_1 \\leq (2 + x_2)^4\\) 可以重新表示为幂锥\n\\[\n\\begin{aligned}\nu &= 5 + y_1\\\\\nv &= 1 \\\\\nw &= 2 + y_2 \\\\\n\\alpha &= 1/4\n\\end{aligned}\n\\]\n记 \\(\\boldsymbol{x} = (y_1,y_2)^{\\top}\\) ，约束矩阵和约束向量如下\n\\[\nA = \\begin{bmatrix}\n-1  & 0 \\\\\n0   & 0 \\\\\n0   & -1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n5 \\\\\n1 \\\\\n2\n\\end{bmatrix}\n\\]\n幂锥用函数 K_powp() 表示，锥优化问题的代码如下：\n\nA &lt;- rbind(c(-1, 0), c(0, 0), c(0, -1))\ncpowp &lt;- C_constraint(L = A, cones = K_powp(1 / 4), rhs = c(5, 1, 2))\nop &lt;- OP(\n  objective = c(3, 5),\n  constraints = cpowp,\n  bounds = V_bound(lb = c(0, 2))\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 2 with\n#&gt; - 2 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'powp'\n#&gt; - 1 lower and 0 upper non-standard variable bounds.\n\n\n\nsol &lt;- ROI_solve(op, solver = \"scs\", max_iter = 1e6)\n# 最优解\nsol$solution\n\n#&gt; [1] 250.998234   2.000352\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] 762.9965\n\n\n\n27.3.7 半正定锥\n如果矩阵 \\(A\\) 是半正定的，记为 \\(A \\succeq 0\\) ，如果矩阵 \\(A\\) 是正定的，记为 \\(A \\succ 0\\) 。记 \\(n\\) 阶实对称矩阵的集合为 \\(\\mathcal{S}^{n}\\) 。半正定锥（Positive Semi Definite Cone）的定义如下：\n\\[\n\\mathcal{K}_{\\text{psd}}^{n} = \\{A | A \\in \\mathcal{S}^{n}, \\boldsymbol{x}^{\\top}A\\boldsymbol{x} \\geq 0, \\forall \\boldsymbol{x} \\in \\mathbb{R}^n \\}\n\\]\n考虑如下锥优化问题\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & x_1 + x_2 - x_3 \\\\\n\\text{s.t.} \\quad &\nx_1 \\begin{bmatrix}\n10  & 3 \\\\\n3   & 10\n\\end{bmatrix} +\nx_2 \\begin{bmatrix}\n6  & -4 \\\\\n-4   & 10\n\\end{bmatrix} +\nx_3 \\begin{bmatrix}\n8  & 1 \\\\\n1  & 6\n\\end{bmatrix} \\preceq\n\\begin{bmatrix}\n16  & -13 \\\\\n-13  & 60\n\\end{bmatrix}\n\\\\\n\\quad & x_1,x_2,x_3 \\geq 0\n\\end{aligned}\n\\]\n函数 K_psd() 表示半正定锥，函数 vech() 将对称矩阵的上三角部分拉成一个向量。\n\n(A &lt;- toeplitz(x = 3:1))\n\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    3    2    1\n#&gt; [2,]    2    3    2\n#&gt; [3,]    1    2    3\n\nvech(A)\n\n#&gt;      [,1]\n#&gt; [1,]    3\n#&gt; [2,]    2\n#&gt; [3,]    1\n#&gt; [4,]    3\n#&gt; [5,]    2\n#&gt; [6,]    3\n\n\n锥优化的表示如下\n\nF1 &lt;- rbind(c(10, 3), c(3, 10))\nF2 &lt;- rbind(c(6, -4), c(-4, 10))\nF3 &lt;- rbind(c(8, 1), c(1, 6))\nF0 &lt;- rbind(c(16, -13), c(-13, 60))\n# 目标优化\nop &lt;- OP(\n  objective = L_objective(c(1, 1, -1)),\n  constraints = C_constraint(\n    L = vech(F1, F2, F3),\n    cones = K_psd(3),\n    rhs = vech(F0)\n  )\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 3 with\n#&gt; - 3 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type conic.\n#&gt;   |- 3 conic constraints of type 'psd'\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n仍然调用 scs 包求解器。\n\nsol &lt;- ROI_solve(op, solver = \"scs\")\n# 最优解\nsol$solution\n\n#&gt; [1] 5.782736e-06 1.065260e-06 1.486444e+00\n\n# 目标函数值\nsol$objval\n\n#&gt; [1] -1.486437",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-nonlinear-optimization",
    "href": "numerical-optimization.html#sec-nonlinear-optimization",
    "title": "27  数值优化",
    "section": "\n27.4 非线性优化",
    "text": "27.4 非线性优化\n非线性优化按是否带有约束，以及约束是线性还是非线性，分为无约束优化、箱式约束优化、线性约束优化和非线性约束优化。箱式约束可看作是线性约束的特殊情况。\n\nR 软件内置的非线性优化函数\n\n\nnlm()\nnlminb()\nconstrOptim()\noptim()\n\n\n\n无约束\n支持\n支持\n不支持\n支持\n\n\n箱式约束\n不支持\n支持\n支持\n支持\n\n\n线性约束\n不支持\n不支持\n支持\n不支持\n\n\n\nR 软件内置的 stats 包有 4 个数值优化方面的函数，函数 nlm() 可求解无约束优化问题，函数 nlminb() 可求解无约束、箱式约束优化问题，函数 constrOptim() 可求解箱式和线性约束优化。函数 optim() 是通用型求解器，包含多个优化算法，可求解无约束、箱式约束优化问题。尽管这些函数在 R 语言中长期存在，在统计中有广泛的使用，如非线性最小二乘 stats::nls()，极大似然估计 stats4::mle() 和广义最小二乘估计 nlme::gls() 等。但是，这些优化函数的求解能力有重合，使用语法不尽相同，对于非线性约束无能为力，下面仍然主要使用 ROI 包来求解多维非线性优化问题。\n\n27.4.1 一元非线性优化\n求如下一维分段非线性函数的最小值，其函数图像见 图 27.5 ，这个函数是不连续的，更不光滑。\n\\[\nf(x) =\n\\begin{cases}\n10 & x \\in (-\\infty,-1]  \\\\\n\\exp(-\\frac{1}{|x-1|}) & x \\in (-1,4) \\\\\n10 & x \\in [4, +\\infty)\n\\end{cases}\n\\]\n\nfn &lt;- function(x) ifelse(x &gt; -1, ifelse(x &lt; 4, exp(-1 / abs(x - 1)), 10), 10)\n\n\n代码op &lt;- par(mar = c(4, 4, 0.5, 0.5))\ncurve(\n  expr = fn, from = -2, to = 5, lwd = 2,\n  panel.first = grid(),\n  xlab = \"$x$\", ylab = \"$f(x)$\"\n)\non.exit(par(op), add = TRUE)\n\n\n\n\n\n\n图 27.5: 一维函数图像\n\n\n\n\n函数 optimize() 可以求解一元函数的极值问题，默认求极小值，参数 f 表示目标函数，参数 interval 表示搜索在此区间内最小值。函数返回一个列表，元素 minimum 表示极小值点，objective 表示极值点对应的目标函数值。\n\noptimize(f = fn, interval = c(-4, 20), maximum = FALSE)\n\n#&gt; $minimum\n#&gt; [1] 19.99995\n#&gt; \n#&gt; $objective\n#&gt; [1] 10\n\noptimize(f = fn, interval = c(-7, 20), maximum = FALSE)\n\n#&gt; $minimum\n#&gt; [1] 0.9992797\n#&gt; \n#&gt; $objective\n#&gt; [1] 0\n\n\n值得注意，对于不连续的分段函数，在不同的区间内搜索极值，可能获得不同的结果，可以绘制函数图像帮助选择最小值。\n\n27.4.2 多元隐函数优化\n这个优化问题来自 1stOpt 软件的帮助文档，下面利用 R 语言来求该多元隐函数的极值。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} y = & ~\\sin\\Big((yx_1 -0.5)^2 + 2x_1 x_2^2 - \\frac{y}{10} \\Big)\\cdot \\\\\n&~\\exp\\Big(-\\Big( \\big(x_1 - 0.5 -\\exp(-x_2 + y)\\big)^2 + x_2^2 - \\frac{y}{5} + 3 \\Big)\\Big)\n\\end{aligned}\n\\]\n其中， \\(x_1 \\in [-1,7],x_2 \\in [-2,2]\\) 。\n对于隐函数 \\(f(x_1,x_2,y)=0\\) ，常规的做法是先计算隐函数的偏导数，并令偏导数为 0，再求解非线性方程组，得到各个驻点，最后，将驻点代入原方程，比较驻点处函数值，根据优化目标选择最大或最小值。\n\\[\n\\begin{aligned}\n\\frac{\\partial f(x_1,x_2,y)}{\\partial x_1} = 0 \\\\\n\\frac{\\partial f(x_1,x_2,y)}{\\partial x_2} = 0\n\\end{aligned}\n\\]\n如果目标函数很复杂，隐函数偏导数难以计算，可以考虑暴力网格搜索。先估计隐函数值 \\(z\\) 的大致范围，给定 \\(x,y\\) 时，计算一元非线性方程的根。\n\nfn &lt;- function(m) {\n  subfun &lt;- function(x) {\n    f1 &lt;- (m[1] * x - 0.5)^2 + 2 * m[1] * m[2]^2 - x / 10\n    f2 &lt;- -((m[1] - 0.5 - exp(-m[2] + x))^2 + m[2]^2 - x / 5 + 3)\n    x - sin(f1) * exp(f2)\n  }\n  uniroot(f = subfun, interval = c(-1, 1))$root\n}\n\n在位置 \\((1,2)\\) 处函数值为 0.0007368468。\n\n# 测试函数 fn\nfn(m = c(1, 2))\n\n#&gt; [1] 0.0007368468\n\n\n将目标区域网格化，通过一元非线性方程求根的方式获得每个格点处的函数值。\n\ndf &lt;- expand.grid(\n  x1 = seq(from = -1, to = 7, length.out = 81),\n  x2 = seq(from = -2, to = 2, length.out = 41)\n)\n# 计算格点处的函数值\ndf$fn &lt;- apply(df, 1, FUN = fn)\n\n在此基础上，绘制隐函数图像，如 图 27.6 所示，可以获得关于隐函数的大致情况。\n\n代码# 绘图\nwireframe(\n  data = df, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 27.6: 隐函数图像\n\n\n\n\n最后，获得暴力网格搜索的结果，目标函数在 \\((2.8,-0.9)\\) 处取得最小值 \\(-0.02159723\\)。总的来说，这是一个近似结果，如果进一步缩小搜索区域，将网格划分得越细，搜索的结果将越接近全局最小值。\n\ndf[df$fn == min(df$fn), ]\n\n#&gt;      x1   x2          fn\n#&gt; 930 2.8 -0.9 -0.02159723\n\n\n将求隐函数极值的问题转为含非线性等式约束的非线性优化问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & y \\\\\n\\text{s.t.} \\quad & f(x_1,x_2,y) = 0\n\\end{aligned}\n\\]\n由于等式约束非常复杂，手动计算等式约束的雅可比矩阵不可行，可以用 numDeriv 包的函数 jacobian() 计算等式约束的雅可比矩阵。考虑到本例中仅含有一个等式约束，雅可比矩阵退化为梯度向量，这可以用 numDeriv 包的另一个函数 grad() 计算。\n\n# 等式约束\nheq &lt;- function(x) {\n  f1 &lt;- (x[1] * x[3] - 0.5)^2 + 2 * x[1] * x[2]^2 - x[3] / 10\n  f2 &lt;- (x[1] - 0.5 - exp(-x[2] + x[3]))^2 + x[2]^2 - x[3] / 5 + 3\n  x[3] - sin(f1) * exp(-f2)\n}\n# 等式约束的梯度\nheq.jac &lt;- function(x) {\n  numDeriv::grad(func = heq, x = x)\n}\n\n函数 L_objective() 表示含 1 个决策变量的线性目标函数，函数 F_constraint() 表示非线性等式约束。\n\n# 定义优化问题\nop &lt;- OP(\n  objective = L_objective(L = c(0, 0, 1)),\n  constraints = F_constraint(\n    # 等式约束\n    F = list(heq = heq),\n    dir = \"==\",\n    rhs = 0,\n    # 等式约束的雅可比\n    J = list(heq.jac = heq.jac)\n  ),\n  bounds = V_bound(\n    ld = -Inf, ud = Inf,\n    li = c(1, 2), ui = c(1, 2),\n    lb = c(-1, -2), ub = c(7, 2),\n    nobj = 3L\n  ),\n  maximum = FALSE # 求最小\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 3 with\n#&gt; - 3 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 1 constraint of type nonlinear.\n#&gt; - 3 lower and 2 upper non-standard variable bounds.\n\n\n将网格搜索的结果作为初值，继续寻找更优的目标函数值。\n\nnlp &lt;- ROI_solve(op,\n  solver = \"nloptr.slsqp\", start = c(2.8, -0.9, -0.02159723)\n)\n# 最优解\nnlp$solution\n\n#&gt; [1]  2.89826224 -0.85731584 -0.02335409\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] -0.02335409\n\n\n可以发现，更优的目标函数值 \\(-0.02335\\) 在 \\((2.898,-0.8573)\\) 取得。\n\n27.4.3 多元无约束优化\n\n27.4.3.1 示例 1\nRastrigin 函数是一个 \\(n\\) 维优化问题测试函数。\n\\[\n\\min_{\\boldsymbol{x}} \\sum_{i=1}^{n}\\big(x_i^2 - 10 \\cos(2\\pi x_i) + 10\\big)\n\\]\n计算函数值的 R 代码如下：\n\nfn &lt;- function(x) {\n  sum(x^2 - 10 * cos(2 * pi * x) + 10)\n}\n\n绘制二维情形下的 Rastrigin 函数图像，如 图 27.7 所示，这是一个多模态的函数，有许多局部极小值。如果采用 BFGS 算法寻优容易陷入局部极值点。\n\n代码df &lt;- expand.grid(\n  x = seq(-4, 4, length.out = 151),\n  y = seq(-4, 4, length.out = 151)\n)\n\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 27.7: 二维 Rastrigin 函数图像\n\n\n\n\n不失一般性，考虑函数维数 \\(n=20\\) ，决策变量 \\(x_i \\in [-50,50], i = 1,2,\\ldots,n\\) 的情况。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 20L),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 20L)\n)\n\n调全局优化器求解优化问题。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\n# 最优解\nnlp$solution\n\n#&gt;  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 0\n\n\n\n代码# R 语言内置的非线性优化函数\n# 无约束\nnlm(f = fn, p = rep(1, 20))\noptim(par = rep(1, 20), fn = fn, method = \"BFGS\")\noptim(par = rep(1, 20), fn = fn, method = \"Nelder-Mead\")\n\n# 箱式约束\noptim(par = rep(1, 20), fn = fn, \n      lower = -50, upper = 50, method = \"L-BFGS-B\")\nnlminb(start = rep(1, 20), objective = fn, lower = -50, upper = 50)\nconstrOptim(\n  theta = rep(1, 20), f = fn, grad = NULL,\n  ui = rbind(diag(rep(1, 20)), diag(rep(-1, 20))),\n  ci = c(rep(-50, 20), rep(-50, 20))\n)\n\n\n\n27.4.3.2 示例 2\n下面这个优化问题来自 1stOpt 软件帮助手册，是一个无约束非线性优化问题，它的目标函数非常复杂，一般的求解器都无法求解。最优解在 \\((7.999982, 7.999982)\\) 取得，目标函数值为 -7.978832。\n\\[\n\\begin{aligned}\n  & \\min_{\\boldsymbol{x}} ~ \\cos(x_1)\\cos(x_2) - \\sum_{i=1}^{5}\\Big( (-1)^i \\cdot i \\cdot 2 \\cdot \\exp\\big(-500 \\cdot ( (x_1 - i \\cdot 2)^2 + (x_2 - i\\cdot 2)^2 ) \\big) \\Big)\n\\end{aligned}\n\\]\n目标函数分两步计算，先计算累加部分的通项，然后代入计算目标函数。\n\nsubfun &lt;- function(i, m) {\n  (-1)^i * i * 2 * exp(-500 * ((m[1] - i * 2)^2 + (m[2] - i * 2)^2))\n}\nfn &lt;- function(x) {\n  cos(x[1]) * cos(x[2]) -\n    sum(mapply(FUN = subfun, i = 1:5, MoreArgs = list(m = x)))\n}\n\n直观起见，绘制目标函数在区域 \\([-50, 50] \\times [-50, 50]\\) 内的图像，如 图 27.8 (a) 所示，可以看到几乎没有变化的梯度，给寻优过程带来很大困难。再将区域 \\([0, 12] \\times [0, 12]\\) 上的三维图像绘制出来，如 图 27.8 (b) 所示，可见，有不少局部陷阱，且分布在 \\(x_2 = x_1\\) 的直线上。\n代码df &lt;- expand.grid(\n  x = seq(-50, 50, length.out = 101),\n  y = seq(-50, 50, length.out = 101)\n)\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\ndf &lt;- expand.grid(\n  x = seq(0, 12, length.out = 151),\n  y = seq(0, 12, length.out = 151)\n)\ndf$fnxy &lt;- apply(df, 1, fn)\nwireframe(\n  data = df, fnxy ~ x * y,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]),\n  ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90), alpha = 0.75, \n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n\n\n\n(a) 区域 \\([-50,50]\\times[-50,50]\\) 内的函数图像\n\n\n\n\n\n\n\n\n\n\n\n(b) 区域 \\([0,12]\\times[0,12]\\) 内的函数图像\n\n\n\n\n\n\n图 27.8: 局部放大前后的函数图像\n\n\n不失一般性，下面考虑 \\(x_1,x_2 \\in [-50,50]\\) ，面对如此复杂的函数，调用全局优化器 nloptr.directL 寻优。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 2L),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 2L)\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\nnlp$solution\n\n#&gt; [1] 22.22222  0.00000\n\nnlp$objval\n\n#&gt; [1] -0.9734211\n\n\n结果还是陷入局部最优解。运筹优化方面的商业软件，著名的有 Lingo 和 Matlab，下面采用 Lingo 20 求解，Lingo 代码如下：\nSETS:\nP/1..5/;\nEndsets\nMin=@cos(x1) * @cos(x2) - @Sum(P(j): (-1)^j * j * 2 * @exp(-500 * ((x1 - j * 2)^2 + (x2 - j * 2)^2)));\n@Bnd(-50, x1, 50);\n@Bnd(-50, x2, 50);\n启用全局优化求解器后，在 \\((x_1 = 7.999982, x_2 = 7.999982)\\) 取得最小值 -7.978832。而默认未启用全局优化求解器的情况下，在 \\((x_1 = 18.84956, x_2 = -40.84070)\\) 取得局部极小值 -1.000000。\n在这种情况下，数值优化算法遇到瓶颈，可以采用一些全局随机优化算法，比如 GA 包 (Scrucca 2013) 实现的遗传算法。经过对参数的一些调优，可以获得与商业软件几乎一样的结果。\n\nnlp &lt;- GA::ga(\n  type = \"real-valued\",\n  fitness = function(x) -fn(x),\n  lower = c(0, 0), upper = c(12, 12),\n  popSize = 500, maxiter = 100, \n  monitor = FALSE, seed = 20232023\n)\n# 最优解\nnlp@solution\n\n#&gt;            x1       x2\n#&gt; [1,] 7.999982 7.999981\n\n# 目标函数值\nnlp@fitnessValue\n\n#&gt; [1] 7.978832\n\n\n其中，参数 type 指定决策变量的类型，type = \"real-valued\" 表示目标函数中的决策变量是实值连续的，参数 fitness 是目标函数，函数 ga() 对目标函数求极大，所以，对当前优化问题，添加了一个负号。 参数 popSize 控制种群大小，值越大，运行时间越长，搜索范围越广，获得的全局优化解越好。对于复杂的优化问题，可以不断增加种群大小来寻优，直至增加种群大小也不能获得更好的解。参数 maxiter 控制种群进化的次数，值越大，搜索次数可以越多，获得的解越好。参数 popSize 的影响大于参数 maxiter ，减少陷入局部最优解（陷阱）的可能。根据已知条件尽可能缩小可行域，以减少种群数量，进而缩短算法迭代时间。\n\n27.4.4 多元箱式约束优化\n有如下带箱式约束的多元非线性优化问题，该示例来自函数 nlminb() 的帮助文档，如果没有箱式约束，全局极小值点在 \\((1,1,\\cdots,1)\\) 处取得。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & (x_1 - 1)^2 + 4\\sum_{i =1}^{n -1}(x_{i+1} -x_i^2)^2  \\\\\n  \\text{s.t.} \\quad &  2 \\leq x_1,x_2,\\cdots,x_n \\leq 4\n\\end{aligned}\n\\]\nR 语言编码的函数代码如下：\n\nfn &lt;- function(x) {\n  n &lt;- length(x)\n  sum(c(1, rep(4, n - 1)) * (x - c(1, x[-n])^2)^2)\n}\n\n在二维的情形下，可以绘制目标函数的三维图像，见 图 27.9 ，函数曲面和香蕉函数有些相似。\n\n代码dat &lt;- expand.grid(\n  x1 = seq(from = 0, to = 4, length.out = 41),\n  x2 = seq(from = 0, to = 4, length.out = 41)\n)\ndat$fn &lt;- apply(dat, 1, fn)\n\nwireframe(\n  data = dat, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 27.9: 类香蕉函数的曲面图\n\n\n\n\nBase R 有 3 个函数可以求解这个优化问题，分别是 nlminb() 、constrOptim()和optim() ，因此，不妨在这个示例上，用这 3 个函数分别求解该优化问题，介绍它们的用法，最后，介绍 ROI 包实现的方法。这个优化问题的目标函数是 \\(n\\) 维非线性的，不失一般性，又不让问题变得太过简单，下面考虑 25 维的情况，\n\n27.4.4.1 nlminb()\n\n函数 nlminb() 参数 start 指定迭代初始值，参数 objective 指定目标函数，参数 lower 和 upper 分别指定箱式约束中的下界和上界。给定初值 \\((3, 3, \\cdots, 3)\\)，下界 \\((2,2,\\cdots,2)\\) 和上界 \\((4,4,\\cdots,4)\\) 。nlminb() 帮助文档说该函数出于历史兼容性的原因尚且存在，一般来说，这个函数会一直维护下去的。\n\nnlminb(\n  start = rep(3, 25), objective = fn,\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093\n#&gt; [25] 4.000000\n#&gt; \n#&gt; $objective\n#&gt; [1] 368.1059\n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $iterations\n#&gt; [1] 6\n#&gt; \n#&gt; $evaluations\n#&gt; function gradient \n#&gt;       10      177 \n#&gt; \n#&gt; $message\n#&gt; [1] \"relative convergence (4)\"\n\n\n从返回结果来看，求解过程成功收敛，最优解的前 23 个决策变量取值为 2，在箱式约束的边界上，第 24 个分量没有边界上，而在内部，第 25 个决策变量取值为 4，也在边界上。目标函数值为 368.1059。\n\n27.4.4.2 constrOptim()\n\n使用 constrOptim() 函数求解，默认求极小，需将箱式或线性不等式约束写成矩阵形式，即 \\(Ax \\geq b\\) 的形式，参数 ui 是 \\(k \\times n\\) 的约束矩阵 \\(A\\)，ci 是右侧 \\(k\\) 维约束向量 \\(b\\)。以上面的优化问题为例，将箱式约束 \\(2 \\leq x_1,x_2 \\leq 4\\) 转化为矩阵形式，约束矩阵和向量分别为：\n\\[\nA = \\begin{bmatrix}\n1  & 0  \\\\\n0  & 1 \\\\\n-1 & 0 \\\\\n0  & -1\n\\end{bmatrix}, \\quad\nb = \\begin{bmatrix}\n2 \\\\\n2 \\\\\n-4 \\\\\n-4\n\\end{bmatrix}\n\\]\n\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  method = \"Nelder-Mead\", # 没有提供梯度，则必须用 Nelder-Mead 方法\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.006142 2.002260 2.003971 2.003967 2.004143 2.004255 2.001178 2.002990\n#&gt;  [9] 2.003883 2.006029 2.017345 2.009236 2.000949 2.007793 2.025831 2.007896\n#&gt; [17] 2.004514 2.004381 2.008771 2.015695 2.005803 2.009127 2.017988 2.257782\n#&gt; [25] 3.999846\n#&gt; \n#&gt; $value\n#&gt; [1] 378.4208\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    12048       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 1\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 25\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003278963\n\n\n返回结果中 convergence = 1 表示迭代次数到达默认的极限 maxit = 500 。参考函数 nlminb() 的求解结果，可知还没有收敛。如果没有提供梯度，则必须用 Nelder-Mead 方法，下面增加迭代次数到 1000。\n\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  method = \"Nelder-Mead\", \n  control = list(maxit = 1000),\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.000081 2.000142 2.001919 2.000584 2.000007 2.000003 2.001097 2.001600\n#&gt;  [9] 2.000207 2.000042 2.000250 2.000295 2.000580 2.002165 2.000453 2.000932\n#&gt; [17] 2.000456 2.000363 2.000418 2.000474 2.009483 2.001156 2.003173 2.241046\n#&gt; [25] 3.990754\n#&gt; \n#&gt; $value\n#&gt; [1] 370.8601\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;    18036       NA \n#&gt; \n#&gt; $convergence\n#&gt; [1] 1\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 19\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003366467\n\n\n结果有改善，目标函数值从 378.4208 减小到 370.8601，但还是没有收敛，可见 Nelder-Mead 方法在这个优化问题上收敛速度比较慢。下面考虑调用基于梯度的 BFGS 优化算法，这得先计算出来目标函数的梯度。\n\n# 输入 n 维向量，输出 n 维向量\ngr &lt;- function(x) {\n  n &lt;- length(x)\n  c(2 * (x[1] - 2), rep(0, n - 1))\n  +8 * c(0, x[-1] - x[-n]^2)\n  -16 * c(x[-n], 0) * c(x[-1] - x[-n]^2, 0)\n}\nconstrOptim(\n  theta = rep(3, 25), # 初始值\n  f = fn, # 目标函数\n  grad = gr,\n  method = \"BFGS\", \n  control = list(maxit = 1000),\n  ui = rbind(diag(rep(1, 25)), diag(rep(-1, 25))),\n  ci = c(rep(2, 25), rep(-4, 25))\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000001\n#&gt; [25] 3.000000\n#&gt; \n#&gt; $value\n#&gt; [1] 373\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;     3721      464 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 3\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.003327104\n\n\n从结果来看，虽然已经收敛，但相比于 Nelder-Mead 方法，目标函数值变大了，可见已陷入局部最优解。\n\n27.4.4.3 optim()\n\n下面再使用函数 optim() 提供的 L-BFGS-B 算法求解优化问题。\n\noptim(\n  par = rep(3, 25), fn = fn, gr = NULL, method = \"L-BFGS-B\",\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093\n#&gt; [25] 4.000000\n#&gt; \n#&gt; $value\n#&gt; [1] 368.1059\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;        6        6 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH\"\n\n\n发现结果和函数 nlminb() 的结果差不多了。\n\noptim(\n  par = rep(3, 25), fn = fn, gr = gr, method = \"L-BFGS-B\",\n  lower = rep(2, 25), upper = rep(4, 25)\n)\n\n#&gt; $par\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n#&gt; \n#&gt; $value\n#&gt; [1] 373\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;        2        2 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"CONVERGENCE: NORM OF PROJECTED GRADIENT &lt;= PGTOL\"\n\n\n然而，当在函数 optim() 里提供梯度信息的时候，虽然目标函数及梯度的计算次数变少了，求解速度提升了，但是最优解反而变差了，最优解和在函数 constrOptim() 中设置 method = \"BFGS\" 算法基本一致。\n\n27.4.4.4 ROI 包\n下面通过 ROI 包，分别调用求解器 nloptr.lbfgs 和 nloptr.directL ，发现前者同样陷入局部最优解，而后者可以获得与 nlminb() 函数一致的结果。\n\nop &lt;- OP(\n  objective = F_objective(fn, n = 25L, G = gr),\n  bounds = V_bound(ld = 2, ud = 4, nobj = 25L)\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.lbfgs\", start = rep(3, 25))\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 373\n\n# 最优解\nnlp$solution\n\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n\n\n调全局优化算法。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 368.1059\n\n# 最优解\nnlp$solution\n\n#&gt;  [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt;  [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000\n#&gt; [17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109096\n#&gt; [25] 4.000000\n\n\n\n27.4.5 多元线性约束优化\n对于带线性约束的多元非线性优化问题，Base R 提供函数 constrOptim() 来求解，下面的示例来自其帮助文档，这是一个带线性约束的二次规划问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}}\n\\quad &  - \\begin{bmatrix}\n0 \\\\\n5 \\\\\n0\n\\end{bmatrix}^{\\top} \\boldsymbol{x} +\\frac{1}{2} \\boldsymbol{x}^{\\top}\\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\begin{bmatrix}\n-4  &  2  &  0 \\\\\n-3  &  1  & -2 \\\\\n0  &  0  &  1\n\\end{bmatrix}^{\\top}\\boldsymbol{x} \\geq \\begin{bmatrix}\n-8 \\\\\n2 \\\\\n0\n\\end{bmatrix}\n\\end{aligned}\n\\]\n\nfQP &lt;- function(x) {\n  -sum(c(0, 5, 0) * x) + 0.5 * sum(x * x)\n}\nAmat &lt;- matrix(c(-4, -3, 0, 2, 1, 0, 0, -2, 1),\n  ncol = 3, nrow = 3, byrow = FALSE\n)\nbvec &lt;- c(-8, 2, 0)\n# 目标函数的梯度\ngQP &lt;- function(x) {\n  -c(0, 5, 0) + x\n}\nconstrOptim(\n  theta = c(2, -1, -1), \n  f = fQP, g = gQP, \n  ui = t(Amat), ci = bvec\n)\n\n#&gt; $par\n#&gt; [1] 0.4761908 1.0476188 2.0952376\n#&gt; \n#&gt; $value\n#&gt; [1] -2.380952\n#&gt; \n#&gt; $counts\n#&gt; function gradient \n#&gt;      406       81 \n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; NULL\n#&gt; \n#&gt; $outer.iterations\n#&gt; [1] 3\n#&gt; \n#&gt; $barrier.value\n#&gt; [1] -0.0006243894\n\n\n在上一节，箱式约束可以看作线性约束的一种特殊情况，ROI 包是支持箱式、线性、二次、锥和非线性约束的。因此，下面给出调用 ROI 包求解上述优化问题的代码。\n\nDmat &lt;- diag(rep(1,3))\ndvec &lt;- c(0, 5, 0)\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = -dvec),\n  constraints = L_constraint(L = t(Amat), dir = rep(\"&gt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(0, 1, 2))\n# 最优解\nnlp$solution\n\n#&gt; [1] 0.4761905 1.0476190 2.0952381\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] -2.380952\n\n\n可见输出结果与函数 constrOptim() 是一致的。\n\n代码# quadprog\nlibrary(quadprog)\nsol &lt;- solve.QP(\n  Dmat = Dmat, dvec = dvec, Amat = Amat, bvec = bvec\n)\nsol\n\n\n\n27.4.6 多元非线性约束优化\nnloptr 包的非线性优化能力覆盖开源优化软件 Octave 和 Ipopt 。通过插件包 ROI.plugin.nloptr，ROI 包可以调用 nloptr 包内置的所有求解器，常用的求解器见下表。表中从优化器类型（局部还是全局优化器），支持的约束条件类型（箱式还是非线性），是否需要提供目标函数的梯度、黑塞和约束条件的雅可比矩阵信息等方面归纳各个求解器的能力。\n\n常用的非线性优化求解器\n\n求解器\n类型\n约束\n梯度\n黑塞\n雅可比\n\n\n\nnloptr.lbfgs\n局部\n箱式\n需要\n不需要\n不需要\n\n\nnloptr.slsqp\n局部\n非线性\n需要\n不需要\n需要\n\n\nnloptr.auglag\n局部\n非线性\n需要\n不需要\n需要\n\n\nnloptr.directL\n全局\n箱式\n不需要\n不需要\n不需要\n\n\nnloptr.isres\n全局\n非线性\n不需要\n不需要\n不需要\n\n\n\n\n27.4.6.1 非线性等式约束\n下面这个示例来自 Octave 软件的非线性优化帮助文档，Octave 中的函数 sqp() 使用序列二次优化求解器（successive quadratic programming solver）求解非线性优化问题，示例中该优化问题包含多个非线性等式约束。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad &  \\exp\\big(\\prod_{i=1}^{5} x_i\\big) - \\frac{1}{2}(x_1^3 + x_2^3 + 1)^2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n   \\sum_{i=1}^{5}x_i^2 - 10 = 0 \\\\\n   x_2 x_3 - 5x_4 x_5 = 0 \\\\\n   x_1^3 + x_2^3 + 1 = 0\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n目标函数是非线性的，有 5 个变量，约束条件也是非线性的，有 3 个等式约束。先手动计算目标函数的梯度，等式约束的雅可比矩阵。\n\n# 目标函数\nfn &lt;- function(x) {\n  exp(prod(x)) - 0.5 * (x[1]^3 + x[2]^3 + 1)^2\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    exp(prod(x)) * prod(x[-1]) - 3 * (x[1]^3 + x[2]^3 + 1) * x[1]^2,\n    exp(prod(x)) * prod(x[-2]) - 3 * (x[1]^3 + x[2]^3 + 1) * x[2]^2,\n    exp(prod(x)) * prod(x[-3]),\n    exp(prod(x)) * prod(x[-4]),\n    exp(prod(x)) * prod(x[-5])\n  )\n}\n# 等式约束\nheq &lt;- function(x) {\n  c(\n    sum(x^2) - 10,\n    x[2] * x[3] - 5 * x[4] * x[5],\n    x[1]^3 + x[2]^3 + 1\n  )\n}\n# 等式约束的雅可比矩阵\nheq.jac &lt;- function(x) {\n  matrix(c(2 * x[1], 2 * x[2], 2 * x[3], 2 * x[4], 2 * x[5],\n    0, x[3], x[2], -5 * x[5], -5 * x[4],\n    3 * x[1]^2, 3 * x[2]^2, 0, 0, 0),\n    ncol = 5, byrow = TRUE\n  )\n}\n\n在 OP() 函数里定义目标优化的各个成分。\n\n# 定义目标优化\nop &lt;- OP(\n  # 5 个决策变量\n  objective = F_objective(F = fn, n = 5L, G = gr), \n  constraints = F_constraint(\n    F = list(heq = heq),\n    dir = \"==\",\n    rhs = 0,\n    # 等式约束的雅可比矩阵\n    J = list(heq.jac = heq.jac)\n  ),\n  bounds = V_bound(ld = -Inf, ud = Inf, nobj = 5L),\n  maximum = FALSE # 求最小\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a nonlinear objective function of length 5 with\n#&gt; - 5 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 1 constraint of type nonlinear.\n#&gt; - 5 lower and 0 upper non-standard variable bounds.\n\n\n调用 SQP（序列二次优化） 求解器 nloptr.slsqp 。\n\nnlp &lt;- ROI_solve(op,\n  solver = \"nloptr.slsqp\",\n  start = c(-1.8, 1.7, 1.9, -0.8, -0.8)\n)\n# 最优解\nnlp$solution\n\n#&gt; [1] -1.7171435  1.5957096  1.8272458 -0.7636431 -0.7636431\n\n# 目标函数值\nnlp$objval\n\n#&gt; [1] 0.05394985\n\n\n计算结果和 Octave 的示例一致。\n\n27.4.6.2 多种非线性约束\n\n非线性等式约束\n非线性不等式约束，不等式约束包含等号\n箱式约束\n\n此优化问题来源于 Ipopt 官网的帮助文档，约束条件比较复杂。提供的初始值为 \\(x_0 = (1,5,5,1)\\)，最优解为 \\(x_{\\star} = (1.00000000,4.74299963,3.82114998,1.37940829)\\)。优化问题的具体内容如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} & \\quad x_1 x_4 (x_1 + x_2 + x_3) + x_3 \\\\\n\\text{s.t.} & \\quad \\left\\{\n    \\begin{array}{l}\n     x_1^2 + x_2^2 + x_3^2 + x_4^2 = 40 \\\\\n     x_1 x_2 x_3 x_4 \\geq 25 \\\\\n     1 \\leq x_1, x_2, x_3, x_4 \\leq 5\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n下面用 ROI 调 nloptr 包求解，看结果是否和例子一致，nloptr 支持箱式约束且支持不等式约束包含等号。\n\n# 一个 4 维的目标函数\nfn &lt;- function(x) {\n  x[1] * x[4] * (x[1] + x[2] + x[3]) + x[3]\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    x[4] * (2 * x[1] + x[2] + x[3]), x[1] * x[4],\n    x[1] * x[4] + 1, x[1] * (x[1] + x[2] + x[3])\n  )\n}\n# 等式约束\nheq &lt;- function(x) {\n  sum(x^2)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  2 * c(x[1], x[2], x[3], x[4])\n}\n# 不等式约束\nhin &lt;- function(x) {\n  prod(x)\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x) {\n  c(prod(x[-1]), prod(x[-2]), prod(x[-3]), prod(x[-4]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, n = 4L, G = gr), # 4 个决策变量\n  constraints = F_constraint(\n    F = list(heq = heq, hin = hin),\n    dir = c(\"==\", \"&gt;=\"),\n    rhs = c(40, 25),\n    # 等式和不等式约束的雅可比\n    J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n  ),\n  bounds = V_bound(ld = 1, ud = 5, nobj = 4L),\n  maximum = FALSE # 求最小\n)\n\n作为对比参考，先计算目标函数的初始值和最优值。\n\n# 目标函数初始值\nfn(c(1, 5, 5, 1))\n\n#&gt; [1] 16\n\n# 目标函数最优值\nfn(c(1.00000000, 4.74299963, 3.82114998, 1.37940829))\n\n#&gt; [1] 17.01402\n\n\n求解一般的非线性约束问题。\n\n求解器 nloptr.mma / nloptr.cobyla 仅支持非线性不等式约束，不支持等式约束。\n函数 nlminb() 只支持等式约束。\n\n因此，下面分别调用 nloptr.auglag、nloptr.slsqp 和 nloptr.isres 来求解上述优化问题。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.auglag\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.000000 4.743174 3.820922 1.379440\n\nnlp$objval\n\n#&gt; [1] 17.01402\n\n\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.000000 4.742996 3.821155 1.379408\n\nnlp$objval\n\n#&gt; [1] 17.01402\n\n\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.isres\", start = c(1, 5, 5, 1))\nnlp$solution\n\n#&gt; [1] 1.627671 4.715803 2.887018 2.603300\n\nnlp$objval\n\n#&gt; [1] 41.99952\n\n\n可以看出，nloptr 提供的优化能力可以覆盖 Ipopt 求解器，从以上求解的情况来看，推荐使用 nloptr.slsqp 求解器，这也是 Octave 的选择。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-integer-linear-optimization",
    "href": "numerical-optimization.html#sec-integer-linear-optimization",
    "title": "27  数值优化",
    "section": "\n27.5 整数优化",
    "text": "27.5 整数优化\n整数优化情况有很多，篇幅所限，仅考虑以下几类常见情形：\n\n目标函数和约束条件为线性，变量取值都为整数的整数优化。\n目标函数和约束条件为线性，变量取值为 0 或 1 的 0-1 整数优化。\n目标函数和约束条件为线性，部分变量带有整数约束的混合整数线性优化。\n目标函数为凸二次、约束条件为线性，部分变量是整数的混合整数二次优化。\n目标函数和约束条件为非线性，部分变量是整数的混合整数非线性优化。\n\n\n27.5.1 纯整数线性优化\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & -2x_1 - x_2 - 4x_3 -3x_4 -x_5\\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    2x_2 + x_3 + 4x_4 + 2x_5 &lt; 54 \\\\\n    3x_1 + 4x_2 + 5x_3 - x_4 - x_5 &lt; 62 \\\\\n    x_1,x_2 \\in [0,100] \\quad x_3 \\in [3, 100] \\\\\n    x_4 \\in [0,100] \\quad x_5 \\in [2,100] \\\\\n    x_i \\in \\mathbb{Z}, ~ i = 1,2,\\cdots,5.\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n求解器 glpk 还可以求解一些整数优化问题。\n\nop &lt;- OP(\n  objective = L_objective(c(-2, -1, -4, -3, -1)),\n  types = rep(\"I\", 5),\n  constraints = L_constraint(\n    L = matrix(c(\n      0, 2, 1, 4, 2,\n      3, 4, 5, -1, -1\n    ), ncol = 5, byrow = TRUE),\n    dir = c(\"&lt;\", \"&lt;\"),\n    rhs = c(54, 62)\n  ),\n  # 添加约束\n  bounds = V_bound(\n    li = 1:5, ui = 1:5,\n    lb = c(0, 0, 3, 0, 2), ub = rep(100, 5), nobj = 5\n  ),\n  maximum = FALSE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a linear objective function of length 5 with\n#&gt; - 5 integer objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type linear.\n#&gt; - 2 lower and 5 upper non-standard variable bounds.\n\n# 求解\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1] 15  0  6 11  2\n\n# 目标函数值\nres$objval\n\n#&gt; [1] -89\n\n\n可知，最优解在 \\((15,0,6,11,2)\\) 处取得，目标函数值为 -89 。\n注意：还有一组最优解 \\((19,0,4,10,5)\\) ，目标函数值也为 -89 ，但是 glpk 求解器未能给出。\n\n27.5.2 0-1 整数线性优化\n目标函数是线性的，决策变量的取值要么是 0 要么是 1。指派问题属于典型的 0-1 整数优化问题。有 \\(n\\) 个人需要去完成 \\(n\\) 项任务，每个人完成一项任务，每项任务只由一个人完成，每个人单独完成各项任务所需花费（时间、费用）不同。要求设计一个方案，人和任务之间建立一一对应的关系，使得总花费最少。\n设第 \\(i\\) 个人完成第 \\(j\\) 项任务的花费为 \\(d_{ij}\\) ，当安排第 \\(i\\) 个人完成第 \\(j\\) 项任务时，记为 \\(x_{ij} = 1\\) ，否则，记为 \\(x_{ij} = 0\\) ，指派问题的数学模型如下：\n\\[\n\\begin{aligned}\n\\min \\quad & \\sum_{i=1}^{n}\\sum_{j=1}^{n}d_{ij}x_{ij} \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    \\sum_{i=1}^{n} x_{ij} = 1, ~~ j = 1,2,\\ldots,n\\\\\n    \\sum_{j=1}^{n} x_{ij} = 1, ~~ i = 1,2,\\ldots,n\\\\\n    x_{ij} = 0 ~~\\text{或}~~ 1\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n指派问题在 lpSolve 包 (Berkelaar 等 2023) 做了很好的封装，只需提供花费矩阵，即可调用求解器求解该问题。\n\n# 花费矩阵 D\nD &lt;- matrix(c(\n  2, 7, 7, 2,\n  7, 7, 3, 2,\n  7, 2, 8, 10,\n  1, 9, 8, 2\n), nrow = 4, ncol = 4, byrow = F)\n# 加载 lpSolve 包 \nlibrary(lpSolve)\n# 调用指派问题求解器\nsol &lt;- lp.assign(D)\n# 最优解\nsol$solution\n\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    0    0    0    1\n#&gt; [2,]    0    0    1    0\n#&gt; [3,]    0    1    0    0\n#&gt; [4,]    1    0    0    0\n\n# 总花费\nsol$objval\n\n#&gt; [1] 8\n\n\n可以使总花费最少的指派计划是第 1 个人完成第 4 项任务，第 2 个人完成第 3 项任务，第 3 个人完成第 2 项任务，第 4 个人完成第 1 项任务，总花费为 8。\n\n27.5.3 混合整数线性优化\n目标函数是线性的，一部分决策变量是整数。\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{x}} \\quad & 3x_1 + 7x_2 - 12x_3 \\\\\n\\text{s.t.} \\quad & \\left\\{\n  \\begin{array}{l}\n    5x_1 + 7x_2 + 2x_3 \\leq 61\\\\\n    3x_1 + 2x_2 - 9x_3 \\leq 35\\\\\n    x_1 + 3x_2 + x_3 \\leq 31\\\\\n    x_1,x_2 \\geq 0, \\quad x_2, x_3 \\in \\mathbb{Z}, \\quad x_3 \\in [-10, 10]\n  \\end{array} \\right.\n\\end{aligned}\n\\]\n矩阵形式如下\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{x}} \\quad &\n  \\begin{bmatrix}\n  3  \\\\\n  7  \\\\\n  -12\n  \\end{bmatrix}\n  ^{\\top} \\boldsymbol{x} \\\\\n\\text{s.t.} \\quad & \\left\\{\n\\begin{array}{l}\n  \\begin{bmatrix}\n  5 & 7 & 2 \\\\\n  3 & 2 & -9\\\\\n  1 & 3 & 1\n  \\end{bmatrix}\n  \\boldsymbol{x} \\leq\n  \\begin{bmatrix}\n   61 \\\\\n   35 \\\\\n   31\n  \\end{bmatrix}\n\\end{array} \\right.\n\\end{aligned}\n\\]\n第1个变量是连续值，第2、3个变量是整数，第3个变量的下、上界分别是 -10 和 10。\n\nop &lt;- OP(\n  objective = L_objective(c(3, 7, -12)),\n  types = c(\"C\", \"I\", \"I\"),\n  constraints = L_constraint(\n    L = matrix(c(\n      5, 7, 2,\n      3, 2, -9,\n      1, 3, 1\n    ), ncol = 3, byrow = TRUE),\n    dir = c(\"&lt;=\", \"&lt;=\", \"&lt;=\"),\n    rhs = c(61, 35, 31)\n  ),\n  # 添加约束\n  bounds = V_bound(\n    li = 3, ui = 3,\n    lb = -10, ub = 10, nobj = 3\n  ),\n  maximum = TRUE\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 3 with\n#&gt; - 1 continuous objective variable,\n#&gt; - 2 integer objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 3 constraints of type linear.\n#&gt; - 1 lower and 1 upper non-standard variable bound.\n\n# 求解\nres &lt;- ROI_solve(op, solver = \"glpk\")\n# 最优解\nres$solution\n\n#&gt; [1]  0.3333333  8.0000000 -2.0000000\n\nres$objval\n\n#&gt; [1] 81\n\n\n\n27.5.4 混合整数二次优化\n目标函数是二次的，一部分决策变量是整数。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & x_1^2 + x_2^2 - x_1  x_2 + 3  x_1 - 2 x_2 \\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      -x_1 - x_2 &lt;= -2 \\\\\n      x_1 - x_2 &lt;= 2 \\\\\n      x_2 &lt;= 3. \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n在二次优化的基础上，对变量添加整型约束，即变成混合整数二次优化 （Mixed Integer Quadratic Programming，简称 MIQP）。\n\n# D\nDmat &lt;- matrix(c(2, -1, -1, 2), nrow = 2, byrow = TRUE)\n# d\ndvec &lt;- c(3, -2)\n# A\nAmat &lt;- matrix(c(\n  -1, -1,\n  1, -1,\n  0, 1\n), ncol = 2, byrow = TRUE)\n# b\nbvec &lt;- c(-2, 2, 3)\n# 目标优化\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(Amat, rep(\"&lt;=\", 3), bvec),\n  types = c(\"I\", \"C\"),\n  maximum = FALSE # 求最小\n)\n# 查看可用于该优化问题的求解器\nROI_applicable_solvers(op)\n\n#&gt; NULL\n\n\n目前，ROI 包支持的开源求解器都不能处理 MIQP 问题。ECOSolveR 包可以求解凸二阶锥优化，部分变量可以是整数。因此，先将凸二次优化转化为凸锥优化问题，再连接 ECOSolveR 包提供 ecos 求解器，最后，调 ecos 求解器求解。\n\\[\n\\begin{aligned}\n\\min_{(t,\\boldsymbol{x})} \\quad &  t\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\nx_1^2 + x_2^2 - x_1  x_2 + 3  x_1 - 2 x_2 \\leq t \\\\\n      -x_1 - x_2 &lt;= -2 \\\\\n      x_1 - x_2 &lt;= 2 \\\\\n      x_2 &lt;= 3. \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n引入新的变量 \\(t\\) ，原目标函数化为线性，约束条件增加一个二次型。\n\\[\n\\begin{aligned}\n\\min_{(t,\\boldsymbol{x})} \\quad &  t\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      \\boldsymbol{x}^{\\top}D\\boldsymbol{x} + 2\\boldsymbol{d}^{\\top}\\boldsymbol{x} \\leq t \\\\\n      A\\boldsymbol{x} \\leq \\boldsymbol{b} \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n其中，\n\\[\nD = \\begin{bmatrix}\n2 & -1\\\\\n-1 & 2\n\\end{bmatrix}, \\quad\n\\boldsymbol{d} =  \n\\begin{bmatrix}\n3 \\\\\n-2\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n-1 & -1  \\\\\n1 & -1 \\\\\n0  & 1\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n-2 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n最后，凸二次优化转为二阶锥优化 SOCP，形式如下：\n\\[\n\\begin{aligned}\n\\min_{(t^{\\star},\\boldsymbol{x})} \\quad & t^{\\star}\\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      \\|D^{1/2}\\boldsymbol{x} + D^{-1/2}\\boldsymbol{d} \\|_2 \\leq t^{\\star} \\\\\n      A\\boldsymbol{x} \\leq \\boldsymbol{b} \\\\\n      x_1 \\in \\mathbb{Z}\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n代码如下\n\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = c(\n    C_constraint(L, cones = K_soc(3)),\n    L_constraint(Amat, rep(\"&lt;=\", 3), bvec)\n  ),\n  types = c(\"I\", \"C\", \"C\"),\n  maximum = FALSE # 默认求最小\n)\n\n# 调用 ECOSolveR 包\nlibrary(ROI.plugin.ecos)\nnlp &lt;- ROI_solve(op, solver = \"ecos\", start = c(1, 2))\nnlp$objval\nnlp$solution\n\n因二次优化的目标函数是二次连续可微的，而且是凸函数，求解器 Bonmin 可以获得最优解。\nvar x1 integer;\nvar x2;\nminimize z: x1^2 + x2^2 - x1 * x2 + 3 * x1 - 2 * x2;\nsubject to A_limit: -x1 - x2 &lt;= -2;\nsubject to B_limit: x1 - x2 &lt;= 2;\nsubject to C_limit: x2 &lt;= 3;\n\nlibrary(rAMPL)\n# 配置 AMPL 安装路径\nenv &lt;- new(Environment, \"/opt/AMPL/ampl.macos64\")\nampl &lt;- new(AMPL, env)\n# 加载混合整数二次优化模型文件\nampl$read(\"code/MIQP.mod\")\n# 设置 MIQP 求解器 Bonmin\nampl$setOption(\"solver\", \"bonmin\")\n# 求解问题\nampl$solve()\n# 最优解\nampl$getData(\"x1\")\nampl$getData(\"x2\")\n# 目标函数值\nampl$getData(\"z\")\n\n最优解在 \\((0,2)\\) 处获得，最优值为 0。\n\n27.5.5 混合整数非线性优化\n在 R 语言社区的官方仓库中还没有开源的 R 包可以求解此类问题，开源社区中 Bonmin 项目专门求解混合整数非线性优化 MINLP（Mixed Integer Non-Linear Programming）问题。数学优化软件 AMPL 封装了 Bonmin 软件，并提供 R 语言接口 rAMPL。AMPL 社区版可以免费使用打包的开源求解器。\n\n线性优化求解器 HiGHS。\n混合整数线性优化求解器 cbc。\n混合整数非线性优化求解器 Bonmin 和 Couenne。\n非线性优化求解器 Ipopt。\n\n安装 AMPL 社区版软件后，再安装 rAMPL 包，它依赖 Rcpp 包，所以需要一并安装。\ninstall.packages(\"Rcpp\", type = \"source\")\n# 从 AMPL 官网安装 rAMPL 包\ninstall.packages(\"https://ampl.com/dl/API/rAMPL.tar.gz\", repos = NULL,\n  INSTALL_opts = c(\"--no-multiarch\", \"--no-staged-install\")\n)\n下面求解如下混合整数非线性优化问题。\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{x}} \\quad & 1.5(x_1 - \\sin(x_1 -x_2))^2 + 0.5x_2^2 + x_3^2 -x_1 x_2 -2x_1 + x_2 x_3 \\\\\n\\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      x_1,x_2 \\in \\mathbb{R} ~~ x_3 \\in \\mathbb{Z} \\\\\n      x_1,x_2 \\in [-20,20] ~~ x_3 \\in [-10,10].\n    \\end{array} \\right.\n\\end{aligned}\n\\]\nAMPL 模型代码如下：\nvar X1;\nvar X2;\nvar X3 integer;\nminimize z: 1.5 * (X1 - sin(X1 - X2))^2 + 0.5 * X2^2 + X3^2 - X1 * X2 - 2 * X1 + X2 * X3;\nsubject to A_limit: -20 &lt;= X1 &lt;= 20;\nsubject to B_limit: -20 &lt;= X2 &lt;= 20;\nsubject to C_limit: -10 &lt;= X3 &lt;= 10;\n将代码保存到文件 code/MINLP.mod ，下面加载 rAMPL 包，调用求解器 Bonmin 求解该优化问题。\n\nlibrary(rAMPL)\n# 配置 AMPL 安装路径\nenv &lt;- new(Environment, \"/opt/AMPL/ampl.macos64\")\nampl &lt;- new(AMPL, env)\n# 加载混合整数非线性优化模型文件\nampl$read(\"code/MINLP.mod\")\n# 设置 MINLP 求解器 Bonmin\nampl$setOption(\"solver\", \"bonmin\")\n# 求解问题\nampl$solve()\n# 最优解\nampl$getData(\"X1\")\nampl$getData(\"X2\")\nampl$getData(\"X3\")\n# 目标函数值\nampl$getData(\"z\")\n\n如果使用 Bonmin 求解器，该优化问题的最优解在 \\((2.892556, 1.702552, -1)\\) 处获得，相应的目标函数值为 \\(-4.176012\\) 。如果使用求解器 Couenne ，它可以找到非凸混合整数非线性优化问题的全局最优解，Couenne 好于 Bonmin 求解器。\n\n# 调用 couenne 求解器\nampl$setOption(\"solver\", \"couenne\")\n# 求解问题\nampl$solve()\n\n最优解在 \\(x_1 = 4.999633, x_2 = 9.734148, x_3 = -5\\) 处取得，最优值为 \\(-10.96182\\) 。下面将两个最优解代入目标函数，验证一下最优值。\n\nfun &lt;- function(x) {\n  1.5 * (x[1] - sin(x[1] - x[2]))^2 + 0.5 * x[2]^2 +\n    x[3]^2 - x[1] * x[2] - 2 * x[1] + x[2] * x[3]\n}\n# 局部最优解\nfun(x = c(2.892556, 1.702552, -1))\n\n#&gt; [1] -4.176012\n\n# 全局最优解\nfun(x = c(4.999633, 9.734148, -5))\n\n#&gt; [1] -10.96182",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-numerical-optimization-summary",
    "href": "numerical-optimization.html#sec-numerical-optimization-summary",
    "title": "27  数值优化",
    "section": "\n27.6 总结",
    "text": "27.6 总结\n对大部分常规优化问题，都可以纳入 ROI 包的框架内。对少量复杂的优化问题，目前，必须借助开源社区的第三方求解器。\n\n对于含整型变量的凸锥优化问题，scs 包不能求解，ECOSolveR 包可以，它还可以求解可转化为凸二阶锥优化问题的混合整数二次优化问题。\n对于特定问题，比如 0-1 整数线性优化中的指派问题，相比于 ROI 包的大一统调用方式，lpSolve 包给出非常简明的使用语法。对凸二次优化问题，给出 quadprog 包的使用语法，补充说明 nloptr 包的结果，以及与 ROI 包调用语法的差异。\n对于凸的混合整数二次优化和非凸的混合整数非线性优化问题，借助 rAMPL 包分别调用开源的求解器 Bonmin 和 Couenne 求解。\n对于复杂的非线性优化问题，因其具有非凸、多模态等特点，求解非常困难。需要引入随机优化算法，比如采用 GA 包的遗传算法求解，效果可以达到商业软件的水平。\n对于凸优化问题，可以求解得又快又好，而对于非凸优化问题，要么只能获得局部最优解，要么可以搜索全局最优解，但不给保证，而且运行时间长。\n\n优化建模是一个具有基础性和支柱性的任务，几乎每个统计模型和机器学习算法背后都有一个优化问题。在 R 语言社区的优化任务视图 (Schwendinger 和 Borchers 2023) 中，可以看到数以百计的扩展包。非常广阔的应用场景催生了非常丰富的理论。根据目标函数和约束条件的情况，可以从不同的角度划分，如线性和非线性优化，连续和离散优化，确定性和随机优化，凸优化和非凸优化等。相关的理论著作非常多，感兴趣的读者可以根据自身情况找本教材系统性地学习。本章结构是按照优化问题分类组织的，主要涉及确定性的数值优化，因部分优化问题比较复杂，因此，也涉及少量的随机优化方法。\n优化建模是一个具有重要商业价值的领域，相关的开源和商业软件有很多，比较流行的有 Python 社区的 Pyomo (Hart, Watson, 和 Woodruff 2011)，Julia 社区的 JuMP (Dunning, Huchette, 和 Lubin 2017)。比较著名的商业软件有 Lingo、Mosek、Gurobi 等，而 AMPL 一个软件平台，对 20 个开源和商业求解器提供一套统一的建模语言，且提供 R、Python 等编程语言接口。\n相比于 Python 和 Julia 社区，R 语言社区在整合开源的优化建模软件方面，还有较长的路要走，ROI 包的出现意味着向整合的路迈出坚实的一步。优化建模的场景具有复杂性和多样性，算法实现更是五花八门，仅线性和整数线性优化方面，就至少有 lpSolve、 Rglpk 和 highs (Schwendinger 和 Schumacher 2023)等包，更别提非线性优化方面。这就又出现一个问题，对一个优化问题，采用何种算法及算法实现具有最好的效果，满足可用性、可靠性。尽管涉及数学和统计，但高质量的软件工具更是一个工程问题。\n从数据分析的角度来说，无论是 Python，还是 Julia，甚至于底层的 C++ 库，都不过是软件工具，首要问题是将实际问题转化为统计或数学模型，这需要抓住主要问题的关键因素，只有先做好建模的工作才能实现工具到商业价值的转化。",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "numerical-optimization.html#sec-numerical-optimization-exercises",
    "href": "numerical-optimization.html#sec-numerical-optimization-exercises",
    "title": "27  数值优化",
    "section": "\n27.7 习题",
    "text": "27.7 习题\n\n求解线性优化和整数线性优化的 R 包有很多，从使用语法、可求解的问题规模和问题类型比较 lpSolve、Rglpk 和 highs 等 R 包。\n求解非线性优化问题的 R 包有很多，其中有一些通过 Rcpp 包打包、调用 C++ 库，比如 RcppEnsmallen、RcppNumerical 等包，还有的 C++ 库提供头文件，可以在 C++ 环境中直接调用，比如 optim 库。通过 R 和 C++ 混合编程，一则引入更加庞大的开源社区，二则扩展求解非线性优化问题的规模和性能。请从求解问题类型、规模和性能等方面比较 5 个比较流行的 C++ 库。\n\n回顾凸二次优化一节，当矩阵 \\(D\\) 为半正定矩阵时，二次优化是非严格凸二次优化。调整示例里目标函数中的矩阵 \\(D\\) 使其行列式等于 0，其它条件不变。使用 ROI 包调用合适的优化求解器求解此类问题。\n\n代码# 非严格凸的二次优化问题\n# 凸二次优化一节的示例 矩阵 D 的行列式为 0\nDmat &lt;- matrix(c(2, 1, 4, 2), nrow = 2, byrow = TRUE)\ndvec &lt;- c(3, -2)\nAmat &lt;- matrix(c(-1, -1, 1, -1, 0, 1), ncol = 2, byrow = TRUE)\nbvec &lt;- c(-2, 2, 3)\nop &lt;- OP(\n  objective = Q_objective(Q = Dmat, L = dvec),\n  constraints = L_constraint(L = Amat, dir = rep(\"&lt;=\", 3), rhs = bvec),\n  maximum = FALSE\n)\nop\n# 调用 SQP 序列二次优化求解器\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1, 2))\n# 目标函数值 0 \nnlp$objval\n# 最优解 (0, 2)\nnlp$solution\n\n\n\n\n求解如下 2 维非线性无约束优化问题。\n\\[\n\\min_{\\boldsymbol{x}} \\quad 100 (x_2 -x_1^2)^2 + (1-x_1)^2\n\\]\n\n代码# Rosenbrock Banana function\n# 目标函数\nfr &lt;- function(x) {\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  100 * (x2 - x1 * x1)^2 + (1 - x1)^2\n}\n# 目标函数的梯度\ngrr &lt;- function(x) {\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  c(\n    -400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),\n    200 * (x2 - x1 * x1)\n  )\n}\n# 求解\nnlminb(start = c(-1.2, 1), objective = fr, gradient = grr)\n# 或者\noptim(par = c(-1.2, 1), fn = fr, gr = grr, method = \"L-BFGS-B\")\n\n\n\n\n求解如下 \\(n\\) 维非线性箱式约束优化问题。\n\\[\n\\min_{\\boldsymbol{x}} \\quad \\exp\\big( - \\sum_{i=1}^{n}(\\frac{x_i}{\\beta})^{2m}\\big)  - 2\\exp(- \\sum_{i=1}^{n}x_i^2)\\prod_{i=1}^{n} \\cos^2(x_i)\n\\]\n其中，\\(\\beta.=15, m = 3\\) ，\\(x_i \\in [-20,20], i = 1,2,\\ldots,n\\) 。请读者分别考虑 \\(n= 2\\) 和 \\(n = 4\\) 的情况。（全局最优解在 \\(x_i = 0, i = 1,2,\\ldots,n\\) 处取得，最优值为 \\(-1\\) 。）\n\n\n求解如下非线性约束优化问题。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & \\exp(\\sin(50 x_1)) + \\sin(60\\exp(x_2)) + \\sin(70\\sin(x_1)) \\\\\n         \\quad & + \\sin(\\sin(80x_2)) - \\sin(10(x_1 +x_2)) + \\frac{(x_1^2 + x_2^2)^{\\sin(x_2)}}{4} \\\\\n    \\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n     x_1 - \\big((\\cos(x_2))^{x_1} - x_1\\big)^{x_2} \\leq 0 \\\\\n    -50 \\leq x_1,x_2 \\leq 50\n    \\end{array} \\right.\n\\end{aligned}\n\\]\n目标函数是不连续的，其函数图像如 图 27.10 所示。（提示：容错能力低的求解器一般无法求解。Lingo 给出一个局部最优解 \\((-46.14402, -0.8879601)\\) ，目标函数值为 \\(-2.645518\\) ，仅供参考。）\n\n代码fn &lt;- function(x) {\n  exp(sin(50 * x[1])) + sin(60 * exp(x[2])) +\n    sin(70 * sin(x[1])) + sin(sin(80 * x[2])) -\n    sin(10 * (x[1] + x[2])) + (x[1]^2 + x[2]^2)^(sin(x[2])) / 4\n}\n\ndf &lt;- expand.grid(\n  x1 = seq(from = 0.8, to = 1.4, length.out = 81),\n  x2 = seq(from = 0, to = 0.4, length.out = 41)\n)\n# 计算格点处的函数值\ndf$fn &lt;- apply(df, 1, FUN = fn)\n\n# 绘图\nwireframe(\n  data = df, fn ~ x1 * x2,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(x[1]), ylab = expression(x[2]),\n  zlab = list(expression(\n    italic(f) ~ group(\"(\", list(x[1], x[2]), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 27.10: 目标函数的曲面图\n\n\n\n\n\n代码fn &lt;- function(x) {\n  exp(sin(50 * x[1])) + sin(60 * exp(x[2])) +\n    sin(70 * sin(x[1])) + sin(sin(80 * x[2])) -\n    sin(10 * (x[1] + x[2])) + (x[1]^2 + x[2]^2)^(sin(x[2])) / 4\n}\ngr &lt;- function(x){\n  numDeriv::grad(fn, c(x[1], x[2]))\n}\nhin &lt;- function(x){\n  x[1] - ( (cos(x[2]))^x[1] - x[1] )^x[2]\n}\nhin.jac &lt;- function(x){\n  numDeriv::grad(hin, c(x[1], x[2]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, n = 2L, G = gr), # 2 个决策变量\n  constraints = F_constraint(\n    F = list(hin = hin),\n    dir = \"&lt;=\",\n    rhs = 0,\n    J = list(hin.jac = hin.jac)\n  ),\n  bounds = V_bound(ld = -50, ud = 50, nobj = 2L),\n  maximum = FALSE # 求最小\n)\n# 全局优化求解器 nloptr.isres，不保证全局最优\n# 最优解 (20.68497, 37.20738) 处取得局部最优解，目标函数值 -3.053314\nnlp &lt;- ROI_solve(op, solver = \"nloptr.isres\", start = c(1, 0))\nnlp$solution\nnlp$objval\n# 局部优化求解器 nloptr.cobyla\n# 在处 (24.199046, 2.964661) 处取得局部最优解，目标函数值 0.6477342\nnlp &lt;- ROI_solve(op, solver = \"nloptr.cobyla\", start = c(1, 0))\nnlp$solution\nnlp$objval\n# nloptr.mma / nloptr.auglag / nloptr.slsqp 容错能力差，都不能求解\nnlp &lt;- ROI_solve(op, solver = \"nloptr.auglag\", start = c(1, 0))\n\n\n\n\n求解如下非线性约束优化问题。\n\\[\n\\begin{aligned}\n  \\min_{\\boldsymbol{x}} \\quad & x_1^2\\sin(x_2) + x_2^2\\cos(x_1)\\\\\n  \\text{s.t.} \\quad & \\left\\{\n    \\begin{array}{l}\n      1 \\leq 3x_1 -x_2 \\leq 3 \\\\\n      x_1 + x_2 \\geq 2 \\\\\n      x_1 x_2 = 2 \\\\\n      \\sin(x_1) \\cos(x_2) \\leq 0.6 \\\\\n      x_1,x_2 \\in (-100,100).\n    \\end{array} \\right.\n  \\end{aligned}\n\\]\n\n代码# 一个 2 维的目标函数\nfn &lt;- function(x) {\n  x[1]^2 * sin(x[2]) + x[2]^2 * cos(x[1])\n}\n# 目标函数的梯度\ngr &lt;- function(x) {\n  c(\n    2 * x[1] * sin(x[2]) - x[2]^2 * sin(x[1]),\n    x[1]^2 * cos(x[2]) + 2 * x[2] * cos(x[1])\n  )\n}\n# 线性约束矩阵\nA &lt;- matrix(c(\n  1, 1,\n  3, -1,\n  3, -1\n), ncol = 2, byrow = TRUE)\n# 等式约束\nheq &lt;- function(x) {\n  prod(x)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  c(x[2], x[1])\n}\n# 不等式约束\nhin &lt;- function(x) {\n  sin(x[1]) * cos(x[2])\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x) {\n  c(cos(x[1]) * cos(x[2]), -sin(x[1]) * sin(x[2]))\n}\n# 定义目标优化\nop &lt;- OP(\n  objective = F_objective(F = fn, G = gr, n = 2L),\n  # rbind 函数组合多种约束\n  constraints = rbind(\n    L_constraint(\n      L = A,\n      dir = c(\"&gt;=\", \"&lt;=\", \"&gt;=\"),\n      rhs = c(2, 3, 1)\n    ),\n    F_constraint(\n      F = list(heq = heq, hin = hin),\n      dir = c(\"==\", \"&lt;=\"),\n      rhs = c(2, 0.6),\n      # 等式和不等式约束的雅可比\n      J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n    )\n  ),\n  bounds = V_bound(ld = -100, ud = 100, nobj = 2L),\n  maximum = FALSE # 求最小\n)\n# 求解优化问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = c(1/2, 4))\n# 最优解\nnlp$solution\n# 目标函数值\nnlp$objval\n\n\n\n\n\n\n\n\nBerkelaar, Michel 等. 2023. lpSolve: Interface to Lp_solve v. 5.5 to Solve Linear/Integer Programs. https://CRAN.R-project.org/package=lpSolve.\n\n\nBrandao, Filipe. 2023. rAMPL: AMPL API for R. https://github.com/ampl/rAMPL.\n\n\nDunning, Iain, Joey Huchette, 和 Miles Lubin. 2017. 《JuMP: A Modeling Language for Mathematical Optimization》. SIAM Review 59 (2): 295–320. https://doi.org/10.1137/15M1020575.\n\n\nFu, Anqi, 和 Balasubramanian Narasimhan. 2023. ECOSolveR: Embedded Conic Solver in R. https://CRAN.R-project.org/package=ECOSolveR.\n\n\nHart, William E, Jean-Paul Watson, 和 David L Woodruff. 2011. 《Pyomo: modeling and solving mathematical programs in Python》. Mathematical Programming Computation 3 (3): 219–60.\n\n\nJohnson, Steven G. 2023. The NLopt nonlinear optimization package. https://CRAN.R-project.org/package=nloptr.\n\n\nO’Donoghue, Brendan, Eric Chu, Parikh Neal, 和 Stephen Boyd. 2016. 《Operator Splitting for Conic Optimization via Homogeneous Self-Dual Embedding》. Journal of Optimization Theory and Applications 169 (3): 1042–68. https://doi.org/10.1007/s10957-016-0892-3.\n\n\nS original by Berwin A. Turlach, Fortran contributions from Cleve Moler dpodi/LINPACK), R port by Andreas Weingessel. 2019. quadprog: Functions to Solve Quadratic Programming Problems. https://CRAN.R-project.org/package=quadprog.\n\n\nSchwendinger, Florian, 和 Hans W. Borchers. 2023. CRAN Task View: Optimization and Mathematical Programming. https://CRAN.R-project.org/view=Optimization.\n\n\nSchwendinger, Florian, 和 Dirk Schumacher. 2023. highs: HiGHS Optimization Solver. https://CRAN.R-project.org/package=highs.\n\n\nScrucca, Luca. 2013. 《GA: A Package for Genetic Algorithms in R》. Journal of Statistical Software 53 (4): 1–37. https://doi.org/10.18637/jss.v053.i04.\n\n\nTheussl, Stefan, 和 Kurt Hornik. 2023. Rglpk: R/GNU Linear Programming Kit Interface. https://CRAN.R-project.org/package=Rglpk.\n\n\nTheußl, Stefan, Florian Schwendinger, 和 Kurt Hornik. 2020. 《ROI: An Extensible R Optimization Infrastructure》. Journal of Statistical Software 94 (15): 1–64. https://doi.org/10.18637/jss.v094.i15.\n\n\n刘浩洋, 户将, 李勇锋, 和 文再文. 2020. 最优化：建模、算法与理论. 北京: 高等教育出版社. http://faculty.bicmr.pku.edu.cn/~wenzw/optbook.html.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>数值优化</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html",
    "href": "optimization-problems.html",
    "title": "28  优化问题",
    "section": "",
    "text": "28.1 旅行商问题\n旅行商问题 The Traveling Salesman Problem 是一个混合整数线性规划问题，TSP 包 (Hahsler 和 Hornik 2007) 是求解此问题的最佳工具包。一般地，旅行商问题作如下定义。已知 \\(n\\) 个城市之间的距离，以矩阵 \\(D\\) 表示各个城市之间的距离，其元素 \\(d_{ij}\\) 表示城市 \\(i\\) 到城市 \\(j\\) 之间的距离，其对角元素 \\(d_{ii} = 0\\)，其中 \\(i,j = 1,2,\\cdots, n\\) 。一个旅行路线可以用 \\(\\{1,2,\\ldots,n\\}\\) 的循环排列 \\(\\pi\\) 表示，\\(\\pi(i)\\) 表示在旅行线路中跟在城市 \\(i\\) 之后的城市。旅行商问题就是找一个排列 \\(\\pi\\) 使得如下旅行线路最短。\n\\[\n\\sum_{i=1}^{n} d_{i\\pi(i)}\n\\]\n每个城市必须走到，且只能走一次。等价于如下整数规划问题，也是一个指派问题。\n\\[\n\\begin{aligned}\n\\min ~ & \\sum_{i=1}^{n}\\sum_{j=1}^{n} d_{ij}x_{ij} \\\\\n\\text{s.t.} ~& \\sum_{i=1}^{n}x_{ij} = 1, ~j = 1,2,\\ldots,n, \\\\\n~& \\sum_{j=1}^{n}x_{ij} = 1, ~ i = 1,2,\\ldots,n, \\\\\n~& x_{ij} = 0 ~\\text{or} ~ 1\n\\end{aligned}\n\\]\n某人要去美国 10 个城市旅行，分别是亚特兰大 Atlanta、芝加哥 Chicago、丹佛 Denver 、休斯顿 Houston、洛杉矶 Los Angeles、迈阿密 Miami、纽约 New York、旧金山 San Francisco、 西雅图 Seattle、华盛顿特区 Washington DC。10 个城市的分布如 图 28.1 所示。从洛杉矶出发，最后回到洛杉矶，如何规划旅行线路使得总行程最短？行程最短的路径是什么？\n代码# 10 个城市的经纬度数据来自 maps 包的 us.cities 数据集\nus_city_latlong &lt;- read.table(file = textConnection(\"\nCity, Latitude, Longitude\nAtlanta, 33.76, -84.42\nChicago, 41.84, -87.68\nDenver, 39.77, -104.87\nHouston, 29.77, -95.39\nLos Angeles, 34.11, -118.41\nMiami, 25.78, -80.21\nNew York, 40.67, -73.94\nSan Francisco, 37.77, -122.45\nSeattle, 47.62, -122.35\nWashington DC, 38.91, -77.01\n\"), header = TRUE, sep = \",\")\n\nlibrary(sf)\nus_city_latlong &lt;- st_as_sf(us_city_latlong,\n  coords = c(\"Longitude\", \"Latitude\"), crs = 4326\n)\nlibrary(ggplot2)\nggplot() +\n  geom_sf_label(\n    data = us_city_latlong, aes(label = City),\n    fun.geometry = sf::st_centroid\n  ) +\n  geom_sf(data = us_city_latlong, color = \"red\") +\n  coord_sf(crs = \"ESRI:102003\") +\n  theme_bw() +\n  labs(x = \"经度\", y = \"纬度\")\n\n\n\n\n\n\n图 28.1: 10 个城市的分布图\n简单起见，这 10 个城市之间的距离以直线距离代替，R 内置的数据集 UScitiesD 已经记录了这 10 个城市之间的直线距离。 UScitiesD 是一个 dist 类型的数据，可以用函数 as.matrix() 将其转化为矩阵类型。\ndata(UScitiesD)\nD &lt;- as.matrix(UScitiesD)\nlibrary(TSP)\nD_tsp &lt;- as.TSP(D)\n# 出发城市洛杉矶\ntour_sol &lt;- solve_TSP(x = D_tsp, method = \"nearest_insertion\", start = 5)\ntour_sol\n\n#&gt; object of class 'TOUR' \n#&gt; result of method 'nearest_insertion' for 10 cities\n#&gt; tour length: 7373\n途经 10 个城市的最短路程为 7373 。因采用启发式的随机优化算法，每次求解的结果可能会有所不同，建议运行多次，比较结果，选择最优的方法。\n# 旅行最短路程\ntour_length(tour_sol)\n\n#&gt; [1] 7373\n\n# 旅行线路方案\nas.integer(tour_sol)\n\n#&gt;  [1]  5  4  6  1 10  7  2  3  9  8\n\nlabels(D_tsp)[as.integer(tour_sol)]\n\n#&gt;  [1] \"LosAngeles\"    \"Houston\"       \"Miami\"         \"Atlanta\"      \n#&gt;  [5] \"Washington.DC\" \"NewYork\"       \"Chicago\"       \"Denver\"       \n#&gt;  [9] \"Seattle\"       \"SanFrancisco\"\n求解结果对应的旅行方案，如 图 28.2 所示，依次走过的城市是：洛杉矶、旧金山、西雅图、丹佛、芝加哥、纽约、华盛顿特区、亚特兰大、迈阿密、休斯顿。\n代码us_city_tour &lt;- st_cast(st_combine(st_geometry(us_city_latlong[as.integer(tour_sol),])), \"POLYGON\")\nggplot() +\n  geom_sf_label(\n    data = us_city_latlong, aes(label = City),\n    fun.geometry = sf::st_centroid\n  ) +\n  geom_sf(data = us_city_latlong, color = \"red\") +\n  geom_sf(data = us_city_tour, fill = NA, color = \"black\") +\n  coord_sf(crs = \"ESRI:102003\") +\n  theme_bw() +\n  labs(x = \"经度\", y = \"纬度\")\n\n\n\n\n\n\n图 28.2: 10 个城市的路线图",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-markowitz-portfolio-optimization",
    "href": "optimization-problems.html#sec-markowitz-portfolio-optimization",
    "title": "28  优化问题",
    "section": "\n28.2 投资组合问题",
    "text": "28.2 投资组合问题\n作为一个理性的投资者，希望回报最大而风险最小，给定投资和回报的约束条件下，选择风险最小的组合。一个简单的马科维茨投资组合优化问题如下：\n\\[\n\\begin{aligned}\n\\min_{\\boldsymbol{w}} \\quad & \\boldsymbol{w}^{\\top}\\hat{\\Sigma}\\boldsymbol{w} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{w}^{\\top} \\leq \\boldsymbol{b}\n\\end{aligned}\n\\]\n其中，\\(\\boldsymbol{w}\\) 是权重向量，每个分量代表对投资对象的投资比例，\\(\\hat{\\Sigma}\\) 是关于投资对象的协方差矩阵，约束条件中包含两个部分，一个是权重之和为 1，一个是投资组合的收益率达到预期值。下面基于 12个科技公司公开的股价数据介绍此组合优化问题。\n首先利用 quantmod 包获取微软、谷歌、亚马逊、惠普、甲骨文、英特尔、威瑞森、eBay、AT&T、Apple、Adobe 和 IBM 等 12 支股票的历史股价数据。根据 2022-11-01 至 2022-12-01 期间的股票调整价，计算各支股票天粒度的收益率。收益率可以看作一个随机变量，收益率的波动变化，即随机变量的方差，可以看作风险。\n\n# 12 支股票的收益率\ntech_stock_return &lt;- readRDS(file = \"data/tech_stock_return.rds\")\nDD &lt;- 100 * tech_stock_return\n# 平均收益率\nr &lt;- mean(DD)\nr\n\n#&gt; [1] 0.3476413\n\n# 目标函数\nfoo &lt;- Q_objective(Q = cov(DD), L = rep(0, ncol(DD)))\n# 投资约束\nfull_invest &lt;- L_constraint(rep(1, ncol(DD)), \"==\", 1)\n# 回报约束\ntarget_return &lt;- L_constraint(apply(DD, 2, mean), \"==\", r)\n# 目标规划\nop &lt;- OP(objective = foo, constraints = rbind(full_invest, target_return))\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Minimize a quadratic objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type linear.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n求解器 nloptr.slsqp 需要给初值和等式约束的梯度，而求解器 quadprog 不需要给初值。下面使用 quadprog 来求解组合优化问题。\n\nlibrary(ROI.plugin.quadprog)\nsol &lt;- ROI_solve(op, solver = \"quadprog\")\n# 最优解：投资组合\nw &lt;- sol$solution\n# 保留 4 位小数\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 目标函数值：投资风险\nsqrt(t(w) %*% cov(DD) %*% w)\n\n#&gt;           [,1]\n#&gt; [1,] 0.9860861\n\n\n求解出来的投资组合是甲骨文、 AT&T 和 IBM，投资比例分别是 33.58% 、37.40% 和 29.02% 。以上 12 支股票都属于科技公司，收益率具有非常高的相关性，因此，最终选出来 3 支。\n与给定预期回报而风险最小的组合优化问题相对应的是另一个问题：给定风险的约束条件下，获得预期回报最大的组合。即求解如下组合优化问题：\n\\[\n\\begin{aligned}\n\\max_{\\boldsymbol{w}} \\quad & \\boldsymbol{w}^{\\top}\\hat{\\boldsymbol{\\mu}} \\\\\n\\text{s.t.} \\quad & A\\boldsymbol{w} \\leq \\boldsymbol{b} \\\\\n\\quad & \\boldsymbol{w}^{\\top}\\hat{\\Sigma}\\boldsymbol{w} \\leq \\sigma\n\\end{aligned}\n\\]\n其中，目标函数中 \\(\\hat{\\boldsymbol{\\mu}}\\) 表示根据历史数据获得的投资对象的收益率，约束条件中 \\(\\sigma\\) 表示投资者可以接受的投资风险，其他符号的含义同前。在给定风险约束 \\(\\sigma\\) 下，求取回报最大的组合。线性约束也可以用函数 Q_constraint() 来表示，这样线性约束和二次约束可以整合在一起，代码如下：\n\n# 风险阈值\nsigma &lt;- sqrt(t(w) %*% cov(DD) %*% w)\nsigma\n\n#&gt;           [,1]\n#&gt; [1,] 0.9860861\n\n# 12 阶的全 0 矩阵\nzero_mat &lt;- diag(x = rep(0, ncol(DD)))\n# 目标函数\nfoo &lt;- Q_objective(Q = zero_mat, L = colMeans(DD))\n# 线性和二次约束\nmaxret_constr &lt;- Q_constraint(\n  Q = list(cov(DD), NULL),\n  L = rbind(\n    rep(0, ncol(DD)),\n    rep(1, ncol(DD))\n  ),\n dir = c(\"&lt;=\", \"==\"), rhs = c(1/2 * sigma^2, 1)\n)\n# 目标规划\nop &lt;- OP(objective = foo, constraints = maxret_constr, maximum = TRUE)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a quadratic objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type quadratic.\n#&gt; - 0 lower and 0 upper non-standard variable bounds.\n\n\n函数 ROI_applicable_solvers() 识别规划问题类型，给出可求解此规划问题的求解器。\n\nROI_applicable_solvers(op)\n\n#&gt; [1] \"nloptr.cobyla\" \"nloptr.mma\"    \"nloptr.auglag\" \"nloptr.isres\" \n#&gt; [5] \"nloptr.slsqp\"\n\n\nquadprog 求解器不能求解该问题，尝试求解器 nloptr.slsqp ，12 支股票同等看待，所以，权重的初始值都设置为 \\(\\frac{1}{12}\\) 。\n\n# 求解规划问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = rep(1/12, 12))\n# 投资组合\nw &lt;- nlp$solution\n# 保留 4 位小数\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 投资组合的预期收益\nw %*% colMeans(DD)\n\n#&gt;           [,1]\n#&gt; [1,] 0.3476413\n\n\n结果显示，投资组合是甲骨文、 AT&T 和 IBM，投资比例分别是 33.58% 、37.40% 和 29.02% 。\n值得注意，当约束条件比较复杂，比如包含一些非线性的等式或不等式约束，可以用函数 F_constraint() 来表示，这更加的灵活，但需要传递（非）线性约束的雅可比向量或矩阵。用函数 F_constraint() 表示的代码如下，求解结果是一样的。\n\n# x 是一个表示权重的列向量 \n# 等式约束\n# 权重之和为 1 的约束\nheq &lt;- function(x) {\n  sum(x)\n}\n# 等式约束的雅可比\nheq.jac &lt;- function(x) {\n  rep(1, length(x))\n}\n# 不等式约束\n# 二次的风险约束\nhin &lt;- function(x){\n  1/2 * t(x) %*% cov(DD) %*% x\n}\n# 不等式约束的雅可比\nhin.jac &lt;- function(x){\n  cov(DD) %*% x\n}\n# 目标规划\nop &lt;- OP(\n  objective = L_objective(L = colMeans(DD)), # 12 个目标变量\n  constraints = F_constraint(\n    # 等式和不等式约束\n    F = list(heq = heq, hin = hin),\n    dir = c(\"==\", \"&lt;=\"),\n    rhs = c(1, 1/2 * sigma^2),\n    # 等式和不等式约束的雅可比\n    J = list(heq.jac = heq.jac, hin.jac = hin.jac)\n  ),\n  # 目标变量的取值范围\n  bounds = V_bound(ld = 0, ud = 1, nobj = 12L),\n  maximum = TRUE # 最大回报\n)\nop\n\n#&gt; ROI Optimization Problem:\n#&gt; \n#&gt; Maximize a linear objective function of length 12 with\n#&gt; - 12 continuous objective variables,\n#&gt; \n#&gt; subject to\n#&gt; - 2 constraints of type nonlinear.\n#&gt; - 0 lower and 12 upper non-standard variable bounds.\n\n# 求解规划问题\nnlp &lt;- ROI_solve(op, solver = \"nloptr.slsqp\", start = rep(1/12, 12))\n# 投资组合\nw &lt;- nlp$solution\nround(w, 4)\n\n#&gt;  [1] 0.0000 0.0000 0.0000 0.0000 0.3358 0.0000 0.0000 0.0000 0.3740 0.0000\n#&gt; [11] 0.0000 0.2902\n\n# 投资组合的预期收益\nw %*% colMeans(DD)\n\n#&gt;           [,1]\n#&gt; [1,] 0.3476413",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-gaussian-process-regression",
    "href": "optimization-problems.html#sec-gaussian-process-regression",
    "title": "28  优化问题",
    "section": "\n28.3 高斯过程回归",
    "text": "28.3 高斯过程回归\n高斯过程回归模型如下：\n\\[\n\\boldsymbol{y}(x) = D\\boldsymbol{\\beta} + S(x)\n\\]\n其中，\\(\\boldsymbol{\\beta}\\) 是一个 \\(p\\times 1\\) 维列向量，随机过程 \\(S(x)\\) 是均值为零，协方差为 \\(V_{\\boldsymbol{\\theta}}\\) 的平稳高斯过程，协方差矩阵 \\(V_{\\boldsymbol{\\theta}}\\) 的元素如下：\n\\[\n\\mathsf{Cov}\\{S(x_i), S(x_j)\\} = \\sigma^2 \\exp(-\\|x_i - x_j\\| / \\phi)\n\\]\n其中， \\(\\boldsymbol{\\theta} = (\\sigma^2,\\phi)\\) 表示与协方差矩阵相关的参数，随机过程 \\(S(x)\\) 的一个实现服从多元正态分布 \\(\\mathrm{MVN}(\\boldsymbol{0},V_{\\boldsymbol{\\theta}})\\) ，则 \\(\\boldsymbol{y}(x)\\) 也服从多元正态分布 \\(\\mathrm{MVN}(D\\boldsymbol{\\beta},V_{\\boldsymbol{\\theta}})\\) 。参数 \\(\\boldsymbol{\\beta}\\) 的广义最小二乘估计为 \\(\\hat{\\boldsymbol{\\beta}}(\\boldsymbol{\\theta}) = (D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}D)^{-1} D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\boldsymbol{y}\\) ，关于参数 \\(\\boldsymbol{\\theta}\\) 的剖面对数似然函数如下：\n\\[\n\\log \\mathcal{L}(\\boldsymbol{\\theta}) = -\\frac{n}{2}\\log (2\\pi) - \\frac{1}{2}\\log (\\det V_{\\boldsymbol{\\theta}}) -\\frac{1}{2}\\boldsymbol{y}^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\big(I - D(D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}D)^{-1}D^{\\top}V_{\\boldsymbol{\\theta}}^{-1}\\big)\\boldsymbol{y}\n\\]\n下面考虑一个来自 MASS 包真实数据 topo。topo 数据集最初来自 John C. Davis （1973年）所著的书《Statistics and Data Analysis in Geology》。后来， J. J. Warnes 和 B. D. Ripley （1987年）以该数据集为例指出空间高斯过程的协方差函数的似然估计中存在的问题(Warnes 和 Ripley 1987)，并将其作为数据集 topo 放在 MASS 包里。Paulo J. Ribeiro Jr 和 Peter J. Diggle （2001年）将该数据集打包成自定义的 geodata 数据类型，放在 geoR 包里，并在他俩合著的书《Model-based Geostatistics》中多次出现。topo 是空间地形数据集，包含有 52 行 3 列，数据点是 310 平方英尺范围内的海拔高度数据，x 坐标每单位 50 英尺，y 坐标单位同 x 坐标，海拔高度 z 单位是英尺。\n\nlibrary(MASS)\ndata(topo)\nstr(topo)\n\n#&gt; 'data.frame':    52 obs. of  3 variables:\n#&gt;  $ x: num  0.3 1.4 2.4 3.6 5.7 1.6 2.9 3.4 3.4 4.8 ...\n#&gt;  $ y: num  6.1 6.2 6.1 6.2 6.2 5.2 5.1 5.3 5.7 5.6 ...\n#&gt;  $ z: int  870 793 755 690 800 800 730 728 710 780 ...\n\n\n根据 topo 数据集， \\(D = \\boldsymbol{1}\\) 是一个 \\(52 \\times 1\\) 的列向量，\\(\\boldsymbol{\\beta} = \\beta\\) 是一个截距项。设置参数初值 \\((\\sigma,\\phi) = (65,2)\\) 。为了与 Ripley 的论文中的图比较，下面扔掉了对数似然函数中常数项，用 R 语言编码的似然函数如下：\n\nlog_lik &lt;- function(x) {\n  n &lt;- nrow(topo)\n  D &lt;- t(t(rep(1, n)))\n  Sigma &lt;- x[1]^2 * exp(-as.matrix(dist(topo[, c(\"x\", \"y\")])) / x[2])\n  inv_Sigma &lt;- solve(Sigma)\n  P &lt;- diag(1, n) - D %*% solve(t(D) %*% solve(Sigma, D), t(D)) %*% inv_Sigma\n  as.vector(-1 / 2 * log(det(Sigma)) - 1 / 2 * t(topo[, \"z\"]) %*% inv_Sigma %*% P %*% topo[, \"z\"])\n}\nlog_lik(x = c(65, 2))\n\n#&gt; [1] -207.1364\n\n\n关于参数的偏导计算复杂，就不计算梯度了，下面调用 R 软件内置的 nlminb 优化器。发现，对不同的初始值，收敛到不同的位置，目标函数值非常接近。\n\nop &lt;- OP(\n  objective = F_objective(log_lik, n = 2L),\n  bounds = V_bound(lb = c(55, 5), ub = c(75, 8)),\n  maximum = TRUE\n)\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(65, 2))\nnlp$solution\n\n#&gt; [1] 65  5\n\nnlp$objval\n\n#&gt; [1] -197.4197\n\n\n如果初始值靠近局部极值点，则就近收敛到该极值点，比如初值 \\((65, 7)\\) ， \\((70, 7.5)\\) 。\n\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(65, 7))\nnlp$solution\n\n#&gt; [1] 65  7\n\nnlp$objval\n\n#&gt; [1] -196.9407\n\nnlp &lt;- ROI_solve(op, solver = \"nlminb\", start = c(70, 7.5))\nnlp$solution\n\n#&gt; [1] 70.0  7.5\n\nnlp$objval\n\n#&gt; [1] -196.8441\n\n\n尝试调用来自 nloptr 包的全局优化求解器 nloptr.directL ，大大小小的坑都跳过去了，结果还是比较满意的。\n\nnlp &lt;- ROI_solve(op, solver = \"nloptr.directL\")\nnlp$solution\n\n#&gt; [1] 63.934432  6.121382\n\nnlp$objval\n\n#&gt; [1] -196.8158\n\n\n目标区域网格化，计算格点处的似然函数值，然后绘制似然函数图像。\n\ndat &lt;- expand.grid(\n  sigma = seq(from = 55, to = 75, length.out = 41),\n  phi = seq(from = 5, to = 8, length.out = 31)\n)\ndat$fn &lt;- apply(dat, 1, log_lik)\n\n似然函数关于参数 \\((\\sigma,\\phi)\\) 的三维曲面见 图 28.3 。\n\n代码wireframe(\n  data = dat, fn ~ sigma * phi,\n  shade = TRUE, drape = FALSE,\n  xlab = expression(sigma), ylab = expression(phi),\n  zlab = list(expression(\n    italic(log-lik) ~ group(\"(\", list(sigma, phi), \")\")\n  ), rot = 90),\n  scales = list(arrows = FALSE, col = \"black\"),\n  shade.colors.palette = custom_palette,\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = -0.5, units = \"inches\"),\n      right.padding = list(x = -1.0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -1.5, units = \"inches\"),\n      top.padding = list(x = -1.5, units = \"inches\")\n    )\n  ),\n  par.settings = list(axis.line = list(col = \"transparent\")),\n  screen = list(z = 30, x = -65, y = 0)\n)\n\n\n\n\n\n\n图 28.3: 对数似然函数的曲面图\n\n\n\n\n等高线图呈现一道非常长且平滑的山岭 long flat ridge，山岭上布满许多局部极大值，普通的数值优化求解器常常陷入其中，只有全局优化求解器才可能找到全局极大值点。高斯过程回归模型的对数似然函数是非凸的，多模态的。\n\n代码levelplot(fn ~ sigma * phi,\n  data = dat, aspect = 1,\n  xlim = c(54.5, 75.5), ylim = c(4.9, 8.1),\n  xlab = expression(sigma), ylab = expression(phi),\n  col.regions = cm.colors, contour = TRUE,\n  scales = list(\n    x = list(alternating = 1, tck = c(1, 0)),\n    y = list(alternating = 1, tck = c(1, 0))\n  ),\n  # 减少三维图形的边空\n  lattice.options = list(\n    layout.widths = list(\n      left.padding = list(x = 0, units = \"inches\"),\n      right.padding = list(x = 0, units = \"inches\")\n    ),\n    layout.heights = list(\n      bottom.padding = list(x = -.5, units = \"inches\"),\n      top.padding = list(x = -.5, units = \"inches\")\n    )\n  )\n)\n\n\n\n\n\n\n图 28.4: 对数似然函数的等高线图\n\n\n\n\n上图中没有看到许多局部极小值，与作者论文中的图 1 似乎不符。原因是什么？似然函数中涉及到的矩阵运算不精确，应该设计精度更高的运算方式？lattice 包绘图引擎无法展示更加细微的差异？还有一种解释，上图是对的，算法迭代时，对不同的初值，常常收敛到不同的结果，而这些不同的结果都位于岭上不同位置，对应的对数似然值却又几乎一样。\n作为验证，下面调用 nlme 包的 gls() 函数拟合数据，参数的极大似然估计结果与全局优化求解器的结果比较一致。参数估计结果 \\((\\sigma, \\phi)= (63.93429, 6.121352)\\) ，对数似然函数值为 -244.6006 ，自编的似然函数 log_lik() 在最优解处的值为 -196.8158，再加上之前扔掉的常数项 -52 / 2 * log(2 * pi) ，就是 -244.6006 ，丝毫不差。\n\nlibrary(nlme)\nfit_topo_ml &lt;- gls(z ~ 1,\n  data = topo, method = \"ML\",\n  correlation = corExp(value = 65, form = ~ x + y)\n)\nsummary(fit_topo_ml)\n\n#&gt; Generalized least squares fit by maximum likelihood\n#&gt;   Model: z ~ 1 \n#&gt;   Data: topo \n#&gt;        AIC     BIC    logLik\n#&gt;   495.2012 501.055 -244.6006\n#&gt; \n#&gt; Correlation Structure: Exponential spatial correlation\n#&gt;  Formula: ~x + y \n#&gt;  Parameter estimate(s):\n#&gt;    range \n#&gt; 6.121352 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Value Std.Error  t-value p-value\n#&gt; (Intercept) 863.708  45.49859 18.98318       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -2.7169766 -1.1919732 -0.5272282  0.1453374  1.5061096 \n#&gt; \n#&gt; Residual standard error: 63.93429 \n#&gt; Degrees of freedom: 52 total; 51 residual\n\n\n如果使用限制极大似然估计，会发现参数估计结果与之相距甚远，而对数似然函数值相差无几。参数估计结果 \\((\\sigma,\\phi) = (128.8275, 25.47324)\\) 。\n\nfit_topo_reml &lt;- gls(z ~ 1,\n  data = topo, method = \"REML\",\n  correlation = corExp(value = 65, form = ~ x + y)\n)\nsummary(fit_topo_reml)\n\n#&gt; Generalized least squares fit by REML\n#&gt;   Model: z ~ 1 \n#&gt;   Data: topo \n#&gt;        AIC      BIC    logLik\n#&gt;   485.1558 490.9513 -239.5779\n#&gt; \n#&gt; Correlation Structure: Exponential spatial correlation\n#&gt;  Formula: ~x + y \n#&gt;  Parameter estimate(s):\n#&gt;    range \n#&gt; 25.47324 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Value Std.Error  t-value p-value\n#&gt; (Intercept) 877.8956  116.7163 7.521619       0\n#&gt; \n#&gt; Standardized residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.45850506 -0.70167923 -0.37178079 -0.03800119  0.63732032 \n#&gt; \n#&gt; Residual standard error: 128.8275 \n#&gt; Degrees of freedom: 52 total; 51 residual",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-poisson-mixture-distributions",
    "href": "optimization-problems.html#sec-poisson-mixture-distributions",
    "title": "28  优化问题",
    "section": "\n28.4 泊松混合分布",
    "text": "28.4 泊松混合分布\n有限混合模型（Finite Mixtures of Distributions）的应用非常广泛，本节参考 BB 包 (Varadhan 和 Gilbert 2009) 的帮助手册，以泊松混合分布为例，介绍其参数的极大似然估计。更多详细的理论和算法介绍从略，感兴趣的读者可以查阅相关文献 (Hasselblad 1969)。BB 包比内置函数 optim() 功能更强，可以求解大规模非线性方程组，也可以求解带简单约束的非线性优化问题，还可以从多个初始值出发寻找全局最优解。\n两个泊松分布以一定比例 \\(p\\) 混合，以概率 \\(p\\) 服从泊松分布 \\(\\mathrm{Poisson}(\\lambda_1)\\) ，而以概率 \\(1-p\\) 服从泊松分布 \\(\\mathrm{Poisson}(\\lambda_1)\\) 。\n\\[\np\\times \\mathrm{Poisson}(\\lambda_1) + (1 - p)\\times \\mathrm{Poisson}(\\lambda_2)\n\\]\n泊松混合分布的概率密度函数 \\(f(x;p,\\lambda_1,\\lambda_2)\\) 如下：\n\\[\nf(x;p,\\lambda_1,\\lambda_2) = p \\times \\frac{\\lambda_1^x \\exp(-\\lambda_1)}{x!} + (1 - p) \\times \\frac{\\lambda_2^x \\exp(-\\lambda_2)}{x!}\n\\]\n随机变量 \\(X\\) 服从参数为 \\(p\\) 的伯努利分布 \\(X \\sim \\mathrm{Bernoulli}(1, p)\\) ，随机变量 \\(Y\\) 服从泊松混合分布，在伯努利分布的基础上，泊松混合分布也可作如下定义：\n\\[\n\\begin{array}{l}\nY \\sim \\left\\{\n\\begin{array}{l}\n\\mathrm{Poisson}(\\lambda_1), \\quad \\text{当} ~ X = 1 ~ \\text{时},\\\\\n\\mathrm{Poisson}(\\lambda_2), \\quad \\text{当} ~ X = 0 ~ \\text{时}.\n\\end{array} \\right.\n\\end{array}\n\\]\n对数似然函数如下：\n\\[\n\\ell(p,\\lambda_1,\\lambda_2) = \\sum_{i=0}^{n}y_i \\log\\big(p\\times \\exp(-\\lambda_1) \\times\\frac{\\lambda_1^{x_i}}{x_i!} + (1 - p)\\times \\exp(-\\lambda_2) \\times\\frac{\\lambda_2 ^{x_i}}{x_i!} \\big)\n\\]\n下 表格 28.1 数据来自 1947 年 Walter Schilling 发表在 JASA 的一篇文章 (Schilling 1947)。连续三年搜集伦敦《泰晤士报》刊登的死亡告示，每天的告示发布 80 岁及以上女性死亡人数。经过汇总统计，发现，在三年里，没有人死亡的告示出现 162 次，死亡 1 人的告示出现 267 次。\n\n\n表格 28.1: 死亡人数的统计\n\n\n\n死亡人数\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n发生频次\n162\n267\n271\n185\n111\n61\n27\n8\n3\n1\n\n\n\n\n\n考虑到夏季和冬季对老人死亡率的影响是不同的，因此，引入泊松混合分布来对数据建模。\n\n# 对数似然函数\n# p 是一个长度为 3 的向量\n# y 是观测数据向量\npoissmix_loglik &lt;- function(p, y) {\n  i &lt;- 0:(length(y) - 1)\n  loglik &lt;- y * log(p[1] * exp(-p[2]) * p[2]^i / exp(lgamma(i + 1)) +\n    (1 - p[1]) * exp(-p[3]) * p[3]^i / exp(lgamma(i + 1)))\n  sum(loglik)\n}\n# lgamma(i + 1) 表示整数 i 的阶乘的对数\n# 参数的下限\nlo &lt;- c(0, 0, 0)\n# 参数的上限\nhi &lt;- c(1, Inf, Inf)\n# 随机生成一组参数初始值\np0 &lt;- runif(3, c(0.2, 1, 1), c(0.8, 5, 8)) \n# 汇总统计出来的死亡人数的频次分布\ny &lt;- c(162, 267, 271, 185, 111, 61, 27, 8, 3, 1)\n\n调用 BB 包的函数 BBoptim() 求解多元非线性箱式约束优化问题。\n\nlibrary(BB)\n# 参数估计\nans &lt;- BBoptim(\n  par = p0, fn = poissmix_loglik, y = y,\n  lower = lo, upper = hi, \n  control = list(maximize = TRUE)\n)\n\n#&gt; iter:  0  f-value:  -2728.652  pgrad:  7.256869 \n#&gt; iter:  10  f-value:  -1991.684  pgrad:  3.057812 \n#&gt; iter:  20  f-value:  -1992.223  pgrad:  14.27044 \n#&gt; iter:  30  f-value:  -1989.946  pgrad:  0.01893341 \n#&gt; iter:  40  f-value:  -1989.946  pgrad:  0.01303306 \n#&gt; iter:  50  f-value:  -1989.946  pgrad:  0.02468141 \n#&gt;   Successful convergence.\n\nans\n\n#&gt; $par\n#&gt; [1] 0.3598835 1.2560919 2.6634020\n#&gt; \n#&gt; $value\n#&gt; [1] -1989.946\n#&gt; \n#&gt; $gradient\n#&gt; [1] 4.547474e-06\n#&gt; \n#&gt; $fn.reduction\n#&gt; [1] -738.7058\n#&gt; \n#&gt; $iter\n#&gt; [1] 56\n#&gt; \n#&gt; $feval\n#&gt; [1] 58\n#&gt; \n#&gt; $convergence\n#&gt; [1] 0\n#&gt; \n#&gt; $message\n#&gt; [1] \"Successful convergence\"\n#&gt; \n#&gt; $cpar\n#&gt; method      M \n#&gt;      2     50\n\n\nnumDeriv::hessian 计算极大似然点的黑塞矩阵，然后计算参数估计的标准差。\n\n# 黑塞矩阵\nhess &lt;- numDeriv::hessian(x = ans$par, func = poissmix_loglik, y = y)\nhess\n\n#&gt;           [,1]       [,2]       [,3]\n#&gt; [1,] -907.1096  270.22872  341.25394\n#&gt; [2,]  270.2287 -113.47958  -61.68196\n#&gt; [3,]  341.2539  -61.68196 -192.78183\n\n# 标准差\nse &lt;- sqrt(diag(solve(-hess)))\nse\n\n#&gt; [1] 0.1946835 0.3500298 0.2504770\n\n\nmultiStart 从不同初始值出发寻找全局最大值，先找一系列局部极大值，通过比较获得全局最大值。\n\n# 随机生成 10 组初始值\np0 &lt;- matrix(runif(30, c(0.2, 1, 1), c(0.8, 8, 8)), \n             nrow = 10, ncol = 3, byrow = TRUE)\nans &lt;- multiStart(\n  par = p0, fn = poissmix_loglik, action = \"optimize\",\n  y = y, lower = lo, upper = hi, quiet = TRUE,\n  control = list(maximize = TRUE, trace = FALSE)\n)\n# 筛选出迭代收敛的解\npmat &lt;- round(cbind(ans$fvalue[ans$conv], ans$par[ans$conv, ]), 4)\ndimnames(pmat) &lt;- list(NULL, c(\"fvalue\", \"parameter 1\", \n                               \"parameter 2\", \"parameter 3\"))\n# 去掉结果一样的重复解\npmat[!duplicated(pmat), ]\n\n#&gt;         fvalue parameter 1 parameter 2 parameter 3\n#&gt; [1,] -1989.946      0.6401      2.6634      1.2561\n#&gt; [2,] -1989.946      0.3599      1.2561      2.6634\n#&gt; [3,] -1989.946      0.3599      1.2560      2.6634",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-maximum-likelihood-estimation",
    "href": "optimization-problems.html#sec-maximum-likelihood-estimation",
    "title": "28  优化问题",
    "section": "\n28.5 极大似然估计",
    "text": "28.5 极大似然估计\n一元函数最优化问题和求根问题是相关的。在统计应用中，二项分布的比例参数的置信区间估计涉及求根，伽马分布的参数的极大似然估计涉及求根。下面介绍求根在估计伽马分布的参数中的应用。\n形状参数为 \\(\\alpha\\) 和尺度参数为 \\(\\sigma\\) 的伽马分布的概率密度函数 \\(f(x;\\alpha, \\sigma)\\) 如下：\n\\[\nf(x;\\alpha,\\sigma) = \\frac{1}{\\sigma^\\alpha \\Gamma(\\alpha)}x^{\\alpha - 1} \\exp(- \\frac{x}{\\sigma}), \\quad \\alpha \\geq 0, \\sigma &gt; 0\n\\]\n其中，\\(\\Gamma(\\cdot)\\) 表示伽马函数，伽马分布的均值为 \\(\\alpha \\sigma\\) ，方差为 \\(\\alpha\\sigma^2\\) 。下 图 28.5 展示两个伽马分布的概率密度函数，形状参数分别为 5 和 9，尺度参数均为 1，即伽马分布 \\(f(x; 5, 1)\\) 和 \\(f(x; 9, 1)\\) 。\n\n代码ggplot() +\n  geom_function(\n    fun = dgamma, args = list(shape = 9, scale = 1),\n    aes(colour = \"list(alpha == 9, sigma == 1)\"),\n    linewidth = 1.2, xlim = c(0, 20), \n  ) +\n  geom_function(\n    fun = dgamma, args = list(shape = 5, scale = 1),\n    aes(colour = \"list(alpha == 5, sigma == 1)\"),\n    linewidth = 1.2, xlim = c(0, 20)\n  ) +\n  scale_colour_viridis_d(\n    labels = scales::parse_format(),\n    begin = 0.3, end = 0.7,\n    option = \"C\"\n  ) +\n  theme_bw(base_family = \"sans\") +\n  theme(axis.title = element_text(family = \"Noto Serif CJK SC\"),\n        legend.title = element_text(family = \"Noto Serif CJK SC\"),\n        legend.position = \"top\", legend.justification = \"right\") +\n  labs(x = \"随机变量\", y = \"概率密度\", color = \"参数\")\n\n\n\n\n\n\n图 28.5: 伽马分布的概率密度函数\n\n\n\n\n给定一组来自伽马分布的样本 \\(x_1,x_2,\\ldots,x_n\\) ，关于参数 \\(\\alpha\\) 和 \\(\\sigma\\) 的似然函数如下：\n\\[\n\\mathcal{L}(\\alpha, \\sigma) = \\big(\\frac{1}{\\sigma^\\alpha \\Gamma(\\alpha)}\\big)^{n} (\\prod_{i=1}^{n} x_i)^{\\alpha - 1} \\exp(- \\frac{ \\sum_{i=1}^{n} x_i }{\\sigma})\n\\]\n则，其对数似然函数如下：\n\\[\n\\ell(\\alpha, \\sigma) = -n\\big(\\alpha \\log(\\sigma) + \\log \\Gamma(\\alpha) \\big) + (\\alpha - 1)\\sum_{i=1}^{n}\\log(x_i) - \\frac{ \\sum_{i=1}^{n} x_i }{\\sigma}\n\\]\n对数似然函数关于参数 \\(\\alpha\\) 和 \\(\\sigma\\) 的偏导数如下：\n\\[\n\\begin{aligned}\n\\frac{\\partial \\ell(\\alpha,\\sigma)}{\\partial \\alpha} &= -n\\Big( \\log(\\sigma) + \\big(\\log \\Gamma(\\alpha)\\big)' \\Big) + \\sum_{i=1}^{n}\\log (x_i) = 0 \\\\\n\\frac{\\partial \\ell(\\alpha,\\sigma)}{\\partial \\sigma} &= - \\frac{n\\alpha}{\\sigma} + \\frac{\\sum_{i=1}^{n}x_i}{\\sigma^2} = 0\n\\end{aligned}\n\\]\n根据第二个式子可得 \\(\\sigma = \\frac{1}{n\\alpha}\\sum_{i=1}^{n}x_i\\) ，将其代入第一个式子可得\n\\[\n\\log(\\alpha) - \\big(\\log \\Gamma(\\alpha)\\big)' = \\log\\big(\\frac{1}{n}\\sum_{i=1}^{n}x_i\\big) - \\frac{1}{n}\\sum_{i=1}^{n}\\log (x_i)\n\\]\n\nset.seed(20232023)\nx &lt;- rgamma(1000, shape = 1.5, scale = 2)\n# 形状参数和尺度参数的矩估计\nc(mean(x)^2 /var(x), var(x)/mean(x))\n\n#&gt; [1] 1.636030 1.902239\n\n# 极大似然估计\n# 常量\ncc &lt;- log(mean(x)) - mean(log(x))\n# 方程\nfun &lt;- function(alpha){\n  log(alpha) - digamma(alpha) - cc\n}\n# 找根\nuniroot(f = fun, interval = c(1, 3))\n\n#&gt; $root\n#&gt; [1] 1.610272\n#&gt; \n#&gt; $f.root\n#&gt; [1] 2.825244e-09\n#&gt; \n#&gt; $iter\n#&gt; [1] 6\n#&gt; \n#&gt; $init.it\n#&gt; [1] NA\n#&gt; \n#&gt; $estim.prec\n#&gt; [1] 6.103516e-05\n\n\n求得形状参数的估计 \\(\\alpha = 1.610272\\) ，进而，可得尺度参数的估计 \\(\\sigma = 1.932667\\) 。\n函数 uniroot() 只能找到方程的一个根，rootSolve 包采用牛顿-拉弗森（ Newton-Raphson ）算法找一元非线性方程（组）的根，特别适合有多个根的情况。\n\nlibrary(rootSolve)\n# 非线性方程（组）的根\nmultiroot(f = fun, start = 1.2)\n\n#&gt; $root\n#&gt; [1] 1.610272\n#&gt; \n#&gt; $f.root\n#&gt; [1] 3.121097e-10\n#&gt; \n#&gt; $iter\n#&gt; [1] 5\n#&gt; \n#&gt; $estim.precis\n#&gt; [1] 3.121097e-10\n\n# 搜索一个方程在区间内所有的根\nuniroot.all(f = fun, interval = c(1, 3))\n\n#&gt; [1] 1.610339",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "optimization-problems.html#sec-optimization-exercises",
    "href": "optimization-problems.html#sec-optimization-exercises",
    "title": "28  优化问题",
    "section": "\n28.6 习题",
    "text": "28.6 习题\n\n某人要周游美国各州，从纽约出发，走遍 50 个州的行政中心，最后回到纽约。规划旅行线路使得总行程最短。Base R 内置的 R 包 datasets 包含美国 50 个州的地理中心数据 state.center 。\n有限混合模型也常用 EM 算法来估计参数，美国黄石公园老忠实间歇泉的喷发规律近似为二维高斯混合分布，请读者以 R 软件内置的数据集 faithful 为基础，采用 EM 算法估计参数。\n\n获取百度、阿里、腾讯、京东、美团、滴滴、字节、360、网易、新浪等 10 支股票的历史股价数据。根据 2021-12-01 至 2022-12-01 股票的调整价计算 12 个月的股价收益率，根据月度股价收益率和波动率数据，设置投资组合，使得月度收益率不低于2%。股票代码以数字编码和 HK 结尾的为港股代码，有的公司在美股和港股上都有。可以用 quantmod 包下载各个公司的股价数据，下载拼多多股价数据的代码如下：\nquantmod::getSymbols(\"PDD\", auto.assign = FALSE, src = \"yahoo\")\n\n\n表格 28.2: 一些互联网公司及股票代码\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n公司\n美团\n阿里巴巴\n京东\n百度\n腾讯\n拼多多\n京东\n阿里巴巴\n\n\n股票代码\n3690.HK\n9988.HK\n9618.HK\n9888.HK\n0700.HK\nPDD\nJD\nBABA\n\n\n\n\n\n\n\n\n\n\n\nHahsler, Michael, 和 Kurt Hornik. 2007. 《TSP: Infrastructure for the traveling salesperson problem》. Journal of Statistical Software 23 (2): 1–21. https://doi.org/10.18637/jss.v023.i02.\n\n\nHasselblad, Victor. 1969. 《Estimation of Finite Mixtures of Distributions from the Exponential Family》. Journal of the American Statistical Association 64 (328): 1459–71. https://doi.org/10.1080/01621459.1969.10501071.\n\n\nSchilling, Walter. 1947. 《A Frequency Distribution Represented as the Sum of Two Poisson Distributions》. Journal of the American Statistical Association 42 (239): 407–24.\n\n\nVaradhan, Ravi, 和 Paul Gilbert. 2009. 《BB: An R Package for Solving a Large System of Nonlinear Equations and for Optimizing a High-Dimensional Nonlinear Objective Function》. Journal of Statistical Software 32 (4): 1–26. https://www.jstatsoft.org/v32/i04/.\n\n\nWarnes, J. J., 和 B. D. Ripley. 1987. 《Problems with likelihood estimation of covariance functions of spatial gaussian processes》. Biometrika 74 (3): 640–42.",
    "crumbs": [
      "优化建模",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>优化问题</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "Agresti, Alan. 2007. An Introduction to Categorical Data\nAnalysis. 2nd ed. Hoboken, New Jersey: John Wiley & Sons, Inc.\n\n\nAnsari, A. R., and R. A. Bradley. 1960. “Rank-Sum Tests for\nDispersions.” The Annals of Mathematical Statistics 31\n(4): 1174–89. https://doi.org/10.1214/aoms/1177705688.\n\n\nAnscombe, F. J. 1973. “Graphs in Statistical Analysis.”\nThe American Statistician 27 (1): 17. https://doi.org/10.2307/2682899.\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra\nThemes, Scales and Geoms for ggplot2.\nhttps://CRAN.R-project.org/package=ggthemes.\n\n\nAttali, Dean, and Christopher Baker. 2022. ggExtra: Add Marginal Histograms to ggplot2, and More ggplot2 Enhancements. https://CRAN.R-project.org/package=ggExtra.\n\n\nBai, H., L. Wang, W. Pan, and M. Frey. 2009. “Measuring\nMathematics Anxiety: Psychometric Analysis of a Bidimensional Affective\nScale.” Journal of Instructional Psychology 36 (3):\n185–93.\n\n\nBates, Douglas, and Dirk Eddelbuettel. 2013. “Fast and Elegant\nNumerical Linear Algebra Using the RcppEigen\nPackage.” Journal of Statistical Software 52 (5): 1–24.\nhttps://doi.org/10.18637/jss.v052.i05.\n\n\nBerkelaar, Michel et al. 2023. lpSolve:\nInterface to Lp_solve v. 5.5 to Solve\nLinear/Integer Programs. https://CRAN.R-project.org/package=lpSolve.\n\n\nBickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. “Sex Bias\nin Graduate Admissions: Data from Berkeley.” Science 187\n(4175): 398–404. https://doi.org/10.1126/science.187.4175.398.\n\n\nBiecek, Przemyslaw. 2023. DrWhy: Explain, Explore and\nDebug Predictive Machine Learning Models. https://github.com/ModelOriented/DrWhy.\n\n\nBion, Ricardo. 2018. ggtech: ggplot2 Tech Themes and Scales.\n\n\nBlyth, Colin R., and David W. Hutchinson. 1960. “Table of\nNeyman-Shortest Unbiased Confidence Intervals for the Binomial\nParameter.” Biometrika 47 (3/4): 381–91. https://www.jstor.org/stable/2333308.\n\n\nBrandao, Filipe. 2023. rAMPL:\nAMPL API for r. https://github.com/ampl/rAMPL.\n\n\nBrown, Lawrence D., T. Tony Cai, and Anirban DasGupta. 2001.\n“Interval Estimation for a Binomial Proportion.”\nStatistical Science, no. 2: 101–33. https://projecteuclid.org/euclid.ss/1009213286.\n\n\nBrunson, Jason Cory. 2020. “ggalluvial: Layered Grammar for Alluvial\nPlots.” Journal of Open Source Software 5 (49): 2017. https://doi.org/10.21105/joss.02017.\n\n\nClopper, C. J., and E. S. Pearson. 1934. “The Use of Confidence or\nFiducial Limits Illustrated in the Case of the Binomial.”\nBiometrika 26 (4): 404–13. https://doi.org/10.1093/biomet/26.4.404.\n\n\nCohen, Jacob. 1994. “The Earth Is Round (p &lt; .05).” American\nPsychologist 49 (12): 997–1003. https://doi.org/10.1037/0003-066x.49.12.997.\n\n\nConstantin, Ahlmann-Eltze, and Indrajeet Patil. 2021. “ggsignif: R Package for Displaying Significance\nBrackets for ggplot2.”\nPsyArxiv. https://doi.org/10.31234/osf.io/7awm6.\n\n\nDavies, Rhian, Steph Locke, and Lucy D’Agostino McGowan. 2022. datasauRus: Datasets from the Datasaurus\nDozen. https://CRAN.R-project.org/package=datasauRus.\n\n\nDobson, Annette J. 1983. An Introduction to Statistical\nModelling. 1st ed. London: Chapman; Hall/CRC. https://doi.org/10.1007/978-1-4899-3174-0.\n\n\nDunning, Iain, Joey Huchette, and Miles Lubin. 2017.\n“JuMP: A Modeling Language for Mathematical\nOptimization.” SIAM Review 59 (2): 295–320. https://doi.org/10.1137/15M1020575.\n\n\nEfron, Bradley, Trevor Hastie, Iain Johnstone, and Robert Tibshirani.\n2004. “Least angle regression.”\nThe Annals of Statistics 32 (2): 407–99. https://doi.org/10.1214/009053604000000067.\n\n\nEpps, T. W., and Lawrence B. Pulley. 1983. “A Test for Normality\nBased on the Empirical Characteristic Function.”\nBiometrika 70 (3): 723–26. https://doi.org/10.2307/2336512.\n\n\nFeinerer, Ingo, Kurt Hornik, and David Meyer. 2008. “Text Mining\nInfrastructure in R.” Journal of Statistical\nSoftware 25 (5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nFeng, Dai, and Luke Tierney. 2008. “Computing and Displaying\nIsosurfaces in R.” Journal of Statistical\nSoftware 28 (1). https://doi.org/10.18637/jss.v028.i01.\n\n\nFligner, Michael A., and Timothy J. Killeen. 1976.\n“Distribution-Free Two-Sample Tests for Scale.” Journal\nof the American Statistical Association 71 (353): 210–13. https://doi.org/10.1080/01621459.1976.10481517.\n\n\nFriendly, Michael. 2021. HistData: Data Sets from the\nHistory of Statistics and Data Visualization. https://CRAN.R-project.org/package=HistData.\n\n\nFriendly, Michael, and David Meyer. 2016. Discrete Data Analysis\nwith r: Visualization and Modeling Techniques for Categorical and Count\nData. 1st ed. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nFu, Anqi, and Balasubramanian Narasimhan. 2023.\nECOSolveR: Embedded Conic Solver in r. https://CRAN.R-project.org/package=ECOSolveR.\n\n\nGalton, F. 1886. “Regression Towards Mediocrity in Hereditary\nStature.” Journal of the Anthropological Institute 15:\n246–63.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, et al. 2021.\nviridis: Colorblind-Friendly Color Maps\nfor R. https://doi.org/10.5281/zenodo.4679424.\n\n\nGeyer, Charles J., and Glen D. Meeden. 2005. “Fuzzy and Randomized\nConfidence Intervals and p-Values.” Statistical Science\n20 (4): 358–66. https://www.jstor.org/stable/20061193.\n\n\nGross, Calli, and Philipp Ottolinger. 2016. ggThemeAssist: Add-in to Customize ggplot2 Themes. https://CRAN.R-project.org/package=ggThemeAssist.\n\n\nGrün, Bettina, and Kurt Hornik. 2011. “topicmodels: An R Package for Fitting\nTopic Models.” Journal of Statistical Software 40 (13):\n1–30. https://doi.org/10.18637/jss.v040.i13.\n\n\nHahsler, Michael, and Kurt Hornik. 2007. “TSP:\nInfrastructure for the Traveling Salesperson\nProblem.” Journal of Statistical Software 23 (2): 1–21.\nhttps://doi.org/10.18637/jss.v023.i02.\n\n\nHanley, James A. 2004. “’Transmuting’ Women into Men: Galton’s\nFamily Data on Human Stature.” The American Statistician\n58 (3): 237–43.\n\n\nHart, William E, Jean-Paul Watson, and David L Woodruff. 2011.\n“Pyomo: Modeling and Solving Mathematical Programs in\nPython.” Mathematical Programming\nComputation 3 (3): 219–60.\n\n\nHasselblad, Victor. 1969. “Estimation of Finite Mixtures of\nDistributions from the Exponential Family.” Journal of the\nAmerican Statistical Association 64 (328): 1459–71. https://doi.org/10.1080/01621459.1969.10501071.\n\n\nHawkins, Oliver. 2022. pilot: A Minimal\nggplot2 Theme with an Accessible Discrete\nColor Palette. https://github.com/olihawkins/pilot.\n\n\nHeyde, C. C., E. Seneta, P. Crépel, S. E. Fienberg, and J. Gani. 2001.\nStatisticians of the Centuries. New York, NY: Springer-Verlag.\nhttps://doi.org/10.1007/978-1-4613-0179-0.\n\n\nHolt, Charles C. 2004. “Forecasting Seasonals and Trends by\nExponentially Weighted Moving Averages.” International\nJournal of Forecasting 20 (1): 5–10. https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nHSU, P. L. 1938. “Contribution to the Theory of \"Student’s\" T-Test as Applied to the Problem of\nTwo Samples.” Statistical Research Memoirs 2: 1–24.\n\n\n———. 1983. Collected Papers. New York, NY: Springer-Verlag.\n\n\nHvitfeldt, Emil. 2021. paletteer:\nComprehensive Collection of Color Palettes. https://github.com/EmilHvitfeldt/paletteer.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine Learning\nfor Text Analysis in R. New York: Chapman; Hall/CRC.\nhttps://smltar.com/.\n\n\nJohnson, Steven G. 2023. The NLopt Nonlinear\nOptimization Package. https://CRAN.R-project.org/package=nloptr.\n\n\nJosé. Chacón, Tarn Duong. 2018. Multivariate Kernel Smoothing and\nIts Applications. Boca Raton, Florida: Chapman; Hall/CRC. https://www.mvstat.net/mvksa/.\n\n\nKabacoff, Robert I. 2022. R in Action: Data Analysis\nand Graphics with R and Tidyverse. 3rd\ned. Shelter Island, NY: Manning Publications Co.\n\n\nKarambelkar, Bhaskar. 2016. colormap:\nColor Palettes Using Colormaps Node Module. https://CRAN.R-project.org/package=colormap.\n\n\nKassambara, Alboukadel. 2022. ggpubr:\nggplot2 Based Publication Ready Plots.\nhttps://CRAN.R-project.org/package=ggpubr.\n\n\nKay, Matthew. 2022. ggdist:\nVisualizations of Distributions and Uncertainty. https://doi.org/10.5281/zenodo.3879620.\n\n\nKim, Seock-Ho, and Allan S. Cohen. 1998. “On the Behrens-Fisher\nProblem: A Review.” Journal of Educational and Behavioral\nStatistics 23 (4): 356–77. https://doi.org/10.2307/1165281.\n\n\nKim, Yongdai, Hosik Choi, and Hee-Seok Oh. 2008. “Smoothly Clipped\nAbsolute Deviation on High Dimensions.” Journal of the\nAmerican Statistical Association 103 (484): 1665–73. https://doi.org/10.1198/016214508000001066.\n\n\nKolaczyk, Eric D., and Gábor Csárdi. 2020. Statistical Analysis of\nNetwork Data with R. 2nd ed. Springer, New York, NY.\nhttps://doi.org/10.1007/978-3-030-44129-6.\n\n\nKothari, Aditya. 2022. ggTimeSeries:\nTime Series Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggTimeSeries.\n\n\nKuhn, Max, and Hadley Wickham. 2020. Tidymodels: A Collection of\nPackages for Modeling and Machine Learning Using Tidyverse\nPrinciples. https://www.tidymodels.org.\n\n\nLang, Michel, and Patrick Schratz. 2023. mlr3verse: Easily Install and Load the mlr3 Package Family. https://CRAN.R-project.org/package=mlr3verse.\n\n\nLemon, Jim. 2006. “plotrix: A Package\nin the Red Light District of R.” R-News 6\n(4): 8–12.\n\n\nLigges, Uwe, and Martin Mächler. 2003. “scatterplot3d: An R Package for\nVisualizing Multivariate Data.” Journal of Statistical\nSoftware 8 (11): 1–20. https://doi.org/10.18637/jss.v008.i11.\n\n\nLikert, Rensis. 1932. “A Technique for the Measurement of\nAttitudes.” Archives of Psychology 142 (1): 1–55.\n\n\nLüdecke, Daniel. 2019. strengejacke:\nLoad Packages Associated with Strenge Jacke! https://github.com/strengejacke/strengejacke.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Brenton M.\nWiernik, Etienne Bacher, Rémi Thériault, and Dominique Makowski. 2022.\n“easystats: Framework for Easy\nStatistical Modeling, Visualization, and Reporting.”\nCRAN. https://easystats.github.io/easystats/.\n\n\nMarron, J. S., and Ian L. Dryden. 2022. Object Oriented Data\nAnalysis. 1st ed. Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nMcGill, Tukey, R., and W. A. Larsen. 1978. “Variations of Box\nPlots.” The American Statistician 32 (1): 12–16. https://www.jstor.org/stable/2683468.\n\n\nMeyer, David, Achim Zeileis, and Kurt Hornik. 2006. “The Strucplot\nFramework: Visualizing Multi-Way Contingency Tables with vcd.” Journal of Statistical\nSoftware 17 (3): 1–48. https://doi.org/10.18637/jss.v017.i03.\n\n\nMood, A. M. 1954. “On the Asymptotic Efficiency of Certain\nNonparametric Two-Sample Tests.” The Annals of Mathematical\nStatistics 25 (3): 514–22. https://doi.org/10.1214/aoms/1177728719.\n\n\nNeitmann, Thomas. 2020. ggcharts:\nShorten the Distance from Data Visualization Idea to Actual Plot.\nhttps://CRAN.R-project.org/package=ggcharts.\n\n\nNeuwirth, Erich. 2022. RColorBrewer:\nColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.\n\n\nNewcombe, Robert G. 1998. “Interval Estimation for the Difference\nBetween Independent Proportions: Comparison of Eleven Methods.”\nStatistics in Medicine 17 (8): 873–90. https://doi.org/10.1002/(SICI)1097-0258(19980430)17:8&lt;873::AID-SIM779&gt;3.0.CO;2-I.\n\n\nO’Donoghue, Brendan, Eric Chu, Parikh Neal, and Stephen Boyd. 2016.\n“Operator Splitting for Conic Optimization via Homogeneous\nSelf-Dual Embedding.” Journal of Optimization Theory and\nApplications 169 (3): 1042–68. https://doi.org/10.1007/s10957-016-0892-3.\n\n\nOtto, James, and David Kahle. 2023. “ggdensity: Improved Bivariate Density\nVisualization in R.” The R Journal 15:\n220–36. https://doi.org/10.32614/RJ-2023-048.\n\n\nPatil, Indrajeet. 2021. “Visualizations with\nstatistical details: The ggstatsplot\napproach.” Journal of Open Source\nSoftware 6 (61): 3167. https://doi.org/10.21105/joss.03167.\n\n\nPedersen, Thomas Lin, and Fabio Crameri. 2022. scico: Colour Palettes Based on the Scientific\nColour-Maps. https://CRAN.R-project.org/package=scico.\n\n\nPu, Xiaoying, and Matthew Kay. 2020. “A Probabilistic Grammar of\nGraphics.” In Proceedings of the 2020 CHI\nConference on Human Factors in Computing Systems, 1–13. ACM. https://doi.org/10.1145/3313831.3376466.\n\n\nRigby, R. A., and D. M. Stasinopoulos. 2005. “Generalized Additive\nModels for Location, Scale and Shape (with Discussion).”\nJournal of the Royal Statistical Society: Series C (Applied\nStatistics) 54 (3): 507–54. https://doi.org/10.1111/j.1467-9876.2005.00510.x.\n\n\nRyan, Jeffrey A., and Joshua M. Ulrich. 2022. quantmod: Quantitative Financial Modelling\nFramework. https://CRAN.R-project.org/package=quantmod.\n\n\nS original by Berwin A. Turlach, Fortran contributions from Cleve Moler\ndpodi/LINPACK), R port by Andreas Weingessel. 2019. quadprog: Functions to Solve Quadratic Programming\nProblems. https://CRAN.R-project.org/package=quadprog.\n\n\nSarkar, Deepayan. 2008. lattice:\nMultivariate Data Visualization with R. New York:\nSpringer. http://lmdvr.r-forge.r-project.org.\n\n\nSchilling, Walter. 1947. “A Frequency Distribution Represented as\nthe Sum of Two Poisson Distributions.” Journal of the\nAmerican Statistical Association 42 (239): 407–24.\n\n\nSchwendinger, Florian, and Hans W. Borchers. 2023. CRAN Task\nView: Optimization and Mathematical Programming. https://CRAN.R-project.org/view=Optimization.\n\n\nSchwendinger, Florian, and Dirk Schumacher. 2023. highs: HiGHS Optimization\nSolver. https://CRAN.R-project.org/package=highs.\n\n\nScrucca, Luca. 2013. “GA: A Package for Genetic\nAlgorithms in R.” Journal of Statistical\nSoftware 53 (4): 1–37. https://doi.org/10.18637/jss.v053.i04.\n\n\nShapiro, S. S., and M. B. Wilk. 1965. “An Analysis of Variance\nTest for Normality (Complete Samples).” Biometrika 52\n(3-4): 591–611. https://doi.org/10.1093/biomet/52.3-4.591.\n\n\nSidiropoulos, Nikos, Sina Hadi Sohi, Thomas Lin Pedersen, Bo Torben\nPorse, Ole Winther, Nicolas Rapin, and Frederik Otzen Bagger. 2018.\n“SinaPlot: An Enhanced Chart for Simple and Truthful\nRepresentation of Single Observations over Multiple Classes.”\nJournal of Computational and Graphical Statistics 27 (3):\n673–76. https://doi.org/10.1080/10618600.2017.1366914.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR. New York: O’Reilly Media, Inc. https://www.tidytextmining.com/.\n\n\nSlowikowski, Kamil. 2021. ggrepel:\nAutomatically Position Non-Overlapping Text Labels with ggplot2. https://CRAN.R-project.org/package=ggrepel.\n\n\nSoetaert, Karline. 2021. plot3D:\nPlotting Multi-Dimensional Data. https://CRAN.R-project.org/package=plot3D.\n\n\n\"Student\". 1908. “The Probable Error of a Mean.”\nBiometrika 6: 1–25.\n\n\nStylianou, Nassos, Will Dahlgreen, Robert Cuffe, Tom Calver, and Ransome\nMpini. 2022. bbplot: Making ggplot2 Graphics in BBC NEWS\nStyle.\n\n\nTang, Yuan, Masaaki Horikoshi, and Wenxuan Li. 2016. “ggfortify: Unified Interface to Visualize\nStatistical Result of Popular r Packages.” The R Journal\n8 (2): 474–85. https://doi.org/10.32614/RJ-2016-060.\n\n\nTheussl, Stefan, and Kurt Hornik. 2023. Rglpk: R/GNU\nLinear Programming Kit Interface. https://CRAN.R-project.org/package=Rglpk.\n\n\nTheußl, Stefan, Florian Schwendinger, and Kurt Hornik. 2020.\n“ROI: An Extensible R Optimization\nInfrastructure.” Journal of Statistical Software 94\n(15): 1–64. https://doi.org/10.18637/jss.v094.i15.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via\nthe Lasso.” Journal of the Royal Statistical\nSociety. Series B (Methodological) 58 (1): 267–88. http://www.jstor.org/stable/2346178.\n\n\nTobin, Ciaran. 2020. ggthemr: Themes for\nggplot2.\n\n\nTyner, Sam, François Briatte, and Heike Hofmann. 2017. “Network\nVisualization with ggplot2.”\nThe R Journal 9 (1): 27–59. https://doi.org/10.32614/RJ-2017-023.\n\n\nVaradhan, Ravi, and Paul Gilbert. 2009. “BB: An\nR Package for Solving a Large System of Nonlinear Equations\nand for Optimizing a High-Dimensional Nonlinear Objective\nFunction.” Journal of Statistical Software 32 (4): 1–26.\nhttps://www.jstatsoft.org/v32/i04/.\n\n\nWand, M. P., and M. C. Jones. 1995. Kernel Smoothing. 1st ed.\nBoca Raton, Florida: Chapman; Hall/CRC. http://matt-wand.utsacademics.info/webWJbook/.\n\n\nWarnes, J. J., and B. D. Ripley. 1987. “Problems with Likelihood\nEstimation of Covariance Functions of Spatial Gaussian\nProcesses.” Biometrika 74 (3): 640–42.\n\n\nWickham, Charlotte. 2018. munsell:\nUtilities for Using Munsell Colours. https://CRAN.R-project.org/package=munsell.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant\nGraphics for Data Analysis. 2nd ed. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science: Import, Tidy, Transform, Visualize,\nand Model Data. 2nd ed. Sebastopol, California: O’Reilly Media,\nInc. https://r4ds.hadley.nz/.\n\n\nWickham, Hadley, Danielle Navarro, and Thomas Lin Pedersen. 2024.\nggplot2: Elegant Graphics for Data\nAnalysis. 3rd ed. Springer-Verlag New York. https://ggplot2-book.org/.\n\n\nWickham, Hadley, and Dana Seidel. 2022. scales: Scale Functions for Visualization. https://CRAN.R-project.org/package=scales.\n\n\nWilke, Claus O. 2020. ggtext: Improved\nText Rendering Support for ggplot2. https://CRAN.R-project.org/package=ggtext.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession,\nand Statistical Inference.” Journal of the American\nStatistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nWinters, Peter R. 1960. “Forecasting Sales by Exponentially\nWeighted Moving Averages.” Management Science 6 (3):\n324–42. https://doi.org/10.1287/mnsc.6.3.324.\n\n\nXiao, Nan. 2018. ggsci: Scientific\nJournal and Sci-Fi Themed Color Palettes for ggplot2. https://CRAN.R-project.org/package=ggsci.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and\nKnitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.\n\n\nYu, Guangchuang. 2022. ggimage: Use\nImage in ggplot2. https://CRAN.R-project.org/package=ggimage.\n\n\nYutani, Hiroaki. 2022. string2path:\nRendering Font into data.frame. https://CRAN.R-project.org/package=string2path.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D.\nMcWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020.\n“colorspace: A Toolbox for\nManipulating and Assessing Colors and Palettes.” Journal of\nStatistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, David Meyer, and Kurt Hornik. 2007.\n“Residual-Based Shadings for Visualizing (Conditional)\nIndependence.” Journal of Computational and Graphical\nStatistics 16 (3): 507–25. https://doi.org/10.1198/106186007X237856.\n\n\nZhang, Cun-Hui. 2010. “Nearly Unbiased Variable Selection Under\nMinimax Concave Penalty.” The Annals of Statistics 38\n(2): 894–942. https://doi.org/10.1214/09-AOS729.\n\n\nZhang, Lijin, Xueyang Li, and Zhiyong Zhang. 2023. “Variety and\nMainstays of the r Developer Community.” The R Journal\n15: 5–25. https://doi.org/10.32614/RJ-2023-060.\n\n\n刘浩洋, 户将, 李勇锋, and 文再文. 2020.\n最优化：建模、算法与理论. 北京: 高等教育出版社. http://faculty.bicmr.pku.edu.cn/~wenzw/optbook.html.\n\n\n宋泽熙. 2011. “两个二项总体成功概率的比较.”\n中国校外教育（理论） z1: 81. https://doi.org/10.3969/j.issn.1004-8502-B.2011.z1.0919.\n\n\n赵鹏, 谢益辉, and 黄湘云. 2021. 现代统计图形. 北京:\n人民邮电出版社. https://bookdown.org/xiangyun/msg.\n\n\n韦博成. 2009.\n“《红楼梦》前80回与后40回某些文风差异的统计分析（两个独立二项总体等价性检验的一个应用）.”\n应用概率统计 25 (4): 441–48. https://doi.org/10.3969/j.issn.1001-4268.2009.04.012.",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "git-github.html",
    "href": "git-github.html",
    "title": "附录 A — Git 和 Github",
    "section": "",
    "text": "A.1 安装配置",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-setup",
    "href": "git-github.html#sec-setup",
    "title": "附录 A — Git 和 Github",
    "section": "",
    "text": "A.1.1 创建账户\n登陆 Github 官网 (https://github.com/)，点击左上角注册按钮，开始注册 Github 账户。\n\n\n\n\n\n\n图 A.1: 点击注册\n\n\n\n接着，输入注册用的邮箱地址，比如 Outlook 和 Gmail 等。\n\n\n\n\n\n\n图 A.2: 输入邮箱\n\n\n\n除了邮箱外，继续输入密码、用户名等，密码可以选用浏览器自动生成的复杂字符串，只要没有被别人占用，用户名可以按着自己的喜好填写。\n\n\n\n\n\n\n图 A.3: 输入用户名\n\n\n\n接着，系统要验证来注册 Github 账户的人是否是真人。\n\n\n\n\n\n\n图 A.4: 回答问题\n\n\n\n正确回答界面上出现的问题后，进入下一步，系统会给你之前提供的邮箱发送一个验证码。\n\n\n\n\n\n\n图 A.5: 输入验证码\n\n\n\n将收到的验证码输入进去，完成账户验证。\n\n\n\n\n\n\n图 A.6: 验证账户\n\n\n\n创建账户后，将自动进入如下界面，接下来，可以创建代码仓库了。\n\n\n\n\n\n\n图 A.7: 创建代码仓库\n\n\n\n\n\nA.1.2 安装 Git\n在 MacOS 系统上，系统自带 Git 工具，无需安装。在 Ubuntu 系统上，安装最新稳定版的命令如下：\nsudo add-apt-repository -y ppa:git-core/ppa\nsudo apt update && sudo apt install git\n在 Windows 系统上，安装最新稳定版的命令如下：\nwinget install --id Git.Git -e --source winget\n\n\nA.1.3 配置密钥\n在配置 GitHub 账户和安装完 Git 客户端后，接着配置密钥，以便将本地的代码推送到远程 Github 账户下的代码仓库。\ngit config --global user.name \"用户名\"\ngit config --global user.email \"邮箱地址\"\n\n\nA.1.4 (*) 账户共存\n在公司往往会有自己的一套代码管理系统，比如 Gitlab 或者某种类似 Gitlab 的工具。本节介绍如何使 Gitlab / Github 账户共存在一台机器上。\n如何生成 SSH 密钥见 Github 文档 — 使用 SSH 连接到 GitHub。有了密钥之后只需在目录 ~/.ssh 下创建一个配置文件 config。\nGithub 对应个人的私有邮箱，Gitlab 对应公司分配的个人邮箱。\n生成 SSH Key\nssh-keygen -t rsa -f ~/.ssh/id_rsa_github -C \"个人邮箱地址\"\nssh-keygen -t rsa -f ~/.ssh/id_rsa_gitlab -C \"公司邮箱地址\"\n将 GitHub/GitLab 公钥分别上传至服务器，然后创建配置文件\ntouch ~/.ssh/config\n配置文件内容如下\n#\n# Github\n#\nHost github.com // Github 代码仓库的服务器地址\nHostName github.com\nUser XiangyunHuang\nIdentityFile ~/.ssh/id_rsa_github\n\n#\n# company\n#\nHost xx.xx.xx.xx // 公司代码仓库的服务器地址\nIdentityFile ~/.ssh/id_rsa_gitlab\n配置成功，你会看到\nssh -T git@xx.xx.xx.xx\nWelcome to GitLab, xiangyunhuang!\n和\nssh -T git@github.com\nHi XiangyunHuang! You've successfully authenticated, but GitHub does not provide shell access.",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-basic-git-operations",
    "href": "git-github.html#sec-basic-git-operations",
    "title": "附录 A — Git 和 Github",
    "section": "A.2 基本操作",
    "text": "A.2 基本操作\n\nA.2.1 初始化仓库\ngit init\n\n\nA.2.2 添加文件\ngit add\n追踪当前目录下的内容\ngit add .\n追踪被修改(modified)文件，不包括新添加的文件和被删除(deleted)的文件，-u 是 --update 的缩写\ngit add -u\n添加所有文件，-A 是 --all 的缩写\ngit add -A\n\n\nA.2.3 记录修改\ngit commit\ngit commit -m \"添加提交说明\"\n\n\nA.2.4 推送修改\ngit push\ngit push -u origin master\n\n\nA.2.5 克隆项目\n克隆项目 git clone\ngit clone git@github.com:XiangyunHuang/data-analysis-in-action.git\n有的项目包含子模块，添加选项 --recursive 可以将子模块也克隆下来。\ngit clone --recursive git@github.com:cosname/cosx.org.git",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-pr-operations",
    "href": "git-github.html#sec-pr-operations",
    "title": "附录 A — Git 和 Github",
    "section": "A.3 分支操作",
    "text": "A.3 分支操作\n对每一个新的问题，创建新的分支，提交新的 PR。\n与人协作开发代码项目，往往涉及 Git 分支操作。通常有两个场景，其一是独立地在分支上进行开发，包含创建分支、修改分支、提交分支、合并分支和删除分支。其二是与人合作互相评审代码修改分支，除了之前的基础操作，还包含在分支上解决代码冲突，同步分支内容。\n\n\n\n\n\n\nflowchart LR\n  A[创建分支] --&gt; B[修改分支]\n  B --&gt; C[提交分支]\n  C --&gt; D[合并分支]\n  D --&gt; E[删除分支]\n\n\n\n\n图 A.8: Git 分支操作\n\n\n\n\n\n\nA.3.1 创建分支\ngit checkout -b 分支名称\n\n\nA.3.2 分支切换\ngit checkout 分支名称\n\n\nA.3.3 修改 PR\n# 拉取合作者的 PR\ngit fetch origin refs/pull/771/head:patch-2\n# 771 是 PR 对应的编号\ngit checkout patch-2\n\n# 你的修改\n\ngit add -u # 追踪修改的内容\ngit commit -m \"描述修改内容\"\n\ngit remote add LalZzy https://github.com/LalZzy/cosx.org.git\ngit push --set-upstream LalZzy patch-2\n\n\nA.3.4 (*) 创建 gh-pages 分支\n基于 GitHub Pages 创建站点用于存放图片和数据。\n\n在 Github 上创建一个空的仓库，命名为 uploads。\n在本地创建目录 uploads。\n切换到 uploads 目录下，执行如下命令。\n\ngit init \ngit checkout -b gh-pages\ngit remote add origin https://github.com/XiangyunHuang/uploads.git\n添加图片或者数据，并推送到 gh-pages 分支。\ngit add README.md\ngit commit \"消息\" \ngit push --set-upstream origin gh-pages\n这样仓库 uploads 只包含 gh-pages 分支，README.md 文件地址为\nhttps://xiangyunhuang.github.io/uploads/README.md",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-r-to-git",
    "href": "git-github.html#sec-r-to-git",
    "title": "附录 A — Git 和 Github",
    "section": "A.4 R 与 Git 交互",
    "text": "A.4 R 与 Git 交互\nusethis 包将 Git 操作封装了，特别是一些复杂的操作，比如修改他人的 PR\n\nA.4.1 从 R 操作 Git\n拉取编号为 1019 的 PR\nusethis::pr_fetch(1019)\n1019 是 PR 的编号，修改完，清理\nusethis::pr_finish()\n\n\nA.4.2 分析 Git 记录\n给我的仓库点赞的人有哪些，如果有很多，仅显示第一页。\nlibrary(gh)\nmy_repos &lt;- gh(\"GET /repos/:owner/:repo/stargazers\", \n               owner = \"XiangyunHuang\", page = 1, \n               repo = \"data-analysis-in-action\")\nvapply(my_repos, \"[[\", \"\", \"login\")\nJeroen Ooms 开发的 gert 包，提供了 git_rm()、 git_status()、 git_add() 和 git_commit() 等函数，其中包含 git_reset() 、git_branch_*() 等高级 Git 操作。查看最近的 5 条提交记录。\nlibrary(gert)\ngit_log(max = 5)\n更多内容，读者请看 Gert: A minimal git client for R。\ngit2r 包对 Git 仓库进行概要。\nsummary(git2r::repository())\ngitdown 包将 Git 提交日志转化为 GitBook\n截止 2023 年 6 月 1 日，统计之都的主站仓库，提交量最大的 10 个人。\ngit shortlog -sn | head -n 10\n 153    Dawei Lang\n 127    Yihui Xie\n 101    Ryan Feng Lin\n  93    Beilei Bian\n  65    Xiangyun Huang\n  46    王佳\n  42    雷博文\n  39    Miao YU\n  35    xiangyun\n  32    fanchao",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  },
  {
    "objectID": "git-github.html#sec-git-extensions",
    "href": "git-github.html#sec-git-extensions",
    "title": "附录 A — Git 和 Github",
    "section": "A.5 (*) 辅助工具",
    "text": "A.5 (*) 辅助工具\nGit 扩展 git-delta 和 tig 是两款辅助工具。 tig 用于查看提交的历史日志。\n\nA.5.1 语法高亮\ngit-delta\nbrew install git-delta\n对 git diff 的输出提供语法高亮\n\n\nA.5.2 文本接口\n在 MacOS 上，推荐用 Homebrew 安装\nbrew install tig\n\n\nA.5.3 大文件存储\nGit Large File Storage (LFS) Git LFS\n# MacOS\nbrew install git-lfs\n# Ubuntu\nsudo apt install git-lfs\n配置 Git LFS\ngit lfs install\n项目中的大型数据文件\ngit lfs track \"*.csv\"\ngit add .gitattributes\ngit commit -m \"Git LFS 追踪数据文件\"\ngit push origin master",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Git 和 Github</span>"
    ]
  }
]