# 常见的统计检验 {#sec-common-statistical-tests}

::: hidden
$$
 \def\bm#1{{\boldsymbol #1}}
$$
:::

::: callout-tip
## 本章亮点

1.  比较全面地展示各类统计检验问题的 R 语言实现，其覆盖面之广，远超市面上同类 R 语言书籍。从连续数据到离散数据，从单样本到两样本，再到一般的多样本，触及最前沿的热门话题。

2.  对每类统计检验问题都给出示例及 R 语言实现，涉及近 40 个统计检验方法。在组织结构上，本章按照数据情况对检验方法分类，方便读者根据手头的数据情况，快速从众多的方法中定位最合适的检验方法，符合从数据出发进行分析实战的要求。
:::

> The Earth is Round ($p < 0.05$)
>
> --- Jacob Cohen [@Cohen1994]

Jacob Cohen 实际谈的是更加深刻的问题。开篇介绍为什么需要假设检验，做检验和不做检验有什么区别？杨灿老师在[讨论帖](https://d.cosx.org/d/420930/11)提出检验的作用和实际应用问题。R. A. Fisher 将抽样分布、参数估计和假设检验列为统计推断的三个中心内容，可见假设检验的重要地位。

真实数据的情况是复杂多样的，本章按照数据情况对检验方法分类，方便读者根据手头的数据情况，快速从众多的方法中定位最合适的检验方法。依次是单样本检验、两样本检验、多样本检验、计数数据检验、配对样本检验。如果已知符合参数检验的条件，优先考虑参数检验。如果不确定是否符合参数检验的条件，对参数检验和非参数检验方法都适用，非参数检验方法的功效更大，方法更优。在总体分布未知的情况下，无论是对均值检验还是对方差检验，大部分情况下都需要非参数检验方法。

-   检验方法归类：参数与非参数检验方法。
-   检验计算方式：近似 Approximate、精确 Extract、模拟 Simulation 和重抽样 Bootstrap 等方式。
-   检验对象归类：位置参数（均值）和尺度参数（方差）的检验。
-   检验总体数量归类：单总体、两个总体和多个总体。
-   检验总体分布归类：正态、二项、泊松、多项分布等。
-   检验总体维度归类：分一维、二维和多维的情形。

有了均值和方差，为什么还要位置参数和尺度参数？为了更一般地描述问题，扩展范围。特别是在总体分布未知或知之甚少的情况下做检验，不再仅限于均值和方差这样的特征量。关于检验方法，如有不明白的地方，可以查看维基百科词条。对每个检验问题，给出原假设和备择假设，检验统计量及其服从的分布，R 语言实现（自编或调用函数，如果调用函数，说明参数及其含义），不讲公式推导过程。

本章目的是让读者根据手头数据可以快速地找到最合适的检验方法。单样本检验、两样本检验和多样本检验都只针对连续数据。计数数据检验针对离散数据，不区分总体数量。配对样本检验是两样本检验中的特殊情况，不分连续还是离散，不分两个样本还是多个样本，多个样本就是两两配对检验。前面都是关于某个特征统计量的检验，对分布的检验涉及样本点是否来自正态分布，样本点是否独立和平稳，样本点是否来自某一分布，两个样本是否来自相同分布等。

```{r}
#| message: false

library(ggplot2)
library(pwr)       # 计算检验的功效和实验样本量
library(MASS)
# library(survival)
# library(coin)    # 补充更多的检验方法
# library(rstatix) # 管道操作整合检验方法
# library(pwrss)   # 常见检验的功效和样本量计算
```

## 单样本检验 {#sec-one-sample}

### 正态总体均值检验

#### 方差已知

$$
\begin{aligned}
\mathrm{I}   \quad H_0: \mu - \mu_0 \leq 0 \quad vs. \quad H_1: \mu - \mu_0 > 0 \\
\mathrm{II}  \quad H_0: \mu - \mu_0 \geq 0 \quad vs. \quad H_1: \mu - \mu_0 < 0 \\
\mathrm{III} \quad H_0: \mu - \mu_0 = 0 \quad vs. \quad H_1: \mu - \mu_0 \neq 0
\end{aligned}
$$

设 $x_1,\cdots,x_n$ 是来自总体 $\mathcal{N}(\mu,\sigma^2)$ 的样本，样本均值和方差分别

$\bar{x} = \frac{\sum_{i=1}^{n}x_i}{n}$ ，$s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2$

考虑到 $\bar{x} \sim \mathcal{N}(\mu,\sigma^2 / n)$ ，则检验统计量服从正态分布

$$
u = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}
$$

假定 $\mu_0 = 1$ 对于检验问题 I 拒绝域 $\{u \geq u_{1-\alpha}\}$

```{r}
set.seed(20232023)
n <- 20
# 样本
x <- rnorm(n, mean = 1.8, sd = 2)
# 检验统计量
u <- (mean(x) - 1) / (2 / sqrt(n))
# 临界值
qnorm(p = 1 - 0.05, mean = 0, sd = 1)
# P 值
1 - pnorm(q = u)
```

#### 方差未知

$$
\begin{aligned}
\mathrm{I}   \quad H_0: \mu - \mu_0 \leq 0 \quad vs. \quad H_1: \mu - \mu_0 > 0 \\
\mathrm{II}  \quad H_0: \mu - \mu_0 \geq 0 \quad vs. \quad H_1: \mu - \mu_0 < 0 \\
\mathrm{III} \quad H_0: \mu - \mu_0 = 0 \quad vs. \quad H_1: \mu - \mu_0 \neq 0
\end{aligned}
$$

考虑到

$$
\begin{aligned}
& \frac{\bar{x} - \mu}{\sigma / \sqrt{n}} \sim \mathcal{N}(0,1) \\
& \frac{(n-1)s^2}{\sigma^2} \sim \chi^2(n-1) \\
& \mathsf{E}\{s^2\} = \sigma^2 \quad \mathsf{Var}\{s^2\} = \frac{2\sigma^4}{n-1}
\end{aligned}
$$

根据 t 分布的定义，检验统计量服从 t 分布，即 $t \sim t(n-1)$

$$
t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}
$$

假定 $\mu_0 = 1$ 对于检验问题 I ，拒绝域 $\{t \geq t_{1-\alpha}(n-1)\}$

```{r}
# 检验统计量
t0 <- (mean(x) - 1) / sqrt(var(x) / n)
# 临界值
qt(p = 1 - 0.05, df = n - 1)
# P 值
1 - pt(q = t0, df = n - 1)
```

::: callout-note
英国统计学家 William Sealy Gosset (1876-1937) 于 1908 年在杂志 《Biometrics》 上以笔名 Student 发表论文《The Probable Error of a Mean》[@Gosset1908]，论文中展示了独立同正态分布的样本 $x_1, \ldots, x_n \stackrel{i.i.d}{\sim} \mathcal{N}(\mu,\sigma^2)$ 的样本方差 $s^2$ 和样本标准差 $s$ 的抽样分布，根据均值和标准差不相关的性质导出 t 分布，宣告 t 分布的诞生，因其在小样本领域的突出贡献，W. S. Gosset 进入世纪名人录 [@Heyde2001]。
:::

### 正态总体方差检验

卡方检验 $\chi^2$ 检验统计量服从卡方分布。

$$
\begin{aligned}
\mathrm{I}   \quad H_0: \sigma^2 - \sigma^2_0 \leq 0 \quad vs. \quad H_1: \sigma^2 - \sigma^2_0 > 0 \\
\mathrm{II}  \quad H_0: \sigma^2 - \sigma^2_0 \geq 0 \quad vs. \quad H_1: \sigma^2 - \sigma^2_0 < 0 \\
\mathrm{III} \quad H_0: \sigma^2 - \sigma^2_0 = 0 \quad vs. \quad H_1: \sigma^2 - \sigma^2_0 \neq 0
\end{aligned}
$$

一般假定均值 $\mu$ 是未知的。检验统计量服从卡方分布 $\chi^2(n-1)$

$$
\chi^2 = \frac{(n-1)s^2}{\sigma^2_0}
$$

设 $\sigma^2_0 = 1.5^2$ ，考虑检验问题 I

```{r}
# 检验统计量
chi <- (n - 1) * var(x) / 1.5^2
# 临界值
qchisq(p = 1 - 0.05, df = n -1)
# P 值
1 - pchisq(q = chi, df = n -1)
```

### 总体未知均值检验

考虑前面正态总体均值检验中的假设 I 的形式，若总体的分布形式未知，则需要 Wilcoxon （威尔科克森）秩和检验 `wilcox.test()` 来做均值的比较。

```{r}
wilcox.test(x = x, mu = 1, alternative = "greater")
```

相比于 t 检验，P 值更小。

### 总体未知方差检验

## 两样本检验 {#sec-two-samples}

设 $x_1,\cdots,x_{n_1}$ 是来自总体 $\mathcal{N}(\mu_1,\sigma_1^2)$ 的样本，设 $y_1,\cdots,y_{n_2}$ 是来自总体 $\mathcal{N}(\mu_2,\sigma_2^2)$ 的样本。

### 正态总体均值检验

常见检验问题

$$
\begin{aligned}
\mathrm{I}   \quad H_0: \mu_1 - \mu_2 \leq 0 \quad vs. \quad H_1: \mu_1 - \mu_2 > 0 \\
\mathrm{II}  \quad H_0: \mu_1 - \mu_2 \geq 0 \quad vs. \quad H_1: \mu_1 - \mu_2 < 0 \\
\mathrm{III} \quad H_0: \mu_1 - \mu_2 = 0 \quad vs. \quad H_1: \mu_1 - \mu_2 \neq 0
\end{aligned}
$$

#### 方差已知

$$
u = \frac{(\bar{X} - \bar{Y}) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}} }
$$

检验统计量服从标准正态分布 $u \sim N(0,1)$，检验统计量 $u$ 对应的样本值 $u_0$，检验的拒绝域和 $P$ 值如下

$$
W_1 = \{u \geq u_{1 - \alpha} \}, \quad p_1 = 1 - \varPhi(u_0) 
$$

```{r}
n_1 <- 100
n_2 <- 80
mu_1 <- 10
sigma_1 <- 2.5
mu_2 <- 6
sigma_2 <- 4.5

set.seed(20232023)
x1 <- rnorm(n_1, mean = mu_1, sd = sigma_1)
y1 <- rnorm(n_2, mean = mu_2, sd = sigma_2)
u0 <- (mean(x1) - mean(y1)) / sqrt(sigma_1^2 / n_1 + sigma_2^2 / n_2)
u0
```

对检验问题 I，给定显著性水平 $\alpha = 0.05$，得出拒绝域 $\{ u \geq 1.645\}$，计算样本观察值得到的检验统计量的值 $u_0 = 6.779$，而该值落在拒绝域，所以拒绝原假设，即拒绝 $\mu_1 - \mu_2 \leq 0$，则接受 $\mu_1 - \mu_2 > 0$。

```{r}
# 计算拒绝域
qnorm(1 - 0.05)
# 计算 P 值
1 - pnorm(u0)
```

#### 方差未知但相等

设 $x_1,\cdots,x_{n_1}$ 是来自总体 $\mathcal{N}(\mu_1,\sigma^2)$ 的样本，设 $y_1,\cdots,y_{n_2}$ 是来自总体 $\mathcal{N}(\mu_2,\sigma^2)$ 的样本。

t 检验，检验统计量服从自由度为 $n_1 + n_2 - 2$ 的 t 分布

$$
t = \frac{\bar{x} -\bar{y}}{s_0\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
$$

其中，

$$
\begin{aligned}
& \bar{x} = \sum_{i=1}^{n_1}x_i \quad \bar{y} = \sum_{i=1}^{n_2}y_i \\
& s_0^2 = \frac{1}{n_1 + n_2 - 2}\big(\sum_{i=1}^{n_1}(x_i - \bar{x})^2 + \sum_{i=1}^{n_2}(y_i - \bar{y})^2\big)
\end{aligned}
$$

```{r}
s_w <- sqrt(1 / (n_1 + n_2 - 2) * ((n_1 - 1) * var(x1) + (n_2 - 1) * var(y1)))
t0 <- (mean(x1) - mean(y1)) / (s_w * sqrt(1 / n_1 + 1 / n_2))
t0
```

样本观察值 $t_0 = 8.155 > t_{0.95}(n_1 + n_2 -2) = 1.653$ 落在拒绝域内，对于检验问题 I 我们要拒绝原假设

```{r}
# 临界值：0.95 分位点对应的分位数
qt(1 - 0.05, df = n_1 + n_2 - 2)
# p 值
1 - pt(t0, df = n_1 + n_2 - 2, lower.tail = TRUE)
```

利用 R 内置的 `t.test()` 函数计算

```{r}
t.test(x = x1, y = y1, alternative = "greater", var.equal = TRUE)
```

检验统计量的值及对应的 P 值都是一样的。

```{r}
# 方差未知但相等
t.test(extra ~ group, data = sleep, var.equal = TRUE)
```

#### 方差未知且不等

设 $x_1,\cdots,x_{n_1}$ 是来自总体 $\mathcal{N}(\mu_1,\sigma_1^2)$ 的样本，设 $y_1,\cdots,y_{n_2}$ 是来自总体 $\mathcal{N}(\mu_2,\sigma_2^2)$ 的样本。

Welch（韦尔奇） t 检验

$$
T = \frac{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}{\sqrt{\frac{s_x^2}{n_1} + \frac{s_y^2}{n_2}} }
$$

其中，$s_x^2$ 表示样本 x 的方差 $s_x^2 = \frac{1}{n_1-1}\sum_{i=1}^{n_1}(x_i -\bar{x})^2$ ，$s_y^2$ 表示样本 y 的方差 $s_y^2 = \frac{1}{n_2-1}\sum_{i=1}^{n_2}(y_i -\bar{y})^2$ 。检验统计量 $T$ 服从自由度为 $l$ 的 t 分布。

$$
l = \frac{s_0^4}{ \frac{s_x^4}{n_1^2(n_1 - 1)} + \frac{s_y^4}{n_2^2(n_2-1)} }
$$

其中， $s_0^2 = s_x^2 / n_1 + s_y^2/n_2$，$l$ 通常不是整数，实际使用时，$l$ 可取最近的整数。

```{r}
s0 <- var(x1) / n_1 + var(y1) / n_2
l <- s0^2 / (var(x1)^2 / (n_1^2 * (n_1 - 1)) + var(y1)^2 / (n_2^2 * (n_2 - 1)))
l
```

所以， $l$ 可取 127。检验统计量的值如下

```{r}
t0 <- (mean(x1) - mean(y1)) / sqrt(s0)
t0
```

```{r}
# 临界值：0.95 分位点对应的分位数
qt(1 - 0.05, df = 127)
# p 值
1 - pt(t0, df = 126, lower.tail = TRUE)
```

与函数 `t.test()` 比较

```{r}
t.test(x = x1, y = y1, alternative = "greater", var.equal = FALSE)
```

举例：sleep 数据集

```{r}
#| label: fig-sleep
#| fig-width: 5
#| fig-height: 4
#| fig-cap: 学生睡眠数据的分布
#| fig-showtext: true
#| echo: false

data("sleep")
library(ggplot2)
ggplot(aes(x = group, y = extra, color = group), data = sleep) +
  geom_boxplot() +
  geom_jitter() +
  theme_classic()
```

```{r}
# 方差未知且不等
t.test(extra ~ group, data = sleep, var.equal = FALSE)
```

1.  两样本的样本量很大，总体方差未知，检验两样本均值的显著性检验，极限分布是正态，$u$ 检验
2.  两个样本的样本量不是很大，总体方差也未知，检验两样本均值的显著性检验，即著名的 Behrens-Fisher 问题，Welch 在 1938 年提出近似服从自由度为 $\ell$ 的 t 分布。

::: callout-note
Egon Pearson 接过他父亲 Karl Pearson 的职位，担任伦敦大学学院的高尔顿统计教授。许宝騄（Pao-Lu Hsu）在 Jerzy Neyman 和 Egon Pearson 主编的杂志《Statistical Research Memoirs》发表第一篇关于 Behrens-Fisher 问题的论文 [@Hsu1938]，1998 年关于 Behrens-Fisher 问题的综述 [@Kim1998]。陈家鼎和郑忠国一起整理了许宝騄的生平事迹和学术成就，见[《许宝騄先生的生平和学术成就》](https://www.math.pku.edu.cn/misc/probstat/doc.pdf)。钟开涞（Kai-Lai Chung）将许宝騄的论文集整理出版 [@HSU1983]。
:::

t 检验的影响是如此巨大，以至于广泛存在于具有统计功能的软件中，比如办公软件里的 t 检验。以 MacOS 上的 Numbers 表格软件为例，如 @fig-numbers-ttest 所示，首先打开 Numbers 软件，新建工作表，输入两组数值，然后点击空白处，再从顶部导航栏找到「插入」菜单，「公式」选项，点击扩展选项「新建公式」，在弹出的会话条里输入 TTEST，依次选择第一组，第二组值，检验类型和样本类型，最后点击确认，即可得到两样本 t 检验的 P 值结果。

```{r}
#| label: fig-numbers-ttest
#| fig-cap: 办公软件 Numbers 的两样本 t 检验
#| echo: false
#| out-width: 80%

knitr::include_graphics(path = "screenshots/number-ttest.png")
```

微软 Excel 办公软件也提供 t 检验计算器，和 MacOS 系统上的 Numbers 办公软件类似，它提供 `T.TEST` 函数，计算结果也一样，此处从略。R 软件自带 `t.test()` 函数，也是用于做 t 检验，如下：

```{r}
t.test(x = c(3, 4, 5, 8, 9, 1, 2, 4, 5), y = c(6, 19, 3, 2, 14, 4, 5, 17, 1))
```

### 正态总体方差检验

比较两个正态总体的方差是否相等，F 检验。

```{r}
var.test(extra ~ group, data = sleep)
```

### 总体未知均值检验

在总体分布未知的情况下，比较均值是否相等的检验。

-   `wilcox.test()` 适用于单样本和两样本的均值检验，单样本 Wilcoxon 秩和检验，两样本 Wilcoxon 符号秩检验，后者也叫 Mann-Whitney 检验。
-   `kruskal.test()` 适用于两样本和多样本，比较多个均值是否相等的检验，Kruskal-Wallis 秩和检验。

单样本和两样本 `wilcox.test()`。

```{r}
wilcox.test(extra ~ group, data = sleep)
```

与 `wilcox.test()` 等价的线性模型

```{r}
signed_rank <- function(x) sign(x) * rank(abs(x))
fit <- lm(signed_rank(extra) ~ group, data = sleep)
summary(fit)
```

两样本和多样本 `kruskal.test()` 。

```{r}
kruskal.test(extra ~ group, data = sleep)
```

与 `kruskal.test()` 等价的线性模型表示。

```{r}
fit <- lm(rank(extra) ~ group, data = sleep)
summary(fit)
```

### 总体未知方差检验

对总体没有分布要求的方差齐性检验方法有四个，按方法类型和适用范围分类，见下 @tbl-bartlett-test 。

|            | 两个样本                        | 多个样本          |
|------------|---------------------------------|-------------------|
| 参数检验   | `bartlett.test()`               | `bartlett.test()` |
| 非参数检验 | `ansari.test()` / `mood.test()` | `fligner.test()`  |

: 检验方法分类 {#tbl-bartlett-test}

Bartlett （巴特利特）检验 `bartlett.test()` 对总体的分布形式没有要求，检验各个组的方差是否有显著性差异，即方差齐性检验，属于参数检验，适用于多个样本的情况。

```{r}
# 两样本
bartlett.test(extra ~ group, data = sleep)
```

Ansari-Bradley 检验 `ansari.test()` 和 Mood 检验 `mood.test()` 属于两样本的非参数检验，检验尺度参数是否相同（齐性）。Fligner-Killeen 检验 `fligner.test()` 也属于非参数检验，适用于两样本和多样本的情况。非参数检验常涉及位置参数和尺度参数这一对概念，就正态分布而言，位置参数可以理解为均值 $\mu$ ，尺度参数可以理解为方差 $\sigma^2$ 。

```{r}
ansari.test(extra ~ group, data = sleep)
mood.test(extra ~ group, data = sleep)
fligner.test(extra ~ group, data = sleep)
```

## 多样本检验 {#sec-multi-samples}

本节考虑 Base R 内置的 PlantGrowth 数据集，它收集自 Annette J. Dobson 所著书籍《An Introduction to Statistical Modelling》[@Dobson1983] 第 2 章第 2 节的案例 --- 研究植物在两种不同试验条件下的生长情况，植物通过光合作用吸收土壤的养分和空气中的二氧化碳，完成积累，故以植物的干重来刻画植物的生长情况，首先将几乎相同的种子随机地分配到实验组和对照组，基于完全随机实验设计（completely randomized experimental design），经过预定的时间后，将植物收割，干燥并称重。

```{r}
str(PlantGrowth)
```

设立对照组（控制组）ctrl 和实验组 trt1 和 trt2，比较不同的处理方式对植物干重的影响

```{r}
summary(PlantGrowth)
```

每个组都有 10 颗植物，生长情况如 @fig-plant-growth 所示

```{r}
#| label: fig-plant-growth
#| fig-width: 5
#| fig-height: 4
#| fig-cap: "植物干重"
#| fig-showtext: true

## Annette J. Dobson 扩展的 Plant Weight Data 数据，见 59 页
library(ggplot2)
ggplot(data = PlantGrowth, aes(x = group, y = weight, color = group)) +
  geom_boxplot() +
  geom_jitter() +
  theme_minimal()
```

### 正态总体均值检验

#### 假定同方差

讲清楚原假设和备择假设。讲清楚假设检验、方差分析、一般线性模型（包含广义线性模型和线性混合效应模型）的关系。

$\sigma_i^2 = \mathsf{Var}\{\epsilon_{ij}\}, i = 1,2,3$ 表示第 $i$ 组的方差，

$$
y_{ij} = \mu + \epsilon_{ij}, i = 1,2,3
$$

其中 $\mu$ 是固定的未知参数。单因素方差分析 `oneway.test()`

```{r}
# 假设各组方差相同
oneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)
```

线性模型也假定各个组的方差是相同的，模型显著性检验的结果和上面是一致的。

```{r}
fit_lm <- lm(weight ~ group, data = PlantGrowth)
anova(fit_lm) # 或者 summary(fit)
```

模型输出整理成 @tbl-lm-plant-growth

```{r}
#| label: tbl-lm-plant-growth
#| tbl-cap: "线性回归的输出"
#| echo: false

# 整理模型输出到数据框
fit_lm_output <- round(coef(summary(fit_lm)), 4)
# 指定行名和列名
rownames(fit_lm_output) <- c("$\\alpha$", "$\\beta_1$", "$\\beta_2$")
colnames(fit_lm_output)[4] <- "$P(T > |t|)$"
knitr::kable(fit_lm_output,
  escape = FALSE, 
  col.names = c("估计值", "标准差", "t 统计量", "P 值")
)
```

双因素方差分析 `aov()` 支持双因素方差分析

```{r}
aov(weight ~ group, data = PlantGrowth)
```

#### 假定异方差

```{r}
# 计算各个组的方差
aggregate(data = PlantGrowth, weight ~ group, FUN = var)
```

各个组的方差确实不太相同。

```{r}
# 假设各组方差不同
oneway.test(weight ~ group, data = PlantGrowth, var.equal = FALSE)
```

线性混合效应模型，假定每一组（层）有不同的方差。

```{r}
fit_gls <- nlme::gls(weight ~ 1,
  data = PlantGrowth, method = "ML",
  weights = nlme::varIdent(form = ~ 1 | group)
)
summary(fit_gls)
```

考虑每个组有不同的方差，放开同方差的假设，发现，从对数似然的角度来看，有一定提升。

```{r}
logLik(fit_lm)
logLik(fit_gls)
```

### 正态总体方差检验

后面总体分布未知的情况下的方差检验也都可以用在这里。

设 $x_1,\cdots,x_{n_1}$ 是来自总体 $\mathcal{N}(\mu_1,\sigma_1^2)$ 的样本，设 $y_1,\cdots,y_{n_2}$ 是来自总体 $\mathcal{N}(\mu_2,\sigma_2^2)$ 的样本，设 $z_1,\cdots,z_{n_3}$ 是来自总体 $\mathcal{N}(\mu_3,\sigma_3^2)$ 的样本。

$$
\sigma_1^2 = \sigma_2^2 = \sigma_3^2 \quad vs. \quad \sigma_1^2,\sigma_2^2,\sigma_3^2 \quad  \text{不全相等}
$$

### 总体未知均值检验

Kruskal-Wallis 秩和检验 `kruskal.test()` 检验均值是否齐性。

```{r}
kruskal.test(weight ~ group, data = PlantGrowth)
```

等价的线性模型表示

```{r}
fit_lm <- lm(rank(weight) ~ group, data = PlantGrowth)
anova(fit_lm) # summary(fit_lm)
```

Friedman 检验是非参数检验。适用于单因素重复测量数据的方差分析，检验是否存在一组值显著高于或低于其他组。术语涉及实验设计，比如完全区组设计 complete block designs 。

典型场景：n 个品酒师对 k 瓶葡萄酒打分，是否存在一组打分显著高于其他组。检验睡眠质量一组人显著好于另一组人。

```{r}
friedman.test(extra ~ group | ID, data = sleep)
```

`formula` 参数取值为 `a ~ b | c` ，`a` 表示数据值，`b` 分组变量 groups，`c` 表示 blocks。

Quade 检验 `quade.test()` 与 Friedman 检验类似，Quade 检验应用于 unreplicated complete block designs。

```{r}
quade.test(extra ~ group | ID, data = sleep)
```

### 总体未知方差检验

三个及以上样本的方差齐性检验。进一步地，我们在线性模型的基础上考虑每个实验组有不同的方差，先做方差齐性检验。

```{r}
# 参数检验
bartlett.test(weight ~ group, data = PlantGrowth)
# 非参数检验
fligner.test(weight ~ group, data = PlantGrowth)
```

检验的结果显示，可以认为三个组的方差没有显著差异。

## 计数数据检验 {#sec-count-data}

计数数据，通俗来说，对象是一个一个或一份一份的，可数的、离散的数据，比如人数。

```{r}
#| eval: false
#| echo: false

# 逻辑回归模型 二分 dichotomous logit regression
glm(family = binomial(link = "logit"))
# Probit 回归模型 二分 dichotomous probit regression
glm(family = binomial(link = "probit"))
# 泊松回归
glm(family = poisson(link = "log"))
# 多项逻辑回归模型
nnet::multinom()
# 比例比/比值比/优势比 有序的多分类模型
MASS::polr()
```

### 比例检验 {#sec-prop-test}

关于比例的检验问题

$$
\begin{aligned}
H_0: P_A = P_B \quad vs. \quad H_1: P_A > P_B \\
H_0: P_A = P_B \quad vs. \quad H_1: P_A < P_B
\end{aligned}
$$

$H_0$ 成立的情况下，暗示着两个样本来自同一总体。

比例检验 `prop.test()` 与比例趋势检验 `prop.trend.test`。Wilson 检验统计量 [@Wilson1927] 考虑单样本比例 $p$ 的区间估计问题。

函数 `prop.test` 用来检验两组或多组二项分布的成功概率（比例）是否相等，或等于给定的值。近似检验，多组数据的比例检验，可以理解为比例齐性检验。

原假设：四个组里面病人中吸烟的比例是相同的 备择假设：四个组里面至少有一个组的吸烟比例是不同的

```{r}
smokers <- c(83, 90, 129, 70)
patients <- c(86, 93, 136, 82)
prop.test(smokers, patients)
prop.trend.test(smokers, patients)
```

设随机变量 X 服从参数为 $p$ 的二项分布 $b(n, p)$， $Y$ 服从参数为 $\theta$ 的二项分布 $b(m,\theta)$， $m,n$ 都假定为较大的正整数，检验如下问题

$$
H_0: P_A \geq P_B \quad vs. \quad H_1: P_A < P_B
$$

根据中心极限定理

$$
\frac{\bar{X} - \bar{Y}}{\sqrt{\frac{p(1-p)}{n} + \frac{\theta(1-\theta)}{m}}}
$$

近似服从标准正态分布 $N(0,1)$。如果用矩估计 $\bar{X}$ 和 $\bar{Y}$ 分别替代总体参数 $p$ 和 $\theta$，构造检验统计量

$$
T = \frac{\bar{X} - \bar{Y}}{\sqrt{\frac{\bar{X}(1-\bar{X})}{n} + \frac{\bar{Y}(1-\bar{Y})}{m}}}
$$

根据 Slutsky 定理，检验统计量 $T$ 近似服从标准正态分布，当 $T$ 偏大时，拒绝 $H_0$。该方法的优势在于当 $n,m$ 比较大时，二项分布比较复杂，无法建立统计表，利用标准正态分布表来给出检验所需要的临界值，简便易行！

当 $p$ 和 $\theta$ 都比较小，上述方法检验效果不好，原因在于由中心极限定理对 $\bar{X}$ 和 $\bar{Y}$ 的正态分布近似效果不好，或者间接地导致 $\bar{X}-\bar{Y}$ 的方差偏小，进而 $T$ 的分辨都不好，而且当 $p,\theta$ 很接近 1 时，上述现象也会产生！

下面介绍新的解决办法

上面的检验问题等价于

$$
H_0: \frac{P_A}{P_B} \geq 1 \quad vs. \quad H_1: \frac{P_A}{P_B} < 1
$$

引入检验统计量

$$
T^{\star} = \frac{\bar{X}}{\bar{Y}}
$$

同样由 Slutsky 定理和中心极限定理可知， $\bar{X}/\bar{Y}$ 近似服从 正态分布 $\mathcal{N}(1,\frac{1-\theta}{m\theta})$

当 $(T^\star - 1)/\hat\sigma$ 偏大时接受 $H_0$，临界值可通过 $\mathcal{N}(0, \hat\sigma^2)$ 分布表计算得到， $\hat\sigma^2$ 是对 $\frac{1-\theta}{m\theta}$ 的估计，比如取 $\hat\sigma^2 = \frac{1-\bar{Y}}{m}\cdot \frac{1}{\bar{Y}}$ 或取 $\hat\sigma^2 = \frac{1-\bar{Y}}{m}\cdot \frac{1}{\bar{X}}$

由于渐近方差形如 $\frac{1-\theta}{m\theta}$，因而在 $\theta$ 较小，渐近方差较大，克服了之前 $\bar{X} - \bar{Y}$的方差较小的问题

$p,\theta$ 很接近 1 时，我们取检验统计量

$$
T^{\star\star} = \frac{1-\bar{Y}}{1-\bar{X}}
$$

结论和 $T^\star$ 类似，当 $T^{\star\star}$ 偏大时，拒绝 $H_0$。

两个二项总体成功概率的比较 [@Song2011]

### 二项检验 {#sec-binom-test}

区间估计与假设检验是有紧密关系的，对于二项分布比例的 11 种区间估计方法的比较 [@Newcombe1998]。函数 `binom.test()` 来做二项检验，函数 `binom.test()` 用来检验伯努利试验中成功概率 $p$ 和给定概率 $p_0$ 的关系，属于精确检验 [@Clopper1934]。

比例 $p$ 的检验， 做 $n$ 次独立试验，样本 $X_1,\ldots,X_n \sim b(1, p)$，事件发生的总次数 $\sum_{i=1}^{n}X_i$。

```{r}
# 模拟一组样本
set.seed(20232023)
x <- sample(x = c(0, 1), size = 100, replace = TRUE, prob = c(0.8, 0.2))
```

二项分布中成功概率的检验

```{r}
binom.test(sum(x), n = 100, p = 0.5)
```

检验成功概率 p 是否等于 0.5， P 值 $5.514 \times 10^{-8}$ 结论是拒绝原假设

```{r}
binom.test(sum(x), n = 100, p = 0.2)
```

检验成功概率 p 是否等于 0.2， P 值 0.4534 结论是不能拒绝原假设

切比雪夫不等式（Chebyshev, 1821-1894）。设随机变量 $X$ 的数学期望和方差都存在，则对任意常数 $\epsilon > 0$，有

$$
\begin{aligned}
P(|X - EX| \geq \epsilon) & \leq \frac{Var(X)}{\epsilon^2} \\
P(|X - EX| \leq \epsilon) & \geq 1 - \frac{Var(X)}{\epsilon^2}
\end{aligned}
$$

### 泊松检验 {#sec-poisson-test}

泊松分布是 1837年由法国数学家泊松 （Poisson, 1781-1840） 首次提出。

`poisson.test()` 泊松分布的参数 $\lambda (>0)$ 的精确检验，适用于单样本和两样本。

```{r}
#| eval: false
#| echo: true

poisson.test(x,
  T = 1, r = 1,
  alternative = c("two.sided", "less", "greater"),
  conf.level = 0.95
)
```

### 卡方检验 {#sec-chisq-test}

列联表中的数据服从多项分布，关于独立性检验，有如下几种常见类型：

1.  相互独立 Mutual independence 所有变量之间相互独立，$X \perp Y \perp Z$ 。
2.  联合独立 Joint independence 两个变量的联合与第三个变量独立，$XY \perp Z$ 。
3.  边际独立 Marginal independence 当忽略第三个变量时，两个变量是独立的。列联表压缩
4.  条件独立 Conditional independence 当固定第三个变量时，两个变量是独立的，$X \perp Y | Z$。

本节数据来自著作《An Introduction to Categorical Data Analysis》[@Agresti2007] 的第2章习题 2.33，探索 1976-1977 年美国佛罗里达州的凶杀案件中被告肤色和死刑判决的关系。

```{r}
#| label: tbl-florida-ethnicity
#| tbl-cap: "佛罗里达州的凶杀案件统计数据"
#| echo: false

tbl <- expand.grid(
  Death = c("Yes", "No"), # 判决结果 是否死刑
  Defend = c("白人", "黑人"),  # 被告 肤色
  Victim = c("白人", "黑人")   # 原告 （被害人）肤色
)
ethnicity <- data.frame(tbl, Freq = c(19, 132, 11, 52, 0, 9,  6, 97))

# 长格式转宽格式
dat1 <- reshape(
  data = ethnicity, direction = "wide",
  idvar = c("Defend", "Victim"),
  timevar = "Death", v.names = "Freq", sep = "_"
)
# 制作表格
gt::gt(dat1) |> 
  gt::cols_label(
    Freq_Yes = "是",
    Freq_No = "否",
    Victim = "被害人",
    Defend = "被告"
  ) |> 
  gt::tab_spanner(
    label = "死刑",
    columns = c(Freq_Yes, Freq_No)
  ) |> 
  gt::opt_row_striping()
```

#### 独立性

皮尔逊卡方检验（ Pearson's $\chi^2$ 检验） `chisq.test()` 常用于列联表独立性检验和方差分析模型的拟合优度检验。下面是一个 $2 \times 2$ 的列联表。

|        | 第一列 | 第二列 | 合计      |
|--------|--------|--------|-----------|
| 第一行 | $a$    | $b$    | $a+b$     |
| 第二行 | $c$    | $d$    | $c+d$     |
| 合计   | $a+c$  | $b+d$  | $a+b+c+d$ |

: 卡方独立性检验

```{r}
# Death 死刑与 Defend （被告）独立性检验
m <- xtabs(Freq ~ Death + Defend, data = ethnicity)
m
chisq.test(m, correct = TRUE)
chisq.test(m, correct = FALSE)
```

当被告是白人时，死刑判决 19 个，占总的死刑判决数量的 19/36 = 52.78%，当被告是黑人时，死刑判决 17 个，占总的死刑判决数量的 17/36 = 47.22%。判决结果与被告种族没有显著关系，但与原告（受害人）种族是有关系的，请继续往下看。

```{r}
# Death 死刑与 Victim （原告）独立性检验
m <- xtabs(Freq ~ Death + Victim, data = ethnicity)
chisq.test(m, correct = TRUE)
chisq.test(m, correct = FALSE)
```

当受害人是白人时，死刑判决 30 个，占总的死刑判决数量的 30/36 = 83.33%，当受害人是黑人时，死刑判决 6 个，占总的死刑判决数量的 6/36 = 16.67%。受害人是白人时，死刑判决明显多于黑人。

多维列联表

```{r}
m <- xtabs(Freq ~ Death + Defend + Victim, data = ethnicity)
m
```

判决结果、被告种族、原告种族三者是否存在联合独立性，即考虑 (Victim, Death) 是否与 Defend 独立，(Victim, Defend) 是否与 Death 独立，(Death, Defend) 与 Victim 是否相互独立。

```{r}
fm <- loglin(table = m, margin = list(c(1, 2), c(1, 3), c(2, 3)), print = FALSE)
fm 
# 拟合对数线性模型
# fm <- loglin(m, list(c(1), c(2), c(3)))
# fm
```

似然比检验统计量（Likelihood Ratio Test statistic），皮尔逊 $\chi^2$ 统计量（Pearson X-square Test statistic）

```{r}
1 - pchisq(fm$lrt, fm$df)
```

拟合对数线性模型

```{r}
fit_dvp <- glm(Freq ~ ., data = ethnicity, family = poisson(link = "log"))
```

模型输出

```{r}
summary(fit_dvp)
```

Pearson $\chi^2$ 统计量

```{r}
sum(residuals(fit_dvp, type = "pearson")^2)
```

**MASS** 包计算模型参数的置信区间

```{r}
#| message: false
confint(fit_dvp, trace = FALSE)
```

对于单元格总样本量小于 40 或 T 小于 1 时，需采用费希尔精确检验（ Fisher 's Exact 检验）。

#### 边际独立性

费希尔精确检验：固定边际的情况下，检验列联表行和列之间的独立性 `fisher.test()` 。

`fisher.test()` 函数用法，统计原理和公式，适用范围和条件，概念背景和历史。

费舍尔 (Sir Ronald Fisher, 1890.2 -- 1962.7)[^common-statistical-tests-1] 和一位女士打赌，女士说能品出奶茶中奶和茶的添加顺序。

[^common-statistical-tests-1]: <https://en.wikipedia.org/wiki/Ronald_Fisher>

`fisher.test()` 针对计数数据，检验列联表中行和列的独立性。

```{r}
TeaTasting <- matrix(c(3, 1, 1, 3),
  nrow = 2,
  dimnames = list(
    Guess = c("Milk", "Tea"),
    Truth = c("Milk", "Tea")
  )
)
TeaTasting
```

```{r}
# 单边 P 值
fisher.test(TeaTasting, alternative = "greater")
# 双边 P 值
fisher.test(TeaTasting, alternative = "two.sided")
# 单边 P 值
sum(dhyper(x = c(3, 4), m = 4, n = 4, k = 4))
```

#### 对称性

用于计数数据的 McNemar's 卡方检验（ McNemar's $\chi^2$ 检验）：检验二维列联表行和列的对称性 `mcnemar.test()`。怎么理解对称性？看帮助实例。

```{r}
Performance <- matrix(c(794, 86, 150, 570),
  nrow = 2,
  dimnames = list(
    "1st Survey" = c("Approve", "Disapprove"),
    "2nd Survey" = c("Approve", "Disapprove")
  )
)
Performance
mcnemar.test(Performance)
```

#### 条件独立性

用于分层分类数据的 Cochran-Mantel-Haenszel 卡方检验：两个枚举（分类）变量的条件独立性，假定不存在三个因素的交互作用。Cochran-Mantel-Haenszel 检验 `mantelhaen.test()`

```{r}
str(UCBAdmissions)
```

`UCBAdmissions` 数据集是一个 $2\times 2 \times 6$ 的三维列联表，R 语言中常用 table 类型表示。实际上，table 类型衍生自 array 数组类型，当把 `UCBAdmissions` 当作一个数组操作时，1、2、3 分别表示 Admit、Gender、Dept 三个维度。

```{r}
mantelhaen.test(UCBAdmissions)
```

没有证据表明院系与性别之间存在关联。在给定院系的情况下，是否录取和性别没有显著关系。

```{r}
# 按系统计
apply(UCBAdmissions, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))

woolf <- function(x) {
  x <- x + 1 / 2
  k <- dim(x)[3]
  or <- apply(x, 3, function(x) (x[1, 1] * x[2, 2]) / (x[1, 2] * x[2, 1]))
  w <- apply(x, 3, function(x) 1 / sum(1 / x))
  1 - pchisq(sum(w * (log(or) - weighted.mean(log(or), w))^2), k - 1)
}
woolf(UCBAdmissions)
```

## 配对样本检验 {#sec-pairwise-data}

### 配对 t 检验 {#sec-pairwise-t-test}

两个组的配对 t 检验 `t.test(paired = TRUE)`

```{r}
t.test(extra ~ group, data = sleep, paired = TRUE)
```

两个组的配对 t 检验 `pairwise.t.test()` ，与前面的结果等价。

```{r}
pairwise.t.test(x = sleep$extra, g = sleep$group, paired = TRUE)
```

多个组两两配对的 t 检验 `pairwise.t.test()`

```{r}
pairwise.t.test(x = PlantGrowth$weight, g = PlantGrowth$group, paired = TRUE)
```

### 配对比例检验 {#sec-pairwise-prop-test}

`pairwise.prop.test()`

### 配对 Wilcoxon 检验 {#sec-pairwise-wilcox-test}

检验的是两个总体的均值是否相等。

配对 Wilcoxon 检验 `pairwise.wilcox.test()` 适用于两个及以上组的两两配对检验。

```{r}
pairwise.wilcox.test(x = PlantGrowth$weight, g = PlantGrowth$group)
```

Wilcoxon 检验 `wilcox.test()` 设置 `paired = TRUE` 也可以做配对检验，但是仅限于两个组。

```{r}
# 不支持
# wilcox.test(weight ~ group, data = PlantGrowth, paired = TRUE)
# 支持
wilcox.test(extra ~ group, data = sleep, paired = TRUE)
```

### 配对相关性检验 {#sec-cor-test}

配对样本的相关性检验 `cor.test()`：Pearson's 相关系数，Kendall's $\tau$ 检验或者 Spearman's $\rho$ 检验

```{r}
# cor.test(method = "pearson")  # lm(y ~ 1 + x)
# cor.test(method = "kendall")
# cor.test(method = "spearman") # lm(rank(y) ~ 1 + rank(x))
```

## 总体分布的检验

前面介绍的检验方法都是对总体的某个特征数（均值、方差）进行检验，下面介绍的检验方法是针对分布的性质。比如样本是否来自正态分布，两个样本是否来自同一分布，样本点之间是否相互独立，样本点列是否平稳等。通过检验方法探索样本的分布性质。

### 正态性检验

> Usually (but not always) doing tests of normality reflect a lack of understanding of the power of rank tests, and an assumption of high power for the tests (qq plots don't always help with that because of their subjectivity). When possible it's good to choose a robust method. Also, doing pre-testing for normality can affect the type I error of the overall analysis.
>
> --- Frank Harrell [^common-statistical-tests-2]

[^common-statistical-tests-2]: <https://stat.ethz.ch/pipermail/r-help/2005-April/070508.html>

检验：拒绝原假设和接受原假设的风险，数据本身和理论的正态分布的距离，抛开 P 值

Shapiro 和 Wilk 提出的 W 检验 `shapiro.test()`

```{r}
set.seed(20232023)
x <- rnorm(100, mean = 5, sd = 3)
shapiro.test(x)
```

> The issue really comes down to the fact that the questions: "exactly normal?", and "normal enough?" are 2 very different questions (with the difference becoming greater with increased sample size) and while the first is the easier to answer, the second is generally the more useful one.
>
> --- Greg Snow [^common-statistical-tests-3]

[^common-statistical-tests-3]: <https://stat.ethz.ch/pipermail/r-help/2009-May/390164.html>

EP 检验对多种备择假设有较高的效率，利用样本的特征函数和正态分布的特征函数的差的模的平方产生的一个加权积分得到 EP 检验统计量 [@Epps1983]

::: callout-tip
样本量 $n \geq 200$ EP 检验统计量 $T_{EP}$ 非常接近 $n = \infty$ 时 $T_{EP}$ 的分位数。
:::

设 $x_1, \ldots, x_n$ 是来自正态总体 $\mathcal{N}(\mu,\sigma^2)$ 的样本， EP 检验统计量定义为

$$
T_{EP} = 1 + \frac{n}{\sqrt{3}} + \frac{2}{n}\sum_{i=2}^{n}\sum_{j=1}^{i-1}\exp\big\{ - \frac{(x_j - x_i)^2}{2s^2_{\star}}  \big\} - \sqrt{2} \sum_{i=1}^{n}\exp\big\{- \frac{(x_i - \bar{x})^2}{4s^2_{\star}}  \big\}
$$

其中 $\bar{x},s^2_{\star}$ 分别是样本均值和（除以 $n$ 的）样本方差。

### 同分布检验 {#sec-ks-test}

Lilliefors 检验 [^common-statistical-tests-4] 和单样本的 ks 检验的关系

[^common-statistical-tests-4]: <https://personal.utdallas.edu/~herve/Abdi-Lillie2007-pretty.pdf>

> As to whether you can do a **Lilliefors test** for several groups, that depends entirely on your ability to understand what the underlying question would be (see Adams D 1979).
>
> --- Knut M. Wittkowski [^common-statistical-tests-5]

[^common-statistical-tests-5]: <https://stat.ethz.ch/pipermail/r-help/2004-February/045597.html>

Kolmogorov-Smirnov 检验：单样本或两样本的同分布检验 `ks.test()`

```{r}
# 数据 x 与正态分布比较
ks.test(x, y = "pnorm")
```

### 独立性检验 {#sec-Box-test}

时间序列独立性检验 `Box.test()` 计算 Box-Pierce 或 Ljung-Box 检验统计量来检查给定时间序列的独立性假设。

### 平稳性检验 {#sec-PP-test}

时间序列单位根检验，检验时间序列平稳性 Phillips-Perron 的单位根检验 `PP.test()`

```{r}
#| eval: false
#| echo: true

PP.test(x, lshort = TRUE)
```

### 球形检验 {#sec-mauchly-test}

Mauchly 球形检验 `mauchly.test()` 检验：Wishart 分布的协方差矩阵是否正比于给定的矩阵。多元分布的协方差矩阵。

如果 $X_1, X_2, \cdots, X_m$，$X_i \in \mathbb{R}^p$，$X_i \overset{i.i.d}{\sim} \mathrm{MVN}(0,\Sigma)$，即 $m$ 个样本点都服从均值为 $0$，协方差矩阵为 $\Sigma$ 的 $p$ 维多元正态分布 $\mathrm{MVN}(0,\Sigma)$，且样本点之间相互独立。则 $M = X'X$ 服从参数为 $\Sigma$ 和 $m$ 的 Wishart 分布 $W_p(\Sigma, m)$。

R 语言内置了一个模拟数生成器，可以直接模拟出服从 Wishart 分布 $W_p(\Sigma, m)$ 的样本，即 $n$ 个随机矩阵，$m = \mathrm{df}, \Sigma = \mathrm{Sigma}$。 R 语言命令如下：

``` r
rWishart(n, df, Sigma)
```

其中，整型参数 `n` 指定样本量，数值参数 `df` 指定自由度，正定的 $p \times p$ 矩阵 `Sigma` 指定 Wishart 分布的矩阵参数。`rWishart()` 返回一个 $p\times p \times n$ 数组 $R$，其中 $R[,,i]$ 是正定矩阵，是服从 Wishart 分布 $W_p(\Sigma, m)$ 的一个样本点，其中 $m = \mathrm{df}, \Sigma = \mathrm{Sigma}$。

```{r}
set.seed(2022)
# 构造 n 个随机矩阵
S <- matrix(c(1.2, 0.9, 0.9, 1.2), nrow = 2, ncol = 2)
rWishart(n = 3, df = 2, Sigma = S)
```

随机矩阵 $M$ 的期望 $\mathsf{E}(M) = m \times \Sigma$，随机矩阵 $M$ 中每个元素的方差

$$
\mathsf{Var}(M_{ij}) = m (\Sigma_{ij}^2 + \Sigma_{ii}\Sigma_{jj}), \quad S = \Sigma
$$

若 $p = 1$，即 $\Sigma$ 是一个标量 $\sigma^2$，Wishart 分布退化为自由度为 $\mathrm{df}$ 的卡方分布 $\chi^2$，即 $W_1(\sigma^2, m) = \sigma^2\chi_{m}^2$。下面计算随机矩阵 $M$ 的期望。

```{r}
set.seed(2022)
Wish <- rWishart(n = 3000, df = 2, Sigma = S)
# 计算随机矩阵 M 的期望
apply(Wish, MARGIN = 1:2, FUN = mean)
# 随机矩阵 M 的期望理论值
2 * S
```

接着计算随机矩阵 $M$ 的方差。

```{r}
# 样本方差
apply(Wish, MARGIN = 1:2, var)
# 理论方差
2*(S^2 + tcrossprod(diag(S)))
```

## 样本量的计算 {#sec-power-of-test}

检验的功效常用于样本量的计算

### t 检验的功效

```{r}
# power.t.test()
```

`power.t.test()` 计算单样本或两样本的 t 检验的功效，或者根据功效计算参数，如样本量

```{r}
#| label: fig-power-t-test
#| fig-cap: "t 检验的功效"
#| fig-width: 4
#| fig-height: 3
#| fig-showtext: true

n <- 30 # 样本量（只是一个例子）
x <- seq(0, 12, 0.01)
library(ggplot2)
dat <- data.frame(xx = x / sqrt(n), yy = 2 * (1 - pt(x, n - 1)))

ggplot(data = dat, aes(x = xx, y = yy)) +
  geom_line() +
  geom_vline(xintercept = c(0.01, 0.2, 0.5, 0.8, 1.2, 2), linetype = 2) +
  theme_classic() +
  labs(x = expression(d == frac(t, sqrt(n))), 
       y = expression(2 * (1 - pt(x, n - 1))))
```

```{r}
power.t.test(
  n = 100, delta = 2.2,
  sd = 1, sig.level = 0.05,
  type = "two.sample",
  alternative = "two.sided"
)
```

| 参数          | 含义                                                                            |
|:------------------|:----------------------------------------------------|
| `n`           | 每个组的样本量                                                                  |
| `delta`       | 两个组的均值之差                                                                |
| `sd`          | 标准差，默认值 1                                                                |
| `sig.level`   | 显著性水平，默认是 0.05 （犯第 I 类错误的概率）                                 |
| `power`       | 检验的功效（1 - 犯第 II 类错误的概率）                                          |
| `type`        | t 检验的类型 `"two.sample"` 两样本、`"one.sample"` 单样本或 `"paired"` 配对样本 |
| `alternative` | 单边或双边检验，取值为 `"two.sided"` 或 `"one.sided"`                           |

: 函数 `power.t.test()` 的参数及其含义 {#tbl-power-t-test}

参数 `n`，`delta`，`power`，`sd` 和 `sig.level` 必须有一个值为 `NULL`，为 `NULL` 的参数是由其它参数决定的。

```{r}
# 前面 t 检验的等价功效计算
library(pwr)
pwr.t.test(
  d = 2.2 / 6.4,
  n = 100,
  sig.level = 0.05,
  type = "two.sample",
  alternative = "two.sided"
)
```

### 比例检验的功效

```{r}
# power.prop.test()
```

`power.prop.test()` 计算两样本比例检验的功效

功效可以用来计算实验所需要的样本量，检验统计量的功效越大/高，检验方法越好，实验所需要的样本量越少

```{r}
# p1 >= p2 的检验 单边和双边检验
power.prop.test(
  p1 = .65, p2 = 0.6, sig.level = .05,
  power = 0.90, alternative = "one.sided"
)

power.prop.test(
  p1 = .65, p2 = 0.6, sig.level = .05,
  power = 0.90, alternative = "two.sided"
)
```

**pwr** 包 `pwr.2p.test()` 函数提供了类似 `power.prop.test()` 函数的功能

```{r}
library(pwr)
# 明确 p1 > p2 的检验
# 单边检验拆分更加明细，分为大于和小于
pwr.2p.test(
  h = ES.h(p1 = 0.65, p2 = 0.6),
  sig.level = 0.05, power = 0.9, alternative = "greater"
)
```

已知两样本的样本量不等，检验 H_0: $p_1 = p_2$ H_1: $p_1 \neq p_2$ 的功效

```{r}
pwr.2p2n.test(
  h = 0.30, n1 = 80, n2 = 245,
  sig.level = 0.05, alternative = "greater"
)
```

h 表示两个样本的差异，计算得到的功效是 0.75

### 方差分析的功效

`power.anova.test()` 计算平衡的单因素方差分析检验的功效

```{r}
power.anova.test(
  groups = 4,       #  4 个组  
  between.var = 1,  # 组间方差为 1
  within.var = 3,   # 组内方差为 3
  power = 0.95      # 1 - 犯第二类错误的概率
)
```

```{r}
library(pwr)
# f 是如何和上面的组间/组内方差等价指定的
pwr.anova.test(
  k = 4,            # 组数
  f = 0.5,          # 效应大小
  sig.level = 0.05, # 显著性水平
  power = 0.95      # 检验的效
)
```

## 统计检验方法

统计检验的一般方法。

### Wald 检验 {#sec-wald-test}

### Wilks 检验 {#sec-wilks-test}

也叫似然比检验

### Rao 检验 {#sec-rao-test}

也叫得分检验

## 假设检验与区间估计的关系

区间估计的意义是解决点估计可靠性问题，它用置信系数解决了对估计结果的信心问题，弥补了点估计的不足。置信系数是最大的置信水平。

Base R 提供的 `binom.test()` 函数可以精确计算置信区间，Clopper-Pearson 区间，而 `prop.test()` 函数可近似计算置信区间，Wilson 区间。

以二项分布的比例检验和二项检验为例。近似区间估计

```{r}
prop.test(x = 2, n = 10, p = 0.95, conf.level = 0.95, correct = TRUE)
```

精确区间估计

```{r}
binom.test(x = 2, n = 10, p = 0.95, conf.level = 0.95)
```

实际达到的置信度水平随真实的未知参数值和样本量的变化而**剧烈**波动，这意味着这种参数估计方法在实际应用中不可靠、真实场景中参数真值是永远未知的，样本量是可控的，并且是可以变化的。根本原因在于这类分布是离散的，比如这里的二项分布。当样本数据服从离散的分布，置信区间的端点也是离散的。这种缺陷是无法避免的，清晰的置信区间和离散的数据之间存在无法调和的冲突。
