# 统计计算 {#sec-statistical-computation}



## 优化问题与回归问题 {#sec-regression-optimization}

<!-- 
广义最小二乘拟合 nlme::gls  预测 nlme::predict.gls
用广义最小二乘拟合线性模型 MASS::lm.gls	
用广义最小二乘拟合趋势面 spatial::surf.gls

[nlsr](https://cran.r-project.org/package=nlsr)
[bestsubset](https://github.com/ryantibs/best-subset/) 最优子集回归
-->



1996 年出现 Lasso [@lasso1996]，由于缺少高效的求解算法，Lasso 在高维小样本特征选择研究中没有广泛流行，最小角回归(Least Angle Regression, LAR)算法 [@lar2004] 的出现有力促进了Lasso在高维小样本数据中的应用。为了解决Lasso的有偏估计问题，自适应 Lasso、松弛 Lasso， SCAD (Smoothly Clipped Absolute Deviation)[@scad2008]，MCP (Minimax Concave Penalty)[@mcp2010] 陆续出现。经典的普通最小二乘、广义最小二乘、岭回归、逐步回归、Lasso 回归、最优子集回归都可转化为优化问题，一般形式如下

$$
\underbrace{\hat{\theta}_{\lambda_n}}_{\text{待估参数}} \in \arg \min_{\theta \in \Omega} \left\{ \underbrace{\mathcal{L}(\theta;Z_{1}^{n})}_{\text{损失函数}} + \lambda_n \underbrace{\mathcal{R}(\theta)}_{\text{正则化项}} \right\}.
$$

下面尝试以 nloptr 包的优化器来展示求解过程，并与 Base R、**glmnet** 和 **MASS** 实现的回归模型比较。

<!-- 向量用小写，矩阵用大写 -->

$$
\arg \min_{\beta,\lambda} ~~ \frac{1}{2} || \mathbf{y} - \mathbf{X} \beta ||_2^2 +  \lambda ||\beta||_1
$$

其中，$X \in \mathbb{R}^{m\times n}$， $y \in \mathbb{R}^m$，$\beta \in \mathbb{R}^n$， $0 < \lambda \in \mathbb{R}$



## 对数似然与损失函数 {#sec-log-likelihood}

随机变量 X 服从参数为 $\lambda > 0$ 的指数分布，密度函数 $p(x)$ 为

\begin{equation*}
\begin{array}{l}
 p(x) = \left\{ 
    \begin{array}{l}
    \lambda\mathrm{e}^{-\lambda x},  x \geq 0\\
    0, \quad x < 0
    \end{array} \right.
\end{array}
\end{equation*}

其中，$\lambda > 0$，下面给定一系列模拟样本观察值 $x_1, x_2, \cdots, x_n$，估计参数 $\lambda$。对数似然函数 $\ell(\lambda) = \log \prod_{i=1}^{n} f(x_i) = n \log \lambda - \lambda \sum_{i=1}^{n}x_i$。解此方程即可得到 $\lambda$ 的极大似然估计 $\lambda_{mle} = \frac{1}{\bar{X}}$，极大值 $\ell(\lambda_{mle}) = - n(1 + \log \bar{X})$。

根据上述样本，计算样本均值 $(\mu - 1.5*\sigma/\sqrt{n}, \mu + 1.5*\sigma/\sqrt{n})$ 和方差 $(0.8\sigma, 1.5\sigma)$。


已知正态分布 $f(x) = \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{- \frac{(x - \mu)^2}{2\sigma^2}}$ 的对数似然形式如下：

$$
\ell(\mu,\sigma^2) = \log \prod_{i=1}^{n} f(x_i) = \sum_{i=1}^{n}\log f(x_i)
$$ {#eq-log-lik-norm}

参数 $\mu$ 和 $\sigma^2$ 的极大似然估计为

在 R 语言中，正态分布的密度函数的对数可用 `dnorm(..., log = TRUE)` 计算。

生成服从指数分布的样本，计算样本的均值和方差，依据均值和方差构造区间，然后将区间网格化，在此网格上绘制正态分布的对数似然函数。即不知道正态分布的参数，将从指数分布模拟出来的样本用正态分布拟合。

<!-- 绕那么大一个圈子，其实就是绘制正态分布的对数似然函数。 -->

```{r}
#| label: fig-log-likelihood
#| fig-cap: "正态分布参数的负对数似然函数"
#| fig-width: 5
#| fig-height: 4.5

set.seed(2021)
n <- 20 # 随机数的个数
x <- rexp(n, rate = 5) # 服从指数分布的随机数
m <- 40 # 网格数
mu <- seq(
  mean(x) - 1.5 * sd(x) / sqrt(n),
  mean(x) + 1.5 * sd(x) / sqrt(n),
  length.out = m
)
sigma <- seq(0.8 * sd(x), 1.5 * sd(x), length.out = m)
df <- expand.grid(x = mu, y = sigma)
# 正态分布的对数似然
loglik <- function(b, x0) -sum(dnorm(x0, b[1], b[2], log = TRUE))

df$fnxy <- apply(df, 1, loglik, x0 = x)
library(lattice)
wireframe(
  data = df, fnxy ~ x * y,
  shade = TRUE, drape = FALSE,
  xlab = expression(mu),
  ylab = expression(sigma),
  zlab = list(expression(-loglik(mu, sigma)), rot = 90),
  scales = list(arrows = FALSE, col = "black"),
  # 减少三维图形的边空
  lattice.options = list(
    layout.widths = list(
      left.padding = list(x = -.6, units = "inches"),
      right.padding = list(x = -1.0, units = "inches")
    ),
    layout.heights = list(
      bottom.padding = list(x = -.8, units = "inches"),
      top.padding = list(x = -1.0, units = "inches")
    )
  ),
  par.settings = list(axis.line = list(col = "transparent")),
  screen = list(z = 120, x = -70, y = 0)
)
```


<!-- 
添加极大值点，除指数分布外，还有正态、二项、泊松分布观察其似然曲面的特点，都是单峰，有唯一极值点，再考虑正态混合模型的似然曲面 

[Getting the most out of logistic regression](https://gongcastro.github.io/blog/logistic-regression/logistic-regression.html)
-->

## 贝叶斯计算框架 Stan {#sec-bayesian-computation-stan}

[Stan](https://github.com/stan-dev/stan) 是一款贝叶斯计算软件，定义了一套概率编程语言，提供 R、Python、Matlab 语言等众多的编程接口，[CmdStan](https://github.com/stan-dev/cmdstan) 是其命令行编程接口，与 Stan 版本保持同步，[CmdStanR](https://github.com/stan-dev/cmdstanr) 包集成 CmdStan 软件，可以非常方便地分析运行结果。下面以二项逻辑回归模型为例，介绍

响应变量 $Y$ 服从伯努利分布 $\mathrm{Binom}(1, p)$，取值是 0 或 1，对线性预测 $X\beta$ 做 Logistic 变换

$$
\mathrm{E}Y = p = \mathrm{Logistic}(X\beta) = \frac{1}{1 + e^{-X\beta}}
$$

Logistic 的逆变换

$$
\mathrm{Logistic}^{-1}(p)= \ln\big(\frac{p}{1-p}\big) = X\beta
$$

从一个逻辑回归模型模拟一组样本，2500 条记录，10 个观测变量，其中只有变量 $X_1$ 和 $X_2$ 的系数非零，代码如下：

```{r}
set.seed(2023)
n <- 2500
k <- 10
X <- matrix(rnorm(n * k), ncol = k)
y <- rbinom(n, size = 1, prob = plogis(3 * X[,1] - 2 * X[,2] + 1))
```

Base R 提供的函数 `glm.fit()` 拟合模型，指定联系函数为 logit 变换

```{r}
fit_r <- glm.fit(x = X, y = y, family = binomial(link = "logit"))
coef(fit_r)
```

调用 **glmnet** 包的函数 `glmnet()` 拟合模型，指定指数族的具体形式为二项分布，伯努利分布是二项分布的特殊形式，也叫两点分布或0-1分布。

```{r}
library(glmnet)
fit_glm <- glmnet(x = X, y = y, family = "binomial")
```

逻辑回归模型的系数在 L1 正则下的解的迭代路径图

```{r}
#| label: fig-logit-glmnet
#| fig-cap: "模型系数的路径"
#| fig-width: 5
#| fig-height: 4

plot(fit_glm)
```

从图可见，剩余两个系数是非零的，一个是 3 一个是 -2，其余都压缩为 0 了。

Stan 编码的模型代码如下：

```{verbatim, file="code/bernoulli_logit_glm.stan", lang="stan"}
```

调用 CmdStan 拟合模型

```{r}
#| label: compile-logit-model
#| message: false
#| results: hide

library(cmdstanr)
mdata <- list(k = k, n = n, y = y, X = X)
# 来自 stan-dev/cmdstanr
mod_logit <- cmdstan_model(
  stan_file = "code/bernoulli_logit_glm.stan",
  compile = TRUE,
  cpp_options = list(stan_threads = TRUE)
)
fit_logit <- mod_logit$sample(
  data = mdata, 
  chains = 4, 
  parallel_chains = 1,
  iter_warmup = 1000, # 每条链预处理迭代次数
  iter_sampling = 2000, # 每条链总迭代次数
  threads_per_chain = 1, # 每条链设置一个线程
  seed = 20232023,
  show_messages = FALSE, 
  refresh = 0
)
fit_logit
```


逻辑回归模型的参数 $\beta_1$ 和 $\beta_2$ 的后验分布图

```{r}
#| label: fig-post-logit
#| fig-cap: "参数的后验分布"
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 6
#| message: false

library(ggplot2)
library(bayesplot)
# 参数的后验分布
mcmc_hist(fit_logit$draws(c("beta[1]", "beta[2]")),
  facet_args = list(
    labeller = ggplot2::label_parsed,
    strip.position = "top",
    ncol = 1
  )
) + theme_classic()
```

