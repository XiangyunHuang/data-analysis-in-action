# 时间序列回归 {#sec-time-series-regression}

```{r}
#| echo: false

source("_common.R")
```

```{r}
#| message: false

library(cmdstanr)
library(zoo)
library(xts) # xts 依赖 zoo
library(fGarch)
library(INLA)
library(mgcv)
library(tensorflow)
library(ggplot2)
library(bayesplot)
```

## 随机波动率模型

随机波动率模型主要用于股票时间序列数据建模。本节以美团股价数据为例介绍随机波动率模型，并分别以 Stan 框架和 **fGarch** 包拟合模型。

```{r}
#| label: fig-meituan-stack
#| message: false
#| fig-cap: 美团股价走势
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4

# 美团上市至 2023-07-15
meituan <- readRDS(file = "data/meituan.rds")
library(zoo)
library(xts)
library(ggplot2)
autoplot(meituan[, "3690.HK.Adjusted"]) +
  theme_classic() +
  labs(x = "日期", y = "股价")
```

对数收益率的计算公式如下：

$$
\mathrm{对数收益率} = \ln(\mathrm{今日收盘价} / \mathrm{上一收盘价} ) = \ln (1 + \mathrm{普通收益率})
$$

下图给出股价对数收益率变化和股价对数收益率的分布，可以看出在不同时间段，收益率波动幅度是不同的，美团股价对数收益率的分布可以看作正态分布。

```{r}
#| label: fig-meituan-log-return
#| fig-cap: 美团股价对数收益率的情况
#| fig-subcap: 
#|  - 对数收益率的变动
#|  - 对数收益率的分布
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| layout-ncol: 2

meituan_log_return <- log(1 + diff(meituan[, "3690.HK.Adjusted"]) /  meituan[, "3690.HK.Adjusted"])[-1,]
autoplot(meituan_log_return) +
  theme_classic() +
  labs(x = "日期", y = "对数收益率")
ggplot(data = meituan_log_return, aes(x = `3690.HK.Adjusted`)) +
  geom_histogram(color = "black", fill = "gray", bins = 30) +
  theme_classic() +
  labs(x = "对数收益率", y = "频数（天数）")
```

检查对数收益率序列的自相关图

```{r}
#| label: fig-log-return
#| fig-cap: 对数收益率的自相关图
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| par: true

acf(meituan_log_return, main = "")
```

发现，滞后 2、3、6、26 阶都有出界，滞后 17 阶略微出界，其它的自相关都在零水平线的界限内。

```{r}
Box.test(meituan_log_return, lag = 12, type = "Ljung")
```

在 0.05 水平下拒绝了白噪声检验，说明对数收益率序列存在相关性。同理，也注意到对数收益率的绝对值和平方序列都不是独立的，存在相关性。

```{r}
# ARCH 效应的检验
Box.test((meituan_log_return - mean(meituan_log_return))^2, lag = 12, type = "Ljung")
```

结果高度显著，说明有 ARCH 效应。

### Stan 框架

随机波动率模型如下

$$
\begin{aligned}
y_t        &=    \epsilon_t \exp(h_t / 2) \\
h_{t+1}    &=    \mu + \phi (h_t - \mu) + \delta_t \sigma \\
h_1        &\sim \textsf{normal}\left( \mu, \frac{\sigma}{\sqrt{1 - \phi^2}} \right) \\
\epsilon_t &\sim \textsf{normal}(0,1) \\
\delta_t   &\sim \textsf{normal}(0,1)
\end{aligned}
$$

其中， $y_t$ 表示在时间 $t$ 时股价的回报，$\epsilon_t$ 表示股价回报在时间 $t$ 时的白噪声扰/波动，$\delta_t$ 表示波动率在时间$t$ 时的波动。$h_t$ 表示对数波动率，带有参数 $\mu$ （对数波动率的均值），$\phi$ （对数波动率的趋势）。代表波动率的序列 $\{h_t\}$ 假定是平稳 $(|\phi| < 1)$ 的随机过程，$h_1$ 来自平稳的分布（此处为正态分布），$\epsilon_t$ 和 $\delta_t$ 是服从不相关的标准正态分布。

Stan 代码如下

```{verbatim, file="code/stochastic_volatility_models.stan", lang="stan"}
```

编译和拟合模型

```{r}
#| message: false

library(cmdstanr)
# 编译模型
mod_volatility_normal <- cmdstan_model(
  stan_file = "code/stochastic_volatility_models.stan",
  compile = TRUE, cpp_options = list(stan_threads = TRUE)
)
# 准备数据
mdata = list(T = 1274, y = as.vector(meituan_log_return))
# 拟合模型
fit_volatility_normal <- mod_volatility_normal$sample(
  data = mdata,
  chains = 2,
  parallel_chains = 2,
  iter_warmup = 1000, 
  iter_sampling = 1000, 
  threads_per_chain = 2, 
  seed = 20232023,
  show_messages = FALSE,
  refresh = 0
)
# 输出结果
fit_volatility_normal$summary(c("mu", "phi", "sigma", "lp__"))
```

### fGarch 包

[《金融时间序列分析讲义》](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/index.html)两个波动率建模方法

-   自回归条件异方差模型（Autoregressive Conditional Heteroskedasticity，简称 ARCH）。
-   广义自回归条件异方差模型 （Generalized Autoregressive Conditional Heteroskedasticity，简称 GARCH ）

确定 ARCH 模型的阶，观察残差的平方的 ACF 和 PACF 。

```{r}
#| label: fig-log-return-resid
#| fig-cap: 对数收益率的残差平方
#| fig-subcap: 
#| - 自相关图
#| - 偏自相关图
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| layout-ncol: 2
#| par: true

acf((meituan_log_return - mean(meituan_log_return))^2, main = "")
pacf((meituan_log_return - mean(meituan_log_return))^2, main = "")
```

发现 ACF 在滞后 1、2、3 阶比较突出，PACF 在滞后 1、2、16、18、29 阶比较突出。所以下面先来考虑低阶的 ARCH(2) 模型，设 $r_t$ 为对数收益率。

$$
\begin{aligned}
r_t &= \mu + a_t, \quad a_t = \sigma_t \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0,1) \\
\sigma_t^2 &= \alpha_0 + \alpha_1 a_{t-1}^2 
  + \alpha_2 a_{t-2}^2.
\end{aligned}
$$

拟合 ARCH 模型，比较模型估计结果，根据系数显著性的结果，采纳 ARCH(2) 模型。

```{r}
#| message: false

library(fGarch)
meituan_garch1 <- garchFit(~ 1 + garch(2, 0), data = meituan_log_return, trace = FALSE, cond.dist = "std")
summary(meituan_garch1)
```

函数 `garchFit()` 的参数 `cond.dist` 默认值为 `"norm"` 表示标准正态分布，`cond.dist = "std"` 表示标准 t 分布。模型均值的估计值接近 0 是符合预期的，且显著性没通过，对数收益率在 0 上下波动。将估计结果代入模型，得到

$$
\begin{aligned}
r_t &= -5.665 \times 10^{-5} + a_t, \quad a_t = \sigma_t \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0,1) \\
\sigma_t^2 &= 1.070 \times 10^{-3} + 0.1156 a_{t-1}^2 + 0.1438a_{t-2}^2.
\end{aligned}
$$

下面考虑 GARCH(1,1) 模型

$$
\begin{aligned}
r_t &= \mu + a_t, \quad a_t = \sigma_t \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0,1) \\
\sigma_t^2 &= \alpha_0 + \alpha_1 a_{t-1}^2 
  + \beta_1 \sigma_{t-1}^2.
\end{aligned}
$$

```{r}
meituan_garch2 <- garchFit(~ 1 + garch(1, 1), data = meituan_log_return, trace = FALSE, cond.dist = "std")
summary(meituan_garch2)
```

波动率的贡献主要来自 $\sigma_{t-1}^2$ ，其系数 $\beta_1$ 为 0.918。通过对数似然的比较，可以发现 GARCH(1,1) 模型比 ARCH(2) 模型更好。

## 贝叶斯可加模型

大规模时间序列回归，观察值是比较多的，可达数十万、数百万，乃至更多。粗粒度时时间跨度往往很长，比如数十年的天粒度数据，细粒度时时间跨度可短可长，比如数年的半小时级数据，总之，需要包含多个季节的数据，各种季节性重复出现。通过时序图可以观察到明显的季节性，而且往往是多种周期不同的季节性混合在一起，有时还包含一定的趋势性。举例来说，比如 2018-2023 年美国旧金山犯罪[事件报告数据](https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-2018-to-Present/wg3w-h783)，事件数量的变化趋势，除了上述季节性因素，特殊事件疫情肯定会影响，数据规模约 200 M 。再比如 2018-2023 年美国境内和跨境旅游业中的[航班数据](https://www.transtats.bts.gov/)，原始数据非常大，R 包 [nycflights13](https://github.com/tidyverse/nycflights13) 提供纽约机场的部分航班数据。

为简单起见，下面以 R 内置的数据集 AirPassengers 为例，介绍 Stan 框架和 INLA 框架建模的过程。数据集 AirPassengers 包含周期性（季节性）和趋势性。作为对比的基础，下面建立非线性回归模型，趋势项和周期项是可加的形式：

$$
y = at + b + c \sin(\frac{t}{12} \times 2\pi) + d \cos(\frac{t}{12} \times 2\pi) + \epsilon
$$

根据数据变化的周期规律，设置周期为 12，还可以在模型中添加周期为 3 或 4 的小周期。其中，$y$ 代表观察值， $a,b,c,d$ 为待定的参数，$\epsilon$ 代表服从标准正态分布的随机误差。

```{r}
#| label: fig-lm
#| fig-cap: 非线性回归
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| par: true

air_passengers_df <- data.frame(y = as.vector(AirPassengers), t = 1:144)
fit_lm1 <- lm(y ~ t + sin(t / 12 * 2 * pi) + cos(t / 12 * 2 * pi), data = air_passengers_df)
fit_lm2 <- update(fit_lm1, . ~ . +
  sin(t / 12 * 2 * 2 * pi) + cos(t / 12 * 2 * 2 * pi),
data = air_passengers_df
)
fit_lm3 <- update(fit_lm2, . ~ . +
  sin(t / 12 * 3 * 2 * pi) + cos(t / 12 * 3 * 2 * pi),
data = air_passengers_df
)
plot(y ~ t, air_passengers_df, type = "l")
lines(x = air_passengers_df$t, y = fit_lm1$fitted.values, col = "red")
lines(x = air_passengers_df$t, y = fit_lm2$fitted.values, col = "green")
lines(x = air_passengers_df$t, y = fit_lm3$fitted.values, col = "orange")
```

模型 1 已经很好地捕捉到趋势和周期信息，当添加小周期后，略有改善，继续添加更多的小周期，不再有明显改善。实际上，小周期对应的回归系数也将不再显著。所以，这类模型的优化空间见顶了，需要进一步观察和利用残差的规律，使用更加复杂的模型。

### Stan 框架

```{r}
library(cmdstanr)
```

### INLA 框架 {#sec-kaust-inla}

模型内容、成分结构和参数解释

阿卜杜拉国王科技大学（King Abdullah University of Science and Technology 简称 KAUST）的 Håvard Rue 等开发了 INLA 框架 [@Rue2009]。INLA 动态时间序列建模 [@Nalini2022]

```{r}
#| message: false

library(INLA)
```

## 一些非参数模型

### mgcv 包 {#sec-gnu-mgcv}

**mgcv** 包 [@Wood2017] 是 R 软件内置的推荐组件，由 Simon Wood 开发和维护，历经多年，成熟稳定。对于时间序列数据预测，数万和百万级观测值都可以 [@wood2015]。函数 `bam()` 相比于函数 `gam()` 的优势是可以处理大规模的时间序列数据。

GAM 估计时序数据中的非线性趋势，残差看作平稳的随机过程，残差序列的相关性由函数 `gamm()` 中参数 correlation 指定。函数 `corCAR1()` 表示一阶条件自回归，这里的条件是指，给定响应变量的分布后，残差序列服从 AR(1) 过程。

```{r}
library(mgcv)
mod <- gamm(y ~ s(t, k = 15),
  data = air_passengers_df, family = gaussian,
  correlation = corCAR1(form = ~t), method = "REML"
)
summary(mod$lme)
```

提取 AR(1) 中的参数 $\phi$ 的估计和置信区间

```{r}
airPhi <- intervals(mod$lme, which = "var-cov")$corStruct
airPhi
```

```{r}
# 趋势估计结果
summary(mod$gam)
```

函数 `gam()` 相比于 `lm()` 的优势是可以用样条拟合非线性趋势，不局限于线性趋势。

```{r}
#| label: fig-mgcv-linear-trend
#| fig-cap: 趋势拟合图
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| par: true

plot(mod$gam)
```

输出结果显示存在线性趋势，符合预期。不过，就此数据集而言，使用 mgcv 包来建模有点杀鸡用牛刀。线性趋势的拟合结果见下图。

```{r}
#| label: fig-mgcv-trend-fitted
#| fig-cap: 线性趋势拟合
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| par: true

plot(y ~ t, air_passengers_df, type = "l")
lines(x = air_passengers_df$t, y = mod$gam$fitted.values, col = "red")
```

可以仿照前面 `lm()` 的介绍，引入三角函数来刻画周期性成分。残差序列不仅限于自回归模型，还可以是一般的 ARMA 模型，比如下面将移动自回归模型的阶定为 p = 2, q = 1。

```{r}
mod2 <- gamm(
  y ~ s(t, k = 15) + I(sin(t / 12 * 2 * pi)) + I(cos(t / 12 * 2 * pi)),
  data = air_passengers_df, family = gaussian,
  correlation = corARMA(form = ~ t, p = 2, q = 1), method = "REML"
)
summary(mod2$lme)
```

```{r}
#| label: fig-mgcv-seasonal-fitted
#| fig-cap: 趋势和季节性拟合
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| par: true

plot(y ~ t, air_passengers_df, type = "l")
lines(x = air_passengers_df$t, y = mod2$gam$fitted.values, col = "red")
```

### tensorflow 框架 {#sec-google-tensorflow}

前面介绍的模型都具有非常强的可解释性，比如各个参数对模型的作用。对于复杂的时间序列数据，比较适合用复杂的模型来拟合，看重模型的泛化能力，而不那么关注模型的机理。

多层感知机是一种全连接层的前馈神经网络。**nnet** 包的函数 `nnet()` 实现了单隐藏层的简单前馈神经网络，可用于时间序列预测，也可用于分类数据的预测。作为对比的基础，下面先用 nnet 包训练和预测数据。

```{r}
# 准备数据
air_passengers <- as.matrix(embed(AirPassengers, 4))
colnames(air_passengers) <- c("y", "x3", "x2", "x1")
data_size <- nrow(air_passengers)
# 拆分数据集
train_size <- floor(data_size * 0.67)
train_data <- air_passengers[1:train_size, ]
test_data <- air_passengers[train_size:data_size, ]

# 随机数种子对结果的影响非常大 试试 set.seed(20232023) 
set.seed(20222022) 
# 单隐藏层 8 个神经元
mod_nnet <- nnet::nnet(
  y ~ x1 + x2 + x3,
  data = air_passengers, # 数据集
  subset = 1:train_size, # 训练数据的指标向量
  linout = TRUE, size = 4, rang = 0.1,
  decay = 5e-4, maxit = 400, trace = FALSE
)
# 预测
train_pred <- predict(mod_nnet, newdata = air_passengers[1:train_size,], type = "raw")
# 训练集 RMSE
sqrt(mean((air_passengers[1:train_size, "y"] - train_pred )^2))
# 预测
test_pred <- predict(mod_nnet, newdata = air_passengers[-(1:train_size),], type = "raw")
# 测试集 RMSE
sqrt(mean((air_passengers[-(1:train_size), "y"] - test_pred)^2))
```

下面将原观测序列，训练集和测试集上的预测序列放在一张图上展示。图中，红色曲线表示训练集上的预测结果，绿色曲线为测试集上预测结果。

```{r}
#| label: fig-nnet
#| fig-cap: 单层感知机预测
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| par: true

train_pred_ts <- ts(data = train_pred, start = c(1949, 3), frequency = 12)
test_pred_ts <- ts(data = test_pred, start = c(1957, 1), frequency = 12)
plot(AirPassengers)
lines(train_pred_ts, col = "red")
lines(test_pred_ts, col = "green")
```

由图可知，在测试集上，随着时间拉长，预测越来越不准。

下面使用 tensorflow 包构造**多层**感知机训练数据和预测。

```{r}
#| message: false

library(tensorflow)
library(keras)
set_random_seed(20222022)
# 模型结构
mod_mlp <- keras_model_sequential() |> 
  layer_dense(units = 12, activation = "relu", input_shape = c(3)) |> 
  layer_dense(units = 8, activation = "relu") |> 
  layer_dense(units = 1)
# 训练目标
compile(mod_mlp,
  loss = "mse", # 损失函数
  optimizer = "adam", # 优化器
  metrics = "mae" # 监控度量
)
# 模型概览
summary(mod_mlp)
```

输入层为 3 个节点，中间两个隐藏层，第一层为 12 个节点，第二层为 8 个节点，全连接网络，最后输出为一层单节点，意味着单个输出。每一层都有节点和权重，参数总数为 161。

```{r}
# 拟合模型
fit(mod_mlp,
  x = train_data[, c("x1", "x2", "x3")],
  y = train_data[, "y"],
  epochs = 200,
  batch_size = 10, # 每次更新梯度所用的样本量
  validation_split = 0.2, # 从训练数据中拆分一部分用作验证集
  verbose = 0 # 不显示训练进度
)
# 将测试数据代入模型，计算损失函数和监控度量
evaluate(mod_mlp, test_data[, c("x1", "x2", "x3")], test_data[, "y"])
# 测试集上的预测
mlp_test_pred <- predict(mod_mlp, test_data[, c("x1", "x2", "x3")]) 
mlp_train_pred <- predict(mod_mlp, train_data[, c("x1", "x2", "x3")]) 
sqrt(mean((test_data[, "y"] - mlp_test_pred)^2)) # 计算均方根误差
```

从 RMSE 来看，MLP（多层感知机）预测效果比单层感知机稍好些，可网络复杂度是增加很多的。

```{r}
#| label: fig-tensorflow-mlp
#| fig-cap: 多层感知机预测
#| fig-showtext: true
#| fig-width: 5
#| fig-height: 4
#| par: true

mlp_train_pred_ts <- ts(data = mlp_train_pred, start = c(1949, 3), frequency = 12)
mlp_test_pred_ts <- ts(data = mlp_test_pred, start = c(1957, 1), frequency = 12)
plot(AirPassengers)
lines(mlp_train_pred_ts, col = "red")
lines(mlp_test_pred_ts, col = "green")
```

下面用 LSTM （长短期记忆）神经网络来训练时间序列数据，预测未来一周的趋势。输出不再是一天（单点输出），而是 7 天的预测值（多点输出）。参考 **tensorflow** 包的[官网](https://tensorflow.rstudio.com/guides/keras/working_with_rnns#introduction)中 RNN 递归神经网络的介绍。

## 习题

1.  基于 R 软件内置的数据集 `sunspots` 和 `sunspot.month` 比较 INLA 和 **mgcv** 框架的预测效果。

    ```{r}
    #| label: fig-sunspots
    #| fig-cap: 预测月粒度太阳黑子数量
    #| fig-width: 7
    #| fig-height: 4
    #| fig-showtext: true
    #| code-fold: true
    #| echo: !expr knitr::is_html_output()

    sunspots_tbl <- broom::tidy(sunspots)
    sunspots_month_tbl <- broom::tidy(sunspot.month)
    ggplot() +
      geom_line(data = sunspots_month_tbl, aes(x = index, y = value), color = "red") +
      geom_line(data = sunspots_tbl, aes(x = index, y = value)) +
      theme_bw() +
      labs(x = "年月", y = "数量")
    ```

    图中黑线和红线分别表示 1749-1983 年、1984-2014 年每月太阳黑子数量。
